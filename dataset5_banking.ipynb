{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Users/bruce/Desktop/datasets/BANK/bank-additional-full.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "duration          0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "y                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['y']=train['y'].map({'no':0,'yes':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>divorced</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>37</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>54</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age            job   marital            education  default  housing  \\\n",
       "0    56      housemaid   married             basic.4y       no       no   \n",
       "1    57       services   married          high.school  unknown       no   \n",
       "2    37       services   married          high.school       no      yes   \n",
       "3    40         admin.   married             basic.6y       no       no   \n",
       "4    56       services   married          high.school       no       no   \n",
       "5    45       services   married             basic.9y  unknown       no   \n",
       "6    59         admin.   married  professional.course       no       no   \n",
       "7    41    blue-collar   married              unknown  unknown       no   \n",
       "8    24     technician    single  professional.course       no      yes   \n",
       "9    25       services    single          high.school       no      yes   \n",
       "10   41    blue-collar   married              unknown  unknown       no   \n",
       "11   25       services    single          high.school       no      yes   \n",
       "12   29    blue-collar    single          high.school       no       no   \n",
       "13   57      housemaid  divorced             basic.4y       no      yes   \n",
       "14   35    blue-collar   married             basic.6y       no      yes   \n",
       "15   54        retired   married             basic.9y  unknown      yes   \n",
       "16   35    blue-collar   married             basic.6y       no      yes   \n",
       "17   46    blue-collar   married             basic.6y  unknown      yes   \n",
       "18   50    blue-collar   married             basic.9y       no      yes   \n",
       "19   39     management    single             basic.9y  unknown       no   \n",
       "20   30     unemployed   married          high.school       no       no   \n",
       "21   55    blue-collar   married             basic.4y  unknown      yes   \n",
       "22   55        retired    single          high.school       no      yes   \n",
       "23   41     technician    single          high.school       no      yes   \n",
       "24   37         admin.   married          high.school       no      yes   \n",
       "25   35     technician   married    university.degree       no       no   \n",
       "26   59     technician   married              unknown       no      yes   \n",
       "27   39  self-employed   married             basic.9y  unknown       no   \n",
       "28   54     technician    single    university.degree  unknown       no   \n",
       "29   55        unknown   married    university.degree  unknown  unknown   \n",
       "\n",
       "       loan    contact month day_of_week ...  campaign  pdays  previous  \\\n",
       "0        no  telephone   may         mon ...         1    999         0   \n",
       "1        no  telephone   may         mon ...         1    999         0   \n",
       "2        no  telephone   may         mon ...         1    999         0   \n",
       "3        no  telephone   may         mon ...         1    999         0   \n",
       "4       yes  telephone   may         mon ...         1    999         0   \n",
       "5        no  telephone   may         mon ...         1    999         0   \n",
       "6        no  telephone   may         mon ...         1    999         0   \n",
       "7        no  telephone   may         mon ...         1    999         0   \n",
       "8        no  telephone   may         mon ...         1    999         0   \n",
       "9        no  telephone   may         mon ...         1    999         0   \n",
       "10       no  telephone   may         mon ...         1    999         0   \n",
       "11       no  telephone   may         mon ...         1    999         0   \n",
       "12      yes  telephone   may         mon ...         1    999         0   \n",
       "13       no  telephone   may         mon ...         1    999         0   \n",
       "14       no  telephone   may         mon ...         1    999         0   \n",
       "15      yes  telephone   may         mon ...         1    999         0   \n",
       "16       no  telephone   may         mon ...         1    999         0   \n",
       "17      yes  telephone   may         mon ...         1    999         0   \n",
       "18      yes  telephone   may         mon ...         1    999         0   \n",
       "19       no  telephone   may         mon ...         1    999         0   \n",
       "20       no  telephone   may         mon ...         1    999         0   \n",
       "21       no  telephone   may         mon ...         1    999         0   \n",
       "22       no  telephone   may         mon ...         1    999         0   \n",
       "23       no  telephone   may         mon ...         1    999         0   \n",
       "24       no  telephone   may         mon ...         1    999         0   \n",
       "25      yes  telephone   may         mon ...         1    999         0   \n",
       "26       no  telephone   may         mon ...         1    999         0   \n",
       "27       no  telephone   may         mon ...         1    999         0   \n",
       "28       no  telephone   may         mon ...         2    999         0   \n",
       "29  unknown  telephone   may         mon ...         1    999         0   \n",
       "\n",
       "       poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "1   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "5   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "6   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "7   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "8   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "9   nonexistent          1.1          93.994          -36.4      4.857   \n",
       "10  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "11  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "12  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "13  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "14  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "15  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "16  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "17  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "18  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "19  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "20  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "21  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "22  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "23  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "24  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "25  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "26  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "27  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "28  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "29  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "\n",
       "    nr.employed  y  \n",
       "0        5191.0  0  \n",
       "1        5191.0  0  \n",
       "2        5191.0  0  \n",
       "3        5191.0  0  \n",
       "4        5191.0  0  \n",
       "5        5191.0  0  \n",
       "6        5191.0  0  \n",
       "7        5191.0  0  \n",
       "8        5191.0  0  \n",
       "9        5191.0  0  \n",
       "10       5191.0  0  \n",
       "11       5191.0  0  \n",
       "12       5191.0  0  \n",
       "13       5191.0  0  \n",
       "14       5191.0  0  \n",
       "15       5191.0  0  \n",
       "16       5191.0  0  \n",
       "17       5191.0  0  \n",
       "18       5191.0  0  \n",
       "19       5191.0  0  \n",
       "20       5191.0  0  \n",
       "21       5191.0  0  \n",
       "22       5191.0  0  \n",
       "23       5191.0  0  \n",
       "24       5191.0  0  \n",
       "25       5191.0  0  \n",
       "26       5191.0  0  \n",
       "27       5191.0  0  \n",
       "28       5191.0  0  \n",
       "29       5191.0  0  \n",
       "\n",
       "[30 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36548 negative instances\n",
      "There are 4640 positive instances\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(train.y[train['y']==0].count())+ \" negative instances\")\n",
    "print(\"There are \" + str(train.y[train['y']==1].count())+ \" positive instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countplots(dataset):\n",
    "    dataset[\"y\"] = pd.Categorical(dataset[\"y\"])\n",
    "    sns.countplot(x=\"y\", data=dataset)\n",
    "    plt.xlabel(\"result\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFXCAYAAACoS5cAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1196e7b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "countplots(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = [\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\", \n",
    "    \"high.school\",  \"professional.course\", \"university.degree\"]\n",
    "levels = range(1,len(values)+1)\n",
    "dict_levels = dict(zip(values, levels))\n",
    "for v in values:\n",
    "    train.loc[train['education'] == v, 'education'] = dict_levels[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_attrs = ['age', 'duration', 'campaign', 'pdays', 'previous',\n",
    "                     'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                     'euribor3m', 'nr.employed',]\n",
    "bin_attrs = ['default', 'housing', 'loan']\n",
    "cate_attrs = ['poutcome', 'education', 'job', 'marital', \n",
    "                  'contact', 'month','day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in numeric_attrs: \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train[i] = scaler.fit_transform(train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in bin_attrs:\n",
    "    train.loc[train[i] == 'no', i] = 0\n",
    "    train.loc[train[i] == 'yes', i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_attrs.remove('education')\n",
    "for i in cate_attrs:\n",
    "    dummies_df = pd.get_dummies(train[i])\n",
    "    dummies_df = dummies_df.rename(columns=lambda x: i+'_'+str(x))\n",
    "    train = pd.concat([train,dummies_df],axis=1)\n",
    "    train = train.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict_unknown(trainX, trainY, testX):\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    forest = forest.fit(trainX, trainY)\n",
    "    test_predictY = forest.predict(testX).astype(int)\n",
    "    return pd.DataFrame(test_predictY,index=testX.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bruce/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "fill_attrs = ['education', 'default', 'housing', 'loan']\n",
    "for i in fill_attrs:     \n",
    "    test_data = train[train[i] == 'unknown']\n",
    "    testX = test_data.drop(fill_attrs, axis=1)\n",
    "    train_data = train[train[i] != 'unknown']        \n",
    "    trainY = list(train_data[i].values)\n",
    "    trainX = train_data.drop(fill_attrs, axis=1)    \n",
    "    test_data[i] = train_predict_unknown(trainX, trainY, testX)\n",
    "    train = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.124520</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.413787</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187888</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.820911</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460069</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.537652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469442</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.441693</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.803333</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.441693</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.139947</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.057857</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.467783</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.628993</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.482104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433071</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.482104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207173</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.957281</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.365306</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.961898</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.849616</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.437075</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322880</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.093650</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.298080</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.332792</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.482104</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.614345</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.341116</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193944</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.578062</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411588</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.149199</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.429405</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.093650</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.229249</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.467783</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.724952</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415445</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.769980</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214887</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.194227</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.379075</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.628993</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.178516</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.628993</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.379668</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.309651</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.482104</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373019</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.477486</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.128377</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.341116</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.379075</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.098268</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029756</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.916870</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.020384</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.245157</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.305794</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-1.441693</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.325078</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.053240</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.135619</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.765363</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380733</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101378</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.381527</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.645200</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.386788</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.093650</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.224799</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.381527</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.332792</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.437075</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349878</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.194227</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.919040</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.865939</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047382</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.093650</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.044119</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.098268</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.255654</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.861322</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.661884</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.578062</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.271082</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age education default housing loan  duration  campaign     pdays  \\\n",
       "0   1.533034         2       0       0    0  0.010471 -0.565922  0.195414   \n",
       "2  -0.290186         5       0       1    0 -0.124520 -0.565922  0.195414   \n",
       "3  -0.002309         3       0       0    0 -0.413787 -0.565922  0.195414   \n",
       "4   1.533034         5       0       0    1  0.187888 -0.565922  0.195414   \n",
       "6   1.820911         6       0       0    0 -0.460069 -0.565922  0.195414   \n",
       "8  -1.537652         6       0       1    0  0.469442 -0.565922  0.195414   \n",
       "9  -1.441693         5       0       1    0 -0.803333 -0.565922  0.195414   \n",
       "11 -1.441693         5       0       1    0 -0.139947 -0.565922  0.195414   \n",
       "12 -1.057857         5       0       0    1 -0.467783 -0.565922  0.195414   \n",
       "13  1.628993         2       0       1    0  0.133892 -0.565922  0.195414   \n",
       "14 -0.482104         3       0       1    0 -0.433071 -0.565922  0.195414   \n",
       "16 -0.482104         3       0       1    0  0.207173 -0.565922  0.195414   \n",
       "18  0.957281         4       0       1    1  0.365306 -0.565922  0.195414   \n",
       "20 -0.961898         5       0       0    0 -0.849616 -0.565922  0.195414   \n",
       "22  1.437075         5       0       1    0  0.322880 -0.565922  0.195414   \n",
       "23  0.093650         5       0       1    0 -0.298080 -0.565922  0.195414   \n",
       "24 -0.290186         5       0       1    0 -0.332792 -0.565922  0.195414   \n",
       "25 -0.482104         7       0       0    1 -0.614345 -0.565922  0.195414   \n",
       "34  1.341116         2       0       0    0 -0.193944 -0.565922  0.195414   \n",
       "36 -0.578062         5       0       0    0  0.411588 -0.565922  0.195414   \n",
       "37  1.149199         4       0       1    0  5.429405 -0.565922  0.195414   \n",
       "38  0.093650         7       0       1    0  1.229249 -0.565922  0.195414   \n",
       "39  1.533034         2       0       1    0 -0.467783 -0.565922  0.195414   \n",
       "40  1.724952         7       0       1    0  0.415445 -0.565922  0.195414   \n",
       "41 -0.769980         5       0       1    0  0.214887 -0.565922  0.195414   \n",
       "42 -0.194227         6       0       0    0 -0.379075 -0.565922  0.195414   \n",
       "43  1.628993         7       0       0    1 -0.178516 -0.565922  0.195414   \n",
       "46  1.628993         7       0       1    1  1.379668 -0.565922  0.195414   \n",
       "47 -0.002309         4       0       0    1 -0.309651 -0.565922  0.195414   \n",
       "48 -0.482104         7       0       1    0  0.373019 -0.565922  0.195414   \n",
       "49  0.477486         4       0       1    0 -0.128377 -0.204909  0.195414   \n",
       "50  1.341116         5       0       0    0 -0.379075 -0.565922  0.195414   \n",
       "51 -0.098268         2       0       0    1  0.029756 -0.565922  0.195414   \n",
       "52  1.916870         5       0       0    0 -0.020384 -0.565922  0.195414   \n",
       "53  1.245157         6       0       0    0 -0.305794 -0.565922  0.195414   \n",
       "59 -1.441693         7       0       1    0 -0.325078 -0.565922  0.195414   \n",
       "61  1.053240         4       0       1    0  2.135619 -0.565922  0.195414   \n",
       "64  0.765363         5       0       0    0  0.380733 -0.565922  0.195414   \n",
       "65 -0.290186         7       0       0    0 -0.101378 -0.565922  0.195414   \n",
       "66  0.381527         4       0       1    0 -0.645200 -0.565922  0.195414   \n",
       "68  1.533034         4       0       1    0 -0.386788 -0.204909  0.195414   \n",
       "70  0.093650         3       0       0    0 -0.224799 -0.565922  0.195414   \n",
       "71  0.381527         7       0       1    0 -0.332792 -0.565922  0.195414   \n",
       "76  1.437075         7       0       0    0  0.349878 -0.565922  0.195414   \n",
       "84 -0.194227         7       0       0    1 -0.919040 -0.565922  0.195414   \n",
       "85 -0.865939         5       0       0    0 -0.047382 -0.565922  0.195414   \n",
       "86  0.093650         3       0       0    0  1.044119 -0.204909  0.195414   \n",
       "87 -0.098268         7       0       1    1 -0.255654 -0.565922  0.195414   \n",
       "88  0.861322         4       0       0    0  4.661884 -0.565922  0.195414   \n",
       "89 -0.578062         5       0       1    0 -0.271082 -0.204909  0.195414   \n",
       "\n",
       "    previous  emp.var.rate       ...         month_mar  month_may  month_nov  \\\n",
       "0  -0.349494      0.648092       ...                 0          1          0   \n",
       "2  -0.349494      0.648092       ...                 0          1          0   \n",
       "3  -0.349494      0.648092       ...                 0          1          0   \n",
       "4  -0.349494      0.648092       ...                 0          1          0   \n",
       "6  -0.349494      0.648092       ...                 0          1          0   \n",
       "8  -0.349494      0.648092       ...                 0          1          0   \n",
       "9  -0.349494      0.648092       ...                 0          1          0   \n",
       "11 -0.349494      0.648092       ...                 0          1          0   \n",
       "12 -0.349494      0.648092       ...                 0          1          0   \n",
       "13 -0.349494      0.648092       ...                 0          1          0   \n",
       "14 -0.349494      0.648092       ...                 0          1          0   \n",
       "16 -0.349494      0.648092       ...                 0          1          0   \n",
       "18 -0.349494      0.648092       ...                 0          1          0   \n",
       "20 -0.349494      0.648092       ...                 0          1          0   \n",
       "22 -0.349494      0.648092       ...                 0          1          0   \n",
       "23 -0.349494      0.648092       ...                 0          1          0   \n",
       "24 -0.349494      0.648092       ...                 0          1          0   \n",
       "25 -0.349494      0.648092       ...                 0          1          0   \n",
       "34 -0.349494      0.648092       ...                 0          1          0   \n",
       "36 -0.349494      0.648092       ...                 0          1          0   \n",
       "37 -0.349494      0.648092       ...                 0          1          0   \n",
       "38 -0.349494      0.648092       ...                 0          1          0   \n",
       "39 -0.349494      0.648092       ...                 0          1          0   \n",
       "40 -0.349494      0.648092       ...                 0          1          0   \n",
       "41 -0.349494      0.648092       ...                 0          1          0   \n",
       "42 -0.349494      0.648092       ...                 0          1          0   \n",
       "43 -0.349494      0.648092       ...                 0          1          0   \n",
       "46 -0.349494      0.648092       ...                 0          1          0   \n",
       "47 -0.349494      0.648092       ...                 0          1          0   \n",
       "48 -0.349494      0.648092       ...                 0          1          0   \n",
       "49 -0.349494      0.648092       ...                 0          1          0   \n",
       "50 -0.349494      0.648092       ...                 0          1          0   \n",
       "51 -0.349494      0.648092       ...                 0          1          0   \n",
       "52 -0.349494      0.648092       ...                 0          1          0   \n",
       "53 -0.349494      0.648092       ...                 0          1          0   \n",
       "59 -0.349494      0.648092       ...                 0          1          0   \n",
       "61 -0.349494      0.648092       ...                 0          1          0   \n",
       "64 -0.349494      0.648092       ...                 0          1          0   \n",
       "65 -0.349494      0.648092       ...                 0          1          0   \n",
       "66 -0.349494      0.648092       ...                 0          1          0   \n",
       "68 -0.349494      0.648092       ...                 0          1          0   \n",
       "70 -0.349494      0.648092       ...                 0          1          0   \n",
       "71 -0.349494      0.648092       ...                 0          1          0   \n",
       "76 -0.349494      0.648092       ...                 0          1          0   \n",
       "84 -0.349494      0.648092       ...                 0          1          0   \n",
       "85 -0.349494      0.648092       ...                 0          1          0   \n",
       "86 -0.349494      0.648092       ...                 0          1          0   \n",
       "87 -0.349494      0.648092       ...                 0          1          0   \n",
       "88 -0.349494      0.648092       ...                 0          1          0   \n",
       "89 -0.349494      0.648092       ...                 0          1          0   \n",
       "\n",
       "    month_oct  month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0           0          0                0                1                0   \n",
       "2           0          0                0                1                0   \n",
       "3           0          0                0                1                0   \n",
       "4           0          0                0                1                0   \n",
       "6           0          0                0                1                0   \n",
       "8           0          0                0                1                0   \n",
       "9           0          0                0                1                0   \n",
       "11          0          0                0                1                0   \n",
       "12          0          0                0                1                0   \n",
       "13          0          0                0                1                0   \n",
       "14          0          0                0                1                0   \n",
       "16          0          0                0                1                0   \n",
       "18          0          0                0                1                0   \n",
       "20          0          0                0                1                0   \n",
       "22          0          0                0                1                0   \n",
       "23          0          0                0                1                0   \n",
       "24          0          0                0                1                0   \n",
       "25          0          0                0                1                0   \n",
       "34          0          0                0                1                0   \n",
       "36          0          0                0                1                0   \n",
       "37          0          0                0                1                0   \n",
       "38          0          0                0                1                0   \n",
       "39          0          0                0                1                0   \n",
       "40          0          0                0                1                0   \n",
       "41          0          0                0                1                0   \n",
       "42          0          0                0                1                0   \n",
       "43          0          0                0                1                0   \n",
       "46          0          0                0                1                0   \n",
       "47          0          0                0                1                0   \n",
       "48          0          0                0                1                0   \n",
       "49          0          0                0                1                0   \n",
       "50          0          0                0                1                0   \n",
       "51          0          0                0                1                0   \n",
       "52          0          0                0                1                0   \n",
       "53          0          0                0                1                0   \n",
       "59          0          0                0                1                0   \n",
       "61          0          0                0                1                0   \n",
       "64          0          0                0                1                0   \n",
       "65          0          0                0                1                0   \n",
       "66          0          0                0                1                0   \n",
       "68          0          0                0                1                0   \n",
       "70          0          0                0                1                0   \n",
       "71          0          0                0                1                0   \n",
       "76          0          0                0                1                0   \n",
       "84          0          0                0                1                0   \n",
       "85          0          0                0                1                0   \n",
       "86          0          0                0                1                0   \n",
       "87          0          0                0                1                0   \n",
       "88          0          0                0                1                0   \n",
       "89          0          0                0                1                0   \n",
       "\n",
       "    day_of_week_tue  day_of_week_wed  \n",
       "0                 0                0  \n",
       "2                 0                0  \n",
       "3                 0                0  \n",
       "4                 0                0  \n",
       "6                 0                0  \n",
       "8                 0                0  \n",
       "9                 0                0  \n",
       "11                0                0  \n",
       "12                0                0  \n",
       "13                0                0  \n",
       "14                0                0  \n",
       "16                0                0  \n",
       "18                0                0  \n",
       "20                0                0  \n",
       "22                0                0  \n",
       "23                0                0  \n",
       "24                0                0  \n",
       "25                0                0  \n",
       "34                0                0  \n",
       "36                0                0  \n",
       "37                0                0  \n",
       "38                0                0  \n",
       "39                0                0  \n",
       "40                0                0  \n",
       "41                0                0  \n",
       "42                0                0  \n",
       "43                0                0  \n",
       "46                0                0  \n",
       "47                0                0  \n",
       "48                0                0  \n",
       "49                0                0  \n",
       "50                0                0  \n",
       "51                0                0  \n",
       "52                0                0  \n",
       "53                0                0  \n",
       "59                0                0  \n",
       "61                0                0  \n",
       "64                0                0  \n",
       "65                0                0  \n",
       "66                0                0  \n",
       "68                0                0  \n",
       "70                0                0  \n",
       "71                0                0  \n",
       "76                0                0  \n",
       "84                0                0  \n",
       "85                0                0  \n",
       "86                0                0  \n",
       "87                0                0  \n",
       "88                0                0  \n",
       "89                0                0  \n",
       "\n",
       "[50 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.290186</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.124520</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.413787</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.533034</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187888</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.820911</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460069</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age education default housing loan  duration  campaign     pdays  \\\n",
       "0  1.533034         2       0       0    0  0.010471 -0.565922  0.195414   \n",
       "2 -0.290186         5       0       1    0 -0.124520 -0.565922  0.195414   \n",
       "3 -0.002309         3       0       0    0 -0.413787 -0.565922  0.195414   \n",
       "4  1.533034         5       0       0    1  0.187888 -0.565922  0.195414   \n",
       "6  1.820911         6       0       0    0 -0.460069 -0.565922  0.195414   \n",
       "\n",
       "   previous  emp.var.rate       ...         month_mar  month_may  month_nov  \\\n",
       "0 -0.349494      0.648092       ...                 0          1          0   \n",
       "2 -0.349494      0.648092       ...                 0          1          0   \n",
       "3 -0.349494      0.648092       ...                 0          1          0   \n",
       "4 -0.349494      0.648092       ...                 0          1          0   \n",
       "6 -0.349494      0.648092       ...                 0          1          0   \n",
       "\n",
       "   month_oct  month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0          0                0                1                0   \n",
       "2          0          0                0                1                0   \n",
       "3          0          0                0                1                0   \n",
       "4          0          0                0                1                0   \n",
       "6          0          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  \n",
       "0                0                0  \n",
       "2                0                0  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "6                0                0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=train.drop(\"y\",axis=1)\n",
    "outcomes=train[\"y\"].values\n",
    "features.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, outcomes, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pr(auc_score, precision, recall, label=None):  \n",
    "    pylab.figure(num=None, figsize=(6, 5))  \n",
    "    pylab.xlim([0.0, 1.0])  \n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Recall')  \n",
    "    pylab.ylabel('Precision')  \n",
    "    pylab.title('P/R (AUC=%0.2f) / %s' % (auc_score, label))  \n",
    "    pylab.fill_between(recall, precision, alpha=0.2)  \n",
    "    pylab.grid(True, linestyle='-', color='0.75')  \n",
    "    pylab.plot(recall, precision, lw=1)      \n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(auc_score, fpr, tpr, label=None):  \n",
    "    pylab.figure(num=None, figsize=(6, 5))  \n",
    "    pylab.xlim([0.0, 1.0])  \n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('False positive rate')  \n",
    "    pylab.ylabel('True positive rate')  \n",
    "    pylab.title('ROC (AUC=%0.2f) / %s' % (auc_score, label))  \n",
    "    pylab.fill_between(fpr, tpr, alpha=0.2)  \n",
    "    pylab.grid(True, linestyle='-', color='0.75')  \n",
    "    pylab.plot(fpr, tpr, lw=1)      \n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest by Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranom Forest         90.28 (+/-) 0.65 \n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=5)\n",
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "cv_result = cross_val_score(model,X_train,Y_train, cv = kfold,scoring = \"accuracy\")\n",
    "results=[\"Ranom Forest\",cv_result.mean(),cv_result.std()]\n",
    "\n",
    "print('{:20s} {:2.2f} (+/-) {:2.2f} '.format(results[0] , results[1] * 100, results[2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy : ', 0.91648052830921622)\n",
      "('Best parameters :', {'max_features': None, 'n_estimators': 500, 'max_depth': 5})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "paramaters = [\n",
    "             {'n_estimators' : [100, 200, 300, 500, 1000], \n",
    "              'max_features' : ['auto','log2',None],\n",
    "              'max_depth':[3,4,5],\n",
    "             }                                       \n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train,Y_train)\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8756  376]\n",
      " [ 501  664]]\n",
      "91.4829562008\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      9132\n",
      "          1       0.64      0.57      0.60      1165\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from matplotlib import pylab\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=500,max_features=None,bootstrap=True,oob_score=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9070   62]\n",
      " [ 909  256]]\n",
      "90.5700689521\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95      9132\n",
      "          1       0.81      0.22      0.35      1165\n",
      "\n",
      "avg / total       0.90      0.91      0.88     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=500,max_features='auto',bootstrap=False,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "\n",
    "\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest by Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8832  300]\n",
      " [ 531  634]]\n",
      "91.9296882587\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.96      9132\n",
      "          1       0.68      0.54      0.60      1165\n",
      "\n",
      "avg / total       0.91      0.92      0.92     10297\n",
      "\n",
      "0.755677248707\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=5,subsample=0.632,colsample_bytree=0.4)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate1, true_positive_rate1, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc1 = auc(false_positive_rate1, true_positive_rate1)\n",
    "print(roc_auc1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison tree by xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8739  393]\n",
      " [ 506  659]]\n",
      "91.2693017384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      9132\n",
      "          1       0.63      0.57      0.59      1165\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10297\n",
      "\n",
      "0.76131487821\n"
     ]
    }
   ],
   "source": [
    "final_model = XGBClassifier(n_estimators=1,num_boost_round=1,max_depth=5,subsample=1,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate2, true_positive_rate2, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc2 = auc(false_positive_rate2, true_positive_rate2)\n",
    "print(roc_auc2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagged decision tree by Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8795  337]\n",
      " [ 508  657]]\n",
      "91.7937263281\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      9132\n",
      "          1       0.66      0.56      0.61      1165\n",
      "\n",
      "avg / total       0.91      0.92      0.92     10297\n",
      "\n",
      "0.763522650153\n"
     ]
    }
   ],
   "source": [
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=5,subsample=0.632,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate3, true_positive_rate3, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc3 = auc(false_positive_rate3, true_positive_rate3)\n",
    "print(roc_auc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAETCAYAAABKlK+0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112b079d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.title('Receiver Operating Characteristic Bank Marketing Dataset')\n",
    "plt.plot(false_positive_rate1,true_positive_rate1, color='red',label = 'random forests = %0.2f' % roc_auc1)\n",
    "plt.plot(false_positive_rate3,true_positive_rate3, color='green',label = 'single tree= %0.2f' % roc_auc3)\n",
    "plt.plot(false_positive_rate2,true_positive_rate2, color='blue',label = 'bagged trees = %0.2f' % roc_auc2)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.axis('tight')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.layers import Dense, Activation, Dropout,Input\n",
    "from keras import optimizers\n",
    "history=History()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard feedforward neura network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(1280, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(128, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(128, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(len(np.unique(Y_train)), activation='softmax'))\n",
    "    \n",
    "m.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27801 samples, validate on 3090 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.24307, saving model to best.model\n",
      "2s - loss: 0.3757 - acc: 0.8785 - val_loss: 0.2431 - val_acc: 0.8990\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.24307 to 0.18144, saving model to best.model\n",
      "2s - loss: 0.2457 - acc: 0.8948 - val_loss: 0.1814 - val_acc: 0.9191\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.18144 to 0.17381, saving model to best.model\n",
      "2s - loss: 0.2172 - acc: 0.8997 - val_loss: 0.1738 - val_acc: 0.9181\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.17381 to 0.17143, saving model to best.model\n",
      "2s - loss: 0.2057 - acc: 0.9037 - val_loss: 0.1714 - val_acc: 0.9197\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "2s - loss: 0.2054 - acc: 0.9045 - val_loss: 0.1731 - val_acc: 0.9191\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.17143 to 0.17058, saving model to best.model\n",
      "2s - loss: 0.2031 - acc: 0.9051 - val_loss: 0.1706 - val_acc: 0.9220\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.17058 to 0.17053, saving model to best.model\n",
      "2s - loss: 0.1995 - acc: 0.9061 - val_loss: 0.1705 - val_acc: 0.9188\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "2s - loss: 0.1984 - acc: 0.9077 - val_loss: 0.1713 - val_acc: 0.9194\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "2s - loss: 0.1994 - acc: 0.9080 - val_loss: 0.1705 - val_acc: 0.9191\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "2s - loss: 0.1973 - acc: 0.9086 - val_loss: 0.1721 - val_acc: 0.9184\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "2s - loss: 0.1969 - acc: 0.9088 - val_loss: 0.1735 - val_acc: 0.9184\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "2s - loss: 0.1947 - acc: 0.9081 - val_loss: 0.1715 - val_acc: 0.9178\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.17053 to 0.16994, saving model to best.model\n",
      "2s - loss: 0.1960 - acc: 0.9093 - val_loss: 0.1699 - val_acc: 0.9188\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "2s - loss: 0.1948 - acc: 0.9094 - val_loss: 0.1719 - val_acc: 0.9178\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.16994 to 0.16992, saving model to best.model\n",
      "2s - loss: 0.1932 - acc: 0.9096 - val_loss: 0.1699 - val_acc: 0.9197\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "2s - loss: 0.1932 - acc: 0.9098 - val_loss: 0.1708 - val_acc: 0.9181\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "2s - loss: 0.1916 - acc: 0.9120 - val_loss: 0.1704 - val_acc: 0.9204\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "2s - loss: 0.1919 - acc: 0.9098 - val_loss: 0.1708 - val_acc: 0.9191\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "2s - loss: 0.1923 - acc: 0.9108 - val_loss: 0.1707 - val_acc: 0.9191\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "2s - loss: 0.1921 - acc: 0.9107 - val_loss: 0.1725 - val_acc: 0.9184\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "2s - loss: 0.1910 - acc: 0.9113 - val_loss: 0.1733 - val_acc: 0.9184\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "2s - loss: 0.1906 - acc: 0.9104 - val_loss: 0.1718 - val_acc: 0.9207\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "2s - loss: 0.1908 - acc: 0.9116 - val_loss: 0.1722 - val_acc: 0.9197\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "2s - loss: 0.1900 - acc: 0.9116 - val_loss: 0.1726 - val_acc: 0.9184\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "2s - loss: 0.1893 - acc: 0.9120 - val_loss: 0.1727 - val_acc: 0.9181\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "2s - loss: 0.1891 - acc: 0.9122 - val_loss: 0.1771 - val_acc: 0.9201\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "2s - loss: 0.1895 - acc: 0.9116 - val_loss: 0.1720 - val_acc: 0.9178\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "2s - loss: 0.1882 - acc: 0.9121 - val_loss: 0.1716 - val_acc: 0.9188\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "2s - loss: 0.1893 - acc: 0.9120 - val_loss: 0.1726 - val_acc: 0.9181\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "2s - loss: 0.1881 - acc: 0.9126 - val_loss: 0.1785 - val_acc: 0.9197\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "2s - loss: 0.1877 - acc: 0.9109 - val_loss: 0.1723 - val_acc: 0.9188\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "2s - loss: 0.1876 - acc: 0.9128 - val_loss: 0.1723 - val_acc: 0.9204\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "2s - loss: 0.1883 - acc: 0.9128 - val_loss: 0.1743 - val_acc: 0.9197\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "2s - loss: 0.1873 - acc: 0.9132 - val_loss: 0.1725 - val_acc: 0.9194\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "2s - loss: 0.1878 - acc: 0.9121 - val_loss: 0.1738 - val_acc: 0.9194\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "2s - loss: 0.1863 - acc: 0.9137 - val_loss: 0.1731 - val_acc: 0.9188\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "2s - loss: 0.1864 - acc: 0.9127 - val_loss: 0.1720 - val_acc: 0.9191\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "2s - loss: 0.1871 - acc: 0.9129 - val_loss: 0.1718 - val_acc: 0.9197\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "2s - loss: 0.1868 - acc: 0.9122 - val_loss: 0.1734 - val_acc: 0.9197\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "2s - loss: 0.1862 - acc: 0.9136 - val_loss: 0.1724 - val_acc: 0.9197\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "2s - loss: 0.1867 - acc: 0.9120 - val_loss: 0.1723 - val_acc: 0.9197\n"
     ]
    }
   ],
   "source": [
    "hist=m.fit(\n",
    "    # Feature matrix\n",
    "    X_train.values, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        History(),\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.load_weights(\"best.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in m.predict(X_test.values).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8797  335]\n",
      " [ 591  574]]\n",
      "91.0070894435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      9132\n",
      "          1       0.63      0.49      0.55      1165\n",
      "\n",
      "avg / total       0.90      0.91      0.91     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFlCAYAAADyLnFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYKgTERFlCYY6ERFRlmCoExERZYn/D7DFP5J/VnB2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c815dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'education', u'default', u'housing', u'loan', u'duration',\n",
       "       u'campaign', u'pdays', u'previous', u'emp.var.rate', u'cons.price.idx',\n",
       "       u'cons.conf.idx', u'euribor3m', u'nr.employed', u'y',\n",
       "       u'poutcome_failure', u'poutcome_nonexistent', u'poutcome_success',\n",
       "       u'job_admin.', u'job_blue-collar', u'job_entrepreneur',\n",
       "       u'job_housemaid', u'job_management', u'job_retired',\n",
       "       u'job_self-employed', u'job_services', u'job_student',\n",
       "       u'job_technician', u'job_unemployed', u'job_unknown',\n",
       "       u'marital_divorced', u'marital_married', u'marital_single',\n",
       "       u'marital_unknown', u'contact_cellular', u'contact_telephone',\n",
       "       u'month_apr', u'month_aug', u'month_dec', u'month_jul', u'month_jun',\n",
       "       u'month_mar', u'month_may', u'month_nov', u'month_oct', u'month_sep',\n",
       "       u'day_of_week_fri', u'day_of_week_mon', u'day_of_week_thu',\n",
       "       u'day_of_week_tue', u'day_of_week_wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27801 samples, validate on 3090 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.18434, saving model to best.model\n",
      "6s - loss: 0.2661 - acc: 0.8959 - val_loss: 0.1843 - val_acc: 0.9204\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.18434 to 0.17314, saving model to best.model\n",
      "6s - loss: 0.2076 - acc: 0.9067 - val_loss: 0.1731 - val_acc: 0.9217\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.17314 to 0.17206, saving model to best.model\n",
      "6s - loss: 0.2016 - acc: 0.9080 - val_loss: 0.1721 - val_acc: 0.9159\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "6s - loss: 0.2008 - acc: 0.9069 - val_loss: 0.1752 - val_acc: 0.9094\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "6s - loss: 0.1989 - acc: 0.9074 - val_loss: 0.1763 - val_acc: 0.9133\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "6s - loss: 0.1991 - acc: 0.9067 - val_loss: 0.1742 - val_acc: 0.9152\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "6s - loss: 0.1967 - acc: 0.9083 - val_loss: 0.1764 - val_acc: 0.9230\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "7s - loss: 0.1960 - acc: 0.9086 - val_loss: 0.1731 - val_acc: 0.9220\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "8s - loss: 0.1942 - acc: 0.9077 - val_loss: 0.1920 - val_acc: 0.9136\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "8s - loss: 0.1950 - acc: 0.9077 - val_loss: 0.1782 - val_acc: 0.9172\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.17206 to 0.17045, saving model to best.model\n",
      "7s - loss: 0.1922 - acc: 0.9092 - val_loss: 0.1705 - val_acc: 0.9217\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "7s - loss: 0.1918 - acc: 0.9102 - val_loss: 0.1717 - val_acc: 0.9162\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.17045 to 0.17038, saving model to best.model\n",
      "7s - loss: 0.1930 - acc: 0.9083 - val_loss: 0.1704 - val_acc: 0.9197\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "7s - loss: 0.1918 - acc: 0.9102 - val_loss: 0.1705 - val_acc: 0.9184\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "7s - loss: 0.1918 - acc: 0.9086 - val_loss: 0.1710 - val_acc: 0.9184\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "7s - loss: 0.1907 - acc: 0.9099 - val_loss: 0.1750 - val_acc: 0.9146\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "8s - loss: 0.1906 - acc: 0.9105 - val_loss: 0.1709 - val_acc: 0.9223\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "6s - loss: 0.1895 - acc: 0.9097 - val_loss: 0.1722 - val_acc: 0.9217\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "6s - loss: 0.1884 - acc: 0.9107 - val_loss: 0.1864 - val_acc: 0.9026\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "6s - loss: 0.1895 - acc: 0.9108 - val_loss: 0.1728 - val_acc: 0.9191\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "6s - loss: 0.1879 - acc: 0.9124 - val_loss: 0.1888 - val_acc: 0.9010\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "6s - loss: 0.1897 - acc: 0.9099 - val_loss: 0.1863 - val_acc: 0.9071\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "6s - loss: 0.1881 - acc: 0.9124 - val_loss: 0.1723 - val_acc: 0.9191\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "6s - loss: 0.1890 - acc: 0.9121 - val_loss: 0.1727 - val_acc: 0.9146\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "6s - loss: 0.1877 - acc: 0.9110 - val_loss: 0.1762 - val_acc: 0.9197\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "8s - loss: 0.1882 - acc: 0.9107 - val_loss: 0.1739 - val_acc: 0.9168\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "7s - loss: 0.1878 - acc: 0.9113 - val_loss: 0.1745 - val_acc: 0.9165\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "8s - loss: 0.1862 - acc: 0.9113 - val_loss: 0.1746 - val_acc: 0.9181\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "7s - loss: 0.1864 - acc: 0.9122 - val_loss: 0.1734 - val_acc: 0.9178\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "8s - loss: 0.1870 - acc: 0.9124 - val_loss: 0.1964 - val_acc: 0.9094\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "7s - loss: 0.1857 - acc: 0.9128 - val_loss: 0.1727 - val_acc: 0.9191\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "7s - loss: 0.1840 - acc: 0.9142 - val_loss: 0.1718 - val_acc: 0.9204\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "7s - loss: 0.1846 - acc: 0.9138 - val_loss: 0.1748 - val_acc: 0.9194\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "7s - loss: 0.1848 - acc: 0.9123 - val_loss: 0.1770 - val_acc: 0.9191\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "7s - loss: 0.1840 - acc: 0.9126 - val_loss: 0.1819 - val_acc: 0.9061\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "7s - loss: 0.1838 - acc: 0.9135 - val_loss: 0.1725 - val_acc: 0.9172\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "6s - loss: 0.1839 - acc: 0.9133 - val_loss: 0.1744 - val_acc: 0.9184\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "6s - loss: 0.1841 - acc: 0.9121 - val_loss: 0.1738 - val_acc: 0.9168\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "6s - loss: 0.1828 - acc: 0.9123 - val_loss: 0.1740 - val_acc: 0.9201\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.models import Model\n",
    "import keras\n",
    "history = History()\n",
    "\n",
    "\n",
    "input_1 = Input(shape=(1,))\n",
    "input_2 = Input(shape=(1,))\n",
    "input_3 = Input(shape=(1,))\n",
    "input_4 = Input(shape=(1,))\n",
    "input_5 = Input(shape=(1,))\n",
    "input_6 = Input(shape=(1,))\n",
    "input_7 = Input(shape=(1,))\n",
    "input_8 = Input(shape=(1,))\n",
    "input_9 = Input(shape=(1,))\n",
    "input_10 = Input(shape=(1,))\n",
    "input_11= Input(shape=(1,))\n",
    "input_12= Input(shape=(1,))\n",
    "input_13= Input(shape=(1,))\n",
    "input_14= Input(shape=(1,))\n",
    "input_15= Input(shape=(1,))\n",
    "input_16= Input(shape=(1,))\n",
    "\n",
    "input_17= Input(shape=(1,))\n",
    "input_18= Input(shape=(1,))\n",
    "input_19= Input(shape=(1,))\n",
    "input_20= Input(shape=(1,))\n",
    "input_21= Input(shape=(1,))\n",
    "input_22 = Input(shape=(1,))\n",
    "input_23= Input(shape=(1,))\n",
    "input_24= Input(shape=(1,))\n",
    "\n",
    "input_25= Input(shape=(1,))\n",
    "input_26= Input(shape=(1,))\n",
    "input_27= Input(shape=(1,))\n",
    "input_28= Input(shape=(1,))\n",
    "input_29= Input(shape=(1,))\n",
    "input_30= Input(shape=(1,))\n",
    "input_31= Input(shape=(1,))\n",
    "input_32= Input(shape=(1,))\n",
    "\n",
    "input_33= Input(shape=(1,))\n",
    "input_34= Input(shape=(1,))\n",
    "input_35= Input(shape=(1,))\n",
    "input_36= Input(shape=(1,))\n",
    "input_37= Input(shape=(1,))\n",
    "input_38= Input(shape=(1,))\n",
    "input_39 = Input(shape=(1,))\n",
    "input_40= Input(shape=(1,))\n",
    "\n",
    "input_41 = Input(shape=(1,))\n",
    "input_42 = Input(shape=(1,))\n",
    "input_43 = Input(shape=(1,))\n",
    "input_44 = Input(shape=(1,))\n",
    "input_45 = Input(shape=(1,))\n",
    "input_46 = Input(shape=(1,))\n",
    "input_47 = Input(shape=(1,))\n",
    "input_48 = Input(shape=(1,))\n",
    "input_49 = Input(shape=(1,))\n",
    "input_50 = Input(shape=(1,))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_1 = Dense(32, activation='sigmoid')(input_1)\n",
    "hidden_2 = Dense(32, activation='sigmoid')(input_2)\n",
    "hidden_3 = Dense(32, activation='sigmoid')(input_3)\n",
    "hidden_4 = Dense(32, activation='sigmoid')(input_4)\n",
    "hidden_5 = Dense(32, activation='sigmoid')(input_5)\n",
    "hidden_6 = Dense(32, activation='sigmoid')(input_6)\n",
    "hidden_7 = Dense(32, activation='sigmoid')(input_7)\n",
    "hidden_8 = Dense(32, activation='sigmoid')(input_8)\n",
    "hidden_9 = Dense(32, activation='sigmoid')(input_9)\n",
    "hidden_10 = Dense(32, activation='sigmoid')(input_10)\n",
    "hidden_11= Dense(32, activation='sigmoid')(input_11)\n",
    "hidden_12 = Dense(32, activation='sigmoid')(input_12)\n",
    "hidden_13 = Dense(32, activation='sigmoid')(input_13)\n",
    "hidden_14 = Dense(32, activation='sigmoid')(input_14)\n",
    "hidden_15 = Dense(32, activation='sigmoid')(input_15)\n",
    "hidden_16 = Dense(32, activation='sigmoid')(input_16)\n",
    "hidden_17 = Dense(32, activation='sigmoid')(input_17)\n",
    "hidden_18 = Dense(32, activation='sigmoid')(input_18)\n",
    "hidden_19 = Dense(32, activation='sigmoid')(input_19)\n",
    "hidden_20 = Dense(32, activation='sigmoid')(input_20)\n",
    "\n",
    "hidden_21 = Dense(32, activation='sigmoid')(input_21)\n",
    "hidden_22 = Dense(32, activation='sigmoid')(input_22)\n",
    "hidden_23 = Dense(32, activation='sigmoid')(input_23)\n",
    "hidden_24 = Dense(32, activation='sigmoid')(input_24)\n",
    "hidden_25 = Dense(32, activation='sigmoid')(input_25)\n",
    "hidden_26 = Dense(32, activation='sigmoid')(input_26)\n",
    "hidden_27 = Dense(32, activation='sigmoid')(input_27)\n",
    "hidden_28 = Dense(32, activation='sigmoid')(input_28)\n",
    "hidden_29 = Dense(32, activation='sigmoid')(input_29)\n",
    "hidden_30 = Dense(32, activation='sigmoid')(input_30)\n",
    "hidden_31 = Dense(32, activation='sigmoid')(input_31)\n",
    "hidden_32 = Dense(32, activation='sigmoid')(input_32)\n",
    "hidden_33 = Dense(32, activation='sigmoid')(input_33)\n",
    "hidden_34 = Dense(32, activation='sigmoid')(input_34)\n",
    "hidden_35 = Dense(32, activation='sigmoid')(input_35)\n",
    "hidden_36 = Dense(32, activation='sigmoid')(input_36)\n",
    "hidden_37 = Dense(32, activation='sigmoid')(input_37)\n",
    "hidden_38 = Dense(32, activation='sigmoid')(input_38)\n",
    "hidden_39 = Dense(32, activation='sigmoid')(input_39)\n",
    "hidden_40 = Dense(32, activation='sigmoid')(input_40)\n",
    "hidden_41 = Dense(32, activation='sigmoid')(input_41)\n",
    "hidden_42 = Dense(32, activation='sigmoid')(input_42)\n",
    "hidden_43 = Dense(32, activation='sigmoid')(input_43)\n",
    "hidden_44 = Dense(32, activation='sigmoid')(input_44)\n",
    "hidden_45 = Dense(32, activation='sigmoid')(input_45)\n",
    "hidden_46 = Dense(32, activation='sigmoid')(input_46)\n",
    "hidden_47 = Dense(32, activation='sigmoid')(input_47)\n",
    "hidden_48 = Dense(32, activation='sigmoid')(input_48)\n",
    "hidden_49 = Dense(32, activation='sigmoid')(input_49)\n",
    "hidden_50 = Dense(32, activation='sigmoid')(input_50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "value_list=[X_train[['age']].values,\n",
    "            X_train[['education']].values,\n",
    "            X_train[['default']].values,\n",
    "            X_train[['housing']].values,\n",
    "            X_train[['loan']].values,\n",
    "            X_train[['duration']].values,\n",
    "            X_train[['campaign']].values,\n",
    "            X_train[['pdays']].values,\n",
    "            X_train[['previous']].values,\n",
    "            X_train[['emp.var.rate']].values,\n",
    "            X_train[['cons.price.idx']].values,\n",
    "            X_train[['cons.conf.idx']].values,\n",
    "            X_train[['euribor3m']].values,\n",
    "            X_train[['nr.employed']].values,\n",
    "            X_train[['poutcome_failure']].values,\n",
    "            X_train[['poutcome_nonexistent']].values,\n",
    "            X_train[['poutcome_success']].values,\n",
    "            X_train[['job_admin.']].values,\n",
    "            X_train[['job_blue-collar']].values,\n",
    "            X_train[['job_entrepreneur']].values,\n",
    "            X_train[['job_housemaid']].values,\n",
    "            X_train[['job_management']].values,\n",
    "            X_train[['job_retired']].values,\n",
    "            X_train[['job_self-employed']].values,\n",
    "            X_train[['job_student']].values,\n",
    "            X_train[['job_technician']].values,\n",
    "            X_train[['job_services']].values,\n",
    "            X_train[['job_unemployed']].values,\n",
    "            X_train[['job_unknown']].values,\n",
    "            X_train[['contact_cellular']].values,\n",
    "            X_train[['marital_divorced']].values,\n",
    "            X_train[['marital_single']].values,\n",
    "            X_train[['marital_married']].values,\n",
    "            X_train[['marital_unknown']].values,\n",
    "            X_train[['contact_telephone']].values,\n",
    "            X_train[['month_apr']].values,\n",
    "            X_train[['month_aug']].values,\n",
    "            X_train[['month_jul']].values,\n",
    "            X_train[['month_dec']].values,\n",
    "            X_train[['month_jun']].values,\n",
    "            X_train[['month_mar']].values,\n",
    "            X_train[['month_may']].values,\n",
    "            X_train[['month_nov']].values,\n",
    "            X_train[['month_oct']].values,\n",
    "            X_train[['month_sep']].values,\n",
    "            X_train[['day_of_week_fri']].values,\n",
    "            X_train[['day_of_week_mon']].values,\n",
    "            X_train[['day_of_week_thu']].values,\n",
    "            X_train[['day_of_week_tue']].values,\n",
    "            X_train[['day_of_week_wed']].values\n",
    "           ]\n",
    "\n",
    "value_list_test=[X_test[['age']].values,\n",
    "            X_test[['education']].values,\n",
    "            X_test[['default']].values,\n",
    "            X_test[['housing']].values,\n",
    "            X_test[['loan']].values,\n",
    "            X_test[['duration']].values,\n",
    "            X_test[['campaign']].values,\n",
    "            X_test[['pdays']].values,\n",
    "            X_test[['previous']].values,\n",
    "            X_test[['emp.var.rate']].values,\n",
    "            X_test[['cons.price.idx']].values,\n",
    "            X_test[['cons.conf.idx']].values,\n",
    "            X_test[['euribor3m']].values,\n",
    "            X_test[['nr.employed']].values,\n",
    "            X_test[['poutcome_failure']].values,\n",
    "            X_test[['poutcome_nonexistent']].values,\n",
    "            X_test[['poutcome_success']].values,\n",
    "            X_test[['job_admin.']].values,\n",
    "            X_test[['job_blue-collar']].values,\n",
    "            X_test[['job_entrepreneur']].values,\n",
    "            X_test[['job_housemaid']].values,\n",
    "            X_test[['job_management']].values,\n",
    "            X_test[['job_retired']].values,\n",
    "            X_test[['job_self-employed']].values,\n",
    "            X_test[['job_student']].values,\n",
    "            X_test[['job_technician']].values,\n",
    "            X_test[['job_services']].values,\n",
    "            X_test[['job_unemployed']].values,\n",
    "            X_test[['job_unknown']].values,\n",
    "            X_test[['contact_cellular']].values,\n",
    "            X_test[['marital_divorced']].values,\n",
    "            X_test[['marital_single']].values,\n",
    "            X_test[['marital_married']].values,\n",
    "            X_test[['marital_unknown']].values,\n",
    "            X_test[['contact_telephone']].values,\n",
    "            X_test[['month_apr']].values,\n",
    "            X_test[['month_aug']].values,\n",
    "            X_test[['month_jul']].values,\n",
    "            X_test[['month_dec']].values,\n",
    "            X_test[['month_jun']].values,\n",
    "            X_test[['month_mar']].values,\n",
    "            X_test[['month_may']].values,\n",
    "            X_test[['month_nov']].values,\n",
    "            X_test[['month_oct']].values,\n",
    "            X_test[['month_sep']].values,\n",
    "            X_test[['day_of_week_fri']].values,\n",
    "            X_test[['day_of_week_mon']].values,\n",
    "            X_test[['day_of_week_thu']].values,\n",
    "            X_test[['day_of_week_tue']].values,\n",
    "            X_test[['day_of_week_wed']].values\n",
    "           ]\n",
    "\n",
    "x = keras.layers.concatenate([hidden_1,hidden_2,hidden_3,hidden_4,hidden_5,hidden_6,hidden_7,hidden_8,\n",
    "                             hidden_9,hidden_10,hidden_11,hidden_12,hidden_13,hidden_14,hidden_15,hidden_16,\n",
    "                             hidden_17,hidden_18,hidden_19,hidden_20,hidden_21,hidden_22,hidden_23,hidden_24,\n",
    "                             hidden_25,hidden_26,hidden_27,hidden_28,hidden_29,hidden_30,hidden_31,hidden_32,\n",
    "                             hidden_33,hidden_34,hidden_35,hidden_36,hidden_37,hidden_38,hidden_39,hidden_40,\n",
    "                             hidden_41,hidden_42,hidden_43,hidden_44,hidden_45,hidden_46,hidden_47,hidden_48,\n",
    "                             hidden_49,hidden_50])\n",
    "\n",
    "x = Dense(96, activation='sigmoid')(x)\n",
    "output = Dense(len(np.unique(Y_train)), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_1,input_2,input_3,input_4,input_5,input_6,input_7,input_8,\n",
    "                     input_9,input_10,input_11,input_12,input_13,input_14,input_15,input_16,\n",
    "                     input_17,input_18,input_19,input_20,input_21,input_22,input_23,input_24,\n",
    "                     input_25,input_26,input_27,input_28,input_29,input_30,input_31,input_32,\n",
    "                     input_33,input_34,input_35,input_36,input_37,input_38,input_39,input_40,\n",
    "                     input_41,input_42,input_43,input_44,input_45,input_46,input_47,input_48,\n",
    "                     input_49,input_50], outputs=[output])\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "hist=model.fit(\n",
    "    # Feature matrix\n",
    "    value_list, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        history,\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=32, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best.model\")\n",
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in model.predict(value_list_test).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8863  269]\n",
      " [ 640  525]]\n",
      "91.1721860736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95      9132\n",
      "          1       0.66      0.45      0.54      1165\n",
      "\n",
      "avg / total       0.90      0.91      0.90     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFlCAYAAADyLnFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRkhQF0IIIWzE/wM/0JGGmcpfhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1276e6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train,data_val=train_test_split(train,test_size=0.25, random_state=10)\n",
    "X_val=data_val.drop(['y'], axis=1).values\n",
    "y_val=data_val['y'].ravel()\n",
    "\n",
    "def train_nn_simple(data_train,X_val,y_val):\n",
    "    \n",
    "\n",
    "    data_train_new=data_train.sample(frac=0.632,replace=True)\n",
    "    X_train=data_train_new.drop(['y'], axis=1).values\n",
    "    y_train=data_train_new['y'].ravel()\n",
    "    \n",
    "    m = Sequential()\n",
    "    m.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='sigmoid'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='sigmoid'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "    \n",
    "    m.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    m.fit(\n",
    "    # Feature matrix\n",
    "    X_train, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.2,\n",
    "    batch_size=256, \n",
    "    )\n",
    "    m.load_weights(\"best.model\")\n",
    "    mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    "    )\n",
    "    y_pred = [mapping[pred] for pred in m.predict(X_val).argmax(axis=1)]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31884, saving model to best.model\n",
      "0s - loss: 0.4022 - acc: 0.8756 - val_loss: 0.3188 - val_acc: 0.8911\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31884 to 0.24314, saving model to best.model\n",
      "0s - loss: 0.3185 - acc: 0.8864 - val_loss: 0.2431 - val_acc: 0.9024\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24314 to 0.20818, saving model to best.model\n",
      "0s - loss: 0.2597 - acc: 0.8964 - val_loss: 0.2082 - val_acc: 0.9049\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20818 to 0.19932, saving model to best.model\n",
      "0s - loss: 0.2320 - acc: 0.9004 - val_loss: 0.1993 - val_acc: 0.9057\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19932 to 0.19392, saving model to best.model\n",
      "0s - loss: 0.2214 - acc: 0.9029 - val_loss: 0.1939 - val_acc: 0.9070\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19392 to 0.19291, saving model to best.model\n",
      "0s - loss: 0.2148 - acc: 0.9039 - val_loss: 0.1929 - val_acc: 0.9070\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19291 to 0.19275, saving model to best.model\n",
      "0s - loss: 0.2082 - acc: 0.9051 - val_loss: 0.1928 - val_acc: 0.9076\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19275 to 0.19173, saving model to best.model\n",
      "0s - loss: 0.2055 - acc: 0.9048 - val_loss: 0.1917 - val_acc: 0.9078\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19173 to 0.19148, saving model to best.model\n",
      "0s - loss: 0.2066 - acc: 0.9042 - val_loss: 0.1915 - val_acc: 0.9067\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2026 - acc: 0.9048 - val_loss: 0.1915 - val_acc: 0.9078\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19148 to 0.19104, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9043 - val_loss: 0.1910 - val_acc: 0.9063\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9060 - val_loss: 0.1914 - val_acc: 0.9070\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9061 - val_loss: 0.1911 - val_acc: 0.9082\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19104 to 0.19067, saving model to best.model\n",
      "0s - loss: 0.1980 - acc: 0.9061 - val_loss: 0.1907 - val_acc: 0.9063\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1981 - acc: 0.9067 - val_loss: 0.1909 - val_acc: 0.9076\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9059 - val_loss: 0.1909 - val_acc: 0.9063\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9049 - val_loss: 0.1907 - val_acc: 0.9076\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9050 - val_loss: 0.1908 - val_acc: 0.9061\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19067 to 0.19057, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9056 - val_loss: 0.1906 - val_acc: 0.9061\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1949 - acc: 0.9066 - val_loss: 0.1909 - val_acc: 0.9084\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19057 to 0.19017, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9060 - val_loss: 0.1902 - val_acc: 0.9057\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19017 to 0.19011, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9072 - val_loss: 0.1901 - val_acc: 0.9057\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9068 - val_loss: 0.1911 - val_acc: 0.9057\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19011 to 0.18998, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9066 - val_loss: 0.1900 - val_acc: 0.9063\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9067 - val_loss: 0.1900 - val_acc: 0.9061\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18998 to 0.18971, saving model to best.model\n",
      "0s - loss: 0.1936 - acc: 0.9071 - val_loss: 0.1897 - val_acc: 0.9059\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9077 - val_loss: 0.1898 - val_acc: 0.9063\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18971 to 0.18952, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9066 - val_loss: 0.1895 - val_acc: 0.9059\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18952 to 0.18949, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9068 - val_loss: 0.1895 - val_acc: 0.9082\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9065 - val_loss: 0.1899 - val_acc: 0.9086\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9075 - val_loss: 0.1900 - val_acc: 0.9069\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18949 to 0.18896, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9084 - val_loss: 0.1890 - val_acc: 0.9086\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9077 - val_loss: 0.1894 - val_acc: 0.9086\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9086 - val_loss: 0.1892 - val_acc: 0.9084\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18896 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9080 - val_loss: 0.1888 - val_acc: 0.9092\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18876 to 0.18841, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9079 - val_loss: 0.1884 - val_acc: 0.9095\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18841 to 0.18840, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9077 - val_loss: 0.1884 - val_acc: 0.9097\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9083 - val_loss: 0.1891 - val_acc: 0.9092\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9079 - val_loss: 0.1885 - val_acc: 0.9103\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9081 - val_loss: 0.1889 - val_acc: 0.9094\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18840 to 0.18775, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9107 - val_loss: 0.1877 - val_acc: 0.9103\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9090 - val_loss: 0.1892 - val_acc: 0.9111\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9088 - val_loss: 0.1883 - val_acc: 0.9103\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9092 - val_loss: 0.1894 - val_acc: 0.9092\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9093 - val_loss: 0.1878 - val_acc: 0.9122\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9096 - val_loss: 0.1878 - val_acc: 0.9117\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18775 to 0.18761, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9077 - val_loss: 0.1876 - val_acc: 0.9111\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9096 - val_loss: 0.1878 - val_acc: 0.9117\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18761 to 0.18745, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9110 - val_loss: 0.1874 - val_acc: 0.9118\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9104 - val_loss: 0.1876 - val_acc: 0.9111\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9092 - val_loss: 0.1878 - val_acc: 0.9117\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18745 to 0.18732, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9115 - val_loss: 0.1873 - val_acc: 0.9120\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9123 - val_loss: 0.1874 - val_acc: 0.9130\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18732 to 0.18712, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9116 - val_loss: 0.1871 - val_acc: 0.9132\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18712 to 0.18683, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9117 - val_loss: 0.1868 - val_acc: 0.9130\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18683 to 0.18679, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9109 - val_loss: 0.1868 - val_acc: 0.9124\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9118 - val_loss: 0.1870 - val_acc: 0.9136\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18679 to 0.18660, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9098 - val_loss: 0.1866 - val_acc: 0.9132\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9111 - val_loss: 0.1873 - val_acc: 0.9130\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9121 - val_loss: 0.1867 - val_acc: 0.9140\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9093 - val_loss: 0.1868 - val_acc: 0.9136\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9138 - val_loss: 0.1870 - val_acc: 0.9136\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18660 to 0.18647, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9120 - val_loss: 0.1865 - val_acc: 0.9128\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9124 - val_loss: 0.1867 - val_acc: 0.9134\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18647 to 0.18631, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9126 - val_loss: 0.1863 - val_acc: 0.9140\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18631 to 0.18622, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9131 - val_loss: 0.1862 - val_acc: 0.9142\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9122 - val_loss: 0.1865 - val_acc: 0.9136\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18622 to 0.18616, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9109 - val_loss: 0.1862 - val_acc: 0.9140\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9120 - val_loss: 0.1862 - val_acc: 0.9142\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18616 to 0.18578, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9134 - val_loss: 0.1858 - val_acc: 0.9140\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9117 - val_loss: 0.1865 - val_acc: 0.9134\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18578 to 0.18553, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9123 - val_loss: 0.1855 - val_acc: 0.9145\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9113 - val_loss: 0.1864 - val_acc: 0.9134\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9119 - val_loss: 0.1860 - val_acc: 0.9149\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9141 - val_loss: 0.1869 - val_acc: 0.9134\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18553 to 0.18550, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9134 - val_loss: 0.1855 - val_acc: 0.9145\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9128 - val_loss: 0.1857 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.18550 to 0.18470, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9126 - val_loss: 0.1847 - val_acc: 0.9143\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9117 - val_loss: 0.1850 - val_acc: 0.9155\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9134 - val_loss: 0.1852 - val_acc: 0.9149\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9136 - val_loss: 0.1851 - val_acc: 0.9147\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9133 - val_loss: 0.1859 - val_acc: 0.9149\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9125 - val_loss: 0.1853 - val_acc: 0.9149\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9128 - val_loss: 0.1848 - val_acc: 0.9151\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9135 - val_loss: 0.1848 - val_acc: 0.9149\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9138 - val_loss: 0.1856 - val_acc: 0.9138\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9126 - val_loss: 0.1847 - val_acc: 0.9149\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18470 to 0.18455, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9147 - val_loss: 0.1846 - val_acc: 0.9149\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18455 to 0.18433, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9136 - val_loss: 0.1843 - val_acc: 0.9151\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9141 - val_loss: 0.1848 - val_acc: 0.9157\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9147 - val_loss: 0.1848 - val_acc: 0.9145\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18433 to 0.18410, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9138 - val_loss: 0.1841 - val_acc: 0.9159\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9145 - val_loss: 0.1846 - val_acc: 0.9145\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9134 - val_loss: 0.1846 - val_acc: 0.9142\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9139 - val_loss: 0.1845 - val_acc: 0.9140\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18410 to 0.18345, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9140 - val_loss: 0.1835 - val_acc: 0.9168\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18345 to 0.18313, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9150 - val_loss: 0.1831 - val_acc: 0.9153\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9136 - val_loss: 0.1843 - val_acc: 0.9128\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9135 - val_loss: 0.1833 - val_acc: 0.9168\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9149 - val_loss: 0.1832 - val_acc: 0.9167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18313 to 0.18304, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9148 - val_loss: 0.1830 - val_acc: 0.9168\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9139 - val_loss: 0.1833 - val_acc: 0.9163\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9161 - val_loss: 0.1836 - val_acc: 0.9147\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9139 - val_loss: 0.1836 - val_acc: 0.9128\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9120 - val_loss: 0.1838 - val_acc: 0.9138\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9139 - val_loss: 0.1831 - val_acc: 0.9167\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18304 to 0.18287, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9144 - val_loss: 0.1829 - val_acc: 0.9167\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9138 - val_loss: 0.1834 - val_acc: 0.9174\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9154 - val_loss: 0.1832 - val_acc: 0.9168\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9141 - val_loss: 0.1833 - val_acc: 0.9145\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18287 to 0.18267, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9149 - val_loss: 0.1827 - val_acc: 0.9170\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.18267 to 0.18224, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9146 - val_loss: 0.1822 - val_acc: 0.9176\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9154 - val_loss: 0.1826 - val_acc: 0.9163\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9138 - val_loss: 0.1824 - val_acc: 0.9165\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9162 - val_loss: 0.1827 - val_acc: 0.9159\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9151 - val_loss: 0.1832 - val_acc: 0.9147\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9149 - val_loss: 0.1832 - val_acc: 0.9168\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9162 - val_loss: 0.1826 - val_acc: 0.9167\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9152 - val_loss: 0.1824 - val_acc: 0.9167\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9144 - val_loss: 0.1826 - val_acc: 0.9174\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.18224 to 0.18219, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9160 - val_loss: 0.1822 - val_acc: 0.9176\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.18219 to 0.18197, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9146 - val_loss: 0.1820 - val_acc: 0.9170\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9152 - val_loss: 0.1833 - val_acc: 0.9153\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9173 - val_loss: 0.1822 - val_acc: 0.9149\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.18197 to 0.18154, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9173 - val_loss: 0.1815 - val_acc: 0.9174\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9156 - val_loss: 0.1824 - val_acc: 0.9143\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9174 - val_loss: 0.1822 - val_acc: 0.9159\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9162 - val_loss: 0.1821 - val_acc: 0.9161\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9156 - val_loss: 0.1817 - val_acc: 0.9161\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9174 - val_loss: 0.1826 - val_acc: 0.9143\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.18154 to 0.18152, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9167 - val_loss: 0.1815 - val_acc: 0.9176\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9163 - val_loss: 0.1820 - val_acc: 0.9153\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9161 - val_loss: 0.1817 - val_acc: 0.9176\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9143 - val_loss: 0.1817 - val_acc: 0.9178\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9164 - val_loss: 0.1818 - val_acc: 0.9165\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.18152 to 0.18150, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9168 - val_loss: 0.1815 - val_acc: 0.9172\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.18150 to 0.18107, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9160 - val_loss: 0.1811 - val_acc: 0.9174\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.18107 to 0.18092, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9163 - val_loss: 0.1809 - val_acc: 0.9172\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9173 - val_loss: 0.1811 - val_acc: 0.9178\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.18092 to 0.18045, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9174 - val_loss: 0.1804 - val_acc: 0.9168\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9148 - val_loss: 0.1821 - val_acc: 0.9147\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9167 - val_loss: 0.1813 - val_acc: 0.9174\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9185 - val_loss: 0.1805 - val_acc: 0.9182\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9168 - val_loss: 0.1805 - val_acc: 0.9178\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9173 - val_loss: 0.1812 - val_acc: 0.9172\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9161 - val_loss: 0.1809 - val_acc: 0.9182\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9164 - val_loss: 0.1810 - val_acc: 0.9170\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9164 - val_loss: 0.1805 - val_acc: 0.9184\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.18045 to 0.18030, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9161 - val_loss: 0.1803 - val_acc: 0.9176\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9164 - val_loss: 0.1803 - val_acc: 0.9188\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9174 - val_loss: 0.1805 - val_acc: 0.9188\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.18030 to 0.18027, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9178 - val_loss: 0.1803 - val_acc: 0.9186\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9169 - val_loss: 0.1805 - val_acc: 0.9172\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.18027 to 0.17991, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9162 - val_loss: 0.1799 - val_acc: 0.9180\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9176 - val_loss: 0.1812 - val_acc: 0.9151\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9194 - val_loss: 0.1804 - val_acc: 0.9180\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9166 - val_loss: 0.1808 - val_acc: 0.9176\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9173 - val_loss: 0.1802 - val_acc: 0.9182\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9186 - val_loss: 0.1807 - val_acc: 0.9174\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9163 - val_loss: 0.1805 - val_acc: 0.9172\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9182 - val_loss: 0.1803 - val_acc: 0.9176\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.17991 to 0.17965, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9174 - val_loss: 0.1797 - val_acc: 0.9180\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9189 - val_loss: 0.1799 - val_acc: 0.9180\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9178 - val_loss: 0.1802 - val_acc: 0.9172\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9164 - val_loss: 0.1798 - val_acc: 0.9191\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9173 - val_loss: 0.1804 - val_acc: 0.9170\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9189 - val_loss: 0.1800 - val_acc: 0.9191\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9203 - val_loss: 0.1800 - val_acc: 0.9182\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9193 - val_loss: 0.1799 - val_acc: 0.9168\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.17965 to 0.17921, saving model to best.model\n",
      "0s - loss: 0.1706 - acc: 0.9186 - val_loss: 0.1792 - val_acc: 0.9191\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9181 - val_loss: 0.1796 - val_acc: 0.9172\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9183 - val_loss: 0.1794 - val_acc: 0.9170\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9187 - val_loss: 0.1800 - val_acc: 0.9174\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9189 - val_loss: 0.1800 - val_acc: 0.9172\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9178 - val_loss: 0.1798 - val_acc: 0.9174\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9176 - val_loss: 0.1795 - val_acc: 0.9174\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9186 - val_loss: 0.1802 - val_acc: 0.9161\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9175 - val_loss: 0.1802 - val_acc: 0.9170\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9187 - val_loss: 0.1797 - val_acc: 0.9174\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9188 - val_loss: 0.1798 - val_acc: 0.9167\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.17921 to 0.17902, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9177 - val_loss: 0.1790 - val_acc: 0.9172\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17902 to 0.17864, saving model to best.model\n",
      "0s - loss: 0.1707 - acc: 0.9188 - val_loss: 0.1786 - val_acc: 0.9176\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9201 - val_loss: 0.1796 - val_acc: 0.9170\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9177 - val_loss: 0.1796 - val_acc: 0.9180\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9194 - val_loss: 0.1792 - val_acc: 0.9168\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9206 - val_loss: 0.1793 - val_acc: 0.9180\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9190 - val_loss: 0.1791 - val_acc: 0.9170\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9192 - val_loss: 0.1789 - val_acc: 0.9174\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9205 - val_loss: 0.1797 - val_acc: 0.9167\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9200 - val_loss: 0.1790 - val_acc: 0.9176\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9195 - val_loss: 0.1792 - val_acc: 0.9184\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9189 - val_loss: 0.1788 - val_acc: 0.9178\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9192 - val_loss: 0.1795 - val_acc: 0.9182\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9193 - val_loss: 0.1804 - val_acc: 0.9142\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.17864 to 0.17843, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9180 - val_loss: 0.1784 - val_acc: 0.9170\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9208 - val_loss: 0.1790 - val_acc: 0.9176\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9186 - val_loss: 0.1794 - val_acc: 0.9176\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9187 - val_loss: 0.1786 - val_acc: 0.9172\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9193 - val_loss: 0.1785 - val_acc: 0.9182\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9193 - val_loss: 0.1790 - val_acc: 0.9170\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32392, saving model to best.model\n",
      "0s - loss: 0.3777 - acc: 0.8833 - val_loss: 0.3239 - val_acc: 0.8829\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32392 to 0.23517, saving model to best.model\n",
      "0s - loss: 0.2981 - acc: 0.8897 - val_loss: 0.2352 - val_acc: 0.9005\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23517 to 0.20809, saving model to best.model\n",
      "0s - loss: 0.2443 - acc: 0.8981 - val_loss: 0.2081 - val_acc: 0.9038\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20809 to 0.19546, saving model to best.model\n",
      "0s - loss: 0.2216 - acc: 0.9017 - val_loss: 0.1955 - val_acc: 0.9090\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19546 to 0.19400, saving model to best.model\n",
      "0s - loss: 0.2094 - acc: 0.9030 - val_loss: 0.1940 - val_acc: 0.9105\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19400 to 0.19143, saving model to best.model\n",
      "0s - loss: 0.2068 - acc: 0.9031 - val_loss: 0.1914 - val_acc: 0.9115\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19143 to 0.19112, saving model to best.model\n",
      "0s - loss: 0.2025 - acc: 0.9046 - val_loss: 0.1911 - val_acc: 0.9109\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19112 to 0.19064, saving model to best.model\n",
      "0s - loss: 0.2005 - acc: 0.9063 - val_loss: 0.1906 - val_acc: 0.9117\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19064 to 0.19062, saving model to best.model\n",
      "0s - loss: 0.1986 - acc: 0.9055 - val_loss: 0.1906 - val_acc: 0.9113\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9074 - val_loss: 0.1907 - val_acc: 0.9113\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19062 to 0.19054, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9067 - val_loss: 0.1905 - val_acc: 0.9113\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19054 to 0.19027, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9085 - val_loss: 0.1903 - val_acc: 0.9134\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19027 to 0.19015, saving model to best.model\n",
      "0s - loss: 0.1980 - acc: 0.9066 - val_loss: 0.1902 - val_acc: 0.9118\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1955 - acc: 0.9080 - val_loss: 0.1903 - val_acc: 0.9120\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1947 - acc: 0.9078 - val_loss: 0.1904 - val_acc: 0.9128\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1953 - acc: 0.9081 - val_loss: 0.1905 - val_acc: 0.9111\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1952 - acc: 0.9077 - val_loss: 0.1904 - val_acc: 0.9115\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9071 - val_loss: 0.1903 - val_acc: 0.9128\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19015 to 0.19012, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9105 - val_loss: 0.1901 - val_acc: 0.9132\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9081 - val_loss: 0.1911 - val_acc: 0.9134\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19012 to 0.18988, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9088 - val_loss: 0.1899 - val_acc: 0.9124\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9094 - val_loss: 0.1906 - val_acc: 0.9130\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18988 to 0.18942, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9092 - val_loss: 0.1894 - val_acc: 0.9128\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9077 - val_loss: 0.1895 - val_acc: 0.9113\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9106 - val_loss: 0.1905 - val_acc: 0.9128\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18942 to 0.18913, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9082 - val_loss: 0.1891 - val_acc: 0.9142\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9099 - val_loss: 0.1902 - val_acc: 0.9138\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18913 to 0.18866, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9105 - val_loss: 0.1887 - val_acc: 0.9132\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9106 - val_loss: 0.1893 - val_acc: 0.9136\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18866 to 0.18854, saving model to best.model\n",
      "0s - loss: 0.1889 - acc: 0.9102 - val_loss: 0.1885 - val_acc: 0.9140\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18854 to 0.18810, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9093 - val_loss: 0.1881 - val_acc: 0.9130\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9115 - val_loss: 0.1884 - val_acc: 0.9145\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9102 - val_loss: 0.1883 - val_acc: 0.9140\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9113 - val_loss: 0.1882 - val_acc: 0.9153\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9106 - val_loss: 0.1882 - val_acc: 0.9142\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18810 to 0.18801, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9112 - val_loss: 0.1880 - val_acc: 0.9147\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9108 - val_loss: 0.1880 - val_acc: 0.9140\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18801 to 0.18731, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9101 - val_loss: 0.1873 - val_acc: 0.9145\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9123 - val_loss: 0.1876 - val_acc: 0.9124\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18731 to 0.18725, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9108 - val_loss: 0.1872 - val_acc: 0.9153\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9108 - val_loss: 0.1874 - val_acc: 0.9122\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18725 to 0.18661, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9118 - val_loss: 0.1866 - val_acc: 0.9149\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9117 - val_loss: 0.1881 - val_acc: 0.9153\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18661 to 0.18621, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9119 - val_loss: 0.1862 - val_acc: 0.9153\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9113 - val_loss: 0.1866 - val_acc: 0.9145\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18621 to 0.18621, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9125 - val_loss: 0.1862 - val_acc: 0.9140\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9115 - val_loss: 0.1864 - val_acc: 0.9118\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18621 to 0.18606, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9121 - val_loss: 0.1861 - val_acc: 0.9138\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9113 - val_loss: 0.1862 - val_acc: 0.9136\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9120 - val_loss: 0.1887 - val_acc: 0.9105\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9111 - val_loss: 0.1862 - val_acc: 0.9134\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18606 to 0.18598, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9133 - val_loss: 0.1860 - val_acc: 0.9122\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9118 - val_loss: 0.1869 - val_acc: 0.9117\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18598 to 0.18591, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9117 - val_loss: 0.1859 - val_acc: 0.9134\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18591 to 0.18590, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9116 - val_loss: 0.1859 - val_acc: 0.9111\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9127 - val_loss: 0.1868 - val_acc: 0.9113\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18590 to 0.18544, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9114 - val_loss: 0.1854 - val_acc: 0.9126\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18544 to 0.18530, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9117 - val_loss: 0.1853 - val_acc: 0.9122\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18530 to 0.18528, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9118 - val_loss: 0.1853 - val_acc: 0.9126\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18528 to 0.18510, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9140 - val_loss: 0.1851 - val_acc: 0.9118\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9108 - val_loss: 0.1855 - val_acc: 0.9120\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9118 - val_loss: 0.1857 - val_acc: 0.9126\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18510 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9130 - val_loss: 0.1851 - val_acc: 0.9117\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9117 - val_loss: 0.1864 - val_acc: 0.9124\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9127 - val_loss: 0.1870 - val_acc: 0.9115\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18508 to 0.18460, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9110 - val_loss: 0.1846 - val_acc: 0.9122\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9126 - val_loss: 0.1849 - val_acc: 0.9130\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18460 to 0.18385, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9131 - val_loss: 0.1839 - val_acc: 0.9117\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9136 - val_loss: 0.1841 - val_acc: 0.9120\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9147 - val_loss: 0.1847 - val_acc: 0.9124\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18385 to 0.18379, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9143 - val_loss: 0.1838 - val_acc: 0.9145\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9126 - val_loss: 0.1838 - val_acc: 0.9142\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18379 to 0.18360, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9128 - val_loss: 0.1836 - val_acc: 0.9142\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9125 - val_loss: 0.1845 - val_acc: 0.9124\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9133 - val_loss: 0.1838 - val_acc: 0.9126\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9145 - val_loss: 0.1854 - val_acc: 0.9132\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18360 to 0.18345, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9136 - val_loss: 0.1834 - val_acc: 0.9128\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9127 - val_loss: 0.1835 - val_acc: 0.9122\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18345 to 0.18328, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9130 - val_loss: 0.1833 - val_acc: 0.9128\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.18328 to 0.18284, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9138 - val_loss: 0.1828 - val_acc: 0.9140\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18284 to 0.18271, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9131 - val_loss: 0.1827 - val_acc: 0.9140\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9142 - val_loss: 0.1832 - val_acc: 0.9132\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9137 - val_loss: 0.1833 - val_acc: 0.9132\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18271 to 0.18260, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9136 - val_loss: 0.1826 - val_acc: 0.9130\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9148 - val_loss: 0.1833 - val_acc: 0.9134\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9126 - val_loss: 0.1828 - val_acc: 0.9143\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18260 to 0.18245, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9136 - val_loss: 0.1825 - val_acc: 0.9140\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18245 to 0.18228, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9151 - val_loss: 0.1823 - val_acc: 0.9149\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9141 - val_loss: 0.1830 - val_acc: 0.9138\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9135 - val_loss: 0.1846 - val_acc: 0.9130\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9139 - val_loss: 0.1835 - val_acc: 0.9130\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9132 - val_loss: 0.1826 - val_acc: 0.9138\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9128 - val_loss: 0.1832 - val_acc: 0.9136\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.18228 to 0.18186, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9143 - val_loss: 0.1819 - val_acc: 0.9153\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9137 - val_loss: 0.1821 - val_acc: 0.9142\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9153 - val_loss: 0.1823 - val_acc: 0.9143\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18186 to 0.18178, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9165 - val_loss: 0.1818 - val_acc: 0.9134\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18178 to 0.18132, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9146 - val_loss: 0.1813 - val_acc: 0.9140\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9149 - val_loss: 0.1822 - val_acc: 0.9134\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9156 - val_loss: 0.1821 - val_acc: 0.9140\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9157 - val_loss: 0.1827 - val_acc: 0.9140\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9146 - val_loss: 0.1819 - val_acc: 0.9134\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9138 - val_loss: 0.1817 - val_acc: 0.9145\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18132 to 0.18129, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9149 - val_loss: 0.1813 - val_acc: 0.9149\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.18129 to 0.18111, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9142 - val_loss: 0.1811 - val_acc: 0.9147\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18111 to 0.18070, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9133 - val_loss: 0.1807 - val_acc: 0.9147\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9143 - val_loss: 0.1811 - val_acc: 0.9143\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9143 - val_loss: 0.1814 - val_acc: 0.9140\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9152 - val_loss: 0.1818 - val_acc: 0.9145\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18070 to 0.18057, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9144 - val_loss: 0.1806 - val_acc: 0.9145\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9137 - val_loss: 0.1806 - val_acc: 0.9145\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9143 - val_loss: 0.1807 - val_acc: 0.9145\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9160 - val_loss: 0.1808 - val_acc: 0.9151\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.18057 to 0.18020, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9149 - val_loss: 0.1802 - val_acc: 0.9143\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.18020 to 0.18017, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9155 - val_loss: 0.1802 - val_acc: 0.9149\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9147 - val_loss: 0.1802 - val_acc: 0.9140\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9144 - val_loss: 0.1806 - val_acc: 0.9147\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9158 - val_loss: 0.1804 - val_acc: 0.9145\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18017 to 0.18003, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9162 - val_loss: 0.1800 - val_acc: 0.9147\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9154 - val_loss: 0.1807 - val_acc: 0.9159\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.18003 to 0.17994, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9169 - val_loss: 0.1799 - val_acc: 0.9155\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9138 - val_loss: 0.1804 - val_acc: 0.9147\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17994 to 0.17991, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9153 - val_loss: 0.1799 - val_acc: 0.9149\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17991 to 0.17973, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9165 - val_loss: 0.1797 - val_acc: 0.9159\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9183 - val_loss: 0.1804 - val_acc: 0.9149\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9146 - val_loss: 0.1803 - val_acc: 0.9157\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9155 - val_loss: 0.1800 - val_acc: 0.9161\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9156 - val_loss: 0.1804 - val_acc: 0.9165\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9151 - val_loss: 0.1803 - val_acc: 0.9157\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9146 - val_loss: 0.1801 - val_acc: 0.9161\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9153 - val_loss: 0.1820 - val_acc: 0.9161\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9164 - val_loss: 0.1798 - val_acc: 0.9157\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9165 - val_loss: 0.1805 - val_acc: 0.9161\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17973 to 0.17930, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9163 - val_loss: 0.1793 - val_acc: 0.9155\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17930 to 0.17898, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9152 - val_loss: 0.1790 - val_acc: 0.9155\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9158 - val_loss: 0.1796 - val_acc: 0.9151\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9158 - val_loss: 0.1804 - val_acc: 0.9151\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9169 - val_loss: 0.1807 - val_acc: 0.9159\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17898 to 0.17898, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9134 - val_loss: 0.1790 - val_acc: 0.9161\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9158 - val_loss: 0.1799 - val_acc: 0.9167\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9159 - val_loss: 0.1791 - val_acc: 0.9163\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17898 to 0.17865, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9176 - val_loss: 0.1787 - val_acc: 0.9157\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17865 to 0.17844, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9154 - val_loss: 0.1784 - val_acc: 0.9161\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9146 - val_loss: 0.1797 - val_acc: 0.9157\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9166 - val_loss: 0.1798 - val_acc: 0.9168\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9159 - val_loss: 0.1791 - val_acc: 0.9167\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9159 - val_loss: 0.1791 - val_acc: 0.9167\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9173 - val_loss: 0.1799 - val_acc: 0.9167\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9164 - val_loss: 0.1788 - val_acc: 0.9165\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9181 - val_loss: 0.1787 - val_acc: 0.9168\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17844 to 0.17802, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9166 - val_loss: 0.1780 - val_acc: 0.9161\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9155 - val_loss: 0.1793 - val_acc: 0.9168\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9165 - val_loss: 0.1789 - val_acc: 0.9163\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9176 - val_loss: 0.1786 - val_acc: 0.9163\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9157 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9159 - val_loss: 0.1783 - val_acc: 0.9165\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9176 - val_loss: 0.1783 - val_acc: 0.9174\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9174 - val_loss: 0.1781 - val_acc: 0.9167\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9154 - val_loss: 0.1801 - val_acc: 0.9165\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9147 - val_loss: 0.1793 - val_acc: 0.9168\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9165 - val_loss: 0.1781 - val_acc: 0.9176\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9167 - val_loss: 0.1781 - val_acc: 0.9167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9156 - val_loss: 0.1790 - val_acc: 0.9167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9174 - val_loss: 0.1781 - val_acc: 0.9163\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17802 to 0.17786, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9174 - val_loss: 0.1779 - val_acc: 0.9165\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9163 - val_loss: 0.1779 - val_acc: 0.9163\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9185 - val_loss: 0.1781 - val_acc: 0.9165\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9164 - val_loss: 0.1782 - val_acc: 0.9174\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17786 to 0.17729, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9186 - val_loss: 0.1773 - val_acc: 0.9159\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9171 - val_loss: 0.1782 - val_acc: 0.9172\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17729 to 0.17726, saving model to best.model\n",
      "0s - loss: 0.1693 - acc: 0.9170 - val_loss: 0.1773 - val_acc: 0.9172\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9180 - val_loss: 0.1782 - val_acc: 0.9174\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9168 - val_loss: 0.1778 - val_acc: 0.9168\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "1s - loss: 0.1706 - acc: 0.9165 - val_loss: 0.1797 - val_acc: 0.9178\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "1s - loss: 0.1691 - acc: 0.9182 - val_loss: 0.1775 - val_acc: 0.9174\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17726 to 0.17716, saving model to best.model\n",
      "0s - loss: 0.1690 - acc: 0.9186 - val_loss: 0.1772 - val_acc: 0.9172\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.17716 to 0.17679, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9174 - val_loss: 0.1768 - val_acc: 0.9176\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9167 - val_loss: 0.1775 - val_acc: 0.9165\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9180 - val_loss: 0.1790 - val_acc: 0.9153\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9170 - val_loss: 0.1774 - val_acc: 0.9157\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9176 - val_loss: 0.1774 - val_acc: 0.9176\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9173 - val_loss: 0.1782 - val_acc: 0.9168\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9173 - val_loss: 0.1775 - val_acc: 0.9168\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9176 - val_loss: 0.1782 - val_acc: 0.9178\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9173 - val_loss: 0.1769 - val_acc: 0.9167\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9190 - val_loss: 0.1782 - val_acc: 0.9176\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9193 - val_loss: 0.1784 - val_acc: 0.9170\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9179 - val_loss: 0.1778 - val_acc: 0.9176\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.17679 to 0.17666, saving model to best.model\n",
      "0s - loss: 0.1679 - acc: 0.9194 - val_loss: 0.1767 - val_acc: 0.9178\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9166 - val_loss: 0.1778 - val_acc: 0.9178\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9183 - val_loss: 0.1773 - val_acc: 0.9168\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9179 - val_loss: 0.1773 - val_acc: 0.9174\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9188 - val_loss: 0.1783 - val_acc: 0.9178\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9180 - val_loss: 0.1783 - val_acc: 0.9172\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9170 - val_loss: 0.1780 - val_acc: 0.9176\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9178 - val_loss: 0.1771 - val_acc: 0.9178\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9171 - val_loss: 0.1768 - val_acc: 0.9180\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9173 - val_loss: 0.1777 - val_acc: 0.9174\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9187 - val_loss: 0.1778 - val_acc: 0.9176\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9188 - val_loss: 0.1793 - val_acc: 0.9168\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32114, saving model to best.model\n",
      "0s - loss: 0.4141 - acc: 0.8663 - val_loss: 0.3211 - val_acc: 0.8942\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32114 to 0.25181, saving model to best.model\n",
      "0s - loss: 0.3341 - acc: 0.8876 - val_loss: 0.2518 - val_acc: 0.8942\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25181 to 0.20847, saving model to best.model\n",
      "0s - loss: 0.2671 - acc: 0.8932 - val_loss: 0.2085 - val_acc: 0.9111\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20847 to 0.19185, saving model to best.model\n",
      "0s - loss: 0.2360 - acc: 0.9008 - val_loss: 0.1919 - val_acc: 0.9155\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19185 to 0.18729, saving model to best.model\n",
      "0s - loss: 0.2222 - acc: 0.9010 - val_loss: 0.1873 - val_acc: 0.9151\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18729 to 0.18558, saving model to best.model\n",
      "0s - loss: 0.2191 - acc: 0.9011 - val_loss: 0.1856 - val_acc: 0.9161\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18558 to 0.18517, saving model to best.model\n",
      "1s - loss: 0.2139 - acc: 0.9025 - val_loss: 0.1852 - val_acc: 0.9165\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18517 to 0.18429, saving model to best.model\n",
      "1s - loss: 0.2097 - acc: 0.9036 - val_loss: 0.1843 - val_acc: 0.9165\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2093 - acc: 0.9037 - val_loss: 0.1847 - val_acc: 0.9138\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18429 to 0.18391, saving model to best.model\n",
      "0s - loss: 0.2056 - acc: 0.9032 - val_loss: 0.1839 - val_acc: 0.9136\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18391 to 0.18367, saving model to best.model\n",
      "0s - loss: 0.2064 - acc: 0.9016 - val_loss: 0.1837 - val_acc: 0.9153\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2007 - acc: 0.9051 - val_loss: 0.1839 - val_acc: 0.9149\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2038 - acc: 0.9036 - val_loss: 0.1838 - val_acc: 0.9138\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2018 - acc: 0.9041 - val_loss: 0.1844 - val_acc: 0.9143\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2033 - acc: 0.9055 - val_loss: 0.1841 - val_acc: 0.9145\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.18367 to 0.18330, saving model to best.model\n",
      "0s - loss: 0.2028 - acc: 0.9042 - val_loss: 0.1833 - val_acc: 0.9138\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.2001 - acc: 0.9052 - val_loss: 0.1833 - val_acc: 0.9147\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18330 to 0.18302, saving model to best.model\n",
      "0s - loss: 0.2004 - acc: 0.9053 - val_loss: 0.1830 - val_acc: 0.9153\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18302 to 0.18295, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9065 - val_loss: 0.1829 - val_acc: 0.9163\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18295 to 0.18246, saving model to best.model\n",
      "0s - loss: 0.1977 - acc: 0.9078 - val_loss: 0.1825 - val_acc: 0.9145\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9076 - val_loss: 0.1830 - val_acc: 0.9134\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2000 - acc: 0.9053 - val_loss: 0.1828 - val_acc: 0.9147\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9065 - val_loss: 0.1826 - val_acc: 0.9145\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18246 to 0.18236, saving model to best.model\n",
      "0s - loss: 0.1981 - acc: 0.9064 - val_loss: 0.1824 - val_acc: 0.9163\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18236 to 0.18199, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9080 - val_loss: 0.1820 - val_acc: 0.9143\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1968 - acc: 0.9070 - val_loss: 0.1827 - val_acc: 0.9143\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1973 - acc: 0.9075 - val_loss: 0.1829 - val_acc: 0.9151\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18199 to 0.18169, saving model to best.model\n",
      "0s - loss: 0.1966 - acc: 0.9067 - val_loss: 0.1817 - val_acc: 0.9145\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1957 - acc: 0.9077 - val_loss: 0.1818 - val_acc: 0.9163\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1949 - acc: 0.9079 - val_loss: 0.1835 - val_acc: 0.9147\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1964 - acc: 0.9072 - val_loss: 0.1820 - val_acc: 0.9157\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9079 - val_loss: 0.1821 - val_acc: 0.9172\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9084 - val_loss: 0.1826 - val_acc: 0.9157\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9091 - val_loss: 0.1819 - val_acc: 0.9155\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9090 - val_loss: 0.1821 - val_acc: 0.9157\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9081 - val_loss: 0.1818 - val_acc: 0.9165\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18169 to 0.18137, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9100 - val_loss: 0.1814 - val_acc: 0.9155\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18137 to 0.18125, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9086 - val_loss: 0.1813 - val_acc: 0.9165\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9088 - val_loss: 0.1817 - val_acc: 0.9147\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9113 - val_loss: 0.1813 - val_acc: 0.9159\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9096 - val_loss: 0.1814 - val_acc: 0.9163\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9079 - val_loss: 0.1834 - val_acc: 0.9153\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18125 to 0.18106, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9092 - val_loss: 0.1811 - val_acc: 0.9149\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9089 - val_loss: 0.1811 - val_acc: 0.9140\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9094 - val_loss: 0.1822 - val_acc: 0.9159\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18106 to 0.18069, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9106 - val_loss: 0.1807 - val_acc: 0.9157\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9095 - val_loss: 0.1809 - val_acc: 0.9151\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9094 - val_loss: 0.1808 - val_acc: 0.9149\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9114 - val_loss: 0.1812 - val_acc: 0.9147\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9114 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9097 - val_loss: 0.1807 - val_acc: 0.9165\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18069 to 0.18066, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9102 - val_loss: 0.1807 - val_acc: 0.9168\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18066 to 0.18042, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9117 - val_loss: 0.1804 - val_acc: 0.9159\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9102 - val_loss: 0.1807 - val_acc: 0.9147\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18042 to 0.18030, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9100 - val_loss: 0.1803 - val_acc: 0.9172\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18030 to 0.18007, saving model to best.model\n",
      "0s - loss: 0.1889 - acc: 0.9105 - val_loss: 0.1801 - val_acc: 0.9147\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9107 - val_loss: 0.1802 - val_acc: 0.9149\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9095 - val_loss: 0.1808 - val_acc: 0.9155\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18007 to 0.17995, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9102 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9104 - val_loss: 0.1804 - val_acc: 0.9147\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17995 to 0.17993, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9102 - val_loss: 0.1799 - val_acc: 0.9159\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17993 to 0.17972, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9098 - val_loss: 0.1797 - val_acc: 0.9159\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9103 - val_loss: 0.1798 - val_acc: 0.9151\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9110 - val_loss: 0.1801 - val_acc: 0.9149\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9116 - val_loss: 0.1797 - val_acc: 0.9147\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.17972 to 0.17938, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9101 - val_loss: 0.1794 - val_acc: 0.9159\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9107 - val_loss: 0.1797 - val_acc: 0.9161\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17938 to 0.17930, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9113 - val_loss: 0.1793 - val_acc: 0.9147\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9103 - val_loss: 0.1799 - val_acc: 0.9145\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.17930 to 0.17894, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9125 - val_loss: 0.1789 - val_acc: 0.9149\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9127 - val_loss: 0.1798 - val_acc: 0.9145\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9107 - val_loss: 0.1796 - val_acc: 0.9155\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9113 - val_loss: 0.1794 - val_acc: 0.9153\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9126 - val_loss: 0.1808 - val_acc: 0.9167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9124 - val_loss: 0.1792 - val_acc: 0.9147\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.17894 to 0.17878, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9110 - val_loss: 0.1788 - val_acc: 0.9145\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9117 - val_loss: 0.1794 - val_acc: 0.9157\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17878 to 0.17872, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9126 - val_loss: 0.1787 - val_acc: 0.9155\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17872 to 0.17869, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9123 - val_loss: 0.1787 - val_acc: 0.9161\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9124 - val_loss: 0.1789 - val_acc: 0.9159\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9134 - val_loss: 0.1788 - val_acc: 0.9153\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.17869 to 0.17820, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9117 - val_loss: 0.1782 - val_acc: 0.9163\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9114 - val_loss: 0.1787 - val_acc: 0.9165\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9111 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9127 - val_loss: 0.1787 - val_acc: 0.9168\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17820 to 0.17797, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9128 - val_loss: 0.1780 - val_acc: 0.9178\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9120 - val_loss: 0.1784 - val_acc: 0.9161\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9120 - val_loss: 0.1782 - val_acc: 0.9163\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17797 to 0.17769, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9130 - val_loss: 0.1777 - val_acc: 0.9157\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9136 - val_loss: 0.1777 - val_acc: 0.9167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9124 - val_loss: 0.1779 - val_acc: 0.9159\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17769 to 0.17759, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9137 - val_loss: 0.1776 - val_acc: 0.9161\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9127 - val_loss: 0.1776 - val_acc: 0.9174\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9125 - val_loss: 0.1781 - val_acc: 0.9176\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9130 - val_loss: 0.1779 - val_acc: 0.9174\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17759 to 0.17756, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9113 - val_loss: 0.1776 - val_acc: 0.9167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9127 - val_loss: 0.1791 - val_acc: 0.9172\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9103 - val_loss: 0.1782 - val_acc: 0.9167\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17756 to 0.17752, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9120 - val_loss: 0.1775 - val_acc: 0.9182\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17752 to 0.17717, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9127 - val_loss: 0.1772 - val_acc: 0.9180\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17717 to 0.17714, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9135 - val_loss: 0.1771 - val_acc: 0.9184\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17714 to 0.17698, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9140 - val_loss: 0.1770 - val_acc: 0.9168\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17698 to 0.17671, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9126 - val_loss: 0.1767 - val_acc: 0.9176\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17671 to 0.17667, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9115 - val_loss: 0.1767 - val_acc: 0.9184\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9126 - val_loss: 0.1770 - val_acc: 0.9188\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9136 - val_loss: 0.1771 - val_acc: 0.9184\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9136 - val_loss: 0.1769 - val_acc: 0.9180\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9140 - val_loss: 0.1770 - val_acc: 0.9188\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9126 - val_loss: 0.1769 - val_acc: 0.9168\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17667 to 0.17644, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9131 - val_loss: 0.1764 - val_acc: 0.9190\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9136 - val_loss: 0.1770 - val_acc: 0.9178\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17644 to 0.17606, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9133 - val_loss: 0.1761 - val_acc: 0.9197\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9127 - val_loss: 0.1764 - val_acc: 0.9186\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17606 to 0.17580, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9140 - val_loss: 0.1758 - val_acc: 0.9193\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.17580 to 0.17576, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9122 - val_loss: 0.1758 - val_acc: 0.9188\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9125 - val_loss: 0.1760 - val_acc: 0.9190\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9130 - val_loss: 0.1763 - val_acc: 0.9182\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9137 - val_loss: 0.1761 - val_acc: 0.9182\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17576 to 0.17560, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9146 - val_loss: 0.1756 - val_acc: 0.9199\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9134 - val_loss: 0.1759 - val_acc: 0.9193\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9132 - val_loss: 0.1759 - val_acc: 0.9195\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9141 - val_loss: 0.1758 - val_acc: 0.9188\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17560 to 0.17506, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9155 - val_loss: 0.1751 - val_acc: 0.9176\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9142 - val_loss: 0.1751 - val_acc: 0.9191\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9137 - val_loss: 0.1753 - val_acc: 0.9188\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9128 - val_loss: 0.1753 - val_acc: 0.9188\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9141 - val_loss: 0.1751 - val_acc: 0.9195\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9151 - val_loss: 0.1762 - val_acc: 0.9188\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17506 to 0.17500, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9124 - val_loss: 0.1750 - val_acc: 0.9195\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17500 to 0.17477, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9124 - val_loss: 0.1748 - val_acc: 0.9197\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9156 - val_loss: 0.1751 - val_acc: 0.9191\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17477 to 0.17463, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9135 - val_loss: 0.1746 - val_acc: 0.9195\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9129 - val_loss: 0.1752 - val_acc: 0.9197\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9132 - val_loss: 0.1748 - val_acc: 0.9199\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17463 to 0.17424, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9144 - val_loss: 0.1742 - val_acc: 0.9190\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9140 - val_loss: 0.1747 - val_acc: 0.9193\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9153 - val_loss: 0.1744 - val_acc: 0.9195\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17424 to 0.17413, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9149 - val_loss: 0.1741 - val_acc: 0.9201\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9139 - val_loss: 0.1750 - val_acc: 0.9188\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17413 to 0.17404, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9160 - val_loss: 0.1740 - val_acc: 0.9193\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9154 - val_loss: 0.1742 - val_acc: 0.9182\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9139 - val_loss: 0.1742 - val_acc: 0.9195\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17404 to 0.17389, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9149 - val_loss: 0.1739 - val_acc: 0.9195\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17389 to 0.17374, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9144 - val_loss: 0.1737 - val_acc: 0.9193\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9136 - val_loss: 0.1742 - val_acc: 0.9188\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9160 - val_loss: 0.1738 - val_acc: 0.9190\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9162 - val_loss: 0.1740 - val_acc: 0.9199\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9150 - val_loss: 0.1738 - val_acc: 0.9191\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17374 to 0.17338, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9152 - val_loss: 0.1734 - val_acc: 0.9197\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9153 - val_loss: 0.1739 - val_acc: 0.9195\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17338 to 0.17313, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9159 - val_loss: 0.1731 - val_acc: 0.9201\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9148 - val_loss: 0.1737 - val_acc: 0.9188\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9163 - val_loss: 0.1732 - val_acc: 0.9195\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9156 - val_loss: 0.1734 - val_acc: 0.9186\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9165 - val_loss: 0.1732 - val_acc: 0.9205\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17313 to 0.17288, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9165 - val_loss: 0.1729 - val_acc: 0.9199\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9161 - val_loss: 0.1735 - val_acc: 0.9199\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9164 - val_loss: 0.1736 - val_acc: 0.9201\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17288 to 0.17281, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9174 - val_loss: 0.1728 - val_acc: 0.9193\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17281 to 0.17257, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9152 - val_loss: 0.1726 - val_acc: 0.9184\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9150 - val_loss: 0.1728 - val_acc: 0.9188\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.17257 to 0.17229, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9164 - val_loss: 0.1723 - val_acc: 0.9195\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9165 - val_loss: 0.1729 - val_acc: 0.9199\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9158 - val_loss: 0.1729 - val_acc: 0.9190\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9171 - val_loss: 0.1725 - val_acc: 0.9201\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.17229 to 0.17210, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9166 - val_loss: 0.1721 - val_acc: 0.9199\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17210 to 0.17205, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9152 - val_loss: 0.1720 - val_acc: 0.9199\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9163 - val_loss: 0.1722 - val_acc: 0.9199\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17205 to 0.17185, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9159 - val_loss: 0.1718 - val_acc: 0.9199\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9170 - val_loss: 0.1723 - val_acc: 0.9199\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9154 - val_loss: 0.1722 - val_acc: 0.9193\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9151 - val_loss: 0.1727 - val_acc: 0.9195\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9166 - val_loss: 0.1724 - val_acc: 0.9191\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9156 - val_loss: 0.1722 - val_acc: 0.9188\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9173 - val_loss: 0.1725 - val_acc: 0.9191\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17185 to 0.17166, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9164 - val_loss: 0.1717 - val_acc: 0.9201\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9153 - val_loss: 0.1723 - val_acc: 0.9195\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9175 - val_loss: 0.1728 - val_acc: 0.9195\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9160 - val_loss: 0.1717 - val_acc: 0.9193\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.17166 to 0.17165, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9161 - val_loss: 0.1716 - val_acc: 0.9209\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9165 - val_loss: 0.1718 - val_acc: 0.9199\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17165 to 0.17148, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9180 - val_loss: 0.1715 - val_acc: 0.9197\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9161 - val_loss: 0.1720 - val_acc: 0.9199\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9167 - val_loss: 0.1721 - val_acc: 0.9197\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9176 - val_loss: 0.1716 - val_acc: 0.9199\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9174 - val_loss: 0.1718 - val_acc: 0.9195\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9174 - val_loss: 0.1723 - val_acc: 0.9211\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9165 - val_loss: 0.1716 - val_acc: 0.9197\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.17148 to 0.17140, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9177 - val_loss: 0.1714 - val_acc: 0.9195\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.17140 to 0.17129, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9168 - val_loss: 0.1713 - val_acc: 0.9203\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9169 - val_loss: 0.1721 - val_acc: 0.9191\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.17129 to 0.17098, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9183 - val_loss: 0.1710 - val_acc: 0.9195\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9178 - val_loss: 0.1713 - val_acc: 0.9209\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9165 - val_loss: 0.1729 - val_acc: 0.9190\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9187 - val_loss: 0.1710 - val_acc: 0.9207\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9176 - val_loss: 0.1712 - val_acc: 0.9197\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.17098 to 0.17096, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9159 - val_loss: 0.1710 - val_acc: 0.9199\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9182 - val_loss: 0.1711 - val_acc: 0.9211\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9179 - val_loss: 0.1718 - val_acc: 0.9201\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.17096 to 0.17049, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9182 - val_loss: 0.1705 - val_acc: 0.9211\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.35027, saving model to best.model\n",
      "0s - loss: 0.4170 - acc: 0.8665 - val_loss: 0.3503 - val_acc: 0.8804\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.35027 to 0.26984, saving model to best.model\n",
      "0s - loss: 0.3295 - acc: 0.8879 - val_loss: 0.2698 - val_acc: 0.8807\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26984 to 0.22815, saving model to best.model\n",
      "0s - loss: 0.2670 - acc: 0.8956 - val_loss: 0.2282 - val_acc: 0.9022\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22815 to 0.21162, saving model to best.model\n",
      "0s - loss: 0.2338 - acc: 0.9011 - val_loss: 0.2116 - val_acc: 0.9065\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.21162 to 0.20792, saving model to best.model\n",
      "0s - loss: 0.2232 - acc: 0.9031 - val_loss: 0.2079 - val_acc: 0.9090\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20792 to 0.20550, saving model to best.model\n",
      "0s - loss: 0.2168 - acc: 0.9045 - val_loss: 0.2055 - val_acc: 0.9105\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.20550 to 0.20398, saving model to best.model\n",
      "0s - loss: 0.2099 - acc: 0.9055 - val_loss: 0.2040 - val_acc: 0.9082\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.20398 to 0.20384, saving model to best.model\n",
      "0s - loss: 0.2086 - acc: 0.9066 - val_loss: 0.2038 - val_acc: 0.9097\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.20384 to 0.20384, saving model to best.model\n",
      "0s - loss: 0.2046 - acc: 0.9067 - val_loss: 0.2038 - val_acc: 0.9094\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2036 - acc: 0.9071 - val_loss: 0.2044 - val_acc: 0.9099\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2017 - acc: 0.9072 - val_loss: 0.2050 - val_acc: 0.9107\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1990 - acc: 0.9106 - val_loss: 0.2040 - val_acc: 0.9092\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2005 - acc: 0.9087 - val_loss: 0.2042 - val_acc: 0.9094\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2000 - acc: 0.9091 - val_loss: 0.2039 - val_acc: 0.9088\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2004 - acc: 0.9067 - val_loss: 0.2049 - val_acc: 0.9092\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9096 - val_loss: 0.2044 - val_acc: 0.9101\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.20384 to 0.20348, saving model to best.model\n",
      "0s - loss: 0.1981 - acc: 0.9104 - val_loss: 0.2035 - val_acc: 0.9092\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.20348 to 0.20325, saving model to best.model\n",
      "0s - loss: 0.1979 - acc: 0.9086 - val_loss: 0.2033 - val_acc: 0.9082\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1985 - acc: 0.9106 - val_loss: 0.2052 - val_acc: 0.9099\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1974 - acc: 0.9090 - val_loss: 0.2036 - val_acc: 0.9095\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.20325 to 0.20265, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9113 - val_loss: 0.2026 - val_acc: 0.9094\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1954 - acc: 0.9094 - val_loss: 0.2032 - val_acc: 0.9101\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20265 to 0.20191, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9091 - val_loss: 0.2019 - val_acc: 0.9099\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20191 to 0.20155, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9095 - val_loss: 0.2015 - val_acc: 0.9088\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9105 - val_loss: 0.2017 - val_acc: 0.9097\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1936 - acc: 0.9114 - val_loss: 0.2025 - val_acc: 0.9095\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1953 - acc: 0.9109 - val_loss: 0.2016 - val_acc: 0.9101\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9113 - val_loss: 0.2020 - val_acc: 0.9109\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9093 - val_loss: 0.2019 - val_acc: 0.9097\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9110 - val_loss: 0.2019 - val_acc: 0.9105\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20155 to 0.20084, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9118 - val_loss: 0.2008 - val_acc: 0.9105\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1920 - acc: 0.9115 - val_loss: 0.2012 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.20084 to 0.20072, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9095 - val_loss: 0.2007 - val_acc: 0.9097\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.20072 to 0.20040, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9134 - val_loss: 0.2004 - val_acc: 0.9113\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.20040 to 0.19945, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9129 - val_loss: 0.1994 - val_acc: 0.9094\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19945 to 0.19940, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9121 - val_loss: 0.1994 - val_acc: 0.9105\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19940 to 0.19921, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9122 - val_loss: 0.1992 - val_acc: 0.9101\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9119 - val_loss: 0.1996 - val_acc: 0.9105\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19921 to 0.19862, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9139 - val_loss: 0.1986 - val_acc: 0.9099\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1904 - acc: 0.9118 - val_loss: 0.1988 - val_acc: 0.9115\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19862 to 0.19822, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9135 - val_loss: 0.1982 - val_acc: 0.9103\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19822 to 0.19817, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9133 - val_loss: 0.1982 - val_acc: 0.9111\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1904 - acc: 0.9123 - val_loss: 0.1985 - val_acc: 0.9113\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9133 - val_loss: 0.1983 - val_acc: 0.9107\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19817 to 0.19779, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9148 - val_loss: 0.1978 - val_acc: 0.9109\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9128 - val_loss: 0.1979 - val_acc: 0.9117\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.19779 to 0.19768, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9134 - val_loss: 0.1977 - val_acc: 0.9120\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9146 - val_loss: 0.1980 - val_acc: 0.9124\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19768 to 0.19731, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9160 - val_loss: 0.1973 - val_acc: 0.9111\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9136 - val_loss: 0.1992 - val_acc: 0.9124\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.19731 to 0.19696, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9125 - val_loss: 0.1970 - val_acc: 0.9120\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9149 - val_loss: 0.1979 - val_acc: 0.9113\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9144 - val_loss: 0.1971 - val_acc: 0.9126\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9146 - val_loss: 0.1985 - val_acc: 0.9117\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.19696 to 0.19630, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9133 - val_loss: 0.1963 - val_acc: 0.9115\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.19630 to 0.19627, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9146 - val_loss: 0.1963 - val_acc: 0.9126\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9136 - val_loss: 0.1966 - val_acc: 0.9124\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9139 - val_loss: 0.1969 - val_acc: 0.9126\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.19627 to 0.19590, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9142 - val_loss: 0.1959 - val_acc: 0.9122\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9143 - val_loss: 0.1981 - val_acc: 0.9113\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9155 - val_loss: 0.1962 - val_acc: 0.9124\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9141 - val_loss: 0.1967 - val_acc: 0.9126\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.19590 to 0.19584, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9138 - val_loss: 0.1958 - val_acc: 0.9126\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.19584 to 0.19505, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9135 - val_loss: 0.1950 - val_acc: 0.9128\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9144 - val_loss: 0.1962 - val_acc: 0.9124\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9153 - val_loss: 0.1955 - val_acc: 0.9128\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.19505 to 0.19486, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9149 - val_loss: 0.1949 - val_acc: 0.9120\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9141 - val_loss: 0.1951 - val_acc: 0.9138\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9156 - val_loss: 0.1949 - val_acc: 0.9128\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.19486 to 0.19433, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9150 - val_loss: 0.1943 - val_acc: 0.9132\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9152 - val_loss: 0.1948 - val_acc: 0.9124\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9150 - val_loss: 0.1951 - val_acc: 0.9124\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.19433 to 0.19402, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9153 - val_loss: 0.1940 - val_acc: 0.9132\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9170 - val_loss: 0.1945 - val_acc: 0.9147\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9161 - val_loss: 0.1946 - val_acc: 0.9128\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9149 - val_loss: 0.1943 - val_acc: 0.9124\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9151 - val_loss: 0.1952 - val_acc: 0.9124\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9150 - val_loss: 0.1955 - val_acc: 0.9126\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9165 - val_loss: 0.1956 - val_acc: 0.9142\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9149 - val_loss: 0.1947 - val_acc: 0.9126\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9150 - val_loss: 0.1942 - val_acc: 0.9128\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.19402 to 0.19319, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9143 - val_loss: 0.1932 - val_acc: 0.9151\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.19319 to 0.19308, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9152 - val_loss: 0.1931 - val_acc: 0.9138\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9160 - val_loss: 0.1939 - val_acc: 0.9132\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9151 - val_loss: 0.1935 - val_acc: 0.9140\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9153 - val_loss: 0.1934 - val_acc: 0.9140\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.19308 to 0.19269, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9152 - val_loss: 0.1927 - val_acc: 0.9126\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9153 - val_loss: 0.1943 - val_acc: 0.9142\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9177 - val_loss: 0.1927 - val_acc: 0.9138\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9160 - val_loss: 0.1937 - val_acc: 0.9138\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.19269 to 0.19238, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9162 - val_loss: 0.1924 - val_acc: 0.9138\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9164 - val_loss: 0.1942 - val_acc: 0.9134\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9152 - val_loss: 0.1927 - val_acc: 0.9134\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9161 - val_loss: 0.1925 - val_acc: 0.9132\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.19238 to 0.19211, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9170 - val_loss: 0.1921 - val_acc: 0.9140\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9176 - val_loss: 0.1926 - val_acc: 0.9142\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.19211 to 0.19199, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9163 - val_loss: 0.1920 - val_acc: 0.9155\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.19199 to 0.19169, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9168 - val_loss: 0.1917 - val_acc: 0.9140\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.19169 to 0.19144, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9172 - val_loss: 0.1914 - val_acc: 0.9151\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9172 - val_loss: 0.1915 - val_acc: 0.9147\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.19144 to 0.19132, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9170 - val_loss: 0.1913 - val_acc: 0.9142\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9168 - val_loss: 0.1920 - val_acc: 0.9151\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9186 - val_loss: 0.1921 - val_acc: 0.9157\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.19132 to 0.19083, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9167 - val_loss: 0.1908 - val_acc: 0.9153\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.19083 to 0.19071, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9176 - val_loss: 0.1907 - val_acc: 0.9151\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9164 - val_loss: 0.1922 - val_acc: 0.9140\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9161 - val_loss: 0.1914 - val_acc: 0.9143\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9164 - val_loss: 0.1913 - val_acc: 0.9153\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9177 - val_loss: 0.1917 - val_acc: 0.9157\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9169 - val_loss: 0.1909 - val_acc: 0.9151\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9170 - val_loss: 0.1907 - val_acc: 0.9155\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.19071 to 0.19048, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9172 - val_loss: 0.1905 - val_acc: 0.9159\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.19048 to 0.19045, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9163 - val_loss: 0.1904 - val_acc: 0.9157\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.19045 to 0.19040, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9165 - val_loss: 0.1904 - val_acc: 0.9147\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.19040 to 0.19007, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9177 - val_loss: 0.1901 - val_acc: 0.9159\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9184 - val_loss: 0.1908 - val_acc: 0.9140\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9178 - val_loss: 0.1926 - val_acc: 0.9147\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9191 - val_loss: 0.1906 - val_acc: 0.9145\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9188 - val_loss: 0.1906 - val_acc: 0.9155\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.19007 to 0.18956, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9169 - val_loss: 0.1896 - val_acc: 0.9161\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9182 - val_loss: 0.1907 - val_acc: 0.9145\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9186 - val_loss: 0.1898 - val_acc: 0.9153\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9179 - val_loss: 0.1907 - val_acc: 0.9161\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9192 - val_loss: 0.1913 - val_acc: 0.9155\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9182 - val_loss: 0.1915 - val_acc: 0.9151\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9170 - val_loss: 0.1903 - val_acc: 0.9155\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18956 to 0.18910, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9182 - val_loss: 0.1891 - val_acc: 0.9163\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.18910 to 0.18896, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9194 - val_loss: 0.1890 - val_acc: 0.9155\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9180 - val_loss: 0.1893 - val_acc: 0.9151\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9189 - val_loss: 0.1892 - val_acc: 0.9155\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9187 - val_loss: 0.1891 - val_acc: 0.9157\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9187 - val_loss: 0.1908 - val_acc: 0.9159\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9174 - val_loss: 0.1897 - val_acc: 0.9167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9190 - val_loss: 0.1904 - val_acc: 0.9159\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.18896 to 0.18889, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9189 - val_loss: 0.1889 - val_acc: 0.9159\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.18889 to 0.18858, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9178 - val_loss: 0.1886 - val_acc: 0.9157\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9166 - val_loss: 0.1888 - val_acc: 0.9163\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9185 - val_loss: 0.1902 - val_acc: 0.9155\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9177 - val_loss: 0.1886 - val_acc: 0.9151\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9192 - val_loss: 0.1894 - val_acc: 0.9165\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.18858 to 0.18831, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9187 - val_loss: 0.1883 - val_acc: 0.9155\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9182 - val_loss: 0.1899 - val_acc: 0.9163\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9192 - val_loss: 0.1883 - val_acc: 0.9159\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.18831 to 0.18764, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9191 - val_loss: 0.1876 - val_acc: 0.9163\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9197 - val_loss: 0.1898 - val_acc: 0.9167\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9191 - val_loss: 0.1888 - val_acc: 0.9159\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9182 - val_loss: 0.1888 - val_acc: 0.9170\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.18764 to 0.18764, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9181 - val_loss: 0.1876 - val_acc: 0.9161\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9180 - val_loss: 0.1887 - val_acc: 0.9165\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9194 - val_loss: 0.1883 - val_acc: 0.9170\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9187 - val_loss: 0.1894 - val_acc: 0.9172\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.18764 to 0.18732, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9189 - val_loss: 0.1873 - val_acc: 0.9165\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9198 - val_loss: 0.1889 - val_acc: 0.9172\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.18732 to 0.18715, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9199 - val_loss: 0.1872 - val_acc: 0.9163\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9190 - val_loss: 0.1872 - val_acc: 0.9161\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9195 - val_loss: 0.1883 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9186 - val_loss: 0.1881 - val_acc: 0.9159\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9198 - val_loss: 0.1873 - val_acc: 0.9165\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.18715 to 0.18708, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9204 - val_loss: 0.1871 - val_acc: 0.9161\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9199 - val_loss: 0.1881 - val_acc: 0.9168\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.18708 to 0.18680, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9186 - val_loss: 0.1868 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9179 - val_loss: 0.1879 - val_acc: 0.9167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9199 - val_loss: 0.1869 - val_acc: 0.9159\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9205 - val_loss: 0.1876 - val_acc: 0.9165\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9197 - val_loss: 0.1888 - val_acc: 0.9174\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9197 - val_loss: 0.1891 - val_acc: 0.9174\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9192 - val_loss: 0.1875 - val_acc: 0.9170\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9202 - val_loss: 0.1873 - val_acc: 0.9170\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.18680 to 0.18679, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9207 - val_loss: 0.1868 - val_acc: 0.9170\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9203 - val_loss: 0.1882 - val_acc: 0.9170\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9205 - val_loss: 0.1874 - val_acc: 0.9168\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.18679 to 0.18672, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9186 - val_loss: 0.1867 - val_acc: 0.9168\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9199 - val_loss: 0.1886 - val_acc: 0.9168\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.18672 to 0.18601, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9217 - val_loss: 0.1860 - val_acc: 0.9155\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9223 - val_loss: 0.1869 - val_acc: 0.9168\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9199 - val_loss: 0.1869 - val_acc: 0.9163\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9201 - val_loss: 0.1868 - val_acc: 0.9178\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9211 - val_loss: 0.1866 - val_acc: 0.9178\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9203 - val_loss: 0.1868 - val_acc: 0.9165\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.18601 to 0.18562, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9211 - val_loss: 0.1856 - val_acc: 0.9159\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9207 - val_loss: 0.1888 - val_acc: 0.9174\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9202 - val_loss: 0.1861 - val_acc: 0.9167\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9207 - val_loss: 0.1870 - val_acc: 0.9172\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9205 - val_loss: 0.1857 - val_acc: 0.9168\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9211 - val_loss: 0.1872 - val_acc: 0.9170\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.18562 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9209 - val_loss: 0.1851 - val_acc: 0.9172\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9232 - val_loss: 0.1867 - val_acc: 0.9172\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9221 - val_loss: 0.1869 - val_acc: 0.9178\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9214 - val_loss: 0.1866 - val_acc: 0.9182\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9201 - val_loss: 0.1892 - val_acc: 0.9174\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9211 - val_loss: 0.1870 - val_acc: 0.9174\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9219 - val_loss: 0.1859 - val_acc: 0.9163\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9218 - val_loss: 0.1852 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9212 - val_loss: 0.1863 - val_acc: 0.9167\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9207 - val_loss: 0.1852 - val_acc: 0.9165\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9206 - val_loss: 0.1881 - val_acc: 0.9167\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9223 - val_loss: 0.1852 - val_acc: 0.9157\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9216 - val_loss: 0.1858 - val_acc: 0.9170\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9220 - val_loss: 0.1871 - val_acc: 0.9165\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.18508 to 0.18449, saving model to best.model\n",
      "0s - loss: 0.1689 - acc: 0.9211 - val_loss: 0.1845 - val_acc: 0.9161\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33054, saving model to best.model\n",
      "0s - loss: 0.3925 - acc: 0.8791 - val_loss: 0.3305 - val_acc: 0.8873\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33054 to 0.24983, saving model to best.model\n",
      "0s - loss: 0.3145 - acc: 0.8902 - val_loss: 0.2498 - val_acc: 0.8982\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24983 to 0.20335, saving model to best.model\n",
      "0s - loss: 0.2525 - acc: 0.8980 - val_loss: 0.2033 - val_acc: 0.9090\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20335 to 0.19012, saving model to best.model\n",
      "0s - loss: 0.2242 - acc: 0.9029 - val_loss: 0.1901 - val_acc: 0.9124\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19012 to 0.18864, saving model to best.model\n",
      "0s - loss: 0.2197 - acc: 0.9038 - val_loss: 0.1886 - val_acc: 0.9107\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18864 to 0.18547, saving model to best.model\n",
      "0s - loss: 0.2102 - acc: 0.9038 - val_loss: 0.1855 - val_acc: 0.9136\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18547 to 0.18430, saving model to best.model\n",
      "0s - loss: 0.2054 - acc: 0.9029 - val_loss: 0.1843 - val_acc: 0.9142\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18430 to 0.18383, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9068 - val_loss: 0.1838 - val_acc: 0.9140\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18383 to 0.18379, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9040 - val_loss: 0.1838 - val_acc: 0.9138\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18379 to 0.18374, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9067 - val_loss: 0.1837 - val_acc: 0.9130\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2018 - acc: 0.9072 - val_loss: 0.1851 - val_acc: 0.9115\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18374 to 0.18337, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9090 - val_loss: 0.1834 - val_acc: 0.9132\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9079 - val_loss: 0.1844 - val_acc: 0.9113\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18337 to 0.18334, saving model to best.model\n",
      "0s - loss: 0.1962 - acc: 0.9069 - val_loss: 0.1833 - val_acc: 0.9130\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1955 - acc: 0.9084 - val_loss: 0.1833 - val_acc: 0.9130\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9068 - val_loss: 0.1838 - val_acc: 0.9113\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18334 to 0.18288, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9084 - val_loss: 0.1829 - val_acc: 0.9122\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1955 - acc: 0.9063 - val_loss: 0.1830 - val_acc: 0.9124\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9079 - val_loss: 0.1833 - val_acc: 0.9132\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18288 to 0.18263, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9083 - val_loss: 0.1826 - val_acc: 0.9132\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1925 - acc: 0.9093 - val_loss: 0.1848 - val_acc: 0.9113\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9099 - val_loss: 0.1830 - val_acc: 0.9126\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18263 to 0.18252, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9083 - val_loss: 0.1825 - val_acc: 0.9130\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9086 - val_loss: 0.1827 - val_acc: 0.9136\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9070 - val_loss: 0.1826 - val_acc: 0.9134\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18252 to 0.18237, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9100 - val_loss: 0.1824 - val_acc: 0.9130\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18237 to 0.18221, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9076 - val_loss: 0.1822 - val_acc: 0.9128\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1920 - acc: 0.9087 - val_loss: 0.1825 - val_acc: 0.9107\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18221 to 0.18199, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9096 - val_loss: 0.1820 - val_acc: 0.9136\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9085 - val_loss: 0.1823 - val_acc: 0.9109\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18199 to 0.18168, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9110 - val_loss: 0.1817 - val_acc: 0.9140\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18168 to 0.18154, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9097 - val_loss: 0.1815 - val_acc: 0.9138\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9093 - val_loss: 0.1816 - val_acc: 0.9142\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9104 - val_loss: 0.1823 - val_acc: 0.9105\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18154 to 0.18141, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9078 - val_loss: 0.1814 - val_acc: 0.9128\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9104 - val_loss: 0.1816 - val_acc: 0.9124\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18141 to 0.18121, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9096 - val_loss: 0.1812 - val_acc: 0.9118\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9104 - val_loss: 0.1817 - val_acc: 0.9115\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18121 to 0.18113, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9107 - val_loss: 0.1811 - val_acc: 0.9136\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18113 to 0.18100, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9104 - val_loss: 0.1810 - val_acc: 0.9122\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9093 - val_loss: 0.1814 - val_acc: 0.9134\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9111 - val_loss: 0.1819 - val_acc: 0.9111\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18100 to 0.18061, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9122 - val_loss: 0.1806 - val_acc: 0.9120\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18061 to 0.18025, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9126 - val_loss: 0.1802 - val_acc: 0.9124\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9122 - val_loss: 0.1808 - val_acc: 0.9122\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9123 - val_loss: 0.1805 - val_acc: 0.9147\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18025 to 0.17989, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9122 - val_loss: 0.1799 - val_acc: 0.9136\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17989 to 0.17986, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9118 - val_loss: 0.1799 - val_acc: 0.9136\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9119 - val_loss: 0.1809 - val_acc: 0.9128\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9113 - val_loss: 0.1801 - val_acc: 0.9126\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17986 to 0.17980, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9130 - val_loss: 0.1798 - val_acc: 0.9132\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9108 - val_loss: 0.1801 - val_acc: 0.9134\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17980 to 0.17979, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9123 - val_loss: 0.1798 - val_acc: 0.9134\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.17979 to 0.17973, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9114 - val_loss: 0.1797 - val_acc: 0.9136\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.17973 to 0.17957, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9114 - val_loss: 0.1796 - val_acc: 0.9122\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9119 - val_loss: 0.1796 - val_acc: 0.9132\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9122 - val_loss: 0.1798 - val_acc: 0.9130\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17957 to 0.17941, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9120 - val_loss: 0.1794 - val_acc: 0.9130\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9143 - val_loss: 0.1796 - val_acc: 0.9138\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9117 - val_loss: 0.1796 - val_acc: 0.9138\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9137 - val_loss: 0.1804 - val_acc: 0.9117\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9131 - val_loss: 0.1796 - val_acc: 0.9134\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17941 to 0.17915, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9133 - val_loss: 0.1791 - val_acc: 0.9136\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9133 - val_loss: 0.1792 - val_acc: 0.9132\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9124 - val_loss: 0.1795 - val_acc: 0.9132\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.17915 to 0.17904, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9116 - val_loss: 0.1790 - val_acc: 0.9143\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.17904 to 0.17860, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9121 - val_loss: 0.1786 - val_acc: 0.9138\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9117 - val_loss: 0.1795 - val_acc: 0.9138\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17860 to 0.17858, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9132 - val_loss: 0.1786 - val_acc: 0.9140\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9133 - val_loss: 0.1786 - val_acc: 0.9132\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.17858 to 0.17855, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9134 - val_loss: 0.1785 - val_acc: 0.9140\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9134 - val_loss: 0.1791 - val_acc: 0.9142\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9140 - val_loss: 0.1788 - val_acc: 0.9143\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17855 to 0.17795, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9156 - val_loss: 0.1780 - val_acc: 0.9140\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9117 - val_loss: 0.1780 - val_acc: 0.9134\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9126 - val_loss: 0.1783 - val_acc: 0.9143\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9129 - val_loss: 0.1785 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9130 - val_loss: 0.1785 - val_acc: 0.9145\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17795 to 0.17762, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9146 - val_loss: 0.1776 - val_acc: 0.9142\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9154 - val_loss: 0.1782 - val_acc: 0.9142\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9133 - val_loss: 0.1782 - val_acc: 0.9143\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9140 - val_loss: 0.1783 - val_acc: 0.9147\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9163 - val_loss: 0.1781 - val_acc: 0.9143\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17762 to 0.17744, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9137 - val_loss: 0.1774 - val_acc: 0.9147\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9157 - val_loss: 0.1777 - val_acc: 0.9149\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17744 to 0.17727, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9144 - val_loss: 0.1773 - val_acc: 0.9147\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17727 to 0.17727, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1773 - val_acc: 0.9145\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9145 - val_loss: 0.1781 - val_acc: 0.9151\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9144 - val_loss: 0.1774 - val_acc: 0.9138\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17727 to 0.17716, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9157 - val_loss: 0.1772 - val_acc: 0.9145\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17716 to 0.17700, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9148 - val_loss: 0.1770 - val_acc: 0.9143\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17700 to 0.17696, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9149 - val_loss: 0.1770 - val_acc: 0.9151\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17696 to 0.17664, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9152 - val_loss: 0.1766 - val_acc: 0.9145\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9159 - val_loss: 0.1775 - val_acc: 0.9143\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17664 to 0.17648, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9156 - val_loss: 0.1765 - val_acc: 0.9143\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9143 - val_loss: 0.1767 - val_acc: 0.9140\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17648 to 0.17647, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9149 - val_loss: 0.1765 - val_acc: 0.9143\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9154 - val_loss: 0.1767 - val_acc: 0.9159\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9154 - val_loss: 0.1767 - val_acc: 0.9142\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17647 to 0.17629, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9161 - val_loss: 0.1763 - val_acc: 0.9138\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9162 - val_loss: 0.1765 - val_acc: 0.9145\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9171 - val_loss: 0.1765 - val_acc: 0.9142\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9163 - val_loss: 0.1767 - val_acc: 0.9147\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17629 to 0.17613, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9163 - val_loss: 0.1761 - val_acc: 0.9143\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.17613 to 0.17596, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9167 - val_loss: 0.1760 - val_acc: 0.9143\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17596 to 0.17595, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9150 - val_loss: 0.1760 - val_acc: 0.9142\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17595 to 0.17570, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9168 - val_loss: 0.1757 - val_acc: 0.9151\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17570 to 0.17556, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9161 - val_loss: 0.1756 - val_acc: 0.9147\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9163 - val_loss: 0.1764 - val_acc: 0.9132\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9158 - val_loss: 0.1759 - val_acc: 0.9130\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9168 - val_loss: 0.1756 - val_acc: 0.9134\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9163 - val_loss: 0.1758 - val_acc: 0.9132\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17556 to 0.17543, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9170 - val_loss: 0.1754 - val_acc: 0.9132\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17543 to 0.17540, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9168 - val_loss: 0.1754 - val_acc: 0.9151\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9165 - val_loss: 0.1763 - val_acc: 0.9170\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9172 - val_loss: 0.1759 - val_acc: 0.9168\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17540 to 0.17515, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9180 - val_loss: 0.1751 - val_acc: 0.9132\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9172 - val_loss: 0.1755 - val_acc: 0.9145\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17515 to 0.17513, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9170 - val_loss: 0.1751 - val_acc: 0.9132\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9178 - val_loss: 0.1756 - val_acc: 0.9147\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9174 - val_loss: 0.1754 - val_acc: 0.9155\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9167 - val_loss: 0.1752 - val_acc: 0.9142\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17513 to 0.17502, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9182 - val_loss: 0.1750 - val_acc: 0.9145\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17502 to 0.17499, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9176 - val_loss: 0.1750 - val_acc: 0.9143\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9180 - val_loss: 0.1750 - val_acc: 0.9161\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17499 to 0.17470, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9166 - val_loss: 0.1747 - val_acc: 0.9151\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9178 - val_loss: 0.1749 - val_acc: 0.9142\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9178 - val_loss: 0.1748 - val_acc: 0.9149\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9167 - val_loss: 0.1749 - val_acc: 0.9145\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17470 to 0.17455, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9168 - val_loss: 0.1746 - val_acc: 0.9149\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17455 to 0.17432, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9183 - val_loss: 0.1743 - val_acc: 0.9157\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9172 - val_loss: 0.1743 - val_acc: 0.9153\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9182 - val_loss: 0.1745 - val_acc: 0.9147\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9170 - val_loss: 0.1746 - val_acc: 0.9149\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9170 - val_loss: 0.1743 - val_acc: 0.9149\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17432 to 0.17430, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9194 - val_loss: 0.1743 - val_acc: 0.9163\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9162 - val_loss: 0.1750 - val_acc: 0.9155\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9161 - val_loss: 0.1747 - val_acc: 0.9147\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17430 to 0.17403, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9181 - val_loss: 0.1740 - val_acc: 0.9168\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17403 to 0.17366, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9170 - val_loss: 0.1737 - val_acc: 0.9167\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9167 - val_loss: 0.1738 - val_acc: 0.9157\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17366 to 0.17348, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9190 - val_loss: 0.1735 - val_acc: 0.9157\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9185 - val_loss: 0.1744 - val_acc: 0.9159\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9178 - val_loss: 0.1738 - val_acc: 0.9161\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9179 - val_loss: 0.1736 - val_acc: 0.9167\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17348 to 0.17342, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9188 - val_loss: 0.1734 - val_acc: 0.9163\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9186 - val_loss: 0.1741 - val_acc: 0.9159\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9163 - val_loss: 0.1737 - val_acc: 0.9155\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9188 - val_loss: 0.1737 - val_acc: 0.9167\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9181 - val_loss: 0.1740 - val_acc: 0.9163\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9188 - val_loss: 0.1737 - val_acc: 0.9159\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17342 to 0.17336, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9186 - val_loss: 0.1734 - val_acc: 0.9170\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9184 - val_loss: 0.1735 - val_acc: 0.9167\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9184 - val_loss: 0.1738 - val_acc: 0.9155\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.17336 to 0.17331, saving model to best.model\n",
      "0s - loss: 0.1688 - acc: 0.9189 - val_loss: 0.1733 - val_acc: 0.9157\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17331 to 0.17298, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9198 - val_loss: 0.1730 - val_acc: 0.9157\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17298 to 0.17296, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9186 - val_loss: 0.1730 - val_acc: 0.9159\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9193 - val_loss: 0.1732 - val_acc: 0.9161\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9180 - val_loss: 0.1732 - val_acc: 0.9165\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17296 to 0.17267, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9183 - val_loss: 0.1727 - val_acc: 0.9167\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9194 - val_loss: 0.1727 - val_acc: 0.9159\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9201 - val_loss: 0.1728 - val_acc: 0.9157\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17267 to 0.17254, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9212 - val_loss: 0.1725 - val_acc: 0.9159\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.17254 to 0.17234, saving model to best.model\n",
      "0s - loss: 0.1686 - acc: 0.9202 - val_loss: 0.1723 - val_acc: 0.9159\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17234 to 0.17227, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9192 - val_loss: 0.1723 - val_acc: 0.9161\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9208 - val_loss: 0.1724 - val_acc: 0.9155\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17227 to 0.17220, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9190 - val_loss: 0.1722 - val_acc: 0.9165\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9194 - val_loss: 0.1725 - val_acc: 0.9174\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9196 - val_loss: 0.1723 - val_acc: 0.9170\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9182 - val_loss: 0.1723 - val_acc: 0.9178\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9196 - val_loss: 0.1736 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9199 - val_loss: 0.1735 - val_acc: 0.9168\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9205 - val_loss: 0.1724 - val_acc: 0.9168\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9191 - val_loss: 0.1723 - val_acc: 0.9163\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.17220 to 0.17216, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9203 - val_loss: 0.1722 - val_acc: 0.9163\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9224 - val_loss: 0.1722 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9203 - val_loss: 0.1722 - val_acc: 0.9182\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9198 - val_loss: 0.1728 - val_acc: 0.9170\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9184 - val_loss: 0.1724 - val_acc: 0.9163\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.17216 to 0.17209, saving model to best.model\n",
      "0s - loss: 0.1689 - acc: 0.9218 - val_loss: 0.1721 - val_acc: 0.9167\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9199 - val_loss: 0.1722 - val_acc: 0.9168\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9199 - val_loss: 0.1721 - val_acc: 0.9168\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9206 - val_loss: 0.1721 - val_acc: 0.9172\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.17209 to 0.17196, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9200 - val_loss: 0.1720 - val_acc: 0.9165\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17196 to 0.17191, saving model to best.model\n",
      "1s - loss: 0.1667 - acc: 0.9210 - val_loss: 0.1719 - val_acc: 0.9176\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9195 - val_loss: 0.1729 - val_acc: 0.9167\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.17191 to 0.17162, saving model to best.model\n",
      "0s - loss: 0.1679 - acc: 0.9205 - val_loss: 0.1716 - val_acc: 0.9163\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9197 - val_loss: 0.1720 - val_acc: 0.9170\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.17162 to 0.17148, saving model to best.model\n",
      "0s - loss: 0.1674 - acc: 0.9211 - val_loss: 0.1715 - val_acc: 0.9168\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9205 - val_loss: 0.1716 - val_acc: 0.9170\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9195 - val_loss: 0.1717 - val_acc: 0.9168\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "1s - loss: 0.1653 - acc: 0.9215 - val_loss: 0.1722 - val_acc: 0.9170\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9200 - val_loss: 0.1720 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9209 - val_loss: 0.1717 - val_acc: 0.9174\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1661 - acc: 0.9211 - val_loss: 0.1715 - val_acc: 0.9178\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9209 - val_loss: 0.1720 - val_acc: 0.9182\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1645 - acc: 0.9216 - val_loss: 0.1717 - val_acc: 0.9180\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9218 - val_loss: 0.1719 - val_acc: 0.9184\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1630 - acc: 0.9228 - val_loss: 0.1722 - val_acc: 0.9184\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.17148 to 0.17131, saving model to best.model\n",
      "0s - loss: 0.1680 - acc: 0.9210 - val_loss: 0.1713 - val_acc: 0.9182\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33732, saving model to best.model\n",
      "0s - loss: 0.3766 - acc: 0.8843 - val_loss: 0.3373 - val_acc: 0.8830\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33732 to 0.25567, saving model to best.model\n",
      "0s - loss: 0.3015 - acc: 0.8906 - val_loss: 0.2557 - val_acc: 0.8971\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25567 to 0.21521, saving model to best.model\n",
      "0s - loss: 0.2476 - acc: 0.8969 - val_loss: 0.2152 - val_acc: 0.9063\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21521 to 0.20541, saving model to best.model\n",
      "0s - loss: 0.2223 - acc: 0.9044 - val_loss: 0.2054 - val_acc: 0.9047\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20541 to 0.20294, saving model to best.model\n",
      "0s - loss: 0.2147 - acc: 0.9048 - val_loss: 0.2029 - val_acc: 0.9057\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20294 to 0.20074, saving model to best.model\n",
      "0s - loss: 0.2104 - acc: 0.9057 - val_loss: 0.2007 - val_acc: 0.9059\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.20074 to 0.20028, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9072 - val_loss: 0.2003 - val_acc: 0.9070\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2026 - acc: 0.9076 - val_loss: 0.2005 - val_acc: 0.9067\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.20028 to 0.20000, saving model to best.model\n",
      "0s - loss: 0.1991 - acc: 0.9091 - val_loss: 0.2000 - val_acc: 0.9065\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.20000 to 0.19984, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9084 - val_loss: 0.1998 - val_acc: 0.9072\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19984 to 0.19915, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9090 - val_loss: 0.1992 - val_acc: 0.9065\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1983 - acc: 0.9087 - val_loss: 0.2000 - val_acc: 0.9070\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19915 to 0.19901, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9087 - val_loss: 0.1990 - val_acc: 0.9080\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1954 - acc: 0.9101 - val_loss: 0.1996 - val_acc: 0.9080\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1966 - acc: 0.9105 - val_loss: 0.1992 - val_acc: 0.9069\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9104 - val_loss: 0.1991 - val_acc: 0.9072\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19901 to 0.19822, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9097 - val_loss: 0.1982 - val_acc: 0.9067\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9100 - val_loss: 0.1986 - val_acc: 0.9069\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9096 - val_loss: 0.1988 - val_acc: 0.9059\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19822 to 0.19793, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9098 - val_loss: 0.1979 - val_acc: 0.9070\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19793 to 0.19766, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9094 - val_loss: 0.1977 - val_acc: 0.9072\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19766 to 0.19758, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9097 - val_loss: 0.1976 - val_acc: 0.9070\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9123 - val_loss: 0.1977 - val_acc: 0.9070\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19758 to 0.19701, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9104 - val_loss: 0.1970 - val_acc: 0.9076\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9110 - val_loss: 0.1971 - val_acc: 0.9072\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9121 - val_loss: 0.1971 - val_acc: 0.9074\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19701 to 0.19664, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9107 - val_loss: 0.1966 - val_acc: 0.9072\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19664 to 0.19609, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9117 - val_loss: 0.1961 - val_acc: 0.9084\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9104 - val_loss: 0.1965 - val_acc: 0.9067\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9095 - val_loss: 0.1968 - val_acc: 0.9082\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9119 - val_loss: 0.1964 - val_acc: 0.9076\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9118 - val_loss: 0.1961 - val_acc: 0.9078\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19609 to 0.19576, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9125 - val_loss: 0.1958 - val_acc: 0.9072\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19576 to 0.19555, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9111 - val_loss: 0.1956 - val_acc: 0.9069\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9112 - val_loss: 0.1960 - val_acc: 0.9061\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19555 to 0.19536, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9111 - val_loss: 0.1954 - val_acc: 0.9082\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9127 - val_loss: 0.1958 - val_acc: 0.9080\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19536 to 0.19518, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9118 - val_loss: 0.1952 - val_acc: 0.9070\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19518 to 0.19500, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9121 - val_loss: 0.1950 - val_acc: 0.9080\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19500 to 0.19471, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9127 - val_loss: 0.1947 - val_acc: 0.9074\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9135 - val_loss: 0.1950 - val_acc: 0.9076\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9129 - val_loss: 0.1951 - val_acc: 0.9080\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9117 - val_loss: 0.1951 - val_acc: 0.9072\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.19471 to 0.19466, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9128 - val_loss: 0.1947 - val_acc: 0.9072\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19466 to 0.19461, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9126 - val_loss: 0.1946 - val_acc: 0.9076\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19461 to 0.19427, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9137 - val_loss: 0.1943 - val_acc: 0.9078\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9127 - val_loss: 0.1945 - val_acc: 0.9084\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.19427 to 0.19415, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9128 - val_loss: 0.1941 - val_acc: 0.9078\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9144 - val_loss: 0.1942 - val_acc: 0.9076\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9135 - val_loss: 0.1951 - val_acc: 0.9086\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9126 - val_loss: 0.1942 - val_acc: 0.9084\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19415 to 0.19352, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9137 - val_loss: 0.1935 - val_acc: 0.9078\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9132 - val_loss: 0.1948 - val_acc: 0.9072\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.19352 to 0.19333, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9126 - val_loss: 0.1933 - val_acc: 0.9082\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9139 - val_loss: 0.1935 - val_acc: 0.9074\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9142 - val_loss: 0.1936 - val_acc: 0.9076\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9144 - val_loss: 0.1935 - val_acc: 0.9107\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.19333 to 0.19324, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9135 - val_loss: 0.1932 - val_acc: 0.9074\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.19324 to 0.19289, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9140 - val_loss: 0.1929 - val_acc: 0.9076\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9138 - val_loss: 0.1933 - val_acc: 0.9086\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9144 - val_loss: 0.1930 - val_acc: 0.9086\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.19289 to 0.19275, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9138 - val_loss: 0.1927 - val_acc: 0.9105\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9142 - val_loss: 0.1929 - val_acc: 0.9095\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9144 - val_loss: 0.1941 - val_acc: 0.9080\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9130 - val_loss: 0.1932 - val_acc: 0.9070\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.19275 to 0.19254, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9149 - val_loss: 0.1925 - val_acc: 0.9084\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9135 - val_loss: 0.1925 - val_acc: 0.9109\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9144 - val_loss: 0.1929 - val_acc: 0.9063\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9157 - val_loss: 0.1926 - val_acc: 0.9111\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9136 - val_loss: 0.1937 - val_acc: 0.9111\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.19254 to 0.19229, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9146 - val_loss: 0.1923 - val_acc: 0.9086\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9150 - val_loss: 0.1924 - val_acc: 0.9084\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9146 - val_loss: 0.1929 - val_acc: 0.9082\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.19229 to 0.19209, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9143 - val_loss: 0.1921 - val_acc: 0.9092\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.19209 to 0.19203, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9153 - val_loss: 0.1920 - val_acc: 0.9094\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.19203 to 0.19188, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9154 - val_loss: 0.1919 - val_acc: 0.9090\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.19188 to 0.19185, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9156 - val_loss: 0.1919 - val_acc: 0.9092\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9151 - val_loss: 0.1919 - val_acc: 0.9092\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9150 - val_loss: 0.1920 - val_acc: 0.9080\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.19185 to 0.19166, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9158 - val_loss: 0.1917 - val_acc: 0.9099\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9161 - val_loss: 0.1923 - val_acc: 0.9105\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.19166 to 0.19156, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1916 - val_acc: 0.9103\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.19156 to 0.19133, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9157 - val_loss: 0.1913 - val_acc: 0.9103\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9152 - val_loss: 0.1913 - val_acc: 0.9109\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9157 - val_loss: 0.1915 - val_acc: 0.9109\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9153 - val_loss: 0.1921 - val_acc: 0.9082\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9157 - val_loss: 0.1922 - val_acc: 0.9076\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.19133 to 0.19079, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9161 - val_loss: 0.1908 - val_acc: 0.9101\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9168 - val_loss: 0.1911 - val_acc: 0.9094\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9158 - val_loss: 0.1908 - val_acc: 0.9103\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9160 - val_loss: 0.1915 - val_acc: 0.9111\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9153 - val_loss: 0.1908 - val_acc: 0.9117\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.19079 to 0.19071, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9166 - val_loss: 0.1907 - val_acc: 0.9103\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.19071 to 0.19053, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9182 - val_loss: 0.1905 - val_acc: 0.9111\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9157 - val_loss: 0.1914 - val_acc: 0.9118\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9160 - val_loss: 0.1913 - val_acc: 0.9113\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9169 - val_loss: 0.1913 - val_acc: 0.9126\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9169 - val_loss: 0.1908 - val_acc: 0.9120\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.19053 to 0.19042, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9183 - val_loss: 0.1904 - val_acc: 0.9122\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9166 - val_loss: 0.1912 - val_acc: 0.9103\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.19042 to 0.19030, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9156 - val_loss: 0.1903 - val_acc: 0.9111\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9158 - val_loss: 0.1910 - val_acc: 0.9122\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9180 - val_loss: 0.1906 - val_acc: 0.9118\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9162 - val_loss: 0.1903 - val_acc: 0.9120\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9167 - val_loss: 0.1908 - val_acc: 0.9105\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9163 - val_loss: 0.1904 - val_acc: 0.9126\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.19030 to 0.19011, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9166 - val_loss: 0.1901 - val_acc: 0.9118\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.19011 to 0.18977, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9188 - val_loss: 0.1898 - val_acc: 0.9118\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9170 - val_loss: 0.1899 - val_acc: 0.9117\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9178 - val_loss: 0.1900 - val_acc: 0.9111\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18977 to 0.18961, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9199 - val_loss: 0.1896 - val_acc: 0.9134\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9174 - val_loss: 0.1901 - val_acc: 0.9132\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9173 - val_loss: 0.1902 - val_acc: 0.9118\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9199 - val_loss: 0.1901 - val_acc: 0.9130\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9172 - val_loss: 0.1897 - val_acc: 0.9124\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9178 - val_loss: 0.1901 - val_acc: 0.9115\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.18961 to 0.18932, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9173 - val_loss: 0.1893 - val_acc: 0.9120\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9180 - val_loss: 0.1896 - val_acc: 0.9128\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9169 - val_loss: 0.1900 - val_acc: 0.9124\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9171 - val_loss: 0.1900 - val_acc: 0.9136\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9174 - val_loss: 0.1894 - val_acc: 0.9128\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.18932 to 0.18929, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9174 - val_loss: 0.1893 - val_acc: 0.9134\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9183 - val_loss: 0.1898 - val_acc: 0.9128\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.18929 to 0.18917, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9183 - val_loss: 0.1892 - val_acc: 0.9134\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9199 - val_loss: 0.1894 - val_acc: 0.9128\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.18917 to 0.18869, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9188 - val_loss: 0.1887 - val_acc: 0.9134\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9187 - val_loss: 0.1887 - val_acc: 0.9140\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9184 - val_loss: 0.1891 - val_acc: 0.9128\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9188 - val_loss: 0.1888 - val_acc: 0.9134\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9183 - val_loss: 0.1901 - val_acc: 0.9138\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.18869 to 0.18825, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9180 - val_loss: 0.1883 - val_acc: 0.9136\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9204 - val_loss: 0.1887 - val_acc: 0.9124\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9196 - val_loss: 0.1887 - val_acc: 0.9126\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9189 - val_loss: 0.1894 - val_acc: 0.9130\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9192 - val_loss: 0.1886 - val_acc: 0.9134\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.18825 to 0.18824, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9180 - val_loss: 0.1882 - val_acc: 0.9136\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9192 - val_loss: 0.1885 - val_acc: 0.9140\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9192 - val_loss: 0.1895 - val_acc: 0.9140\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9202 - val_loss: 0.1883 - val_acc: 0.9143\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9199 - val_loss: 0.1894 - val_acc: 0.9136\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9199 - val_loss: 0.1888 - val_acc: 0.9143\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.18824 to 0.18823, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9186 - val_loss: 0.1882 - val_acc: 0.9136\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9201 - val_loss: 0.1886 - val_acc: 0.9147\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.18823 to 0.18787, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9187 - val_loss: 0.1879 - val_acc: 0.9145\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.18787 to 0.18780, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9193 - val_loss: 0.1878 - val_acc: 0.9143\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9209 - val_loss: 0.1883 - val_acc: 0.9140\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18780 to 0.18776, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9196 - val_loss: 0.1878 - val_acc: 0.9145\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.18776 to 0.18749, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9208 - val_loss: 0.1875 - val_acc: 0.9140\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9203 - val_loss: 0.1883 - val_acc: 0.9147\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9205 - val_loss: 0.1877 - val_acc: 0.9143\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.18749 to 0.18743, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9180 - val_loss: 0.1874 - val_acc: 0.9145\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9205 - val_loss: 0.1886 - val_acc: 0.9140\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9199 - val_loss: 0.1883 - val_acc: 0.9142\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9195 - val_loss: 0.1879 - val_acc: 0.9143\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9207 - val_loss: 0.1879 - val_acc: 0.9151\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9182 - val_loss: 0.1875 - val_acc: 0.9147\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.18743 to 0.18708, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9199 - val_loss: 0.1871 - val_acc: 0.9149\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9202 - val_loss: 0.1885 - val_acc: 0.9138\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9216 - val_loss: 0.1879 - val_acc: 0.9147\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9199 - val_loss: 0.1882 - val_acc: 0.9149\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9212 - val_loss: 0.1874 - val_acc: 0.9153\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9213 - val_loss: 0.1884 - val_acc: 0.9157\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9201 - val_loss: 0.1872 - val_acc: 0.9151\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.18708 to 0.18680, saving model to best.model\n",
      "0s - loss: 0.1700 - acc: 0.9196 - val_loss: 0.1868 - val_acc: 0.9153\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.18680 to 0.18668, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9200 - val_loss: 0.1867 - val_acc: 0.9161\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9202 - val_loss: 0.1877 - val_acc: 0.9157\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9197 - val_loss: 0.1878 - val_acc: 0.9159\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9203 - val_loss: 0.1871 - val_acc: 0.9149\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9203 - val_loss: 0.1874 - val_acc: 0.9153\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9221 - val_loss: 0.1868 - val_acc: 0.9149\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.18668 to 0.18641, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9192 - val_loss: 0.1864 - val_acc: 0.9157\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9205 - val_loss: 0.1870 - val_acc: 0.9161\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9198 - val_loss: 0.1875 - val_acc: 0.9159\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9201 - val_loss: 0.1877 - val_acc: 0.9167\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.18641 to 0.18624, saving model to best.model\n",
      "0s - loss: 0.1682 - acc: 0.9218 - val_loss: 0.1862 - val_acc: 0.9155\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9233 - val_loss: 0.1864 - val_acc: 0.9147\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9212 - val_loss: 0.1863 - val_acc: 0.9155\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9228 - val_loss: 0.1865 - val_acc: 0.9153\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9204 - val_loss: 0.1866 - val_acc: 0.9151\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9220 - val_loss: 0.1863 - val_acc: 0.9157\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9214 - val_loss: 0.1863 - val_acc: 0.9157\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.18624 to 0.18615, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9209 - val_loss: 0.1862 - val_acc: 0.9165\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9214 - val_loss: 0.1870 - val_acc: 0.9153\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9230 - val_loss: 0.1864 - val_acc: 0.9163\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1660 - acc: 0.9234 - val_loss: 0.1871 - val_acc: 0.9161\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9223 - val_loss: 0.1862 - val_acc: 0.9163\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9217 - val_loss: 0.1863 - val_acc: 0.9161\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1663 - acc: 0.9231 - val_loss: 0.1880 - val_acc: 0.9161\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9228 - val_loss: 0.1865 - val_acc: 0.9167\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.18615 to 0.18553, saving model to best.model\n",
      "0s - loss: 0.1684 - acc: 0.9210 - val_loss: 0.1855 - val_acc: 0.9168\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1664 - acc: 0.9219 - val_loss: 0.1862 - val_acc: 0.9165\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.18553 to 0.18543, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9224 - val_loss: 0.1854 - val_acc: 0.9165\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9219 - val_loss: 0.1861 - val_acc: 0.9165\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9223 - val_loss: 0.1860 - val_acc: 0.9163\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9233 - val_loss: 0.1855 - val_acc: 0.9161\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.18543 to 0.18489, saving model to best.model\n",
      "0s - loss: 0.1670 - acc: 0.9217 - val_loss: 0.1849 - val_acc: 0.9167\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1661 - acc: 0.9231 - val_loss: 0.1855 - val_acc: 0.9163\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1660 - acc: 0.9212 - val_loss: 0.1859 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9210 - val_loss: 0.1854 - val_acc: 0.9155\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9214 - val_loss: 0.1858 - val_acc: 0.9161\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.35102, saving model to best.model\n",
      "0s - loss: 0.4038 - acc: 0.8742 - val_loss: 0.3510 - val_acc: 0.8790\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.35102 to 0.25264, saving model to best.model\n",
      "0s - loss: 0.3200 - acc: 0.8878 - val_loss: 0.2526 - val_acc: 0.8957\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25264 to 0.21650, saving model to best.model\n",
      "0s - loss: 0.2611 - acc: 0.8927 - val_loss: 0.2165 - val_acc: 0.9038\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21650 to 0.20321, saving model to best.model\n",
      "0s - loss: 0.2364 - acc: 0.8990 - val_loss: 0.2032 - val_acc: 0.9042\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20321 to 0.20070, saving model to best.model\n",
      "0s - loss: 0.2262 - acc: 0.8989 - val_loss: 0.2007 - val_acc: 0.9022\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20070 to 0.19829, saving model to best.model\n",
      "0s - loss: 0.2170 - acc: 0.9016 - val_loss: 0.1983 - val_acc: 0.9053\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19829 to 0.19815, saving model to best.model\n",
      "0s - loss: 0.2138 - acc: 0.9016 - val_loss: 0.1981 - val_acc: 0.9019\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19815 to 0.19783, saving model to best.model\n",
      "0s - loss: 0.2122 - acc: 0.9036 - val_loss: 0.1978 - val_acc: 0.9036\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19783 to 0.19734, saving model to best.model\n",
      "0s - loss: 0.2089 - acc: 0.9009 - val_loss: 0.1973 - val_acc: 0.9040\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2078 - acc: 0.9026 - val_loss: 0.1974 - val_acc: 0.9038\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2087 - acc: 0.9012 - val_loss: 0.1975 - val_acc: 0.9036\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19734 to 0.19693, saving model to best.model\n",
      "0s - loss: 0.2067 - acc: 0.9018 - val_loss: 0.1969 - val_acc: 0.9028\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2061 - acc: 0.9022 - val_loss: 0.1972 - val_acc: 0.9026\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2034 - acc: 0.9041 - val_loss: 0.1972 - val_acc: 0.9028\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2034 - acc: 0.9038 - val_loss: 0.1972 - val_acc: 0.9036\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19693 to 0.19686, saving model to best.model\n",
      "0s - loss: 0.2031 - acc: 0.9028 - val_loss: 0.1969 - val_acc: 0.9032\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19686 to 0.19621, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9028 - val_loss: 0.1962 - val_acc: 0.9028\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2030 - acc: 0.9049 - val_loss: 0.1965 - val_acc: 0.9034\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19621 to 0.19582, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9037 - val_loss: 0.1958 - val_acc: 0.9032\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2027 - acc: 0.9031 - val_loss: 0.1960 - val_acc: 0.9032\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19582 to 0.19550, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9051 - val_loss: 0.1955 - val_acc: 0.9024\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2005 - acc: 0.9043 - val_loss: 0.1957 - val_acc: 0.9042\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19550 to 0.19501, saving model to best.model\n",
      "0s - loss: 0.1998 - acc: 0.9051 - val_loss: 0.1950 - val_acc: 0.9030\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19501 to 0.19490, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9056 - val_loss: 0.1949 - val_acc: 0.9032\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9034 - val_loss: 0.1949 - val_acc: 0.9038\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1996 - acc: 0.9048 - val_loss: 0.1951 - val_acc: 0.9038\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19490 to 0.19382, saving model to best.model\n",
      "0s - loss: 0.1984 - acc: 0.9046 - val_loss: 0.1938 - val_acc: 0.9046\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1998 - acc: 0.9051 - val_loss: 0.1939 - val_acc: 0.9040\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1978 - acc: 0.9058 - val_loss: 0.1948 - val_acc: 0.9046\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19382 to 0.19325, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9039 - val_loss: 0.1932 - val_acc: 0.9032\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1978 - acc: 0.9045 - val_loss: 0.1934 - val_acc: 0.9030\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9050 - val_loss: 0.1938 - val_acc: 0.9026\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19325 to 0.19310, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9049 - val_loss: 0.1931 - val_acc: 0.9032\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19310 to 0.19240, saving model to best.model\n",
      "0s - loss: 0.1974 - acc: 0.9063 - val_loss: 0.1924 - val_acc: 0.9057\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1961 - acc: 0.9067 - val_loss: 0.1933 - val_acc: 0.9067\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19240 to 0.19197, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9056 - val_loss: 0.1920 - val_acc: 0.9036\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1965 - acc: 0.9048 - val_loss: 0.1922 - val_acc: 0.9026\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1946 - acc: 0.9075 - val_loss: 0.1920 - val_acc: 0.9021\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1963 - acc: 0.9078 - val_loss: 0.1922 - val_acc: 0.9049\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19197 to 0.19163, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9059 - val_loss: 0.1916 - val_acc: 0.9046\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19163 to 0.19142, saving model to best.model\n",
      "0s - loss: 0.1966 - acc: 0.9053 - val_loss: 0.1914 - val_acc: 0.9065\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9061 - val_loss: 0.1919 - val_acc: 0.9030\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1951 - acc: 0.9066 - val_loss: 0.1916 - val_acc: 0.9047\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9079 - val_loss: 0.1920 - val_acc: 0.9044\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19142 to 0.19108, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9076 - val_loss: 0.1911 - val_acc: 0.9047\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1934 - acc: 0.9069 - val_loss: 0.1914 - val_acc: 0.9032\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9068 - val_loss: 0.1912 - val_acc: 0.9057\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.19108 to 0.19065, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9075 - val_loss: 0.1907 - val_acc: 0.9055\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1934 - acc: 0.9062 - val_loss: 0.1911 - val_acc: 0.9067\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.19065 to 0.19027, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9076 - val_loss: 0.1903 - val_acc: 0.9063\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9070 - val_loss: 0.1909 - val_acc: 0.9055\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19027 to 0.18993, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9053 - val_loss: 0.1899 - val_acc: 0.9057\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9070 - val_loss: 0.1904 - val_acc: 0.9055\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18993 to 0.18978, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9094 - val_loss: 0.1898 - val_acc: 0.9057\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18978 to 0.18958, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9099 - val_loss: 0.1896 - val_acc: 0.9053\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9068 - val_loss: 0.1909 - val_acc: 0.9069\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9078 - val_loss: 0.1907 - val_acc: 0.9059\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18958 to 0.18913, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9068 - val_loss: 0.1891 - val_acc: 0.9055\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9083 - val_loss: 0.1892 - val_acc: 0.9049\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1914 - acc: 0.9079 - val_loss: 0.1891 - val_acc: 0.9051\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9098 - val_loss: 0.1893 - val_acc: 0.9063\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9090 - val_loss: 0.1896 - val_acc: 0.9074\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18913 to 0.18869, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9072 - val_loss: 0.1887 - val_acc: 0.9061\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18869 to 0.18862, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9093 - val_loss: 0.1886 - val_acc: 0.9059\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1904 - acc: 0.9093 - val_loss: 0.1888 - val_acc: 0.9053\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9097 - val_loss: 0.1888 - val_acc: 0.9076\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9090 - val_loss: 0.1892 - val_acc: 0.9061\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18862 to 0.18836, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9076 - val_loss: 0.1884 - val_acc: 0.9063\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18836 to 0.18821, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9088 - val_loss: 0.1882 - val_acc: 0.9069\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9078 - val_loss: 0.1883 - val_acc: 0.9070\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18821 to 0.18816, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9091 - val_loss: 0.1882 - val_acc: 0.9070\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18816 to 0.18793, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9064 - val_loss: 0.1879 - val_acc: 0.9076\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18793 to 0.18747, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9110 - val_loss: 0.1875 - val_acc: 0.9067\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9089 - val_loss: 0.1895 - val_acc: 0.9069\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9088 - val_loss: 0.1876 - val_acc: 0.9084\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9077 - val_loss: 0.1882 - val_acc: 0.9061\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9090 - val_loss: 0.1877 - val_acc: 0.9063\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9104 - val_loss: 0.1880 - val_acc: 0.9059\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9107 - val_loss: 0.1879 - val_acc: 0.9070\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9087 - val_loss: 0.1875 - val_acc: 0.9063\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9090 - val_loss: 0.1876 - val_acc: 0.9074\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9098 - val_loss: 0.1875 - val_acc: 0.9067\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9099 - val_loss: 0.1876 - val_acc: 0.9069\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18747 to 0.18652, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9096 - val_loss: 0.1865 - val_acc: 0.9076\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9104 - val_loss: 0.1871 - val_acc: 0.9080\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9112 - val_loss: 0.1866 - val_acc: 0.9065\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18652 to 0.18635, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9098 - val_loss: 0.1864 - val_acc: 0.9067\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9129 - val_loss: 0.1871 - val_acc: 0.9076\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9107 - val_loss: 0.1867 - val_acc: 0.9069\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9114 - val_loss: 0.1868 - val_acc: 0.9055\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9116 - val_loss: 0.1869 - val_acc: 0.9059\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9126 - val_loss: 0.1865 - val_acc: 0.9067\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18635 to 0.18579, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9102 - val_loss: 0.1858 - val_acc: 0.9067\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9106 - val_loss: 0.1864 - val_acc: 0.9069\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.18579 to 0.18561, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9108 - val_loss: 0.1856 - val_acc: 0.9074\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9113 - val_loss: 0.1859 - val_acc: 0.9097\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18561 to 0.18524, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9114 - val_loss: 0.1852 - val_acc: 0.9067\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9105 - val_loss: 0.1861 - val_acc: 0.9090\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9111 - val_loss: 0.1856 - val_acc: 0.9069\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9113 - val_loss: 0.1861 - val_acc: 0.9070\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9105 - val_loss: 0.1853 - val_acc: 0.9090\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18524 to 0.18495, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9114 - val_loss: 0.1850 - val_acc: 0.9097\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9108 - val_loss: 0.1850 - val_acc: 0.9082\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9112 - val_loss: 0.1855 - val_acc: 0.9101\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9119 - val_loss: 0.1855 - val_acc: 0.9061\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18495 to 0.18474, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9121 - val_loss: 0.1847 - val_acc: 0.9107\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9106 - val_loss: 0.1850 - val_acc: 0.9070\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.18474 to 0.18466, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9109 - val_loss: 0.1847 - val_acc: 0.9097\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.18466 to 0.18450, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9116 - val_loss: 0.1845 - val_acc: 0.9086\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18450 to 0.18446, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9100 - val_loss: 0.1845 - val_acc: 0.9074\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9112 - val_loss: 0.1845 - val_acc: 0.9082\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9110 - val_loss: 0.1845 - val_acc: 0.9090\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9121 - val_loss: 0.1846 - val_acc: 0.9095\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9117 - val_loss: 0.1847 - val_acc: 0.9072\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.18446 to 0.18420, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9126 - val_loss: 0.1842 - val_acc: 0.9086\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.18420 to 0.18388, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9133 - val_loss: 0.1839 - val_acc: 0.9090\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9130 - val_loss: 0.1842 - val_acc: 0.9099\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18388 to 0.18374, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9120 - val_loss: 0.1837 - val_acc: 0.9111\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9105 - val_loss: 0.1838 - val_acc: 0.9088\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9133 - val_loss: 0.1846 - val_acc: 0.9072\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9130 - val_loss: 0.1840 - val_acc: 0.9080\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9120 - val_loss: 0.1843 - val_acc: 0.9080\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.18374 to 0.18357, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9121 - val_loss: 0.1836 - val_acc: 0.9105\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.18357 to 0.18313, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9138 - val_loss: 0.1831 - val_acc: 0.9126\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.18313 to 0.18312, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9125 - val_loss: 0.1831 - val_acc: 0.9134\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9126 - val_loss: 0.1835 - val_acc: 0.9092\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18312 to 0.18298, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9133 - val_loss: 0.1830 - val_acc: 0.9117\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.18298 to 0.18291, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9118 - val_loss: 0.1829 - val_acc: 0.9109\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9114 - val_loss: 0.1829 - val_acc: 0.9111\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9123 - val_loss: 0.1831 - val_acc: 0.9109\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.18291 to 0.18280, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9132 - val_loss: 0.1828 - val_acc: 0.9105\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9122 - val_loss: 0.1831 - val_acc: 0.9117\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9125 - val_loss: 0.1833 - val_acc: 0.9115\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9128 - val_loss: 0.1828 - val_acc: 0.9094\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9127 - val_loss: 0.1830 - val_acc: 0.9092\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9139 - val_loss: 0.1830 - val_acc: 0.9115\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.18280 to 0.18256, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9155 - val_loss: 0.1826 - val_acc: 0.9107\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.18256 to 0.18231, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9147 - val_loss: 0.1823 - val_acc: 0.9128\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9143 - val_loss: 0.1827 - val_acc: 0.9111\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9141 - val_loss: 0.1826 - val_acc: 0.9111\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.18231 to 0.18221, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9124 - val_loss: 0.1822 - val_acc: 0.9117\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9131 - val_loss: 0.1826 - val_acc: 0.9134\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9132 - val_loss: 0.1822 - val_acc: 0.9109\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.18221 to 0.18189, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9149 - val_loss: 0.1819 - val_acc: 0.9136\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9149 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.18189 to 0.18179, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9149 - val_loss: 0.1818 - val_acc: 0.9124\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18179 to 0.18160, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9150 - val_loss: 0.1816 - val_acc: 0.9134\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9139 - val_loss: 0.1816 - val_acc: 0.9145\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.18160 to 0.18135, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9132 - val_loss: 0.1814 - val_acc: 0.9149\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9138 - val_loss: 0.1818 - val_acc: 0.9107\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.18135 to 0.18122, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9150 - val_loss: 0.1812 - val_acc: 0.9155\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9159 - val_loss: 0.1819 - val_acc: 0.9147\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9135 - val_loss: 0.1820 - val_acc: 0.9140\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9138 - val_loss: 0.1815 - val_acc: 0.9142\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9157 - val_loss: 0.1814 - val_acc: 0.9140\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9127 - val_loss: 0.1815 - val_acc: 0.9130\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9146 - val_loss: 0.1813 - val_acc: 0.9155\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.18122 to 0.18096, saving model to best.model\n",
      "0s - loss: 0.1771 - acc: 0.9136 - val_loss: 0.1810 - val_acc: 0.9134\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.18096 to 0.18080, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9127 - val_loss: 0.1808 - val_acc: 0.9143\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9133 - val_loss: 0.1811 - val_acc: 0.9128\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9148 - val_loss: 0.1808 - val_acc: 0.9149\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9137 - val_loss: 0.1808 - val_acc: 0.9145\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9160 - val_loss: 0.1819 - val_acc: 0.9109\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.18080 to 0.18059, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9150 - val_loss: 0.1806 - val_acc: 0.9138\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.18059 to 0.18041, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9128 - val_loss: 0.1804 - val_acc: 0.9143\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9148 - val_loss: 0.1807 - val_acc: 0.9143\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9149 - val_loss: 0.1823 - val_acc: 0.9132\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9150 - val_loss: 0.1806 - val_acc: 0.9143\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9164 - val_loss: 0.1806 - val_acc: 0.9130\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.18041 to 0.18025, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9137 - val_loss: 0.1803 - val_acc: 0.9138\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9152 - val_loss: 0.1806 - val_acc: 0.9120\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.18025 to 0.18016, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9151 - val_loss: 0.1802 - val_acc: 0.9149\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9141 - val_loss: 0.1806 - val_acc: 0.9140\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9142 - val_loss: 0.1809 - val_acc: 0.9143\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9152 - val_loss: 0.1803 - val_acc: 0.9138\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9134 - val_loss: 0.1806 - val_acc: 0.9136\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9166 - val_loss: 0.1807 - val_acc: 0.9136\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9141 - val_loss: 0.1808 - val_acc: 0.9140\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9157 - val_loss: 0.1811 - val_acc: 0.9134\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9166 - val_loss: 0.1802 - val_acc: 0.9130\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9156 - val_loss: 0.1808 - val_acc: 0.9140\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9163 - val_loss: 0.1802 - val_acc: 0.9128\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9153 - val_loss: 0.1803 - val_acc: 0.9124\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9163 - val_loss: 0.1802 - val_acc: 0.9130\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9149 - val_loss: 0.1803 - val_acc: 0.9143\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.18016 to 0.18007, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9157 - val_loss: 0.1801 - val_acc: 0.9140\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9155 - val_loss: 0.1803 - val_acc: 0.9142\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9149 - val_loss: 0.1805 - val_acc: 0.9132\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9141 - val_loss: 0.1801 - val_acc: 0.9147\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.18007 to 0.18001, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9139 - val_loss: 0.1800 - val_acc: 0.9138\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9134 - val_loss: 0.1803 - val_acc: 0.9117\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9160 - val_loss: 0.1812 - val_acc: 0.9132\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9147 - val_loss: 0.1801 - val_acc: 0.9138\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9154 - val_loss: 0.1800 - val_acc: 0.9143\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9164 - val_loss: 0.1800 - val_acc: 0.9143\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9158 - val_loss: 0.1801 - val_acc: 0.9136\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9163 - val_loss: 0.1800 - val_acc: 0.9138\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9150 - val_loss: 0.1807 - val_acc: 0.9134\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.18001 to 0.17967, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9162 - val_loss: 0.1797 - val_acc: 0.9138\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.17967 to 0.17945, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9150 - val_loss: 0.1794 - val_acc: 0.9138\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31378, saving model to best.model\n",
      "0s - loss: 0.3862 - acc: 0.8804 - val_loss: 0.3138 - val_acc: 0.8949\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31378 to 0.23702, saving model to best.model\n",
      "0s - loss: 0.3122 - acc: 0.8904 - val_loss: 0.2370 - val_acc: 0.9067\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23702 to 0.19806, saving model to best.model\n",
      "0s - loss: 0.2539 - acc: 0.8968 - val_loss: 0.1981 - val_acc: 0.9124\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.19806 to 0.18589, saving model to best.model\n",
      "0s - loss: 0.2273 - acc: 0.9019 - val_loss: 0.1859 - val_acc: 0.9153\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.18589 to 0.18222, saving model to best.model\n",
      "0s - loss: 0.2180 - acc: 0.9025 - val_loss: 0.1822 - val_acc: 0.9178\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18222 to 0.17995, saving model to best.model\n",
      "0s - loss: 0.2106 - acc: 0.9033 - val_loss: 0.1799 - val_acc: 0.9186\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.17995 to 0.17830, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9055 - val_loss: 0.1783 - val_acc: 0.9197\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.17830 to 0.17778, saving model to best.model\n",
      "0s - loss: 0.2032 - acc: 0.9067 - val_loss: 0.1778 - val_acc: 0.9195\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.17778 to 0.17768, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9053 - val_loss: 0.1777 - val_acc: 0.9195\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.17768 to 0.17712, saving model to best.model\n",
      "0s - loss: 0.1992 - acc: 0.9069 - val_loss: 0.1771 - val_acc: 0.9203\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9038 - val_loss: 0.1771 - val_acc: 0.9207\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1983 - acc: 0.9067 - val_loss: 0.1771 - val_acc: 0.9201\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1965 - acc: 0.9075 - val_loss: 0.1772 - val_acc: 0.9213\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.17712 to 0.17697, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9075 - val_loss: 0.1770 - val_acc: 0.9215\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.17697 to 0.17675, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9066 - val_loss: 0.1768 - val_acc: 0.9195\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.17675 to 0.17671, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9076 - val_loss: 0.1767 - val_acc: 0.9215\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.17671 to 0.17653, saving model to best.model\n",
      "0s - loss: 0.1959 - acc: 0.9089 - val_loss: 0.1765 - val_acc: 0.9199\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1944 - acc: 0.9085 - val_loss: 0.1771 - val_acc: 0.9191\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9078 - val_loss: 0.1765 - val_acc: 0.9216\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.17653 to 0.17625, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9102 - val_loss: 0.1763 - val_acc: 0.9211\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.17625 to 0.17542, saving model to best.model\n",
      "0s - loss: 0.1934 - acc: 0.9076 - val_loss: 0.1754 - val_acc: 0.9213\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1947 - acc: 0.9078 - val_loss: 0.1755 - val_acc: 0.9195\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9091 - val_loss: 0.1758 - val_acc: 0.9195\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.17542 to 0.17542, saving model to best.model\n",
      "0s - loss: 0.1914 - acc: 0.9078 - val_loss: 0.1754 - val_acc: 0.9207\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.17542 to 0.17526, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9110 - val_loss: 0.1753 - val_acc: 0.9215\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.17526 to 0.17510, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9099 - val_loss: 0.1751 - val_acc: 0.9184\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.17510 to 0.17443, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9103 - val_loss: 0.1744 - val_acc: 0.9188\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9086 - val_loss: 0.1744 - val_acc: 0.9199\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1920 - acc: 0.9095 - val_loss: 0.1761 - val_acc: 0.9159\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.17443 to 0.17414, saving model to best.model\n",
      "0s - loss: 0.1914 - acc: 0.9108 - val_loss: 0.1741 - val_acc: 0.9191\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.17414 to 0.17395, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9095 - val_loss: 0.1739 - val_acc: 0.9193\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9104 - val_loss: 0.1740 - val_acc: 0.9193\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17395 to 0.17383, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9109 - val_loss: 0.1738 - val_acc: 0.9188\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17383 to 0.17346, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9094 - val_loss: 0.1735 - val_acc: 0.9188\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9113 - val_loss: 0.1739 - val_acc: 0.9191\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9124 - val_loss: 0.1737 - val_acc: 0.9188\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9098 - val_loss: 0.1739 - val_acc: 0.9184\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17346 to 0.17342, saving model to best.model\n",
      "0s - loss: 0.1889 - acc: 0.9103 - val_loss: 0.1734 - val_acc: 0.9195\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9113 - val_loss: 0.1734 - val_acc: 0.9191\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17342 to 0.17297, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9121 - val_loss: 0.1730 - val_acc: 0.9167\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17297 to 0.17277, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9114 - val_loss: 0.1728 - val_acc: 0.9197\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9112 - val_loss: 0.1729 - val_acc: 0.9184\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17277 to 0.17273, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9110 - val_loss: 0.1727 - val_acc: 0.9178\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9114 - val_loss: 0.1742 - val_acc: 0.9195\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9131 - val_loss: 0.1730 - val_acc: 0.9182\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17273 to 0.17234, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9130 - val_loss: 0.1723 - val_acc: 0.9168\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9115 - val_loss: 0.1736 - val_acc: 0.9167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17234 to 0.17232, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9117 - val_loss: 0.1723 - val_acc: 0.9184\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17232 to 0.17201, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9104 - val_loss: 0.1720 - val_acc: 0.9172\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17201 to 0.17193, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9136 - val_loss: 0.1719 - val_acc: 0.9165\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17193 to 0.17165, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9106 - val_loss: 0.1716 - val_acc: 0.9186\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.17165 to 0.17161, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9115 - val_loss: 0.1716 - val_acc: 0.9168\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9119 - val_loss: 0.1721 - val_acc: 0.9172\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9136 - val_loss: 0.1724 - val_acc: 0.9207\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9104 - val_loss: 0.1717 - val_acc: 0.9180\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9134 - val_loss: 0.1720 - val_acc: 0.9195\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.17161 to 0.17119, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9130 - val_loss: 0.1712 - val_acc: 0.9174\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9131 - val_loss: 0.1717 - val_acc: 0.9197\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9129 - val_loss: 0.1722 - val_acc: 0.9211\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.17119 to 0.17069, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9139 - val_loss: 0.1707 - val_acc: 0.9190\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9126 - val_loss: 0.1721 - val_acc: 0.9213\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17069 to 0.17051, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9141 - val_loss: 0.1705 - val_acc: 0.9190\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9150 - val_loss: 0.1706 - val_acc: 0.9191\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9134 - val_loss: 0.1705 - val_acc: 0.9205\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.17051 to 0.17032, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9114 - val_loss: 0.1703 - val_acc: 0.9213\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.17032 to 0.17011, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9137 - val_loss: 0.1701 - val_acc: 0.9193\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9122 - val_loss: 0.1715 - val_acc: 0.9205\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9137 - val_loss: 0.1702 - val_acc: 0.9207\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9124 - val_loss: 0.1704 - val_acc: 0.9209\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9139 - val_loss: 0.1704 - val_acc: 0.9186\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.17011 to 0.16979, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9135 - val_loss: 0.1698 - val_acc: 0.9209\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.16979 to 0.16975, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9133 - val_loss: 0.1698 - val_acc: 0.9209\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9148 - val_loss: 0.1698 - val_acc: 0.9199\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.16975 to 0.16963, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9145 - val_loss: 0.1696 - val_acc: 0.9209\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9124 - val_loss: 0.1698 - val_acc: 0.9209\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9168 - val_loss: 0.1697 - val_acc: 0.9211\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9154 - val_loss: 0.1697 - val_acc: 0.9203\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9134 - val_loss: 0.1697 - val_acc: 0.9215\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9147 - val_loss: 0.1697 - val_acc: 0.9216\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.16963 to 0.16943, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9141 - val_loss: 0.1694 - val_acc: 0.9197\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.16943 to 0.16931, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9153 - val_loss: 0.1693 - val_acc: 0.9195\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.16931 to 0.16920, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9156 - val_loss: 0.1692 - val_acc: 0.9224\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9139 - val_loss: 0.1694 - val_acc: 0.9199\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.16920 to 0.16905, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9150 - val_loss: 0.1691 - val_acc: 0.9218\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9156 - val_loss: 0.1698 - val_acc: 0.9201\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9136 - val_loss: 0.1694 - val_acc: 0.9216\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9151 - val_loss: 0.1698 - val_acc: 0.9199\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.16905 to 0.16890, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9150 - val_loss: 0.1689 - val_acc: 0.9211\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9146 - val_loss: 0.1695 - val_acc: 0.9213\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9149 - val_loss: 0.1693 - val_acc: 0.9197\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9157 - val_loss: 0.1692 - val_acc: 0.9195\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.16890 to 0.16868, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9160 - val_loss: 0.1687 - val_acc: 0.9209\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9164 - val_loss: 0.1691 - val_acc: 0.9218\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9146 - val_loss: 0.1690 - val_acc: 0.9193\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.16868 to 0.16868, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9150 - val_loss: 0.1687 - val_acc: 0.9201\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9149 - val_loss: 0.1689 - val_acc: 0.9215\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.16868 to 0.16844, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9163 - val_loss: 0.1684 - val_acc: 0.9207\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9149 - val_loss: 0.1686 - val_acc: 0.9201\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.16844 to 0.16843, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9163 - val_loss: 0.1684 - val_acc: 0.9205\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9163 - val_loss: 0.1690 - val_acc: 0.9216\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9171 - val_loss: 0.1685 - val_acc: 0.9220\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.16843 to 0.16829, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9169 - val_loss: 0.1683 - val_acc: 0.9220\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9156 - val_loss: 0.1688 - val_acc: 0.9216\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9172 - val_loss: 0.1684 - val_acc: 0.9215\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9144 - val_loss: 0.1684 - val_acc: 0.9209\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9168 - val_loss: 0.1686 - val_acc: 0.9213\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9158 - val_loss: 0.1685 - val_acc: 0.9213\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.16829 to 0.16811, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9178 - val_loss: 0.1681 - val_acc: 0.9216\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.16811 to 0.16803, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9155 - val_loss: 0.1680 - val_acc: 0.9211\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9168 - val_loss: 0.1682 - val_acc: 0.9203\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9156 - val_loss: 0.1682 - val_acc: 0.9211\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9166 - val_loss: 0.1680 - val_acc: 0.9220\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9152 - val_loss: 0.1681 - val_acc: 0.9193\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9141 - val_loss: 0.1681 - val_acc: 0.9207\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9164 - val_loss: 0.1685 - val_acc: 0.9203\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.16803 to 0.16773, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9175 - val_loss: 0.1677 - val_acc: 0.9224\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9169 - val_loss: 0.1678 - val_acc: 0.9216\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9167 - val_loss: 0.1678 - val_acc: 0.9215\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9168 - val_loss: 0.1681 - val_acc: 0.9230\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9179 - val_loss: 0.1677 - val_acc: 0.9220\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9187 - val_loss: 0.1677 - val_acc: 0.9215\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.16773 to 0.16750, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9175 - val_loss: 0.1675 - val_acc: 0.9216\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9161 - val_loss: 0.1677 - val_acc: 0.9222\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.16750 to 0.16746, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9169 - val_loss: 0.1675 - val_acc: 0.9220\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9173 - val_loss: 0.1675 - val_acc: 0.9224\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9163 - val_loss: 0.1675 - val_acc: 0.9213\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9172 - val_loss: 0.1681 - val_acc: 0.9222\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9161 - val_loss: 0.1679 - val_acc: 0.9228\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.16746 to 0.16726, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9175 - val_loss: 0.1673 - val_acc: 0.9222\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9173 - val_loss: 0.1674 - val_acc: 0.9218\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9170 - val_loss: 0.1673 - val_acc: 0.9207\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.16726 to 0.16705, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9167 - val_loss: 0.1671 - val_acc: 0.9224\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.16705 to 0.16700, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9183 - val_loss: 0.1670 - val_acc: 0.9207\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9174 - val_loss: 0.1673 - val_acc: 0.9228\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9189 - val_loss: 0.1672 - val_acc: 0.9209\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9166 - val_loss: 0.1673 - val_acc: 0.9224\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9178 - val_loss: 0.1677 - val_acc: 0.9224\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9185 - val_loss: 0.1673 - val_acc: 0.9230\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9190 - val_loss: 0.1672 - val_acc: 0.9220\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9194 - val_loss: 0.1672 - val_acc: 0.9220\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.16700 to 0.16690, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9184 - val_loss: 0.1669 - val_acc: 0.9213\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.16690 to 0.16676, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9174 - val_loss: 0.1668 - val_acc: 0.9215\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9195 - val_loss: 0.1671 - val_acc: 0.9230\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9186 - val_loss: 0.1670 - val_acc: 0.9236\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9184 - val_loss: 0.1673 - val_acc: 0.9232\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9175 - val_loss: 0.1670 - val_acc: 0.9199\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9186 - val_loss: 0.1669 - val_acc: 0.9209\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9181 - val_loss: 0.1671 - val_acc: 0.9230\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9194 - val_loss: 0.1670 - val_acc: 0.9236\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9196 - val_loss: 0.1670 - val_acc: 0.9211\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.16676 to 0.16671, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9185 - val_loss: 0.1667 - val_acc: 0.9232\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.16671 to 0.16671, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9192 - val_loss: 0.1667 - val_acc: 0.9230\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9187 - val_loss: 0.1671 - val_acc: 0.9228\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9187 - val_loss: 0.1668 - val_acc: 0.9230\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.16671 to 0.16663, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9183 - val_loss: 0.1666 - val_acc: 0.9215\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9195 - val_loss: 0.1669 - val_acc: 0.9218\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.16663 to 0.16659, saving model to best.model\n",
      "0s - loss: 0.1712 - acc: 0.9195 - val_loss: 0.1666 - val_acc: 0.9226\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.16659 to 0.16658, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9178 - val_loss: 0.1666 - val_acc: 0.9226\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9180 - val_loss: 0.1667 - val_acc: 0.9222\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9206 - val_loss: 0.1673 - val_acc: 0.9209\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9176 - val_loss: 0.1668 - val_acc: 0.9236\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.16658 to 0.16644, saving model to best.model\n",
      "0s - loss: 0.1688 - acc: 0.9181 - val_loss: 0.1664 - val_acc: 0.9224\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.16644 to 0.16644, saving model to best.model\n",
      "0s - loss: 0.1694 - acc: 0.9193 - val_loss: 0.1664 - val_acc: 0.9226\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.16644 to 0.16619, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9184 - val_loss: 0.1662 - val_acc: 0.9234\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.16619 to 0.16611, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9177 - val_loss: 0.1661 - val_acc: 0.9230\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9194 - val_loss: 0.1662 - val_acc: 0.9224\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9199 - val_loss: 0.1670 - val_acc: 0.9218\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9181 - val_loss: 0.1663 - val_acc: 0.9230\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9199 - val_loss: 0.1666 - val_acc: 0.9226\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9197 - val_loss: 0.1665 - val_acc: 0.9216\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9185 - val_loss: 0.1663 - val_acc: 0.9222\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9191 - val_loss: 0.1667 - val_acc: 0.9222\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9184 - val_loss: 0.1665 - val_acc: 0.9209\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9194 - val_loss: 0.1666 - val_acc: 0.9207\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9193 - val_loss: 0.1666 - val_acc: 0.9220\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9187 - val_loss: 0.1667 - val_acc: 0.9220\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9197 - val_loss: 0.1663 - val_acc: 0.9220\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9192 - val_loss: 0.1662 - val_acc: 0.9209\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9198 - val_loss: 0.1668 - val_acc: 0.9224\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9190 - val_loss: 0.1661 - val_acc: 0.9209\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.16611 to 0.16606, saving model to best.model\n",
      "0s - loss: 0.1693 - acc: 0.9170 - val_loss: 0.1661 - val_acc: 0.9205\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9201 - val_loss: 0.1662 - val_acc: 0.9224\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9197 - val_loss: 0.1667 - val_acc: 0.9218\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9207 - val_loss: 0.1663 - val_acc: 0.9224\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9208 - val_loss: 0.1662 - val_acc: 0.9222\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.16606 to 0.16592, saving model to best.model\n",
      "0s - loss: 0.1659 - acc: 0.9199 - val_loss: 0.1659 - val_acc: 0.9216\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9194 - val_loss: 0.1662 - val_acc: 0.9213\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1661 - acc: 0.9192 - val_loss: 0.1663 - val_acc: 0.9218\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9200 - val_loss: 0.1667 - val_acc: 0.9234\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9198 - val_loss: 0.1660 - val_acc: 0.9216\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9197 - val_loss: 0.1664 - val_acc: 0.9216\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9190 - val_loss: 0.1660 - val_acc: 0.9222\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.16592 to 0.16570, saving model to best.model\n",
      "0s - loss: 0.1671 - acc: 0.9201 - val_loss: 0.1657 - val_acc: 0.9236\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9187 - val_loss: 0.1660 - val_acc: 0.9222\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9200 - val_loss: 0.1665 - val_acc: 0.9220\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9208 - val_loss: 0.1664 - val_acc: 0.9218\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9220 - val_loss: 0.1658 - val_acc: 0.9220\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9194 - val_loss: 0.1661 - val_acc: 0.9220\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1650 - acc: 0.9200 - val_loss: 0.1663 - val_acc: 0.9220\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1645 - acc: 0.9204 - val_loss: 0.1662 - val_acc: 0.9216\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31804, saving model to best.model\n",
      "0s - loss: 0.3823 - acc: 0.8835 - val_loss: 0.3180 - val_acc: 0.8886\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31804 to 0.22826, saving model to best.model\n",
      "0s - loss: 0.3047 - acc: 0.8913 - val_loss: 0.2283 - val_acc: 0.9070\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.22826 to 0.20235, saving model to best.model\n",
      "0s - loss: 0.2414 - acc: 0.9005 - val_loss: 0.2024 - val_acc: 0.9103\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20235 to 0.19159, saving model to best.model\n",
      "0s - loss: 0.2240 - acc: 0.9048 - val_loss: 0.1916 - val_acc: 0.9167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19159 to 0.18799, saving model to best.model\n",
      "0s - loss: 0.2146 - acc: 0.9055 - val_loss: 0.1880 - val_acc: 0.9178\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18799 to 0.18655, saving model to best.model\n",
      "0s - loss: 0.2072 - acc: 0.9078 - val_loss: 0.1866 - val_acc: 0.9168\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18655 to 0.18592, saving model to best.model\n",
      "0s - loss: 0.2043 - acc: 0.9077 - val_loss: 0.1859 - val_acc: 0.9167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2017 - acc: 0.9085 - val_loss: 0.1865 - val_acc: 0.9178\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18592 to 0.18552, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9095 - val_loss: 0.1855 - val_acc: 0.9168\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.1990 - acc: 0.9091 - val_loss: 0.1865 - val_acc: 0.9138\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18552 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1992 - acc: 0.9083 - val_loss: 0.1851 - val_acc: 0.9157\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9095 - val_loss: 0.1851 - val_acc: 0.9165\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18508 to 0.18496, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9091 - val_loss: 0.1850 - val_acc: 0.9163\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1950 - acc: 0.9097 - val_loss: 0.1853 - val_acc: 0.9165\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9106 - val_loss: 0.1864 - val_acc: 0.9165\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.18496 to 0.18475, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9096 - val_loss: 0.1847 - val_acc: 0.9163\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18475 to 0.18455, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9113 - val_loss: 0.1845 - val_acc: 0.9165\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9089 - val_loss: 0.1848 - val_acc: 0.9165\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18455 to 0.18412, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9109 - val_loss: 0.1841 - val_acc: 0.9163\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18412 to 0.18383, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9111 - val_loss: 0.1838 - val_acc: 0.9163\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9109 - val_loss: 0.1850 - val_acc: 0.9163\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18383 to 0.18372, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9108 - val_loss: 0.1837 - val_acc: 0.9167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18372 to 0.18360, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9107 - val_loss: 0.1836 - val_acc: 0.9159\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18360 to 0.18360, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9103 - val_loss: 0.1836 - val_acc: 0.9170\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18360 to 0.18328, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9121 - val_loss: 0.1833 - val_acc: 0.9170\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18328 to 0.18297, saving model to best.model\n",
      "0s - loss: 0.1914 - acc: 0.9115 - val_loss: 0.1830 - val_acc: 0.9174\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9122 - val_loss: 0.1831 - val_acc: 0.9178\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9117 - val_loss: 0.1838 - val_acc: 0.9170\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18297 to 0.18240, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9114 - val_loss: 0.1824 - val_acc: 0.9163\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18240 to 0.18215, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9120 - val_loss: 0.1822 - val_acc: 0.9176\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18215 to 0.18182, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9120 - val_loss: 0.1818 - val_acc: 0.9180\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18182 to 0.18177, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9127 - val_loss: 0.1818 - val_acc: 0.9176\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18177 to 0.18166, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9121 - val_loss: 0.1817 - val_acc: 0.9186\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9120 - val_loss: 0.1823 - val_acc: 0.9165\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18166 to 0.18137, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9112 - val_loss: 0.1814 - val_acc: 0.9176\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18137 to 0.18093, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9131 - val_loss: 0.1809 - val_acc: 0.9182\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18093 to 0.18088, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9113 - val_loss: 0.1809 - val_acc: 0.9188\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18088 to 0.18057, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9144 - val_loss: 0.1806 - val_acc: 0.9182\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9125 - val_loss: 0.1811 - val_acc: 0.9167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18057 to 0.18013, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9127 - val_loss: 0.1801 - val_acc: 0.9193\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18013 to 0.18012, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9147 - val_loss: 0.1801 - val_acc: 0.9191\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18012 to 0.18007, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9128 - val_loss: 0.1801 - val_acc: 0.9203\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9117 - val_loss: 0.1810 - val_acc: 0.9180\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18007 to 0.17959, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9134 - val_loss: 0.1796 - val_acc: 0.9190\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.17959 to 0.17937, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9138 - val_loss: 0.1794 - val_acc: 0.9195\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9133 - val_loss: 0.1800 - val_acc: 0.9201\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9128 - val_loss: 0.1795 - val_acc: 0.9209\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17937 to 0.17906, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9138 - val_loss: 0.1791 - val_acc: 0.9209\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17906 to 0.17885, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9157 - val_loss: 0.1788 - val_acc: 0.9201\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17885 to 0.17856, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9153 - val_loss: 0.1786 - val_acc: 0.9205\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9148 - val_loss: 0.1792 - val_acc: 0.9191\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9147 - val_loss: 0.1787 - val_acc: 0.9193\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9122 - val_loss: 0.1791 - val_acc: 0.9199\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.17856 to 0.17841, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9150 - val_loss: 0.1784 - val_acc: 0.9209\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.17841 to 0.17801, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9148 - val_loss: 0.1780 - val_acc: 0.9201\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.17801 to 0.17800, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9155 - val_loss: 0.1780 - val_acc: 0.9209\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.17800 to 0.17771, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9145 - val_loss: 0.1777 - val_acc: 0.9201\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9143 - val_loss: 0.1780 - val_acc: 0.9201\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.17771 to 0.17738, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9144 - val_loss: 0.1774 - val_acc: 0.9197\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9144 - val_loss: 0.1776 - val_acc: 0.9215\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17738 to 0.17722, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9159 - val_loss: 0.1772 - val_acc: 0.9197\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9145 - val_loss: 0.1773 - val_acc: 0.9199\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17722 to 0.17718, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9148 - val_loss: 0.1772 - val_acc: 0.9215\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17718 to 0.17655, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9154 - val_loss: 0.1766 - val_acc: 0.9186\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.17655 to 0.17650, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9142 - val_loss: 0.1765 - val_acc: 0.9211\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9140 - val_loss: 0.1769 - val_acc: 0.9216\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.17650 to 0.17643, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9156 - val_loss: 0.1764 - val_acc: 0.9211\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9150 - val_loss: 0.1765 - val_acc: 0.9215\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17643 to 0.17615, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9160 - val_loss: 0.1761 - val_acc: 0.9205\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9154 - val_loss: 0.1762 - val_acc: 0.9201\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9158 - val_loss: 0.1787 - val_acc: 0.9199\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17615 to 0.17583, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9151 - val_loss: 0.1758 - val_acc: 0.9193\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.17583 to 0.17566, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9162 - val_loss: 0.1757 - val_acc: 0.9191\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17566 to 0.17562, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9156 - val_loss: 0.1756 - val_acc: 0.9199\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17562 to 0.17548, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9163 - val_loss: 0.1755 - val_acc: 0.9197\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9157 - val_loss: 0.1757 - val_acc: 0.9199\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9163 - val_loss: 0.1771 - val_acc: 0.9209\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17548 to 0.17517, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9169 - val_loss: 0.1752 - val_acc: 0.9205\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9168 - val_loss: 0.1756 - val_acc: 0.9213\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.17517 to 0.17500, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9159 - val_loss: 0.1750 - val_acc: 0.9207\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9168 - val_loss: 0.1754 - val_acc: 0.9209\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.17500 to 0.17489, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9170 - val_loss: 0.1749 - val_acc: 0.9207\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9172 - val_loss: 0.1757 - val_acc: 0.9215\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17489 to 0.17467, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9160 - val_loss: 0.1747 - val_acc: 0.9201\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9173 - val_loss: 0.1757 - val_acc: 0.9224\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9160 - val_loss: 0.1751 - val_acc: 0.9215\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17467 to 0.17406, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9175 - val_loss: 0.1741 - val_acc: 0.9213\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9177 - val_loss: 0.1742 - val_acc: 0.9205\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17406 to 0.17387, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9182 - val_loss: 0.1739 - val_acc: 0.9205\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9168 - val_loss: 0.1743 - val_acc: 0.9191\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9175 - val_loss: 0.1739 - val_acc: 0.9211\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9164 - val_loss: 0.1743 - val_acc: 0.9209\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17387 to 0.17357, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9156 - val_loss: 0.1736 - val_acc: 0.9218\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17357 to 0.17327, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9186 - val_loss: 0.1733 - val_acc: 0.9211\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9160 - val_loss: 0.1734 - val_acc: 0.9213\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17327 to 0.17304, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9177 - val_loss: 0.1730 - val_acc: 0.9220\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9163 - val_loss: 0.1734 - val_acc: 0.9203\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17304 to 0.17303, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9175 - val_loss: 0.1730 - val_acc: 0.9213\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9169 - val_loss: 0.1734 - val_acc: 0.9220\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17303 to 0.17284, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9199 - val_loss: 0.1728 - val_acc: 0.9211\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9175 - val_loss: 0.1734 - val_acc: 0.9213\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9178 - val_loss: 0.1734 - val_acc: 0.9218\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9172 - val_loss: 0.1729 - val_acc: 0.9215\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17284 to 0.17265, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9171 - val_loss: 0.1727 - val_acc: 0.9213\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.17265 to 0.17241, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9177 - val_loss: 0.1724 - val_acc: 0.9216\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17241 to 0.17209, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9185 - val_loss: 0.1721 - val_acc: 0.9216\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9196 - val_loss: 0.1722 - val_acc: 0.9226\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9187 - val_loss: 0.1722 - val_acc: 0.9216\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17209 to 0.17204, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9173 - val_loss: 0.1720 - val_acc: 0.9220\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17204 to 0.17185, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9182 - val_loss: 0.1719 - val_acc: 0.9215\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9176 - val_loss: 0.1720 - val_acc: 0.9211\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17185 to 0.17156, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9179 - val_loss: 0.1716 - val_acc: 0.9213\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17156 to 0.17153, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9176 - val_loss: 0.1715 - val_acc: 0.9218\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17153 to 0.17152, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9187 - val_loss: 0.1715 - val_acc: 0.9211\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.17152 to 0.17128, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9183 - val_loss: 0.1713 - val_acc: 0.9218\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9172 - val_loss: 0.1716 - val_acc: 0.9220\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9190 - val_loss: 0.1717 - val_acc: 0.9228\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9200 - val_loss: 0.1716 - val_acc: 0.9215\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17128 to 0.17092, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9191 - val_loss: 0.1709 - val_acc: 0.9222\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.17092 to 0.17090, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9187 - val_loss: 0.1709 - val_acc: 0.9222\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9185 - val_loss: 0.1709 - val_acc: 0.9218\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17090 to 0.17086, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9180 - val_loss: 0.1709 - val_acc: 0.9207\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9184 - val_loss: 0.1710 - val_acc: 0.9239\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17086 to 0.17059, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9201 - val_loss: 0.1706 - val_acc: 0.9236\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9186 - val_loss: 0.1706 - val_acc: 0.9224\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17059 to 0.17030, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9175 - val_loss: 0.1703 - val_acc: 0.9216\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9196 - val_loss: 0.1706 - val_acc: 0.9230\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9211 - val_loss: 0.1704 - val_acc: 0.9238\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9182 - val_loss: 0.1703 - val_acc: 0.9228\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17030 to 0.16995, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9195 - val_loss: 0.1699 - val_acc: 0.9232\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9193 - val_loss: 0.1707 - val_acc: 0.9234\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9172 - val_loss: 0.1702 - val_acc: 0.9236\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9181 - val_loss: 0.1702 - val_acc: 0.9238\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9184 - val_loss: 0.1700 - val_acc: 0.9236\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.16995 to 0.16972, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9198 - val_loss: 0.1697 - val_acc: 0.9224\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9185 - val_loss: 0.1698 - val_acc: 0.9234\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.16972 to 0.16968, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9179 - val_loss: 0.1697 - val_acc: 0.9238\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.16968 to 0.16949, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9203 - val_loss: 0.1695 - val_acc: 0.9241\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9186 - val_loss: 0.1698 - val_acc: 0.9238\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9195 - val_loss: 0.1695 - val_acc: 0.9243\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.16949 to 0.16944, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9203 - val_loss: 0.1694 - val_acc: 0.9215\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.16944 to 0.16926, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9199 - val_loss: 0.1693 - val_acc: 0.9238\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.16926 to 0.16916, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9202 - val_loss: 0.1692 - val_acc: 0.9241\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.16916 to 0.16892, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9188 - val_loss: 0.1689 - val_acc: 0.9241\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9194 - val_loss: 0.1694 - val_acc: 0.9241\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9186 - val_loss: 0.1690 - val_acc: 0.9228\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9198 - val_loss: 0.1693 - val_acc: 0.9234\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9198 - val_loss: 0.1694 - val_acc: 0.9253\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9201 - val_loss: 0.1715 - val_acc: 0.9241\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.16892 to 0.16889, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9207 - val_loss: 0.1689 - val_acc: 0.9249\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.16889 to 0.16854, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9206 - val_loss: 0.1685 - val_acc: 0.9239\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9211 - val_loss: 0.1687 - val_acc: 0.9226\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.16854 to 0.16843, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9204 - val_loss: 0.1684 - val_acc: 0.9247\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.16843 to 0.16817, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9208 - val_loss: 0.1682 - val_acc: 0.9241\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9204 - val_loss: 0.1685 - val_acc: 0.9251\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9202 - val_loss: 0.1682 - val_acc: 0.9236\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9207 - val_loss: 0.1692 - val_acc: 0.9243\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9201 - val_loss: 0.1683 - val_acc: 0.9243\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.16817 to 0.16813, saving model to best.model\n",
      "0s - loss: 0.1700 - acc: 0.9208 - val_loss: 0.1681 - val_acc: 0.9243\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.16813 to 0.16771, saving model to best.model\n",
      "0s - loss: 0.1705 - acc: 0.9207 - val_loss: 0.1677 - val_acc: 0.9234\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.16771 to 0.16758, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9203 - val_loss: 0.1676 - val_acc: 0.9239\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9198 - val_loss: 0.1681 - val_acc: 0.9232\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9204 - val_loss: 0.1679 - val_acc: 0.9249\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9208 - val_loss: 0.1677 - val_acc: 0.9236\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9203 - val_loss: 0.1688 - val_acc: 0.9253\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.16758 to 0.16754, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9195 - val_loss: 0.1675 - val_acc: 0.9247\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9211 - val_loss: 0.1679 - val_acc: 0.9238\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.16754 to 0.16734, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9200 - val_loss: 0.1673 - val_acc: 0.9238\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9211 - val_loss: 0.1674 - val_acc: 0.9243\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.16734 to 0.16728, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9200 - val_loss: 0.1673 - val_acc: 0.9236\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9212 - val_loss: 0.1678 - val_acc: 0.9249\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.16728 to 0.16722, saving model to best.model\n",
      "0s - loss: 0.1694 - acc: 0.9218 - val_loss: 0.1672 - val_acc: 0.9243\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9205 - val_loss: 0.1673 - val_acc: 0.9247\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.16722 to 0.16692, saving model to best.model\n",
      "0s - loss: 0.1692 - acc: 0.9212 - val_loss: 0.1669 - val_acc: 0.9239\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9221 - val_loss: 0.1672 - val_acc: 0.9241\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9204 - val_loss: 0.1671 - val_acc: 0.9234\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9213 - val_loss: 0.1670 - val_acc: 0.9251\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.16692 to 0.16657, saving model to best.model\n",
      "0s - loss: 0.1677 - acc: 0.9216 - val_loss: 0.1666 - val_acc: 0.9255\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9214 - val_loss: 0.1672 - val_acc: 0.9251\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9215 - val_loss: 0.1672 - val_acc: 0.9234\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9210 - val_loss: 0.1669 - val_acc: 0.9255\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9204 - val_loss: 0.1666 - val_acc: 0.9251\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9206 - val_loss: 0.1667 - val_acc: 0.9249\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9229 - val_loss: 0.1672 - val_acc: 0.9247\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.16657 to 0.16647, saving model to best.model\n",
      "0s - loss: 0.1700 - acc: 0.9215 - val_loss: 0.1665 - val_acc: 0.9236\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.16647 to 0.16628, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9215 - val_loss: 0.1663 - val_acc: 0.9238\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9209 - val_loss: 0.1668 - val_acc: 0.9243\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9213 - val_loss: 0.1666 - val_acc: 0.9234\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9218 - val_loss: 0.1668 - val_acc: 0.9230\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.16628 to 0.16616, saving model to best.model\n",
      "0s - loss: 0.1676 - acc: 0.9211 - val_loss: 0.1662 - val_acc: 0.9239\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9223 - val_loss: 0.1664 - val_acc: 0.9232\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9219 - val_loss: 0.1663 - val_acc: 0.9238\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9210 - val_loss: 0.1663 - val_acc: 0.9245\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.16616 to 0.16593, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9216 - val_loss: 0.1659 - val_acc: 0.9251\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9222 - val_loss: 0.1660 - val_acc: 0.9249\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9217 - val_loss: 0.1659 - val_acc: 0.9243\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.16593 to 0.16575, saving model to best.model\n",
      "0s - loss: 0.1653 - acc: 0.9236 - val_loss: 0.1658 - val_acc: 0.9245\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9216 - val_loss: 0.1660 - val_acc: 0.9249\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9222 - val_loss: 0.1658 - val_acc: 0.9251\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.16575 to 0.16546, saving model to best.model\n",
      "0s - loss: 0.1667 - acc: 0.9214 - val_loss: 0.1655 - val_acc: 0.9253\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34185, saving model to best.model\n",
      "0s - loss: 0.4090 - acc: 0.8661 - val_loss: 0.3418 - val_acc: 0.8859\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34185 to 0.27622, saving model to best.model\n",
      "0s - loss: 0.3351 - acc: 0.8898 - val_loss: 0.2762 - val_acc: 0.8859\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27622 to 0.22849, saving model to best.model\n",
      "0s - loss: 0.2663 - acc: 0.8946 - val_loss: 0.2285 - val_acc: 0.9038\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22849 to 0.21632, saving model to best.model\n",
      "0s - loss: 0.2345 - acc: 0.9003 - val_loss: 0.2163 - val_acc: 0.9070\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.21632 to 0.21150, saving model to best.model\n",
      "0s - loss: 0.2184 - acc: 0.9033 - val_loss: 0.2115 - val_acc: 0.9070\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.21150 to 0.20986, saving model to best.model\n",
      "0s - loss: 0.2130 - acc: 0.9063 - val_loss: 0.2099 - val_acc: 0.9049\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.20986 to 0.20683, saving model to best.model\n",
      "0s - loss: 0.2098 - acc: 0.9046 - val_loss: 0.2068 - val_acc: 0.8998\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2066 - acc: 0.9052 - val_loss: 0.2071 - val_acc: 0.9009\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.20683 to 0.20596, saving model to best.model\n",
      "0s - loss: 0.2028 - acc: 0.9046 - val_loss: 0.2060 - val_acc: 0.8996\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.20596 to 0.20585, saving model to best.model\n",
      "0s - loss: 0.2014 - acc: 0.9036 - val_loss: 0.2059 - val_acc: 0.9009\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2005 - acc: 0.9062 - val_loss: 0.2060 - val_acc: 0.9015\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.20585 to 0.20508, saving model to best.model\n",
      "0s - loss: 0.2013 - acc: 0.9051 - val_loss: 0.2051 - val_acc: 0.9017\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2000 - acc: 0.9052 - val_loss: 0.2064 - val_acc: 0.9015\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1983 - acc: 0.9067 - val_loss: 0.2060 - val_acc: 0.9009\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.20508 to 0.20475, saving model to best.model\n",
      "0s - loss: 0.1986 - acc: 0.9065 - val_loss: 0.2048 - val_acc: 0.9005\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1972 - acc: 0.9062 - val_loss: 0.2059 - val_acc: 0.9042\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.20475 to 0.20451, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9053 - val_loss: 0.2045 - val_acc: 0.8998\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1971 - acc: 0.9069 - val_loss: 0.2046 - val_acc: 0.8971\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1967 - acc: 0.9072 - val_loss: 0.2046 - val_acc: 0.9001\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1966 - acc: 0.9067 - val_loss: 0.2047 - val_acc: 0.9005\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.20451 to 0.20419, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9071 - val_loss: 0.2042 - val_acc: 0.9007\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.20419 to 0.20358, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9062 - val_loss: 0.2036 - val_acc: 0.9005\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20358 to 0.20348, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9064 - val_loss: 0.2035 - val_acc: 0.9003\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20348 to 0.20299, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9085 - val_loss: 0.2030 - val_acc: 0.9019\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9106 - val_loss: 0.2035 - val_acc: 0.9007\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1934 - acc: 0.9076 - val_loss: 0.2034 - val_acc: 0.9009\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9075 - val_loss: 0.2034 - val_acc: 0.9003\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9086 - val_loss: 0.2035 - val_acc: 0.9047\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9088 - val_loss: 0.2036 - val_acc: 0.9022\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20299 to 0.20227, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9073 - val_loss: 0.2023 - val_acc: 0.9051\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20227 to 0.20126, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9092 - val_loss: 0.2013 - val_acc: 0.9003\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20126 to 0.20122, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9088 - val_loss: 0.2012 - val_acc: 0.8998\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.20122 to 0.20090, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9090 - val_loss: 0.2009 - val_acc: 0.8990\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.20090 to 0.20076, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9090 - val_loss: 0.2008 - val_acc: 0.9051\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.20076 to 0.20045, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9094 - val_loss: 0.2004 - val_acc: 0.9024\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9102 - val_loss: 0.2005 - val_acc: 0.9026\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9094 - val_loss: 0.2030 - val_acc: 0.9040\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.20045 to 0.19964, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9114 - val_loss: 0.1996 - val_acc: 0.9065\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9097 - val_loss: 0.2000 - val_acc: 0.9063\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9101 - val_loss: 0.2003 - val_acc: 0.9067\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9103 - val_loss: 0.2003 - val_acc: 0.9059\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19964 to 0.19918, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9106 - val_loss: 0.1992 - val_acc: 0.9036\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9099 - val_loss: 0.1993 - val_acc: 0.9082\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9100 - val_loss: 0.2003 - val_acc: 0.9057\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19918 to 0.19906, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9102 - val_loss: 0.1991 - val_acc: 0.9047\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19906 to 0.19856, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9111 - val_loss: 0.1986 - val_acc: 0.9065\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.19856 to 0.19851, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9107 - val_loss: 0.1985 - val_acc: 0.9028\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9116 - val_loss: 0.1988 - val_acc: 0.9067\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19851 to 0.19829, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9104 - val_loss: 0.1983 - val_acc: 0.9040\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.19829 to 0.19813, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9117 - val_loss: 0.1981 - val_acc: 0.9057\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9112 - val_loss: 0.1983 - val_acc: 0.9034\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9113 - val_loss: 0.1988 - val_acc: 0.9070\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9114 - val_loss: 0.1994 - val_acc: 0.9078\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.19813 to 0.19803, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9132 - val_loss: 0.1980 - val_acc: 0.9028\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9112 - val_loss: 0.1981 - val_acc: 0.9070\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9104 - val_loss: 0.1988 - val_acc: 0.9082\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9111 - val_loss: 0.1986 - val_acc: 0.9080\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9122 - val_loss: 0.1986 - val_acc: 0.9080\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.19803 to 0.19737, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9114 - val_loss: 0.1974 - val_acc: 0.9061\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1872 - acc: 0.9112 - val_loss: 0.1976 - val_acc: 0.9063\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9115 - val_loss: 0.1983 - val_acc: 0.9101\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.19737 to 0.19735, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9106 - val_loss: 0.1974 - val_acc: 0.9065\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9124 - val_loss: 0.1987 - val_acc: 0.9080\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.19735 to 0.19695, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9121 - val_loss: 0.1970 - val_acc: 0.9067\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.19695 to 0.19667, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9124 - val_loss: 0.1967 - val_acc: 0.9074\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.19667 to 0.19645, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9115 - val_loss: 0.1964 - val_acc: 0.9063\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9131 - val_loss: 0.1970 - val_acc: 0.9063\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9120 - val_loss: 0.1965 - val_acc: 0.9049\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9115 - val_loss: 0.1992 - val_acc: 0.9049\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9123 - val_loss: 0.1969 - val_acc: 0.9049\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9139 - val_loss: 0.1976 - val_acc: 0.9080\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.19645 to 0.19618, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9124 - val_loss: 0.1962 - val_acc: 0.9070\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9132 - val_loss: 0.1977 - val_acc: 0.9080\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9128 - val_loss: 0.1964 - val_acc: 0.9065\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9112 - val_loss: 0.1968 - val_acc: 0.9061\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9123 - val_loss: 0.1965 - val_acc: 0.9086\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9123 - val_loss: 0.1975 - val_acc: 0.9086\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9126 - val_loss: 0.1979 - val_acc: 0.9084\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.19618 to 0.19574, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9120 - val_loss: 0.1957 - val_acc: 0.9065\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9113 - val_loss: 0.1961 - val_acc: 0.9080\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.19574 to 0.19542, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9136 - val_loss: 0.1954 - val_acc: 0.9046\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9134 - val_loss: 0.1957 - val_acc: 0.9069\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.19542 to 0.19518, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9130 - val_loss: 0.1952 - val_acc: 0.9059\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.19518 to 0.19497, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9137 - val_loss: 0.1950 - val_acc: 0.9061\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9124 - val_loss: 0.1962 - val_acc: 0.9084\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9132 - val_loss: 0.1954 - val_acc: 0.9061\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9128 - val_loss: 0.1957 - val_acc: 0.9057\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9129 - val_loss: 0.1969 - val_acc: 0.9082\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.19497 to 0.19463, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9139 - val_loss: 0.1946 - val_acc: 0.9065\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9127 - val_loss: 0.1959 - val_acc: 0.9094\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9133 - val_loss: 0.1948 - val_acc: 0.9101\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9124 - val_loss: 0.1961 - val_acc: 0.9063\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9118 - val_loss: 0.1954 - val_acc: 0.9044\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9121 - val_loss: 0.1957 - val_acc: 0.9074\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.19463 to 0.19389, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9129 - val_loss: 0.1939 - val_acc: 0.9063\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9123 - val_loss: 0.1945 - val_acc: 0.9082\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.19389 to 0.19348, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9126 - val_loss: 0.1935 - val_acc: 0.9074\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9135 - val_loss: 0.1941 - val_acc: 0.9072\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9132 - val_loss: 0.1953 - val_acc: 0.9086\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.19348 to 0.19326, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9135 - val_loss: 0.1933 - val_acc: 0.9099\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.19326 to 0.19290, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9141 - val_loss: 0.1929 - val_acc: 0.9076\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9137 - val_loss: 0.1935 - val_acc: 0.9109\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9154 - val_loss: 0.1943 - val_acc: 0.9094\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9142 - val_loss: 0.1947 - val_acc: 0.9099\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9154 - val_loss: 0.1930 - val_acc: 0.9072\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9150 - val_loss: 0.1939 - val_acc: 0.9080\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.19290 to 0.19284, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9143 - val_loss: 0.1928 - val_acc: 0.9072\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.19284 to 0.19267, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9134 - val_loss: 0.1927 - val_acc: 0.9080\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9145 - val_loss: 0.1944 - val_acc: 0.9090\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9142 - val_loss: 0.1935 - val_acc: 0.9088\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.19267 to 0.19233, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9138 - val_loss: 0.1923 - val_acc: 0.9072\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9134 - val_loss: 0.1931 - val_acc: 0.9074\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9142 - val_loss: 0.1927 - val_acc: 0.9082\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9148 - val_loss: 0.1926 - val_acc: 0.9076\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9140 - val_loss: 0.1932 - val_acc: 0.9086\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9127 - val_loss: 0.1940 - val_acc: 0.9094\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9128 - val_loss: 0.1934 - val_acc: 0.9094\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.19233 to 0.19224, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9145 - val_loss: 0.1922 - val_acc: 0.9090\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.19224 to 0.19219, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9146 - val_loss: 0.1922 - val_acc: 0.9090\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9140 - val_loss: 0.1926 - val_acc: 0.9088\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.19219 to 0.19143, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9134 - val_loss: 0.1914 - val_acc: 0.9078\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9140 - val_loss: 0.1920 - val_acc: 0.9078\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9130 - val_loss: 0.1915 - val_acc: 0.9092\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9137 - val_loss: 0.1924 - val_acc: 0.9094\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9154 - val_loss: 0.1930 - val_acc: 0.9082\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9150 - val_loss: 0.1920 - val_acc: 0.9088\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9156 - val_loss: 0.1932 - val_acc: 0.9094\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9165 - val_loss: 0.1922 - val_acc: 0.9086\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.19143 to 0.19076, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9141 - val_loss: 0.1908 - val_acc: 0.9094\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9151 - val_loss: 0.1911 - val_acc: 0.9088\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9151 - val_loss: 0.1930 - val_acc: 0.9095\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.19076 to 0.19063, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9145 - val_loss: 0.1906 - val_acc: 0.9095\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9170 - val_loss: 0.1911 - val_acc: 0.9078\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9158 - val_loss: 0.1906 - val_acc: 0.9094\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9152 - val_loss: 0.1921 - val_acc: 0.9082\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.19063 to 0.19002, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9148 - val_loss: 0.1900 - val_acc: 0.9095\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9154 - val_loss: 0.1901 - val_acc: 0.9097\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9171 - val_loss: 0.1902 - val_acc: 0.9094\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9152 - val_loss: 0.1937 - val_acc: 0.9094\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9152 - val_loss: 0.1925 - val_acc: 0.9099\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9157 - val_loss: 0.1904 - val_acc: 0.9097\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9150 - val_loss: 0.1903 - val_acc: 0.9094\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.19002 to 0.18981, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9153 - val_loss: 0.1898 - val_acc: 0.9099\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9157 - val_loss: 0.1909 - val_acc: 0.9090\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9144 - val_loss: 0.1911 - val_acc: 0.9097\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9138 - val_loss: 0.1906 - val_acc: 0.9099\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18981 to 0.18938, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9166 - val_loss: 0.1894 - val_acc: 0.9105\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9152 - val_loss: 0.1916 - val_acc: 0.9099\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9159 - val_loss: 0.1904 - val_acc: 0.9103\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9167 - val_loss: 0.1896 - val_acc: 0.9092\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9154 - val_loss: 0.1919 - val_acc: 0.9103\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9168 - val_loss: 0.1901 - val_acc: 0.9107\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9164 - val_loss: 0.1903 - val_acc: 0.9103\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.18938 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9169 - val_loss: 0.1888 - val_acc: 0.9086\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9151 - val_loss: 0.1892 - val_acc: 0.9103\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9150 - val_loss: 0.1903 - val_acc: 0.9099\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9150 - val_loss: 0.1892 - val_acc: 0.9095\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9148 - val_loss: 0.1905 - val_acc: 0.9101\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9153 - val_loss: 0.1896 - val_acc: 0.9103\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.18876 to 0.18801, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9162 - val_loss: 0.1880 - val_acc: 0.9094\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9166 - val_loss: 0.1891 - val_acc: 0.9103\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9149 - val_loss: 0.1903 - val_acc: 0.9101\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9163 - val_loss: 0.1885 - val_acc: 0.9109\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9176 - val_loss: 0.1894 - val_acc: 0.9107\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9163 - val_loss: 0.1887 - val_acc: 0.9111\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9178 - val_loss: 0.1891 - val_acc: 0.9107\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9185 - val_loss: 0.1882 - val_acc: 0.9113\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9179 - val_loss: 0.1890 - val_acc: 0.9105\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.18801 to 0.18738, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9169 - val_loss: 0.1874 - val_acc: 0.9095\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9169 - val_loss: 0.1885 - val_acc: 0.9105\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9165 - val_loss: 0.1879 - val_acc: 0.9109\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9157 - val_loss: 0.1895 - val_acc: 0.9113\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9160 - val_loss: 0.1892 - val_acc: 0.9103\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9179 - val_loss: 0.1897 - val_acc: 0.9111\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9182 - val_loss: 0.1877 - val_acc: 0.9092\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9160 - val_loss: 0.1891 - val_acc: 0.9113\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9165 - val_loss: 0.1898 - val_acc: 0.9103\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9173 - val_loss: 0.1878 - val_acc: 0.9101\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9161 - val_loss: 0.1876 - val_acc: 0.9097\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.18738 to 0.18729, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9163 - val_loss: 0.1873 - val_acc: 0.9117\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.18729 to 0.18679, saving model to best.model\n",
      "0s - loss: 0.1692 - acc: 0.9195 - val_loss: 0.1868 - val_acc: 0.9101\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9177 - val_loss: 0.1884 - val_acc: 0.9090\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9184 - val_loss: 0.1872 - val_acc: 0.9113\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9187 - val_loss: 0.1879 - val_acc: 0.9107\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9178 - val_loss: 0.1885 - val_acc: 0.9111\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.18679 to 0.18661, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9167 - val_loss: 0.1866 - val_acc: 0.9105\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.18661 to 0.18637, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9170 - val_loss: 0.1864 - val_acc: 0.9109\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9189 - val_loss: 0.1864 - val_acc: 0.9111\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.18637 to 0.18577, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9194 - val_loss: 0.1858 - val_acc: 0.9115\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9191 - val_loss: 0.1861 - val_acc: 0.9107\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9171 - val_loss: 0.1871 - val_acc: 0.9111\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9174 - val_loss: 0.1871 - val_acc: 0.9111\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9178 - val_loss: 0.1863 - val_acc: 0.9109\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9169 - val_loss: 0.1861 - val_acc: 0.9109\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9185 - val_loss: 0.1860 - val_acc: 0.9109\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9183 - val_loss: 0.1875 - val_acc: 0.9111\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9190 - val_loss: 0.1861 - val_acc: 0.9107\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9192 - val_loss: 0.1875 - val_acc: 0.9109\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.18577 to 0.18569, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9186 - val_loss: 0.1857 - val_acc: 0.9111\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9178 - val_loss: 0.1862 - val_acc: 0.9115\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33839, saving model to best.model\n",
      "0s - loss: 0.4334 - acc: 0.8544 - val_loss: 0.3384 - val_acc: 0.8877\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33839 to 0.27553, saving model to best.model\n",
      "0s - loss: 0.3456 - acc: 0.8860 - val_loss: 0.2755 - val_acc: 0.8877\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27553 to 0.21900, saving model to best.model\n",
      "0s - loss: 0.2773 - acc: 0.8912 - val_loss: 0.2190 - val_acc: 0.9019\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21900 to 0.19504, saving model to best.model\n",
      "0s - loss: 0.2416 - acc: 0.8984 - val_loss: 0.1950 - val_acc: 0.9086\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19504 to 0.18993, saving model to best.model\n",
      "0s - loss: 0.2272 - acc: 0.9007 - val_loss: 0.1899 - val_acc: 0.9092\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18993 to 0.18702, saving model to best.model\n",
      "0s - loss: 0.2176 - acc: 0.9034 - val_loss: 0.1870 - val_acc: 0.9113\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18702 to 0.18457, saving model to best.model\n",
      "0s - loss: 0.2105 - acc: 0.9059 - val_loss: 0.1846 - val_acc: 0.9130\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18457 to 0.18449, saving model to best.model\n",
      "0s - loss: 0.2059 - acc: 0.9059 - val_loss: 0.1845 - val_acc: 0.9113\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18449 to 0.18364, saving model to best.model\n",
      "0s - loss: 0.2036 - acc: 0.9057 - val_loss: 0.1836 - val_acc: 0.9132\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18364 to 0.18267, saving model to best.model\n",
      "0s - loss: 0.2019 - acc: 0.9051 - val_loss: 0.1827 - val_acc: 0.9140\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2007 - acc: 0.9046 - val_loss: 0.1837 - val_acc: 0.9109\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18267 to 0.18242, saving model to best.model\n",
      "0s - loss: 0.1991 - acc: 0.9069 - val_loss: 0.1824 - val_acc: 0.9126\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1986 - acc: 0.9053 - val_loss: 0.1824 - val_acc: 0.9120\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18242 to 0.18234, saving model to best.model\n",
      "0s - loss: 0.1986 - acc: 0.9076 - val_loss: 0.1823 - val_acc: 0.9118\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.18234 to 0.18215, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9073 - val_loss: 0.1821 - val_acc: 0.9122\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1960 - acc: 0.9082 - val_loss: 0.1822 - val_acc: 0.9122\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1951 - acc: 0.9060 - val_loss: 0.1830 - val_acc: 0.9117\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18215 to 0.18191, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9076 - val_loss: 0.1819 - val_acc: 0.9122\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9074 - val_loss: 0.1824 - val_acc: 0.9122\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18191 to 0.18170, saving model to best.model\n",
      "0s - loss: 0.1955 - acc: 0.9082 - val_loss: 0.1817 - val_acc: 0.9113\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9089 - val_loss: 0.1820 - val_acc: 0.9118\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18170 to 0.18161, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9083 - val_loss: 0.1816 - val_acc: 0.9117\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18161 to 0.18133, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9073 - val_loss: 0.1813 - val_acc: 0.9109\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1928 - acc: 0.9091 - val_loss: 0.1814 - val_acc: 0.9118\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9084 - val_loss: 0.1815 - val_acc: 0.9109\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18133 to 0.18093, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9094 - val_loss: 0.1809 - val_acc: 0.9117\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9085 - val_loss: 0.1812 - val_acc: 0.9103\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18093 to 0.18075, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9105 - val_loss: 0.1808 - val_acc: 0.9107\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18075 to 0.18069, saving model to best.model\n",
      "0s - loss: 0.1903 - acc: 0.9103 - val_loss: 0.1807 - val_acc: 0.9122\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18069 to 0.18052, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9100 - val_loss: 0.1805 - val_acc: 0.9122\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18052 to 0.18047, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9095 - val_loss: 0.1805 - val_acc: 0.9120\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18047 to 0.18015, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9107 - val_loss: 0.1802 - val_acc: 0.9115\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9108 - val_loss: 0.1806 - val_acc: 0.9107\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18015 to 0.17988, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9107 - val_loss: 0.1799 - val_acc: 0.9109\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9119 - val_loss: 0.1812 - val_acc: 0.9101\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9103 - val_loss: 0.1802 - val_acc: 0.9111\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9105 - val_loss: 0.1803 - val_acc: 0.9109\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17988 to 0.17973, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9109 - val_loss: 0.1797 - val_acc: 0.9107\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9122 - val_loss: 0.1800 - val_acc: 0.9115\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17973 to 0.17946, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9126 - val_loss: 0.1795 - val_acc: 0.9118\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9116 - val_loss: 0.1797 - val_acc: 0.9122\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17946 to 0.17946, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9106 - val_loss: 0.1795 - val_acc: 0.9117\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9124 - val_loss: 0.1798 - val_acc: 0.9107\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9111 - val_loss: 0.1795 - val_acc: 0.9122\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.17946 to 0.17941, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9118 - val_loss: 0.1794 - val_acc: 0.9107\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17941 to 0.17921, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9109 - val_loss: 0.1792 - val_acc: 0.9111\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9125 - val_loss: 0.1793 - val_acc: 0.9117\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9132 - val_loss: 0.1800 - val_acc: 0.9105\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17921 to 0.17894, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9133 - val_loss: 0.1789 - val_acc: 0.9126\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9125 - val_loss: 0.1798 - val_acc: 0.9118\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9127 - val_loss: 0.1792 - val_acc: 0.9103\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9127 - val_loss: 0.1793 - val_acc: 0.9122\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17894 to 0.17840, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9136 - val_loss: 0.1784 - val_acc: 0.9124\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9121 - val_loss: 0.1801 - val_acc: 0.9122\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9144 - val_loss: 0.1791 - val_acc: 0.9103\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9128 - val_loss: 0.1792 - val_acc: 0.9128\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.17840 to 0.17824, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9139 - val_loss: 0.1782 - val_acc: 0.9130\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17824 to 0.17819, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9154 - val_loss: 0.1782 - val_acc: 0.9128\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.17819 to 0.17804, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9150 - val_loss: 0.1780 - val_acc: 0.9111\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9151 - val_loss: 0.1781 - val_acc: 0.9120\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17804 to 0.17801, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9139 - val_loss: 0.1780 - val_acc: 0.9107\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9142 - val_loss: 0.1780 - val_acc: 0.9124\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17801 to 0.17794, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9151 - val_loss: 0.1779 - val_acc: 0.9118\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9159 - val_loss: 0.1783 - val_acc: 0.9120\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.17794 to 0.17767, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9152 - val_loss: 0.1777 - val_acc: 0.9120\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9140 - val_loss: 0.1778 - val_acc: 0.9126\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9148 - val_loss: 0.1778 - val_acc: 0.9132\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17767 to 0.17745, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9138 - val_loss: 0.1775 - val_acc: 0.9130\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9134 - val_loss: 0.1775 - val_acc: 0.9118\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9149 - val_loss: 0.1775 - val_acc: 0.9124\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.17745 to 0.17717, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9159 - val_loss: 0.1772 - val_acc: 0.9136\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17717 to 0.17702, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9140 - val_loss: 0.1770 - val_acc: 0.9124\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9150 - val_loss: 0.1773 - val_acc: 0.9126\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9155 - val_loss: 0.1771 - val_acc: 0.9140\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17702 to 0.17682, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9150 - val_loss: 0.1768 - val_acc: 0.9120\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.17682 to 0.17652, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9170 - val_loss: 0.1765 - val_acc: 0.9136\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.17652 to 0.17651, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1765 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17651 to 0.17623, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9152 - val_loss: 0.1762 - val_acc: 0.9138\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9172 - val_loss: 0.1765 - val_acc: 0.9145\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.17623 to 0.17619, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9159 - val_loss: 0.1762 - val_acc: 0.9140\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17619 to 0.17618, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9162 - val_loss: 0.1762 - val_acc: 0.9120\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9167 - val_loss: 0.1762 - val_acc: 0.9140\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9175 - val_loss: 0.1764 - val_acc: 0.9151\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9161 - val_loss: 0.1765 - val_acc: 0.9153\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9156 - val_loss: 0.1763 - val_acc: 0.9136\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17618 to 0.17564, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9154 - val_loss: 0.1756 - val_acc: 0.9132\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17564 to 0.17555, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9154 - val_loss: 0.1755 - val_acc: 0.9143\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17555 to 0.17533, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9160 - val_loss: 0.1753 - val_acc: 0.9143\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17533 to 0.17505, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9166 - val_loss: 0.1751 - val_acc: 0.9136\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17505 to 0.17494, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9175 - val_loss: 0.1749 - val_acc: 0.9145\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9177 - val_loss: 0.1755 - val_acc: 0.9130\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9174 - val_loss: 0.1752 - val_acc: 0.9153\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17494 to 0.17475, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9163 - val_loss: 0.1748 - val_acc: 0.9151\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17475 to 0.17470, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9177 - val_loss: 0.1747 - val_acc: 0.9145\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9170 - val_loss: 0.1751 - val_acc: 0.9147\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9165 - val_loss: 0.1751 - val_acc: 0.9155\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17470 to 0.17451, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9168 - val_loss: 0.1745 - val_acc: 0.9161\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17451 to 0.17431, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9162 - val_loss: 0.1743 - val_acc: 0.9145\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17431 to 0.17422, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9165 - val_loss: 0.1742 - val_acc: 0.9140\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9181 - val_loss: 0.1745 - val_acc: 0.9157\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17422 to 0.17399, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9180 - val_loss: 0.1740 - val_acc: 0.9149\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9183 - val_loss: 0.1743 - val_acc: 0.9163\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9170 - val_loss: 0.1746 - val_acc: 0.9151\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9169 - val_loss: 0.1743 - val_acc: 0.9147\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.17399 to 0.17382, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9178 - val_loss: 0.1738 - val_acc: 0.9163\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17382 to 0.17353, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9193 - val_loss: 0.1735 - val_acc: 0.9161\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9185 - val_loss: 0.1739 - val_acc: 0.9161\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "1s - loss: 0.1748 - acc: 0.9195 - val_loss: 0.1737 - val_acc: 0.9151\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17353 to 0.17350, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9185 - val_loss: 0.1735 - val_acc: 0.9147\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17350 to 0.17319, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9196 - val_loss: 0.1732 - val_acc: 0.9165\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.17319 to 0.17318, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9195 - val_loss: 0.1732 - val_acc: 0.9155\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9185 - val_loss: 0.1732 - val_acc: 0.9147\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9194 - val_loss: 0.1732 - val_acc: 0.9155\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9165 - val_loss: 0.1732 - val_acc: 0.9163\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9197 - val_loss: 0.1735 - val_acc: 0.9159\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17318 to 0.17301, saving model to best.model\n",
      "1s - loss: 0.1731 - acc: 0.9174 - val_loss: 0.1730 - val_acc: 0.9170\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17301 to 0.17278, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9197 - val_loss: 0.1728 - val_acc: 0.9153\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9194 - val_loss: 0.1729 - val_acc: 0.9153\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9182 - val_loss: 0.1728 - val_acc: 0.9172\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9180 - val_loss: 0.1734 - val_acc: 0.9163\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17278 to 0.17246, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9186 - val_loss: 0.1725 - val_acc: 0.9182\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17246 to 0.17240, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9198 - val_loss: 0.1724 - val_acc: 0.9165\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9206 - val_loss: 0.1724 - val_acc: 0.9186\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9192 - val_loss: 0.1724 - val_acc: 0.9180\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17240 to 0.17210, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9176 - val_loss: 0.1721 - val_acc: 0.9161\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17210 to 0.17209, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9188 - val_loss: 0.1721 - val_acc: 0.9153\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.17209 to 0.17178, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9205 - val_loss: 0.1718 - val_acc: 0.9178\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17178 to 0.17163, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9196 - val_loss: 0.1716 - val_acc: 0.9167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9201 - val_loss: 0.1716 - val_acc: 0.9180\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9199 - val_loss: 0.1717 - val_acc: 0.9159\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9198 - val_loss: 0.1717 - val_acc: 0.9182\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9207 - val_loss: 0.1719 - val_acc: 0.9180\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9172 - val_loss: 0.1719 - val_acc: 0.9182\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9188 - val_loss: 0.1717 - val_acc: 0.9163\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17163 to 0.17161, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9208 - val_loss: 0.1716 - val_acc: 0.9182\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17161 to 0.17133, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9200 - val_loss: 0.1713 - val_acc: 0.9182\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9193 - val_loss: 0.1716 - val_acc: 0.9182\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17133 to 0.17128, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9189 - val_loss: 0.1713 - val_acc: 0.9180\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9198 - val_loss: 0.1714 - val_acc: 0.9167\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9188 - val_loss: 0.1714 - val_acc: 0.9159\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17128 to 0.17126, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9202 - val_loss: 0.1713 - val_acc: 0.9168\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17126 to 0.17125, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9202 - val_loss: 0.1712 - val_acc: 0.9168\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17125 to 0.17098, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9212 - val_loss: 0.1710 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17098 to 0.17091, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9199 - val_loss: 0.1709 - val_acc: 0.9178\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.17091 to 0.17084, saving model to best.model\n",
      "0s - loss: 0.1691 - acc: 0.9198 - val_loss: 0.1708 - val_acc: 0.9170\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9207 - val_loss: 0.1712 - val_acc: 0.9184\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17084 to 0.17081, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9201 - val_loss: 0.1708 - val_acc: 0.9168\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9199 - val_loss: 0.1714 - val_acc: 0.9180\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17081 to 0.17064, saving model to best.model\n",
      "0s - loss: 0.1689 - acc: 0.9199 - val_loss: 0.1706 - val_acc: 0.9174\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9221 - val_loss: 0.1710 - val_acc: 0.9195\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17064 to 0.17052, saving model to best.model\n",
      "0s - loss: 0.1679 - acc: 0.9209 - val_loss: 0.1705 - val_acc: 0.9184\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17052 to 0.17046, saving model to best.model\n",
      "0s - loss: 0.1684 - acc: 0.9221 - val_loss: 0.1705 - val_acc: 0.9178\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17046 to 0.17035, saving model to best.model\n",
      "0s - loss: 0.1692 - acc: 0.9204 - val_loss: 0.1704 - val_acc: 0.9178\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9209 - val_loss: 0.1705 - val_acc: 0.9184\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9200 - val_loss: 0.1705 - val_acc: 0.9178\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9208 - val_loss: 0.1705 - val_acc: 0.9186\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17035 to 0.17012, saving model to best.model\n",
      "0s - loss: 0.1678 - acc: 0.9212 - val_loss: 0.1701 - val_acc: 0.9172\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9220 - val_loss: 0.1706 - val_acc: 0.9165\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9227 - val_loss: 0.1703 - val_acc: 0.9172\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9222 - val_loss: 0.1705 - val_acc: 0.9167\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9203 - val_loss: 0.1705 - val_acc: 0.9184\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9221 - val_loss: 0.1707 - val_acc: 0.9180\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9208 - val_loss: 0.1702 - val_acc: 0.9170\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9211 - val_loss: 0.1704 - val_acc: 0.9174\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9206 - val_loss: 0.1702 - val_acc: 0.9174\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9212 - val_loss: 0.1703 - val_acc: 0.9184\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9225 - val_loss: 0.1703 - val_acc: 0.9174\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9219 - val_loss: 0.1703 - val_acc: 0.9180\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17012 to 0.17003, saving model to best.model\n",
      "0s - loss: 0.1685 - acc: 0.9210 - val_loss: 0.1700 - val_acc: 0.9182\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1655 - acc: 0.9212 - val_loss: 0.1701 - val_acc: 0.9186\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17003 to 0.17001, saving model to best.model\n",
      "0s - loss: 0.1680 - acc: 0.9213 - val_loss: 0.1700 - val_acc: 0.9182\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9235 - val_loss: 0.1701 - val_acc: 0.9184\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17001 to 0.16964, saving model to best.model\n",
      "0s - loss: 0.1661 - acc: 0.9220 - val_loss: 0.1696 - val_acc: 0.9186\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.16964 to 0.16961, saving model to best.model\n",
      "0s - loss: 0.1669 - acc: 0.9214 - val_loss: 0.1696 - val_acc: 0.9172\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.16961 to 0.16943, saving model to best.model\n",
      "0s - loss: 0.1677 - acc: 0.9195 - val_loss: 0.1694 - val_acc: 0.9186\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9207 - val_loss: 0.1699 - val_acc: 0.9161\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9211 - val_loss: 0.1696 - val_acc: 0.9191\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9201 - val_loss: 0.1695 - val_acc: 0.9188\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.16943 to 0.16934, saving model to best.model\n",
      "0s - loss: 0.1642 - acc: 0.9222 - val_loss: 0.1693 - val_acc: 0.9182\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.16934 to 0.16927, saving model to best.model\n",
      "0s - loss: 0.1650 - acc: 0.9236 - val_loss: 0.1693 - val_acc: 0.9186\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.16927 to 0.16917, saving model to best.model\n",
      "0s - loss: 0.1659 - acc: 0.9214 - val_loss: 0.1692 - val_acc: 0.9188\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1661 - acc: 0.9211 - val_loss: 0.1694 - val_acc: 0.9180\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1652 - acc: 0.9233 - val_loss: 0.1696 - val_acc: 0.9186\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.16917 to 0.16891, saving model to best.model\n",
      "0s - loss: 0.1655 - acc: 0.9224 - val_loss: 0.1689 - val_acc: 0.9178\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9224 - val_loss: 0.1691 - val_acc: 0.9186\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1645 - acc: 0.9223 - val_loss: 0.1692 - val_acc: 0.9188\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1653 - acc: 0.9223 - val_loss: 0.1693 - val_acc: 0.9170\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1655 - acc: 0.9211 - val_loss: 0.1692 - val_acc: 0.9188\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9235 - val_loss: 0.1690 - val_acc: 0.9174\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9211 - val_loss: 0.1690 - val_acc: 0.9191\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1664 - acc: 0.9221 - val_loss: 0.1708 - val_acc: 0.9191\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9219 - val_loss: 0.1691 - val_acc: 0.9190\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.16891 to 0.16885, saving model to best.model\n",
      "0s - loss: 0.1645 - acc: 0.9225 - val_loss: 0.1689 - val_acc: 0.9193\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1642 - acc: 0.9216 - val_loss: 0.1690 - val_acc: 0.9174\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1642 - acc: 0.9242 - val_loss: 0.1696 - val_acc: 0.9190\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1625 - acc: 0.9220 - val_loss: 0.1695 - val_acc: 0.9182\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1644 - acc: 0.9230 - val_loss: 0.1689 - val_acc: 0.9188\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.16885 to 0.16875, saving model to best.model\n",
      "0s - loss: 0.1645 - acc: 0.9226 - val_loss: 0.1688 - val_acc: 0.9191\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1633 - acc: 0.9235 - val_loss: 0.1689 - val_acc: 0.9188\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1631 - acc: 0.9231 - val_loss: 0.1694 - val_acc: 0.9176\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34146, saving model to best.model\n",
      "0s - loss: 0.4289 - acc: 0.8620 - val_loss: 0.3415 - val_acc: 0.8853\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34146 to 0.27356, saving model to best.model\n",
      "0s - loss: 0.3486 - acc: 0.8812 - val_loss: 0.2736 - val_acc: 0.8853\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27356 to 0.22231, saving model to best.model\n",
      "0s - loss: 0.2733 - acc: 0.8910 - val_loss: 0.2223 - val_acc: 0.9001\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22231 to 0.20615, saving model to best.model\n",
      "0s - loss: 0.2344 - acc: 0.8974 - val_loss: 0.2061 - val_acc: 0.9067\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20615 to 0.20168, saving model to best.model\n",
      "0s - loss: 0.2257 - acc: 0.9024 - val_loss: 0.2017 - val_acc: 0.9059\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20168 to 0.20050, saving model to best.model\n",
      "0s - loss: 0.2179 - acc: 0.9025 - val_loss: 0.2005 - val_acc: 0.9055\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.20050 to 0.19944, saving model to best.model\n",
      "0s - loss: 0.2101 - acc: 0.9042 - val_loss: 0.1994 - val_acc: 0.9051\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2072 - acc: 0.9031 - val_loss: 0.1996 - val_acc: 0.9069\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19944 to 0.19895, saving model to best.model\n",
      "0s - loss: 0.2053 - acc: 0.9060 - val_loss: 0.1990 - val_acc: 0.9061\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19895 to 0.19880, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9075 - val_loss: 0.1988 - val_acc: 0.9063\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19880 to 0.19812, saving model to best.model\n",
      "0s - loss: 0.2018 - acc: 0.9072 - val_loss: 0.1981 - val_acc: 0.9070\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2012 - acc: 0.9047 - val_loss: 0.1990 - val_acc: 0.9063\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2006 - acc: 0.9072 - val_loss: 0.1992 - val_acc: 0.9072\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2006 - acc: 0.9072 - val_loss: 0.1987 - val_acc: 0.9082\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9069 - val_loss: 0.1983 - val_acc: 0.9082\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19812 to 0.19783, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9065 - val_loss: 0.1978 - val_acc: 0.9078\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19783 to 0.19764, saving model to best.model\n",
      "0s - loss: 0.1966 - acc: 0.9099 - val_loss: 0.1976 - val_acc: 0.9074\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1971 - acc: 0.9096 - val_loss: 0.1977 - val_acc: 0.9084\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9072 - val_loss: 0.1982 - val_acc: 0.9084\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9079 - val_loss: 0.1983 - val_acc: 0.9076\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19764 to 0.19736, saving model to best.model\n",
      "0s - loss: 0.1985 - acc: 0.9081 - val_loss: 0.1974 - val_acc: 0.9078\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9084 - val_loss: 0.1975 - val_acc: 0.9076\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1944 - acc: 0.9090 - val_loss: 0.1975 - val_acc: 0.9070\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19736 to 0.19707, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9097 - val_loss: 0.1971 - val_acc: 0.9082\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19707 to 0.19685, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9102 - val_loss: 0.1968 - val_acc: 0.9086\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9092 - val_loss: 0.1969 - val_acc: 0.9095\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9109 - val_loss: 0.1969 - val_acc: 0.9074\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9090 - val_loss: 0.1971 - val_acc: 0.9076\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19685 to 0.19638, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9102 - val_loss: 0.1964 - val_acc: 0.9080\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1950 - acc: 0.9089 - val_loss: 0.1970 - val_acc: 0.9070\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19638 to 0.19593, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9111 - val_loss: 0.1959 - val_acc: 0.9097\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9083 - val_loss: 0.1961 - val_acc: 0.9080\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19593 to 0.19517, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9088 - val_loss: 0.1952 - val_acc: 0.9099\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9087 - val_loss: 0.1956 - val_acc: 0.9094\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19517 to 0.19494, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9095 - val_loss: 0.1949 - val_acc: 0.9094\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19494 to 0.19476, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9094 - val_loss: 0.1948 - val_acc: 0.9099\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19476 to 0.19470, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9092 - val_loss: 0.1947 - val_acc: 0.9094\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1909 - acc: 0.9097 - val_loss: 0.1948 - val_acc: 0.9090\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19470 to 0.19407, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9113 - val_loss: 0.1941 - val_acc: 0.9094\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19407 to 0.19360, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9129 - val_loss: 0.1936 - val_acc: 0.9090\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9112 - val_loss: 0.1941 - val_acc: 0.9090\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9095 - val_loss: 0.1942 - val_acc: 0.9088\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19360 to 0.19336, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9109 - val_loss: 0.1934 - val_acc: 0.9092\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.19336 to 0.19306, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9129 - val_loss: 0.1931 - val_acc: 0.9097\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9106 - val_loss: 0.1936 - val_acc: 0.9090\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19306 to 0.19302, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9126 - val_loss: 0.1930 - val_acc: 0.9099\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.19302 to 0.19267, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9122 - val_loss: 0.1927 - val_acc: 0.9099\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9111 - val_loss: 0.1930 - val_acc: 0.9088\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19267 to 0.19264, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9101 - val_loss: 0.1926 - val_acc: 0.9101\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9104 - val_loss: 0.1936 - val_acc: 0.9090\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9116 - val_loss: 0.1932 - val_acc: 0.9088\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19264 to 0.19203, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9125 - val_loss: 0.1920 - val_acc: 0.9092\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9127 - val_loss: 0.1944 - val_acc: 0.9076\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9108 - val_loss: 0.1923 - val_acc: 0.9120\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.19203 to 0.19197, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9117 - val_loss: 0.1920 - val_acc: 0.9107\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.19197 to 0.19122, saving model to best.model\n",
      "0s - loss: 0.1869 - acc: 0.9123 - val_loss: 0.1912 - val_acc: 0.9103\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.19122 to 0.19119, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9114 - val_loss: 0.1912 - val_acc: 0.9097\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.19119 to 0.19114, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9117 - val_loss: 0.1911 - val_acc: 0.9109\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9140 - val_loss: 0.1913 - val_acc: 0.9105\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.19114 to 0.19089, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9124 - val_loss: 0.1909 - val_acc: 0.9122\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9111 - val_loss: 0.1911 - val_acc: 0.9097\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.19089 to 0.19037, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9126 - val_loss: 0.1904 - val_acc: 0.9111\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9140 - val_loss: 0.1911 - val_acc: 0.9095\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9131 - val_loss: 0.1904 - val_acc: 0.9099\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.19037 to 0.18996, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9121 - val_loss: 0.1900 - val_acc: 0.9109\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9112 - val_loss: 0.1907 - val_acc: 0.9103\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9148 - val_loss: 0.1905 - val_acc: 0.9099\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18996 to 0.18922, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9133 - val_loss: 0.1892 - val_acc: 0.9113\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9150 - val_loss: 0.1899 - val_acc: 0.9115\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9133 - val_loss: 0.1915 - val_acc: 0.9103\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18922 to 0.18917, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9137 - val_loss: 0.1892 - val_acc: 0.9117\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9131 - val_loss: 0.1903 - val_acc: 0.9111\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18917 to 0.18888, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9139 - val_loss: 0.1889 - val_acc: 0.9120\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9108 - val_loss: 0.1901 - val_acc: 0.9111\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9135 - val_loss: 0.1899 - val_acc: 0.9115\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18888 to 0.18855, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9143 - val_loss: 0.1885 - val_acc: 0.9118\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9118 - val_loss: 0.1893 - val_acc: 0.9117\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9134 - val_loss: 0.1892 - val_acc: 0.9113\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18855 to 0.18832, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9134 - val_loss: 0.1883 - val_acc: 0.9117\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9127 - val_loss: 0.1887 - val_acc: 0.9109\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9145 - val_loss: 0.1885 - val_acc: 0.9113\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18832 to 0.18818, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9138 - val_loss: 0.1882 - val_acc: 0.9126\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.18818 to 0.18775, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9152 - val_loss: 0.1878 - val_acc: 0.9132\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9136 - val_loss: 0.1882 - val_acc: 0.9117\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.18775 to 0.18775, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9128 - val_loss: 0.1878 - val_acc: 0.9128\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9129 - val_loss: 0.1884 - val_acc: 0.9105\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18775 to 0.18740, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9143 - val_loss: 0.1874 - val_acc: 0.9126\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9138 - val_loss: 0.1876 - val_acc: 0.9117\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9142 - val_loss: 0.1878 - val_acc: 0.9130\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9128 - val_loss: 0.1884 - val_acc: 0.9103\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9146 - val_loss: 0.1879 - val_acc: 0.9115\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9124 - val_loss: 0.1874 - val_acc: 0.9130\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18740 to 0.18690, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9161 - val_loss: 0.1869 - val_acc: 0.9128\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9140 - val_loss: 0.1878 - val_acc: 0.9111\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9149 - val_loss: 0.1873 - val_acc: 0.9124\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9152 - val_loss: 0.1869 - val_acc: 0.9130\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9158 - val_loss: 0.1869 - val_acc: 0.9124\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18690 to 0.18680, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9145 - val_loss: 0.1868 - val_acc: 0.9138\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.18680 to 0.18677, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9133 - val_loss: 0.1868 - val_acc: 0.9140\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9145 - val_loss: 0.1869 - val_acc: 0.9134\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9156 - val_loss: 0.1870 - val_acc: 0.9134\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9150 - val_loss: 0.1873 - val_acc: 0.9113\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18677 to 0.18658, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9146 - val_loss: 0.1866 - val_acc: 0.9132\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9148 - val_loss: 0.1869 - val_acc: 0.9094\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.18658 to 0.18618, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9140 - val_loss: 0.1862 - val_acc: 0.9130\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18618 to 0.18588, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9155 - val_loss: 0.1859 - val_acc: 0.9140\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9154 - val_loss: 0.1868 - val_acc: 0.9115\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9153 - val_loss: 0.1864 - val_acc: 0.9130\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9165 - val_loss: 0.1860 - val_acc: 0.9134\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9155 - val_loss: 0.1860 - val_acc: 0.9103\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9159 - val_loss: 0.1859 - val_acc: 0.9095\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.18588 to 0.18573, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9158 - val_loss: 0.1857 - val_acc: 0.9134\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9156 - val_loss: 0.1866 - val_acc: 0.9118\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9146 - val_loss: 0.1863 - val_acc: 0.9101\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.18573 to 0.18534, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9166 - val_loss: 0.1853 - val_acc: 0.9145\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1859 - val_acc: 0.9113\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9153 - val_loss: 0.1860 - val_acc: 0.9111\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9145 - val_loss: 0.1868 - val_acc: 0.9115\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9150 - val_loss: 0.1866 - val_acc: 0.9094\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9154 - val_loss: 0.1856 - val_acc: 0.9120\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9184 - val_loss: 0.1856 - val_acc: 0.9120\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.18534 to 0.18512, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9171 - val_loss: 0.1851 - val_acc: 0.9126\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9158 - val_loss: 0.1858 - val_acc: 0.9107\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.18512 to 0.18501, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9159 - val_loss: 0.1850 - val_acc: 0.9122\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9178 - val_loss: 0.1851 - val_acc: 0.9113\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9168 - val_loss: 0.1852 - val_acc: 0.9115\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18501 to 0.18501, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9151 - val_loss: 0.1850 - val_acc: 0.9132\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9180 - val_loss: 0.1854 - val_acc: 0.9109\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9163 - val_loss: 0.1853 - val_acc: 0.9115\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.18501 to 0.18463, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9169 - val_loss: 0.1846 - val_acc: 0.9107\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9173 - val_loss: 0.1848 - val_acc: 0.9128\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9158 - val_loss: 0.1848 - val_acc: 0.9094\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.18463 to 0.18442, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9167 - val_loss: 0.1844 - val_acc: 0.9115\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9180 - val_loss: 0.1849 - val_acc: 0.9132\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.18442 to 0.18411, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9169 - val_loss: 0.1841 - val_acc: 0.9111\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9171 - val_loss: 0.1848 - val_acc: 0.9094\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9175 - val_loss: 0.1857 - val_acc: 0.9101\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9170 - val_loss: 0.1849 - val_acc: 0.9103\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.18411 to 0.18383, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9165 - val_loss: 0.1838 - val_acc: 0.9130\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9161 - val_loss: 0.1847 - val_acc: 0.9107\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9178 - val_loss: 0.1847 - val_acc: 0.9097\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9178 - val_loss: 0.1849 - val_acc: 0.9107\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.18383 to 0.18380, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9154 - val_loss: 0.1838 - val_acc: 0.9128\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9164 - val_loss: 0.1844 - val_acc: 0.9109\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9177 - val_loss: 0.1844 - val_acc: 0.9103\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9175 - val_loss: 0.1849 - val_acc: 0.9111\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18380 to 0.18327, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9149 - val_loss: 0.1833 - val_acc: 0.9134\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9168 - val_loss: 0.1834 - val_acc: 0.9128\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9168 - val_loss: 0.1843 - val_acc: 0.9099\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9183 - val_loss: 0.1837 - val_acc: 0.9103\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9151 - val_loss: 0.1849 - val_acc: 0.9130\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9157 - val_loss: 0.1849 - val_acc: 0.9122\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9166 - val_loss: 0.1844 - val_acc: 0.9101\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9189 - val_loss: 0.1837 - val_acc: 0.9095\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9185 - val_loss: 0.1839 - val_acc: 0.9107\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9171 - val_loss: 0.1838 - val_acc: 0.9115\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9172 - val_loss: 0.1840 - val_acc: 0.9111\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9169 - val_loss: 0.1840 - val_acc: 0.9118\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9168 - val_loss: 0.1836 - val_acc: 0.9115\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9176 - val_loss: 0.1843 - val_acc: 0.9105\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9181 - val_loss: 0.1837 - val_acc: 0.9101\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9161 - val_loss: 0.1841 - val_acc: 0.9109\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9164 - val_loss: 0.1836 - val_acc: 0.9109\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9172 - val_loss: 0.1838 - val_acc: 0.9086\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9176 - val_loss: 0.1835 - val_acc: 0.9107\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9178 - val_loss: 0.1836 - val_acc: 0.9142\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9190 - val_loss: 0.1844 - val_acc: 0.9117\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9191 - val_loss: 0.1838 - val_acc: 0.9122\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9171 - val_loss: 0.1841 - val_acc: 0.9090\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9180 - val_loss: 0.1835 - val_acc: 0.9115\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9175 - val_loss: 0.1834 - val_acc: 0.9105\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9187 - val_loss: 0.1835 - val_acc: 0.9105\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9191 - val_loss: 0.1835 - val_acc: 0.9107\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32318, saving model to best.model\n",
      "0s - loss: 0.4510 - acc: 0.8478 - val_loss: 0.3232 - val_acc: 0.8940\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32318 to 0.26646, saving model to best.model\n",
      "0s - loss: 0.3506 - acc: 0.8824 - val_loss: 0.2665 - val_acc: 0.8940\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26646 to 0.21782, saving model to best.model\n",
      "0s - loss: 0.2863 - acc: 0.8905 - val_loss: 0.2178 - val_acc: 0.9067\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21782 to 0.19413, saving model to best.model\n",
      "0s - loss: 0.2453 - acc: 0.8976 - val_loss: 0.1941 - val_acc: 0.9095\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19413 to 0.18745, saving model to best.model\n",
      "0s - loss: 0.2236 - acc: 0.9025 - val_loss: 0.1874 - val_acc: 0.9128\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18745 to 0.18477, saving model to best.model\n",
      "0s - loss: 0.2173 - acc: 0.9054 - val_loss: 0.1848 - val_acc: 0.9155\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18477 to 0.18340, saving model to best.model\n",
      "0s - loss: 0.2133 - acc: 0.9041 - val_loss: 0.1834 - val_acc: 0.9155\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18340 to 0.18300, saving model to best.model\n",
      "0s - loss: 0.2109 - acc: 0.9029 - val_loss: 0.1830 - val_acc: 0.9149\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18300 to 0.18248, saving model to best.model\n",
      "0s - loss: 0.2068 - acc: 0.9043 - val_loss: 0.1825 - val_acc: 0.9132\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18248 to 0.18216, saving model to best.model\n",
      "0s - loss: 0.2063 - acc: 0.9030 - val_loss: 0.1822 - val_acc: 0.9134\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18216 to 0.18206, saving model to best.model\n",
      "0s - loss: 0.2030 - acc: 0.9057 - val_loss: 0.1821 - val_acc: 0.9147\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18206 to 0.18185, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9041 - val_loss: 0.1818 - val_acc: 0.9147\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18185 to 0.18173, saving model to best.model\n",
      "0s - loss: 0.2010 - acc: 0.9075 - val_loss: 0.1817 - val_acc: 0.9155\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2014 - acc: 0.9057 - val_loss: 0.1821 - val_acc: 0.9147\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2006 - acc: 0.9072 - val_loss: 0.1820 - val_acc: 0.9134\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.18173 to 0.18163, saving model to best.model\n",
      "0s - loss: 0.1986 - acc: 0.9064 - val_loss: 0.1816 - val_acc: 0.9136\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9059 - val_loss: 0.1824 - val_acc: 0.9142\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18163 to 0.18152, saving model to best.model\n",
      "0s - loss: 0.1986 - acc: 0.9059 - val_loss: 0.1815 - val_acc: 0.9149\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9086 - val_loss: 0.1815 - val_acc: 0.9143\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1973 - acc: 0.9077 - val_loss: 0.1819 - val_acc: 0.9149\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18152 to 0.18112, saving model to best.model\n",
      "0s - loss: 0.1968 - acc: 0.9080 - val_loss: 0.1811 - val_acc: 0.9140\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9078 - val_loss: 0.1812 - val_acc: 0.9159\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9094 - val_loss: 0.1826 - val_acc: 0.9142\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18112 to 0.18085, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9085 - val_loss: 0.1809 - val_acc: 0.9142\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18085 to 0.18065, saving model to best.model\n",
      "0s - loss: 0.1963 - acc: 0.9084 - val_loss: 0.1806 - val_acc: 0.9142\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9097 - val_loss: 0.1811 - val_acc: 0.9159\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9094 - val_loss: 0.1808 - val_acc: 0.9157\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18065 to 0.18027, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9096 - val_loss: 0.1803 - val_acc: 0.9153\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9079 - val_loss: 0.1810 - val_acc: 0.9153\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18027 to 0.18001, saving model to best.model\n",
      "0s - loss: 0.1959 - acc: 0.9078 - val_loss: 0.1800 - val_acc: 0.9138\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18001 to 0.17977, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9102 - val_loss: 0.1798 - val_acc: 0.9147\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.17977 to 0.17976, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9107 - val_loss: 0.1798 - val_acc: 0.9157\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9104 - val_loss: 0.1802 - val_acc: 0.9167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9105 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1909 - acc: 0.9109 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17976 to 0.17957, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9098 - val_loss: 0.1796 - val_acc: 0.9159\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17957 to 0.17931, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9118 - val_loss: 0.1793 - val_acc: 0.9145\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17931 to 0.17918, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9103 - val_loss: 0.1792 - val_acc: 0.9147\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9096 - val_loss: 0.1801 - val_acc: 0.9151\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9114 - val_loss: 0.1793 - val_acc: 0.9161\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17918 to 0.17878, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9107 - val_loss: 0.1788 - val_acc: 0.9142\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9129 - val_loss: 0.1788 - val_acc: 0.9143\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9118 - val_loss: 0.1792 - val_acc: 0.9161\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9111 - val_loss: 0.1790 - val_acc: 0.9155\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.17878 to 0.17840, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9123 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17840 to 0.17822, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9119 - val_loss: 0.1782 - val_acc: 0.9143\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.17822 to 0.17804, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9113 - val_loss: 0.1780 - val_acc: 0.9138\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9115 - val_loss: 0.1783 - val_acc: 0.9157\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9126 - val_loss: 0.1782 - val_acc: 0.9163\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17804 to 0.17786, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9126 - val_loss: 0.1779 - val_acc: 0.9159\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9112 - val_loss: 0.1780 - val_acc: 0.9170\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.17786 to 0.17768, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9112 - val_loss: 0.1777 - val_acc: 0.9149\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17768 to 0.17758, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9130 - val_loss: 0.1776 - val_acc: 0.9147\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9111 - val_loss: 0.1781 - val_acc: 0.9163\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9134 - val_loss: 0.1776 - val_acc: 0.9153\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.17758 to 0.17735, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9127 - val_loss: 0.1774 - val_acc: 0.9151\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9124 - val_loss: 0.1778 - val_acc: 0.9168\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9120 - val_loss: 0.1778 - val_acc: 0.9165\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9126 - val_loss: 0.1776 - val_acc: 0.9145\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9131 - val_loss: 0.1774 - val_acc: 0.9145\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17735 to 0.17721, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9122 - val_loss: 0.1772 - val_acc: 0.9165\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17721 to 0.17712, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9132 - val_loss: 0.1771 - val_acc: 0.9143\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9139 - val_loss: 0.1773 - val_acc: 0.9161\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9123 - val_loss: 0.1772 - val_acc: 0.9151\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.17712 to 0.17699, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9125 - val_loss: 0.1770 - val_acc: 0.9142\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.17699 to 0.17696, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9145 - val_loss: 0.1770 - val_acc: 0.9155\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9135 - val_loss: 0.1772 - val_acc: 0.9163\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17696 to 0.17688, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9132 - val_loss: 0.1769 - val_acc: 0.9161\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9137 - val_loss: 0.1770 - val_acc: 0.9161\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9151 - val_loss: 0.1769 - val_acc: 0.9159\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9140 - val_loss: 0.1770 - val_acc: 0.9163\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17688 to 0.17645, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9144 - val_loss: 0.1764 - val_acc: 0.9143\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9133 - val_loss: 0.1770 - val_acc: 0.9153\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9146 - val_loss: 0.1769 - val_acc: 0.9149\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9147 - val_loss: 0.1769 - val_acc: 0.9161\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9142 - val_loss: 0.1782 - val_acc: 0.9155\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.17645 to 0.17637, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9120 - val_loss: 0.1764 - val_acc: 0.9159\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17637 to 0.17619, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9150 - val_loss: 0.1762 - val_acc: 0.9155\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9141 - val_loss: 0.1762 - val_acc: 0.9155\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9163 - val_loss: 0.1792 - val_acc: 0.9147\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9148 - val_loss: 0.1770 - val_acc: 0.9163\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9137 - val_loss: 0.1763 - val_acc: 0.9145\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.17619 to 0.17600, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9139 - val_loss: 0.1760 - val_acc: 0.9153\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17600 to 0.17596, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9156 - val_loss: 0.1760 - val_acc: 0.9145\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9151 - val_loss: 0.1764 - val_acc: 0.9153\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9147 - val_loss: 0.1762 - val_acc: 0.9170\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9151 - val_loss: 0.1761 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17596 to 0.17592, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9147 - val_loss: 0.1759 - val_acc: 0.9143\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9158 - val_loss: 0.1761 - val_acc: 0.9165\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17592 to 0.17581, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9160 - val_loss: 0.1758 - val_acc: 0.9163\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9153 - val_loss: 0.1766 - val_acc: 0.9155\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17581 to 0.17578, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9159 - val_loss: 0.1758 - val_acc: 0.9157\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9141 - val_loss: 0.1765 - val_acc: 0.9172\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9159 - val_loss: 0.1760 - val_acc: 0.9165\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9164 - val_loss: 0.1761 - val_acc: 0.9165\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17578 to 0.17536, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9155 - val_loss: 0.1754 - val_acc: 0.9153\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9142 - val_loss: 0.1764 - val_acc: 0.9172\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9146 - val_loss: 0.1756 - val_acc: 0.9153\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9154 - val_loss: 0.1766 - val_acc: 0.9161\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17536 to 0.17502, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9170 - val_loss: 0.1750 - val_acc: 0.9161\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9159 - val_loss: 0.1755 - val_acc: 0.9168\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9167 - val_loss: 0.1762 - val_acc: 0.9161\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9154 - val_loss: 0.1760 - val_acc: 0.9165\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9152 - val_loss: 0.1753 - val_acc: 0.9155\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9168 - val_loss: 0.1752 - val_acc: 0.9151\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9167 - val_loss: 0.1762 - val_acc: 0.9165\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9159 - val_loss: 0.1758 - val_acc: 0.9161\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9166 - val_loss: 0.1755 - val_acc: 0.9157\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9165 - val_loss: 0.1758 - val_acc: 0.9172\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17502 to 0.17492, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9160 - val_loss: 0.1749 - val_acc: 0.9165\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9170 - val_loss: 0.1764 - val_acc: 0.9167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9156 - val_loss: 0.1756 - val_acc: 0.9155\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9164 - val_loss: 0.1764 - val_acc: 0.9165\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9166 - val_loss: 0.1752 - val_acc: 0.9159\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9172 - val_loss: 0.1757 - val_acc: 0.9153\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17492 to 0.17487, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9162 - val_loss: 0.1749 - val_acc: 0.9157\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9178 - val_loss: 0.1753 - val_acc: 0.9163\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9174 - val_loss: 0.1753 - val_acc: 0.9161\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17487 to 0.17483, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9171 - val_loss: 0.1748 - val_acc: 0.9167\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9153 - val_loss: 0.1759 - val_acc: 0.9153\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17483 to 0.17482, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9167 - val_loss: 0.1748 - val_acc: 0.9147\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9175 - val_loss: 0.1755 - val_acc: 0.9165\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9167 - val_loss: 0.1753 - val_acc: 0.9165\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9180 - val_loss: 0.1749 - val_acc: 0.9155\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9188 - val_loss: 0.1748 - val_acc: 0.9157\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9167 - val_loss: 0.1749 - val_acc: 0.9163\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9167 - val_loss: 0.1756 - val_acc: 0.9168\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9188 - val_loss: 0.1749 - val_acc: 0.9163\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17482 to 0.17456, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9185 - val_loss: 0.1746 - val_acc: 0.9163\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9162 - val_loss: 0.1747 - val_acc: 0.9167\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17456 to 0.17444, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9184 - val_loss: 0.1744 - val_acc: 0.9165\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9178 - val_loss: 0.1749 - val_acc: 0.9165\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9164 - val_loss: 0.1753 - val_acc: 0.9157\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9169 - val_loss: 0.1752 - val_acc: 0.9163\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17444 to 0.17391, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9175 - val_loss: 0.1739 - val_acc: 0.9165\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9167 - val_loss: 0.1750 - val_acc: 0.9165\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9160 - val_loss: 0.1746 - val_acc: 0.9159\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9178 - val_loss: 0.1748 - val_acc: 0.9161\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9174 - val_loss: 0.1745 - val_acc: 0.9157\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9168 - val_loss: 0.1753 - val_acc: 0.9163\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9174 - val_loss: 0.1742 - val_acc: 0.9163\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9190 - val_loss: 0.1750 - val_acc: 0.9159\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9178 - val_loss: 0.1744 - val_acc: 0.9159\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9163 - val_loss: 0.1745 - val_acc: 0.9161\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9179 - val_loss: 0.1749 - val_acc: 0.9161\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9191 - val_loss: 0.1739 - val_acc: 0.9167\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9168 - val_loss: 0.1742 - val_acc: 0.9168\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9179 - val_loss: 0.1745 - val_acc: 0.9172\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9184 - val_loss: 0.1764 - val_acc: 0.9161\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17391 to 0.17380, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9192 - val_loss: 0.1738 - val_acc: 0.9165\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17380 to 0.17354, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9181 - val_loss: 0.1735 - val_acc: 0.9167\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9174 - val_loss: 0.1746 - val_acc: 0.9157\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9186 - val_loss: 0.1744 - val_acc: 0.9161\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9169 - val_loss: 0.1736 - val_acc: 0.9159\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9175 - val_loss: 0.1742 - val_acc: 0.9163\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9190 - val_loss: 0.1740 - val_acc: 0.9161\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9188 - val_loss: 0.1743 - val_acc: 0.9165\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9187 - val_loss: 0.1750 - val_acc: 0.9168\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9178 - val_loss: 0.1747 - val_acc: 0.9157\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9192 - val_loss: 0.1740 - val_acc: 0.9170\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9195 - val_loss: 0.1738 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9176 - val_loss: 0.1741 - val_acc: 0.9151\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9195 - val_loss: 0.1753 - val_acc: 0.9155\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9191 - val_loss: 0.1736 - val_acc: 0.9167\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17354 to 0.17344, saving model to best.model\n",
      "0s - loss: 0.1730 - acc: 0.9209 - val_loss: 0.1734 - val_acc: 0.9165\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9183 - val_loss: 0.1746 - val_acc: 0.9165\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9193 - val_loss: 0.1742 - val_acc: 0.9153\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.17344 to 0.17344, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9201 - val_loss: 0.1734 - val_acc: 0.9165\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9194 - val_loss: 0.1739 - val_acc: 0.9149\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9197 - val_loss: 0.1736 - val_acc: 0.9155\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9183 - val_loss: 0.1738 - val_acc: 0.9168\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9187 - val_loss: 0.1746 - val_acc: 0.9165\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9196 - val_loss: 0.1740 - val_acc: 0.9159\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9190 - val_loss: 0.1740 - val_acc: 0.9163\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9198 - val_loss: 0.1739 - val_acc: 0.9161\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9201 - val_loss: 0.1739 - val_acc: 0.9163\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9206 - val_loss: 0.1744 - val_acc: 0.9157\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9186 - val_loss: 0.1739 - val_acc: 0.9157\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9182 - val_loss: 0.1743 - val_acc: 0.9157\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.17344 to 0.17341, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9199 - val_loss: 0.1734 - val_acc: 0.9168\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9208 - val_loss: 0.1737 - val_acc: 0.9167\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9208 - val_loss: 0.1740 - val_acc: 0.9157\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17341 to 0.17294, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9194 - val_loss: 0.1729 - val_acc: 0.9168\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9217 - val_loss: 0.1736 - val_acc: 0.9157\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9191 - val_loss: 0.1733 - val_acc: 0.9163\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.17294 to 0.17292, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9197 - val_loss: 0.1729 - val_acc: 0.9168\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9201 - val_loss: 0.1731 - val_acc: 0.9161\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9192 - val_loss: 0.1732 - val_acc: 0.9159\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9210 - val_loss: 0.1737 - val_acc: 0.9157\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9201 - val_loss: 0.1731 - val_acc: 0.9153\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9203 - val_loss: 0.1746 - val_acc: 0.9157\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9200 - val_loss: 0.1731 - val_acc: 0.9155\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.17292 to 0.17279, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9191 - val_loss: 0.1728 - val_acc: 0.9163\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9194 - val_loss: 0.1740 - val_acc: 0.9161\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9204 - val_loss: 0.1733 - val_acc: 0.9167\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9209 - val_loss: 0.1736 - val_acc: 0.9168\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9208 - val_loss: 0.1729 - val_acc: 0.9155\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9199 - val_loss: 0.1735 - val_acc: 0.9157\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9215 - val_loss: 0.1743 - val_acc: 0.9167\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9197 - val_loss: 0.1738 - val_acc: 0.9168\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33821, saving model to best.model\n",
      "0s - loss: 0.3963 - acc: 0.8763 - val_loss: 0.3382 - val_acc: 0.8884\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33821 to 0.25419, saving model to best.model\n",
      "0s - loss: 0.3198 - acc: 0.8914 - val_loss: 0.2542 - val_acc: 0.8967\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25419 to 0.21142, saving model to best.model\n",
      "0s - loss: 0.2551 - acc: 0.8978 - val_loss: 0.2114 - val_acc: 0.9065\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21142 to 0.19820, saving model to best.model\n",
      "0s - loss: 0.2237 - acc: 0.9044 - val_loss: 0.1982 - val_acc: 0.9113\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19820 to 0.19367, saving model to best.model\n",
      "0s - loss: 0.2115 - acc: 0.9049 - val_loss: 0.1937 - val_acc: 0.9113\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19367 to 0.19234, saving model to best.model\n",
      "0s - loss: 0.2057 - acc: 0.9079 - val_loss: 0.1923 - val_acc: 0.9117\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19234 to 0.19060, saving model to best.model\n",
      "0s - loss: 0.2029 - acc: 0.9081 - val_loss: 0.1906 - val_acc: 0.9130\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.1996 - acc: 0.9082 - val_loss: 0.1915 - val_acc: 0.9124\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19060 to 0.18912, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9094 - val_loss: 0.1891 - val_acc: 0.9120\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18912 to 0.18814, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9112 - val_loss: 0.1881 - val_acc: 0.9113\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9114 - val_loss: 0.1929 - val_acc: 0.9128\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9115 - val_loss: 0.1908 - val_acc: 0.9128\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18814 to 0.18746, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9118 - val_loss: 0.1875 - val_acc: 0.9132\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18746 to 0.18721, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9112 - val_loss: 0.1872 - val_acc: 0.9120\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9106 - val_loss: 0.1877 - val_acc: 0.9117\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.18721 to 0.18694, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9126 - val_loss: 0.1869 - val_acc: 0.9132\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9116 - val_loss: 0.1875 - val_acc: 0.9122\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1904 - acc: 0.9116 - val_loss: 0.1872 - val_acc: 0.9134\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18694 to 0.18661, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9128 - val_loss: 0.1866 - val_acc: 0.9136\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9136 - val_loss: 0.1871 - val_acc: 0.9118\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9122 - val_loss: 0.1885 - val_acc: 0.9122\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9121 - val_loss: 0.1892 - val_acc: 0.9136\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9121 - val_loss: 0.1880 - val_acc: 0.9140\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18661 to 0.18618, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9138 - val_loss: 0.1862 - val_acc: 0.9130\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9135 - val_loss: 0.1864 - val_acc: 0.9134\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18618 to 0.18598, saving model to best.model\n",
      "0s - loss: 0.1889 - acc: 0.9139 - val_loss: 0.1860 - val_acc: 0.9143\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9141 - val_loss: 0.1878 - val_acc: 0.9142\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9138 - val_loss: 0.1866 - val_acc: 0.9134\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18598 to 0.18542, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9145 - val_loss: 0.1854 - val_acc: 0.9151\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9143 - val_loss: 0.1873 - val_acc: 0.9132\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18542 to 0.18509, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9135 - val_loss: 0.1851 - val_acc: 0.9128\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18509 to 0.18499, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9140 - val_loss: 0.1850 - val_acc: 0.9155\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18499 to 0.18486, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9137 - val_loss: 0.1849 - val_acc: 0.9143\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9146 - val_loss: 0.1855 - val_acc: 0.9143\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9132 - val_loss: 0.1865 - val_acc: 0.9151\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9153 - val_loss: 0.1862 - val_acc: 0.9151\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9144 - val_loss: 0.1858 - val_acc: 0.9151\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18486 to 0.18451, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9155 - val_loss: 0.1845 - val_acc: 0.9149\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9146 - val_loss: 0.1847 - val_acc: 0.9153\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9162 - val_loss: 0.1848 - val_acc: 0.9147\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9155 - val_loss: 0.1848 - val_acc: 0.9168\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9160 - val_loss: 0.1866 - val_acc: 0.9167\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9165 - val_loss: 0.1856 - val_acc: 0.9176\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18451 to 0.18370, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9141 - val_loss: 0.1837 - val_acc: 0.9168\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9152 - val_loss: 0.1853 - val_acc: 0.9161\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9167 - val_loss: 0.1839 - val_acc: 0.9182\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18370 to 0.18368, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9158 - val_loss: 0.1837 - val_acc: 0.9167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9156 - val_loss: 0.1845 - val_acc: 0.9184\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18368 to 0.18296, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9165 - val_loss: 0.1830 - val_acc: 0.9184\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9152 - val_loss: 0.1833 - val_acc: 0.9172\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9171 - val_loss: 0.1830 - val_acc: 0.9180\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9183 - val_loss: 0.1830 - val_acc: 0.9170\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9163 - val_loss: 0.1831 - val_acc: 0.9188\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18296 to 0.18243, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9168 - val_loss: 0.1824 - val_acc: 0.9184\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9179 - val_loss: 0.1827 - val_acc: 0.9182\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18243 to 0.18237, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9178 - val_loss: 0.1824 - val_acc: 0.9184\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18237 to 0.18211, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9168 - val_loss: 0.1821 - val_acc: 0.9184\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9179 - val_loss: 0.1827 - val_acc: 0.9180\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9178 - val_loss: 0.1822 - val_acc: 0.9191\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9163 - val_loss: 0.1821 - val_acc: 0.9182\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18211 to 0.18180, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9174 - val_loss: 0.1818 - val_acc: 0.9188\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9195 - val_loss: 0.1820 - val_acc: 0.9186\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9169 - val_loss: 0.1820 - val_acc: 0.9180\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9163 - val_loss: 0.1840 - val_acc: 0.9195\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9180 - val_loss: 0.1829 - val_acc: 0.9193\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9184 - val_loss: 0.1819 - val_acc: 0.9191\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18180 to 0.18117, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9187 - val_loss: 0.1812 - val_acc: 0.9180\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9188 - val_loss: 0.1817 - val_acc: 0.9191\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18117 to 0.18103, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9188 - val_loss: 0.1810 - val_acc: 0.9191\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9193 - val_loss: 0.1822 - val_acc: 0.9182\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18103 to 0.18098, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9185 - val_loss: 0.1810 - val_acc: 0.9195\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18098 to 0.18075, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9168 - val_loss: 0.1808 - val_acc: 0.9197\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18075 to 0.18049, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9201 - val_loss: 0.1805 - val_acc: 0.9186\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9197 - val_loss: 0.1805 - val_acc: 0.9191\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18049 to 0.18015, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9187 - val_loss: 0.1801 - val_acc: 0.9191\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9192 - val_loss: 0.1815 - val_acc: 0.9195\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18015 to 0.17992, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9188 - val_loss: 0.1799 - val_acc: 0.9190\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9199 - val_loss: 0.1807 - val_acc: 0.9201\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9175 - val_loss: 0.1799 - val_acc: 0.9190\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.17992 to 0.17987, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9181 - val_loss: 0.1799 - val_acc: 0.9193\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9180 - val_loss: 0.1804 - val_acc: 0.9195\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9182 - val_loss: 0.1809 - val_acc: 0.9193\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9203 - val_loss: 0.1802 - val_acc: 0.9197\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9189 - val_loss: 0.1817 - val_acc: 0.9191\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9213 - val_loss: 0.1803 - val_acc: 0.9191\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17987 to 0.17926, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9203 - val_loss: 0.1793 - val_acc: 0.9203\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9201 - val_loss: 0.1798 - val_acc: 0.9197\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9194 - val_loss: 0.1804 - val_acc: 0.9190\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17926 to 0.17883, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9201 - val_loss: 0.1788 - val_acc: 0.9205\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9203 - val_loss: 0.1792 - val_acc: 0.9197\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9204 - val_loss: 0.1797 - val_acc: 0.9199\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9201 - val_loss: 0.1791 - val_acc: 0.9201\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9205 - val_loss: 0.1794 - val_acc: 0.9195\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9191 - val_loss: 0.1791 - val_acc: 0.9199\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17883 to 0.17881, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9204 - val_loss: 0.1788 - val_acc: 0.9197\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9217 - val_loss: 0.1799 - val_acc: 0.9186\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17881 to 0.17864, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9202 - val_loss: 0.1786 - val_acc: 0.9191\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9210 - val_loss: 0.1796 - val_acc: 0.9195\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17864 to 0.17844, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9215 - val_loss: 0.1784 - val_acc: 0.9193\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9194 - val_loss: 0.1790 - val_acc: 0.9190\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9199 - val_loss: 0.1786 - val_acc: 0.9188\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9201 - val_loss: 0.1792 - val_acc: 0.9191\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9216 - val_loss: 0.1793 - val_acc: 0.9190\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17844 to 0.17828, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9209 - val_loss: 0.1783 - val_acc: 0.9186\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9199 - val_loss: 0.1787 - val_acc: 0.9188\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9202 - val_loss: 0.1787 - val_acc: 0.9193\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17828 to 0.17809, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9215 - val_loss: 0.1781 - val_acc: 0.9190\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9219 - val_loss: 0.1802 - val_acc: 0.9186\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9193 - val_loss: 0.1788 - val_acc: 0.9193\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17809 to 0.17776, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9211 - val_loss: 0.1778 - val_acc: 0.9201\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9210 - val_loss: 0.1781 - val_acc: 0.9188\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9198 - val_loss: 0.1784 - val_acc: 0.9190\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17776 to 0.17744, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9216 - val_loss: 0.1774 - val_acc: 0.9193\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9219 - val_loss: 0.1780 - val_acc: 0.9197\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9221 - val_loss: 0.1779 - val_acc: 0.9201\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9228 - val_loss: 0.1785 - val_acc: 0.9188\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9208 - val_loss: 0.1797 - val_acc: 0.9186\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9219 - val_loss: 0.1779 - val_acc: 0.9193\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9226 - val_loss: 0.1784 - val_acc: 0.9201\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9226 - val_loss: 0.1793 - val_acc: 0.9190\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9213 - val_loss: 0.1778 - val_acc: 0.9193\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17744 to 0.17739, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9229 - val_loss: 0.1774 - val_acc: 0.9197\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17739 to 0.17726, saving model to best.model\n",
      "0s - loss: 0.1712 - acc: 0.9222 - val_loss: 0.1773 - val_acc: 0.9190\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9207 - val_loss: 0.1781 - val_acc: 0.9184\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17726 to 0.17718, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9226 - val_loss: 0.1772 - val_acc: 0.9190\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9240 - val_loss: 0.1776 - val_acc: 0.9193\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9213 - val_loss: 0.1775 - val_acc: 0.9203\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9228 - val_loss: 0.1776 - val_acc: 0.9191\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9220 - val_loss: 0.1788 - val_acc: 0.9199\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9212 - val_loss: 0.1781 - val_acc: 0.9203\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9222 - val_loss: 0.1791 - val_acc: 0.9199\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9226 - val_loss: 0.1783 - val_acc: 0.9188\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9229 - val_loss: 0.1782 - val_acc: 0.9197\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9227 - val_loss: 0.1772 - val_acc: 0.9193\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17718 to 0.17693, saving model to best.model\n",
      "0s - loss: 0.1690 - acc: 0.9234 - val_loss: 0.1769 - val_acc: 0.9184\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9233 - val_loss: 0.1772 - val_acc: 0.9193\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17693 to 0.17689, saving model to best.model\n",
      "0s - loss: 0.1681 - acc: 0.9211 - val_loss: 0.1769 - val_acc: 0.9199\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9227 - val_loss: 0.1809 - val_acc: 0.9186\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9220 - val_loss: 0.1783 - val_acc: 0.9193\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9226 - val_loss: 0.1771 - val_acc: 0.9195\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9249 - val_loss: 0.1775 - val_acc: 0.9190\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9227 - val_loss: 0.1779 - val_acc: 0.9201\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9223 - val_loss: 0.1784 - val_acc: 0.9205\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9226 - val_loss: 0.1788 - val_acc: 0.9197\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9236 - val_loss: 0.1781 - val_acc: 0.9203\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9244 - val_loss: 0.1772 - val_acc: 0.9191\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9230 - val_loss: 0.1774 - val_acc: 0.9190\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9222 - val_loss: 0.1778 - val_acc: 0.9201\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9259 - val_loss: 0.1773 - val_acc: 0.9199\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9217 - val_loss: 0.1770 - val_acc: 0.9193\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17689 to 0.17673, saving model to best.model\n",
      "0s - loss: 0.1668 - acc: 0.9229 - val_loss: 0.1767 - val_acc: 0.9195\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9223 - val_loss: 0.1777 - val_acc: 0.9188\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9240 - val_loss: 0.1768 - val_acc: 0.9190\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9239 - val_loss: 0.1784 - val_acc: 0.9188\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9243 - val_loss: 0.1769 - val_acc: 0.9191\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1645 - acc: 0.9257 - val_loss: 0.1790 - val_acc: 0.9190\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1656 - acc: 0.9231 - val_loss: 0.1773 - val_acc: 0.9195\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1652 - acc: 0.9231 - val_loss: 0.1780 - val_acc: 0.9191\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9239 - val_loss: 0.1788 - val_acc: 0.9184\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1663 - acc: 0.9227 - val_loss: 0.1780 - val_acc: 0.9197\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1660 - acc: 0.9240 - val_loss: 0.1774 - val_acc: 0.9195\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1648 - acc: 0.9244 - val_loss: 0.1770 - val_acc: 0.9203\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9240 - val_loss: 0.1769 - val_acc: 0.9201\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9255 - val_loss: 0.1787 - val_acc: 0.9190\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9234 - val_loss: 0.1775 - val_acc: 0.9188\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9245 - val_loss: 0.1794 - val_acc: 0.9203\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9248 - val_loss: 0.1782 - val_acc: 0.9201\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9238 - val_loss: 0.1785 - val_acc: 0.9195\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1640 - acc: 0.9253 - val_loss: 0.1778 - val_acc: 0.9197\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1653 - acc: 0.9230 - val_loss: 0.1775 - val_acc: 0.9199\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1656 - acc: 0.9254 - val_loss: 0.1773 - val_acc: 0.9191\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1648 - acc: 0.9247 - val_loss: 0.1785 - val_acc: 0.9186\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1655 - acc: 0.9251 - val_loss: 0.1775 - val_acc: 0.9186\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1657 - acc: 0.9251 - val_loss: 0.1780 - val_acc: 0.9190\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1646 - acc: 0.9245 - val_loss: 0.1772 - val_acc: 0.9193\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17673 to 0.17616, saving model to best.model\n",
      "0s - loss: 0.1656 - acc: 0.9236 - val_loss: 0.1762 - val_acc: 0.9199\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9241 - val_loss: 0.1773 - val_acc: 0.9188\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1640 - acc: 0.9251 - val_loss: 0.1765 - val_acc: 0.9188\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17616 to 0.17599, saving model to best.model\n",
      "0s - loss: 0.1645 - acc: 0.9232 - val_loss: 0.1760 - val_acc: 0.9195\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1645 - acc: 0.9259 - val_loss: 0.1771 - val_acc: 0.9203\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1645 - acc: 0.9245 - val_loss: 0.1769 - val_acc: 0.9213\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1644 - acc: 0.9260 - val_loss: 0.1776 - val_acc: 0.9211\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1632 - acc: 0.9255 - val_loss: 0.1773 - val_acc: 0.9209\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1629 - acc: 0.9250 - val_loss: 0.1764 - val_acc: 0.9203\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1636 - acc: 0.9260 - val_loss: 0.1777 - val_acc: 0.9209\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1623 - acc: 0.9267 - val_loss: 0.1789 - val_acc: 0.9213\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1633 - acc: 0.9244 - val_loss: 0.1787 - val_acc: 0.9205\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1629 - acc: 0.9248 - val_loss: 0.1772 - val_acc: 0.9190\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1632 - acc: 0.9243 - val_loss: 0.1779 - val_acc: 0.9215\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1627 - acc: 0.9273 - val_loss: 0.1767 - val_acc: 0.9207\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1628 - acc: 0.9246 - val_loss: 0.1775 - val_acc: 0.9213\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1622 - acc: 0.9253 - val_loss: 0.1773 - val_acc: 0.9190\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1640 - acc: 0.9242 - val_loss: 0.1781 - val_acc: 0.9199\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1631 - acc: 0.9261 - val_loss: 0.1769 - val_acc: 0.9197\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1613 - acc: 0.9253 - val_loss: 0.1771 - val_acc: 0.9205\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1624 - acc: 0.9263 - val_loss: 0.1763 - val_acc: 0.9207\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1626 - acc: 0.9249 - val_loss: 0.1774 - val_acc: 0.9203\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1641 - acc: 0.9248 - val_loss: 0.1780 - val_acc: 0.9215\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1621 - acc: 0.9257 - val_loss: 0.1774 - val_acc: 0.9199\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1623 - acc: 0.9246 - val_loss: 0.1779 - val_acc: 0.9203\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31934, saving model to best.model\n",
      "0s - loss: 0.3871 - acc: 0.8812 - val_loss: 0.3193 - val_acc: 0.8901\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31934 to 0.23658, saving model to best.model\n",
      "0s - loss: 0.3103 - acc: 0.8872 - val_loss: 0.2366 - val_acc: 0.9055\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23658 to 0.19841, saving model to best.model\n",
      "0s - loss: 0.2537 - acc: 0.8968 - val_loss: 0.1984 - val_acc: 0.9120\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.19841 to 0.19319, saving model to best.model\n",
      "0s - loss: 0.2268 - acc: 0.9029 - val_loss: 0.1932 - val_acc: 0.9142\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19319 to 0.18568, saving model to best.model\n",
      "0s - loss: 0.2162 - acc: 0.9034 - val_loss: 0.1857 - val_acc: 0.9126\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18568 to 0.18445, saving model to best.model\n",
      "0s - loss: 0.2100 - acc: 0.9061 - val_loss: 0.1844 - val_acc: 0.9134\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18445 to 0.18374, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9071 - val_loss: 0.1837 - val_acc: 0.9136\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18374 to 0.18324, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9072 - val_loss: 0.1832 - val_acc: 0.9161\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18324 to 0.18313, saving model to best.model\n",
      "0s - loss: 0.2018 - acc: 0.9065 - val_loss: 0.1831 - val_acc: 0.9151\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2012 - acc: 0.9076 - val_loss: 0.1834 - val_acc: 0.9155\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1997 - acc: 0.9080 - val_loss: 0.1842 - val_acc: 0.9161\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1995 - acc: 0.9064 - val_loss: 0.1839 - val_acc: 0.9157\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9094 - val_loss: 0.1835 - val_acc: 0.9155\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9073 - val_loss: 0.1836 - val_acc: 0.9134\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1952 - acc: 0.9084 - val_loss: 0.1846 - val_acc: 0.9128\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9078 - val_loss: 0.1838 - val_acc: 0.9153\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9078 - val_loss: 0.1852 - val_acc: 0.9115\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1977 - acc: 0.9078 - val_loss: 0.1839 - val_acc: 0.9147\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18313 to 0.18303, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9102 - val_loss: 0.1830 - val_acc: 0.9155\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18303 to 0.18299, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9084 - val_loss: 0.1830 - val_acc: 0.9157\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1972 - acc: 0.9094 - val_loss: 0.1833 - val_acc: 0.9159\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9084 - val_loss: 0.1832 - val_acc: 0.9157\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9105 - val_loss: 0.1830 - val_acc: 0.9155\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18299 to 0.18276, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9095 - val_loss: 0.1828 - val_acc: 0.9155\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18276 to 0.18257, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9101 - val_loss: 0.1826 - val_acc: 0.9153\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1928 - acc: 0.9095 - val_loss: 0.1828 - val_acc: 0.9149\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9100 - val_loss: 0.1829 - val_acc: 0.9153\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9100 - val_loss: 0.1826 - val_acc: 0.9138\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9093 - val_loss: 0.1826 - val_acc: 0.9155\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18257 to 0.18224, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9101 - val_loss: 0.1822 - val_acc: 0.9143\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18224 to 0.18197, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9114 - val_loss: 0.1820 - val_acc: 0.9151\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18197 to 0.18156, saving model to best.model\n",
      "0s - loss: 0.1925 - acc: 0.9109 - val_loss: 0.1816 - val_acc: 0.9147\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9104 - val_loss: 0.1820 - val_acc: 0.9145\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9109 - val_loss: 0.1818 - val_acc: 0.9142\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18156 to 0.18138, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9112 - val_loss: 0.1814 - val_acc: 0.9142\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18138 to 0.18137, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9118 - val_loss: 0.1814 - val_acc: 0.9142\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9109 - val_loss: 0.1818 - val_acc: 0.9132\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18137 to 0.18083, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9120 - val_loss: 0.1808 - val_acc: 0.9145\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9102 - val_loss: 0.1813 - val_acc: 0.9130\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9112 - val_loss: 0.1815 - val_acc: 0.9124\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9112 - val_loss: 0.1809 - val_acc: 0.9128\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9120 - val_loss: 0.1810 - val_acc: 0.9130\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9128 - val_loss: 0.1812 - val_acc: 0.9134\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18083 to 0.18081, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9120 - val_loss: 0.1808 - val_acc: 0.9130\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18081 to 0.18058, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9111 - val_loss: 0.1806 - val_acc: 0.9132\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18058 to 0.18047, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9120 - val_loss: 0.1805 - val_acc: 0.9157\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18047 to 0.18042, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9124 - val_loss: 0.1804 - val_acc: 0.9138\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9129 - val_loss: 0.1806 - val_acc: 0.9149\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9126 - val_loss: 0.1811 - val_acc: 0.9153\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18042 to 0.18006, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9105 - val_loss: 0.1801 - val_acc: 0.9142\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9132 - val_loss: 0.1803 - val_acc: 0.9140\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9126 - val_loss: 0.1806 - val_acc: 0.9167\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9126 - val_loss: 0.1802 - val_acc: 0.9143\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18006 to 0.17987, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9134 - val_loss: 0.1799 - val_acc: 0.9149\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9140 - val_loss: 0.1809 - val_acc: 0.9145\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9112 - val_loss: 0.1802 - val_acc: 0.9155\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.17987 to 0.17950, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9121 - val_loss: 0.1795 - val_acc: 0.9157\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9132 - val_loss: 0.1797 - val_acc: 0.9170\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.17950 to 0.17933, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9126 - val_loss: 0.1793 - val_acc: 0.9157\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9134 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "1s - loss: 0.1856 - acc: 0.9131 - val_loss: 0.1794 - val_acc: 0.9165\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17933 to 0.17926, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9144 - val_loss: 0.1793 - val_acc: 0.9167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9142 - val_loss: 0.1795 - val_acc: 0.9170\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17926 to 0.17886, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9139 - val_loss: 0.1789 - val_acc: 0.9182\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.17886 to 0.17882, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9149 - val_loss: 0.1788 - val_acc: 0.9176\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9140 - val_loss: 0.1789 - val_acc: 0.9155\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.17882 to 0.17858, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9140 - val_loss: 0.1786 - val_acc: 0.9170\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17858 to 0.17833, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9136 - val_loss: 0.1783 - val_acc: 0.9155\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9151 - val_loss: 0.1786 - val_acc: 0.9170\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9150 - val_loss: 0.1785 - val_acc: 0.9174\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9145 - val_loss: 0.1784 - val_acc: 0.9172\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9144 - val_loss: 0.1788 - val_acc: 0.9167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.17833 to 0.17828, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9144 - val_loss: 0.1783 - val_acc: 0.9168\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9144 - val_loss: 0.1784 - val_acc: 0.9170\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9150 - val_loss: 0.1786 - val_acc: 0.9168\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9159 - val_loss: 0.1784 - val_acc: 0.9170\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.17828 to 0.17810, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9131 - val_loss: 0.1781 - val_acc: 0.9176\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17810 to 0.17769, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9139 - val_loss: 0.1777 - val_acc: 0.9180\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17769 to 0.17753, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9148 - val_loss: 0.1775 - val_acc: 0.9170\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9136 - val_loss: 0.1778 - val_acc: 0.9174\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9152 - val_loss: 0.1778 - val_acc: 0.9178\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9141 - val_loss: 0.1779 - val_acc: 0.9176\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.17753 to 0.17741, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9145 - val_loss: 0.1774 - val_acc: 0.9174\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9153 - val_loss: 0.1775 - val_acc: 0.9176\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9166 - val_loss: 0.1778 - val_acc: 0.9176\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9159 - val_loss: 0.1779 - val_acc: 0.9176\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17741 to 0.17730, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9148 - val_loss: 0.1773 - val_acc: 0.9174\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9163 - val_loss: 0.1779 - val_acc: 0.9172\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17730 to 0.17709, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9159 - val_loss: 0.1771 - val_acc: 0.9184\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17709 to 0.17690, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9150 - val_loss: 0.1769 - val_acc: 0.9191\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9156 - val_loss: 0.1770 - val_acc: 0.9174\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17690 to 0.17661, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9174 - val_loss: 0.1766 - val_acc: 0.9186\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9153 - val_loss: 0.1768 - val_acc: 0.9186\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9156 - val_loss: 0.1786 - val_acc: 0.9176\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9133 - val_loss: 0.1768 - val_acc: 0.9180\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9164 - val_loss: 0.1768 - val_acc: 0.9190\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17661 to 0.17651, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9163 - val_loss: 0.1765 - val_acc: 0.9191\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9165 - val_loss: 0.1768 - val_acc: 0.9180\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9151 - val_loss: 0.1769 - val_acc: 0.9186\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9150 - val_loss: 0.1771 - val_acc: 0.9180\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9148 - val_loss: 0.1765 - val_acc: 0.9186\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17651 to 0.17650, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9174 - val_loss: 0.1765 - val_acc: 0.9193\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9148 - val_loss: 0.1769 - val_acc: 0.9193\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9160 - val_loss: 0.1766 - val_acc: 0.9190\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "1s - loss: 0.1793 - acc: 0.9154 - val_loss: 0.1769 - val_acc: 0.9186\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9161 - val_loss: 0.1766 - val_acc: 0.9197\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17650 to 0.17639, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9150 - val_loss: 0.1764 - val_acc: 0.9186\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9165 - val_loss: 0.1765 - val_acc: 0.9186\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17639 to 0.17599, saving model to best.model\n",
      "1s - loss: 0.1782 - acc: 0.9163 - val_loss: 0.1760 - val_acc: 0.9195\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17599 to 0.17587, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9169 - val_loss: 0.1759 - val_acc: 0.9197\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9151 - val_loss: 0.1759 - val_acc: 0.9197\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17587 to 0.17584, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9172 - val_loss: 0.1758 - val_acc: 0.9201\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9179 - val_loss: 0.1760 - val_acc: 0.9201\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9165 - val_loss: 0.1761 - val_acc: 0.9176\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9162 - val_loss: 0.1762 - val_acc: 0.9186\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9176 - val_loss: 0.1763 - val_acc: 0.9178\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9166 - val_loss: 0.1759 - val_acc: 0.9193\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9181 - val_loss: 0.1761 - val_acc: 0.9207\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9164 - val_loss: 0.1761 - val_acc: 0.9180\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.17584 to 0.17548, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9160 - val_loss: 0.1755 - val_acc: 0.9199\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17548 to 0.17546, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9173 - val_loss: 0.1755 - val_acc: 0.9203\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9167 - val_loss: 0.1757 - val_acc: 0.9201\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17546 to 0.17528, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9150 - val_loss: 0.1753 - val_acc: 0.9209\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17528 to 0.17506, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9170 - val_loss: 0.1751 - val_acc: 0.9205\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9168 - val_loss: 0.1759 - val_acc: 0.9184\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9161 - val_loss: 0.1759 - val_acc: 0.9188\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9170 - val_loss: 0.1754 - val_acc: 0.9207\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9176 - val_loss: 0.1761 - val_acc: 0.9180\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9163 - val_loss: 0.1760 - val_acc: 0.9195\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9161 - val_loss: 0.1764 - val_acc: 0.9176\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9173 - val_loss: 0.1753 - val_acc: 0.9207\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9175 - val_loss: 0.1754 - val_acc: 0.9201\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9159 - val_loss: 0.1751 - val_acc: 0.9203\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17506 to 0.17486, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9161 - val_loss: 0.1749 - val_acc: 0.9209\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9185 - val_loss: 0.1753 - val_acc: 0.9199\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9160 - val_loss: 0.1750 - val_acc: 0.9199\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9177 - val_loss: 0.1751 - val_acc: 0.9209\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9186 - val_loss: 0.1757 - val_acc: 0.9191\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9179 - val_loss: 0.1757 - val_acc: 0.9191\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17486 to 0.17478, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9169 - val_loss: 0.1748 - val_acc: 0.9205\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17478 to 0.17449, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9175 - val_loss: 0.1745 - val_acc: 0.9207\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9177 - val_loss: 0.1749 - val_acc: 0.9193\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9157 - val_loss: 0.1749 - val_acc: 0.9207\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9183 - val_loss: 0.1752 - val_acc: 0.9190\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9166 - val_loss: 0.1751 - val_acc: 0.9215\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9178 - val_loss: 0.1748 - val_acc: 0.9203\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9175 - val_loss: 0.1747 - val_acc: 0.9199\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.17449 to 0.17411, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9177 - val_loss: 0.1741 - val_acc: 0.9207\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9177 - val_loss: 0.1752 - val_acc: 0.9186\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9176 - val_loss: 0.1746 - val_acc: 0.9211\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9186 - val_loss: 0.1758 - val_acc: 0.9197\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9193 - val_loss: 0.1751 - val_acc: 0.9205\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9182 - val_loss: 0.1742 - val_acc: 0.9201\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9191 - val_loss: 0.1746 - val_acc: 0.9199\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9184 - val_loss: 0.1751 - val_acc: 0.9207\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9192 - val_loss: 0.1742 - val_acc: 0.9203\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9169 - val_loss: 0.1741 - val_acc: 0.9201\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9180 - val_loss: 0.1747 - val_acc: 0.9199\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17411 to 0.17407, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9179 - val_loss: 0.1741 - val_acc: 0.9193\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9205 - val_loss: 0.1747 - val_acc: 0.9193\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9183 - val_loss: 0.1746 - val_acc: 0.9211\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9170 - val_loss: 0.1742 - val_acc: 0.9207\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9182 - val_loss: 0.1743 - val_acc: 0.9213\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.17407 to 0.17387, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9177 - val_loss: 0.1739 - val_acc: 0.9213\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9189 - val_loss: 0.1742 - val_acc: 0.9205\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9190 - val_loss: 0.1740 - val_acc: 0.9201\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17387 to 0.17351, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9172 - val_loss: 0.1735 - val_acc: 0.9195\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9181 - val_loss: 0.1741 - val_acc: 0.9203\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9196 - val_loss: 0.1739 - val_acc: 0.9211\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9194 - val_loss: 0.1742 - val_acc: 0.9195\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9171 - val_loss: 0.1737 - val_acc: 0.9201\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9183 - val_loss: 0.1739 - val_acc: 0.9201\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9191 - val_loss: 0.1748 - val_acc: 0.9213\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9199 - val_loss: 0.1740 - val_acc: 0.9222\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9173 - val_loss: 0.1736 - val_acc: 0.9216\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9202 - val_loss: 0.1736 - val_acc: 0.9213\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9195 - val_loss: 0.1736 - val_acc: 0.9207\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9196 - val_loss: 0.1755 - val_acc: 0.9207\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9194 - val_loss: 0.1738 - val_acc: 0.9207\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9190 - val_loss: 0.1741 - val_acc: 0.9213\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9189 - val_loss: 0.1746 - val_acc: 0.9211\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9184 - val_loss: 0.1746 - val_acc: 0.9199\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9180 - val_loss: 0.1745 - val_acc: 0.9201\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.17351 to 0.17326, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9183 - val_loss: 0.1733 - val_acc: 0.9216\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17326 to 0.17324, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9191 - val_loss: 0.1732 - val_acc: 0.9213\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.17324 to 0.17319, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9193 - val_loss: 0.1732 - val_acc: 0.9224\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9193 - val_loss: 0.1740 - val_acc: 0.9201\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9181 - val_loss: 0.1738 - val_acc: 0.9209\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9197 - val_loss: 0.1742 - val_acc: 0.9209\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.17319 to 0.17262, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9186 - val_loss: 0.1726 - val_acc: 0.9215\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9186 - val_loss: 0.1728 - val_acc: 0.9205\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9199 - val_loss: 0.1740 - val_acc: 0.9220\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9209 - val_loss: 0.1728 - val_acc: 0.9216\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9189 - val_loss: 0.1728 - val_acc: 0.9215\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9200 - val_loss: 0.1737 - val_acc: 0.9209\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9209 - val_loss: 0.1734 - val_acc: 0.9216\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9195 - val_loss: 0.1728 - val_acc: 0.9213\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9193 - val_loss: 0.1741 - val_acc: 0.9226\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9203 - val_loss: 0.1734 - val_acc: 0.9209\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9179 - val_loss: 0.1728 - val_acc: 0.9216\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.30879, saving model to best.model\n",
      "0s - loss: 0.3780 - acc: 0.8851 - val_loss: 0.3088 - val_acc: 0.8911\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.30879 to 0.23252, saving model to best.model\n",
      "0s - loss: 0.2932 - acc: 0.8909 - val_loss: 0.2325 - val_acc: 0.9026\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23252 to 0.20357, saving model to best.model\n",
      "0s - loss: 0.2447 - acc: 0.8987 - val_loss: 0.2036 - val_acc: 0.9067\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20357 to 0.19586, saving model to best.model\n",
      "0s - loss: 0.2240 - acc: 0.9025 - val_loss: 0.1959 - val_acc: 0.9070\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19586 to 0.19349, saving model to best.model\n",
      "0s - loss: 0.2153 - acc: 0.9046 - val_loss: 0.1935 - val_acc: 0.9094\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.2078 - acc: 0.9049 - val_loss: 0.1942 - val_acc: 0.9086\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19349 to 0.19160, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9065 - val_loss: 0.1916 - val_acc: 0.9097\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19160 to 0.19089, saving model to best.model\n",
      "0s - loss: 0.2035 - acc: 0.9036 - val_loss: 0.1909 - val_acc: 0.9099\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19089 to 0.19028, saving model to best.model\n",
      "0s - loss: 0.2024 - acc: 0.9046 - val_loss: 0.1903 - val_acc: 0.9111\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19028 to 0.19015, saving model to best.model\n",
      "0s - loss: 0.2001 - acc: 0.9078 - val_loss: 0.1902 - val_acc: 0.9099\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19015 to 0.19010, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9062 - val_loss: 0.1901 - val_acc: 0.9117\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9075 - val_loss: 0.1904 - val_acc: 0.9080\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19010 to 0.18987, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9063 - val_loss: 0.1899 - val_acc: 0.9101\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18987 to 0.18982, saving model to best.model\n",
      "0s - loss: 0.1978 - acc: 0.9078 - val_loss: 0.1898 - val_acc: 0.9111\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.18982 to 0.18945, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9082 - val_loss: 0.1895 - val_acc: 0.9115\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1977 - acc: 0.9072 - val_loss: 0.1899 - val_acc: 0.9095\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18945 to 0.18916, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9083 - val_loss: 0.1892 - val_acc: 0.9092\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18916 to 0.18891, saving model to best.model\n",
      "0s - loss: 0.1959 - acc: 0.9077 - val_loss: 0.1889 - val_acc: 0.9105\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18891 to 0.18864, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9063 - val_loss: 0.1886 - val_acc: 0.9109\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9084 - val_loss: 0.1887 - val_acc: 0.9103\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18864 to 0.18832, saving model to best.model\n",
      "0s - loss: 0.1943 - acc: 0.9085 - val_loss: 0.1883 - val_acc: 0.9111\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18832 to 0.18825, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9091 - val_loss: 0.1883 - val_acc: 0.9107\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18825 to 0.18806, saving model to best.model\n",
      "1s - loss: 0.1935 - acc: 0.9097 - val_loss: 0.1881 - val_acc: 0.9099\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18806 to 0.18773, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9091 - val_loss: 0.1877 - val_acc: 0.9122\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18773 to 0.18746, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9088 - val_loss: 0.1875 - val_acc: 0.9117\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18746 to 0.18743, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9088 - val_loss: 0.1874 - val_acc: 0.9103\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9087 - val_loss: 0.1875 - val_acc: 0.9115\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18743 to 0.18712, saving model to best.model\n",
      "1s - loss: 0.1926 - acc: 0.9100 - val_loss: 0.1871 - val_acc: 0.9111\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18712 to 0.18679, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9091 - val_loss: 0.1868 - val_acc: 0.9113\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9082 - val_loss: 0.1869 - val_acc: 0.9118\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18679 to 0.18671, saving model to best.model\n",
      "1s - loss: 0.1920 - acc: 0.9096 - val_loss: 0.1867 - val_acc: 0.9113\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "1s - loss: 0.1933 - acc: 0.9080 - val_loss: 0.1868 - val_acc: 0.9118\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18671 to 0.18609, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9113 - val_loss: 0.1861 - val_acc: 0.9117\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18609 to 0.18584, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9102 - val_loss: 0.1858 - val_acc: 0.9126\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18584 to 0.18566, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9099 - val_loss: 0.1857 - val_acc: 0.9122\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18566 to 0.18545, saving model to best.model\n",
      "1s - loss: 0.1898 - acc: 0.9090 - val_loss: 0.1854 - val_acc: 0.9124\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18545 to 0.18524, saving model to best.model\n",
      "1s - loss: 0.1923 - acc: 0.9102 - val_loss: 0.1852 - val_acc: 0.9113\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9102 - val_loss: 0.1854 - val_acc: 0.9122\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18524 to 0.18501, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9109 - val_loss: 0.1850 - val_acc: 0.9122\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1904 - acc: 0.9100 - val_loss: 0.1852 - val_acc: 0.9122\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9104 - val_loss: 0.1851 - val_acc: 0.9115\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18501 to 0.18455, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9108 - val_loss: 0.1846 - val_acc: 0.9124\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18455 to 0.18443, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9104 - val_loss: 0.1844 - val_acc: 0.9124\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18443 to 0.18401, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9114 - val_loss: 0.1840 - val_acc: 0.9120\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9118 - val_loss: 0.1845 - val_acc: 0.9120\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18401 to 0.18373, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9118 - val_loss: 0.1837 - val_acc: 0.9122\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9101 - val_loss: 0.1843 - val_acc: 0.9130\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9101 - val_loss: 0.1838 - val_acc: 0.9130\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18373 to 0.18370, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9096 - val_loss: 0.1837 - val_acc: 0.9130\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9137 - val_loss: 0.1838 - val_acc: 0.9136\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18370 to 0.18302, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9118 - val_loss: 0.1830 - val_acc: 0.9126\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9127 - val_loss: 0.1832 - val_acc: 0.9124\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18302 to 0.18297, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9114 - val_loss: 0.1830 - val_acc: 0.9115\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9110 - val_loss: 0.1830 - val_acc: 0.9128\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18297 to 0.18294, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9121 - val_loss: 0.1829 - val_acc: 0.9142\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18294 to 0.18283, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9124 - val_loss: 0.1828 - val_acc: 0.9140\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9115 - val_loss: 0.1829 - val_acc: 0.9128\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18283 to 0.18223, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9125 - val_loss: 0.1822 - val_acc: 0.9136\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18223 to 0.18190, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9122 - val_loss: 0.1819 - val_acc: 0.9132\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9122 - val_loss: 0.1819 - val_acc: 0.9136\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9127 - val_loss: 0.1823 - val_acc: 0.9138\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18190 to 0.18159, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9135 - val_loss: 0.1816 - val_acc: 0.9126\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9120 - val_loss: 0.1817 - val_acc: 0.9132\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9114 - val_loss: 0.1816 - val_acc: 0.9134\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9127 - val_loss: 0.1819 - val_acc: 0.9145\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18159 to 0.18125, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9142 - val_loss: 0.1812 - val_acc: 0.9140\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9138 - val_loss: 0.1818 - val_acc: 0.9142\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9135 - val_loss: 0.1814 - val_acc: 0.9143\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9122 - val_loss: 0.1816 - val_acc: 0.9143\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9121 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18125 to 0.18087, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9130 - val_loss: 0.1809 - val_acc: 0.9147\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18087 to 0.18054, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9116 - val_loss: 0.1805 - val_acc: 0.9142\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9114 - val_loss: 0.1808 - val_acc: 0.9140\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18054 to 0.18048, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9128 - val_loss: 0.1805 - val_acc: 0.9145\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18048 to 0.18027, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9128 - val_loss: 0.1803 - val_acc: 0.9130\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9137 - val_loss: 0.1805 - val_acc: 0.9143\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18027 to 0.18018, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9124 - val_loss: 0.1802 - val_acc: 0.9147\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9126 - val_loss: 0.1805 - val_acc: 0.9149\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9145 - val_loss: 0.1802 - val_acc: 0.9151\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9140 - val_loss: 0.1803 - val_acc: 0.9138\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18018 to 0.17975, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9162 - val_loss: 0.1797 - val_acc: 0.9151\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9136 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9132 - val_loss: 0.1801 - val_acc: 0.9151\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17975 to 0.17963, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9132 - val_loss: 0.1796 - val_acc: 0.9136\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9137 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17963 to 0.17935, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9137 - val_loss: 0.1793 - val_acc: 0.9143\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17935 to 0.17924, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9150 - val_loss: 0.1792 - val_acc: 0.9143\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17924 to 0.17911, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9148 - val_loss: 0.1791 - val_acc: 0.9134\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17911 to 0.17890, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9143 - val_loss: 0.1789 - val_acc: 0.9136\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17890 to 0.17889, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9143 - val_loss: 0.1789 - val_acc: 0.9143\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9140 - val_loss: 0.1794 - val_acc: 0.9147\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17889 to 0.17884, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9138 - val_loss: 0.1788 - val_acc: 0.9142\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9136 - val_loss: 0.1789 - val_acc: 0.9134\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17884 to 0.17870, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9166 - val_loss: 0.1787 - val_acc: 0.9142\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17870 to 0.17865, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9145 - val_loss: 0.1787 - val_acc: 0.9143\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9143 - val_loss: 0.1788 - val_acc: 0.9142\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9143 - val_loss: 0.1792 - val_acc: 0.9145\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9150 - val_loss: 0.1787 - val_acc: 0.9140\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17865 to 0.17845, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9159 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9145 - val_loss: 0.1786 - val_acc: 0.9145\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17845 to 0.17821, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9152 - val_loss: 0.1782 - val_acc: 0.9147\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9152 - val_loss: 0.1783 - val_acc: 0.9140\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17821 to 0.17800, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9161 - val_loss: 0.1780 - val_acc: 0.9147\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17800 to 0.17783, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9151 - val_loss: 0.1778 - val_acc: 0.9143\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.17783 to 0.17769, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9145 - val_loss: 0.1777 - val_acc: 0.9147\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9159 - val_loss: 0.1784 - val_acc: 0.9163\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9155 - val_loss: 0.1778 - val_acc: 0.9140\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17769 to 0.17739, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9159 - val_loss: 0.1774 - val_acc: 0.9143\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9165 - val_loss: 0.1778 - val_acc: 0.9153\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9140 - val_loss: 0.1774 - val_acc: 0.9145\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.17739 to 0.17734, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9167 - val_loss: 0.1773 - val_acc: 0.9142\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9143 - val_loss: 0.1777 - val_acc: 0.9159\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17734 to 0.17722, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9172 - val_loss: 0.1772 - val_acc: 0.9149\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17722 to 0.17705, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9167 - val_loss: 0.1770 - val_acc: 0.9143\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9157 - val_loss: 0.1771 - val_acc: 0.9142\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "1s - loss: 0.1782 - acc: 0.9160 - val_loss: 0.1773 - val_acc: 0.9153\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17705 to 0.17689, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9164 - val_loss: 0.1769 - val_acc: 0.9140\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17689 to 0.17662, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9164 - val_loss: 0.1766 - val_acc: 0.9143\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9173 - val_loss: 0.1768 - val_acc: 0.9163\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.17662 to 0.17658, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9151 - val_loss: 0.1766 - val_acc: 0.9140\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9163 - val_loss: 0.1766 - val_acc: 0.9157\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17658 to 0.17650, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9172 - val_loss: 0.1765 - val_acc: 0.9155\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17650 to 0.17618, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9174 - val_loss: 0.1762 - val_acc: 0.9157\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17618 to 0.17617, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9157 - val_loss: 0.1762 - val_acc: 0.9149\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9161 - val_loss: 0.1763 - val_acc: 0.9159\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9163 - val_loss: 0.1762 - val_acc: 0.9159\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9164 - val_loss: 0.1763 - val_acc: 0.9165\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9168 - val_loss: 0.1762 - val_acc: 0.9161\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17617 to 0.17585, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9184 - val_loss: 0.1758 - val_acc: 0.9155\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9173 - val_loss: 0.1761 - val_acc: 0.9170\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9173 - val_loss: 0.1761 - val_acc: 0.9161\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17585 to 0.17572, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9170 - val_loss: 0.1757 - val_acc: 0.9149\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17572 to 0.17571, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9177 - val_loss: 0.1757 - val_acc: 0.9163\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17571 to 0.17553, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9163 - val_loss: 0.1755 - val_acc: 0.9165\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17553 to 0.17548, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9168 - val_loss: 0.1755 - val_acc: 0.9167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17548 to 0.17543, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9184 - val_loss: 0.1754 - val_acc: 0.9167\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17543 to 0.17522, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9171 - val_loss: 0.1752 - val_acc: 0.9163\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9167 - val_loss: 0.1753 - val_acc: 0.9167\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9179 - val_loss: 0.1758 - val_acc: 0.9155\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9173 - val_loss: 0.1757 - val_acc: 0.9163\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17522 to 0.17509, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9182 - val_loss: 0.1751 - val_acc: 0.9161\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17509 to 0.17499, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9189 - val_loss: 0.1750 - val_acc: 0.9157\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9179 - val_loss: 0.1750 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17499 to 0.17487, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9188 - val_loss: 0.1749 - val_acc: 0.9161\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9174 - val_loss: 0.1751 - val_acc: 0.9168\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9166 - val_loss: 0.1754 - val_acc: 0.9155\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9169 - val_loss: 0.1754 - val_acc: 0.9155\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9184 - val_loss: 0.1753 - val_acc: 0.9157\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9179 - val_loss: 0.1753 - val_acc: 0.9155\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17487 to 0.17451, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9178 - val_loss: 0.1745 - val_acc: 0.9159\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9195 - val_loss: 0.1748 - val_acc: 0.9165\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17451 to 0.17443, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9193 - val_loss: 0.1744 - val_acc: 0.9159\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9169 - val_loss: 0.1745 - val_acc: 0.9153\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9167 - val_loss: 0.1748 - val_acc: 0.9151\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9186 - val_loss: 0.1748 - val_acc: 0.9157\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9180 - val_loss: 0.1746 - val_acc: 0.9153\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9188 - val_loss: 0.1744 - val_acc: 0.9165\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9193 - val_loss: 0.1751 - val_acc: 0.9165\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9188 - val_loss: 0.1745 - val_acc: 0.9172\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9179 - val_loss: 0.1748 - val_acc: 0.9172\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.17443 to 0.17419, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9199 - val_loss: 0.1742 - val_acc: 0.9168\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9199 - val_loss: 0.1743 - val_acc: 0.9172\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17419 to 0.17412, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9185 - val_loss: 0.1741 - val_acc: 0.9174\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9177 - val_loss: 0.1746 - val_acc: 0.9180\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9189 - val_loss: 0.1747 - val_acc: 0.9172\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9178 - val_loss: 0.1744 - val_acc: 0.9170\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9168 - val_loss: 0.1744 - val_acc: 0.9178\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9189 - val_loss: 0.1743 - val_acc: 0.9172\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17412 to 0.17361, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9186 - val_loss: 0.1736 - val_acc: 0.9170\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9195 - val_loss: 0.1745 - val_acc: 0.9165\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9173 - val_loss: 0.1739 - val_acc: 0.9159\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9181 - val_loss: 0.1745 - val_acc: 0.9174\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9185 - val_loss: 0.1743 - val_acc: 0.9170\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9183 - val_loss: 0.1741 - val_acc: 0.9170\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9203 - val_loss: 0.1744 - val_acc: 0.9180\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9197 - val_loss: 0.1741 - val_acc: 0.9174\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9193 - val_loss: 0.1737 - val_acc: 0.9172\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9201 - val_loss: 0.1738 - val_acc: 0.9184\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9207 - val_loss: 0.1737 - val_acc: 0.9180\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9192 - val_loss: 0.1741 - val_acc: 0.9182\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9182 - val_loss: 0.1739 - val_acc: 0.9178\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9211 - val_loss: 0.1752 - val_acc: 0.9168\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17361 to 0.17348, saving model to best.model\n",
      "0s - loss: 0.1700 - acc: 0.9206 - val_loss: 0.1735 - val_acc: 0.9178\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9216 - val_loss: 0.1735 - val_acc: 0.9172\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9199 - val_loss: 0.1738 - val_acc: 0.9176\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9197 - val_loss: 0.1741 - val_acc: 0.9176\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9194 - val_loss: 0.1738 - val_acc: 0.9172\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.17348 to 0.17319, saving model to best.model\n",
      "0s - loss: 0.1679 - acc: 0.9200 - val_loss: 0.1732 - val_acc: 0.9178\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9209 - val_loss: 0.1743 - val_acc: 0.9174\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9198 - val_loss: 0.1744 - val_acc: 0.9172\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9200 - val_loss: 0.1744 - val_acc: 0.9174\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9202 - val_loss: 0.1735 - val_acc: 0.9174\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9200 - val_loss: 0.1732 - val_acc: 0.9182\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9211 - val_loss: 0.1734 - val_acc: 0.9180\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9208 - val_loss: 0.1735 - val_acc: 0.9182\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9191 - val_loss: 0.1735 - val_acc: 0.9176\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.17319 to 0.17292, saving model to best.model\n",
      "0s - loss: 0.1676 - acc: 0.9217 - val_loss: 0.1729 - val_acc: 0.9176\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9205 - val_loss: 0.1735 - val_acc: 0.9172\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.17292 to 0.17276, saving model to best.model\n",
      "0s - loss: 0.1691 - acc: 0.9195 - val_loss: 0.1728 - val_acc: 0.9174\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9203 - val_loss: 0.1731 - val_acc: 0.9180\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33063, saving model to best.model\n",
      "0s - loss: 0.4245 - acc: 0.8629 - val_loss: 0.3306 - val_acc: 0.8905\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33063 to 0.26742, saving model to best.model\n",
      "0s - loss: 0.3435 - acc: 0.8842 - val_loss: 0.2674 - val_acc: 0.8905\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26742 to 0.21575, saving model to best.model\n",
      "0s - loss: 0.2775 - acc: 0.8919 - val_loss: 0.2158 - val_acc: 0.9072\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21575 to 0.19538, saving model to best.model\n",
      "1s - loss: 0.2380 - acc: 0.9016 - val_loss: 0.1954 - val_acc: 0.9132\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19538 to 0.18904, saving model to best.model\n",
      "0s - loss: 0.2233 - acc: 0.9023 - val_loss: 0.1890 - val_acc: 0.9113\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18904 to 0.18758, saving model to best.model\n",
      "0s - loss: 0.2183 - acc: 0.9028 - val_loss: 0.1876 - val_acc: 0.9111\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18758 to 0.18556, saving model to best.model\n",
      "0s - loss: 0.2112 - acc: 0.9051 - val_loss: 0.1856 - val_acc: 0.9122\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18556 to 0.18486, saving model to best.model\n",
      "0s - loss: 0.2077 - acc: 0.9053 - val_loss: 0.1849 - val_acc: 0.9128\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2068 - acc: 0.9066 - val_loss: 0.1851 - val_acc: 0.9128\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18486 to 0.18418, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9082 - val_loss: 0.1842 - val_acc: 0.9115\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2013 - acc: 0.9081 - val_loss: 0.1846 - val_acc: 0.9103\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18418 to 0.18373, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9089 - val_loss: 0.1837 - val_acc: 0.9128\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2017 - acc: 0.9101 - val_loss: 0.1840 - val_acc: 0.9132\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9068 - val_loss: 0.1841 - val_acc: 0.9128\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1976 - acc: 0.9062 - val_loss: 0.1838 - val_acc: 0.9126\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1976 - acc: 0.9087 - val_loss: 0.1839 - val_acc: 0.9134\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9094 - val_loss: 0.1839 - val_acc: 0.9109\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18373 to 0.18339, saving model to best.model\n",
      "0s - loss: 0.1979 - acc: 0.9090 - val_loss: 0.1834 - val_acc: 0.9124\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18339 to 0.18326, saving model to best.model\n",
      "0s - loss: 0.1968 - acc: 0.9093 - val_loss: 0.1833 - val_acc: 0.9142\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18326 to 0.18306, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9086 - val_loss: 0.1831 - val_acc: 0.9138\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9092 - val_loss: 0.1831 - val_acc: 0.9126\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1963 - acc: 0.9086 - val_loss: 0.1833 - val_acc: 0.9103\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18306 to 0.18271, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9097 - val_loss: 0.1827 - val_acc: 0.9111\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18271 to 0.18267, saving model to best.model\n",
      "0s - loss: 0.1934 - acc: 0.9105 - val_loss: 0.1827 - val_acc: 0.9138\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18267 to 0.18206, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9104 - val_loss: 0.1821 - val_acc: 0.9132\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9088 - val_loss: 0.1822 - val_acc: 0.9130\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18206 to 0.18190, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9097 - val_loss: 0.1819 - val_acc: 0.9134\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9108 - val_loss: 0.1821 - val_acc: 0.9122\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9113 - val_loss: 0.1821 - val_acc: 0.9126\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18190 to 0.18126, saving model to best.model\n",
      "1s - loss: 0.1915 - acc: 0.9120 - val_loss: 0.1813 - val_acc: 0.9132\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18126 to 0.18114, saving model to best.model\n",
      "0s - loss: 0.1925 - acc: 0.9105 - val_loss: 0.1811 - val_acc: 0.9132\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18114 to 0.18080, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9131 - val_loss: 0.1808 - val_acc: 0.9128\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9103 - val_loss: 0.1808 - val_acc: 0.9120\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9099 - val_loss: 0.1815 - val_acc: 0.9153\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18080 to 0.18060, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9113 - val_loss: 0.1806 - val_acc: 0.9138\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18060 to 0.18045, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9087 - val_loss: 0.1805 - val_acc: 0.9134\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18045 to 0.18026, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9115 - val_loss: 0.1803 - val_acc: 0.9130\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18026 to 0.18011, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9110 - val_loss: 0.1801 - val_acc: 0.9126\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18011 to 0.17967, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9124 - val_loss: 0.1797 - val_acc: 0.9140\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1904 - acc: 0.9109 - val_loss: 0.1800 - val_acc: 0.9155\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17967 to 0.17953, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9118 - val_loss: 0.1795 - val_acc: 0.9157\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9109 - val_loss: 0.1817 - val_acc: 0.9126\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17953 to 0.17918, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9126 - val_loss: 0.1792 - val_acc: 0.9136\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9124 - val_loss: 0.1796 - val_acc: 0.9138\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9114 - val_loss: 0.1794 - val_acc: 0.9140\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17918 to 0.17896, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9112 - val_loss: 0.1790 - val_acc: 0.9151\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9108 - val_loss: 0.1797 - val_acc: 0.9134\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17896 to 0.17882, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9134 - val_loss: 0.1788 - val_acc: 0.9151\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9129 - val_loss: 0.1788 - val_acc: 0.9157\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17882 to 0.17854, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9129 - val_loss: 0.1785 - val_acc: 0.9151\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9138 - val_loss: 0.1786 - val_acc: 0.9161\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.17854 to 0.17836, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9136 - val_loss: 0.1784 - val_acc: 0.9157\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9133 - val_loss: 0.1785 - val_acc: 0.9159\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9122 - val_loss: 0.1785 - val_acc: 0.9157\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.17836 to 0.17815, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9126 - val_loss: 0.1782 - val_acc: 0.9161\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9149 - val_loss: 0.1786 - val_acc: 0.9167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9132 - val_loss: 0.1785 - val_acc: 0.9172\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17815 to 0.17800, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9126 - val_loss: 0.1780 - val_acc: 0.9170\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.17800 to 0.17778, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9134 - val_loss: 0.1778 - val_acc: 0.9167\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9127 - val_loss: 0.1778 - val_acc: 0.9159\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17778 to 0.17768, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9123 - val_loss: 0.1777 - val_acc: 0.9176\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17768 to 0.17722, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9135 - val_loss: 0.1772 - val_acc: 0.9172\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17722 to 0.17711, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9140 - val_loss: 0.1771 - val_acc: 0.9172\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9156 - val_loss: 0.1783 - val_acc: 0.9170\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9153 - val_loss: 0.1773 - val_acc: 0.9178\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9153 - val_loss: 0.1778 - val_acc: 0.9176\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9134 - val_loss: 0.1773 - val_acc: 0.9163\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17711 to 0.17683, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9147 - val_loss: 0.1768 - val_acc: 0.9178\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17683 to 0.17683, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9151 - val_loss: 0.1768 - val_acc: 0.9172\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.17683 to 0.17678, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9154 - val_loss: 0.1768 - val_acc: 0.9174\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9139 - val_loss: 0.1769 - val_acc: 0.9168\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17678 to 0.17675, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9144 - val_loss: 0.1767 - val_acc: 0.9182\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.17675 to 0.17656, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9149 - val_loss: 0.1766 - val_acc: 0.9178\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9150 - val_loss: 0.1766 - val_acc: 0.9174\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17656 to 0.17611, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9150 - val_loss: 0.1761 - val_acc: 0.9174\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9153 - val_loss: 0.1762 - val_acc: 0.9182\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9158 - val_loss: 0.1763 - val_acc: 0.9172\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9166 - val_loss: 0.1766 - val_acc: 0.9180\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17611 to 0.17605, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9150 - val_loss: 0.1760 - val_acc: 0.9184\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "1s - loss: 0.1822 - acc: 0.9157 - val_loss: 0.1764 - val_acc: 0.9170\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17605 to 0.17568, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9167 - val_loss: 0.1757 - val_acc: 0.9186\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9171 - val_loss: 0.1759 - val_acc: 0.9191\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9171 - val_loss: 0.1758 - val_acc: 0.9201\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9164 - val_loss: 0.1757 - val_acc: 0.9172\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.17568 to 0.17561, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9164 - val_loss: 0.1756 - val_acc: 0.9193\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9177 - val_loss: 0.1758 - val_acc: 0.9201\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17561 to 0.17527, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9163 - val_loss: 0.1753 - val_acc: 0.9191\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9149 - val_loss: 0.1756 - val_acc: 0.9184\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9166 - val_loss: 0.1753 - val_acc: 0.9191\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9164 - val_loss: 0.1753 - val_acc: 0.9197\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17527 to 0.17501, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9168 - val_loss: 0.1750 - val_acc: 0.9203\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9181 - val_loss: 0.1753 - val_acc: 0.9195\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17501 to 0.17484, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9168 - val_loss: 0.1748 - val_acc: 0.9195\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9169 - val_loss: 0.1763 - val_acc: 0.9174\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9161 - val_loss: 0.1750 - val_acc: 0.9209\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17484 to 0.17480, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9178 - val_loss: 0.1748 - val_acc: 0.9199\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9168 - val_loss: 0.1748 - val_acc: 0.9209\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17480 to 0.17469, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9172 - val_loss: 0.1747 - val_acc: 0.9203\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17469 to 0.17461, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9182 - val_loss: 0.1746 - val_acc: 0.9213\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17461 to 0.17457, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9170 - val_loss: 0.1746 - val_acc: 0.9193\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17457 to 0.17442, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9170 - val_loss: 0.1744 - val_acc: 0.9199\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9183 - val_loss: 0.1745 - val_acc: 0.9193\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9172 - val_loss: 0.1748 - val_acc: 0.9215\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9175 - val_loss: 0.1753 - val_acc: 0.9190\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.17442 to 0.17436, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9190 - val_loss: 0.1744 - val_acc: 0.9209\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9163 - val_loss: 0.1746 - val_acc: 0.9205\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17436 to 0.17409, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9189 - val_loss: 0.1741 - val_acc: 0.9199\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9168 - val_loss: 0.1745 - val_acc: 0.9176\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17409 to 0.17408, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9192 - val_loss: 0.1741 - val_acc: 0.9215\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9177 - val_loss: 0.1753 - val_acc: 0.9195\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9181 - val_loss: 0.1743 - val_acc: 0.9195\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9188 - val_loss: 0.1742 - val_acc: 0.9197\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17408 to 0.17386, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9199 - val_loss: 0.1739 - val_acc: 0.9199\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17386 to 0.17356, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9185 - val_loss: 0.1736 - val_acc: 0.9205\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9184 - val_loss: 0.1741 - val_acc: 0.9215\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9193 - val_loss: 0.1738 - val_acc: 0.9211\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9198 - val_loss: 0.1737 - val_acc: 0.9193\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "1s - loss: 0.1768 - acc: 0.9191 - val_loss: 0.1739 - val_acc: 0.9218\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9199 - val_loss: 0.1736 - val_acc: 0.9197\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9196 - val_loss: 0.1738 - val_acc: 0.9211\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9204 - val_loss: 0.1741 - val_acc: 0.9218\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17356 to 0.17338, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9186 - val_loss: 0.1734 - val_acc: 0.9205\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17338 to 0.17324, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9187 - val_loss: 0.1732 - val_acc: 0.9215\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9189 - val_loss: 0.1743 - val_acc: 0.9199\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9194 - val_loss: 0.1740 - val_acc: 0.9213\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9187 - val_loss: 0.1733 - val_acc: 0.9211\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9187 - val_loss: 0.1734 - val_acc: 0.9220\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9191 - val_loss: 0.1733 - val_acc: 0.9218\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9198 - val_loss: 0.1738 - val_acc: 0.9205\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9201 - val_loss: 0.1733 - val_acc: 0.9216\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17324 to 0.17315, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9195 - val_loss: 0.1732 - val_acc: 0.9216\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17315 to 0.17304, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9182 - val_loss: 0.1730 - val_acc: 0.9211\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17304 to 0.17300, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9200 - val_loss: 0.1730 - val_acc: 0.9222\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17300 to 0.17261, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9183 - val_loss: 0.1726 - val_acc: 0.9222\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9183 - val_loss: 0.1732 - val_acc: 0.9213\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9183 - val_loss: 0.1734 - val_acc: 0.9188\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17261 to 0.17245, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9204 - val_loss: 0.1724 - val_acc: 0.9203\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9199 - val_loss: 0.1725 - val_acc: 0.9201\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9191 - val_loss: 0.1727 - val_acc: 0.9220\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9197 - val_loss: 0.1728 - val_acc: 0.9209\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9191 - val_loss: 0.1732 - val_acc: 0.9220\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9201 - val_loss: 0.1727 - val_acc: 0.9203\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9205 - val_loss: 0.1728 - val_acc: 0.9218\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9203 - val_loss: 0.1726 - val_acc: 0.9209\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9196 - val_loss: 0.1736 - val_acc: 0.9218\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9218 - val_loss: 0.1728 - val_acc: 0.9205\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9194 - val_loss: 0.1727 - val_acc: 0.9195\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9213 - val_loss: 0.1725 - val_acc: 0.9209\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9208 - val_loss: 0.1725 - val_acc: 0.9203\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17245 to 0.17230, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9216 - val_loss: 0.1723 - val_acc: 0.9186\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9214 - val_loss: 0.1726 - val_acc: 0.9218\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9201 - val_loss: 0.1724 - val_acc: 0.9197\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9215 - val_loss: 0.1724 - val_acc: 0.9215\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9200 - val_loss: 0.1725 - val_acc: 0.9205\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9211 - val_loss: 0.1724 - val_acc: 0.9222\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9200 - val_loss: 0.1731 - val_acc: 0.9211\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17230 to 0.17211, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9206 - val_loss: 0.1721 - val_acc: 0.9213\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9218 - val_loss: 0.1722 - val_acc: 0.9222\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17211 to 0.17168, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9211 - val_loss: 0.1717 - val_acc: 0.9209\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9207 - val_loss: 0.1727 - val_acc: 0.9205\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9223 - val_loss: 0.1725 - val_acc: 0.9203\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.17168 to 0.17154, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9214 - val_loss: 0.1715 - val_acc: 0.9203\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9208 - val_loss: 0.1725 - val_acc: 0.9203\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9204 - val_loss: 0.1720 - val_acc: 0.9216\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9214 - val_loss: 0.1716 - val_acc: 0.9213\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9214 - val_loss: 0.1721 - val_acc: 0.9205\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9218 - val_loss: 0.1718 - val_acc: 0.9215\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9220 - val_loss: 0.1716 - val_acc: 0.9211\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9211 - val_loss: 0.1725 - val_acc: 0.9215\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9235 - val_loss: 0.1717 - val_acc: 0.9201\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9211 - val_loss: 0.1719 - val_acc: 0.9211\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9202 - val_loss: 0.1718 - val_acc: 0.9207\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17154 to 0.17114, saving model to best.model\n",
      "1s - loss: 0.1705 - acc: 0.9211 - val_loss: 0.1711 - val_acc: 0.9209\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9219 - val_loss: 0.1713 - val_acc: 0.9205\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9216 - val_loss: 0.1718 - val_acc: 0.9193\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9223 - val_loss: 0.1714 - val_acc: 0.9215\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9233 - val_loss: 0.1714 - val_acc: 0.9209\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9220 - val_loss: 0.1716 - val_acc: 0.9218\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9209 - val_loss: 0.1712 - val_acc: 0.9201\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.17114 to 0.17082, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9209 - val_loss: 0.1708 - val_acc: 0.9207\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9229 - val_loss: 0.1710 - val_acc: 0.9205\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "1s - loss: 0.1717 - acc: 0.9227 - val_loss: 0.1711 - val_acc: 0.9203\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17082 to 0.17069, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9212 - val_loss: 0.1707 - val_acc: 0.9205\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9208 - val_loss: 0.1709 - val_acc: 0.9203\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9226 - val_loss: 0.1711 - val_acc: 0.9211\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9223 - val_loss: 0.1709 - val_acc: 0.9211\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9218 - val_loss: 0.1713 - val_acc: 0.9199\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9217 - val_loss: 0.1716 - val_acc: 0.9195\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9210 - val_loss: 0.1710 - val_acc: 0.9193\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9231 - val_loss: 0.1710 - val_acc: 0.9195\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9230 - val_loss: 0.1717 - val_acc: 0.9205\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.17069 to 0.17023, saving model to best.model\n",
      "0s - loss: 0.1680 - acc: 0.9238 - val_loss: 0.1702 - val_acc: 0.9215\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9208 - val_loss: 0.1705 - val_acc: 0.9209\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9240 - val_loss: 0.1707 - val_acc: 0.9190\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9213 - val_loss: 0.1712 - val_acc: 0.9207\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9219 - val_loss: 0.1710 - val_acc: 0.9218\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9237 - val_loss: 0.1707 - val_acc: 0.9211\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9213 - val_loss: 0.1704 - val_acc: 0.9197\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9228 - val_loss: 0.1704 - val_acc: 0.9216\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9245 - val_loss: 0.1716 - val_acc: 0.9220\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31840, saving model to best.model\n",
      "0s - loss: 0.3918 - acc: 0.8789 - val_loss: 0.3184 - val_acc: 0.8890\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31840 to 0.23800, saving model to best.model\n",
      "0s - loss: 0.3080 - acc: 0.8908 - val_loss: 0.2380 - val_acc: 0.9036\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23800 to 0.20858, saving model to best.model\n",
      "0s - loss: 0.2534 - acc: 0.8990 - val_loss: 0.2086 - val_acc: 0.9061\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20858 to 0.19700, saving model to best.model\n",
      "0s - loss: 0.2299 - acc: 0.9029 - val_loss: 0.1970 - val_acc: 0.9072\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19700 to 0.19268, saving model to best.model\n",
      "0s - loss: 0.2206 - acc: 0.9032 - val_loss: 0.1927 - val_acc: 0.9080\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19268 to 0.19057, saving model to best.model\n",
      "1s - loss: 0.2124 - acc: 0.9066 - val_loss: 0.1906 - val_acc: 0.9088\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19057 to 0.18956, saving model to best.model\n",
      "0s - loss: 0.2082 - acc: 0.9052 - val_loss: 0.1896 - val_acc: 0.9097\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18956 to 0.18849, saving model to best.model\n",
      "0s - loss: 0.2054 - acc: 0.9063 - val_loss: 0.1885 - val_acc: 0.9097\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18849 to 0.18837, saving model to best.model\n",
      "0s - loss: 0.2034 - acc: 0.9070 - val_loss: 0.1884 - val_acc: 0.9107\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18837 to 0.18802, saving model to best.model\n",
      "0s - loss: 0.2036 - acc: 0.9074 - val_loss: 0.1880 - val_acc: 0.9115\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1994 - acc: 0.9084 - val_loss: 0.1891 - val_acc: 0.9094\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2005 - acc: 0.9075 - val_loss: 0.1886 - val_acc: 0.9101\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2004 - acc: 0.9075 - val_loss: 0.1901 - val_acc: 0.9065\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18802 to 0.18763, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9075 - val_loss: 0.1876 - val_acc: 0.9105\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9107 - val_loss: 0.1877 - val_acc: 0.9115\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.18763 to 0.18749, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9058 - val_loss: 0.1875 - val_acc: 0.9134\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9080 - val_loss: 0.1875 - val_acc: 0.9126\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9094 - val_loss: 0.1876 - val_acc: 0.9115\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18749 to 0.18748, saving model to best.model\n",
      "0s - loss: 0.1968 - acc: 0.9079 - val_loss: 0.1875 - val_acc: 0.9109\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1956 - acc: 0.9084 - val_loss: 0.1879 - val_acc: 0.9101\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1952 - acc: 0.9097 - val_loss: 0.1880 - val_acc: 0.9113\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9089 - val_loss: 0.1883 - val_acc: 0.9115\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18748 to 0.18716, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9077 - val_loss: 0.1872 - val_acc: 0.9101\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18716 to 0.18693, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9090 - val_loss: 0.1869 - val_acc: 0.9117\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18693 to 0.18685, saving model to best.model\n",
      "0s - loss: 0.1941 - acc: 0.9097 - val_loss: 0.1869 - val_acc: 0.9095\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9091 - val_loss: 0.1872 - val_acc: 0.9090\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18685 to 0.18654, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9095 - val_loss: 0.1865 - val_acc: 0.9099\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18654 to 0.18643, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9106 - val_loss: 0.1864 - val_acc: 0.9095\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9086 - val_loss: 0.1871 - val_acc: 0.9097\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9110 - val_loss: 0.1866 - val_acc: 0.9095\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9108 - val_loss: 0.1868 - val_acc: 0.9107\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1914 - acc: 0.9104 - val_loss: 0.1868 - val_acc: 0.9086\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18643 to 0.18606, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9109 - val_loss: 0.1861 - val_acc: 0.9092\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18606 to 0.18589, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9120 - val_loss: 0.1859 - val_acc: 0.9097\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9101 - val_loss: 0.1859 - val_acc: 0.9099\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9106 - val_loss: 0.1862 - val_acc: 0.9113\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9100 - val_loss: 0.1860 - val_acc: 0.9107\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18589 to 0.18565, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9118 - val_loss: 0.1857 - val_acc: 0.9107\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9114 - val_loss: 0.1866 - val_acc: 0.9094\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9110 - val_loss: 0.1858 - val_acc: 0.9086\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18565 to 0.18519, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9115 - val_loss: 0.1852 - val_acc: 0.9105\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9118 - val_loss: 0.1857 - val_acc: 0.9094\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9109 - val_loss: 0.1852 - val_acc: 0.9097\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9104 - val_loss: 0.1854 - val_acc: 0.9094\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18519 to 0.18495, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9118 - val_loss: 0.1849 - val_acc: 0.9101\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1872 - acc: 0.9144 - val_loss: 0.1851 - val_acc: 0.9099\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1872 - acc: 0.9126 - val_loss: 0.1855 - val_acc: 0.9094\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18495 to 0.18469, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9114 - val_loss: 0.1847 - val_acc: 0.9105\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18469 to 0.18445, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9117 - val_loss: 0.1844 - val_acc: 0.9113\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18445 to 0.18421, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9137 - val_loss: 0.1842 - val_acc: 0.9101\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9125 - val_loss: 0.1847 - val_acc: 0.9105\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9114 - val_loss: 0.1846 - val_acc: 0.9109\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9138 - val_loss: 0.1845 - val_acc: 0.9101\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18421 to 0.18412, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9137 - val_loss: 0.1841 - val_acc: 0.9111\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9145 - val_loss: 0.1843 - val_acc: 0.9103\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9140 - val_loss: 0.1842 - val_acc: 0.9115\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18412 to 0.18384, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9127 - val_loss: 0.1838 - val_acc: 0.9120\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18384 to 0.18367, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9155 - val_loss: 0.1837 - val_acc: 0.9113\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9149 - val_loss: 0.1839 - val_acc: 0.9122\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9127 - val_loss: 0.1837 - val_acc: 0.9124\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9133 - val_loss: 0.1844 - val_acc: 0.9103\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9136 - val_loss: 0.1840 - val_acc: 0.9128\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9134 - val_loss: 0.1838 - val_acc: 0.9130\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18367 to 0.18321, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9126 - val_loss: 0.1832 - val_acc: 0.9134\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9162 - val_loss: 0.1838 - val_acc: 0.9113\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9126 - val_loss: 0.1833 - val_acc: 0.9134\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9161 - val_loss: 0.1839 - val_acc: 0.9130\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9137 - val_loss: 0.1834 - val_acc: 0.9120\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18321 to 0.18312, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9131 - val_loss: 0.1831 - val_acc: 0.9124\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9151 - val_loss: 0.1832 - val_acc: 0.9128\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18312 to 0.18273, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9148 - val_loss: 0.1827 - val_acc: 0.9132\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "1s - loss: 0.1822 - acc: 0.9142 - val_loss: 0.1831 - val_acc: 0.9128\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9151 - val_loss: 0.1828 - val_acc: 0.9130\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9147 - val_loss: 0.1828 - val_acc: 0.9132\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18273 to 0.18244, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9143 - val_loss: 0.1824 - val_acc: 0.9143\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9151 - val_loss: 0.1829 - val_acc: 0.9130\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9158 - val_loss: 0.1826 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9148 - val_loss: 0.1825 - val_acc: 0.9145\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9144 - val_loss: 0.1833 - val_acc: 0.9128\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9138 - val_loss: 0.1828 - val_acc: 0.9118\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18244 to 0.18240, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9156 - val_loss: 0.1824 - val_acc: 0.9140\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18240 to 0.18198, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9147 - val_loss: 0.1820 - val_acc: 0.9145\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9155 - val_loss: 0.1822 - val_acc: 0.9149\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18198 to 0.18191, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9163 - val_loss: 0.1819 - val_acc: 0.9149\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9152 - val_loss: 0.1821 - val_acc: 0.9142\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9159 - val_loss: 0.1825 - val_acc: 0.9147\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18191 to 0.18173, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9159 - val_loss: 0.1817 - val_acc: 0.9145\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9150 - val_loss: 0.1819 - val_acc: 0.9140\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9154 - val_loss: 0.1821 - val_acc: 0.9140\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9159 - val_loss: 0.1821 - val_acc: 0.9134\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9124 - val_loss: 0.1827 - val_acc: 0.9082\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9164 - val_loss: 0.1823 - val_acc: 0.9134\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18173 to 0.18141, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9155 - val_loss: 0.1814 - val_acc: 0.9149\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9169 - val_loss: 0.1814 - val_acc: 0.9147\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.18141 to 0.18141, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9163 - val_loss: 0.1814 - val_acc: 0.9147\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18141 to 0.18126, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9159 - val_loss: 0.1813 - val_acc: 0.9138\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18126 to 0.18124, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9152 - val_loss: 0.1812 - val_acc: 0.9151\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18124 to 0.18094, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9153 - val_loss: 0.1809 - val_acc: 0.9155\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9151 - val_loss: 0.1811 - val_acc: 0.9155\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9161 - val_loss: 0.1815 - val_acc: 0.9132\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9159 - val_loss: 0.1810 - val_acc: 0.9145\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9163 - val_loss: 0.1818 - val_acc: 0.9122\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18094 to 0.18093, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9146 - val_loss: 0.1809 - val_acc: 0.9136\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18093 to 0.18084, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9150 - val_loss: 0.1808 - val_acc: 0.9140\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.18084 to 0.18061, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9162 - val_loss: 0.1806 - val_acc: 0.9145\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9164 - val_loss: 0.1809 - val_acc: 0.9126\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9160 - val_loss: 0.1809 - val_acc: 0.9153\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.18061 to 0.18043, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9158 - val_loss: 0.1804 - val_acc: 0.9142\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.18043 to 0.18034, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9157 - val_loss: 0.1803 - val_acc: 0.9142\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18034 to 0.18019, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9166 - val_loss: 0.1802 - val_acc: 0.9147\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18019 to 0.17981, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9175 - val_loss: 0.1798 - val_acc: 0.9145\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9165 - val_loss: 0.1801 - val_acc: 0.9138\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9170 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9168 - val_loss: 0.1800 - val_acc: 0.9159\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.17981 to 0.17958, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9167 - val_loss: 0.1796 - val_acc: 0.9140\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9160 - val_loss: 0.1797 - val_acc: 0.9140\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9180 - val_loss: 0.1798 - val_acc: 0.9149\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9180 - val_loss: 0.1799 - val_acc: 0.9122\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17958 to 0.17935, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9174 - val_loss: 0.1794 - val_acc: 0.9140\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.17935 to 0.17911, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9164 - val_loss: 0.1791 - val_acc: 0.9132\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9191 - val_loss: 0.1791 - val_acc: 0.9153\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9182 - val_loss: 0.1792 - val_acc: 0.9134\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9170 - val_loss: 0.1794 - val_acc: 0.9142\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17911 to 0.17910, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9182 - val_loss: 0.1791 - val_acc: 0.9142\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9175 - val_loss: 0.1793 - val_acc: 0.9124\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17910 to 0.17886, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9172 - val_loss: 0.1789 - val_acc: 0.9159\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.17886 to 0.17885, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9172 - val_loss: 0.1789 - val_acc: 0.9142\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17885 to 0.17846, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9189 - val_loss: 0.1785 - val_acc: 0.9149\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9182 - val_loss: 0.1786 - val_acc: 0.9124\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9178 - val_loss: 0.1787 - val_acc: 0.9147\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9182 - val_loss: 0.1788 - val_acc: 0.9153\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9185 - val_loss: 0.1785 - val_acc: 0.9165\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9180 - val_loss: 0.1786 - val_acc: 0.9120\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9175 - val_loss: 0.1786 - val_acc: 0.9142\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17846 to 0.17838, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9180 - val_loss: 0.1784 - val_acc: 0.9143\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9188 - val_loss: 0.1784 - val_acc: 0.9130\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9165 - val_loss: 0.1787 - val_acc: 0.9151\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17838 to 0.17806, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9187 - val_loss: 0.1781 - val_acc: 0.9149\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17806 to 0.17805, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9186 - val_loss: 0.1780 - val_acc: 0.9149\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9178 - val_loss: 0.1782 - val_acc: 0.9149\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17805 to 0.17782, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9175 - val_loss: 0.1778 - val_acc: 0.9165\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9171 - val_loss: 0.1779 - val_acc: 0.9142\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9179 - val_loss: 0.1779 - val_acc: 0.9151\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9185 - val_loss: 0.1780 - val_acc: 0.9165\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9190 - val_loss: 0.1782 - val_acc: 0.9147\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17782 to 0.17766, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9192 - val_loss: 0.1777 - val_acc: 0.9153\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9177 - val_loss: 0.1781 - val_acc: 0.9151\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9189 - val_loss: 0.1778 - val_acc: 0.9149\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9181 - val_loss: 0.1777 - val_acc: 0.9163\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17766 to 0.17764, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9195 - val_loss: 0.1776 - val_acc: 0.9157\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17764 to 0.17742, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9207 - val_loss: 0.1774 - val_acc: 0.9167\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9194 - val_loss: 0.1776 - val_acc: 0.9159\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17742 to 0.17727, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9212 - val_loss: 0.1773 - val_acc: 0.9165\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9180 - val_loss: 0.1777 - val_acc: 0.9157\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9186 - val_loss: 0.1774 - val_acc: 0.9168\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9187 - val_loss: 0.1773 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17727 to 0.17705, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9170 - val_loss: 0.1770 - val_acc: 0.9145\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17705 to 0.17700, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9180 - val_loss: 0.1770 - val_acc: 0.9153\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9192 - val_loss: 0.1770 - val_acc: 0.9151\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17700 to 0.17678, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9190 - val_loss: 0.1768 - val_acc: 0.9157\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9187 - val_loss: 0.1769 - val_acc: 0.9157\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9203 - val_loss: 0.1769 - val_acc: 0.9168\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9190 - val_loss: 0.1775 - val_acc: 0.9170\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9209 - val_loss: 0.1770 - val_acc: 0.9159\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9195 - val_loss: 0.1769 - val_acc: 0.9167\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9197 - val_loss: 0.1769 - val_acc: 0.9188\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17678 to 0.17677, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9199 - val_loss: 0.1768 - val_acc: 0.9147\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.17677 to 0.17636, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9199 - val_loss: 0.1764 - val_acc: 0.9193\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9221 - val_loss: 0.1772 - val_acc: 0.9168\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9179 - val_loss: 0.1764 - val_acc: 0.9163\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9194 - val_loss: 0.1766 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9199 - val_loss: 0.1769 - val_acc: 0.9174\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9197 - val_loss: 0.1771 - val_acc: 0.9174\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9203 - val_loss: 0.1768 - val_acc: 0.9155\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9192 - val_loss: 0.1767 - val_acc: 0.9165\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9185 - val_loss: 0.1766 - val_acc: 0.9174\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9204 - val_loss: 0.1764 - val_acc: 0.9182\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9201 - val_loss: 0.1765 - val_acc: 0.9176\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17636 to 0.17622, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9225 - val_loss: 0.1762 - val_acc: 0.9155\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9208 - val_loss: 0.1769 - val_acc: 0.9178\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9201 - val_loss: 0.1764 - val_acc: 0.9163\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17622 to 0.17606, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9221 - val_loss: 0.1761 - val_acc: 0.9176\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9211 - val_loss: 0.1764 - val_acc: 0.9182\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9203 - val_loss: 0.1765 - val_acc: 0.9180\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9213 - val_loss: 0.1769 - val_acc: 0.9178\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9205 - val_loss: 0.1763 - val_acc: 0.9186\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9200 - val_loss: 0.1765 - val_acc: 0.9180\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9215 - val_loss: 0.1767 - val_acc: 0.9174\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9191 - val_loss: 0.1778 - val_acc: 0.9180\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9189 - val_loss: 0.1765 - val_acc: 0.9167\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.17606 to 0.17601, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9218 - val_loss: 0.1760 - val_acc: 0.9180\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9200 - val_loss: 0.1765 - val_acc: 0.9159\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9217 - val_loss: 0.1770 - val_acc: 0.9149\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9203 - val_loss: 0.1761 - val_acc: 0.9172\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9202 - val_loss: 0.1764 - val_acc: 0.9170\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9203 - val_loss: 0.1764 - val_acc: 0.9176\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9202 - val_loss: 0.1764 - val_acc: 0.9180\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9212 - val_loss: 0.1761 - val_acc: 0.9168\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.17601 to 0.17577, saving model to best.model\n",
      "0s - loss: 0.1682 - acc: 0.9213 - val_loss: 0.1758 - val_acc: 0.9172\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9218 - val_loss: 0.1758 - val_acc: 0.9170\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34475, saving model to best.model\n",
      "0s - loss: 0.4367 - acc: 0.8533 - val_loss: 0.3448 - val_acc: 0.8892\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34475 to 0.28631, saving model to best.model\n",
      "0s - loss: 0.3430 - acc: 0.8890 - val_loss: 0.2863 - val_acc: 0.8892\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.28631 to 0.22910, saving model to best.model\n",
      "0s - loss: 0.2763 - acc: 0.8965 - val_loss: 0.2291 - val_acc: 0.9042\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22910 to 0.20297, saving model to best.model\n",
      "0s - loss: 0.2383 - acc: 0.9014 - val_loss: 0.2030 - val_acc: 0.9105\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20297 to 0.19743, saving model to best.model\n",
      "0s - loss: 0.2232 - acc: 0.9050 - val_loss: 0.1974 - val_acc: 0.9134\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19743 to 0.19367, saving model to best.model\n",
      "0s - loss: 0.2146 - acc: 0.9049 - val_loss: 0.1937 - val_acc: 0.9149\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19367 to 0.19253, saving model to best.model\n",
      "0s - loss: 0.2117 - acc: 0.9059 - val_loss: 0.1925 - val_acc: 0.9143\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19253 to 0.19245, saving model to best.model\n",
      "0s - loss: 0.2057 - acc: 0.9077 - val_loss: 0.1924 - val_acc: 0.9151\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2051 - acc: 0.9060 - val_loss: 0.1925 - val_acc: 0.9138\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19245 to 0.19197, saving model to best.model\n",
      "0s - loss: 0.2011 - acc: 0.9092 - val_loss: 0.1920 - val_acc: 0.9147\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19197 to 0.19004, saving model to best.model\n",
      "0s - loss: 0.1998 - acc: 0.9072 - val_loss: 0.1900 - val_acc: 0.9157\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2000 - acc: 0.9081 - val_loss: 0.1904 - val_acc: 0.9149\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1981 - acc: 0.9071 - val_loss: 0.1905 - val_acc: 0.9143\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9090 - val_loss: 0.1903 - val_acc: 0.9145\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9078 - val_loss: 0.1913 - val_acc: 0.9145\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19004 to 0.19002, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9095 - val_loss: 0.1900 - val_acc: 0.9145\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19002 to 0.18973, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9106 - val_loss: 0.1897 - val_acc: 0.9161\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9103 - val_loss: 0.1902 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9114 - val_loss: 0.1900 - val_acc: 0.9149\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18973 to 0.18895, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9106 - val_loss: 0.1889 - val_acc: 0.9153\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18895 to 0.18887, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9092 - val_loss: 0.1889 - val_acc: 0.9153\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9099 - val_loss: 0.1889 - val_acc: 0.9147\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18887 to 0.18832, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9098 - val_loss: 0.1883 - val_acc: 0.9155\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18832 to 0.18807, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9118 - val_loss: 0.1881 - val_acc: 0.9153\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9114 - val_loss: 0.1881 - val_acc: 0.9155\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9119 - val_loss: 0.1886 - val_acc: 0.9153\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1909 - acc: 0.9110 - val_loss: 0.1882 - val_acc: 0.9153\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18807 to 0.18743, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9126 - val_loss: 0.1874 - val_acc: 0.9153\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9131 - val_loss: 0.1876 - val_acc: 0.9145\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18743 to 0.18645, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9126 - val_loss: 0.1865 - val_acc: 0.9161\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9129 - val_loss: 0.1868 - val_acc: 0.9151\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9136 - val_loss: 0.1869 - val_acc: 0.9155\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9146 - val_loss: 0.1865 - val_acc: 0.9145\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18645 to 0.18600, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9137 - val_loss: 0.1860 - val_acc: 0.9142\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18600 to 0.18598, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9141 - val_loss: 0.1860 - val_acc: 0.9143\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9129 - val_loss: 0.1869 - val_acc: 0.9149\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9130 - val_loss: 0.1862 - val_acc: 0.9143\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18598 to 0.18533, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9148 - val_loss: 0.1853 - val_acc: 0.9145\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9152 - val_loss: 0.1857 - val_acc: 0.9149\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18533 to 0.18468, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9140 - val_loss: 0.1847 - val_acc: 0.9145\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9137 - val_loss: 0.1851 - val_acc: 0.9163\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9155 - val_loss: 0.1851 - val_acc: 0.9136\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9143 - val_loss: 0.1848 - val_acc: 0.9122\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9151 - val_loss: 0.1859 - val_acc: 0.9136\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18468 to 0.18441, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9152 - val_loss: 0.1844 - val_acc: 0.9163\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9145 - val_loss: 0.1858 - val_acc: 0.9118\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18441 to 0.18412, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9147 - val_loss: 0.1841 - val_acc: 0.9136\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18412 to 0.18402, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9144 - val_loss: 0.1840 - val_acc: 0.9122\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9150 - val_loss: 0.1841 - val_acc: 0.9120\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18402 to 0.18373, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9147 - val_loss: 0.1837 - val_acc: 0.9130\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9151 - val_loss: 0.1838 - val_acc: 0.9130\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9150 - val_loss: 0.1839 - val_acc: 0.9136\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9149 - val_loss: 0.1840 - val_acc: 0.9138\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9150 - val_loss: 0.1848 - val_acc: 0.9130\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18373 to 0.18299, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9157 - val_loss: 0.1830 - val_acc: 0.9126\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9147 - val_loss: 0.1835 - val_acc: 0.9134\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18299 to 0.18295, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9153 - val_loss: 0.1829 - val_acc: 0.9138\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9163 - val_loss: 0.1832 - val_acc: 0.9136\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18295 to 0.18285, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9159 - val_loss: 0.1828 - val_acc: 0.9136\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18285 to 0.18260, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9168 - val_loss: 0.1826 - val_acc: 0.9136\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18260 to 0.18255, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9163 - val_loss: 0.1826 - val_acc: 0.9136\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18255 to 0.18249, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9155 - val_loss: 0.1825 - val_acc: 0.9138\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9168 - val_loss: 0.1826 - val_acc: 0.9147\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9156 - val_loss: 0.1826 - val_acc: 0.9138\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9175 - val_loss: 0.1826 - val_acc: 0.9149\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18249 to 0.18228, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9166 - val_loss: 0.1823 - val_acc: 0.9155\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18228 to 0.18200, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9163 - val_loss: 0.1820 - val_acc: 0.9153\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9165 - val_loss: 0.1825 - val_acc: 0.9138\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18200 to 0.18191, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9173 - val_loss: 0.1819 - val_acc: 0.9140\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9150 - val_loss: 0.1820 - val_acc: 0.9140\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9174 - val_loss: 0.1819 - val_acc: 0.9143\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9167 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18191 to 0.18151, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9180 - val_loss: 0.1815 - val_acc: 0.9151\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9173 - val_loss: 0.1822 - val_acc: 0.9140\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18151 to 0.18134, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9154 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9175 - val_loss: 0.1815 - val_acc: 0.9140\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9175 - val_loss: 0.1815 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9180 - val_loss: 0.1814 - val_acc: 0.9145\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18134 to 0.18131, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9170 - val_loss: 0.1813 - val_acc: 0.9168\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.18131 to 0.18117, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9177 - val_loss: 0.1812 - val_acc: 0.9145\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18117 to 0.18098, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9180 - val_loss: 0.1810 - val_acc: 0.9167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9155 - val_loss: 0.1813 - val_acc: 0.9140\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9176 - val_loss: 0.1812 - val_acc: 0.9142\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9181 - val_loss: 0.1810 - val_acc: 0.9142\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.18098 to 0.18058, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9164 - val_loss: 0.1806 - val_acc: 0.9163\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9169 - val_loss: 0.1812 - val_acc: 0.9136\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9178 - val_loss: 0.1810 - val_acc: 0.9157\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9183 - val_loss: 0.1812 - val_acc: 0.9134\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9175 - val_loss: 0.1809 - val_acc: 0.9143\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9162 - val_loss: 0.1814 - val_acc: 0.9138\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18058 to 0.18048, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9184 - val_loss: 0.1805 - val_acc: 0.9155\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9183 - val_loss: 0.1808 - val_acc: 0.9138\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9168 - val_loss: 0.1806 - val_acc: 0.9157\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9173 - val_loss: 0.1808 - val_acc: 0.9149\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9183 - val_loss: 0.1807 - val_acc: 0.9149\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18048 to 0.18022, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9182 - val_loss: 0.1802 - val_acc: 0.9157\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9179 - val_loss: 0.1809 - val_acc: 0.9138\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9173 - val_loss: 0.1805 - val_acc: 0.9140\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9179 - val_loss: 0.1805 - val_acc: 0.9147\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18022 to 0.17991, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9190 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9198 - val_loss: 0.1803 - val_acc: 0.9159\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17991 to 0.17986, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9171 - val_loss: 0.1799 - val_acc: 0.9143\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9190 - val_loss: 0.1799 - val_acc: 0.9161\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17986 to 0.17956, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9195 - val_loss: 0.1796 - val_acc: 0.9149\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9185 - val_loss: 0.1797 - val_acc: 0.9161\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17956 to 0.17927, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9210 - val_loss: 0.1793 - val_acc: 0.9170\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9178 - val_loss: 0.1794 - val_acc: 0.9163\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9169 - val_loss: 0.1797 - val_acc: 0.9167\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9185 - val_loss: 0.1799 - val_acc: 0.9161\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9188 - val_loss: 0.1795 - val_acc: 0.9159\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9196 - val_loss: 0.1793 - val_acc: 0.9165\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17927 to 0.17925, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9191 - val_loss: 0.1793 - val_acc: 0.9155\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9188 - val_loss: 0.1800 - val_acc: 0.9140\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9186 - val_loss: 0.1796 - val_acc: 0.9155\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9187 - val_loss: 0.1797 - val_acc: 0.9161\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9183 - val_loss: 0.1804 - val_acc: 0.9145\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9190 - val_loss: 0.1803 - val_acc: 0.9163\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9195 - val_loss: 0.1796 - val_acc: 0.9147\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17925 to 0.17903, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9194 - val_loss: 0.1790 - val_acc: 0.9153\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9199 - val_loss: 0.1792 - val_acc: 0.9147\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9199 - val_loss: 0.1791 - val_acc: 0.9157\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9206 - val_loss: 0.1799 - val_acc: 0.9142\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9181 - val_loss: 0.1794 - val_acc: 0.9136\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17903 to 0.17895, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9182 - val_loss: 0.1790 - val_acc: 0.9143\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9194 - val_loss: 0.1799 - val_acc: 0.9138\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17895 to 0.17887, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9216 - val_loss: 0.1789 - val_acc: 0.9163\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9198 - val_loss: 0.1793 - val_acc: 0.9163\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17887 to 0.17878, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9184 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9192 - val_loss: 0.1789 - val_acc: 0.9163\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9204 - val_loss: 0.1790 - val_acc: 0.9170\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9204 - val_loss: 0.1791 - val_acc: 0.9155\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "1s - loss: 0.1715 - acc: 0.9198 - val_loss: 0.1791 - val_acc: 0.9168\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9194 - val_loss: 0.1794 - val_acc: 0.9167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9200 - val_loss: 0.1789 - val_acc: 0.9159\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9203 - val_loss: 0.1792 - val_acc: 0.9165\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17878 to 0.17859, saving model to best.model\n",
      "0s - loss: 0.1706 - acc: 0.9206 - val_loss: 0.1786 - val_acc: 0.9170\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17859 to 0.17842, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9216 - val_loss: 0.1784 - val_acc: 0.9170\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9199 - val_loss: 0.1784 - val_acc: 0.9176\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9207 - val_loss: 0.1792 - val_acc: 0.9174\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9180 - val_loss: 0.1796 - val_acc: 0.9145\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9203 - val_loss: 0.1792 - val_acc: 0.9134\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9203 - val_loss: 0.1790 - val_acc: 0.9163\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9202 - val_loss: 0.1793 - val_acc: 0.9176\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9217 - val_loss: 0.1790 - val_acc: 0.9161\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9208 - val_loss: 0.1803 - val_acc: 0.9163\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9205 - val_loss: 0.1790 - val_acc: 0.9174\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9210 - val_loss: 0.1788 - val_acc: 0.9178\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9203 - val_loss: 0.1810 - val_acc: 0.9161\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9206 - val_loss: 0.1785 - val_acc: 0.9167\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9189 - val_loss: 0.1795 - val_acc: 0.9155\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9217 - val_loss: 0.1804 - val_acc: 0.9176\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9207 - val_loss: 0.1793 - val_acc: 0.9161\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "1s - loss: 0.1689 - acc: 0.9200 - val_loss: 0.1787 - val_acc: 0.9159\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17842 to 0.17815, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9198 - val_loss: 0.1781 - val_acc: 0.9182\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9214 - val_loss: 0.1788 - val_acc: 0.9168\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9213 - val_loss: 0.1805 - val_acc: 0.9165\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9205 - val_loss: 0.1797 - val_acc: 0.9149\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9217 - val_loss: 0.1789 - val_acc: 0.9170\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9211 - val_loss: 0.1786 - val_acc: 0.9168\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9222 - val_loss: 0.1804 - val_acc: 0.9170\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9221 - val_loss: 0.1783 - val_acc: 0.9172\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9225 - val_loss: 0.1794 - val_acc: 0.9174\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9213 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9200 - val_loss: 0.1787 - val_acc: 0.9159\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9205 - val_loss: 0.1791 - val_acc: 0.9176\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9210 - val_loss: 0.1792 - val_acc: 0.9142\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9210 - val_loss: 0.1789 - val_acc: 0.9172\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9215 - val_loss: 0.1782 - val_acc: 0.9165\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9206 - val_loss: 0.1793 - val_acc: 0.9157\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9228 - val_loss: 0.1787 - val_acc: 0.9170\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9213 - val_loss: 0.1784 - val_acc: 0.9155\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9219 - val_loss: 0.1782 - val_acc: 0.9172\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17815 to 0.17805, saving model to best.model\n",
      "0s - loss: 0.1671 - acc: 0.9221 - val_loss: 0.1780 - val_acc: 0.9182\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9230 - val_loss: 0.1785 - val_acc: 0.9178\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9211 - val_loss: 0.1782 - val_acc: 0.9161\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9219 - val_loss: 0.1783 - val_acc: 0.9184\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.17805 to 0.17802, saving model to best.model\n",
      "0s - loss: 0.1657 - acc: 0.9231 - val_loss: 0.1780 - val_acc: 0.9161\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9215 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17802 to 0.17753, saving model to best.model\n",
      "0s - loss: 0.1670 - acc: 0.9206 - val_loss: 0.1775 - val_acc: 0.9178\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1664 - acc: 0.9218 - val_loss: 0.1779 - val_acc: 0.9184\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1648 - acc: 0.9232 - val_loss: 0.1779 - val_acc: 0.9188\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1644 - acc: 0.9228 - val_loss: 0.1799 - val_acc: 0.9161\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9216 - val_loss: 0.1779 - val_acc: 0.9159\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1664 - acc: 0.9221 - val_loss: 0.1777 - val_acc: 0.9163\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17753 to 0.17744, saving model to best.model\n",
      "0s - loss: 0.1657 - acc: 0.9208 - val_loss: 0.1774 - val_acc: 0.9155\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1655 - acc: 0.9218 - val_loss: 0.1779 - val_acc: 0.9191\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1635 - acc: 0.9220 - val_loss: 0.1781 - val_acc: 0.9178\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9220 - val_loss: 0.1783 - val_acc: 0.9168\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9235 - val_loss: 0.1777 - val_acc: 0.9163\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9213 - val_loss: 0.1782 - val_acc: 0.9182\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1652 - acc: 0.9222 - val_loss: 0.1781 - val_acc: 0.9153\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9215 - val_loss: 0.1787 - val_acc: 0.9161\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9227 - val_loss: 0.1777 - val_acc: 0.9186\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1644 - acc: 0.9226 - val_loss: 0.1783 - val_acc: 0.9182\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1636 - acc: 0.9219 - val_loss: 0.1776 - val_acc: 0.9186\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1633 - acc: 0.9230 - val_loss: 0.1807 - val_acc: 0.9151\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9227 - val_loss: 0.1782 - val_acc: 0.9165\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "1s - loss: 0.1634 - acc: 0.9227 - val_loss: 0.1778 - val_acc: 0.9147\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1635 - acc: 0.9221 - val_loss: 0.1792 - val_acc: 0.9170\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1638 - acc: 0.9223 - val_loss: 0.1791 - val_acc: 0.9163\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32618, saving model to best.model\n",
      "1s - loss: 0.3998 - acc: 0.8750 - val_loss: 0.3262 - val_acc: 0.8894\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32618 to 0.23677, saving model to best.model\n",
      "0s - loss: 0.3130 - acc: 0.8871 - val_loss: 0.2368 - val_acc: 0.9038\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23677 to 0.20922, saving model to best.model\n",
      "0s - loss: 0.2492 - acc: 0.8953 - val_loss: 0.2092 - val_acc: 0.9076\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20922 to 0.20007, saving model to best.model\n",
      "0s - loss: 0.2263 - acc: 0.9016 - val_loss: 0.2001 - val_acc: 0.9115\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20007 to 0.19828, saving model to best.model\n",
      "0s - loss: 0.2151 - acc: 0.9026 - val_loss: 0.1983 - val_acc: 0.9105\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19828 to 0.19598, saving model to best.model\n",
      "0s - loss: 0.2108 - acc: 0.9038 - val_loss: 0.1960 - val_acc: 0.9124\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19598 to 0.19531, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9056 - val_loss: 0.1953 - val_acc: 0.9109\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2027 - acc: 0.9062 - val_loss: 0.1965 - val_acc: 0.9120\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19531 to 0.19500, saving model to best.model\n",
      "0s - loss: 0.2024 - acc: 0.9042 - val_loss: 0.1950 - val_acc: 0.9113\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.1992 - acc: 0.9067 - val_loss: 0.1953 - val_acc: 0.9105\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1994 - acc: 0.9078 - val_loss: 0.1951 - val_acc: 0.9109\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1972 - acc: 0.9084 - val_loss: 0.1962 - val_acc: 0.9103\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1967 - acc: 0.9056 - val_loss: 0.1957 - val_acc: 0.9076\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1995 - acc: 0.9068 - val_loss: 0.1952 - val_acc: 0.9095\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19500 to 0.19476, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9089 - val_loss: 0.1948 - val_acc: 0.9103\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9092 - val_loss: 0.1952 - val_acc: 0.9095\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19476 to 0.19476, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9077 - val_loss: 0.1948 - val_acc: 0.9109\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9067 - val_loss: 0.1948 - val_acc: 0.9084\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19476 to 0.19472, saving model to best.model\n",
      "0s - loss: 0.1941 - acc: 0.9079 - val_loss: 0.1947 - val_acc: 0.9103\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19472 to 0.19456, saving model to best.model\n",
      "0s - loss: 0.1968 - acc: 0.9083 - val_loss: 0.1946 - val_acc: 0.9099\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19456 to 0.19390, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9065 - val_loss: 0.1939 - val_acc: 0.9095\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19390 to 0.19360, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9072 - val_loss: 0.1936 - val_acc: 0.9107\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9085 - val_loss: 0.1941 - val_acc: 0.9099\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1925 - acc: 0.9105 - val_loss: 0.1942 - val_acc: 0.9109\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19360 to 0.19339, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9095 - val_loss: 0.1934 - val_acc: 0.9099\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19339 to 0.19333, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9072 - val_loss: 0.1933 - val_acc: 0.9105\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19333 to 0.19275, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9086 - val_loss: 0.1928 - val_acc: 0.9103\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9076 - val_loss: 0.1932 - val_acc: 0.9092\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19275 to 0.19262, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9095 - val_loss: 0.1926 - val_acc: 0.9092\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9087 - val_loss: 0.1929 - val_acc: 0.9092\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9095 - val_loss: 0.1927 - val_acc: 0.9095\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19262 to 0.19241, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9094 - val_loss: 0.1924 - val_acc: 0.9095\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9106 - val_loss: 0.1927 - val_acc: 0.9092\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19241 to 0.19178, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9094 - val_loss: 0.1918 - val_acc: 0.9097\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9099 - val_loss: 0.1932 - val_acc: 0.9103\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9097 - val_loss: 0.1937 - val_acc: 0.9113\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9097 - val_loss: 0.1922 - val_acc: 0.9099\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9109 - val_loss: 0.1918 - val_acc: 0.9092\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19178 to 0.19131, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9092 - val_loss: 0.1913 - val_acc: 0.9105\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9096 - val_loss: 0.1913 - val_acc: 0.9092\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9109 - val_loss: 0.1920 - val_acc: 0.9090\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19131 to 0.19102, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9102 - val_loss: 0.1910 - val_acc: 0.9099\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9105 - val_loss: 0.1912 - val_acc: 0.9105\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.19102 to 0.19040, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9112 - val_loss: 0.1904 - val_acc: 0.9107\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9112 - val_loss: 0.1908 - val_acc: 0.9099\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9117 - val_loss: 0.1917 - val_acc: 0.9092\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9120 - val_loss: 0.1904 - val_acc: 0.9107\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.19040 to 0.19036, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9110 - val_loss: 0.1904 - val_acc: 0.9111\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9110 - val_loss: 0.1916 - val_acc: 0.9124\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.19036 to 0.19013, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9121 - val_loss: 0.1901 - val_acc: 0.9126\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9121 - val_loss: 0.1908 - val_acc: 0.9115\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19013 to 0.18979, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9108 - val_loss: 0.1898 - val_acc: 0.9126\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18979 to 0.18948, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9135 - val_loss: 0.1895 - val_acc: 0.9118\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18948 to 0.18896, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9125 - val_loss: 0.1890 - val_acc: 0.9134\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9111 - val_loss: 0.1906 - val_acc: 0.9105\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9120 - val_loss: 0.1909 - val_acc: 0.9111\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9122 - val_loss: 0.1897 - val_acc: 0.9132\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9132 - val_loss: 0.1907 - val_acc: 0.9132\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18896 to 0.18855, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9119 - val_loss: 0.1886 - val_acc: 0.9136\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9109 - val_loss: 0.1888 - val_acc: 0.9130\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9132 - val_loss: 0.1894 - val_acc: 0.9130\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9107 - val_loss: 0.1890 - val_acc: 0.9149\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9131 - val_loss: 0.1890 - val_acc: 0.9134\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9130 - val_loss: 0.1886 - val_acc: 0.9124\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18855 to 0.18824, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9127 - val_loss: 0.1882 - val_acc: 0.9140\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9119 - val_loss: 0.1896 - val_acc: 0.9124\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9119 - val_loss: 0.1888 - val_acc: 0.9120\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9139 - val_loss: 0.1883 - val_acc: 0.9147\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18824 to 0.18818, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9134 - val_loss: 0.1882 - val_acc: 0.9143\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18818 to 0.18778, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9131 - val_loss: 0.1878 - val_acc: 0.9147\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9135 - val_loss: 0.1880 - val_acc: 0.9143\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18778 to 0.18777, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9126 - val_loss: 0.1878 - val_acc: 0.9149\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18777 to 0.18723, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9142 - val_loss: 0.1872 - val_acc: 0.9149\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9140 - val_loss: 0.1881 - val_acc: 0.9145\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9140 - val_loss: 0.1879 - val_acc: 0.9143\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9130 - val_loss: 0.1879 - val_acc: 0.9142\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9135 - val_loss: 0.1885 - val_acc: 0.9145\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9151 - val_loss: 0.1879 - val_acc: 0.9149\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9146 - val_loss: 0.1896 - val_acc: 0.9147\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9145 - val_loss: 0.1877 - val_acc: 0.9145\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9148 - val_loss: 0.1881 - val_acc: 0.9105\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9138 - val_loss: 0.1882 - val_acc: 0.9145\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.18723 to 0.18678, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9147 - val_loss: 0.1868 - val_acc: 0.9143\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9145 - val_loss: 0.1887 - val_acc: 0.9147\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9134 - val_loss: 0.1873 - val_acc: 0.9143\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9150 - val_loss: 0.1884 - val_acc: 0.9142\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9171 - val_loss: 0.1880 - val_acc: 0.9143\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9140 - val_loss: 0.1869 - val_acc: 0.9140\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9138 - val_loss: 0.1876 - val_acc: 0.9143\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9155 - val_loss: 0.1871 - val_acc: 0.9140\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9139 - val_loss: 0.1871 - val_acc: 0.9142\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18678 to 0.18669, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9141 - val_loss: 0.1867 - val_acc: 0.9151\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9141 - val_loss: 0.1871 - val_acc: 0.9145\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9159 - val_loss: 0.1871 - val_acc: 0.9142\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.18669 to 0.18608, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9155 - val_loss: 0.1861 - val_acc: 0.9138\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18608 to 0.18600, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9161 - val_loss: 0.1860 - val_acc: 0.9145\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9156 - val_loss: 0.1865 - val_acc: 0.9145\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1869 - val_acc: 0.9138\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9160 - val_loss: 0.1866 - val_acc: 0.9143\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9156 - val_loss: 0.1880 - val_acc: 0.9126\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9152 - val_loss: 0.1872 - val_acc: 0.9142\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18600 to 0.18558, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9155 - val_loss: 0.1856 - val_acc: 0.9147\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9151 - val_loss: 0.1857 - val_acc: 0.9130\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9175 - val_loss: 0.1863 - val_acc: 0.9126\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9157 - val_loss: 0.1867 - val_acc: 0.9136\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9173 - val_loss: 0.1865 - val_acc: 0.9140\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9168 - val_loss: 0.1862 - val_acc: 0.9128\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9161 - val_loss: 0.1864 - val_acc: 0.9138\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9169 - val_loss: 0.1859 - val_acc: 0.9138\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "1s - loss: 0.1787 - acc: 0.9166 - val_loss: 0.1856 - val_acc: 0.9130\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9173 - val_loss: 0.1863 - val_acc: 0.9132\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9171 - val_loss: 0.1872 - val_acc: 0.9140\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.18558 to 0.18544, saving model to best.model\n",
      "1s - loss: 0.1782 - acc: 0.9174 - val_loss: 0.1854 - val_acc: 0.9130\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9181 - val_loss: 0.1855 - val_acc: 0.9128\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9163 - val_loss: 0.1870 - val_acc: 0.9128\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9170 - val_loss: 0.1865 - val_acc: 0.9145\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.18544 to 0.18498, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9160 - val_loss: 0.1850 - val_acc: 0.9138\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9171 - val_loss: 0.1851 - val_acc: 0.9130\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9163 - val_loss: 0.1861 - val_acc: 0.9138\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9188 - val_loss: 0.1860 - val_acc: 0.9130\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.18498 to 0.18469, saving model to best.model\n",
      "0s - loss: 0.1771 - acc: 0.9164 - val_loss: 0.1847 - val_acc: 0.9130\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9176 - val_loss: 0.1859 - val_acc: 0.9117\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9166 - val_loss: 0.1859 - val_acc: 0.9134\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9181 - val_loss: 0.1852 - val_acc: 0.9132\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9180 - val_loss: 0.1849 - val_acc: 0.9134\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9180 - val_loss: 0.1850 - val_acc: 0.9142\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18469 to 0.18442, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9166 - val_loss: 0.1844 - val_acc: 0.9128\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9186 - val_loss: 0.1857 - val_acc: 0.9128\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9175 - val_loss: 0.1862 - val_acc: 0.9130\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9176 - val_loss: 0.1849 - val_acc: 0.9136\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9187 - val_loss: 0.1854 - val_acc: 0.9118\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9174 - val_loss: 0.1857 - val_acc: 0.9122\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9194 - val_loss: 0.1856 - val_acc: 0.9140\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.18442 to 0.18399, saving model to best.model\n",
      "0s - loss: 0.1771 - acc: 0.9176 - val_loss: 0.1840 - val_acc: 0.9124\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "1s - loss: 0.1761 - acc: 0.9177 - val_loss: 0.1845 - val_acc: 0.9140\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9191 - val_loss: 0.1859 - val_acc: 0.9130\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9177 - val_loss: 0.1844 - val_acc: 0.9124\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "1s - loss: 0.1751 - acc: 0.9187 - val_loss: 0.1846 - val_acc: 0.9134\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9183 - val_loss: 0.1850 - val_acc: 0.9128\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9181 - val_loss: 0.1845 - val_acc: 0.9134\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9197 - val_loss: 0.1852 - val_acc: 0.9142\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9170 - val_loss: 0.1856 - val_acc: 0.9132\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9189 - val_loss: 0.1844 - val_acc: 0.9118\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9179 - val_loss: 0.1842 - val_acc: 0.9136\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9179 - val_loss: 0.1843 - val_acc: 0.9134\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9177 - val_loss: 0.1853 - val_acc: 0.9140\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18399 to 0.18329, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9192 - val_loss: 0.1833 - val_acc: 0.9143\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9174 - val_loss: 0.1847 - val_acc: 0.9138\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9184 - val_loss: 0.1846 - val_acc: 0.9130\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9197 - val_loss: 0.1840 - val_acc: 0.9124\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9183 - val_loss: 0.1840 - val_acc: 0.9124\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9186 - val_loss: 0.1845 - val_acc: 0.9130\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9183 - val_loss: 0.1843 - val_acc: 0.9140\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9194 - val_loss: 0.1841 - val_acc: 0.9143\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9179 - val_loss: 0.1843 - val_acc: 0.9147\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9187 - val_loss: 0.1845 - val_acc: 0.9136\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9188 - val_loss: 0.1848 - val_acc: 0.9142\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9191 - val_loss: 0.1837 - val_acc: 0.9149\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9190 - val_loss: 0.1835 - val_acc: 0.9134\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9190 - val_loss: 0.1859 - val_acc: 0.9149\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9205 - val_loss: 0.1847 - val_acc: 0.9136\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9192 - val_loss: 0.1849 - val_acc: 0.9142\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9205 - val_loss: 0.1839 - val_acc: 0.9132\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9211 - val_loss: 0.1839 - val_acc: 0.9134\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9184 - val_loss: 0.1840 - val_acc: 0.9132\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.18329 to 0.18260, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9184 - val_loss: 0.1826 - val_acc: 0.9134\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9200 - val_loss: 0.1847 - val_acc: 0.9136\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9200 - val_loss: 0.1848 - val_acc: 0.9143\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9184 - val_loss: 0.1832 - val_acc: 0.9142\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.18260 to 0.18259, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9197 - val_loss: 0.1826 - val_acc: 0.9143\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9196 - val_loss: 0.1828 - val_acc: 0.9128\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9211 - val_loss: 0.1827 - val_acc: 0.9151\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9209 - val_loss: 0.1849 - val_acc: 0.9140\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9194 - val_loss: 0.1830 - val_acc: 0.9132\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9216 - val_loss: 0.1832 - val_acc: 0.9143\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9199 - val_loss: 0.1826 - val_acc: 0.9143\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9208 - val_loss: 0.1831 - val_acc: 0.9130\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9212 - val_loss: 0.1826 - val_acc: 0.9145\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9205 - val_loss: 0.1829 - val_acc: 0.9132\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9220 - val_loss: 0.1827 - val_acc: 0.9138\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9207 - val_loss: 0.1839 - val_acc: 0.9130\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9214 - val_loss: 0.1832 - val_acc: 0.9130\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.18259 to 0.18198, saving model to best.model\n",
      "0s - loss: 0.1705 - acc: 0.9214 - val_loss: 0.1820 - val_acc: 0.9155\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9200 - val_loss: 0.1835 - val_acc: 0.9143\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "1s - loss: 0.1699 - acc: 0.9219 - val_loss: 0.1830 - val_acc: 0.9126\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9202 - val_loss: 0.1826 - val_acc: 0.9130\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.18198 to 0.18198, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9204 - val_loss: 0.1820 - val_acc: 0.9149\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9205 - val_loss: 0.1820 - val_acc: 0.9145\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.18198 to 0.18175, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9201 - val_loss: 0.1818 - val_acc: 0.9149\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9212 - val_loss: 0.1818 - val_acc: 0.9134\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9204 - val_loss: 0.1826 - val_acc: 0.9143\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9219 - val_loss: 0.1822 - val_acc: 0.9128\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9213 - val_loss: 0.1837 - val_acc: 0.9140\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9209 - val_loss: 0.1861 - val_acc: 0.9149\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.18175 to 0.18103, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9210 - val_loss: 0.1810 - val_acc: 0.9120\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9216 - val_loss: 0.1829 - val_acc: 0.9134\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9224 - val_loss: 0.1817 - val_acc: 0.9130\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9208 - val_loss: 0.1822 - val_acc: 0.9147\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9214 - val_loss: 0.1818 - val_acc: 0.9147\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9229 - val_loss: 0.1824 - val_acc: 0.9136\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34685, saving model to best.model\n",
      "0s - loss: 0.3970 - acc: 0.8764 - val_loss: 0.3469 - val_acc: 0.8821\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34685 to 0.25680, saving model to best.model\n",
      "0s - loss: 0.3164 - acc: 0.8894 - val_loss: 0.2568 - val_acc: 0.8951\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25680 to 0.21902, saving model to best.model\n",
      "0s - loss: 0.2572 - acc: 0.8942 - val_loss: 0.2190 - val_acc: 0.9003\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21902 to 0.21056, saving model to best.model\n",
      "0s - loss: 0.2320 - acc: 0.9012 - val_loss: 0.2106 - val_acc: 0.9024\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.21056 to 0.20794, saving model to best.model\n",
      "0s - loss: 0.2236 - acc: 0.9007 - val_loss: 0.2079 - val_acc: 0.9013\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20794 to 0.20630, saving model to best.model\n",
      "0s - loss: 0.2166 - acc: 0.9017 - val_loss: 0.2063 - val_acc: 0.9024\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.20630 to 0.20306, saving model to best.model\n",
      "0s - loss: 0.2098 - acc: 0.9039 - val_loss: 0.2031 - val_acc: 0.9038\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.20306 to 0.20237, saving model to best.model\n",
      "0s - loss: 0.2089 - acc: 0.9034 - val_loss: 0.2024 - val_acc: 0.9032\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2079 - acc: 0.9022 - val_loss: 0.2025 - val_acc: 0.9036\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.20237 to 0.20198, saving model to best.model\n",
      "0s - loss: 0.2057 - acc: 0.9019 - val_loss: 0.2020 - val_acc: 0.9040\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.20198 to 0.20182, saving model to best.model\n",
      "0s - loss: 0.2046 - acc: 0.9025 - val_loss: 0.2018 - val_acc: 0.9042\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2040 - acc: 0.9042 - val_loss: 0.2019 - val_acc: 0.9044\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2031 - acc: 0.9051 - val_loss: 0.2019 - val_acc: 0.9042\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.20182 to 0.20178, saving model to best.model\n",
      "0s - loss: 0.2028 - acc: 0.9040 - val_loss: 0.2018 - val_acc: 0.9040\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1994 - acc: 0.9037 - val_loss: 0.2019 - val_acc: 0.9042\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2015 - acc: 0.9042 - val_loss: 0.2023 - val_acc: 0.9038\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9026 - val_loss: 0.2021 - val_acc: 0.9036\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2015 - acc: 0.9050 - val_loss: 0.2020 - val_acc: 0.9038\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.20178 to 0.20140, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9036 - val_loss: 0.2014 - val_acc: 0.9038\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1997 - acc: 0.9041 - val_loss: 0.2030 - val_acc: 0.9011\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2021 - acc: 0.9031 - val_loss: 0.2015 - val_acc: 0.9042\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.20140 to 0.20110, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9056 - val_loss: 0.2011 - val_acc: 0.9044\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9039 - val_loss: 0.2023 - val_acc: 0.9017\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9045 - val_loss: 0.2015 - val_acc: 0.9040\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20110 to 0.20077, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9036 - val_loss: 0.2008 - val_acc: 0.9032\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20077 to 0.20068, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9053 - val_loss: 0.2007 - val_acc: 0.9042\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20068 to 0.20028, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9053 - val_loss: 0.2003 - val_acc: 0.9053\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20028 to 0.20006, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9056 - val_loss: 0.2001 - val_acc: 0.9042\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20006 to 0.19994, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9053 - val_loss: 0.1999 - val_acc: 0.9049\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1954 - acc: 0.9062 - val_loss: 0.2000 - val_acc: 0.9049\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19994 to 0.19921, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9051 - val_loss: 0.1992 - val_acc: 0.9042\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1953 - acc: 0.9059 - val_loss: 0.1995 - val_acc: 0.9053\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1953 - acc: 0.9059 - val_loss: 0.1995 - val_acc: 0.9013\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1959 - acc: 0.9062 - val_loss: 0.1999 - val_acc: 0.9011\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19921 to 0.19855, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9050 - val_loss: 0.1986 - val_acc: 0.9053\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9057 - val_loss: 0.1989 - val_acc: 0.9028\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19855 to 0.19806, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9084 - val_loss: 0.1981 - val_acc: 0.9040\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19806 to 0.19773, saving model to best.model\n",
      "0s - loss: 0.1955 - acc: 0.9061 - val_loss: 0.1977 - val_acc: 0.9046\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9074 - val_loss: 0.1983 - val_acc: 0.9009\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9076 - val_loss: 0.1991 - val_acc: 0.9013\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19773 to 0.19720, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9070 - val_loss: 0.1972 - val_acc: 0.9044\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9071 - val_loss: 0.1975 - val_acc: 0.9026\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19720 to 0.19709, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9073 - val_loss: 0.1971 - val_acc: 0.9024\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9080 - val_loss: 0.1973 - val_acc: 0.9022\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19709 to 0.19684, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9081 - val_loss: 0.1968 - val_acc: 0.9019\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19684 to 0.19669, saving model to best.model\n",
      "1s - loss: 0.1929 - acc: 0.9079 - val_loss: 0.1967 - val_acc: 0.9026\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.19669 to 0.19621, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9077 - val_loss: 0.1962 - val_acc: 0.9053\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.19621 to 0.19608, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9078 - val_loss: 0.1961 - val_acc: 0.9032\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9086 - val_loss: 0.1965 - val_acc: 0.9032\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.19608 to 0.19593, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9090 - val_loss: 0.1959 - val_acc: 0.9036\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9103 - val_loss: 0.1979 - val_acc: 0.9030\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19593 to 0.19544, saving model to best.model\n",
      "0s - loss: 0.1925 - acc: 0.9067 - val_loss: 0.1954 - val_acc: 0.9046\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.19544 to 0.19511, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9089 - val_loss: 0.1951 - val_acc: 0.9042\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9091 - val_loss: 0.1964 - val_acc: 0.9026\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.19511 to 0.19480, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9096 - val_loss: 0.1948 - val_acc: 0.9057\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9099 - val_loss: 0.1954 - val_acc: 0.9053\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.19480 to 0.19462, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9087 - val_loss: 0.1946 - val_acc: 0.9051\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9089 - val_loss: 0.1950 - val_acc: 0.9061\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9081 - val_loss: 0.1955 - val_acc: 0.9044\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9078 - val_loss: 0.1952 - val_acc: 0.9038\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.19462 to 0.19414, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9083 - val_loss: 0.1941 - val_acc: 0.9069\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9081 - val_loss: 0.1950 - val_acc: 0.9055\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.19414 to 0.19385, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9083 - val_loss: 0.1938 - val_acc: 0.9074\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.19385 to 0.19359, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9107 - val_loss: 0.1936 - val_acc: 0.9080\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9103 - val_loss: 0.1936 - val_acc: 0.9070\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.19359 to 0.19338, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9094 - val_loss: 0.1934 - val_acc: 0.9086\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9109 - val_loss: 0.1941 - val_acc: 0.9065\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.19338 to 0.19319, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9096 - val_loss: 0.1932 - val_acc: 0.9074\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.19319 to 0.19308, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9107 - val_loss: 0.1931 - val_acc: 0.9065\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9105 - val_loss: 0.1945 - val_acc: 0.9057\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.19308 to 0.19275, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9106 - val_loss: 0.1927 - val_acc: 0.9088\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.19275 to 0.19244, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9102 - val_loss: 0.1924 - val_acc: 0.9069\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9094 - val_loss: 0.1937 - val_acc: 0.9070\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9121 - val_loss: 0.1935 - val_acc: 0.9065\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.19244 to 0.19197, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9115 - val_loss: 0.1920 - val_acc: 0.9067\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9114 - val_loss: 0.1922 - val_acc: 0.9080\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9113 - val_loss: 0.1924 - val_acc: 0.9086\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.19197 to 0.19192, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9107 - val_loss: 0.1919 - val_acc: 0.9090\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9118 - val_loss: 0.1923 - val_acc: 0.9070\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.19192 to 0.19159, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9127 - val_loss: 0.1916 - val_acc: 0.9084\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.19159 to 0.19155, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9127 - val_loss: 0.1915 - val_acc: 0.9094\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.19155 to 0.19150, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9114 - val_loss: 0.1915 - val_acc: 0.9082\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.19150 to 0.19149, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9111 - val_loss: 0.1915 - val_acc: 0.9067\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.19149 to 0.19123, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9118 - val_loss: 0.1912 - val_acc: 0.9097\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9119 - val_loss: 0.1918 - val_acc: 0.9069\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9117 - val_loss: 0.1915 - val_acc: 0.9074\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9126 - val_loss: 0.1918 - val_acc: 0.9078\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.19123 to 0.19081, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9123 - val_loss: 0.1908 - val_acc: 0.9094\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9127 - val_loss: 0.1919 - val_acc: 0.9074\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9119 - val_loss: 0.1908 - val_acc: 0.9070\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9121 - val_loss: 0.1910 - val_acc: 0.9069\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9126 - val_loss: 0.1914 - val_acc: 0.9070\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9121 - val_loss: 0.1911 - val_acc: 0.9070\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.19081 to 0.19045, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9118 - val_loss: 0.1905 - val_acc: 0.9097\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9137 - val_loss: 0.1907 - val_acc: 0.9101\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9120 - val_loss: 0.1905 - val_acc: 0.9092\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.19045 to 0.19045, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9123 - val_loss: 0.1904 - val_acc: 0.9080\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.19045 to 0.19005, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9126 - val_loss: 0.1900 - val_acc: 0.9094\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9134 - val_loss: 0.1904 - val_acc: 0.9076\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9140 - val_loss: 0.1902 - val_acc: 0.9088\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9122 - val_loss: 0.1911 - val_acc: 0.9078\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9104 - val_loss: 0.1911 - val_acc: 0.9082\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9114 - val_loss: 0.1903 - val_acc: 0.9103\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9130 - val_loss: 0.1905 - val_acc: 0.9099\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.19005 to 0.18950, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9120 - val_loss: 0.1895 - val_acc: 0.9103\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9131 - val_loss: 0.1896 - val_acc: 0.9103\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9125 - val_loss: 0.1898 - val_acc: 0.9072\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.18950 to 0.18927, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9134 - val_loss: 0.1893 - val_acc: 0.9103\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.18927 to 0.18923, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9147 - val_loss: 0.1892 - val_acc: 0.9101\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9133 - val_loss: 0.1899 - val_acc: 0.9103\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9113 - val_loss: 0.1895 - val_acc: 0.9105\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9124 - val_loss: 0.1903 - val_acc: 0.9097\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9122 - val_loss: 0.1896 - val_acc: 0.9090\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9144 - val_loss: 0.1905 - val_acc: 0.9078\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9136 - val_loss: 0.1898 - val_acc: 0.9099\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9129 - val_loss: 0.1905 - val_acc: 0.9086\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "1s - loss: 0.1782 - acc: 0.9124 - val_loss: 0.1895 - val_acc: 0.9109\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18923 to 0.18914, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9123 - val_loss: 0.1891 - val_acc: 0.9107\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18914 to 0.18903, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9128 - val_loss: 0.1890 - val_acc: 0.9115\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.18903 to 0.18886, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9137 - val_loss: 0.1889 - val_acc: 0.9092\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9146 - val_loss: 0.1891 - val_acc: 0.9090\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9148 - val_loss: 0.1902 - val_acc: 0.9099\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9147 - val_loss: 0.1894 - val_acc: 0.9113\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9138 - val_loss: 0.1890 - val_acc: 0.9090\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9132 - val_loss: 0.1903 - val_acc: 0.9088\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9134 - val_loss: 0.1890 - val_acc: 0.9111\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9135 - val_loss: 0.1910 - val_acc: 0.9097\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9128 - val_loss: 0.1901 - val_acc: 0.9103\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9140 - val_loss: 0.1902 - val_acc: 0.9092\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.18886 to 0.18882, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9144 - val_loss: 0.1888 - val_acc: 0.9107\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9141 - val_loss: 0.1897 - val_acc: 0.9122\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.18882 to 0.18871, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9129 - val_loss: 0.1887 - val_acc: 0.9126\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9130 - val_loss: 0.1911 - val_acc: 0.9101\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9167 - val_loss: 0.1893 - val_acc: 0.9115\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9138 - val_loss: 0.1890 - val_acc: 0.9126\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.18871 to 0.18871, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9163 - val_loss: 0.1887 - val_acc: 0.9120\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9128 - val_loss: 0.1897 - val_acc: 0.9097\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9140 - val_loss: 0.1903 - val_acc: 0.9117\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9142 - val_loss: 0.1892 - val_acc: 0.9132\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.18871 to 0.18859, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9138 - val_loss: 0.1886 - val_acc: 0.9101\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9142 - val_loss: 0.1902 - val_acc: 0.9122\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9136 - val_loss: 0.1888 - val_acc: 0.9126\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.18859 to 0.18842, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9150 - val_loss: 0.1884 - val_acc: 0.9122\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9138 - val_loss: 0.1890 - val_acc: 0.9113\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.18842 to 0.18778, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9136 - val_loss: 0.1878 - val_acc: 0.9118\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9140 - val_loss: 0.1893 - val_acc: 0.9122\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9145 - val_loss: 0.1886 - val_acc: 0.9122\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9145 - val_loss: 0.1884 - val_acc: 0.9120\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9136 - val_loss: 0.1882 - val_acc: 0.9130\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9135 - val_loss: 0.1888 - val_acc: 0.9107\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9159 - val_loss: 0.1901 - val_acc: 0.9122\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9147 - val_loss: 0.1884 - val_acc: 0.9120\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9145 - val_loss: 0.1882 - val_acc: 0.9130\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9159 - val_loss: 0.1883 - val_acc: 0.9120\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9162 - val_loss: 0.1894 - val_acc: 0.9124\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9153 - val_loss: 0.1898 - val_acc: 0.9126\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9151 - val_loss: 0.1890 - val_acc: 0.9111\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9151 - val_loss: 0.1917 - val_acc: 0.9113\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9153 - val_loss: 0.1885 - val_acc: 0.9115\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9158 - val_loss: 0.1908 - val_acc: 0.9132\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9140 - val_loss: 0.1889 - val_acc: 0.9132\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9160 - val_loss: 0.1889 - val_acc: 0.9138\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9137 - val_loss: 0.1889 - val_acc: 0.9124\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9151 - val_loss: 0.1894 - val_acc: 0.9134\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9153 - val_loss: 0.1889 - val_acc: 0.9122\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9145 - val_loss: 0.1882 - val_acc: 0.9142\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9170 - val_loss: 0.1886 - val_acc: 0.9128\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9147 - val_loss: 0.1894 - val_acc: 0.9126\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9153 - val_loss: 0.1887 - val_acc: 0.9140\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9146 - val_loss: 0.1902 - val_acc: 0.9126\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9151 - val_loss: 0.1889 - val_acc: 0.9132\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.36682, saving model to best.model\n",
      "0s - loss: 0.4070 - acc: 0.8692 - val_loss: 0.3668 - val_acc: 0.8782\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.36682 to 0.28981, saving model to best.model\n",
      "0s - loss: 0.3392 - acc: 0.8887 - val_loss: 0.2898 - val_acc: 0.8782\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.28981 to 0.23195, saving model to best.model\n",
      "0s - loss: 0.2734 - acc: 0.8926 - val_loss: 0.2320 - val_acc: 0.9038\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.23195 to 0.20608, saving model to best.model\n",
      "0s - loss: 0.2389 - acc: 0.8970 - val_loss: 0.2061 - val_acc: 0.9105\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20608 to 0.20122, saving model to best.model\n",
      "0s - loss: 0.2242 - acc: 0.9019 - val_loss: 0.2012 - val_acc: 0.9090\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20122 to 0.19917, saving model to best.model\n",
      "0s - loss: 0.2173 - acc: 0.9034 - val_loss: 0.1992 - val_acc: 0.9109\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19917 to 0.19800, saving model to best.model\n",
      "0s - loss: 0.2092 - acc: 0.9040 - val_loss: 0.1980 - val_acc: 0.9097\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19800 to 0.19668, saving model to best.model\n",
      "0s - loss: 0.2082 - acc: 0.9029 - val_loss: 0.1967 - val_acc: 0.9103\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2074 - acc: 0.9023 - val_loss: 0.1973 - val_acc: 0.9103\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2048 - acc: 0.9056 - val_loss: 0.1975 - val_acc: 0.9109\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2044 - acc: 0.9051 - val_loss: 0.1968 - val_acc: 0.9094\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2027 - acc: 0.9058 - val_loss: 0.1975 - val_acc: 0.9113\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2010 - acc: 0.9058 - val_loss: 0.1976 - val_acc: 0.9103\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2030 - acc: 0.9044 - val_loss: 0.1970 - val_acc: 0.9072\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "1s - loss: 0.1997 - acc: 0.9046 - val_loss: 0.1970 - val_acc: 0.9088\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19668 to 0.19629, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9045 - val_loss: 0.1963 - val_acc: 0.9086\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9081 - val_loss: 0.1964 - val_acc: 0.9082\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19629 to 0.19588, saving model to best.model\n",
      "0s - loss: 0.1978 - acc: 0.9063 - val_loss: 0.1959 - val_acc: 0.9090\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9045 - val_loss: 0.1964 - val_acc: 0.9080\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1990 - acc: 0.9057 - val_loss: 0.1967 - val_acc: 0.9090\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9056 - val_loss: 0.1959 - val_acc: 0.9099\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19588 to 0.19578, saving model to best.model\n",
      "0s - loss: 0.1980 - acc: 0.9065 - val_loss: 0.1958 - val_acc: 0.9097\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19578 to 0.19572, saving model to best.model\n",
      "0s - loss: 0.1992 - acc: 0.9094 - val_loss: 0.1957 - val_acc: 0.9084\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9067 - val_loss: 0.1966 - val_acc: 0.9061\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9068 - val_loss: 0.1960 - val_acc: 0.9084\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19572 to 0.19540, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9061 - val_loss: 0.1954 - val_acc: 0.9069\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19540 to 0.19431, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9062 - val_loss: 0.1943 - val_acc: 0.9095\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1947 - acc: 0.9094 - val_loss: 0.1955 - val_acc: 0.9074\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9076 - val_loss: 0.1947 - val_acc: 0.9074\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9082 - val_loss: 0.1944 - val_acc: 0.9107\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19431 to 0.19414, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9080 - val_loss: 0.1941 - val_acc: 0.9094\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19414 to 0.19412, saving model to best.model\n",
      "0s - loss: 0.1961 - acc: 0.9084 - val_loss: 0.1941 - val_acc: 0.9074\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19412 to 0.19310, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9078 - val_loss: 0.1931 - val_acc: 0.9097\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1956 - acc: 0.9091 - val_loss: 0.1941 - val_acc: 0.9088\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9093 - val_loss: 0.1942 - val_acc: 0.9088\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9099 - val_loss: 0.1934 - val_acc: 0.9084\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1928 - acc: 0.9093 - val_loss: 0.1932 - val_acc: 0.9090\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9109 - val_loss: 0.1940 - val_acc: 0.9086\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9092 - val_loss: 0.1937 - val_acc: 0.9088\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19310 to 0.19232, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9108 - val_loss: 0.1923 - val_acc: 0.9103\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19232 to 0.19211, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9098 - val_loss: 0.1921 - val_acc: 0.9111\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1936 - acc: 0.9090 - val_loss: 0.1926 - val_acc: 0.9120\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19211 to 0.19202, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9096 - val_loss: 0.1920 - val_acc: 0.9101\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9096 - val_loss: 0.1926 - val_acc: 0.9092\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19202 to 0.19158, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9108 - val_loss: 0.1916 - val_acc: 0.9103\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19158 to 0.19136, saving model to best.model\n",
      "0s - loss: 0.1914 - acc: 0.9098 - val_loss: 0.1914 - val_acc: 0.9128\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9109 - val_loss: 0.1916 - val_acc: 0.9097\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.19136 to 0.19093, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9073 - val_loss: 0.1909 - val_acc: 0.9126\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1914 - acc: 0.9105 - val_loss: 0.1918 - val_acc: 0.9103\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9103 - val_loss: 0.1927 - val_acc: 0.9115\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.19093 to 0.19080, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9105 - val_loss: 0.1908 - val_acc: 0.9105\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19080 to 0.19040, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9112 - val_loss: 0.1904 - val_acc: 0.9105\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9108 - val_loss: 0.1909 - val_acc: 0.9113\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "1s - loss: 0.1900 - acc: 0.9126 - val_loss: 0.1908 - val_acc: 0.9117\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9098 - val_loss: 0.1910 - val_acc: 0.9113\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.19040 to 0.18992, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9095 - val_loss: 0.1899 - val_acc: 0.9138\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9116 - val_loss: 0.1902 - val_acc: 0.9113\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9110 - val_loss: 0.1905 - val_acc: 0.9118\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18992 to 0.18988, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9094 - val_loss: 0.1899 - val_acc: 0.9138\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18988 to 0.18986, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9115 - val_loss: 0.1899 - val_acc: 0.9140\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18986 to 0.18892, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9116 - val_loss: 0.1889 - val_acc: 0.9142\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9114 - val_loss: 0.1900 - val_acc: 0.9145\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18892 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9113 - val_loss: 0.1888 - val_acc: 0.9134\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9121 - val_loss: 0.1892 - val_acc: 0.9128\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18876 to 0.18865, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9110 - val_loss: 0.1886 - val_acc: 0.9132\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18865 to 0.18844, saving model to best.model\n",
      "1s - loss: 0.1879 - acc: 0.9104 - val_loss: 0.1884 - val_acc: 0.9132\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18844 to 0.18823, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9115 - val_loss: 0.1882 - val_acc: 0.9140\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9126 - val_loss: 0.1885 - val_acc: 0.9126\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9124 - val_loss: 0.1895 - val_acc: 0.9132\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18823 to 0.18821, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9121 - val_loss: 0.1882 - val_acc: 0.9126\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9114 - val_loss: 0.1885 - val_acc: 0.9130\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18821 to 0.18809, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9115 - val_loss: 0.1881 - val_acc: 0.9134\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9130 - val_loss: 0.1886 - val_acc: 0.9142\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9114 - val_loss: 0.1882 - val_acc: 0.9149\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9125 - val_loss: 0.1881 - val_acc: 0.9132\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9105 - val_loss: 0.1885 - val_acc: 0.9136\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18809 to 0.18775, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9140 - val_loss: 0.1878 - val_acc: 0.9136\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.18775 to 0.18750, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9135 - val_loss: 0.1875 - val_acc: 0.9142\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9106 - val_loss: 0.1881 - val_acc: 0.9155\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9109 - val_loss: 0.1879 - val_acc: 0.9143\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9124 - val_loss: 0.1879 - val_acc: 0.9140\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18750 to 0.18746, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9114 - val_loss: 0.1875 - val_acc: 0.9145\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.18746 to 0.18654, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9138 - val_loss: 0.1865 - val_acc: 0.9134\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9129 - val_loss: 0.1866 - val_acc: 0.9136\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9133 - val_loss: 0.1869 - val_acc: 0.9142\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.18654 to 0.18634, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9119 - val_loss: 0.1863 - val_acc: 0.9140\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9126 - val_loss: 0.1864 - val_acc: 0.9151\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18634 to 0.18629, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9148 - val_loss: 0.1863 - val_acc: 0.9143\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18629 to 0.18610, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9142 - val_loss: 0.1861 - val_acc: 0.9149\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9135 - val_loss: 0.1868 - val_acc: 0.9145\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9145 - val_loss: 0.1864 - val_acc: 0.9147\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18610 to 0.18545, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9138 - val_loss: 0.1855 - val_acc: 0.9155\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9127 - val_loss: 0.1869 - val_acc: 0.9145\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9118 - val_loss: 0.1863 - val_acc: 0.9136\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9135 - val_loss: 0.1860 - val_acc: 0.9147\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9127 - val_loss: 0.1863 - val_acc: 0.9143\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9142 - val_loss: 0.1860 - val_acc: 0.9143\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9138 - val_loss: 0.1862 - val_acc: 0.9140\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9132 - val_loss: 0.1863 - val_acc: 0.9145\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18545 to 0.18536, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9149 - val_loss: 0.1854 - val_acc: 0.9147\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9127 - val_loss: 0.1859 - val_acc: 0.9147\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9140 - val_loss: 0.1863 - val_acc: 0.9143\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9139 - val_loss: 0.1855 - val_acc: 0.9147\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18536 to 0.18483, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9151 - val_loss: 0.1848 - val_acc: 0.9147\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9147 - val_loss: 0.1860 - val_acc: 0.9147\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9145 - val_loss: 0.1855 - val_acc: 0.9155\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9147 - val_loss: 0.1853 - val_acc: 0.9145\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9147 - val_loss: 0.1857 - val_acc: 0.9153\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9138 - val_loss: 0.1856 - val_acc: 0.9138\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9146 - val_loss: 0.1863 - val_acc: 0.9147\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18483 to 0.18467, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9149 - val_loss: 0.1847 - val_acc: 0.9147\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9150 - val_loss: 0.1850 - val_acc: 0.9145\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9120 - val_loss: 0.1854 - val_acc: 0.9136\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9153 - val_loss: 0.1854 - val_acc: 0.9145\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9140 - val_loss: 0.1849 - val_acc: 0.9143\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9139 - val_loss: 0.1852 - val_acc: 0.9138\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9157 - val_loss: 0.1852 - val_acc: 0.9132\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18467 to 0.18408, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9157 - val_loss: 0.1841 - val_acc: 0.9147\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9159 - val_loss: 0.1844 - val_acc: 0.9145\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9147 - val_loss: 0.1855 - val_acc: 0.9136\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9142 - val_loss: 0.1841 - val_acc: 0.9136\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.18408 to 0.18385, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9150 - val_loss: 0.1839 - val_acc: 0.9138\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9148 - val_loss: 0.1849 - val_acc: 0.9145\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9153 - val_loss: 0.1844 - val_acc: 0.9149\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9150 - val_loss: 0.1842 - val_acc: 0.9149\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9158 - val_loss: 0.1843 - val_acc: 0.9136\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9166 - val_loss: 0.1840 - val_acc: 0.9138\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.18385 to 0.18365, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9149 - val_loss: 0.1837 - val_acc: 0.9134\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9162 - val_loss: 0.1842 - val_acc: 0.9145\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9157 - val_loss: 0.1851 - val_acc: 0.9155\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9150 - val_loss: 0.1845 - val_acc: 0.9149\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.18365 to 0.18326, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9147 - val_loss: 0.1833 - val_acc: 0.9136\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9157 - val_loss: 0.1840 - val_acc: 0.9149\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9150 - val_loss: 0.1848 - val_acc: 0.9145\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9160 - val_loss: 0.1847 - val_acc: 0.9159\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9151 - val_loss: 0.1848 - val_acc: 0.9147\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9166 - val_loss: 0.1837 - val_acc: 0.9147\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9175 - val_loss: 0.1843 - val_acc: 0.9149\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9165 - val_loss: 0.1835 - val_acc: 0.9130\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9154 - val_loss: 0.1840 - val_acc: 0.9136\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.18326 to 0.18287, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9160 - val_loss: 0.1829 - val_acc: 0.9140\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9157 - val_loss: 0.1831 - val_acc: 0.9130\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9150 - val_loss: 0.1833 - val_acc: 0.9134\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9178 - val_loss: 0.1844 - val_acc: 0.9134\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9167 - val_loss: 0.1837 - val_acc: 0.9138\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9162 - val_loss: 0.1833 - val_acc: 0.9140\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9157 - val_loss: 0.1829 - val_acc: 0.9132\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9172 - val_loss: 0.1829 - val_acc: 0.9138\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9159 - val_loss: 0.1832 - val_acc: 0.9132\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9182 - val_loss: 0.1854 - val_acc: 0.9157\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9163 - val_loss: 0.1829 - val_acc: 0.9138\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9169 - val_loss: 0.1829 - val_acc: 0.9138\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.18287 to 0.18280, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9165 - val_loss: 0.1828 - val_acc: 0.9132\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9184 - val_loss: 0.1836 - val_acc: 0.9159\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.18280 to 0.18256, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9167 - val_loss: 0.1826 - val_acc: 0.9134\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9168 - val_loss: 0.1846 - val_acc: 0.9142\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9158 - val_loss: 0.1826 - val_acc: 0.9149\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9182 - val_loss: 0.1854 - val_acc: 0.9157\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9163 - val_loss: 0.1833 - val_acc: 0.9145\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9184 - val_loss: 0.1837 - val_acc: 0.9149\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9181 - val_loss: 0.1827 - val_acc: 0.9147\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9168 - val_loss: 0.1836 - val_acc: 0.9149\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9165 - val_loss: 0.1828 - val_acc: 0.9143\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.18256 to 0.18223, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9192 - val_loss: 0.1822 - val_acc: 0.9136\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9173 - val_loss: 0.1839 - val_acc: 0.9155\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.18223 to 0.18218, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9168 - val_loss: 0.1822 - val_acc: 0.9143\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9170 - val_loss: 0.1827 - val_acc: 0.9142\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9169 - val_loss: 0.1830 - val_acc: 0.9153\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9187 - val_loss: 0.1830 - val_acc: 0.9147\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.18218 to 0.18216, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9185 - val_loss: 0.1822 - val_acc: 0.9138\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9184 - val_loss: 0.1831 - val_acc: 0.9161\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9175 - val_loss: 0.1828 - val_acc: 0.9140\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9186 - val_loss: 0.1831 - val_acc: 0.9155\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9158 - val_loss: 0.1833 - val_acc: 0.9153\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.18216 to 0.18211, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9187 - val_loss: 0.1821 - val_acc: 0.9153\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9183 - val_loss: 0.1825 - val_acc: 0.9149\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9180 - val_loss: 0.1822 - val_acc: 0.9149\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9176 - val_loss: 0.1828 - val_acc: 0.9153\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9187 - val_loss: 0.1824 - val_acc: 0.9134\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9190 - val_loss: 0.1824 - val_acc: 0.9142\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9175 - val_loss: 0.1826 - val_acc: 0.9147\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9179 - val_loss: 0.1827 - val_acc: 0.9159\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9197 - val_loss: 0.1822 - val_acc: 0.9143\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9186 - val_loss: 0.1828 - val_acc: 0.9165\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9182 - val_loss: 0.1825 - val_acc: 0.9145\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9184 - val_loss: 0.1832 - val_acc: 0.9165\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9181 - val_loss: 0.1827 - val_acc: 0.9153\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.18211 to 0.18206, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9183 - val_loss: 0.1821 - val_acc: 0.9147\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9174 - val_loss: 0.1824 - val_acc: 0.9159\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.18206 to 0.18197, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9188 - val_loss: 0.1820 - val_acc: 0.9157\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9193 - val_loss: 0.1826 - val_acc: 0.9149\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9196 - val_loss: 0.1827 - val_acc: 0.9165\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9191 - val_loss: 0.1839 - val_acc: 0.9165\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9192 - val_loss: 0.1828 - val_acc: 0.9167\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9185 - val_loss: 0.1836 - val_acc: 0.9167\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9175 - val_loss: 0.1829 - val_acc: 0.9145\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9179 - val_loss: 0.1833 - val_acc: 0.9155\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9187 - val_loss: 0.1829 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9188 - val_loss: 0.1824 - val_acc: 0.9153\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9180 - val_loss: 0.1848 - val_acc: 0.9151\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32055, saving model to best.model\n",
      "0s - loss: 0.4079 - acc: 0.8720 - val_loss: 0.3206 - val_acc: 0.8925\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32055 to 0.24330, saving model to best.model\n",
      "0s - loss: 0.3315 - acc: 0.8847 - val_loss: 0.2433 - val_acc: 0.9003\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24330 to 0.20375, saving model to best.model\n",
      "0s - loss: 0.2665 - acc: 0.8904 - val_loss: 0.2037 - val_acc: 0.9107\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20375 to 0.19384, saving model to best.model\n",
      "0s - loss: 0.2367 - acc: 0.8972 - val_loss: 0.1938 - val_acc: 0.9099\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19384 to 0.19143, saving model to best.model\n",
      "0s - loss: 0.2244 - acc: 0.8981 - val_loss: 0.1914 - val_acc: 0.9113\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19143 to 0.18983, saving model to best.model\n",
      "0s - loss: 0.2217 - acc: 0.8982 - val_loss: 0.1898 - val_acc: 0.9080\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18983 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.2133 - acc: 0.9014 - val_loss: 0.1888 - val_acc: 0.9101\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18876 to 0.18808, saving model to best.model\n",
      "0s - loss: 0.2142 - acc: 0.9002 - val_loss: 0.1881 - val_acc: 0.9088\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2112 - acc: 0.9026 - val_loss: 0.1890 - val_acc: 0.9078\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2090 - acc: 0.9019 - val_loss: 0.1886 - val_acc: 0.9078\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18808 to 0.18781, saving model to best.model\n",
      "0s - loss: 0.2071 - acc: 0.9029 - val_loss: 0.1878 - val_acc: 0.9117\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2061 - acc: 0.9037 - val_loss: 0.1879 - val_acc: 0.9084\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18781 to 0.18768, saving model to best.model\n",
      "0s - loss: 0.2058 - acc: 0.9024 - val_loss: 0.1877 - val_acc: 0.9101\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2026 - acc: 0.9039 - val_loss: 0.1902 - val_acc: 0.9036\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2043 - acc: 0.9031 - val_loss: 0.1882 - val_acc: 0.9080\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2060 - acc: 0.9025 - val_loss: 0.1882 - val_acc: 0.9080\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18768 to 0.18700, saving model to best.model\n",
      "0s - loss: 0.2040 - acc: 0.9040 - val_loss: 0.1870 - val_acc: 0.9090\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2033 - acc: 0.9037 - val_loss: 0.1881 - val_acc: 0.9103\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.2018 - acc: 0.9050 - val_loss: 0.1877 - val_acc: 0.9070\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2012 - acc: 0.9034 - val_loss: 0.1870 - val_acc: 0.9105\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18700 to 0.18679, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9038 - val_loss: 0.1868 - val_acc: 0.9095\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2003 - acc: 0.9036 - val_loss: 0.1870 - val_acc: 0.9092\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18679 to 0.18655, saving model to best.model\n",
      "0s - loss: 0.2013 - acc: 0.9035 - val_loss: 0.1865 - val_acc: 0.9105\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2010 - acc: 0.9032 - val_loss: 0.1879 - val_acc: 0.9061\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18655 to 0.18597, saving model to best.model\n",
      "0s - loss: 0.2008 - acc: 0.9030 - val_loss: 0.1860 - val_acc: 0.9111\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18597 to 0.18578, saving model to best.model\n",
      "0s - loss: 0.2002 - acc: 0.9049 - val_loss: 0.1858 - val_acc: 0.9095\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18578 to 0.18559, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9049 - val_loss: 0.1856 - val_acc: 0.9092\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18559 to 0.18522, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9036 - val_loss: 0.1852 - val_acc: 0.9092\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9038 - val_loss: 0.1863 - val_acc: 0.9099\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1986 - acc: 0.9054 - val_loss: 0.1852 - val_acc: 0.9107\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18522 to 0.18482, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9037 - val_loss: 0.1848 - val_acc: 0.9103\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18482 to 0.18431, saving model to best.model\n",
      "0s - loss: 0.1984 - acc: 0.9056 - val_loss: 0.1843 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18431 to 0.18398, saving model to best.model\n",
      "0s - loss: 0.1979 - acc: 0.9053 - val_loss: 0.1840 - val_acc: 0.9111\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18398 to 0.18374, saving model to best.model\n",
      "1s - loss: 0.1982 - acc: 0.9066 - val_loss: 0.1837 - val_acc: 0.9109\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9054 - val_loss: 0.1846 - val_acc: 0.9103\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1983 - acc: 0.9055 - val_loss: 0.1844 - val_acc: 0.9113\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9076 - val_loss: 0.1843 - val_acc: 0.9099\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18374 to 0.18306, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9076 - val_loss: 0.1831 - val_acc: 0.9120\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1959 - acc: 0.9058 - val_loss: 0.1834 - val_acc: 0.9118\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18306 to 0.18287, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9062 - val_loss: 0.1829 - val_acc: 0.9115\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18287 to 0.18250, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9057 - val_loss: 0.1825 - val_acc: 0.9118\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9049 - val_loss: 0.1831 - val_acc: 0.9117\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18250 to 0.18206, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9059 - val_loss: 0.1821 - val_acc: 0.9126\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18206 to 0.18169, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9064 - val_loss: 0.1817 - val_acc: 0.9120\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1950 - acc: 0.9066 - val_loss: 0.1820 - val_acc: 0.9118\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9076 - val_loss: 0.1818 - val_acc: 0.9128\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1949 - acc: 0.9055 - val_loss: 0.1827 - val_acc: 0.9120\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18169 to 0.18162, saving model to best.model\n",
      "0s - loss: 0.1925 - acc: 0.9086 - val_loss: 0.1816 - val_acc: 0.9118\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9068 - val_loss: 0.1820 - val_acc: 0.9126\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18162 to 0.18109, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9081 - val_loss: 0.1811 - val_acc: 0.9138\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18109 to 0.18101, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9093 - val_loss: 0.1810 - val_acc: 0.9124\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9076 - val_loss: 0.1815 - val_acc: 0.9128\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9083 - val_loss: 0.1815 - val_acc: 0.9126\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18101 to 0.18049, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9082 - val_loss: 0.1805 - val_acc: 0.9136\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9066 - val_loss: 0.1823 - val_acc: 0.9120\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18049 to 0.18042, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9096 - val_loss: 0.1804 - val_acc: 0.9136\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9078 - val_loss: 0.1811 - val_acc: 0.9128\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18042 to 0.18015, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9075 - val_loss: 0.1802 - val_acc: 0.9134\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18015 to 0.17976, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9089 - val_loss: 0.1798 - val_acc: 0.9138\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9062 - val_loss: 0.1799 - val_acc: 0.9138\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9078 - val_loss: 0.1803 - val_acc: 0.9138\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9077 - val_loss: 0.1801 - val_acc: 0.9136\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17976 to 0.17942, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9082 - val_loss: 0.1794 - val_acc: 0.9138\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9081 - val_loss: 0.1799 - val_acc: 0.9134\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9081 - val_loss: 0.1797 - val_acc: 0.9136\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9093 - val_loss: 0.1800 - val_acc: 0.9134\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9097 - val_loss: 0.1797 - val_acc: 0.9138\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17942 to 0.17896, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9069 - val_loss: 0.1790 - val_acc: 0.9143\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9086 - val_loss: 0.1798 - val_acc: 0.9138\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9083 - val_loss: 0.1795 - val_acc: 0.9143\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.17896 to 0.17862, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9089 - val_loss: 0.1786 - val_acc: 0.9142\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "1s - loss: 0.1905 - acc: 0.9082 - val_loss: 0.1786 - val_acc: 0.9140\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.17862 to 0.17857, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9108 - val_loss: 0.1786 - val_acc: 0.9134\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9087 - val_loss: 0.1786 - val_acc: 0.9138\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9084 - val_loss: 0.1793 - val_acc: 0.9145\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.17857 to 0.17812, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9100 - val_loss: 0.1781 - val_acc: 0.9145\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.17812 to 0.17803, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9098 - val_loss: 0.1780 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17803 to 0.17795, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9100 - val_loss: 0.1779 - val_acc: 0.9138\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9082 - val_loss: 0.1784 - val_acc: 0.9140\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.17795 to 0.17782, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9089 - val_loss: 0.1778 - val_acc: 0.9147\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17782 to 0.17772, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9102 - val_loss: 0.1777 - val_acc: 0.9149\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9090 - val_loss: 0.1777 - val_acc: 0.9142\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9095 - val_loss: 0.1778 - val_acc: 0.9138\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17772 to 0.17734, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9100 - val_loss: 0.1773 - val_acc: 0.9153\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.17734 to 0.17733, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9092 - val_loss: 0.1773 - val_acc: 0.9153\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "1s - loss: 0.1869 - acc: 0.9097 - val_loss: 0.1775 - val_acc: 0.9153\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9088 - val_loss: 0.1787 - val_acc: 0.9149\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17733 to 0.17721, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9100 - val_loss: 0.1772 - val_acc: 0.9159\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17721 to 0.17698, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9105 - val_loss: 0.1770 - val_acc: 0.9157\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9105 - val_loss: 0.1771 - val_acc: 0.9142\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17698 to 0.17691, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9108 - val_loss: 0.1769 - val_acc: 0.9151\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17691 to 0.17672, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9104 - val_loss: 0.1767 - val_acc: 0.9153\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9103 - val_loss: 0.1780 - val_acc: 0.9142\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9104 - val_loss: 0.1784 - val_acc: 0.9155\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9092 - val_loss: 0.1770 - val_acc: 0.9165\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17672 to 0.17660, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9098 - val_loss: 0.1766 - val_acc: 0.9167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17660 to 0.17656, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9114 - val_loss: 0.1766 - val_acc: 0.9149\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "1s - loss: 0.1853 - acc: 0.9114 - val_loss: 0.1767 - val_acc: 0.9145\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17656 to 0.17638, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9111 - val_loss: 0.1764 - val_acc: 0.9167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9102 - val_loss: 0.1776 - val_acc: 0.9140\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17638 to 0.17628, saving model to best.model\n",
      "1s - loss: 0.1845 - acc: 0.9103 - val_loss: 0.1763 - val_acc: 0.9163\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9114 - val_loss: 0.1763 - val_acc: 0.9170\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17628 to 0.17621, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9107 - val_loss: 0.1762 - val_acc: 0.9167\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17621 to 0.17613, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9094 - val_loss: 0.1761 - val_acc: 0.9165\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9131 - val_loss: 0.1766 - val_acc: 0.9149\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17613 to 0.17609, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9111 - val_loss: 0.1761 - val_acc: 0.9163\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9106 - val_loss: 0.1771 - val_acc: 0.9143\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9121 - val_loss: 0.1776 - val_acc: 0.9165\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9116 - val_loss: 0.1762 - val_acc: 0.9147\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17609 to 0.17568, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9122 - val_loss: 0.1757 - val_acc: 0.9155\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9115 - val_loss: 0.1758 - val_acc: 0.9165\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9126 - val_loss: 0.1757 - val_acc: 0.9157\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9102 - val_loss: 0.1760 - val_acc: 0.9145\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17568 to 0.17540, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9112 - val_loss: 0.1754 - val_acc: 0.9176\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9102 - val_loss: 0.1759 - val_acc: 0.9140\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9119 - val_loss: 0.1756 - val_acc: 0.9149\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9114 - val_loss: 0.1755 - val_acc: 0.9147\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17540 to 0.17525, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9123 - val_loss: 0.1752 - val_acc: 0.9161\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17525 to 0.17520, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9134 - val_loss: 0.1752 - val_acc: 0.9161\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9107 - val_loss: 0.1755 - val_acc: 0.9176\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9123 - val_loss: 0.1753 - val_acc: 0.9163\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9128 - val_loss: 0.1760 - val_acc: 0.9165\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9127 - val_loss: 0.1755 - val_acc: 0.9163\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9128 - val_loss: 0.1754 - val_acc: 0.9155\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9126 - val_loss: 0.1754 - val_acc: 0.9153\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9135 - val_loss: 0.1753 - val_acc: 0.9165\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9107 - val_loss: 0.1757 - val_acc: 0.9142\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9129 - val_loss: 0.1752 - val_acc: 0.9163\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9135 - val_loss: 0.1756 - val_acc: 0.9151\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17520 to 0.17494, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9136 - val_loss: 0.1749 - val_acc: 0.9161\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9121 - val_loss: 0.1752 - val_acc: 0.9153\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9124 - val_loss: 0.1752 - val_acc: 0.9147\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17494 to 0.17480, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9125 - val_loss: 0.1748 - val_acc: 0.9155\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9133 - val_loss: 0.1753 - val_acc: 0.9145\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9129 - val_loss: 0.1750 - val_acc: 0.9151\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9130 - val_loss: 0.1751 - val_acc: 0.9161\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17480 to 0.17465, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9119 - val_loss: 0.1746 - val_acc: 0.9157\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9129 - val_loss: 0.1748 - val_acc: 0.9170\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17465 to 0.17451, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9128 - val_loss: 0.1745 - val_acc: 0.9161\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9130 - val_loss: 0.1746 - val_acc: 0.9174\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17451 to 0.17445, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9119 - val_loss: 0.1744 - val_acc: 0.9170\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9128 - val_loss: 0.1745 - val_acc: 0.9167\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17445 to 0.17445, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9137 - val_loss: 0.1744 - val_acc: 0.9145\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9138 - val_loss: 0.1749 - val_acc: 0.9167\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9142 - val_loss: 0.1751 - val_acc: 0.9157\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9140 - val_loss: 0.1745 - val_acc: 0.9172\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9126 - val_loss: 0.1745 - val_acc: 0.9153\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.17445 to 0.17443, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9130 - val_loss: 0.1744 - val_acc: 0.9159\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9140 - val_loss: 0.1746 - val_acc: 0.9151\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17443 to 0.17434, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9138 - val_loss: 0.1743 - val_acc: 0.9159\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9122 - val_loss: 0.1748 - val_acc: 0.9159\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9128 - val_loss: 0.1747 - val_acc: 0.9151\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17434 to 0.17406, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9137 - val_loss: 0.1741 - val_acc: 0.9155\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9134 - val_loss: 0.1742 - val_acc: 0.9159\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9118 - val_loss: 0.1743 - val_acc: 0.9155\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17406 to 0.17382, saving model to best.model\n",
      "0s - loss: 0.1771 - acc: 0.9135 - val_loss: 0.1738 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9138 - val_loss: 0.1740 - val_acc: 0.9172\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9143 - val_loss: 0.1752 - val_acc: 0.9165\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9129 - val_loss: 0.1746 - val_acc: 0.9176\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9136 - val_loss: 0.1740 - val_acc: 0.9170\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9134 - val_loss: 0.1742 - val_acc: 0.9163\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9140 - val_loss: 0.1743 - val_acc: 0.9168\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9136 - val_loss: 0.1743 - val_acc: 0.9172\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9153 - val_loss: 0.1741 - val_acc: 0.9180\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17382 to 0.17367, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9147 - val_loss: 0.1737 - val_acc: 0.9172\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9139 - val_loss: 0.1744 - val_acc: 0.9186\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9149 - val_loss: 0.1742 - val_acc: 0.9180\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9142 - val_loss: 0.1737 - val_acc: 0.9180\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9151 - val_loss: 0.1744 - val_acc: 0.9184\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9143 - val_loss: 0.1741 - val_acc: 0.9176\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9141 - val_loss: 0.1739 - val_acc: 0.9174\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9137 - val_loss: 0.1739 - val_acc: 0.9170\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17367 to 0.17363, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9151 - val_loss: 0.1736 - val_acc: 0.9167\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9142 - val_loss: 0.1751 - val_acc: 0.9167\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9135 - val_loss: 0.1740 - val_acc: 0.9182\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9147 - val_loss: 0.1740 - val_acc: 0.9178\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9140 - val_loss: 0.1741 - val_acc: 0.9170\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9151 - val_loss: 0.1737 - val_acc: 0.9172\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9138 - val_loss: 0.1737 - val_acc: 0.9182\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9153 - val_loss: 0.1736 - val_acc: 0.9178\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9154 - val_loss: 0.1737 - val_acc: 0.9182\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9156 - val_loss: 0.1741 - val_acc: 0.9170\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9153 - val_loss: 0.1736 - val_acc: 0.9178\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9151 - val_loss: 0.1738 - val_acc: 0.9180\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9145 - val_loss: 0.1742 - val_acc: 0.9168\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9149 - val_loss: 0.1739 - val_acc: 0.9182\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9154 - val_loss: 0.1738 - val_acc: 0.9184\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9133 - val_loss: 0.1739 - val_acc: 0.9170\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.17363 to 0.17353, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9150 - val_loss: 0.1735 - val_acc: 0.9178\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9171 - val_loss: 0.1742 - val_acc: 0.9180\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.17353 to 0.17322, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9148 - val_loss: 0.1732 - val_acc: 0.9188\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9142 - val_loss: 0.1736 - val_acc: 0.9176\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.17322 to 0.17319, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9158 - val_loss: 0.1732 - val_acc: 0.9178\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.17319 to 0.17292, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9149 - val_loss: 0.1729 - val_acc: 0.9180\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9152 - val_loss: 0.1732 - val_acc: 0.9176\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9160 - val_loss: 0.1734 - val_acc: 0.9184\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9157 - val_loss: 0.1730 - val_acc: 0.9191\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9151 - val_loss: 0.1734 - val_acc: 0.9184\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9142 - val_loss: 0.1732 - val_acc: 0.9178\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.17292 to 0.17285, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9168 - val_loss: 0.1728 - val_acc: 0.9188\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34223, saving model to best.model\n",
      "0s - loss: 0.4098 - acc: 0.8652 - val_loss: 0.3422 - val_acc: 0.8853\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34223 to 0.27377, saving model to best.model\n",
      "0s - loss: 0.3336 - acc: 0.8897 - val_loss: 0.2738 - val_acc: 0.8853\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27377 to 0.22049, saving model to best.model\n",
      "0s - loss: 0.2681 - acc: 0.8949 - val_loss: 0.2205 - val_acc: 0.9030\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22049 to 0.20517, saving model to best.model\n",
      "0s - loss: 0.2318 - acc: 0.9013 - val_loss: 0.2052 - val_acc: 0.9065\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20517 to 0.20195, saving model to best.model\n",
      "0s - loss: 0.2197 - acc: 0.9029 - val_loss: 0.2020 - val_acc: 0.9099\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20195 to 0.20049, saving model to best.model\n",
      "0s - loss: 0.2153 - acc: 0.9042 - val_loss: 0.2005 - val_acc: 0.9120\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.2087 - acc: 0.9053 - val_loss: 0.2005 - val_acc: 0.9082\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.20049 to 0.19925, saving model to best.model\n",
      "0s - loss: 0.2076 - acc: 0.9068 - val_loss: 0.1993 - val_acc: 0.9128\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19925 to 0.19894, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9073 - val_loss: 0.1989 - val_acc: 0.9113\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19894 to 0.19883, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9060 - val_loss: 0.1988 - val_acc: 0.9115\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19883 to 0.19869, saving model to best.model\n",
      "0s - loss: 0.2040 - acc: 0.9051 - val_loss: 0.1987 - val_acc: 0.9097\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2004 - acc: 0.9070 - val_loss: 0.1989 - val_acc: 0.9099\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2009 - acc: 0.9083 - val_loss: 0.1989 - val_acc: 0.9099\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19869 to 0.19865, saving model to best.model\n",
      "0s - loss: 0.2005 - acc: 0.9098 - val_loss: 0.1986 - val_acc: 0.9078\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19865 to 0.19854, saving model to best.model\n",
      "0s - loss: 0.1989 - acc: 0.9090 - val_loss: 0.1985 - val_acc: 0.9080\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19854 to 0.19837, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9074 - val_loss: 0.1984 - val_acc: 0.9080\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1986 - acc: 0.9083 - val_loss: 0.1993 - val_acc: 0.9090\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19837 to 0.19800, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9088 - val_loss: 0.1980 - val_acc: 0.9086\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9112 - val_loss: 0.1984 - val_acc: 0.9082\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1963 - acc: 0.9093 - val_loss: 0.1980 - val_acc: 0.9088\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19800 to 0.19731, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9087 - val_loss: 0.1973 - val_acc: 0.9082\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19731 to 0.19702, saving model to best.model\n",
      "0s - loss: 0.1963 - acc: 0.9096 - val_loss: 0.1970 - val_acc: 0.9095\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19702 to 0.19678, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9094 - val_loss: 0.1968 - val_acc: 0.9092\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9099 - val_loss: 0.1968 - val_acc: 0.9084\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19678 to 0.19632, saving model to best.model\n",
      "0s - loss: 0.1941 - acc: 0.9091 - val_loss: 0.1963 - val_acc: 0.9095\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19632 to 0.19597, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9109 - val_loss: 0.1960 - val_acc: 0.9097\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9087 - val_loss: 0.1960 - val_acc: 0.9103\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19597 to 0.19574, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9102 - val_loss: 0.1957 - val_acc: 0.9082\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9100 - val_loss: 0.1959 - val_acc: 0.9095\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19574 to 0.19526, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9115 - val_loss: 0.1953 - val_acc: 0.9080\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9104 - val_loss: 0.1955 - val_acc: 0.9084\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19526 to 0.19468, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9110 - val_loss: 0.1947 - val_acc: 0.9090\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19468 to 0.19437, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9120 - val_loss: 0.1944 - val_acc: 0.9084\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19437 to 0.19410, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9097 - val_loss: 0.1941 - val_acc: 0.9082\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19410 to 0.19384, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9090 - val_loss: 0.1938 - val_acc: 0.9103\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19384 to 0.19365, saving model to best.model\n",
      "0s - loss: 0.1910 - acc: 0.9129 - val_loss: 0.1937 - val_acc: 0.9090\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19365 to 0.19352, saving model to best.model\n",
      "1s - loss: 0.1914 - acc: 0.9099 - val_loss: 0.1935 - val_acc: 0.9090\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19352 to 0.19337, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9110 - val_loss: 0.1934 - val_acc: 0.9101\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19337 to 0.19314, saving model to best.model\n",
      "1s - loss: 0.1909 - acc: 0.9112 - val_loss: 0.1931 - val_acc: 0.9101\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19314 to 0.19296, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9105 - val_loss: 0.1930 - val_acc: 0.9103\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19296 to 0.19278, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9106 - val_loss: 0.1928 - val_acc: 0.9092\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19278 to 0.19241, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9119 - val_loss: 0.1924 - val_acc: 0.9107\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9122 - val_loss: 0.1925 - val_acc: 0.9095\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.19241 to 0.19203, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9130 - val_loss: 0.1920 - val_acc: 0.9094\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19203 to 0.19195, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9118 - val_loss: 0.1920 - val_acc: 0.9103\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9103 - val_loss: 0.1921 - val_acc: 0.9084\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.19195 to 0.19157, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9123 - val_loss: 0.1916 - val_acc: 0.9109\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9126 - val_loss: 0.1922 - val_acc: 0.9095\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19157 to 0.19123, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9117 - val_loss: 0.1912 - val_acc: 0.9111\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.19123 to 0.19118, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9117 - val_loss: 0.1912 - val_acc: 0.9097\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.19118 to 0.19106, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9113 - val_loss: 0.1911 - val_acc: 0.9103\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19106 to 0.19092, saving model to best.model\n",
      "1s - loss: 0.1873 - acc: 0.9117 - val_loss: 0.1909 - val_acc: 0.9095\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.19092 to 0.19067, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9138 - val_loss: 0.1907 - val_acc: 0.9111\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.19067 to 0.19048, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9120 - val_loss: 0.1905 - val_acc: 0.9103\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.19048 to 0.19009, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9136 - val_loss: 0.1901 - val_acc: 0.9111\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.19009 to 0.19006, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9142 - val_loss: 0.1901 - val_acc: 0.9105\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "1s - loss: 0.1868 - acc: 0.9126 - val_loss: 0.1902 - val_acc: 0.9113\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.19006 to 0.18995, saving model to best.model\n",
      "1s - loss: 0.1871 - acc: 0.9133 - val_loss: 0.1899 - val_acc: 0.9103\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18995 to 0.18962, saving model to best.model\n",
      "1s - loss: 0.1866 - acc: 0.9137 - val_loss: 0.1896 - val_acc: 0.9111\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "1s - loss: 0.1858 - acc: 0.9136 - val_loss: 0.1896 - val_acc: 0.9105\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9150 - val_loss: 0.1898 - val_acc: 0.9097\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18962 to 0.18946, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9122 - val_loss: 0.1895 - val_acc: 0.9103\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18946 to 0.18911, saving model to best.model\n",
      "1s - loss: 0.1860 - acc: 0.9141 - val_loss: 0.1891 - val_acc: 0.9109\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "1s - loss: 0.1859 - acc: 0.9141 - val_loss: 0.1893 - val_acc: 0.9105\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "1s - loss: 0.1859 - acc: 0.9128 - val_loss: 0.1892 - val_acc: 0.9097\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9131 - val_loss: 0.1892 - val_acc: 0.9115\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18911 to 0.18869, saving model to best.model\n",
      "1s - loss: 0.1862 - acc: 0.9147 - val_loss: 0.1887 - val_acc: 0.9101\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "1s - loss: 0.1864 - acc: 0.9131 - val_loss: 0.1897 - val_acc: 0.9092\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18869 to 0.18857, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9152 - val_loss: 0.1886 - val_acc: 0.9090\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18857 to 0.18833, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9141 - val_loss: 0.1883 - val_acc: 0.9082\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18833 to 0.18825, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9138 - val_loss: 0.1882 - val_acc: 0.9111\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9119 - val_loss: 0.1884 - val_acc: 0.9107\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9138 - val_loss: 0.1886 - val_acc: 0.9111\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18825 to 0.18802, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9144 - val_loss: 0.1880 - val_acc: 0.9097\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18802 to 0.18757, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9149 - val_loss: 0.1876 - val_acc: 0.9105\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18757 to 0.18737, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9138 - val_loss: 0.1874 - val_acc: 0.9097\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9158 - val_loss: 0.1875 - val_acc: 0.9097\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9138 - val_loss: 0.1874 - val_acc: 0.9101\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9144 - val_loss: 0.1877 - val_acc: 0.9103\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.18737 to 0.18717, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9156 - val_loss: 0.1872 - val_acc: 0.9105\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9157 - val_loss: 0.1872 - val_acc: 0.9107\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18717 to 0.18707, saving model to best.model\n",
      "1s - loss: 0.1822 - acc: 0.9150 - val_loss: 0.1871 - val_acc: 0.9113\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9147 - val_loss: 0.1877 - val_acc: 0.9105\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18707 to 0.18700, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9140 - val_loss: 0.1870 - val_acc: 0.9103\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.18700 to 0.18648, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9146 - val_loss: 0.1865 - val_acc: 0.9105\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9146 - val_loss: 0.1865 - val_acc: 0.9124\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18648 to 0.18630, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9145 - val_loss: 0.1863 - val_acc: 0.9094\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9145 - val_loss: 0.1863 - val_acc: 0.9095\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18630 to 0.18602, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9156 - val_loss: 0.1860 - val_acc: 0.9109\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9144 - val_loss: 0.1867 - val_acc: 0.9107\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18602 to 0.18598, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9159 - val_loss: 0.1860 - val_acc: 0.9111\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18598 to 0.18540, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9172 - val_loss: 0.1854 - val_acc: 0.9115\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9149 - val_loss: 0.1855 - val_acc: 0.9105\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9146 - val_loss: 0.1855 - val_acc: 0.9107\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9165 - val_loss: 0.1855 - val_acc: 0.9117\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9165 - val_loss: 0.1857 - val_acc: 0.9107\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9158 - val_loss: 0.1856 - val_acc: 0.9117\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18540 to 0.18525, saving model to best.model\n",
      "0s - loss: 0.1820 - acc: 0.9150 - val_loss: 0.1852 - val_acc: 0.9107\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9159 - val_loss: 0.1860 - val_acc: 0.9111\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18525 to 0.18523, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9158 - val_loss: 0.1852 - val_acc: 0.9109\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18523 to 0.18506, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9146 - val_loss: 0.1851 - val_acc: 0.9113\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18506 to 0.18503, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9142 - val_loss: 0.1850 - val_acc: 0.9118\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18503 to 0.18472, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9166 - val_loss: 0.1847 - val_acc: 0.9113\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9162 - val_loss: 0.1850 - val_acc: 0.9118\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.18472 to 0.18448, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9155 - val_loss: 0.1845 - val_acc: 0.9118\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9146 - val_loss: 0.1850 - val_acc: 0.9115\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18448 to 0.18446, saving model to best.model\n",
      "1s - loss: 0.1787 - acc: 0.9172 - val_loss: 0.1845 - val_acc: 0.9117\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.18446 to 0.18435, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9161 - val_loss: 0.1843 - val_acc: 0.9117\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.18435 to 0.18417, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9161 - val_loss: 0.1842 - val_acc: 0.9111\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18417 to 0.18415, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9169 - val_loss: 0.1842 - val_acc: 0.9122\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18415 to 0.18394, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9161 - val_loss: 0.1839 - val_acc: 0.9126\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.18394 to 0.18374, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9166 - val_loss: 0.1837 - val_acc: 0.9118\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.18374 to 0.18364, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9162 - val_loss: 0.1836 - val_acc: 0.9120\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9167 - val_loss: 0.1841 - val_acc: 0.9128\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9152 - val_loss: 0.1848 - val_acc: 0.9126\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9166 - val_loss: 0.1838 - val_acc: 0.9126\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9174 - val_loss: 0.1842 - val_acc: 0.9118\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9155 - val_loss: 0.1839 - val_acc: 0.9124\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9178 - val_loss: 0.1839 - val_acc: 0.9128\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9173 - val_loss: 0.1839 - val_acc: 0.9138\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.18364 to 0.18320, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9161 - val_loss: 0.1832 - val_acc: 0.9122\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9177 - val_loss: 0.1834 - val_acc: 0.9132\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9163 - val_loss: 0.1838 - val_acc: 0.9132\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9155 - val_loss: 0.1834 - val_acc: 0.9134\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.18320 to 0.18308, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9168 - val_loss: 0.1831 - val_acc: 0.9128\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.18308 to 0.18296, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9177 - val_loss: 0.1830 - val_acc: 0.9122\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18296 to 0.18292, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9158 - val_loss: 0.1829 - val_acc: 0.9134\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.18292 to 0.18274, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9165 - val_loss: 0.1827 - val_acc: 0.9134\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9176 - val_loss: 0.1829 - val_acc: 0.9134\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.18274 to 0.18232, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9185 - val_loss: 0.1823 - val_acc: 0.9138\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9157 - val_loss: 0.1827 - val_acc: 0.9136\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9167 - val_loss: 0.1827 - val_acc: 0.9132\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9163 - val_loss: 0.1838 - val_acc: 0.9142\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9175 - val_loss: 0.1826 - val_acc: 0.9140\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.18232 to 0.18231, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9185 - val_loss: 0.1823 - val_acc: 0.9138\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9157 - val_loss: 0.1832 - val_acc: 0.9136\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9178 - val_loss: 0.1826 - val_acc: 0.9128\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.18231 to 0.18206, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9186 - val_loss: 0.1821 - val_acc: 0.9140\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9170 - val_loss: 0.1822 - val_acc: 0.9138\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9182 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9184 - val_loss: 0.1824 - val_acc: 0.9136\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.18206 to 0.18164, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9192 - val_loss: 0.1816 - val_acc: 0.9145\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9180 - val_loss: 0.1817 - val_acc: 0.9142\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9168 - val_loss: 0.1818 - val_acc: 0.9126\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9180 - val_loss: 0.1817 - val_acc: 0.9134\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9192 - val_loss: 0.1817 - val_acc: 0.9136\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9175 - val_loss: 0.1818 - val_acc: 0.9138\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.18164 to 0.18133, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9182 - val_loss: 0.1813 - val_acc: 0.9142\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9173 - val_loss: 0.1827 - val_acc: 0.9136\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9179 - val_loss: 0.1815 - val_acc: 0.9143\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9181 - val_loss: 0.1822 - val_acc: 0.9134\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.18133 to 0.18074, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9187 - val_loss: 0.1807 - val_acc: 0.9143\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9184 - val_loss: 0.1808 - val_acc: 0.9134\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9177 - val_loss: 0.1810 - val_acc: 0.9147\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9193 - val_loss: 0.1810 - val_acc: 0.9132\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.18074 to 0.18066, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9191 - val_loss: 0.1807 - val_acc: 0.9132\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9178 - val_loss: 0.1807 - val_acc: 0.9147\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9179 - val_loss: 0.1810 - val_acc: 0.9143\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.18066 to 0.18065, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9177 - val_loss: 0.1807 - val_acc: 0.9155\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9183 - val_loss: 0.1807 - val_acc: 0.9157\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.18065 to 0.18060, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9200 - val_loss: 0.1806 - val_acc: 0.9163\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9202 - val_loss: 0.1808 - val_acc: 0.9153\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9175 - val_loss: 0.1808 - val_acc: 0.9142\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.18060 to 0.18054, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9203 - val_loss: 0.1805 - val_acc: 0.9168\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "1s - loss: 0.1737 - acc: 0.9190 - val_loss: 0.1807 - val_acc: 0.9176\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9185 - val_loss: 0.1806 - val_acc: 0.9143\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.18054 to 0.18033, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9196 - val_loss: 0.1803 - val_acc: 0.9165\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.18033 to 0.18028, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9184 - val_loss: 0.1803 - val_acc: 0.9172\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9176 - val_loss: 0.1807 - val_acc: 0.9136\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.18028 to 0.18006, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9178 - val_loss: 0.1801 - val_acc: 0.9167\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9193 - val_loss: 0.1804 - val_acc: 0.9163\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9182 - val_loss: 0.1801 - val_acc: 0.9145\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9185 - val_loss: 0.1804 - val_acc: 0.9165\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9203 - val_loss: 0.1804 - val_acc: 0.9161\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9189 - val_loss: 0.1809 - val_acc: 0.9151\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.18006 to 0.17964, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9175 - val_loss: 0.1796 - val_acc: 0.9178\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9198 - val_loss: 0.1799 - val_acc: 0.9176\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9213 - val_loss: 0.1801 - val_acc: 0.9151\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17964 to 0.17948, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9198 - val_loss: 0.1795 - val_acc: 0.9167\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9205 - val_loss: 0.1805 - val_acc: 0.9142\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9198 - val_loss: 0.1797 - val_acc: 0.9167\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17948 to 0.17922, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9197 - val_loss: 0.1792 - val_acc: 0.9176\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9193 - val_loss: 0.1794 - val_acc: 0.9155\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9195 - val_loss: 0.1793 - val_acc: 0.9168\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "1s - loss: 0.1716 - acc: 0.9191 - val_loss: 0.1792 - val_acc: 0.9182\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9198 - val_loss: 0.1796 - val_acc: 0.9149\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.17922 to 0.17918, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9205 - val_loss: 0.1792 - val_acc: 0.9161\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9208 - val_loss: 0.1802 - val_acc: 0.9143\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9197 - val_loss: 0.1795 - val_acc: 0.9172\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9198 - val_loss: 0.1796 - val_acc: 0.9178\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9192 - val_loss: 0.1797 - val_acc: 0.9165\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.17918 to 0.17906, saving model to best.model\n",
      "0s - loss: 0.1707 - acc: 0.9197 - val_loss: 0.1791 - val_acc: 0.9161\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.17906 to 0.17890, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9210 - val_loss: 0.1789 - val_acc: 0.9170\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9200 - val_loss: 0.1789 - val_acc: 0.9149\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9201 - val_loss: 0.1798 - val_acc: 0.9165\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.17890 to 0.17879, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9203 - val_loss: 0.1788 - val_acc: 0.9170\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9193 - val_loss: 0.1788 - val_acc: 0.9174\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9207 - val_loss: 0.1803 - val_acc: 0.9153\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.17879 to 0.17856, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9200 - val_loss: 0.1786 - val_acc: 0.9180\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.17856 to 0.17830, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9197 - val_loss: 0.1783 - val_acc: 0.9161\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33599, saving model to best.model\n",
      "0s - loss: 0.3807 - acc: 0.8842 - val_loss: 0.3360 - val_acc: 0.8836\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33599 to 0.24945, saving model to best.model\n",
      "0s - loss: 0.3012 - acc: 0.8924 - val_loss: 0.2495 - val_acc: 0.8984\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24945 to 0.21547, saving model to best.model\n",
      "0s - loss: 0.2447 - acc: 0.9007 - val_loss: 0.2155 - val_acc: 0.9059\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21547 to 0.20564, saving model to best.model\n",
      "0s - loss: 0.2189 - acc: 0.9064 - val_loss: 0.2056 - val_acc: 0.9063\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20564 to 0.20159, saving model to best.model\n",
      "0s - loss: 0.2113 - acc: 0.9076 - val_loss: 0.2016 - val_acc: 0.9063\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20159 to 0.19923, saving model to best.model\n",
      "0s - loss: 0.2036 - acc: 0.9082 - val_loss: 0.1992 - val_acc: 0.9072\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19923 to 0.19863, saving model to best.model\n",
      "1s - loss: 0.1981 - acc: 0.9077 - val_loss: 0.1986 - val_acc: 0.9061\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9111 - val_loss: 0.1989 - val_acc: 0.9082\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19863 to 0.19784, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9090 - val_loss: 0.1978 - val_acc: 0.9070\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "1s - loss: 0.1938 - acc: 0.9115 - val_loss: 0.1980 - val_acc: 0.9069\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9104 - val_loss: 0.1980 - val_acc: 0.9069\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9110 - val_loss: 0.1997 - val_acc: 0.9063\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19784 to 0.19756, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9115 - val_loss: 0.1976 - val_acc: 0.9070\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9118 - val_loss: 0.1978 - val_acc: 0.9065\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19756 to 0.19701, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9110 - val_loss: 0.1970 - val_acc: 0.9072\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9127 - val_loss: 0.1978 - val_acc: 0.9088\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19701 to 0.19671, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9144 - val_loss: 0.1967 - val_acc: 0.9067\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9119 - val_loss: 0.1995 - val_acc: 0.9090\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19671 to 0.19667, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9133 - val_loss: 0.1967 - val_acc: 0.9074\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9140 - val_loss: 0.1972 - val_acc: 0.9069\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9134 - val_loss: 0.1992 - val_acc: 0.9092\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9115 - val_loss: 0.1971 - val_acc: 0.9070\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19667 to 0.19630, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9131 - val_loss: 0.1963 - val_acc: 0.9065\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19630 to 0.19580, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9135 - val_loss: 0.1958 - val_acc: 0.9078\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9134 - val_loss: 0.1974 - val_acc: 0.9084\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19580 to 0.19562, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9118 - val_loss: 0.1956 - val_acc: 0.9069\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9136 - val_loss: 0.1973 - val_acc: 0.9084\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9134 - val_loss: 0.1962 - val_acc: 0.9078\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19562 to 0.19485, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9142 - val_loss: 0.1949 - val_acc: 0.9084\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9127 - val_loss: 0.1950 - val_acc: 0.9080\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9145 - val_loss: 0.1950 - val_acc: 0.9078\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19485 to 0.19484, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9135 - val_loss: 0.1948 - val_acc: 0.9092\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9135 - val_loss: 0.1957 - val_acc: 0.9088\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9131 - val_loss: 0.1960 - val_acc: 0.9097\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9141 - val_loss: 0.1957 - val_acc: 0.9088\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9156 - val_loss: 0.1950 - val_acc: 0.9078\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9128 - val_loss: 0.1948 - val_acc: 0.9076\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19484 to 0.19411, saving model to best.model\n",
      "0s - loss: 0.1820 - acc: 0.9159 - val_loss: 0.1941 - val_acc: 0.9088\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9156 - val_loss: 0.1942 - val_acc: 0.9078\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19411 to 0.19380, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9151 - val_loss: 0.1938 - val_acc: 0.9074\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9161 - val_loss: 0.1943 - val_acc: 0.9078\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9145 - val_loss: 0.1952 - val_acc: 0.9078\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19380 to 0.19330, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9163 - val_loss: 0.1933 - val_acc: 0.9086\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9147 - val_loss: 0.1940 - val_acc: 0.9092\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19330 to 0.19326, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9165 - val_loss: 0.1933 - val_acc: 0.9094\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9153 - val_loss: 0.1945 - val_acc: 0.9078\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9138 - val_loss: 0.1936 - val_acc: 0.9088\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9167 - val_loss: 0.1943 - val_acc: 0.9105\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9155 - val_loss: 0.1953 - val_acc: 0.9088\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9174 - val_loss: 0.1934 - val_acc: 0.9095\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9157 - val_loss: 0.1939 - val_acc: 0.9103\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.19326 to 0.19316, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9149 - val_loss: 0.1932 - val_acc: 0.9095\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9163 - val_loss: 0.1940 - val_acc: 0.9101\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9166 - val_loss: 0.1942 - val_acc: 0.9111\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9171 - val_loss: 0.1932 - val_acc: 0.9094\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9156 - val_loss: 0.1938 - val_acc: 0.9095\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9163 - val_loss: 0.1936 - val_acc: 0.9105\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9158 - val_loss: 0.1941 - val_acc: 0.9101\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.19316 to 0.19265, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9174 - val_loss: 0.1927 - val_acc: 0.9111\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9174 - val_loss: 0.1948 - val_acc: 0.9097\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.19265 to 0.19245, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9167 - val_loss: 0.1924 - val_acc: 0.9107\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.19245 to 0.19212, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9171 - val_loss: 0.1921 - val_acc: 0.9103\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "1s - loss: 0.1790 - acc: 0.9157 - val_loss: 0.1934 - val_acc: 0.9088\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.19212 to 0.19167, saving model to best.model\n",
      "1s - loss: 0.1766 - acc: 0.9172 - val_loss: 0.1917 - val_acc: 0.9111\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9184 - val_loss: 0.1931 - val_acc: 0.9115\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "1s - loss: 0.1774 - acc: 0.9160 - val_loss: 0.1924 - val_acc: 0.9111\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9185 - val_loss: 0.1943 - val_acc: 0.9103\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9162 - val_loss: 0.1918 - val_acc: 0.9103\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.19167 to 0.19126, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9161 - val_loss: 0.1913 - val_acc: 0.9107\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9161 - val_loss: 0.1913 - val_acc: 0.9115\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9191 - val_loss: 0.1926 - val_acc: 0.9111\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9172 - val_loss: 0.1938 - val_acc: 0.9094\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9163 - val_loss: 0.1922 - val_acc: 0.9111\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9181 - val_loss: 0.1918 - val_acc: 0.9115\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9189 - val_loss: 0.1923 - val_acc: 0.9109\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9176 - val_loss: 0.1918 - val_acc: 0.9113\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9171 - val_loss: 0.1920 - val_acc: 0.9117\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9182 - val_loss: 0.1913 - val_acc: 0.9109\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9173 - val_loss: 0.1922 - val_acc: 0.9111\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.19126 to 0.19059, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9181 - val_loss: 0.1906 - val_acc: 0.9117\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9181 - val_loss: 0.1908 - val_acc: 0.9109\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9181 - val_loss: 0.1917 - val_acc: 0.9115\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9180 - val_loss: 0.1924 - val_acc: 0.9117\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9197 - val_loss: 0.1907 - val_acc: 0.9115\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9184 - val_loss: 0.1906 - val_acc: 0.9109\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.19059 to 0.19043, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9187 - val_loss: 0.1904 - val_acc: 0.9117\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9184 - val_loss: 0.1909 - val_acc: 0.9109\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9184 - val_loss: 0.1911 - val_acc: 0.9107\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.19043 to 0.19036, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9200 - val_loss: 0.1904 - val_acc: 0.9113\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9181 - val_loss: 0.1936 - val_acc: 0.9113\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9187 - val_loss: 0.1920 - val_acc: 0.9113\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.19036 to 0.18969, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9193 - val_loss: 0.1897 - val_acc: 0.9118\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9207 - val_loss: 0.1904 - val_acc: 0.9115\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.18969 to 0.18949, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9199 - val_loss: 0.1895 - val_acc: 0.9115\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9192 - val_loss: 0.1900 - val_acc: 0.9113\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9189 - val_loss: 0.1907 - val_acc: 0.9109\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "1s - loss: 0.1734 - acc: 0.9193 - val_loss: 0.1899 - val_acc: 0.9111\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9184 - val_loss: 0.1896 - val_acc: 0.9099\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9178 - val_loss: 0.1897 - val_acc: 0.9120\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9192 - val_loss: 0.1907 - val_acc: 0.9115\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9195 - val_loss: 0.1900 - val_acc: 0.9111\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18949 to 0.18902, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9189 - val_loss: 0.1890 - val_acc: 0.9118\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9186 - val_loss: 0.1901 - val_acc: 0.9118\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18902 to 0.18891, saving model to best.model\n",
      "0s - loss: 0.1706 - acc: 0.9212 - val_loss: 0.1889 - val_acc: 0.9111\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9206 - val_loss: 0.1901 - val_acc: 0.9101\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9187 - val_loss: 0.1896 - val_acc: 0.9113\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9203 - val_loss: 0.1897 - val_acc: 0.9120\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9202 - val_loss: 0.1895 - val_acc: 0.9105\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9199 - val_loss: 0.1898 - val_acc: 0.9103\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9203 - val_loss: 0.1893 - val_acc: 0.9111\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9220 - val_loss: 0.1901 - val_acc: 0.9111\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9210 - val_loss: 0.1902 - val_acc: 0.9111\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9208 - val_loss: 0.1908 - val_acc: 0.9109\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.18891 to 0.18824, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9205 - val_loss: 0.1882 - val_acc: 0.9105\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9200 - val_loss: 0.1896 - val_acc: 0.9107\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9206 - val_loss: 0.1896 - val_acc: 0.9109\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9207 - val_loss: 0.1911 - val_acc: 0.9120\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9201 - val_loss: 0.1910 - val_acc: 0.9118\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9212 - val_loss: 0.1893 - val_acc: 0.9111\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9211 - val_loss: 0.1890 - val_acc: 0.9111\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9200 - val_loss: 0.1900 - val_acc: 0.9136\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9213 - val_loss: 0.1921 - val_acc: 0.9118\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9200 - val_loss: 0.1889 - val_acc: 0.9115\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9209 - val_loss: 0.1888 - val_acc: 0.9118\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9196 - val_loss: 0.1899 - val_acc: 0.9120\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9205 - val_loss: 0.1895 - val_acc: 0.9109\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9207 - val_loss: 0.1885 - val_acc: 0.9117\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9189 - val_loss: 0.1915 - val_acc: 0.9101\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9212 - val_loss: 0.1908 - val_acc: 0.9118\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9203 - val_loss: 0.1903 - val_acc: 0.9122\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9217 - val_loss: 0.1897 - val_acc: 0.9126\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9217 - val_loss: 0.1894 - val_acc: 0.9124\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9214 - val_loss: 0.1900 - val_acc: 0.9120\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9230 - val_loss: 0.1894 - val_acc: 0.9117\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9218 - val_loss: 0.1888 - val_acc: 0.9126\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9213 - val_loss: 0.1903 - val_acc: 0.9128\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9233 - val_loss: 0.1898 - val_acc: 0.9132\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9227 - val_loss: 0.1894 - val_acc: 0.9124\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9227 - val_loss: 0.1895 - val_acc: 0.9115\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9226 - val_loss: 0.1897 - val_acc: 0.9113\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32208, saving model to best.model\n",
      "0s - loss: 0.3891 - acc: 0.8782 - val_loss: 0.3221 - val_acc: 0.8907\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32208 to 0.24078, saving model to best.model\n",
      "0s - loss: 0.3135 - acc: 0.8904 - val_loss: 0.2408 - val_acc: 0.9015\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24078 to 0.20377, saving model to best.model\n",
      "0s - loss: 0.2531 - acc: 0.8972 - val_loss: 0.2038 - val_acc: 0.9080\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20377 to 0.19488, saving model to best.model\n",
      "0s - loss: 0.2267 - acc: 0.9032 - val_loss: 0.1949 - val_acc: 0.9092\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19488 to 0.19210, saving model to best.model\n",
      "0s - loss: 0.2158 - acc: 0.9055 - val_loss: 0.1921 - val_acc: 0.9095\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19210 to 0.18898, saving model to best.model\n",
      "0s - loss: 0.2105 - acc: 0.9052 - val_loss: 0.1890 - val_acc: 0.9101\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18898 to 0.18665, saving model to best.model\n",
      "0s - loss: 0.2058 - acc: 0.9065 - val_loss: 0.1867 - val_acc: 0.9117\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2061 - acc: 0.9059 - val_loss: 0.1876 - val_acc: 0.9105\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18665 to 0.18597, saving model to best.model\n",
      "1s - loss: 0.2019 - acc: 0.9064 - val_loss: 0.1860 - val_acc: 0.9122\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18597 to 0.18570, saving model to best.model\n",
      "0s - loss: 0.2023 - acc: 0.9081 - val_loss: 0.1857 - val_acc: 0.9115\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2013 - acc: 0.9072 - val_loss: 0.1861 - val_acc: 0.9109\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18570 to 0.18528, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9071 - val_loss: 0.1853 - val_acc: 0.9107\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9078 - val_loss: 0.1858 - val_acc: 0.9115\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9088 - val_loss: 0.1856 - val_acc: 0.9113\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9103 - val_loss: 0.1859 - val_acc: 0.9124\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "1s - loss: 0.1972 - acc: 0.9096 - val_loss: 0.1856 - val_acc: 0.9120\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9087 - val_loss: 0.1864 - val_acc: 0.9111\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18528 to 0.18482, saving model to best.model\n",
      "0s - loss: 0.1961 - acc: 0.9081 - val_loss: 0.1848 - val_acc: 0.9115\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9104 - val_loss: 0.1852 - val_acc: 0.9124\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18482 to 0.18466, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9100 - val_loss: 0.1847 - val_acc: 0.9124\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18466 to 0.18445, saving model to best.model\n",
      "0s - loss: 0.1959 - acc: 0.9104 - val_loss: 0.1845 - val_acc: 0.9126\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18445 to 0.18407, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9102 - val_loss: 0.1841 - val_acc: 0.9097\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9107 - val_loss: 0.1842 - val_acc: 0.9107\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9082 - val_loss: 0.1847 - val_acc: 0.9099\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1928 - acc: 0.9105 - val_loss: 0.1841 - val_acc: 0.9105\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1914 - acc: 0.9104 - val_loss: 0.1844 - val_acc: 0.9101\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18407 to 0.18337, saving model to best.model\n",
      "0s - loss: 0.1936 - acc: 0.9116 - val_loss: 0.1834 - val_acc: 0.9118\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18337 to 0.18331, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9114 - val_loss: 0.1833 - val_acc: 0.9122\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9119 - val_loss: 0.1833 - val_acc: 0.9124\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18331 to 0.18308, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9102 - val_loss: 0.1831 - val_acc: 0.9124\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9118 - val_loss: 0.1831 - val_acc: 0.9111\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9102 - val_loss: 0.1832 - val_acc: 0.9122\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9142 - val_loss: 0.1836 - val_acc: 0.9113\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18308 to 0.18228, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9111 - val_loss: 0.1823 - val_acc: 0.9101\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9131 - val_loss: 0.1823 - val_acc: 0.9115\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9128 - val_loss: 0.1825 - val_acc: 0.9118\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18228 to 0.18178, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9123 - val_loss: 0.1818 - val_acc: 0.9101\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9131 - val_loss: 0.1818 - val_acc: 0.9109\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18178 to 0.18161, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9138 - val_loss: 0.1816 - val_acc: 0.9109\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18161 to 0.18141, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9120 - val_loss: 0.1814 - val_acc: 0.9105\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9143 - val_loss: 0.1816 - val_acc: 0.9122\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9133 - val_loss: 0.1814 - val_acc: 0.9118\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9135 - val_loss: 0.1814 - val_acc: 0.9128\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9118 - val_loss: 0.1816 - val_acc: 0.9134\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18141 to 0.18104, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9138 - val_loss: 0.1810 - val_acc: 0.9113\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18104 to 0.18080, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9138 - val_loss: 0.1808 - val_acc: 0.9111\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9142 - val_loss: 0.1815 - val_acc: 0.9124\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9129 - val_loss: 0.1819 - val_acc: 0.9122\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18080 to 0.18075, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9147 - val_loss: 0.1807 - val_acc: 0.9122\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18075 to 0.18061, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9125 - val_loss: 0.1806 - val_acc: 0.9124\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9140 - val_loss: 0.1815 - val_acc: 0.9122\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9142 - val_loss: 0.1808 - val_acc: 0.9140\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18061 to 0.18035, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9134 - val_loss: 0.1803 - val_acc: 0.9136\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9140 - val_loss: 0.1804 - val_acc: 0.9113\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9129 - val_loss: 0.1807 - val_acc: 0.9138\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9154 - val_loss: 0.1805 - val_acc: 0.9120\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18035 to 0.18013, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9162 - val_loss: 0.1801 - val_acc: 0.9132\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9141 - val_loss: 0.1803 - val_acc: 0.9128\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18013 to 0.17996, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9151 - val_loss: 0.1800 - val_acc: 0.9143\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.17996 to 0.17991, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9152 - val_loss: 0.1799 - val_acc: 0.9147\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9160 - val_loss: 0.1803 - val_acc: 0.9143\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17991 to 0.17980, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9162 - val_loss: 0.1798 - val_acc: 0.9134\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17980 to 0.17962, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9138 - val_loss: 0.1796 - val_acc: 0.9140\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9171 - val_loss: 0.1799 - val_acc: 0.9138\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9174 - val_loss: 0.1803 - val_acc: 0.9143\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9156 - val_loss: 0.1801 - val_acc: 0.9134\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9144 - val_loss: 0.1803 - val_acc: 0.9136\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9151 - val_loss: 0.1799 - val_acc: 0.9134\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17962 to 0.17961, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9162 - val_loss: 0.1796 - val_acc: 0.9138\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9158 - val_loss: 0.1797 - val_acc: 0.9145\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9168 - val_loss: 0.1797 - val_acc: 0.9145\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17961 to 0.17953, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9162 - val_loss: 0.1795 - val_acc: 0.9140\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "1s - loss: 0.1810 - acc: 0.9164 - val_loss: 0.1799 - val_acc: 0.9118\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17953 to 0.17933, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9168 - val_loss: 0.1793 - val_acc: 0.9132\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9166 - val_loss: 0.1799 - val_acc: 0.9134\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9163 - val_loss: 0.1796 - val_acc: 0.9149\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9169 - val_loss: 0.1793 - val_acc: 0.9140\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9180 - val_loss: 0.1810 - val_acc: 0.9132\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17933 to 0.17920, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9170 - val_loss: 0.1792 - val_acc: 0.9142\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.17920 to 0.17899, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9170 - val_loss: 0.1790 - val_acc: 0.9143\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9172 - val_loss: 0.1790 - val_acc: 0.9143\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9165 - val_loss: 0.1796 - val_acc: 0.9140\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9176 - val_loss: 0.1791 - val_acc: 0.9138\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9169 - val_loss: 0.1792 - val_acc: 0.9132\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.17899 to 0.17889, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9160 - val_loss: 0.1789 - val_acc: 0.9143\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9176 - val_loss: 0.1793 - val_acc: 0.9143\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9175 - val_loss: 0.1792 - val_acc: 0.9140\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9174 - val_loss: 0.1791 - val_acc: 0.9140\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17889 to 0.17868, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9172 - val_loss: 0.1787 - val_acc: 0.9140\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17868 to 0.17850, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9180 - val_loss: 0.1785 - val_acc: 0.9138\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9194 - val_loss: 0.1792 - val_acc: 0.9138\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17850 to 0.17837, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9167 - val_loss: 0.1784 - val_acc: 0.9143\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9178 - val_loss: 0.1791 - val_acc: 0.9142\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9193 - val_loss: 0.1786 - val_acc: 0.9142\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9180 - val_loss: 0.1785 - val_acc: 0.9142\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9172 - val_loss: 0.1784 - val_acc: 0.9138\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9178 - val_loss: 0.1787 - val_acc: 0.9149\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9198 - val_loss: 0.1786 - val_acc: 0.9140\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9177 - val_loss: 0.1784 - val_acc: 0.9143\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9187 - val_loss: 0.1785 - val_acc: 0.9147\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9174 - val_loss: 0.1784 - val_acc: 0.9147\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9185 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9180 - val_loss: 0.1785 - val_acc: 0.9149\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17837 to 0.17812, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9188 - val_loss: 0.1781 - val_acc: 0.9145\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9197 - val_loss: 0.1786 - val_acc: 0.9145\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9187 - val_loss: 0.1781 - val_acc: 0.9147\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9191 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17812 to 0.17794, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9184 - val_loss: 0.1779 - val_acc: 0.9149\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9197 - val_loss: 0.1783 - val_acc: 0.9140\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9190 - val_loss: 0.1782 - val_acc: 0.9132\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.17794 to 0.17762, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9181 - val_loss: 0.1776 - val_acc: 0.9138\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9182 - val_loss: 0.1779 - val_acc: 0.9140\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9193 - val_loss: 0.1782 - val_acc: 0.9142\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9180 - val_loss: 0.1779 - val_acc: 0.9143\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9186 - val_loss: 0.1796 - val_acc: 0.9134\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9172 - val_loss: 0.1787 - val_acc: 0.9138\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "1s - loss: 0.1736 - acc: 0.9191 - val_loss: 0.1779 - val_acc: 0.9136\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9186 - val_loss: 0.1794 - val_acc: 0.9142\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9206 - val_loss: 0.1783 - val_acc: 0.9134\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9195 - val_loss: 0.1784 - val_acc: 0.9153\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9192 - val_loss: 0.1779 - val_acc: 0.9149\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9210 - val_loss: 0.1777 - val_acc: 0.9140\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9214 - val_loss: 0.1778 - val_acc: 0.9142\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9200 - val_loss: 0.1781 - val_acc: 0.9120\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9177 - val_loss: 0.1777 - val_acc: 0.9134\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17762 to 0.17749, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9188 - val_loss: 0.1775 - val_acc: 0.9142\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9200 - val_loss: 0.1778 - val_acc: 0.9140\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9199 - val_loss: 0.1792 - val_acc: 0.9120\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9193 - val_loss: 0.1780 - val_acc: 0.9149\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9186 - val_loss: 0.1775 - val_acc: 0.9142\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9190 - val_loss: 0.1788 - val_acc: 0.9155\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "1s - loss: 0.1744 - acc: 0.9185 - val_loss: 0.1776 - val_acc: 0.9145\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17749 to 0.17712, saving model to best.model\n",
      "1s - loss: 0.1735 - acc: 0.9203 - val_loss: 0.1771 - val_acc: 0.9138\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "1s - loss: 0.1730 - acc: 0.9206 - val_loss: 0.1774 - val_acc: 0.9142\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "1s - loss: 0.1718 - acc: 0.9216 - val_loss: 0.1781 - val_acc: 0.9143\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9201 - val_loss: 0.1775 - val_acc: 0.9151\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9204 - val_loss: 0.1772 - val_acc: 0.9147\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9196 - val_loss: 0.1772 - val_acc: 0.9151\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17712 to 0.17709, saving model to best.model\n",
      "1s - loss: 0.1713 - acc: 0.9185 - val_loss: 0.1771 - val_acc: 0.9138\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9207 - val_loss: 0.1773 - val_acc: 0.9151\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "1s - loss: 0.1727 - acc: 0.9200 - val_loss: 0.1778 - val_acc: 0.9136\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17709 to 0.17701, saving model to best.model\n",
      "1s - loss: 0.1719 - acc: 0.9191 - val_loss: 0.1770 - val_acc: 0.9145\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "1s - loss: 0.1704 - acc: 0.9197 - val_loss: 0.1776 - val_acc: 0.9136\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9196 - val_loss: 0.1773 - val_acc: 0.9153\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.17701 to 0.17690, saving model to best.model\n",
      "0s - loss: 0.1700 - acc: 0.9213 - val_loss: 0.1769 - val_acc: 0.9142\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9213 - val_loss: 0.1773 - val_acc: 0.9153\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17690 to 0.17689, saving model to best.model\n",
      "0s - loss: 0.1706 - acc: 0.9208 - val_loss: 0.1769 - val_acc: 0.9142\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9205 - val_loss: 0.1779 - val_acc: 0.9143\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9204 - val_loss: 0.1770 - val_acc: 0.9140\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9199 - val_loss: 0.1775 - val_acc: 0.9145\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9212 - val_loss: 0.1798 - val_acc: 0.9147\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17689 to 0.17656, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9220 - val_loss: 0.1766 - val_acc: 0.9145\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9212 - val_loss: 0.1772 - val_acc: 0.9149\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9209 - val_loss: 0.1769 - val_acc: 0.9157\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9200 - val_loss: 0.1769 - val_acc: 0.9136\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9215 - val_loss: 0.1771 - val_acc: 0.9136\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9222 - val_loss: 0.1769 - val_acc: 0.9145\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9219 - val_loss: 0.1768 - val_acc: 0.9145\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "1s - loss: 0.1690 - acc: 0.9224 - val_loss: 0.1776 - val_acc: 0.9140\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9219 - val_loss: 0.1770 - val_acc: 0.9161\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9214 - val_loss: 0.1788 - val_acc: 0.9147\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9202 - val_loss: 0.1772 - val_acc: 0.9145\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9227 - val_loss: 0.1776 - val_acc: 0.9136\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9223 - val_loss: 0.1778 - val_acc: 0.9147\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9216 - val_loss: 0.1777 - val_acc: 0.9143\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.17656 to 0.17653, saving model to best.model\n",
      "0s - loss: 0.1690 - acc: 0.9217 - val_loss: 0.1765 - val_acc: 0.9149\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9229 - val_loss: 0.1774 - val_acc: 0.9145\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9203 - val_loss: 0.1771 - val_acc: 0.9155\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9216 - val_loss: 0.1768 - val_acc: 0.9145\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9229 - val_loss: 0.1776 - val_acc: 0.9161\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9211 - val_loss: 0.1767 - val_acc: 0.9145\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9245 - val_loss: 0.1772 - val_acc: 0.9151\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9217 - val_loss: 0.1778 - val_acc: 0.9140\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9227 - val_loss: 0.1766 - val_acc: 0.9145\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9212 - val_loss: 0.1782 - val_acc: 0.9157\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9218 - val_loss: 0.1767 - val_acc: 0.9140\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9224 - val_loss: 0.1780 - val_acc: 0.9140\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9248 - val_loss: 0.1768 - val_acc: 0.9143\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9235 - val_loss: 0.1769 - val_acc: 0.9136\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9228 - val_loss: 0.1792 - val_acc: 0.9151\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9227 - val_loss: 0.1775 - val_acc: 0.9147\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9233 - val_loss: 0.1765 - val_acc: 0.9140\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1657 - acc: 0.9223 - val_loss: 0.1772 - val_acc: 0.9140\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9231 - val_loss: 0.1766 - val_acc: 0.9142\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1653 - acc: 0.9232 - val_loss: 0.1773 - val_acc: 0.9138\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.17653 to 0.17607, saving model to best.model\n",
      "0s - loss: 0.1669 - acc: 0.9229 - val_loss: 0.1761 - val_acc: 0.9145\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9238 - val_loss: 0.1765 - val_acc: 0.9136\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1664 - acc: 0.9221 - val_loss: 0.1764 - val_acc: 0.9145\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1657 - acc: 0.9231 - val_loss: 0.1772 - val_acc: 0.9142\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9244 - val_loss: 0.1769 - val_acc: 0.9151\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9232 - val_loss: 0.1774 - val_acc: 0.9151\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1648 - acc: 0.9239 - val_loss: 0.1775 - val_acc: 0.9145\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9233 - val_loss: 0.1768 - val_acc: 0.9151\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1639 - acc: 0.9242 - val_loss: 0.1765 - val_acc: 0.9161\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9251 - val_loss: 0.1771 - val_acc: 0.9140\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9244 - val_loss: 0.1774 - val_acc: 0.9134\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1636 - acc: 0.9240 - val_loss: 0.1777 - val_acc: 0.9145\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1624 - acc: 0.9248 - val_loss: 0.1764 - val_acc: 0.9136\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1650 - acc: 0.9236 - val_loss: 0.1768 - val_acc: 0.9149\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1650 - acc: 0.9246 - val_loss: 0.1773 - val_acc: 0.9147\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33980, saving model to best.model\n",
      "0s - loss: 0.4064 - acc: 0.8722 - val_loss: 0.3398 - val_acc: 0.8857\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33980 to 0.24936, saving model to best.model\n",
      "0s - loss: 0.3346 - acc: 0.8835 - val_loss: 0.2494 - val_acc: 0.8934\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24936 to 0.20356, saving model to best.model\n",
      "1s - loss: 0.2657 - acc: 0.8920 - val_loss: 0.2036 - val_acc: 0.9099\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20356 to 0.19348, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9009 - val_loss: 0.1935 - val_acc: 0.9118\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19348 to 0.18997, saving model to best.model\n",
      "0s - loss: 0.2191 - acc: 0.9025 - val_loss: 0.1900 - val_acc: 0.9122\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18997 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.2160 - acc: 0.9027 - val_loss: 0.1888 - val_acc: 0.9132\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.2125 - acc: 0.9043 - val_loss: 0.1889 - val_acc: 0.9132\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18876 to 0.18819, saving model to best.model\n",
      "0s - loss: 0.2075 - acc: 0.9059 - val_loss: 0.1882 - val_acc: 0.9122\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18819 to 0.18814, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9063 - val_loss: 0.1881 - val_acc: 0.9126\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9064 - val_loss: 0.1885 - val_acc: 0.9134\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2023 - acc: 0.9067 - val_loss: 0.1883 - val_acc: 0.9128\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2011 - acc: 0.9044 - val_loss: 0.1885 - val_acc: 0.9132\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2019 - acc: 0.9071 - val_loss: 0.1889 - val_acc: 0.9126\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1995 - acc: 0.9046 - val_loss: 0.1903 - val_acc: 0.9134\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1989 - acc: 0.9076 - val_loss: 0.1892 - val_acc: 0.9113\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1977 - acc: 0.9101 - val_loss: 0.1890 - val_acc: 0.9138\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1977 - acc: 0.9076 - val_loss: 0.1889 - val_acc: 0.9128\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9077 - val_loss: 0.1885 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9089 - val_loss: 0.1887 - val_acc: 0.9117\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9089 - val_loss: 0.1885 - val_acc: 0.9115\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9079 - val_loss: 0.1887 - val_acc: 0.9130\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1956 - acc: 0.9101 - val_loss: 0.1885 - val_acc: 0.9130\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1951 - acc: 0.9090 - val_loss: 0.1887 - val_acc: 0.9134\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1956 - acc: 0.9086 - val_loss: 0.1885 - val_acc: 0.9109\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1955 - acc: 0.9097 - val_loss: 0.1882 - val_acc: 0.9118\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9071 - val_loss: 0.1883 - val_acc: 0.9120\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9091 - val_loss: 0.1884 - val_acc: 0.9128\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18814 to 0.18813, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9081 - val_loss: 0.1881 - val_acc: 0.9120\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9091 - val_loss: 0.1888 - val_acc: 0.9126\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18813 to 0.18809, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9095 - val_loss: 0.1881 - val_acc: 0.9122\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18809 to 0.18805, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9073 - val_loss: 0.1881 - val_acc: 0.9126\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18805 to 0.18763, saving model to best.model\n",
      "0s - loss: 0.1940 - acc: 0.9098 - val_loss: 0.1876 - val_acc: 0.9130\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1925 - acc: 0.9108 - val_loss: 0.1880 - val_acc: 0.9124\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9094 - val_loss: 0.1877 - val_acc: 0.9130\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18763 to 0.18759, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9097 - val_loss: 0.1876 - val_acc: 0.9120\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18759 to 0.18737, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9102 - val_loss: 0.1874 - val_acc: 0.9138\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9099 - val_loss: 0.1878 - val_acc: 0.9143\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9090 - val_loss: 0.1876 - val_acc: 0.9136\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9102 - val_loss: 0.1876 - val_acc: 0.9136\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18737 to 0.18722, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9092 - val_loss: 0.1872 - val_acc: 0.9128\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18722 to 0.18683, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9122 - val_loss: 0.1868 - val_acc: 0.9142\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9089 - val_loss: 0.1870 - val_acc: 0.9143\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1909 - acc: 0.9102 - val_loss: 0.1869 - val_acc: 0.9128\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18683 to 0.18649, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9111 - val_loss: 0.1865 - val_acc: 0.9140\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9101 - val_loss: 0.1866 - val_acc: 0.9136\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9108 - val_loss: 0.1869 - val_acc: 0.9128\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18649 to 0.18632, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9114 - val_loss: 0.1863 - val_acc: 0.9142\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18632 to 0.18599, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9119 - val_loss: 0.1860 - val_acc: 0.9138\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9120 - val_loss: 0.1866 - val_acc: 0.9134\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9118 - val_loss: 0.1861 - val_acc: 0.9140\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9105 - val_loss: 0.1861 - val_acc: 0.9149\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18599 to 0.18573, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9128 - val_loss: 0.1857 - val_acc: 0.9138\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9129 - val_loss: 0.1862 - val_acc: 0.9155\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9119 - val_loss: 0.1859 - val_acc: 0.9147\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18573 to 0.18515, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9129 - val_loss: 0.1852 - val_acc: 0.9149\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9121 - val_loss: 0.1853 - val_acc: 0.9155\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18515 to 0.18499, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9115 - val_loss: 0.1850 - val_acc: 0.9147\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9128 - val_loss: 0.1852 - val_acc: 0.9149\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18499 to 0.18472, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9126 - val_loss: 0.1847 - val_acc: 0.9147\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9126 - val_loss: 0.1852 - val_acc: 0.9155\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9131 - val_loss: 0.1851 - val_acc: 0.9167\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9142 - val_loss: 0.1848 - val_acc: 0.9145\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18472 to 0.18444, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9138 - val_loss: 0.1844 - val_acc: 0.9163\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9128 - val_loss: 0.1846 - val_acc: 0.9157\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18444 to 0.18419, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9144 - val_loss: 0.1842 - val_acc: 0.9140\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18419 to 0.18362, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9133 - val_loss: 0.1836 - val_acc: 0.9151\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9135 - val_loss: 0.1838 - val_acc: 0.9159\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18362 to 0.18357, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9155 - val_loss: 0.1836 - val_acc: 0.9165\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9139 - val_loss: 0.1837 - val_acc: 0.9155\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9134 - val_loss: 0.1839 - val_acc: 0.9155\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9143 - val_loss: 0.1837 - val_acc: 0.9165\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9151 - val_loss: 0.1840 - val_acc: 0.9155\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9132 - val_loss: 0.1844 - val_acc: 0.9140\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9138 - val_loss: 0.1837 - val_acc: 0.9145\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9150 - val_loss: 0.1838 - val_acc: 0.9155\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18357 to 0.18293, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9141 - val_loss: 0.1829 - val_acc: 0.9159\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9134 - val_loss: 0.1840 - val_acc: 0.9143\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9137 - val_loss: 0.1837 - val_acc: 0.9157\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9142 - val_loss: 0.1832 - val_acc: 0.9157\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9148 - val_loss: 0.1830 - val_acc: 0.9157\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18293 to 0.18274, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9150 - val_loss: 0.1827 - val_acc: 0.9159\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9147 - val_loss: 0.1828 - val_acc: 0.9151\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.18274 to 0.18247, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9138 - val_loss: 0.1825 - val_acc: 0.9161\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9149 - val_loss: 0.1825 - val_acc: 0.9157\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9138 - val_loss: 0.1826 - val_acc: 0.9172\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.18247 to 0.18219, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9140 - val_loss: 0.1822 - val_acc: 0.9163\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18219 to 0.18205, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9145 - val_loss: 0.1821 - val_acc: 0.9163\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18205 to 0.18174, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9148 - val_loss: 0.1817 - val_acc: 0.9159\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9143 - val_loss: 0.1821 - val_acc: 0.9167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9148 - val_loss: 0.1820 - val_acc: 0.9165\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18174 to 0.18166, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9144 - val_loss: 0.1817 - val_acc: 0.9161\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18166 to 0.18155, saving model to best.model\n",
      "1s - loss: 0.1819 - acc: 0.9156 - val_loss: 0.1816 - val_acc: 0.9161\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9144 - val_loss: 0.1819 - val_acc: 0.9153\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9158 - val_loss: 0.1819 - val_acc: 0.9163\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.18155 to 0.18140, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9146 - val_loss: 0.1814 - val_acc: 0.9167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9156 - val_loss: 0.1824 - val_acc: 0.9167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9150 - val_loss: 0.1817 - val_acc: 0.9168\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18140 to 0.18134, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9158 - val_loss: 0.1813 - val_acc: 0.9165\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9168 - val_loss: 0.1819 - val_acc: 0.9170\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18134 to 0.18133, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9153 - val_loss: 0.1813 - val_acc: 0.9172\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9151 - val_loss: 0.1814 - val_acc: 0.9167\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18133 to 0.18123, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9166 - val_loss: 0.1812 - val_acc: 0.9167\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18123 to 0.18103, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9178 - val_loss: 0.1810 - val_acc: 0.9168\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9162 - val_loss: 0.1819 - val_acc: 0.9159\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9165 - val_loss: 0.1818 - val_acc: 0.9172\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18103 to 0.18097, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9173 - val_loss: 0.1810 - val_acc: 0.9170\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18097 to 0.18078, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9166 - val_loss: 0.1808 - val_acc: 0.9172\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9169 - val_loss: 0.1814 - val_acc: 0.9168\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9166 - val_loss: 0.1809 - val_acc: 0.9167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18078 to 0.18042, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9163 - val_loss: 0.1804 - val_acc: 0.9180\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9160 - val_loss: 0.1808 - val_acc: 0.9161\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.18042 to 0.18023, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9163 - val_loss: 0.1802 - val_acc: 0.9176\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9190 - val_loss: 0.1804 - val_acc: 0.9176\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9177 - val_loss: 0.1804 - val_acc: 0.9174\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9162 - val_loss: 0.1824 - val_acc: 0.9176\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9166 - val_loss: 0.1807 - val_acc: 0.9170\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.18023 to 0.18017, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9173 - val_loss: 0.1802 - val_acc: 0.9188\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9175 - val_loss: 0.1806 - val_acc: 0.9178\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18017 to 0.18008, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9163 - val_loss: 0.1801 - val_acc: 0.9180\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.18008 to 0.17986, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9164 - val_loss: 0.1799 - val_acc: 0.9180\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9168 - val_loss: 0.1805 - val_acc: 0.9168\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17986 to 0.17955, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9165 - val_loss: 0.1795 - val_acc: 0.9186\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17955 to 0.17945, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9175 - val_loss: 0.1794 - val_acc: 0.9182\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9179 - val_loss: 0.1808 - val_acc: 0.9168\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9188 - val_loss: 0.1797 - val_acc: 0.9180\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9183 - val_loss: 0.1797 - val_acc: 0.9190\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9172 - val_loss: 0.1803 - val_acc: 0.9178\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9183 - val_loss: 0.1795 - val_acc: 0.9182\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17945 to 0.17908, saving model to best.model\n",
      "1s - loss: 0.1769 - acc: 0.9176 - val_loss: 0.1791 - val_acc: 0.9178\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9173 - val_loss: 0.1795 - val_acc: 0.9186\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9184 - val_loss: 0.1793 - val_acc: 0.9186\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9179 - val_loss: 0.1791 - val_acc: 0.9201\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17908 to 0.17886, saving model to best.model\n",
      "1s - loss: 0.1758 - acc: 0.9188 - val_loss: 0.1789 - val_acc: 0.9182\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9164 - val_loss: 0.1792 - val_acc: 0.9197\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9174 - val_loss: 0.1806 - val_acc: 0.9168\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17886 to 0.17884, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9177 - val_loss: 0.1788 - val_acc: 0.9188\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9202 - val_loss: 0.1795 - val_acc: 0.9190\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9184 - val_loss: 0.1797 - val_acc: 0.9203\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9199 - val_loss: 0.1791 - val_acc: 0.9199\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9196 - val_loss: 0.1798 - val_acc: 0.9201\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9183 - val_loss: 0.1789 - val_acc: 0.9193\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9179 - val_loss: 0.1793 - val_acc: 0.9174\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9186 - val_loss: 0.1789 - val_acc: 0.9182\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17884 to 0.17854, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9191 - val_loss: 0.1785 - val_acc: 0.9182\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9195 - val_loss: 0.1789 - val_acc: 0.9186\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9183 - val_loss: 0.1788 - val_acc: 0.9180\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9182 - val_loss: 0.1787 - val_acc: 0.9205\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9191 - val_loss: 0.1788 - val_acc: 0.9184\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17854 to 0.17816, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9195 - val_loss: 0.1782 - val_acc: 0.9191\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9157 - val_loss: 0.1793 - val_acc: 0.9188\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9205 - val_loss: 0.1783 - val_acc: 0.9184\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17816 to 0.17802, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9192 - val_loss: 0.1780 - val_acc: 0.9188\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9199 - val_loss: 0.1783 - val_acc: 0.9191\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9209 - val_loss: 0.1783 - val_acc: 0.9199\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.17802 to 0.17788, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9194 - val_loss: 0.1779 - val_acc: 0.9191\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17788 to 0.17752, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9189 - val_loss: 0.1775 - val_acc: 0.9193\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9214 - val_loss: 0.1778 - val_acc: 0.9195\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9194 - val_loss: 0.1779 - val_acc: 0.9180\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "1s - loss: 0.1731 - acc: 0.9187 - val_loss: 0.1780 - val_acc: 0.9193\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9187 - val_loss: 0.1782 - val_acc: 0.9197\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9202 - val_loss: 0.1778 - val_acc: 0.9188\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9210 - val_loss: 0.1780 - val_acc: 0.9195\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17752 to 0.17733, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9188 - val_loss: 0.1773 - val_acc: 0.9193\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9199 - val_loss: 0.1775 - val_acc: 0.9195\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "1s - loss: 0.1712 - acc: 0.9208 - val_loss: 0.1776 - val_acc: 0.9186\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9194 - val_loss: 0.1776 - val_acc: 0.9188\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9202 - val_loss: 0.1777 - val_acc: 0.9191\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9204 - val_loss: 0.1779 - val_acc: 0.9178\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9195 - val_loss: 0.1781 - val_acc: 0.9178\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9206 - val_loss: 0.1775 - val_acc: 0.9191\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9191 - val_loss: 0.1774 - val_acc: 0.9191\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.17733 to 0.17722, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9187 - val_loss: 0.1772 - val_acc: 0.9197\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17722 to 0.17672, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9198 - val_loss: 0.1767 - val_acc: 0.9195\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9208 - val_loss: 0.1771 - val_acc: 0.9186\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9198 - val_loss: 0.1768 - val_acc: 0.9190\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17672 to 0.17663, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9211 - val_loss: 0.1766 - val_acc: 0.9191\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9199 - val_loss: 0.1770 - val_acc: 0.9178\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9198 - val_loss: 0.1771 - val_acc: 0.9182\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9206 - val_loss: 0.1771 - val_acc: 0.9191\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "1s - loss: 0.1707 - acc: 0.9195 - val_loss: 0.1771 - val_acc: 0.9193\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9197 - val_loss: 0.1772 - val_acc: 0.9191\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9199 - val_loss: 0.1771 - val_acc: 0.9188\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9201 - val_loss: 0.1772 - val_acc: 0.9184\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9220 - val_loss: 0.1772 - val_acc: 0.9190\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9210 - val_loss: 0.1771 - val_acc: 0.9191\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9199 - val_loss: 0.1768 - val_acc: 0.9186\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9212 - val_loss: 0.1772 - val_acc: 0.9190\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.17663 to 0.17650, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9210 - val_loss: 0.1765 - val_acc: 0.9191\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9205 - val_loss: 0.1765 - val_acc: 0.9182\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9195 - val_loss: 0.1776 - val_acc: 0.9180\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9222 - val_loss: 0.1767 - val_acc: 0.9182\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9212 - val_loss: 0.1765 - val_acc: 0.9188\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9225 - val_loss: 0.1771 - val_acc: 0.9182\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9210 - val_loss: 0.1771 - val_acc: 0.9180\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9199 - val_loss: 0.1782 - val_acc: 0.9172\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9212 - val_loss: 0.1778 - val_acc: 0.9172\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9223 - val_loss: 0.1768 - val_acc: 0.9190\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "1s - loss: 0.1704 - acc: 0.9199 - val_loss: 0.1769 - val_acc: 0.9184\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9229 - val_loss: 0.1768 - val_acc: 0.9178\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9212 - val_loss: 0.1766 - val_acc: 0.9197\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32173, saving model to best.model\n",
      "0s - loss: 0.3715 - acc: 0.8865 - val_loss: 0.3217 - val_acc: 0.8859\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32173 to 0.23945, saving model to best.model\n",
      "0s - loss: 0.2988 - acc: 0.8897 - val_loss: 0.2395 - val_acc: 0.8992\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23945 to 0.20959, saving model to best.model\n",
      "0s - loss: 0.2467 - acc: 0.8980 - val_loss: 0.2096 - val_acc: 0.9022\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20959 to 0.20541, saving model to best.model\n",
      "0s - loss: 0.2264 - acc: 0.9022 - val_loss: 0.2054 - val_acc: 0.9046\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20541 to 0.19793, saving model to best.model\n",
      "0s - loss: 0.2166 - acc: 0.9039 - val_loss: 0.1979 - val_acc: 0.9080\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19793 to 0.19786, saving model to best.model\n",
      "0s - loss: 0.2107 - acc: 0.9032 - val_loss: 0.1979 - val_acc: 0.9038\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19786 to 0.19592, saving model to best.model\n",
      "0s - loss: 0.2078 - acc: 0.9048 - val_loss: 0.1959 - val_acc: 0.9059\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19592 to 0.19473, saving model to best.model\n",
      "0s - loss: 0.2059 - acc: 0.9080 - val_loss: 0.1947 - val_acc: 0.9082\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19473 to 0.19434, saving model to best.model\n",
      "0s - loss: 0.2068 - acc: 0.9059 - val_loss: 0.1943 - val_acc: 0.9080\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19434 to 0.19433, saving model to best.model\n",
      "0s - loss: 0.2035 - acc: 0.9067 - val_loss: 0.1943 - val_acc: 0.9078\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19433 to 0.19403, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9068 - val_loss: 0.1940 - val_acc: 0.9076\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19403 to 0.19366, saving model to best.model\n",
      "1s - loss: 0.2004 - acc: 0.9067 - val_loss: 0.1937 - val_acc: 0.9076\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2001 - acc: 0.9082 - val_loss: 0.1946 - val_acc: 0.9078\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19366 to 0.19349, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9069 - val_loss: 0.1935 - val_acc: 0.9072\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19349 to 0.19347, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9095 - val_loss: 0.1935 - val_acc: 0.9082\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9068 - val_loss: 0.1936 - val_acc: 0.9072\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1973 - acc: 0.9099 - val_loss: 0.1943 - val_acc: 0.9059\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1986 - acc: 0.9070 - val_loss: 0.1936 - val_acc: 0.9070\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1968 - acc: 0.9100 - val_loss: 0.1944 - val_acc: 0.9047\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1977 - acc: 0.9091 - val_loss: 0.1950 - val_acc: 0.9042\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19347 to 0.19304, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9088 - val_loss: 0.1930 - val_acc: 0.9067\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19304 to 0.19288, saving model to best.model\n",
      "0s - loss: 0.1981 - acc: 0.9087 - val_loss: 0.1929 - val_acc: 0.9074\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19288 to 0.19277, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9096 - val_loss: 0.1928 - val_acc: 0.9069\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19277 to 0.19270, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9099 - val_loss: 0.1927 - val_acc: 0.9061\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1936 - acc: 0.9098 - val_loss: 0.1929 - val_acc: 0.9069\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19270 to 0.19219, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9090 - val_loss: 0.1922 - val_acc: 0.9067\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1951 - acc: 0.9108 - val_loss: 0.1930 - val_acc: 0.9040\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19219 to 0.19195, saving model to best.model\n",
      "0s - loss: 0.1943 - acc: 0.9109 - val_loss: 0.1919 - val_acc: 0.9057\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19195 to 0.19179, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9114 - val_loss: 0.1918 - val_acc: 0.9059\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9103 - val_loss: 0.1918 - val_acc: 0.9070\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "1s - loss: 0.1930 - acc: 0.9107 - val_loss: 0.1920 - val_acc: 0.9057\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9117 - val_loss: 0.1938 - val_acc: 0.9026\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19179 to 0.19143, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9087 - val_loss: 0.1914 - val_acc: 0.9065\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19143 to 0.19124, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9118 - val_loss: 0.1912 - val_acc: 0.9084\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9123 - val_loss: 0.1915 - val_acc: 0.9042\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9112 - val_loss: 0.1914 - val_acc: 0.9042\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19124 to 0.19066, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9105 - val_loss: 0.1907 - val_acc: 0.9055\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9113 - val_loss: 0.1908 - val_acc: 0.9061\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9102 - val_loss: 0.1932 - val_acc: 0.9047\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9113 - val_loss: 0.1915 - val_acc: 0.9030\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19066 to 0.19062, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9122 - val_loss: 0.1906 - val_acc: 0.9049\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9100 - val_loss: 0.1909 - val_acc: 0.9044\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19062 to 0.18984, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9112 - val_loss: 0.1898 - val_acc: 0.9063\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9109 - val_loss: 0.1900 - val_acc: 0.9065\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18984 to 0.18931, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9121 - val_loss: 0.1893 - val_acc: 0.9084\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9127 - val_loss: 0.1901 - val_acc: 0.9076\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9129 - val_loss: 0.1898 - val_acc: 0.9034\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9111 - val_loss: 0.1901 - val_acc: 0.9082\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18931 to 0.18898, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9097 - val_loss: 0.1890 - val_acc: 0.9078\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9122 - val_loss: 0.1894 - val_acc: 0.9044\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18898 to 0.18888, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9124 - val_loss: 0.1889 - val_acc: 0.9103\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18888 to 0.18870, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9112 - val_loss: 0.1887 - val_acc: 0.9072\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "1s - loss: 0.1875 - acc: 0.9123 - val_loss: 0.1889 - val_acc: 0.9057\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9138 - val_loss: 0.1892 - val_acc: 0.9053\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18870 to 0.18841, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9126 - val_loss: 0.1884 - val_acc: 0.9082\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "1s - loss: 0.1873 - acc: 0.9121 - val_loss: 0.1889 - val_acc: 0.9069\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9138 - val_loss: 0.1884 - val_acc: 0.9074\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9136 - val_loss: 0.1897 - val_acc: 0.9057\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9129 - val_loss: 0.1884 - val_acc: 0.9076\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18841 to 0.18818, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9126 - val_loss: 0.1882 - val_acc: 0.9070\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18818 to 0.18779, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9129 - val_loss: 0.1878 - val_acc: 0.9072\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9132 - val_loss: 0.1881 - val_acc: 0.9086\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9118 - val_loss: 0.1915 - val_acc: 0.9049\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18779 to 0.18760, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9136 - val_loss: 0.1876 - val_acc: 0.9080\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18760 to 0.18755, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9126 - val_loss: 0.1876 - val_acc: 0.9080\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18755 to 0.18726, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9154 - val_loss: 0.1873 - val_acc: 0.9095\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9141 - val_loss: 0.1876 - val_acc: 0.9086\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18726 to 0.18703, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9142 - val_loss: 0.1870 - val_acc: 0.9088\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9152 - val_loss: 0.1870 - val_acc: 0.9092\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9137 - val_loss: 0.1878 - val_acc: 0.9084\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9158 - val_loss: 0.1876 - val_acc: 0.9095\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9145 - val_loss: 0.1875 - val_acc: 0.9094\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18703 to 0.18670, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9135 - val_loss: 0.1867 - val_acc: 0.9092\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18670 to 0.18654, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9142 - val_loss: 0.1865 - val_acc: 0.9099\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18654 to 0.18642, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9139 - val_loss: 0.1864 - val_acc: 0.9099\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9154 - val_loss: 0.1864 - val_acc: 0.9109\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18642 to 0.18614, saving model to best.model\n",
      "1s - loss: 0.1835 - acc: 0.9133 - val_loss: 0.1861 - val_acc: 0.9099\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9144 - val_loss: 0.1862 - val_acc: 0.9099\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9137 - val_loss: 0.1868 - val_acc: 0.9105\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9156 - val_loss: 0.1864 - val_acc: 0.9103\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "1s - loss: 0.1832 - acc: 0.9150 - val_loss: 0.1864 - val_acc: 0.9095\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18614 to 0.18584, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9150 - val_loss: 0.1858 - val_acc: 0.9107\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9150 - val_loss: 0.1861 - val_acc: 0.9105\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9165 - val_loss: 0.1872 - val_acc: 0.9095\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9147 - val_loss: 0.1874 - val_acc: 0.9088\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9164 - val_loss: 0.1859 - val_acc: 0.9105\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9173 - val_loss: 0.1859 - val_acc: 0.9111\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18584 to 0.18575, saving model to best.model\n",
      "1s - loss: 0.1827 - acc: 0.9159 - val_loss: 0.1857 - val_acc: 0.9107\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18575 to 0.18566, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9154 - val_loss: 0.1857 - val_acc: 0.9107\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.18566 to 0.18538, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9151 - val_loss: 0.1854 - val_acc: 0.9113\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18538 to 0.18529, saving model to best.model\n",
      "1s - loss: 0.1818 - acc: 0.9155 - val_loss: 0.1853 - val_acc: 0.9118\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18529 to 0.18517, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9168 - val_loss: 0.1852 - val_acc: 0.9120\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18517 to 0.18512, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9164 - val_loss: 0.1851 - val_acc: 0.9105\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9167 - val_loss: 0.1859 - val_acc: 0.9094\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9172 - val_loss: 0.1854 - val_acc: 0.9109\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9180 - val_loss: 0.1859 - val_acc: 0.9080\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9152 - val_loss: 0.1866 - val_acc: 0.9099\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9167 - val_loss: 0.1852 - val_acc: 0.9124\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.18512 to 0.18498, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9161 - val_loss: 0.1850 - val_acc: 0.9111\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18498 to 0.18434, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9163 - val_loss: 0.1843 - val_acc: 0.9115\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9158 - val_loss: 0.1846 - val_acc: 0.9122\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18434 to 0.18429, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9155 - val_loss: 0.1843 - val_acc: 0.9118\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9174 - val_loss: 0.1851 - val_acc: 0.9120\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18429 to 0.18425, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9177 - val_loss: 0.1843 - val_acc: 0.9120\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9173 - val_loss: 0.1844 - val_acc: 0.9115\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18425 to 0.18407, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9173 - val_loss: 0.1841 - val_acc: 0.9122\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9181 - val_loss: 0.1846 - val_acc: 0.9105\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9166 - val_loss: 0.1841 - val_acc: 0.9126\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9155 - val_loss: 0.1842 - val_acc: 0.9118\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9179 - val_loss: 0.1843 - val_acc: 0.9118\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18407 to 0.18399, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9182 - val_loss: 0.1840 - val_acc: 0.9120\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9175 - val_loss: 0.1845 - val_acc: 0.9118\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.18399 to 0.18383, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9173 - val_loss: 0.1838 - val_acc: 0.9128\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9175 - val_loss: 0.1851 - val_acc: 0.9084\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9184 - val_loss: 0.1839 - val_acc: 0.9122\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9167 - val_loss: 0.1843 - val_acc: 0.9130\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9175 - val_loss: 0.1840 - val_acc: 0.9099\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18383 to 0.18372, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9164 - val_loss: 0.1837 - val_acc: 0.9136\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18372 to 0.18356, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9181 - val_loss: 0.1836 - val_acc: 0.9122\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.18356 to 0.18315, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9168 - val_loss: 0.1832 - val_acc: 0.9118\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9184 - val_loss: 0.1840 - val_acc: 0.9115\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9181 - val_loss: 0.1850 - val_acc: 0.9136\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9178 - val_loss: 0.1848 - val_acc: 0.9122\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9170 - val_loss: 0.1833 - val_acc: 0.9128\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9176 - val_loss: 0.1833 - val_acc: 0.9136\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.18315 to 0.18302, saving model to best.model\n",
      "0s - loss: 0.1771 - acc: 0.9178 - val_loss: 0.1830 - val_acc: 0.9130\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18302 to 0.18298, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9181 - val_loss: 0.1830 - val_acc: 0.9122\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9179 - val_loss: 0.1830 - val_acc: 0.9124\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.18298 to 0.18263, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9190 - val_loss: 0.1826 - val_acc: 0.9120\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9188 - val_loss: 0.1832 - val_acc: 0.9109\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9180 - val_loss: 0.1828 - val_acc: 0.9132\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9188 - val_loss: 0.1854 - val_acc: 0.9117\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.18263 to 0.18258, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9188 - val_loss: 0.1826 - val_acc: 0.9122\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "1s - loss: 0.1770 - acc: 0.9169 - val_loss: 0.1834 - val_acc: 0.9113\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9189 - val_loss: 0.1834 - val_acc: 0.9118\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9183 - val_loss: 0.1835 - val_acc: 0.9124\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9207 - val_loss: 0.1829 - val_acc: 0.9138\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9178 - val_loss: 0.1826 - val_acc: 0.9120\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.18258 to 0.18223, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9180 - val_loss: 0.1822 - val_acc: 0.9130\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "1s - loss: 0.1745 - acc: 0.9195 - val_loss: 0.1845 - val_acc: 0.9088\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9180 - val_loss: 0.1824 - val_acc: 0.9140\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.18223 to 0.18200, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9181 - val_loss: 0.1820 - val_acc: 0.9124\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.18200 to 0.18173, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9194 - val_loss: 0.1817 - val_acc: 0.9134\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9199 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9186 - val_loss: 0.1828 - val_acc: 0.9120\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9202 - val_loss: 0.1831 - val_acc: 0.9122\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9196 - val_loss: 0.1828 - val_acc: 0.9136\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9165 - val_loss: 0.1830 - val_acc: 0.9111\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9189 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9194 - val_loss: 0.1817 - val_acc: 0.9132\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9182 - val_loss: 0.1831 - val_acc: 0.9138\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9187 - val_loss: 0.1818 - val_acc: 0.9122\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9199 - val_loss: 0.1822 - val_acc: 0.9117\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.18173 to 0.18144, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9206 - val_loss: 0.1814 - val_acc: 0.9136\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9197 - val_loss: 0.1820 - val_acc: 0.9132\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9188 - val_loss: 0.1821 - val_acc: 0.9120\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9194 - val_loss: 0.1824 - val_acc: 0.9138\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9203 - val_loss: 0.1820 - val_acc: 0.9124\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9178 - val_loss: 0.1822 - val_acc: 0.9128\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9199 - val_loss: 0.1820 - val_acc: 0.9111\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9180 - val_loss: 0.1815 - val_acc: 0.9134\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "1s - loss: 0.1724 - acc: 0.9193 - val_loss: 0.1830 - val_acc: 0.9105\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9192 - val_loss: 0.1826 - val_acc: 0.9122\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9202 - val_loss: 0.1820 - val_acc: 0.9126\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.18144 to 0.18115, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9187 - val_loss: 0.1812 - val_acc: 0.9134\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9192 - val_loss: 0.1821 - val_acc: 0.9124\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9195 - val_loss: 0.1818 - val_acc: 0.9126\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.18115 to 0.18113, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9198 - val_loss: 0.1811 - val_acc: 0.9132\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9202 - val_loss: 0.1817 - val_acc: 0.9136\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9190 - val_loss: 0.1815 - val_acc: 0.9109\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "1s - loss: 0.1710 - acc: 0.9207 - val_loss: 0.1813 - val_acc: 0.9120\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9213 - val_loss: 0.1821 - val_acc: 0.9113\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9210 - val_loss: 0.1819 - val_acc: 0.9115\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9199 - val_loss: 0.1821 - val_acc: 0.9140\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9205 - val_loss: 0.1820 - val_acc: 0.9134\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9219 - val_loss: 0.1823 - val_acc: 0.9132\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9206 - val_loss: 0.1819 - val_acc: 0.9130\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9202 - val_loss: 0.1812 - val_acc: 0.9120\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9212 - val_loss: 0.1826 - val_acc: 0.9115\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9211 - val_loss: 0.1820 - val_acc: 0.9124\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9203 - val_loss: 0.1814 - val_acc: 0.9130\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.18113 to 0.18105, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9213 - val_loss: 0.1811 - val_acc: 0.9118\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9210 - val_loss: 0.1817 - val_acc: 0.9136\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9211 - val_loss: 0.1819 - val_acc: 0.9136\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9206 - val_loss: 0.1818 - val_acc: 0.9143\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9221 - val_loss: 0.1812 - val_acc: 0.9145\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9211 - val_loss: 0.1812 - val_acc: 0.9128\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9218 - val_loss: 0.1826 - val_acc: 0.9145\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9222 - val_loss: 0.1812 - val_acc: 0.9138\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9214 - val_loss: 0.1821 - val_acc: 0.9140\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.18105 to 0.18090, saving model to best.model\n",
      "0s - loss: 0.1689 - acc: 0.9214 - val_loss: 0.1809 - val_acc: 0.9138\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9220 - val_loss: 0.1831 - val_acc: 0.9136\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9216 - val_loss: 0.1812 - val_acc: 0.9143\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9224 - val_loss: 0.1823 - val_acc: 0.9130\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9233 - val_loss: 0.1810 - val_acc: 0.9138\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9211 - val_loss: 0.1828 - val_acc: 0.9122\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.18090 to 0.18087, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9210 - val_loss: 0.1809 - val_acc: 0.9126\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9212 - val_loss: 0.1811 - val_acc: 0.9147\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9209 - val_loss: 0.1812 - val_acc: 0.9147\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9227 - val_loss: 0.1816 - val_acc: 0.9143\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32513, saving model to best.model\n",
      "0s - loss: 0.4205 - acc: 0.8630 - val_loss: 0.3251 - val_acc: 0.8911\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32513 to 0.26131, saving model to best.model\n",
      "0s - loss: 0.3392 - acc: 0.8839 - val_loss: 0.2613 - val_acc: 0.8911\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26131 to 0.21430, saving model to best.model\n",
      "0s - loss: 0.2755 - acc: 0.8925 - val_loss: 0.2143 - val_acc: 0.9086\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21430 to 0.19719, saving model to best.model\n",
      "0s - loss: 0.2403 - acc: 0.8975 - val_loss: 0.1972 - val_acc: 0.9124\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19719 to 0.19223, saving model to best.model\n",
      "1s - loss: 0.2258 - acc: 0.9007 - val_loss: 0.1922 - val_acc: 0.9115\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19223 to 0.19189, saving model to best.model\n",
      "0s - loss: 0.2207 - acc: 0.9000 - val_loss: 0.1919 - val_acc: 0.9124\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19189 to 0.18922, saving model to best.model\n",
      "0s - loss: 0.2142 - acc: 0.9025 - val_loss: 0.1892 - val_acc: 0.9130\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18922 to 0.18824, saving model to best.model\n",
      "0s - loss: 0.2104 - acc: 0.9033 - val_loss: 0.1882 - val_acc: 0.9145\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18824 to 0.18788, saving model to best.model\n",
      "0s - loss: 0.2077 - acc: 0.9036 - val_loss: 0.1879 - val_acc: 0.9143\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2065 - acc: 0.9031 - val_loss: 0.1881 - val_acc: 0.9130\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18788 to 0.18774, saving model to best.model\n",
      "0s - loss: 0.2031 - acc: 0.9038 - val_loss: 0.1877 - val_acc: 0.9128\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2031 - acc: 0.9042 - val_loss: 0.1882 - val_acc: 0.9143\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2020 - acc: 0.9060 - val_loss: 0.1880 - val_acc: 0.9130\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "1s - loss: 0.2004 - acc: 0.9029 - val_loss: 0.1878 - val_acc: 0.9132\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2010 - acc: 0.9067 - val_loss: 0.1884 - val_acc: 0.9122\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1994 - acc: 0.9030 - val_loss: 0.1883 - val_acc: 0.9143\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18774 to 0.18742, saving model to best.model\n",
      "0s - loss: 0.1997 - acc: 0.9063 - val_loss: 0.1874 - val_acc: 0.9128\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18742 to 0.18724, saving model to best.model\n",
      "0s - loss: 0.2011 - acc: 0.9048 - val_loss: 0.1872 - val_acc: 0.9134\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18724 to 0.18696, saving model to best.model\n",
      "0s - loss: 0.1991 - acc: 0.9051 - val_loss: 0.1870 - val_acc: 0.9128\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1993 - acc: 0.9059 - val_loss: 0.1872 - val_acc: 0.9128\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18696 to 0.18684, saving model to best.model\n",
      "0s - loss: 0.1992 - acc: 0.9048 - val_loss: 0.1868 - val_acc: 0.9142\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18684 to 0.18660, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9052 - val_loss: 0.1866 - val_acc: 0.9136\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18660 to 0.18637, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9061 - val_loss: 0.1864 - val_acc: 0.9130\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18637 to 0.18628, saving model to best.model\n",
      "0s - loss: 0.1966 - acc: 0.9071 - val_loss: 0.1863 - val_acc: 0.9134\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18628 to 0.18594, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9055 - val_loss: 0.1859 - val_acc: 0.9138\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18594 to 0.18587, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9065 - val_loss: 0.1859 - val_acc: 0.9140\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18587 to 0.18577, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9056 - val_loss: 0.1858 - val_acc: 0.9138\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18577 to 0.18554, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9061 - val_loss: 0.1855 - val_acc: 0.9145\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18554 to 0.18525, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9077 - val_loss: 0.1852 - val_acc: 0.9143\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18525 to 0.18477, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9072 - val_loss: 0.1848 - val_acc: 0.9138\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9081 - val_loss: 0.1849 - val_acc: 0.9142\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1934 - acc: 0.9068 - val_loss: 0.1853 - val_acc: 0.9130\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9070 - val_loss: 0.1848 - val_acc: 0.9143\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18477 to 0.18450, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9090 - val_loss: 0.1845 - val_acc: 0.9136\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18450 to 0.18436, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9086 - val_loss: 0.1844 - val_acc: 0.9136\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18436 to 0.18414, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9087 - val_loss: 0.1841 - val_acc: 0.9142\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18414 to 0.18392, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9065 - val_loss: 0.1839 - val_acc: 0.9138\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1925 - acc: 0.9081 - val_loss: 0.1840 - val_acc: 0.9149\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18392 to 0.18379, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9080 - val_loss: 0.1838 - val_acc: 0.9149\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9074 - val_loss: 0.1839 - val_acc: 0.9155\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18379 to 0.18339, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9075 - val_loss: 0.1834 - val_acc: 0.9149\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18339 to 0.18314, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9100 - val_loss: 0.1831 - val_acc: 0.9151\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18314 to 0.18301, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9088 - val_loss: 0.1830 - val_acc: 0.9168\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1925 - acc: 0.9065 - val_loss: 0.1830 - val_acc: 0.9168\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9084 - val_loss: 0.1831 - val_acc: 0.9163\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18301 to 0.18284, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9074 - val_loss: 0.1828 - val_acc: 0.9163\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18284 to 0.18278, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9071 - val_loss: 0.1828 - val_acc: 0.9161\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18278 to 0.18212, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9079 - val_loss: 0.1821 - val_acc: 0.9170\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9079 - val_loss: 0.1822 - val_acc: 0.9170\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18212 to 0.18206, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9092 - val_loss: 0.1821 - val_acc: 0.9176\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9099 - val_loss: 0.1828 - val_acc: 0.9163\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18206 to 0.18142, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9085 - val_loss: 0.1814 - val_acc: 0.9184\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9101 - val_loss: 0.1818 - val_acc: 0.9178\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9085 - val_loss: 0.1816 - val_acc: 0.9182\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9093 - val_loss: 0.1814 - val_acc: 0.9182\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18142 to 0.18082, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9102 - val_loss: 0.1808 - val_acc: 0.9190\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9104 - val_loss: 0.1814 - val_acc: 0.9190\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18082 to 0.18077, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9119 - val_loss: 0.1808 - val_acc: 0.9180\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9113 - val_loss: 0.1809 - val_acc: 0.9180\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9095 - val_loss: 0.1810 - val_acc: 0.9174\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18077 to 0.18040, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9102 - val_loss: 0.1804 - val_acc: 0.9190\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18040 to 0.18039, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9091 - val_loss: 0.1804 - val_acc: 0.9184\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9090 - val_loss: 0.1806 - val_acc: 0.9186\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18039 to 0.17986, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9121 - val_loss: 0.1799 - val_acc: 0.9188\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9129 - val_loss: 0.1801 - val_acc: 0.9186\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9102 - val_loss: 0.1799 - val_acc: 0.9188\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.17986 to 0.17983, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9115 - val_loss: 0.1798 - val_acc: 0.9184\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17983 to 0.17969, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9114 - val_loss: 0.1797 - val_acc: 0.9191\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9109 - val_loss: 0.1798 - val_acc: 0.9193\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.17969 to 0.17969, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9101 - val_loss: 0.1797 - val_acc: 0.9188\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.17969 to 0.17957, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9114 - val_loss: 0.1796 - val_acc: 0.9190\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17957 to 0.17918, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9111 - val_loss: 0.1792 - val_acc: 0.9201\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9117 - val_loss: 0.1797 - val_acc: 0.9201\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9095 - val_loss: 0.1793 - val_acc: 0.9195\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17918 to 0.17865, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9128 - val_loss: 0.1786 - val_acc: 0.9191\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9103 - val_loss: 0.1789 - val_acc: 0.9191\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9123 - val_loss: 0.1788 - val_acc: 0.9199\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9116 - val_loss: 0.1788 - val_acc: 0.9193\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9115 - val_loss: 0.1792 - val_acc: 0.9193\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.17865 to 0.17819, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9119 - val_loss: 0.1782 - val_acc: 0.9201\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9112 - val_loss: 0.1785 - val_acc: 0.9201\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9100 - val_loss: 0.1787 - val_acc: 0.9203\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9114 - val_loss: 0.1786 - val_acc: 0.9197\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9130 - val_loss: 0.1788 - val_acc: 0.9209\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9106 - val_loss: 0.1783 - val_acc: 0.9197\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9115 - val_loss: 0.1782 - val_acc: 0.9199\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17819 to 0.17785, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9117 - val_loss: 0.1779 - val_acc: 0.9201\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9126 - val_loss: 0.1785 - val_acc: 0.9205\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9119 - val_loss: 0.1788 - val_acc: 0.9195\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9131 - val_loss: 0.1791 - val_acc: 0.9182\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9114 - val_loss: 0.1780 - val_acc: 0.9205\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9123 - val_loss: 0.1792 - val_acc: 0.9190\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17785 to 0.17766, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9132 - val_loss: 0.1777 - val_acc: 0.9201\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17766 to 0.17754, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9131 - val_loss: 0.1775 - val_acc: 0.9209\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9133 - val_loss: 0.1776 - val_acc: 0.9193\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9116 - val_loss: 0.1776 - val_acc: 0.9205\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17754 to 0.17699, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9134 - val_loss: 0.1770 - val_acc: 0.9209\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17699 to 0.17678, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9122 - val_loss: 0.1768 - val_acc: 0.9211\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17678 to 0.17673, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9142 - val_loss: 0.1767 - val_acc: 0.9205\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9124 - val_loss: 0.1769 - val_acc: 0.9199\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9131 - val_loss: 0.1767 - val_acc: 0.9207\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "1s - loss: 0.1817 - acc: 0.9116 - val_loss: 0.1767 - val_acc: 0.9201\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17673 to 0.17648, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9134 - val_loss: 0.1765 - val_acc: 0.9207\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9135 - val_loss: 0.1768 - val_acc: 0.9207\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9123 - val_loss: 0.1768 - val_acc: 0.9216\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9113 - val_loss: 0.1767 - val_acc: 0.9203\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9131 - val_loss: 0.1765 - val_acc: 0.9193\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9114 - val_loss: 0.1767 - val_acc: 0.9188\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17648 to 0.17618, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9140 - val_loss: 0.1762 - val_acc: 0.9207\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9125 - val_loss: 0.1767 - val_acc: 0.9211\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.17618 to 0.17616, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9126 - val_loss: 0.1762 - val_acc: 0.9205\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9152 - val_loss: 0.1762 - val_acc: 0.9186\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17616 to 0.17563, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9149 - val_loss: 0.1756 - val_acc: 0.9207\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9117 - val_loss: 0.1757 - val_acc: 0.9207\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9122 - val_loss: 0.1758 - val_acc: 0.9195\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9124 - val_loss: 0.1763 - val_acc: 0.9180\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9135 - val_loss: 0.1759 - val_acc: 0.9211\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17563 to 0.17530, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9135 - val_loss: 0.1753 - val_acc: 0.9199\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17530 to 0.17510, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9139 - val_loss: 0.1751 - val_acc: 0.9193\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9148 - val_loss: 0.1752 - val_acc: 0.9209\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9123 - val_loss: 0.1754 - val_acc: 0.9203\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9142 - val_loss: 0.1753 - val_acc: 0.9201\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9133 - val_loss: 0.1757 - val_acc: 0.9201\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9137 - val_loss: 0.1752 - val_acc: 0.9205\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9128 - val_loss: 0.1757 - val_acc: 0.9191\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17510 to 0.17504, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9134 - val_loss: 0.1750 - val_acc: 0.9201\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9136 - val_loss: 0.1751 - val_acc: 0.9203\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17504 to 0.17503, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9136 - val_loss: 0.1750 - val_acc: 0.9207\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17503 to 0.17456, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9150 - val_loss: 0.1746 - val_acc: 0.9203\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9147 - val_loss: 0.1751 - val_acc: 0.9201\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9130 - val_loss: 0.1746 - val_acc: 0.9205\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9149 - val_loss: 0.1750 - val_acc: 0.9209\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9149 - val_loss: 0.1752 - val_acc: 0.9197\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9149 - val_loss: 0.1746 - val_acc: 0.9201\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17456 to 0.17452, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9143 - val_loss: 0.1745 - val_acc: 0.9201\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17452 to 0.17428, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9139 - val_loss: 0.1743 - val_acc: 0.9195\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9158 - val_loss: 0.1745 - val_acc: 0.9201\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17428 to 0.17376, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9154 - val_loss: 0.1738 - val_acc: 0.9203\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9155 - val_loss: 0.1741 - val_acc: 0.9193\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9134 - val_loss: 0.1747 - val_acc: 0.9199\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9153 - val_loss: 0.1743 - val_acc: 0.9199\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9153 - val_loss: 0.1740 - val_acc: 0.9193\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9140 - val_loss: 0.1758 - val_acc: 0.9215\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9154 - val_loss: 0.1740 - val_acc: 0.9209\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9147 - val_loss: 0.1739 - val_acc: 0.9203\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9145 - val_loss: 0.1740 - val_acc: 0.9211\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9149 - val_loss: 0.1744 - val_acc: 0.9209\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.17376 to 0.17356, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9148 - val_loss: 0.1736 - val_acc: 0.9203\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17356 to 0.17314, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9164 - val_loss: 0.1731 - val_acc: 0.9203\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9146 - val_loss: 0.1734 - val_acc: 0.9203\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17314 to 0.17302, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9152 - val_loss: 0.1730 - val_acc: 0.9201\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9157 - val_loss: 0.1736 - val_acc: 0.9199\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9156 - val_loss: 0.1734 - val_acc: 0.9205\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9161 - val_loss: 0.1730 - val_acc: 0.9203\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9182 - val_loss: 0.1734 - val_acc: 0.9216\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9168 - val_loss: 0.1736 - val_acc: 0.9211\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9143 - val_loss: 0.1735 - val_acc: 0.9220\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9150 - val_loss: 0.1731 - val_acc: 0.9201\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17302 to 0.17291, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9153 - val_loss: 0.1729 - val_acc: 0.9205\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9138 - val_loss: 0.1730 - val_acc: 0.9209\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9152 - val_loss: 0.1737 - val_acc: 0.9207\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9170 - val_loss: 0.1731 - val_acc: 0.9205\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9169 - val_loss: 0.1730 - val_acc: 0.9216\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9162 - val_loss: 0.1731 - val_acc: 0.9215\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9168 - val_loss: 0.1731 - val_acc: 0.9209\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.17291 to 0.17266, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9161 - val_loss: 0.1727 - val_acc: 0.9211\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9159 - val_loss: 0.1732 - val_acc: 0.9209\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9177 - val_loss: 0.1736 - val_acc: 0.9215\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9159 - val_loss: 0.1730 - val_acc: 0.9211\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9166 - val_loss: 0.1727 - val_acc: 0.9205\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9163 - val_loss: 0.1728 - val_acc: 0.9209\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9162 - val_loss: 0.1737 - val_acc: 0.9209\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9160 - val_loss: 0.1741 - val_acc: 0.9203\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9156 - val_loss: 0.1729 - val_acc: 0.9207\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9166 - val_loss: 0.1733 - val_acc: 0.9215\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9160 - val_loss: 0.1736 - val_acc: 0.9209\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.17266 to 0.17252, saving model to best.model\n",
      "0s - loss: 0.1712 - acc: 0.9163 - val_loss: 0.1725 - val_acc: 0.9220\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.17252 to 0.17242, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9166 - val_loss: 0.1724 - val_acc: 0.9209\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17242 to 0.17207, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9164 - val_loss: 0.1721 - val_acc: 0.9211\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9169 - val_loss: 0.1724 - val_acc: 0.9213\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.17207 to 0.17206, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9182 - val_loss: 0.1721 - val_acc: 0.9216\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9171 - val_loss: 0.1723 - val_acc: 0.9213\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9168 - val_loss: 0.1725 - val_acc: 0.9209\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9173 - val_loss: 0.1726 - val_acc: 0.9216\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9174 - val_loss: 0.1723 - val_acc: 0.9218\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9174 - val_loss: 0.1734 - val_acc: 0.9228\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9161 - val_loss: 0.1728 - val_acc: 0.9211\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9183 - val_loss: 0.1725 - val_acc: 0.9216\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9158 - val_loss: 0.1726 - val_acc: 0.9213\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9156 - val_loss: 0.1723 - val_acc: 0.9211\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9150 - val_loss: 0.1726 - val_acc: 0.9213\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9159 - val_loss: 0.1727 - val_acc: 0.9215\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9172 - val_loss: 0.1723 - val_acc: 0.9211\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9175 - val_loss: 0.1727 - val_acc: 0.9213\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9163 - val_loss: 0.1726 - val_acc: 0.9211\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9193 - val_loss: 0.1727 - val_acc: 0.9216\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9195 - val_loss: 0.1729 - val_acc: 0.9216\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9174 - val_loss: 0.1721 - val_acc: 0.9215\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9175 - val_loss: 0.1722 - val_acc: 0.9222\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9179 - val_loss: 0.1732 - val_acc: 0.9220\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32723, saving model to best.model\n",
      "0s - loss: 0.3902 - acc: 0.8797 - val_loss: 0.3272 - val_acc: 0.8865\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32723 to 0.24383, saving model to best.model\n",
      "0s - loss: 0.3167 - acc: 0.8875 - val_loss: 0.2438 - val_acc: 0.9017\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24383 to 0.20882, saving model to best.model\n",
      "0s - loss: 0.2568 - acc: 0.8946 - val_loss: 0.2088 - val_acc: 0.9092\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20882 to 0.20458, saving model to best.model\n",
      "0s - loss: 0.2303 - acc: 0.9003 - val_loss: 0.2046 - val_acc: 0.9095\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20458 to 0.19678, saving model to best.model\n",
      "0s - loss: 0.2214 - acc: 0.9008 - val_loss: 0.1968 - val_acc: 0.9101\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19678 to 0.19551, saving model to best.model\n",
      "0s - loss: 0.2116 - acc: 0.9024 - val_loss: 0.1955 - val_acc: 0.9099\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19551 to 0.19491, saving model to best.model\n",
      "0s - loss: 0.2099 - acc: 0.9049 - val_loss: 0.1949 - val_acc: 0.9099\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19491 to 0.19408, saving model to best.model\n",
      "0s - loss: 0.2098 - acc: 0.9036 - val_loss: 0.1941 - val_acc: 0.9113\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2067 - acc: 0.9051 - val_loss: 0.1942 - val_acc: 0.9109\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19408 to 0.19383, saving model to best.model\n",
      "0s - loss: 0.2046 - acc: 0.9050 - val_loss: 0.1938 - val_acc: 0.9105\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2038 - acc: 0.9043 - val_loss: 0.1940 - val_acc: 0.9109\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19383 to 0.19381, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9059 - val_loss: 0.1938 - val_acc: 0.9128\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19381 to 0.19366, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9057 - val_loss: 0.1937 - val_acc: 0.9126\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19366 to 0.19329, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9060 - val_loss: 0.1933 - val_acc: 0.9117\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1992 - acc: 0.9058 - val_loss: 0.1934 - val_acc: 0.9113\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19329 to 0.19325, saving model to best.model\n",
      "0s - loss: 0.2021 - acc: 0.9052 - val_loss: 0.1933 - val_acc: 0.9130\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19325 to 0.19302, saving model to best.model\n",
      "0s - loss: 0.2011 - acc: 0.9060 - val_loss: 0.1930 - val_acc: 0.9120\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1978 - acc: 0.9059 - val_loss: 0.1932 - val_acc: 0.9107\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19302 to 0.19283, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9087 - val_loss: 0.1928 - val_acc: 0.9107\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1974 - acc: 0.9081 - val_loss: 0.1947 - val_acc: 0.9076\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9077 - val_loss: 0.1933 - val_acc: 0.9080\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19283 to 0.19240, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9067 - val_loss: 0.1924 - val_acc: 0.9107\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19240 to 0.19201, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9071 - val_loss: 0.1920 - val_acc: 0.9113\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19201 to 0.19193, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9090 - val_loss: 0.1919 - val_acc: 0.9111\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19193 to 0.19180, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9085 - val_loss: 0.1918 - val_acc: 0.9115\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1961 - acc: 0.9074 - val_loss: 0.1919 - val_acc: 0.9118\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19180 to 0.19110, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9077 - val_loss: 0.1911 - val_acc: 0.9105\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19110 to 0.19101, saving model to best.model\n",
      "0s - loss: 0.1958 - acc: 0.9089 - val_loss: 0.1910 - val_acc: 0.9109\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1964 - acc: 0.9074 - val_loss: 0.1913 - val_acc: 0.9097\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19101 to 0.19093, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9083 - val_loss: 0.1909 - val_acc: 0.9107\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19093 to 0.19059, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9080 - val_loss: 0.1906 - val_acc: 0.9092\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19059 to 0.19041, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9068 - val_loss: 0.1904 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19041 to 0.18995, saving model to best.model\n",
      "0s - loss: 0.1943 - acc: 0.9099 - val_loss: 0.1899 - val_acc: 0.9107\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18995 to 0.18992, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9088 - val_loss: 0.1899 - val_acc: 0.9113\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18992 to 0.18964, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9101 - val_loss: 0.1896 - val_acc: 0.9113\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9079 - val_loss: 0.1896 - val_acc: 0.9120\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18964 to 0.18920, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9089 - val_loss: 0.1892 - val_acc: 0.9124\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18920 to 0.18905, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9097 - val_loss: 0.1890 - val_acc: 0.9117\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9102 - val_loss: 0.1900 - val_acc: 0.9115\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9099 - val_loss: 0.1891 - val_acc: 0.9107\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18905 to 0.18865, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9093 - val_loss: 0.1886 - val_acc: 0.9109\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9092 - val_loss: 0.1888 - val_acc: 0.9103\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18865 to 0.18855, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9092 - val_loss: 0.1885 - val_acc: 0.9115\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18855 to 0.18809, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9097 - val_loss: 0.1881 - val_acc: 0.9107\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1909 - acc: 0.9095 - val_loss: 0.1883 - val_acc: 0.9113\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9090 - val_loss: 0.1881 - val_acc: 0.9109\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18809 to 0.18793, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9106 - val_loss: 0.1879 - val_acc: 0.9120\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18793 to 0.18754, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9112 - val_loss: 0.1875 - val_acc: 0.9118\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18754 to 0.18740, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9094 - val_loss: 0.1874 - val_acc: 0.9117\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18740 to 0.18728, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9107 - val_loss: 0.1873 - val_acc: 0.9126\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18728 to 0.18706, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9119 - val_loss: 0.1871 - val_acc: 0.9128\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18706 to 0.18697, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9115 - val_loss: 0.1870 - val_acc: 0.9124\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18697 to 0.18662, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9103 - val_loss: 0.1866 - val_acc: 0.9122\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9100 - val_loss: 0.1867 - val_acc: 0.9118\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9103 - val_loss: 0.1868 - val_acc: 0.9117\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18662 to 0.18658, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9122 - val_loss: 0.1866 - val_acc: 0.9122\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18658 to 0.18611, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9098 - val_loss: 0.1861 - val_acc: 0.9122\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18611 to 0.18611, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9116 - val_loss: 0.1861 - val_acc: 0.9120\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18611 to 0.18586, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9116 - val_loss: 0.1859 - val_acc: 0.9122\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18586 to 0.18570, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9114 - val_loss: 0.1857 - val_acc: 0.9122\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18570 to 0.18543, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9122 - val_loss: 0.1854 - val_acc: 0.9124\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18543 to 0.18535, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9105 - val_loss: 0.1853 - val_acc: 0.9120\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9118 - val_loss: 0.1860 - val_acc: 0.9124\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18535 to 0.18493, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9115 - val_loss: 0.1849 - val_acc: 0.9124\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9114 - val_loss: 0.1855 - val_acc: 0.9130\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9139 - val_loss: 0.1849 - val_acc: 0.9132\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18493 to 0.18475, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9105 - val_loss: 0.1848 - val_acc: 0.9122\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9124 - val_loss: 0.1848 - val_acc: 0.9122\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18475 to 0.18467, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9108 - val_loss: 0.1847 - val_acc: 0.9130\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9121 - val_loss: 0.1853 - val_acc: 0.9122\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9118 - val_loss: 0.1855 - val_acc: 0.9136\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9118 - val_loss: 0.1852 - val_acc: 0.9124\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18467 to 0.18425, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9130 - val_loss: 0.1842 - val_acc: 0.9140\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18425 to 0.18410, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9126 - val_loss: 0.1841 - val_acc: 0.9128\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9125 - val_loss: 0.1845 - val_acc: 0.9136\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9116 - val_loss: 0.1843 - val_acc: 0.9126\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18410 to 0.18398, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9131 - val_loss: 0.1840 - val_acc: 0.9124\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.18398 to 0.18391, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9122 - val_loss: 0.1839 - val_acc: 0.9134\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9143 - val_loss: 0.1844 - val_acc: 0.9138\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9126 - val_loss: 0.1848 - val_acc: 0.9138\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18391 to 0.18381, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9132 - val_loss: 0.1838 - val_acc: 0.9136\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9135 - val_loss: 0.1841 - val_acc: 0.9136\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9132 - val_loss: 0.1842 - val_acc: 0.9126\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9143 - val_loss: 0.1846 - val_acc: 0.9142\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9136 - val_loss: 0.1841 - val_acc: 0.9122\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.18381 to 0.18377, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9127 - val_loss: 0.1838 - val_acc: 0.9134\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9132 - val_loss: 0.1842 - val_acc: 0.9132\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9133 - val_loss: 0.1842 - val_acc: 0.9128\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18377 to 0.18359, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9137 - val_loss: 0.1836 - val_acc: 0.9117\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9143 - val_loss: 0.1837 - val_acc: 0.9130\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18359 to 0.18315, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9138 - val_loss: 0.1831 - val_acc: 0.9145\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9138 - val_loss: 0.1838 - val_acc: 0.9132\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9135 - val_loss: 0.1835 - val_acc: 0.9117\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9146 - val_loss: 0.1838 - val_acc: 0.9132\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9154 - val_loss: 0.1833 - val_acc: 0.9126\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9135 - val_loss: 0.1836 - val_acc: 0.9147\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18315 to 0.18304, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9153 - val_loss: 0.1830 - val_acc: 0.9126\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9126 - val_loss: 0.1835 - val_acc: 0.9130\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.18304 to 0.18261, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9132 - val_loss: 0.1826 - val_acc: 0.9159\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18261 to 0.18259, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9147 - val_loss: 0.1826 - val_acc: 0.9130\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18259 to 0.18252, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9132 - val_loss: 0.1825 - val_acc: 0.9153\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9146 - val_loss: 0.1840 - val_acc: 0.9126\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9128 - val_loss: 0.1828 - val_acc: 0.9128\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9131 - val_loss: 0.1832 - val_acc: 0.9145\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9143 - val_loss: 0.1828 - val_acc: 0.9130\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "1s - loss: 0.1801 - acc: 0.9139 - val_loss: 0.1826 - val_acc: 0.9142\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18252 to 0.18236, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9154 - val_loss: 0.1824 - val_acc: 0.9145\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9147 - val_loss: 0.1830 - val_acc: 0.9149\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9147 - val_loss: 0.1824 - val_acc: 0.9149\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9146 - val_loss: 0.1827 - val_acc: 0.9149\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18236 to 0.18226, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9135 - val_loss: 0.1823 - val_acc: 0.9147\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9149 - val_loss: 0.1823 - val_acc: 0.9143\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9137 - val_loss: 0.1827 - val_acc: 0.9157\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9154 - val_loss: 0.1826 - val_acc: 0.9155\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9163 - val_loss: 0.1847 - val_acc: 0.9140\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9164 - val_loss: 0.1825 - val_acc: 0.9128\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9137 - val_loss: 0.1832 - val_acc: 0.9132\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18226 to 0.18212, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9152 - val_loss: 0.1821 - val_acc: 0.9132\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18212 to 0.18208, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9163 - val_loss: 0.1821 - val_acc: 0.9132\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9155 - val_loss: 0.1827 - val_acc: 0.9142\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9151 - val_loss: 0.1823 - val_acc: 0.9136\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9159 - val_loss: 0.1822 - val_acc: 0.9140\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9139 - val_loss: 0.1826 - val_acc: 0.9134\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9148 - val_loss: 0.1821 - val_acc: 0.9134\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.18208 to 0.18178, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9140 - val_loss: 0.1818 - val_acc: 0.9136\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.18178 to 0.18170, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9147 - val_loss: 0.1817 - val_acc: 0.9151\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18170 to 0.18158, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9162 - val_loss: 0.1816 - val_acc: 0.9143\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9172 - val_loss: 0.1816 - val_acc: 0.9140\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.18158 to 0.18148, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9163 - val_loss: 0.1815 - val_acc: 0.9142\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9155 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "1s - loss: 0.1765 - acc: 0.9159 - val_loss: 0.1815 - val_acc: 0.9138\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.18148 to 0.18130, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9140 - val_loss: 0.1813 - val_acc: 0.9140\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9168 - val_loss: 0.1817 - val_acc: 0.9130\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9143 - val_loss: 0.1815 - val_acc: 0.9138\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9155 - val_loss: 0.1814 - val_acc: 0.9149\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9147 - val_loss: 0.1815 - val_acc: 0.9140\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9165 - val_loss: 0.1818 - val_acc: 0.9143\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.18130 to 0.18108, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9175 - val_loss: 0.1811 - val_acc: 0.9145\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.18108 to 0.18102, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9158 - val_loss: 0.1810 - val_acc: 0.9140\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.18102 to 0.18085, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9167 - val_loss: 0.1809 - val_acc: 0.9140\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9166 - val_loss: 0.1812 - val_acc: 0.9145\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9173 - val_loss: 0.1820 - val_acc: 0.9143\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9170 - val_loss: 0.1809 - val_acc: 0.9130\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9192 - val_loss: 0.1812 - val_acc: 0.9151\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.18085 to 0.18081, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9160 - val_loss: 0.1808 - val_acc: 0.9136\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9167 - val_loss: 0.1810 - val_acc: 0.9130\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9176 - val_loss: 0.1814 - val_acc: 0.9134\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9180 - val_loss: 0.1812 - val_acc: 0.9149\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.18081 to 0.18078, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9176 - val_loss: 0.1808 - val_acc: 0.9147\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9175 - val_loss: 0.1810 - val_acc: 0.9143\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9167 - val_loss: 0.1818 - val_acc: 0.9143\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9170 - val_loss: 0.1817 - val_acc: 0.9142\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9149 - val_loss: 0.1811 - val_acc: 0.9147\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9170 - val_loss: 0.1817 - val_acc: 0.9134\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9169 - val_loss: 0.1812 - val_acc: 0.9140\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.18078 to 0.18053, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9177 - val_loss: 0.1805 - val_acc: 0.9151\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9174 - val_loss: 0.1813 - val_acc: 0.9145\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9162 - val_loss: 0.1806 - val_acc: 0.9142\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.18053 to 0.18050, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9171 - val_loss: 0.1805 - val_acc: 0.9149\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9175 - val_loss: 0.1808 - val_acc: 0.9151\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.18050 to 0.18038, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9153 - val_loss: 0.1804 - val_acc: 0.9140\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9189 - val_loss: 0.1818 - val_acc: 0.9134\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9167 - val_loss: 0.1808 - val_acc: 0.9147\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9170 - val_loss: 0.1806 - val_acc: 0.9149\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.18038 to 0.18033, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9182 - val_loss: 0.1803 - val_acc: 0.9147\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9184 - val_loss: 0.1819 - val_acc: 0.9140\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9186 - val_loss: 0.1805 - val_acc: 0.9153\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9178 - val_loss: 0.1806 - val_acc: 0.9151\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9168 - val_loss: 0.1807 - val_acc: 0.9151\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9166 - val_loss: 0.1805 - val_acc: 0.9151\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9185 - val_loss: 0.1803 - val_acc: 0.9151\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9192 - val_loss: 0.1806 - val_acc: 0.9145\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9163 - val_loss: 0.1806 - val_acc: 0.9149\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9192 - val_loss: 0.1806 - val_acc: 0.9151\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9185 - val_loss: 0.1809 - val_acc: 0.9149\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9192 - val_loss: 0.1814 - val_acc: 0.9145\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9176 - val_loss: 0.1810 - val_acc: 0.9147\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9172 - val_loss: 0.1814 - val_acc: 0.9163\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.18033 to 0.18032, saving model to best.model\n",
      "0s - loss: 0.1704 - acc: 0.9193 - val_loss: 0.1803 - val_acc: 0.9151\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9197 - val_loss: 0.1807 - val_acc: 0.9159\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.18032 to 0.17996, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9196 - val_loss: 0.1800 - val_acc: 0.9149\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9170 - val_loss: 0.1806 - val_acc: 0.9161\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9185 - val_loss: 0.1801 - val_acc: 0.9165\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9189 - val_loss: 0.1810 - val_acc: 0.9161\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9201 - val_loss: 0.1812 - val_acc: 0.9165\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9193 - val_loss: 0.1802 - val_acc: 0.9161\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9185 - val_loss: 0.1800 - val_acc: 0.9151\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9176 - val_loss: 0.1800 - val_acc: 0.9151\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9198 - val_loss: 0.1808 - val_acc: 0.9155\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.17996 to 0.17989, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9193 - val_loss: 0.1799 - val_acc: 0.9138\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9193 - val_loss: 0.1800 - val_acc: 0.9155\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9186 - val_loss: 0.1799 - val_acc: 0.9165\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.17989 to 0.17979, saving model to best.model\n",
      "0s - loss: 0.1699 - acc: 0.9177 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9179 - val_loss: 0.1805 - val_acc: 0.9142\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9192 - val_loss: 0.1824 - val_acc: 0.9155\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9201 - val_loss: 0.1801 - val_acc: 0.9140\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9195 - val_loss: 0.1803 - val_acc: 0.9157\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9186 - val_loss: 0.1804 - val_acc: 0.9153\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9176 - val_loss: 0.1800 - val_acc: 0.9149\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9195 - val_loss: 0.1803 - val_acc: 0.9151\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33226, saving model to best.model\n",
      "0s - loss: 0.3910 - acc: 0.8796 - val_loss: 0.3323 - val_acc: 0.8905\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33226 to 0.26425, saving model to best.model\n",
      "0s - loss: 0.3285 - acc: 0.8916 - val_loss: 0.2643 - val_acc: 0.8903\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26425 to 0.21578, saving model to best.model\n",
      "0s - loss: 0.2657 - acc: 0.8959 - val_loss: 0.2158 - val_acc: 0.9080\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21578 to 0.20329, saving model to best.model\n",
      "0s - loss: 0.2347 - acc: 0.9019 - val_loss: 0.2033 - val_acc: 0.9080\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20329 to 0.19916, saving model to best.model\n",
      "0s - loss: 0.2186 - acc: 0.9071 - val_loss: 0.1992 - val_acc: 0.9095\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19916 to 0.19695, saving model to best.model\n",
      "0s - loss: 0.2122 - acc: 0.9056 - val_loss: 0.1969 - val_acc: 0.9088\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19695 to 0.19597, saving model to best.model\n",
      "0s - loss: 0.2098 - acc: 0.9059 - val_loss: 0.1960 - val_acc: 0.9107\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2060 - acc: 0.9074 - val_loss: 0.1969 - val_acc: 0.9070\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19597 to 0.19524, saving model to best.model\n",
      "1s - loss: 0.2071 - acc: 0.9074 - val_loss: 0.1952 - val_acc: 0.9084\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19524 to 0.19518, saving model to best.model\n",
      "0s - loss: 0.2035 - acc: 0.9078 - val_loss: 0.1952 - val_acc: 0.9084\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19518 to 0.19482, saving model to best.model\n",
      "0s - loss: 0.2029 - acc: 0.9077 - val_loss: 0.1948 - val_acc: 0.9086\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2014 - acc: 0.9088 - val_loss: 0.1959 - val_acc: 0.9072\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19482 to 0.19418, saving model to best.model\n",
      "0s - loss: 0.2012 - acc: 0.9090 - val_loss: 0.1942 - val_acc: 0.9084\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19418 to 0.19365, saving model to best.model\n",
      "0s - loss: 0.1988 - acc: 0.9102 - val_loss: 0.1936 - val_acc: 0.9090\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19365 to 0.19352, saving model to best.model\n",
      "0s - loss: 0.1997 - acc: 0.9091 - val_loss: 0.1935 - val_acc: 0.9095\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9098 - val_loss: 0.1954 - val_acc: 0.9074\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9111 - val_loss: 0.1959 - val_acc: 0.9069\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19352 to 0.19280, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9106 - val_loss: 0.1928 - val_acc: 0.9097\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19280 to 0.19219, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9114 - val_loss: 0.1922 - val_acc: 0.9099\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9091 - val_loss: 0.1934 - val_acc: 0.9070\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19219 to 0.19151, saving model to best.model\n",
      "0s - loss: 0.1962 - acc: 0.9124 - val_loss: 0.1915 - val_acc: 0.9084\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19151 to 0.19129, saving model to best.model\n",
      "0s - loss: 0.1962 - acc: 0.9111 - val_loss: 0.1913 - val_acc: 0.9101\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19129 to 0.19104, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9112 - val_loss: 0.1910 - val_acc: 0.9082\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19104 to 0.19076, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9108 - val_loss: 0.1908 - val_acc: 0.9082\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19076 to 0.19040, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9111 - val_loss: 0.1904 - val_acc: 0.9099\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19040 to 0.19008, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9103 - val_loss: 0.1901 - val_acc: 0.9074\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19008 to 0.18973, saving model to best.model\n",
      "1s - loss: 0.1935 - acc: 0.9112 - val_loss: 0.1897 - val_acc: 0.9094\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9108 - val_loss: 0.1901 - val_acc: 0.9080\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9122 - val_loss: 0.1908 - val_acc: 0.9084\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18973 to 0.18914, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9112 - val_loss: 0.1891 - val_acc: 0.9088\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9104 - val_loss: 0.1896 - val_acc: 0.9095\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18914 to 0.18865, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9111 - val_loss: 0.1886 - val_acc: 0.9082\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9134 - val_loss: 0.1896 - val_acc: 0.9084\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9117 - val_loss: 0.1898 - val_acc: 0.9086\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18865 to 0.18806, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9130 - val_loss: 0.1881 - val_acc: 0.9101\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18806 to 0.18782, saving model to best.model\n",
      "1s - loss: 0.1911 - acc: 0.9129 - val_loss: 0.1878 - val_acc: 0.9088\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9114 - val_loss: 0.1886 - val_acc: 0.9086\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18782 to 0.18775, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9144 - val_loss: 0.1877 - val_acc: 0.9097\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9123 - val_loss: 0.1886 - val_acc: 0.9090\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9133 - val_loss: 0.1879 - val_acc: 0.9092\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18775 to 0.18712, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9145 - val_loss: 0.1871 - val_acc: 0.9099\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9141 - val_loss: 0.1874 - val_acc: 0.9097\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9129 - val_loss: 0.1872 - val_acc: 0.9113\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18712 to 0.18690, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9147 - val_loss: 0.1869 - val_acc: 0.9107\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18690 to 0.18624, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9129 - val_loss: 0.1862 - val_acc: 0.9122\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9138 - val_loss: 0.1864 - val_acc: 0.9105\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9137 - val_loss: 0.1864 - val_acc: 0.9105\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9142 - val_loss: 0.1864 - val_acc: 0.9126\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18624 to 0.18571, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9138 - val_loss: 0.1857 - val_acc: 0.9138\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9146 - val_loss: 0.1860 - val_acc: 0.9122\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18571 to 0.18543, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9145 - val_loss: 0.1854 - val_acc: 0.9134\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9152 - val_loss: 0.1860 - val_acc: 0.9113\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18543 to 0.18531, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9133 - val_loss: 0.1853 - val_acc: 0.9145\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9151 - val_loss: 0.1856 - val_acc: 0.9134\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9127 - val_loss: 0.1854 - val_acc: 0.9132\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9156 - val_loss: 0.1873 - val_acc: 0.9117\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18531 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9156 - val_loss: 0.1851 - val_acc: 0.9136\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18508 to 0.18465, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9148 - val_loss: 0.1847 - val_acc: 0.9130\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9154 - val_loss: 0.1849 - val_acc: 0.9136\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18465 to 0.18444, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9163 - val_loss: 0.1844 - val_acc: 0.9136\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9157 - val_loss: 0.1846 - val_acc: 0.9142\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9140 - val_loss: 0.1847 - val_acc: 0.9136\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9138 - val_loss: 0.1847 - val_acc: 0.9138\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9157 - val_loss: 0.1846 - val_acc: 0.9143\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9156 - val_loss: 0.1847 - val_acc: 0.9143\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18444 to 0.18440, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9160 - val_loss: 0.1844 - val_acc: 0.9138\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18440 to 0.18427, saving model to best.model\n",
      "1s - loss: 0.1856 - acc: 0.9152 - val_loss: 0.1843 - val_acc: 0.9140\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18427 to 0.18414, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9151 - val_loss: 0.1841 - val_acc: 0.9130\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9151 - val_loss: 0.1844 - val_acc: 0.9132\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18414 to 0.18378, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9164 - val_loss: 0.1838 - val_acc: 0.9140\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9157 - val_loss: 0.1842 - val_acc: 0.9140\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9158 - val_loss: 0.1842 - val_acc: 0.9136\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9156 - val_loss: 0.1839 - val_acc: 0.9126\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18378 to 0.18323, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9158 - val_loss: 0.1832 - val_acc: 0.9142\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9179 - val_loss: 0.1833 - val_acc: 0.9140\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9159 - val_loss: 0.1848 - val_acc: 0.9130\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9152 - val_loss: 0.1850 - val_acc: 0.9134\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9171 - val_loss: 0.1840 - val_acc: 0.9132\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18323 to 0.18305, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9164 - val_loss: 0.1831 - val_acc: 0.9134\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9164 - val_loss: 0.1833 - val_acc: 0.9153\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18305 to 0.18285, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9170 - val_loss: 0.1829 - val_acc: 0.9140\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9166 - val_loss: 0.1832 - val_acc: 0.9149\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9165 - val_loss: 0.1829 - val_acc: 0.9149\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18285 to 0.18238, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9160 - val_loss: 0.1824 - val_acc: 0.9159\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9165 - val_loss: 0.1827 - val_acc: 0.9147\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9180 - val_loss: 0.1825 - val_acc: 0.9151\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9171 - val_loss: 0.1829 - val_acc: 0.9157\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18238 to 0.18232, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9161 - val_loss: 0.1823 - val_acc: 0.9157\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9163 - val_loss: 0.1828 - val_acc: 0.9147\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9165 - val_loss: 0.1824 - val_acc: 0.9153\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18232 to 0.18221, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9167 - val_loss: 0.1822 - val_acc: 0.9161\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18221 to 0.18202, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9162 - val_loss: 0.1820 - val_acc: 0.9151\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18202 to 0.18192, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9161 - val_loss: 0.1819 - val_acc: 0.9145\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9177 - val_loss: 0.1823 - val_acc: 0.9142\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9187 - val_loss: 0.1824 - val_acc: 0.9149\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9168 - val_loss: 0.1820 - val_acc: 0.9157\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18192 to 0.18175, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9177 - val_loss: 0.1818 - val_acc: 0.9145\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18175 to 0.18171, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9150 - val_loss: 0.1817 - val_acc: 0.9149\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9167 - val_loss: 0.1823 - val_acc: 0.9142\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9177 - val_loss: 0.1824 - val_acc: 0.9153\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9174 - val_loss: 0.1817 - val_acc: 0.9149\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9179 - val_loss: 0.1826 - val_acc: 0.9147\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18171 to 0.18110, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9169 - val_loss: 0.1811 - val_acc: 0.9172\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9172 - val_loss: 0.1813 - val_acc: 0.9155\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9186 - val_loss: 0.1820 - val_acc: 0.9143\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18110 to 0.18106, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9167 - val_loss: 0.1811 - val_acc: 0.9170\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18106 to 0.18086, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9163 - val_loss: 0.1809 - val_acc: 0.9159\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9174 - val_loss: 0.1813 - val_acc: 0.9163\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9184 - val_loss: 0.1809 - val_acc: 0.9159\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9164 - val_loss: 0.1809 - val_acc: 0.9153\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9183 - val_loss: 0.1809 - val_acc: 0.9157\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9186 - val_loss: 0.1815 - val_acc: 0.9143\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "1s - loss: 0.1789 - acc: 0.9170 - val_loss: 0.1809 - val_acc: 0.9159\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.18086 to 0.18064, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9190 - val_loss: 0.1806 - val_acc: 0.9157\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9177 - val_loss: 0.1806 - val_acc: 0.9155\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9177 - val_loss: 0.1808 - val_acc: 0.9163\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.18064 to 0.18055, saving model to best.model\n",
      "1s - loss: 0.1780 - acc: 0.9176 - val_loss: 0.1806 - val_acc: 0.9159\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18055 to 0.18021, saving model to best.model\n",
      "1s - loss: 0.1796 - acc: 0.9169 - val_loss: 0.1802 - val_acc: 0.9163\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18021 to 0.18009, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9178 - val_loss: 0.1801 - val_acc: 0.9159\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9174 - val_loss: 0.1817 - val_acc: 0.9151\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9167 - val_loss: 0.1809 - val_acc: 0.9149\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9186 - val_loss: 0.1802 - val_acc: 0.9159\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9177 - val_loss: 0.1801 - val_acc: 0.9159\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.18009 to 0.17971, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9176 - val_loss: 0.1797 - val_acc: 0.9165\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9181 - val_loss: 0.1804 - val_acc: 0.9155\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17971 to 0.17968, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9181 - val_loss: 0.1797 - val_acc: 0.9163\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.17968 to 0.17939, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9198 - val_loss: 0.1794 - val_acc: 0.9178\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9175 - val_loss: 0.1799 - val_acc: 0.9157\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17939 to 0.17911, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9181 - val_loss: 0.1791 - val_acc: 0.9180\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9178 - val_loss: 0.1792 - val_acc: 0.9170\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9175 - val_loss: 0.1797 - val_acc: 0.9170\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9197 - val_loss: 0.1813 - val_acc: 0.9153\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9165 - val_loss: 0.1793 - val_acc: 0.9165\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17911 to 0.17901, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9190 - val_loss: 0.1790 - val_acc: 0.9182\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9187 - val_loss: 0.1790 - val_acc: 0.9170\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9180 - val_loss: 0.1790 - val_acc: 0.9157\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17901 to 0.17886, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9177 - val_loss: 0.1789 - val_acc: 0.9178\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17886 to 0.17866, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9193 - val_loss: 0.1787 - val_acc: 0.9182\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9182 - val_loss: 0.1790 - val_acc: 0.9163\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17866 to 0.17835, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9181 - val_loss: 0.1784 - val_acc: 0.9190\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9188 - val_loss: 0.1785 - val_acc: 0.9165\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17835 to 0.17820, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9179 - val_loss: 0.1782 - val_acc: 0.9188\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9185 - val_loss: 0.1785 - val_acc: 0.9182\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9172 - val_loss: 0.1784 - val_acc: 0.9174\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9183 - val_loss: 0.1783 - val_acc: 0.9178\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17820 to 0.17808, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9187 - val_loss: 0.1781 - val_acc: 0.9191\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9198 - val_loss: 0.1790 - val_acc: 0.9172\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.17808 to 0.17784, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9189 - val_loss: 0.1778 - val_acc: 0.9190\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17784 to 0.17761, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9185 - val_loss: 0.1776 - val_acc: 0.9184\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17761 to 0.17742, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9195 - val_loss: 0.1774 - val_acc: 0.9201\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9198 - val_loss: 0.1776 - val_acc: 0.9199\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9203 - val_loss: 0.1775 - val_acc: 0.9193\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9185 - val_loss: 0.1775 - val_acc: 0.9188\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9186 - val_loss: 0.1776 - val_acc: 0.9167\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9189 - val_loss: 0.1783 - val_acc: 0.9167\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9186 - val_loss: 0.1775 - val_acc: 0.9174\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9191 - val_loss: 0.1777 - val_acc: 0.9197\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17742 to 0.17720, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9209 - val_loss: 0.1772 - val_acc: 0.9184\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9198 - val_loss: 0.1777 - val_acc: 0.9186\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17720 to 0.17703, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9201 - val_loss: 0.1770 - val_acc: 0.9199\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9195 - val_loss: 0.1770 - val_acc: 0.9190\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9194 - val_loss: 0.1772 - val_acc: 0.9193\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17703 to 0.17701, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9179 - val_loss: 0.1770 - val_acc: 0.9195\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9201 - val_loss: 0.1772 - val_acc: 0.9190\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17701 to 0.17681, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9189 - val_loss: 0.1768 - val_acc: 0.9186\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9193 - val_loss: 0.1772 - val_acc: 0.9172\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17681 to 0.17653, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9203 - val_loss: 0.1765 - val_acc: 0.9182\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9187 - val_loss: 0.1770 - val_acc: 0.9193\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9200 - val_loss: 0.1775 - val_acc: 0.9170\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.17653 to 0.17627, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9201 - val_loss: 0.1763 - val_acc: 0.9193\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9201 - val_loss: 0.1764 - val_acc: 0.9195\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9191 - val_loss: 0.1768 - val_acc: 0.9190\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9184 - val_loss: 0.1774 - val_acc: 0.9180\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9209 - val_loss: 0.1769 - val_acc: 0.9184\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.17627 to 0.17624, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9197 - val_loss: 0.1762 - val_acc: 0.9193\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17624 to 0.17603, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9182 - val_loss: 0.1760 - val_acc: 0.9193\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9194 - val_loss: 0.1761 - val_acc: 0.9191\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.17603 to 0.17570, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9185 - val_loss: 0.1757 - val_acc: 0.9191\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9198 - val_loss: 0.1758 - val_acc: 0.9197\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9207 - val_loss: 0.1757 - val_acc: 0.9193\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9197 - val_loss: 0.1761 - val_acc: 0.9195\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9198 - val_loss: 0.1762 - val_acc: 0.9190\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17570 to 0.17566, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9208 - val_loss: 0.1757 - val_acc: 0.9190\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.17566 to 0.17527, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9189 - val_loss: 0.1753 - val_acc: 0.9191\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9196 - val_loss: 0.1755 - val_acc: 0.9184\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9195 - val_loss: 0.1757 - val_acc: 0.9186\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.17527 to 0.17513, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9204 - val_loss: 0.1751 - val_acc: 0.9186\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9202 - val_loss: 0.1753 - val_acc: 0.9193\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9199 - val_loss: 0.1758 - val_acc: 0.9190\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9203 - val_loss: 0.1752 - val_acc: 0.9199\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9213 - val_loss: 0.1756 - val_acc: 0.9190\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9200 - val_loss: 0.1754 - val_acc: 0.9188\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9202 - val_loss: 0.1755 - val_acc: 0.9188\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9221 - val_loss: 0.1753 - val_acc: 0.9186\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.17513 to 0.17471, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9223 - val_loss: 0.1747 - val_acc: 0.9201\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.17471 to 0.17458, saving model to best.model\n",
      "0s - loss: 0.1706 - acc: 0.9193 - val_loss: 0.1746 - val_acc: 0.9199\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9203 - val_loss: 0.1753 - val_acc: 0.9190\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9209 - val_loss: 0.1749 - val_acc: 0.9188\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.17458 to 0.17457, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9202 - val_loss: 0.1746 - val_acc: 0.9195\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9203 - val_loss: 0.1747 - val_acc: 0.9197\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33182, saving model to best.model\n",
      "0s - loss: 0.4258 - acc: 0.8617 - val_loss: 0.3318 - val_acc: 0.8915\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33182 to 0.27740, saving model to best.model\n",
      "0s - loss: 0.3502 - acc: 0.8865 - val_loss: 0.2774 - val_acc: 0.8915\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27740 to 0.22591, saving model to best.model\n",
      "0s - loss: 0.2812 - acc: 0.8920 - val_loss: 0.2259 - val_acc: 0.9047\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22591 to 0.20186, saving model to best.model\n",
      "0s - loss: 0.2419 - acc: 0.8978 - val_loss: 0.2019 - val_acc: 0.9053\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20186 to 0.19631, saving model to best.model\n",
      "0s - loss: 0.2286 - acc: 0.8996 - val_loss: 0.1963 - val_acc: 0.9069\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.2154 - acc: 0.9028 - val_loss: 0.1975 - val_acc: 0.9078\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19631 to 0.19333, saving model to best.model\n",
      "0s - loss: 0.2126 - acc: 0.9019 - val_loss: 0.1933 - val_acc: 0.9084\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19333 to 0.19221, saving model to best.model\n",
      "0s - loss: 0.2088 - acc: 0.9049 - val_loss: 0.1922 - val_acc: 0.9094\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19221 to 0.19194, saving model to best.model\n",
      "0s - loss: 0.2068 - acc: 0.9035 - val_loss: 0.1919 - val_acc: 0.9094\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2057 - acc: 0.9030 - val_loss: 0.1921 - val_acc: 0.9088\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19194 to 0.19156, saving model to best.model\n",
      "0s - loss: 0.2030 - acc: 0.9053 - val_loss: 0.1916 - val_acc: 0.9101\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2005 - acc: 0.9040 - val_loss: 0.1917 - val_acc: 0.9092\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2019 - acc: 0.9057 - val_loss: 0.1917 - val_acc: 0.9090\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2005 - acc: 0.9052 - val_loss: 0.1920 - val_acc: 0.9101\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19156 to 0.19139, saving model to best.model\n",
      "0s - loss: 0.1994 - acc: 0.9064 - val_loss: 0.1914 - val_acc: 0.9115\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19139 to 0.19116, saving model to best.model\n",
      "0s - loss: 0.2002 - acc: 0.9070 - val_loss: 0.1912 - val_acc: 0.9105\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19116 to 0.19088, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9065 - val_loss: 0.1909 - val_acc: 0.9105\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1972 - acc: 0.9078 - val_loss: 0.1921 - val_acc: 0.9070\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1992 - acc: 0.9071 - val_loss: 0.1909 - val_acc: 0.9124\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9070 - val_loss: 0.1911 - val_acc: 0.9092\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9069 - val_loss: 0.1912 - val_acc: 0.9109\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19088 to 0.19041, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9081 - val_loss: 0.1904 - val_acc: 0.9105\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19041 to 0.18995, saving model to best.model\n",
      "1s - loss: 0.1952 - acc: 0.9070 - val_loss: 0.1900 - val_acc: 0.9103\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9077 - val_loss: 0.1908 - val_acc: 0.9076\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1959 - acc: 0.9080 - val_loss: 0.1905 - val_acc: 0.9088\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18995 to 0.18950, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9093 - val_loss: 0.1895 - val_acc: 0.9115\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18950 to 0.18874, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9096 - val_loss: 0.1887 - val_acc: 0.9103\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9098 - val_loss: 0.1897 - val_acc: 0.9092\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9097 - val_loss: 0.1889 - val_acc: 0.9113\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18874 to 0.18858, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9099 - val_loss: 0.1886 - val_acc: 0.9095\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18858 to 0.18808, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9090 - val_loss: 0.1881 - val_acc: 0.9097\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9086 - val_loss: 0.1881 - val_acc: 0.9103\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18808 to 0.18762, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9104 - val_loss: 0.1876 - val_acc: 0.9105\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18762 to 0.18757, saving model to best.model\n",
      "0s - loss: 0.1910 - acc: 0.9101 - val_loss: 0.1876 - val_acc: 0.9103\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18757 to 0.18719, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9101 - val_loss: 0.1872 - val_acc: 0.9105\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18719 to 0.18681, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9102 - val_loss: 0.1868 - val_acc: 0.9115\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18681 to 0.18622, saving model to best.model\n",
      "0s - loss: 0.1910 - acc: 0.9108 - val_loss: 0.1862 - val_acc: 0.9109\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18622 to 0.18616, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9108 - val_loss: 0.1862 - val_acc: 0.9109\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18616 to 0.18586, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9110 - val_loss: 0.1859 - val_acc: 0.9118\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18586 to 0.18577, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9121 - val_loss: 0.1858 - val_acc: 0.9103\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18577 to 0.18576, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9098 - val_loss: 0.1858 - val_acc: 0.9101\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18576 to 0.18529, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9091 - val_loss: 0.1853 - val_acc: 0.9107\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9117 - val_loss: 0.1858 - val_acc: 0.9117\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18529 to 0.18519, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9117 - val_loss: 0.1852 - val_acc: 0.9115\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9100 - val_loss: 0.1862 - val_acc: 0.9107\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18519 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9109 - val_loss: 0.1851 - val_acc: 0.9111\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9114 - val_loss: 0.1855 - val_acc: 0.9101\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18508 to 0.18452, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9113 - val_loss: 0.1845 - val_acc: 0.9124\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9109 - val_loss: 0.1849 - val_acc: 0.9111\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18452 to 0.18434, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9109 - val_loss: 0.1843 - val_acc: 0.9122\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9115 - val_loss: 0.1844 - val_acc: 0.9126\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18434 to 0.18418, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9103 - val_loss: 0.1842 - val_acc: 0.9122\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18418 to 0.18408, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9130 - val_loss: 0.1841 - val_acc: 0.9118\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18408 to 0.18372, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9125 - val_loss: 0.1837 - val_acc: 0.9138\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18372 to 0.18316, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9123 - val_loss: 0.1832 - val_acc: 0.9115\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9109 - val_loss: 0.1837 - val_acc: 0.9124\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18316 to 0.18269, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9106 - val_loss: 0.1827 - val_acc: 0.9111\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9110 - val_loss: 0.1829 - val_acc: 0.9118\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9126 - val_loss: 0.1828 - val_acc: 0.9111\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18269 to 0.18256, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9122 - val_loss: 0.1826 - val_acc: 0.9140\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18256 to 0.18234, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9117 - val_loss: 0.1823 - val_acc: 0.9113\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9119 - val_loss: 0.1826 - val_acc: 0.9138\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18234 to 0.18203, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9124 - val_loss: 0.1820 - val_acc: 0.9109\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9138 - val_loss: 0.1822 - val_acc: 0.9130\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9127 - val_loss: 0.1820 - val_acc: 0.9147\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9124 - val_loss: 0.1822 - val_acc: 0.9111\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18203 to 0.18202, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9126 - val_loss: 0.1820 - val_acc: 0.9140\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18202 to 0.18190, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9142 - val_loss: 0.1819 - val_acc: 0.9138\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18190 to 0.18170, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9123 - val_loss: 0.1817 - val_acc: 0.9122\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18170 to 0.18159, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9107 - val_loss: 0.1816 - val_acc: 0.9130\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9138 - val_loss: 0.1822 - val_acc: 0.9151\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18159 to 0.18110, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9126 - val_loss: 0.1811 - val_acc: 0.9132\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9133 - val_loss: 0.1812 - val_acc: 0.9124\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9126 - val_loss: 0.1812 - val_acc: 0.9120\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18110 to 0.18087, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9136 - val_loss: 0.1809 - val_acc: 0.9126\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9142 - val_loss: 0.1810 - val_acc: 0.9151\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9146 - val_loss: 0.1809 - val_acc: 0.9136\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9130 - val_loss: 0.1810 - val_acc: 0.9134\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18087 to 0.18050, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9141 - val_loss: 0.1805 - val_acc: 0.9120\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9137 - val_loss: 0.1805 - val_acc: 0.9138\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18050 to 0.18028, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9146 - val_loss: 0.1803 - val_acc: 0.9138\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9146 - val_loss: 0.1804 - val_acc: 0.9142\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9153 - val_loss: 0.1803 - val_acc: 0.9136\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9148 - val_loss: 0.1809 - val_acc: 0.9130\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9162 - val_loss: 0.1805 - val_acc: 0.9134\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.18028 to 0.17992, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9144 - val_loss: 0.1799 - val_acc: 0.9134\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9140 - val_loss: 0.1801 - val_acc: 0.9140\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17992 to 0.17960, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9129 - val_loss: 0.1796 - val_acc: 0.9143\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9133 - val_loss: 0.1802 - val_acc: 0.9142\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17960 to 0.17952, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9141 - val_loss: 0.1795 - val_acc: 0.9142\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17952 to 0.17942, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9136 - val_loss: 0.1794 - val_acc: 0.9132\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9147 - val_loss: 0.1796 - val_acc: 0.9136\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9159 - val_loss: 0.1795 - val_acc: 0.9142\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9153 - val_loss: 0.1795 - val_acc: 0.9136\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17942 to 0.17889, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9162 - val_loss: 0.1789 - val_acc: 0.9145\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9152 - val_loss: 0.1792 - val_acc: 0.9134\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17889 to 0.17880, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9154 - val_loss: 0.1788 - val_acc: 0.9153\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17880 to 0.17854, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9139 - val_loss: 0.1785 - val_acc: 0.9149\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9160 - val_loss: 0.1789 - val_acc: 0.9147\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9157 - val_loss: 0.1790 - val_acc: 0.9149\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9149 - val_loss: 0.1789 - val_acc: 0.9143\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17854 to 0.17845, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9154 - val_loss: 0.1785 - val_acc: 0.9147\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17845 to 0.17839, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9152 - val_loss: 0.1784 - val_acc: 0.9149\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17839 to 0.17808, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9151 - val_loss: 0.1781 - val_acc: 0.9147\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9169 - val_loss: 0.1782 - val_acc: 0.9153\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9149 - val_loss: 0.1781 - val_acc: 0.9149\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17808 to 0.17797, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9151 - val_loss: 0.1780 - val_acc: 0.9134\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "1s - loss: 0.1768 - acc: 0.9158 - val_loss: 0.1784 - val_acc: 0.9147\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17797 to 0.17781, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9152 - val_loss: 0.1778 - val_acc: 0.9145\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9155 - val_loss: 0.1779 - val_acc: 0.9153\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9160 - val_loss: 0.1781 - val_acc: 0.9140\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17781 to 0.17772, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9164 - val_loss: 0.1777 - val_acc: 0.9151\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9161 - val_loss: 0.1778 - val_acc: 0.9157\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17772 to 0.17756, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9165 - val_loss: 0.1776 - val_acc: 0.9151\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.17756 to 0.17738, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9171 - val_loss: 0.1774 - val_acc: 0.9142\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9163 - val_loss: 0.1779 - val_acc: 0.9143\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9164 - val_loss: 0.1783 - val_acc: 0.9153\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9163 - val_loss: 0.1796 - val_acc: 0.9132\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9156 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.17738 to 0.17738, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9148 - val_loss: 0.1774 - val_acc: 0.9149\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9170 - val_loss: 0.1780 - val_acc: 0.9147\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17738 to 0.17697, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9175 - val_loss: 0.1770 - val_acc: 0.9143\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9172 - val_loss: 0.1773 - val_acc: 0.9149\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17697 to 0.17692, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9171 - val_loss: 0.1769 - val_acc: 0.9151\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17692 to 0.17668, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9162 - val_loss: 0.1767 - val_acc: 0.9157\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17668 to 0.17648, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9172 - val_loss: 0.1765 - val_acc: 0.9147\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9177 - val_loss: 0.1767 - val_acc: 0.9155\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9178 - val_loss: 0.1771 - val_acc: 0.9155\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17648 to 0.17647, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9172 - val_loss: 0.1765 - val_acc: 0.9153\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17647 to 0.17628, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9170 - val_loss: 0.1763 - val_acc: 0.9153\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17628 to 0.17600, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9171 - val_loss: 0.1760 - val_acc: 0.9151\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9162 - val_loss: 0.1768 - val_acc: 0.9138\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9182 - val_loss: 0.1773 - val_acc: 0.9138\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9156 - val_loss: 0.1760 - val_acc: 0.9145\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17600 to 0.17589, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9184 - val_loss: 0.1759 - val_acc: 0.9134\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17589 to 0.17577, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9188 - val_loss: 0.1758 - val_acc: 0.9145\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9185 - val_loss: 0.1761 - val_acc: 0.9142\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9159 - val_loss: 0.1760 - val_acc: 0.9134\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9185 - val_loss: 0.1758 - val_acc: 0.9143\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9180 - val_loss: 0.1759 - val_acc: 0.9142\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9179 - val_loss: 0.1759 - val_acc: 0.9136\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17577 to 0.17543, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9174 - val_loss: 0.1754 - val_acc: 0.9138\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9186 - val_loss: 0.1758 - val_acc: 0.9124\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17543 to 0.17507, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9186 - val_loss: 0.1751 - val_acc: 0.9134\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9172 - val_loss: 0.1752 - val_acc: 0.9147\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9183 - val_loss: 0.1760 - val_acc: 0.9142\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9188 - val_loss: 0.1759 - val_acc: 0.9130\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "1s - loss: 0.1720 - acc: 0.9190 - val_loss: 0.1755 - val_acc: 0.9145\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9184 - val_loss: 0.1753 - val_acc: 0.9151\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17507 to 0.17486, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9171 - val_loss: 0.1749 - val_acc: 0.9153\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9188 - val_loss: 0.1752 - val_acc: 0.9136\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9197 - val_loss: 0.1753 - val_acc: 0.9155\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9175 - val_loss: 0.1753 - val_acc: 0.9143\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9175 - val_loss: 0.1755 - val_acc: 0.9122\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9194 - val_loss: 0.1754 - val_acc: 0.9132\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17486 to 0.17468, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9173 - val_loss: 0.1747 - val_acc: 0.9149\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9185 - val_loss: 0.1753 - val_acc: 0.9136\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9194 - val_loss: 0.1749 - val_acc: 0.9138\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9199 - val_loss: 0.1755 - val_acc: 0.9132\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9182 - val_loss: 0.1747 - val_acc: 0.9138\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9188 - val_loss: 0.1749 - val_acc: 0.9136\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9208 - val_loss: 0.1751 - val_acc: 0.9138\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17468 to 0.17463, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9204 - val_loss: 0.1746 - val_acc: 0.9126\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9196 - val_loss: 0.1750 - val_acc: 0.9134\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9186 - val_loss: 0.1746 - val_acc: 0.9142\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.17463 to 0.17442, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9184 - val_loss: 0.1744 - val_acc: 0.9161\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9189 - val_loss: 0.1748 - val_acc: 0.9142\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9209 - val_loss: 0.1747 - val_acc: 0.9130\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9193 - val_loss: 0.1745 - val_acc: 0.9134\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.17442 to 0.17420, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9186 - val_loss: 0.1742 - val_acc: 0.9136\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17420 to 0.17389, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9189 - val_loss: 0.1739 - val_acc: 0.9143\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9210 - val_loss: 0.1740 - val_acc: 0.9140\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9180 - val_loss: 0.1747 - val_acc: 0.9151\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9208 - val_loss: 0.1742 - val_acc: 0.9145\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9198 - val_loss: 0.1740 - val_acc: 0.9157\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9191 - val_loss: 0.1741 - val_acc: 0.9136\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9200 - val_loss: 0.1754 - val_acc: 0.9149\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.17389 to 0.17388, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9187 - val_loss: 0.1739 - val_acc: 0.9136\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9198 - val_loss: 0.1748 - val_acc: 0.9151\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9199 - val_loss: 0.1740 - val_acc: 0.9145\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9197 - val_loss: 0.1746 - val_acc: 0.9145\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9207 - val_loss: 0.1744 - val_acc: 0.9132\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17388 to 0.17362, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9210 - val_loss: 0.1736 - val_acc: 0.9143\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9189 - val_loss: 0.1739 - val_acc: 0.9140\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9193 - val_loss: 0.1739 - val_acc: 0.9138\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9197 - val_loss: 0.1749 - val_acc: 0.9138\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9202 - val_loss: 0.1738 - val_acc: 0.9143\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9203 - val_loss: 0.1746 - val_acc: 0.9149\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9196 - val_loss: 0.1738 - val_acc: 0.9143\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9199 - val_loss: 0.1737 - val_acc: 0.9147\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.17362 to 0.17336, saving model to best.model\n",
      "0s - loss: 0.1686 - acc: 0.9202 - val_loss: 0.1734 - val_acc: 0.9149\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9203 - val_loss: 0.1751 - val_acc: 0.9147\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9212 - val_loss: 0.1737 - val_acc: 0.9145\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9215 - val_loss: 0.1736 - val_acc: 0.9138\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9203 - val_loss: 0.1737 - val_acc: 0.9140\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9202 - val_loss: 0.1734 - val_acc: 0.9149\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9216 - val_loss: 0.1735 - val_acc: 0.9143\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9202 - val_loss: 0.1734 - val_acc: 0.9147\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9199 - val_loss: 0.1740 - val_acc: 0.9149\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9202 - val_loss: 0.1740 - val_acc: 0.9151\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33683, saving model to best.model\n",
      "0s - loss: 0.4187 - acc: 0.8655 - val_loss: 0.3368 - val_acc: 0.8857\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33683 to 0.27204, saving model to best.model\n",
      "0s - loss: 0.3359 - acc: 0.8853 - val_loss: 0.2720 - val_acc: 0.8859\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27204 to 0.22334, saving model to best.model\n",
      "0s - loss: 0.2713 - acc: 0.8923 - val_loss: 0.2233 - val_acc: 0.9003\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22334 to 0.20706, saving model to best.model\n",
      "0s - loss: 0.2401 - acc: 0.9000 - val_loss: 0.2071 - val_acc: 0.9021\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20706 to 0.20053, saving model to best.model\n",
      "0s - loss: 0.2271 - acc: 0.9017 - val_loss: 0.2005 - val_acc: 0.9038\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20053 to 0.19713, saving model to best.model\n",
      "0s - loss: 0.2156 - acc: 0.9031 - val_loss: 0.1971 - val_acc: 0.9061\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19713 to 0.19475, saving model to best.model\n",
      "0s - loss: 0.2104 - acc: 0.9031 - val_loss: 0.1948 - val_acc: 0.9061\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19475 to 0.19369, saving model to best.model\n",
      "0s - loss: 0.2109 - acc: 0.9041 - val_loss: 0.1937 - val_acc: 0.9067\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19369 to 0.19307, saving model to best.model\n",
      "0s - loss: 0.2096 - acc: 0.9034 - val_loss: 0.1931 - val_acc: 0.9067\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19307 to 0.19189, saving model to best.model\n",
      "0s - loss: 0.2063 - acc: 0.9056 - val_loss: 0.1919 - val_acc: 0.9065\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2038 - acc: 0.9047 - val_loss: 0.1927 - val_acc: 0.9059\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2027 - acc: 0.9061 - val_loss: 0.1923 - val_acc: 0.9042\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19189 to 0.19133, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9057 - val_loss: 0.1913 - val_acc: 0.9059\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19133 to 0.19115, saving model to best.model\n",
      "0s - loss: 0.2027 - acc: 0.9064 - val_loss: 0.1911 - val_acc: 0.9047\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19115 to 0.19109, saving model to best.model\n",
      "0s - loss: 0.2006 - acc: 0.9065 - val_loss: 0.1911 - val_acc: 0.9055\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19109 to 0.19065, saving model to best.model\n",
      "0s - loss: 0.1996 - acc: 0.9055 - val_loss: 0.1906 - val_acc: 0.9057\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19065 to 0.19056, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9059 - val_loss: 0.1906 - val_acc: 0.9063\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9080 - val_loss: 0.1910 - val_acc: 0.9044\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19056 to 0.19042, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9058 - val_loss: 0.1904 - val_acc: 0.9065\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1983 - acc: 0.9078 - val_loss: 0.1907 - val_acc: 0.9063\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1989 - acc: 0.9065 - val_loss: 0.1906 - val_acc: 0.9065\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19042 to 0.19013, saving model to best.model\n",
      "1s - loss: 0.1984 - acc: 0.9087 - val_loss: 0.1901 - val_acc: 0.9061\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1972 - acc: 0.9061 - val_loss: 0.1905 - val_acc: 0.9053\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19013 to 0.19013, saving model to best.model\n",
      "0s - loss: 0.1996 - acc: 0.9072 - val_loss: 0.1901 - val_acc: 0.9055\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19013 to 0.19003, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9086 - val_loss: 0.1900 - val_acc: 0.9063\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1956 - acc: 0.9078 - val_loss: 0.1902 - val_acc: 0.9053\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19003 to 0.18948, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9066 - val_loss: 0.1895 - val_acc: 0.9069\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1966 - acc: 0.9082 - val_loss: 0.1899 - val_acc: 0.9063\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18948 to 0.18933, saving model to best.model\n",
      "0s - loss: 0.1962 - acc: 0.9078 - val_loss: 0.1893 - val_acc: 0.9057\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18933 to 0.18921, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9077 - val_loss: 0.1892 - val_acc: 0.9055\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18921 to 0.18899, saving model to best.model\n",
      "0s - loss: 0.1941 - acc: 0.9106 - val_loss: 0.1890 - val_acc: 0.9072\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18899 to 0.18885, saving model to best.model\n",
      "0s - loss: 0.1934 - acc: 0.9117 - val_loss: 0.1889 - val_acc: 0.9070\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9085 - val_loss: 0.1890 - val_acc: 0.9055\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18885 to 0.18878, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9093 - val_loss: 0.1888 - val_acc: 0.9053\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18878 to 0.18810, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9096 - val_loss: 0.1881 - val_acc: 0.9076\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18810 to 0.18787, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9090 - val_loss: 0.1879 - val_acc: 0.9063\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9102 - val_loss: 0.1884 - val_acc: 0.9061\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1923 - acc: 0.9113 - val_loss: 0.1879 - val_acc: 0.9053\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18787 to 0.18775, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9096 - val_loss: 0.1878 - val_acc: 0.9053\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18775 to 0.18714, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9095 - val_loss: 0.1871 - val_acc: 0.9063\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18714 to 0.18712, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9079 - val_loss: 0.1871 - val_acc: 0.9059\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9099 - val_loss: 0.1871 - val_acc: 0.9072\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18712 to 0.18659, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9100 - val_loss: 0.1866 - val_acc: 0.9070\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18659 to 0.18629, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9108 - val_loss: 0.1863 - val_acc: 0.9072\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9110 - val_loss: 0.1864 - val_acc: 0.9059\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9080 - val_loss: 0.1863 - val_acc: 0.9070\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18629 to 0.18618, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9113 - val_loss: 0.1862 - val_acc: 0.9076\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18618 to 0.18607, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9119 - val_loss: 0.1861 - val_acc: 0.9053\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18607 to 0.18553, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9105 - val_loss: 0.1855 - val_acc: 0.9097\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18553 to 0.18539, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9125 - val_loss: 0.1854 - val_acc: 0.9069\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9104 - val_loss: 0.1859 - val_acc: 0.9092\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9109 - val_loss: 0.1864 - val_acc: 0.9072\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18539 to 0.18537, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9106 - val_loss: 0.1854 - val_acc: 0.9070\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18537 to 0.18527, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9106 - val_loss: 0.1853 - val_acc: 0.9103\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18527 to 0.18514, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9117 - val_loss: 0.1851 - val_acc: 0.9078\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18514 to 0.18452, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9118 - val_loss: 0.1845 - val_acc: 0.9107\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18452 to 0.18443, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9114 - val_loss: 0.1844 - val_acc: 0.9061\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9107 - val_loss: 0.1850 - val_acc: 0.9103\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18443 to 0.18399, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9125 - val_loss: 0.1840 - val_acc: 0.9097\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18399 to 0.18391, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9107 - val_loss: 0.1839 - val_acc: 0.9082\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18391 to 0.18388, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9103 - val_loss: 0.1839 - val_acc: 0.9070\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18388 to 0.18370, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9115 - val_loss: 0.1837 - val_acc: 0.9072\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18370 to 0.18359, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9106 - val_loss: 0.1836 - val_acc: 0.9088\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9125 - val_loss: 0.1837 - val_acc: 0.9082\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18359 to 0.18335, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9116 - val_loss: 0.1833 - val_acc: 0.9107\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18335 to 0.18317, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9121 - val_loss: 0.1832 - val_acc: 0.9107\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18317 to 0.18303, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9122 - val_loss: 0.1830 - val_acc: 0.9097\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18303 to 0.18271, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9120 - val_loss: 0.1827 - val_acc: 0.9111\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18271 to 0.18260, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9123 - val_loss: 0.1826 - val_acc: 0.9113\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9116 - val_loss: 0.1826 - val_acc: 0.9109\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18260 to 0.18237, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9118 - val_loss: 0.1824 - val_acc: 0.9109\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9129 - val_loss: 0.1830 - val_acc: 0.9105\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18237 to 0.18221, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9146 - val_loss: 0.1822 - val_acc: 0.9120\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18221 to 0.18216, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9121 - val_loss: 0.1822 - val_acc: 0.9115\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18216 to 0.18187, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9137 - val_loss: 0.1819 - val_acc: 0.9124\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9129 - val_loss: 0.1826 - val_acc: 0.9111\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9121 - val_loss: 0.1826 - val_acc: 0.9107\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.18187 to 0.18129, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9117 - val_loss: 0.1813 - val_acc: 0.9111\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18129 to 0.18089, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9131 - val_loss: 0.1809 - val_acc: 0.9126\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9132 - val_loss: 0.1811 - val_acc: 0.9124\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9143 - val_loss: 0.1813 - val_acc: 0.9122\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18089 to 0.18051, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9122 - val_loss: 0.1805 - val_acc: 0.9122\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.18051 to 0.18038, saving model to best.model\n",
      "1s - loss: 0.1849 - acc: 0.9141 - val_loss: 0.1804 - val_acc: 0.9120\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9138 - val_loss: 0.1811 - val_acc: 0.9118\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9149 - val_loss: 0.1810 - val_acc: 0.9136\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9134 - val_loss: 0.1806 - val_acc: 0.9130\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18038 to 0.18014, saving model to best.model\n",
      "1s - loss: 0.1860 - acc: 0.9115 - val_loss: 0.1801 - val_acc: 0.9126\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18014 to 0.17995, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9123 - val_loss: 0.1799 - val_acc: 0.9132\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17995 to 0.17992, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9140 - val_loss: 0.1799 - val_acc: 0.9128\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9125 - val_loss: 0.1800 - val_acc: 0.9128\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17992 to 0.17972, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9139 - val_loss: 0.1797 - val_acc: 0.9124\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17972 to 0.17963, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9147 - val_loss: 0.1796 - val_acc: 0.9126\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17963 to 0.17944, saving model to best.model\n",
      "0s - loss: 0.1820 - acc: 0.9132 - val_loss: 0.1794 - val_acc: 0.9126\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17944 to 0.17911, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9142 - val_loss: 0.1791 - val_acc: 0.9120\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9126 - val_loss: 0.1792 - val_acc: 0.9124\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17911 to 0.17895, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9141 - val_loss: 0.1790 - val_acc: 0.9130\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17895 to 0.17871, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9152 - val_loss: 0.1787 - val_acc: 0.9138\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9135 - val_loss: 0.1791 - val_acc: 0.9138\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9129 - val_loss: 0.1788 - val_acc: 0.9128\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17871 to 0.17852, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9141 - val_loss: 0.1785 - val_acc: 0.9124\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17852 to 0.17828, saving model to best.model\n",
      "1s - loss: 0.1820 - acc: 0.9133 - val_loss: 0.1783 - val_acc: 0.9140\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17828 to 0.17812, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9136 - val_loss: 0.1781 - val_acc: 0.9142\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9144 - val_loss: 0.1788 - val_acc: 0.9126\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17812 to 0.17786, saving model to best.model\n",
      "1s - loss: 0.1846 - acc: 0.9140 - val_loss: 0.1779 - val_acc: 0.9130\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9148 - val_loss: 0.1780 - val_acc: 0.9142\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9166 - val_loss: 0.1789 - val_acc: 0.9124\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17786 to 0.17784, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9148 - val_loss: 0.1778 - val_acc: 0.9136\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17784 to 0.17757, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9157 - val_loss: 0.1776 - val_acc: 0.9143\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17757 to 0.17738, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9164 - val_loss: 0.1774 - val_acc: 0.9143\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9156 - val_loss: 0.1774 - val_acc: 0.9136\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9151 - val_loss: 0.1775 - val_acc: 0.9140\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9141 - val_loss: 0.1775 - val_acc: 0.9142\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.17738 to 0.17732, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9148 - val_loss: 0.1773 - val_acc: 0.9147\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17732 to 0.17717, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9150 - val_loss: 0.1772 - val_acc: 0.9149\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.17717 to 0.17683, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9150 - val_loss: 0.1768 - val_acc: 0.9138\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9167 - val_loss: 0.1771 - val_acc: 0.9151\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9146 - val_loss: 0.1771 - val_acc: 0.9134\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17683 to 0.17663, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9141 - val_loss: 0.1766 - val_acc: 0.9145\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9156 - val_loss: 0.1768 - val_acc: 0.9155\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9161 - val_loss: 0.1769 - val_acc: 0.9151\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17663 to 0.17638, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9160 - val_loss: 0.1764 - val_acc: 0.9153\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9155 - val_loss: 0.1765 - val_acc: 0.9145\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17638 to 0.17629, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9159 - val_loss: 0.1763 - val_acc: 0.9143\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17629 to 0.17601, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9160 - val_loss: 0.1760 - val_acc: 0.9155\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9172 - val_loss: 0.1769 - val_acc: 0.9118\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9167 - val_loss: 0.1762 - val_acc: 0.9155\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9145 - val_loss: 0.1761 - val_acc: 0.9151\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9150 - val_loss: 0.1766 - val_acc: 0.9126\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9150 - val_loss: 0.1762 - val_acc: 0.9159\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17601 to 0.17597, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9162 - val_loss: 0.1760 - val_acc: 0.9143\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17597 to 0.17593, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9156 - val_loss: 0.1759 - val_acc: 0.9147\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17593 to 0.17568, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9149 - val_loss: 0.1757 - val_acc: 0.9161\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17568 to 0.17546, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9168 - val_loss: 0.1755 - val_acc: 0.9153\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9159 - val_loss: 0.1761 - val_acc: 0.9134\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17546 to 0.17544, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9164 - val_loss: 0.1754 - val_acc: 0.9153\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9145 - val_loss: 0.1756 - val_acc: 0.9165\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9175 - val_loss: 0.1756 - val_acc: 0.9155\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9152 - val_loss: 0.1757 - val_acc: 0.9140\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9157 - val_loss: 0.1756 - val_acc: 0.9168\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17544 to 0.17536, saving model to best.model\n",
      "1s - loss: 0.1764 - acc: 0.9156 - val_loss: 0.1754 - val_acc: 0.9165\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17536 to 0.17510, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9169 - val_loss: 0.1751 - val_acc: 0.9153\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17510 to 0.17486, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9154 - val_loss: 0.1749 - val_acc: 0.9153\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17486 to 0.17477, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9151 - val_loss: 0.1748 - val_acc: 0.9163\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9163 - val_loss: 0.1752 - val_acc: 0.9168\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.17477 to 0.17471, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9163 - val_loss: 0.1747 - val_acc: 0.9163\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17471 to 0.17464, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9163 - val_loss: 0.1746 - val_acc: 0.9159\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17464 to 0.17439, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9164 - val_loss: 0.1744 - val_acc: 0.9163\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.17439 to 0.17435, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9173 - val_loss: 0.1744 - val_acc: 0.9170\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17435 to 0.17434, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9161 - val_loss: 0.1743 - val_acc: 0.9163\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17434 to 0.17417, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9157 - val_loss: 0.1742 - val_acc: 0.9159\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9163 - val_loss: 0.1745 - val_acc: 0.9145\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9163 - val_loss: 0.1743 - val_acc: 0.9149\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9160 - val_loss: 0.1744 - val_acc: 0.9165\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "1s - loss: 0.1761 - acc: 0.9165 - val_loss: 0.1744 - val_acc: 0.9167\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9169 - val_loss: 0.1743 - val_acc: 0.9147\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9154 - val_loss: 0.1743 - val_acc: 0.9157\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9175 - val_loss: 0.1748 - val_acc: 0.9151\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9174 - val_loss: 0.1743 - val_acc: 0.9143\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9179 - val_loss: 0.1743 - val_acc: 0.9147\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9152 - val_loss: 0.1742 - val_acc: 0.9159\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.17417 to 0.17406, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9181 - val_loss: 0.1741 - val_acc: 0.9157\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9172 - val_loss: 0.1742 - val_acc: 0.9155\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9173 - val_loss: 0.1744 - val_acc: 0.9143\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9167 - val_loss: 0.1745 - val_acc: 0.9161\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17406 to 0.17382, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9167 - val_loss: 0.1738 - val_acc: 0.9143\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9169 - val_loss: 0.1741 - val_acc: 0.9155\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9175 - val_loss: 0.1751 - val_acc: 0.9147\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9155 - val_loss: 0.1740 - val_acc: 0.9140\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17382 to 0.17347, saving model to best.model\n",
      "1s - loss: 0.1741 - acc: 0.9181 - val_loss: 0.1735 - val_acc: 0.9159\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.17347 to 0.17346, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9186 - val_loss: 0.1735 - val_acc: 0.9157\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "1s - loss: 0.1737 - acc: 0.9187 - val_loss: 0.1736 - val_acc: 0.9165\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.17346 to 0.17317, saving model to best.model\n",
      "1s - loss: 0.1751 - acc: 0.9164 - val_loss: 0.1732 - val_acc: 0.9147\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9185 - val_loss: 0.1733 - val_acc: 0.9161\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "1s - loss: 0.1735 - acc: 0.9177 - val_loss: 0.1733 - val_acc: 0.9147\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9185 - val_loss: 0.1737 - val_acc: 0.9134\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9169 - val_loss: 0.1737 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9169 - val_loss: 0.1735 - val_acc: 0.9157\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9177 - val_loss: 0.1736 - val_acc: 0.9161\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9179 - val_loss: 0.1734 - val_acc: 0.9165\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9163 - val_loss: 0.1733 - val_acc: 0.9142\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9197 - val_loss: 0.1737 - val_acc: 0.9155\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9172 - val_loss: 0.1735 - val_acc: 0.9136\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9180 - val_loss: 0.1733 - val_acc: 0.9140\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9159 - val_loss: 0.1734 - val_acc: 0.9151\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17317 to 0.17311, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9172 - val_loss: 0.1731 - val_acc: 0.9149\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9182 - val_loss: 0.1734 - val_acc: 0.9147\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9179 - val_loss: 0.1737 - val_acc: 0.9159\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9161 - val_loss: 0.1733 - val_acc: 0.9151\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9167 - val_loss: 0.1741 - val_acc: 0.9140\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9164 - val_loss: 0.1734 - val_acc: 0.9140\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9165 - val_loss: 0.1746 - val_acc: 0.9138\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9186 - val_loss: 0.1734 - val_acc: 0.9142\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9179 - val_loss: 0.1738 - val_acc: 0.9161\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9173 - val_loss: 0.1735 - val_acc: 0.9149\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9195 - val_loss: 0.1733 - val_acc: 0.9143\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9179 - val_loss: 0.1741 - val_acc: 0.9143\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9177 - val_loss: 0.1733 - val_acc: 0.9155\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9178 - val_loss: 0.1731 - val_acc: 0.9159\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "1s - loss: 0.1735 - acc: 0.9168 - val_loss: 0.1738 - val_acc: 0.9128\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9183 - val_loss: 0.1733 - val_acc: 0.9145\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32940, saving model to best.model\n",
      "0s - loss: 0.4450 - acc: 0.8512 - val_loss: 0.3294 - val_acc: 0.8926\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32940 to 0.26857, saving model to best.model\n",
      "0s - loss: 0.3533 - acc: 0.8831 - val_loss: 0.2686 - val_acc: 0.8926\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26857 to 0.21164, saving model to best.model\n",
      "0s - loss: 0.2816 - acc: 0.8888 - val_loss: 0.2116 - val_acc: 0.9128\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21164 to 0.19207, saving model to best.model\n",
      "0s - loss: 0.2408 - acc: 0.8971 - val_loss: 0.1921 - val_acc: 0.9161\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19207 to 0.18723, saving model to best.model\n",
      "0s - loss: 0.2235 - acc: 0.9033 - val_loss: 0.1872 - val_acc: 0.9186\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18723 to 0.18494, saving model to best.model\n",
      "0s - loss: 0.2153 - acc: 0.9050 - val_loss: 0.1849 - val_acc: 0.9174\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18494 to 0.18315, saving model to best.model\n",
      "0s - loss: 0.2096 - acc: 0.9050 - val_loss: 0.1832 - val_acc: 0.9167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18315 to 0.18278, saving model to best.model\n",
      "0s - loss: 0.2088 - acc: 0.9062 - val_loss: 0.1828 - val_acc: 0.9170\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18278 to 0.18208, saving model to best.model\n",
      "0s - loss: 0.2070 - acc: 0.9057 - val_loss: 0.1821 - val_acc: 0.9163\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18208 to 0.18174, saving model to best.model\n",
      "0s - loss: 0.2031 - acc: 0.9073 - val_loss: 0.1817 - val_acc: 0.9157\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18174 to 0.18150, saving model to best.model\n",
      "0s - loss: 0.2040 - acc: 0.9064 - val_loss: 0.1815 - val_acc: 0.9151\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2025 - acc: 0.9065 - val_loss: 0.1818 - val_acc: 0.9159\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2010 - acc: 0.9085 - val_loss: 0.1816 - val_acc: 0.9155\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18150 to 0.18110, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9097 - val_loss: 0.1811 - val_acc: 0.9155\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2004 - acc: 0.9077 - val_loss: 0.1817 - val_acc: 0.9161\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2007 - acc: 0.9102 - val_loss: 0.1812 - val_acc: 0.9161\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18110 to 0.18107, saving model to best.model\n",
      "0s - loss: 0.1986 - acc: 0.9100 - val_loss: 0.1811 - val_acc: 0.9159\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1978 - acc: 0.9096 - val_loss: 0.1815 - val_acc: 0.9153\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "1s - loss: 0.1983 - acc: 0.9100 - val_loss: 0.1811 - val_acc: 0.9159\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18107 to 0.18085, saving model to best.model\n",
      "0s - loss: 0.1979 - acc: 0.9101 - val_loss: 0.1809 - val_acc: 0.9153\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "1s - loss: 0.1959 - acc: 0.9094 - val_loss: 0.1809 - val_acc: 0.9161\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18085 to 0.18079, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9101 - val_loss: 0.1808 - val_acc: 0.9163\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18079 to 0.18046, saving model to best.model\n",
      "1s - loss: 0.1974 - acc: 0.9108 - val_loss: 0.1805 - val_acc: 0.9153\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18046 to 0.18028, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9114 - val_loss: 0.1803 - val_acc: 0.9153\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18028 to 0.18014, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9110 - val_loss: 0.1801 - val_acc: 0.9159\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18014 to 0.18007, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9109 - val_loss: 0.1801 - val_acc: 0.9163\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18007 to 0.17990, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9101 - val_loss: 0.1799 - val_acc: 0.9151\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.17990 to 0.17983, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9107 - val_loss: 0.1798 - val_acc: 0.9168\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9115 - val_loss: 0.1802 - val_acc: 0.9170\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.17983 to 0.17958, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9114 - val_loss: 0.1796 - val_acc: 0.9159\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.17958 to 0.17952, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9112 - val_loss: 0.1795 - val_acc: 0.9165\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9128 - val_loss: 0.1798 - val_acc: 0.9168\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9115 - val_loss: 0.1796 - val_acc: 0.9174\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17952 to 0.17944, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9105 - val_loss: 0.1794 - val_acc: 0.9176\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17944 to 0.17919, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9121 - val_loss: 0.1792 - val_acc: 0.9167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9120 - val_loss: 0.1793 - val_acc: 0.9159\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17919 to 0.17905, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9114 - val_loss: 0.1791 - val_acc: 0.9167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9120 - val_loss: 0.1792 - val_acc: 0.9174\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9122 - val_loss: 0.1794 - val_acc: 0.9147\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9116 - val_loss: 0.1795 - val_acc: 0.9174\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17905 to 0.17869, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9135 - val_loss: 0.1787 - val_acc: 0.9153\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9109 - val_loss: 0.1789 - val_acc: 0.9163\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17869 to 0.17830, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9133 - val_loss: 0.1783 - val_acc: 0.9155\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9125 - val_loss: 0.1785 - val_acc: 0.9163\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9141 - val_loss: 0.1783 - val_acc: 0.9172\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9121 - val_loss: 0.1783 - val_acc: 0.9163\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9131 - val_loss: 0.1791 - val_acc: 0.9145\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17830 to 0.17793, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9133 - val_loss: 0.1779 - val_acc: 0.9172\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9138 - val_loss: 0.1784 - val_acc: 0.9165\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9114 - val_loss: 0.1781 - val_acc: 0.9172\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17793 to 0.17773, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9130 - val_loss: 0.1777 - val_acc: 0.9174\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9147 - val_loss: 0.1779 - val_acc: 0.9165\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17773 to 0.17752, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9126 - val_loss: 0.1775 - val_acc: 0.9170\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9127 - val_loss: 0.1777 - val_acc: 0.9172\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9128 - val_loss: 0.1777 - val_acc: 0.9165\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9133 - val_loss: 0.1778 - val_acc: 0.9167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9148 - val_loss: 0.1775 - val_acc: 0.9157\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9147 - val_loss: 0.1777 - val_acc: 0.9172\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9128 - val_loss: 0.1776 - val_acc: 0.9151\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.17752 to 0.17734, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9132 - val_loss: 0.1773 - val_acc: 0.9159\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17734 to 0.17727, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9133 - val_loss: 0.1773 - val_acc: 0.9168\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1872 - acc: 0.9128 - val_loss: 0.1783 - val_acc: 0.9159\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17727 to 0.17713, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9135 - val_loss: 0.1771 - val_acc: 0.9165\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9138 - val_loss: 0.1775 - val_acc: 0.9147\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.17713 to 0.17694, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9152 - val_loss: 0.1769 - val_acc: 0.9168\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9148 - val_loss: 0.1773 - val_acc: 0.9159\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9134 - val_loss: 0.1773 - val_acc: 0.9167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9158 - val_loss: 0.1772 - val_acc: 0.9167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9131 - val_loss: 0.1777 - val_acc: 0.9170\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.17694 to 0.17675, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9152 - val_loss: 0.1768 - val_acc: 0.9161\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9128 - val_loss: 0.1768 - val_acc: 0.9161\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9143 - val_loss: 0.1770 - val_acc: 0.9172\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9140 - val_loss: 0.1771 - val_acc: 0.9161\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17675 to 0.17639, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9155 - val_loss: 0.1764 - val_acc: 0.9168\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9152 - val_loss: 0.1769 - val_acc: 0.9157\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9155 - val_loss: 0.1765 - val_acc: 0.9168\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9154 - val_loss: 0.1768 - val_acc: 0.9172\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9153 - val_loss: 0.1765 - val_acc: 0.9163\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17639 to 0.17637, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9163 - val_loss: 0.1764 - val_acc: 0.9167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9155 - val_loss: 0.1764 - val_acc: 0.9172\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17637 to 0.17635, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9145 - val_loss: 0.1763 - val_acc: 0.9174\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.17635 to 0.17599, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9152 - val_loss: 0.1760 - val_acc: 0.9165\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9156 - val_loss: 0.1771 - val_acc: 0.9176\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9145 - val_loss: 0.1762 - val_acc: 0.9176\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.17599 to 0.17584, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9160 - val_loss: 0.1758 - val_acc: 0.9168\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17584 to 0.17570, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9143 - val_loss: 0.1757 - val_acc: 0.9174\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9164 - val_loss: 0.1760 - val_acc: 0.9165\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9152 - val_loss: 0.1757 - val_acc: 0.9170\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9165 - val_loss: 0.1760 - val_acc: 0.9172\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17570 to 0.17552, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9159 - val_loss: 0.1755 - val_acc: 0.9172\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17552 to 0.17537, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9153 - val_loss: 0.1754 - val_acc: 0.9174\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17537 to 0.17527, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9166 - val_loss: 0.1753 - val_acc: 0.9172\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17527 to 0.17522, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9150 - val_loss: 0.1752 - val_acc: 0.9174\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9151 - val_loss: 0.1753 - val_acc: 0.9168\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9144 - val_loss: 0.1757 - val_acc: 0.9182\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9163 - val_loss: 0.1757 - val_acc: 0.9165\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9146 - val_loss: 0.1757 - val_acc: 0.9180\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9155 - val_loss: 0.1755 - val_acc: 0.9174\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9153 - val_loss: 0.1755 - val_acc: 0.9174\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17522 to 0.17502, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9160 - val_loss: 0.1750 - val_acc: 0.9172\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9156 - val_loss: 0.1754 - val_acc: 0.9172\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17502 to 0.17491, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9162 - val_loss: 0.1749 - val_acc: 0.9168\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9160 - val_loss: 0.1754 - val_acc: 0.9186\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17491 to 0.17478, saving model to best.model\n",
      "1s - loss: 0.1812 - acc: 0.9171 - val_loss: 0.1748 - val_acc: 0.9182\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "1s - loss: 0.1806 - acc: 0.9171 - val_loss: 0.1748 - val_acc: 0.9165\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17478 to 0.17459, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9162 - val_loss: 0.1746 - val_acc: 0.9174\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17459 to 0.17453, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9158 - val_loss: 0.1745 - val_acc: 0.9180\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9167 - val_loss: 0.1752 - val_acc: 0.9180\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17453 to 0.17431, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9187 - val_loss: 0.1743 - val_acc: 0.9190\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17431 to 0.17410, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9158 - val_loss: 0.1741 - val_acc: 0.9180\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.17410 to 0.17386, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9155 - val_loss: 0.1739 - val_acc: 0.9186\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9175 - val_loss: 0.1740 - val_acc: 0.9182\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9178 - val_loss: 0.1744 - val_acc: 0.9188\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17386 to 0.17382, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9177 - val_loss: 0.1738 - val_acc: 0.9190\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9175 - val_loss: 0.1742 - val_acc: 0.9191\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9178 - val_loss: 0.1753 - val_acc: 0.9178\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9175 - val_loss: 0.1750 - val_acc: 0.9188\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17382 to 0.17381, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9164 - val_loss: 0.1738 - val_acc: 0.9193\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9184 - val_loss: 0.1742 - val_acc: 0.9191\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9181 - val_loss: 0.1743 - val_acc: 0.9191\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17381 to 0.17362, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9177 - val_loss: 0.1736 - val_acc: 0.9195\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9162 - val_loss: 0.1737 - val_acc: 0.9191\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9173 - val_loss: 0.1753 - val_acc: 0.9176\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9168 - val_loss: 0.1747 - val_acc: 0.9167\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17362 to 0.17336, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9181 - val_loss: 0.1734 - val_acc: 0.9186\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9191 - val_loss: 0.1737 - val_acc: 0.9190\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9175 - val_loss: 0.1743 - val_acc: 0.9199\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17336 to 0.17317, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9175 - val_loss: 0.1732 - val_acc: 0.9193\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9181 - val_loss: 0.1734 - val_acc: 0.9197\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9178 - val_loss: 0.1734 - val_acc: 0.9201\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9175 - val_loss: 0.1732 - val_acc: 0.9199\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9175 - val_loss: 0.1735 - val_acc: 0.9203\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9194 - val_loss: 0.1737 - val_acc: 0.9203\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9187 - val_loss: 0.1738 - val_acc: 0.9205\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9192 - val_loss: 0.1735 - val_acc: 0.9197\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9191 - val_loss: 0.1735 - val_acc: 0.9197\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17317 to 0.17274, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9175 - val_loss: 0.1727 - val_acc: 0.9197\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9162 - val_loss: 0.1729 - val_acc: 0.9201\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17274 to 0.17272, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9183 - val_loss: 0.1727 - val_acc: 0.9197\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17272 to 0.17258, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9185 - val_loss: 0.1726 - val_acc: 0.9199\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9180 - val_loss: 0.1748 - val_acc: 0.9207\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9174 - val_loss: 0.1727 - val_acc: 0.9209\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9192 - val_loss: 0.1727 - val_acc: 0.9201\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9196 - val_loss: 0.1728 - val_acc: 0.9207\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.17258 to 0.17225, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9212 - val_loss: 0.1723 - val_acc: 0.9203\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17225 to 0.17191, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9189 - val_loss: 0.1719 - val_acc: 0.9199\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9181 - val_loss: 0.1723 - val_acc: 0.9205\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9192 - val_loss: 0.1726 - val_acc: 0.9199\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9184 - val_loss: 0.1724 - val_acc: 0.9197\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9174 - val_loss: 0.1722 - val_acc: 0.9209\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9197 - val_loss: 0.1723 - val_acc: 0.9207\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9184 - val_loss: 0.1721 - val_acc: 0.9197\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9187 - val_loss: 0.1723 - val_acc: 0.9193\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17191 to 0.17186, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9185 - val_loss: 0.1719 - val_acc: 0.9209\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9194 - val_loss: 0.1720 - val_acc: 0.9199\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9203 - val_loss: 0.1725 - val_acc: 0.9207\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9192 - val_loss: 0.1719 - val_acc: 0.9213\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17186 to 0.17184, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9204 - val_loss: 0.1718 - val_acc: 0.9203\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9189 - val_loss: 0.1721 - val_acc: 0.9205\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17184 to 0.17155, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9188 - val_loss: 0.1715 - val_acc: 0.9211\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.17155 to 0.17111, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9188 - val_loss: 0.1711 - val_acc: 0.9209\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9199 - val_loss: 0.1732 - val_acc: 0.9203\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9194 - val_loss: 0.1722 - val_acc: 0.9213\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "1s - loss: 0.1728 - acc: 0.9204 - val_loss: 0.1719 - val_acc: 0.9203\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9203 - val_loss: 0.1720 - val_acc: 0.9207\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9199 - val_loss: 0.1723 - val_acc: 0.9207\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9202 - val_loss: 0.1718 - val_acc: 0.9216\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9199 - val_loss: 0.1716 - val_acc: 0.9211\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9186 - val_loss: 0.1715 - val_acc: 0.9211\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9199 - val_loss: 0.1716 - val_acc: 0.9205\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9206 - val_loss: 0.1723 - val_acc: 0.9213\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9193 - val_loss: 0.1718 - val_acc: 0.9203\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9187 - val_loss: 0.1720 - val_acc: 0.9216\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9190 - val_loss: 0.1723 - val_acc: 0.9216\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9201 - val_loss: 0.1726 - val_acc: 0.9209\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9203 - val_loss: 0.1722 - val_acc: 0.9215\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9199 - val_loss: 0.1713 - val_acc: 0.9215\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9198 - val_loss: 0.1721 - val_acc: 0.9215\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9199 - val_loss: 0.1720 - val_acc: 0.9201\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9200 - val_loss: 0.1723 - val_acc: 0.9201\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9199 - val_loss: 0.1716 - val_acc: 0.9213\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9204 - val_loss: 0.1716 - val_acc: 0.9209\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9196 - val_loss: 0.1717 - val_acc: 0.9215\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9209 - val_loss: 0.1721 - val_acc: 0.9211\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9214 - val_loss: 0.1716 - val_acc: 0.9201\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9202 - val_loss: 0.1718 - val_acc: 0.9201\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9221 - val_loss: 0.1719 - val_acc: 0.9209\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31401, saving model to best.model\n",
      "0s - loss: 0.3788 - acc: 0.8835 - val_loss: 0.3140 - val_acc: 0.8875\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31401 to 0.24358, saving model to best.model\n",
      "0s - loss: 0.2933 - acc: 0.8934 - val_loss: 0.2436 - val_acc: 0.8996\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24358 to 0.21051, saving model to best.model\n",
      "0s - loss: 0.2443 - acc: 0.9002 - val_loss: 0.2105 - val_acc: 0.9124\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21051 to 0.20036, saving model to best.model\n",
      "0s - loss: 0.2223 - acc: 0.9051 - val_loss: 0.2004 - val_acc: 0.9122\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20036 to 0.19985, saving model to best.model\n",
      "0s - loss: 0.2133 - acc: 0.9051 - val_loss: 0.1999 - val_acc: 0.9095\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19985 to 0.19592, saving model to best.model\n",
      "0s - loss: 0.2087 - acc: 0.9042 - val_loss: 0.1959 - val_acc: 0.9117\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19592 to 0.19523, saving model to best.model\n",
      "0s - loss: 0.2030 - acc: 0.9058 - val_loss: 0.1952 - val_acc: 0.9103\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19523 to 0.19398, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9077 - val_loss: 0.1940 - val_acc: 0.9109\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19398 to 0.19381, saving model to best.model\n",
      "0s - loss: 0.1991 - acc: 0.9072 - val_loss: 0.1938 - val_acc: 0.9118\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19381 to 0.19380, saving model to best.model\n",
      "0s - loss: 0.1960 - acc: 0.9088 - val_loss: 0.1938 - val_acc: 0.9101\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19380 to 0.19355, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9082 - val_loss: 0.1935 - val_acc: 0.9103\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19355 to 0.19324, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9081 - val_loss: 0.1932 - val_acc: 0.9113\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19324 to 0.19259, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9095 - val_loss: 0.1926 - val_acc: 0.9117\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9075 - val_loss: 0.1926 - val_acc: 0.9109\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19259 to 0.19226, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9071 - val_loss: 0.1923 - val_acc: 0.9105\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9111 - val_loss: 0.1923 - val_acc: 0.9113\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9105 - val_loss: 0.1926 - val_acc: 0.9111\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19226 to 0.19175, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9102 - val_loss: 0.1918 - val_acc: 0.9115\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9121 - val_loss: 0.1924 - val_acc: 0.9103\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19175 to 0.19135, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9097 - val_loss: 0.1914 - val_acc: 0.9117\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19135 to 0.19117, saving model to best.model\n",
      "0s - loss: 0.1903 - acc: 0.9102 - val_loss: 0.1912 - val_acc: 0.9118\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19117 to 0.19102, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9104 - val_loss: 0.1910 - val_acc: 0.9115\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19102 to 0.19047, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9107 - val_loss: 0.1905 - val_acc: 0.9113\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19047 to 0.19041, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9120 - val_loss: 0.1904 - val_acc: 0.9107\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9102 - val_loss: 0.1905 - val_acc: 0.9115\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9116 - val_loss: 0.1909 - val_acc: 0.9107\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9114 - val_loss: 0.1904 - val_acc: 0.9113\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19041 to 0.18977, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9120 - val_loss: 0.1898 - val_acc: 0.9101\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18977 to 0.18959, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9122 - val_loss: 0.1896 - val_acc: 0.9097\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18959 to 0.18939, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9120 - val_loss: 0.1894 - val_acc: 0.9118\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18939 to 0.18907, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9126 - val_loss: 0.1891 - val_acc: 0.9130\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18907 to 0.18873, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9119 - val_loss: 0.1887 - val_acc: 0.9101\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18873 to 0.18868, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9119 - val_loss: 0.1887 - val_acc: 0.9097\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18868 to 0.18843, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9138 - val_loss: 0.1884 - val_acc: 0.9092\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18843 to 0.18823, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9125 - val_loss: 0.1882 - val_acc: 0.9095\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18823 to 0.18812, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9115 - val_loss: 0.1881 - val_acc: 0.9101\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9127 - val_loss: 0.1881 - val_acc: 0.9099\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9111 - val_loss: 0.1884 - val_acc: 0.9107\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18812 to 0.18791, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9127 - val_loss: 0.1879 - val_acc: 0.9109\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18791 to 0.18762, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9126 - val_loss: 0.1876 - val_acc: 0.9107\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18762 to 0.18732, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9140 - val_loss: 0.1873 - val_acc: 0.9111\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18732 to 0.18713, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9124 - val_loss: 0.1871 - val_acc: 0.9113\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9130 - val_loss: 0.1875 - val_acc: 0.9103\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18713 to 0.18684, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9138 - val_loss: 0.1868 - val_acc: 0.9115\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9136 - val_loss: 0.1868 - val_acc: 0.9118\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9126 - val_loss: 0.1870 - val_acc: 0.9122\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18684 to 0.18654, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9121 - val_loss: 0.1865 - val_acc: 0.9118\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18654 to 0.18628, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9132 - val_loss: 0.1863 - val_acc: 0.9132\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9135 - val_loss: 0.1868 - val_acc: 0.9128\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18628 to 0.18616, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9138 - val_loss: 0.1862 - val_acc: 0.9122\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9150 - val_loss: 0.1864 - val_acc: 0.9126\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9142 - val_loss: 0.1864 - val_acc: 0.9107\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18616 to 0.18580, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9139 - val_loss: 0.1858 - val_acc: 0.9128\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9146 - val_loss: 0.1861 - val_acc: 0.9124\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9138 - val_loss: 0.1861 - val_acc: 0.9115\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9153 - val_loss: 0.1858 - val_acc: 0.9117\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9154 - val_loss: 0.1870 - val_acc: 0.9101\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18580 to 0.18579, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9152 - val_loss: 0.1858 - val_acc: 0.9118\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18579 to 0.18567, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9140 - val_loss: 0.1857 - val_acc: 0.9130\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9152 - val_loss: 0.1858 - val_acc: 0.9111\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18567 to 0.18548, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9142 - val_loss: 0.1855 - val_acc: 0.9113\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18548 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9161 - val_loss: 0.1851 - val_acc: 0.9117\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18508 to 0.18496, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9158 - val_loss: 0.1850 - val_acc: 0.9117\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9161 - val_loss: 0.1859 - val_acc: 0.9122\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9144 - val_loss: 0.1850 - val_acc: 0.9101\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9147 - val_loss: 0.1850 - val_acc: 0.9115\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.18496 to 0.18448, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9150 - val_loss: 0.1845 - val_acc: 0.9126\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9161 - val_loss: 0.1845 - val_acc: 0.9113\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9142 - val_loss: 0.1846 - val_acc: 0.9115\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18448 to 0.18409, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9156 - val_loss: 0.1841 - val_acc: 0.9136\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18409 to 0.18399, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9170 - val_loss: 0.1840 - val_acc: 0.9130\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9169 - val_loss: 0.1843 - val_acc: 0.9128\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18399 to 0.18395, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9173 - val_loss: 0.1839 - val_acc: 0.9109\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9152 - val_loss: 0.1843 - val_acc: 0.9140\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18395 to 0.18394, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9154 - val_loss: 0.1839 - val_acc: 0.9120\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9157 - val_loss: 0.1840 - val_acc: 0.9118\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18394 to 0.18352, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9153 - val_loss: 0.1835 - val_acc: 0.9136\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9163 - val_loss: 0.1837 - val_acc: 0.9128\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9165 - val_loss: 0.1838 - val_acc: 0.9138\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9153 - val_loss: 0.1836 - val_acc: 0.9138\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18352 to 0.18328, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9158 - val_loss: 0.1833 - val_acc: 0.9122\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9166 - val_loss: 0.1837 - val_acc: 0.9128\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9163 - val_loss: 0.1834 - val_acc: 0.9120\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18328 to 0.18288, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9166 - val_loss: 0.1829 - val_acc: 0.9134\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9180 - val_loss: 0.1833 - val_acc: 0.9128\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9166 - val_loss: 0.1830 - val_acc: 0.9134\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9176 - val_loss: 0.1830 - val_acc: 0.9107\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9168 - val_loss: 0.1830 - val_acc: 0.9105\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18288 to 0.18279, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9173 - val_loss: 0.1828 - val_acc: 0.9113\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.18279 to 0.18257, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9167 - val_loss: 0.1826 - val_acc: 0.9138\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9181 - val_loss: 0.1829 - val_acc: 0.9128\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18257 to 0.18240, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9186 - val_loss: 0.1824 - val_acc: 0.9138\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9161 - val_loss: 0.1824 - val_acc: 0.9132\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.18240 to 0.18204, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9163 - val_loss: 0.1820 - val_acc: 0.9130\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9173 - val_loss: 0.1830 - val_acc: 0.9115\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18204 to 0.18200, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9171 - val_loss: 0.1820 - val_acc: 0.9134\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9191 - val_loss: 0.1827 - val_acc: 0.9136\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9174 - val_loss: 0.1822 - val_acc: 0.9134\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9172 - val_loss: 0.1828 - val_acc: 0.9130\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18200 to 0.18154, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9178 - val_loss: 0.1815 - val_acc: 0.9128\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18154 to 0.18148, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9184 - val_loss: 0.1815 - val_acc: 0.9130\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9189 - val_loss: 0.1826 - val_acc: 0.9134\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18148 to 0.18107, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9176 - val_loss: 0.1811 - val_acc: 0.9128\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9174 - val_loss: 0.1822 - val_acc: 0.9128\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9194 - val_loss: 0.1811 - val_acc: 0.9138\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9188 - val_loss: 0.1812 - val_acc: 0.9134\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.18107 to 0.18105, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9166 - val_loss: 0.1810 - val_acc: 0.9142\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9187 - val_loss: 0.1812 - val_acc: 0.9128\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9177 - val_loss: 0.1811 - val_acc: 0.9134\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18105 to 0.18050, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9185 - val_loss: 0.1805 - val_acc: 0.9130\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9174 - val_loss: 0.1807 - val_acc: 0.9136\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9173 - val_loss: 0.1808 - val_acc: 0.9130\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9194 - val_loss: 0.1808 - val_acc: 0.9136\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9186 - val_loss: 0.1812 - val_acc: 0.9130\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.18050 to 0.18045, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9179 - val_loss: 0.1804 - val_acc: 0.9142\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9195 - val_loss: 0.1806 - val_acc: 0.9138\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9191 - val_loss: 0.1805 - val_acc: 0.9140\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9180 - val_loss: 0.1805 - val_acc: 0.9140\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9198 - val_loss: 0.1820 - val_acc: 0.9136\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.18045 to 0.18011, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9194 - val_loss: 0.1801 - val_acc: 0.9140\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9187 - val_loss: 0.1804 - val_acc: 0.9140\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9202 - val_loss: 0.1802 - val_acc: 0.9138\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.18011 to 0.18003, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9175 - val_loss: 0.1800 - val_acc: 0.9143\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9187 - val_loss: 0.1803 - val_acc: 0.9145\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9188 - val_loss: 0.1807 - val_acc: 0.9142\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.18003 to 0.17983, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9189 - val_loss: 0.1798 - val_acc: 0.9149\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.17983 to 0.17977, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9191 - val_loss: 0.1798 - val_acc: 0.9147\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17977 to 0.17951, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9194 - val_loss: 0.1795 - val_acc: 0.9143\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9186 - val_loss: 0.1796 - val_acc: 0.9145\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9193 - val_loss: 0.1797 - val_acc: 0.9149\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9192 - val_loss: 0.1804 - val_acc: 0.9145\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17951 to 0.17937, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9187 - val_loss: 0.1794 - val_acc: 0.9145\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9184 - val_loss: 0.1794 - val_acc: 0.9142\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17937 to 0.17925, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9187 - val_loss: 0.1792 - val_acc: 0.9140\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9199 - val_loss: 0.1794 - val_acc: 0.9138\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17925 to 0.17915, saving model to best.model\n",
      "0s - loss: 0.1707 - acc: 0.9209 - val_loss: 0.1792 - val_acc: 0.9142\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17915 to 0.17903, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9208 - val_loss: 0.1790 - val_acc: 0.9143\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9187 - val_loss: 0.1792 - val_acc: 0.9142\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17903 to 0.17902, saving model to best.model\n",
      "0s - loss: 0.1706 - acc: 0.9190 - val_loss: 0.1790 - val_acc: 0.9147\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9197 - val_loss: 0.1799 - val_acc: 0.9151\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17902 to 0.17898, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9196 - val_loss: 0.1790 - val_acc: 0.9149\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9201 - val_loss: 0.1796 - val_acc: 0.9151\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17898 to 0.17878, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9204 - val_loss: 0.1788 - val_acc: 0.9147\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17878 to 0.17865, saving model to best.model\n",
      "0s - loss: 0.1694 - acc: 0.9212 - val_loss: 0.1787 - val_acc: 0.9149\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9192 - val_loss: 0.1797 - val_acc: 0.9153\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9194 - val_loss: 0.1788 - val_acc: 0.9147\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17865 to 0.17857, saving model to best.model\n",
      "1s - loss: 0.1709 - acc: 0.9194 - val_loss: 0.1786 - val_acc: 0.9161\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9209 - val_loss: 0.1790 - val_acc: 0.9151\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17857 to 0.17798, saving model to best.model\n",
      "0s - loss: 0.1700 - acc: 0.9186 - val_loss: 0.1780 - val_acc: 0.9149\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "1s - loss: 0.1687 - acc: 0.9200 - val_loss: 0.1780 - val_acc: 0.9151\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9206 - val_loss: 0.1783 - val_acc: 0.9153\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9194 - val_loss: 0.1783 - val_acc: 0.9149\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17798 to 0.17793, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9208 - val_loss: 0.1779 - val_acc: 0.9155\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17793 to 0.17788, saving model to best.model\n",
      "1s - loss: 0.1688 - acc: 0.9200 - val_loss: 0.1779 - val_acc: 0.9153\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9194 - val_loss: 0.1783 - val_acc: 0.9159\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17788 to 0.17769, saving model to best.model\n",
      "1s - loss: 0.1680 - acc: 0.9204 - val_loss: 0.1777 - val_acc: 0.9145\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17769 to 0.17751, saving model to best.model\n",
      "0s - loss: 0.1693 - acc: 0.9193 - val_loss: 0.1775 - val_acc: 0.9145\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9201 - val_loss: 0.1776 - val_acc: 0.9155\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17751 to 0.17739, saving model to best.model\n",
      "0s - loss: 0.1685 - acc: 0.9198 - val_loss: 0.1774 - val_acc: 0.9153\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9211 - val_loss: 0.1784 - val_acc: 0.9157\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9224 - val_loss: 0.1775 - val_acc: 0.9151\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9210 - val_loss: 0.1779 - val_acc: 0.9147\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9206 - val_loss: 0.1779 - val_acc: 0.9153\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9203 - val_loss: 0.1774 - val_acc: 0.9161\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9198 - val_loss: 0.1777 - val_acc: 0.9143\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9195 - val_loss: 0.1774 - val_acc: 0.9155\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17739 to 0.17699, saving model to best.model\n",
      "1s - loss: 0.1681 - acc: 0.9208 - val_loss: 0.1770 - val_acc: 0.9155\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9203 - val_loss: 0.1773 - val_acc: 0.9149\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "1s - loss: 0.1675 - acc: 0.9198 - val_loss: 0.1781 - val_acc: 0.9151\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "1s - loss: 0.1674 - acc: 0.9194 - val_loss: 0.1771 - val_acc: 0.9159\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17699 to 0.17686, saving model to best.model\n",
      "0s - loss: 0.1658 - acc: 0.9201 - val_loss: 0.1769 - val_acc: 0.9159\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.17686 to 0.17671, saving model to best.model\n",
      "1s - loss: 0.1667 - acc: 0.9204 - val_loss: 0.1767 - val_acc: 0.9167\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9195 - val_loss: 0.1770 - val_acc: 0.9155\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9208 - val_loss: 0.1767 - val_acc: 0.9155\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9214 - val_loss: 0.1770 - val_acc: 0.9153\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17671 to 0.17647, saving model to best.model\n",
      "0s - loss: 0.1668 - acc: 0.9211 - val_loss: 0.1765 - val_acc: 0.9151\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.17647 to 0.17636, saving model to best.model\n",
      "0s - loss: 0.1672 - acc: 0.9211 - val_loss: 0.1764 - val_acc: 0.9155\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.17636 to 0.17634, saving model to best.model\n",
      "0s - loss: 0.1669 - acc: 0.9205 - val_loss: 0.1763 - val_acc: 0.9161\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1655 - acc: 0.9206 - val_loss: 0.1765 - val_acc: 0.9153\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1652 - acc: 0.9221 - val_loss: 0.1765 - val_acc: 0.9157\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.17634 to 0.17611, saving model to best.model\n",
      "0s - loss: 0.1666 - acc: 0.9210 - val_loss: 0.1761 - val_acc: 0.9163\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9215 - val_loss: 0.1764 - val_acc: 0.9161\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9214 - val_loss: 0.1764 - val_acc: 0.9161\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.17611 to 0.17598, saving model to best.model\n",
      "0s - loss: 0.1655 - acc: 0.9204 - val_loss: 0.1760 - val_acc: 0.9155\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9204 - val_loss: 0.1767 - val_acc: 0.9163\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.17598 to 0.17578, saving model to best.model\n",
      "0s - loss: 0.1662 - acc: 0.9213 - val_loss: 0.1758 - val_acc: 0.9155\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9220 - val_loss: 0.1762 - val_acc: 0.9159\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1664 - acc: 0.9219 - val_loss: 0.1760 - val_acc: 0.9163\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9202 - val_loss: 0.1761 - val_acc: 0.9163\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.17578 to 0.17558, saving model to best.model\n",
      "0s - loss: 0.1669 - acc: 0.9205 - val_loss: 0.1756 - val_acc: 0.9168\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1656 - acc: 0.9218 - val_loss: 0.1756 - val_acc: 0.9159\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1652 - acc: 0.9218 - val_loss: 0.1756 - val_acc: 0.9170\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1638 - acc: 0.9233 - val_loss: 0.1761 - val_acc: 0.9145\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1661 - acc: 0.9210 - val_loss: 0.1761 - val_acc: 0.9163\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.17558 to 0.17521, saving model to best.model\n",
      "0s - loss: 0.1648 - acc: 0.9227 - val_loss: 0.1752 - val_acc: 0.9167\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9188 - val_loss: 0.1760 - val_acc: 0.9161\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9230 - val_loss: 0.1754 - val_acc: 0.9161\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9225 - val_loss: 0.1754 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1626 - acc: 0.9222 - val_loss: 0.1762 - val_acc: 0.9159\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1640 - acc: 0.9220 - val_loss: 0.1754 - val_acc: 0.9143\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33389, saving model to best.model\n",
      "0s - loss: 0.4644 - acc: 0.8409 - val_loss: 0.3339 - val_acc: 0.8878\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33389 to 0.27290, saving model to best.model\n",
      "0s - loss: 0.3520 - acc: 0.8803 - val_loss: 0.2729 - val_acc: 0.8878\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27290 to 0.22055, saving model to best.model\n",
      "0s - loss: 0.2880 - acc: 0.8893 - val_loss: 0.2206 - val_acc: 0.9044\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22055 to 0.19622, saving model to best.model\n",
      "0s - loss: 0.2466 - acc: 0.8959 - val_loss: 0.1962 - val_acc: 0.9120\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19622 to 0.19049, saving model to best.model\n",
      "0s - loss: 0.2329 - acc: 0.8965 - val_loss: 0.1905 - val_acc: 0.9124\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19049 to 0.18711, saving model to best.model\n",
      "0s - loss: 0.2234 - acc: 0.8977 - val_loss: 0.1871 - val_acc: 0.9155\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18711 to 0.18539, saving model to best.model\n",
      "0s - loss: 0.2190 - acc: 0.8993 - val_loss: 0.1854 - val_acc: 0.9155\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18539 to 0.18458, saving model to best.model\n",
      "0s - loss: 0.2145 - acc: 0.8999 - val_loss: 0.1846 - val_acc: 0.9163\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18458 to 0.18332, saving model to best.model\n",
      "0s - loss: 0.2102 - acc: 0.9035 - val_loss: 0.1833 - val_acc: 0.9170\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18332 to 0.18310, saving model to best.model\n",
      "0s - loss: 0.2097 - acc: 0.8993 - val_loss: 0.1831 - val_acc: 0.9168\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2085 - acc: 0.9031 - val_loss: 0.1832 - val_acc: 0.9159\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18310 to 0.18257, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9041 - val_loss: 0.1826 - val_acc: 0.9161\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2054 - acc: 0.9030 - val_loss: 0.1831 - val_acc: 0.9178\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2066 - acc: 0.9036 - val_loss: 0.1830 - val_acc: 0.9176\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2030 - acc: 0.9045 - val_loss: 0.1843 - val_acc: 0.9167\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2013 - acc: 0.9048 - val_loss: 0.1827 - val_acc: 0.9163\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18257 to 0.18252, saving model to best.model\n",
      "0s - loss: 0.2056 - acc: 0.9027 - val_loss: 0.1825 - val_acc: 0.9159\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18252 to 0.18235, saving model to best.model\n",
      "0s - loss: 0.2014 - acc: 0.9034 - val_loss: 0.1824 - val_acc: 0.9176\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18235 to 0.18205, saving model to best.model\n",
      "0s - loss: 0.2010 - acc: 0.9051 - val_loss: 0.1820 - val_acc: 0.9172\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2012 - acc: 0.9031 - val_loss: 0.1821 - val_acc: 0.9159\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "1s - loss: 0.1993 - acc: 0.9036 - val_loss: 0.1822 - val_acc: 0.9174\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2001 - acc: 0.9050 - val_loss: 0.1821 - val_acc: 0.9167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18205 to 0.18139, saving model to best.model\n",
      "1s - loss: 0.1980 - acc: 0.9050 - val_loss: 0.1814 - val_acc: 0.9157\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9033 - val_loss: 0.1818 - val_acc: 0.9172\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9069 - val_loss: 0.1817 - val_acc: 0.9165\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1989 - acc: 0.9049 - val_loss: 0.1815 - val_acc: 0.9151\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18139 to 0.18064, saving model to best.model\n",
      "0s - loss: 0.1985 - acc: 0.9050 - val_loss: 0.1806 - val_acc: 0.9168\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9057 - val_loss: 0.1810 - val_acc: 0.9159\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1981 - acc: 0.9060 - val_loss: 0.1808 - val_acc: 0.9174\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18064 to 0.18020, saving model to best.model\n",
      "1s - loss: 0.1976 - acc: 0.9054 - val_loss: 0.1802 - val_acc: 0.9161\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18020 to 0.17991, saving model to best.model\n",
      "0s - loss: 0.1958 - acc: 0.9076 - val_loss: 0.1799 - val_acc: 0.9157\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1961 - acc: 0.9064 - val_loss: 0.1828 - val_acc: 0.9155\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17991 to 0.17949, saving model to best.model\n",
      "0s - loss: 0.1958 - acc: 0.9088 - val_loss: 0.1795 - val_acc: 0.9184\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1950 - acc: 0.9074 - val_loss: 0.1806 - val_acc: 0.9161\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17949 to 0.17905, saving model to best.model\n",
      "0s - loss: 0.1955 - acc: 0.9074 - val_loss: 0.1790 - val_acc: 0.9174\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9076 - val_loss: 0.1795 - val_acc: 0.9174\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1954 - acc: 0.9080 - val_loss: 0.1794 - val_acc: 0.9172\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "1s - loss: 0.1950 - acc: 0.9058 - val_loss: 0.1791 - val_acc: 0.9167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9096 - val_loss: 0.1794 - val_acc: 0.9165\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17905 to 0.17854, saving model to best.model\n",
      "0s - loss: 0.1941 - acc: 0.9081 - val_loss: 0.1785 - val_acc: 0.9170\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17854 to 0.17820, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9090 - val_loss: 0.1782 - val_acc: 0.9165\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17820 to 0.17804, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9086 - val_loss: 0.1780 - val_acc: 0.9178\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9084 - val_loss: 0.1784 - val_acc: 0.9178\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9075 - val_loss: 0.1781 - val_acc: 0.9172\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9073 - val_loss: 0.1791 - val_acc: 0.9174\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9096 - val_loss: 0.1782 - val_acc: 0.9168\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.17804 to 0.17763, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9100 - val_loss: 0.1776 - val_acc: 0.9184\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17763 to 0.17739, saving model to best.model\n",
      "0s - loss: 0.1910 - acc: 0.9085 - val_loss: 0.1774 - val_acc: 0.9180\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17739 to 0.17732, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9111 - val_loss: 0.1773 - val_acc: 0.9168\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9090 - val_loss: 0.1779 - val_acc: 0.9157\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9095 - val_loss: 0.1778 - val_acc: 0.9161\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9110 - val_loss: 0.1781 - val_acc: 0.9151\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17732 to 0.17701, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9092 - val_loss: 0.1770 - val_acc: 0.9168\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9111 - val_loss: 0.1773 - val_acc: 0.9172\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9077 - val_loss: 0.1775 - val_acc: 0.9172\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.17701 to 0.17677, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9090 - val_loss: 0.1768 - val_acc: 0.9165\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9126 - val_loss: 0.1768 - val_acc: 0.9168\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17677 to 0.17637, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9106 - val_loss: 0.1764 - val_acc: 0.9170\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.17637 to 0.17596, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9123 - val_loss: 0.1760 - val_acc: 0.9168\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9112 - val_loss: 0.1763 - val_acc: 0.9165\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9090 - val_loss: 0.1762 - val_acc: 0.9165\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9106 - val_loss: 0.1769 - val_acc: 0.9159\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17596 to 0.17577, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9098 - val_loss: 0.1758 - val_acc: 0.9170\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17577 to 0.17540, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9121 - val_loss: 0.1754 - val_acc: 0.9167\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9127 - val_loss: 0.1762 - val_acc: 0.9168\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9100 - val_loss: 0.1767 - val_acc: 0.9165\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9111 - val_loss: 0.1756 - val_acc: 0.9170\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9110 - val_loss: 0.1769 - val_acc: 0.9157\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9114 - val_loss: 0.1756 - val_acc: 0.9170\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9123 - val_loss: 0.1756 - val_acc: 0.9167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9118 - val_loss: 0.1761 - val_acc: 0.9165\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9121 - val_loss: 0.1757 - val_acc: 0.9161\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.17540 to 0.17484, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9117 - val_loss: 0.1748 - val_acc: 0.9163\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9114 - val_loss: 0.1761 - val_acc: 0.9159\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9107 - val_loss: 0.1749 - val_acc: 0.9161\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9136 - val_loss: 0.1758 - val_acc: 0.9170\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9112 - val_loss: 0.1750 - val_acc: 0.9167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17484 to 0.17466, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9121 - val_loss: 0.1747 - val_acc: 0.9174\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17466 to 0.17424, saving model to best.model\n",
      "0s - loss: 0.1869 - acc: 0.9119 - val_loss: 0.1742 - val_acc: 0.9165\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9121 - val_loss: 0.1763 - val_acc: 0.9161\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9123 - val_loss: 0.1750 - val_acc: 0.9170\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.17424 to 0.17415, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9124 - val_loss: 0.1742 - val_acc: 0.9168\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.17415 to 0.17407, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9121 - val_loss: 0.1741 - val_acc: 0.9167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9123 - val_loss: 0.1745 - val_acc: 0.9170\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9117 - val_loss: 0.1749 - val_acc: 0.9161\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17407 to 0.17382, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9128 - val_loss: 0.1738 - val_acc: 0.9172\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9125 - val_loss: 0.1744 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "1s - loss: 0.1850 - acc: 0.9157 - val_loss: 0.1743 - val_acc: 0.9168\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "1s - loss: 0.1858 - acc: 0.9147 - val_loss: 0.1747 - val_acc: 0.9163\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "1s - loss: 0.1869 - acc: 0.9127 - val_loss: 0.1743 - val_acc: 0.9167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17382 to 0.17366, saving model to best.model\n",
      "1s - loss: 0.1840 - acc: 0.9127 - val_loss: 0.1737 - val_acc: 0.9165\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9141 - val_loss: 0.1738 - val_acc: 0.9174\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9131 - val_loss: 0.1744 - val_acc: 0.9168\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17366 to 0.17336, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9152 - val_loss: 0.1734 - val_acc: 0.9172\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9139 - val_loss: 0.1734 - val_acc: 0.9176\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9130 - val_loss: 0.1737 - val_acc: 0.9180\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9118 - val_loss: 0.1746 - val_acc: 0.9176\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9141 - val_loss: 0.1735 - val_acc: 0.9165\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17336 to 0.17285, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9152 - val_loss: 0.1729 - val_acc: 0.9178\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9143 - val_loss: 0.1731 - val_acc: 0.9172\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9128 - val_loss: 0.1729 - val_acc: 0.9178\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9148 - val_loss: 0.1731 - val_acc: 0.9180\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9115 - val_loss: 0.1736 - val_acc: 0.9178\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9139 - val_loss: 0.1734 - val_acc: 0.9176\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9134 - val_loss: 0.1730 - val_acc: 0.9182\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17285 to 0.17264, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9141 - val_loss: 0.1726 - val_acc: 0.9184\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17264 to 0.17255, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9147 - val_loss: 0.1725 - val_acc: 0.9174\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17255 to 0.17236, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9155 - val_loss: 0.1724 - val_acc: 0.9182\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9149 - val_loss: 0.1729 - val_acc: 0.9178\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9143 - val_loss: 0.1727 - val_acc: 0.9176\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9149 - val_loss: 0.1726 - val_acc: 0.9172\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9136 - val_loss: 0.1724 - val_acc: 0.9172\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9129 - val_loss: 0.1724 - val_acc: 0.9180\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9150 - val_loss: 0.1726 - val_acc: 0.9180\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9154 - val_loss: 0.1731 - val_acc: 0.9170\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9145 - val_loss: 0.1725 - val_acc: 0.9193\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9161 - val_loss: 0.1725 - val_acc: 0.9178\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9140 - val_loss: 0.1724 - val_acc: 0.9176\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17236 to 0.17225, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9141 - val_loss: 0.1723 - val_acc: 0.9178\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.17225 to 0.17219, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9144 - val_loss: 0.1722 - val_acc: 0.9184\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17219 to 0.17182, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9157 - val_loss: 0.1718 - val_acc: 0.9174\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9157 - val_loss: 0.1718 - val_acc: 0.9184\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9145 - val_loss: 0.1721 - val_acc: 0.9170\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17182 to 0.17175, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9151 - val_loss: 0.1717 - val_acc: 0.9182\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9149 - val_loss: 0.1724 - val_acc: 0.9203\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9144 - val_loss: 0.1722 - val_acc: 0.9178\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9150 - val_loss: 0.1722 - val_acc: 0.9207\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9167 - val_loss: 0.1718 - val_acc: 0.9201\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9150 - val_loss: 0.1721 - val_acc: 0.9176\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9163 - val_loss: 0.1719 - val_acc: 0.9186\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9171 - val_loss: 0.1722 - val_acc: 0.9190\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9153 - val_loss: 0.1719 - val_acc: 0.9188\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17175 to 0.17163, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9148 - val_loss: 0.1716 - val_acc: 0.9209\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17163 to 0.17103, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9167 - val_loss: 0.1710 - val_acc: 0.9186\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9162 - val_loss: 0.1711 - val_acc: 0.9197\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9172 - val_loss: 0.1723 - val_acc: 0.9207\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9166 - val_loss: 0.1718 - val_acc: 0.9184\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9186 - val_loss: 0.1722 - val_acc: 0.9180\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9160 - val_loss: 0.1712 - val_acc: 0.9203\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9156 - val_loss: 0.1715 - val_acc: 0.9182\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17103 to 0.17074, saving model to best.model\n",
      "1s - loss: 0.1788 - acc: 0.9173 - val_loss: 0.1707 - val_acc: 0.9193\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9172 - val_loss: 0.1712 - val_acc: 0.9201\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9180 - val_loss: 0.1715 - val_acc: 0.9174\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9159 - val_loss: 0.1712 - val_acc: 0.9209\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9165 - val_loss: 0.1713 - val_acc: 0.9174\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17074 to 0.17045, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9158 - val_loss: 0.1704 - val_acc: 0.9197\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9164 - val_loss: 0.1710 - val_acc: 0.9199\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9161 - val_loss: 0.1713 - val_acc: 0.9193\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9166 - val_loss: 0.1708 - val_acc: 0.9180\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9156 - val_loss: 0.1706 - val_acc: 0.9211\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9182 - val_loss: 0.1707 - val_acc: 0.9176\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9166 - val_loss: 0.1705 - val_acc: 0.9182\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17045 to 0.17035, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9168 - val_loss: 0.1703 - val_acc: 0.9178\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9166 - val_loss: 0.1707 - val_acc: 0.9203\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.17035 to 0.17021, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9180 - val_loss: 0.1702 - val_acc: 0.9209\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9179 - val_loss: 0.1706 - val_acc: 0.9205\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9178 - val_loss: 0.1703 - val_acc: 0.9224\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9170 - val_loss: 0.1703 - val_acc: 0.9222\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9157 - val_loss: 0.1702 - val_acc: 0.9209\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17021 to 0.16973, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9195 - val_loss: 0.1697 - val_acc: 0.9218\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9169 - val_loss: 0.1699 - val_acc: 0.9205\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.16973 to 0.16971, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9178 - val_loss: 0.1697 - val_acc: 0.9205\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9176 - val_loss: 0.1699 - val_acc: 0.9203\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9180 - val_loss: 0.1702 - val_acc: 0.9222\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.16971 to 0.16960, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9178 - val_loss: 0.1696 - val_acc: 0.9203\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9175 - val_loss: 0.1697 - val_acc: 0.9184\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9185 - val_loss: 0.1698 - val_acc: 0.9218\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9169 - val_loss: 0.1702 - val_acc: 0.9195\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9176 - val_loss: 0.1698 - val_acc: 0.9209\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.16960 to 0.16920, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9177 - val_loss: 0.1692 - val_acc: 0.9215\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9194 - val_loss: 0.1695 - val_acc: 0.9205\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9170 - val_loss: 0.1697 - val_acc: 0.9205\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9172 - val_loss: 0.1697 - val_acc: 0.9216\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9163 - val_loss: 0.1706 - val_acc: 0.9226\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.16920 to 0.16907, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9175 - val_loss: 0.1691 - val_acc: 0.9201\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9178 - val_loss: 0.1694 - val_acc: 0.9213\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9185 - val_loss: 0.1696 - val_acc: 0.9207\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9181 - val_loss: 0.1692 - val_acc: 0.9232\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9182 - val_loss: 0.1691 - val_acc: 0.9209\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.16907 to 0.16893, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9183 - val_loss: 0.1689 - val_acc: 0.9209\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9188 - val_loss: 0.1693 - val_acc: 0.9207\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9184 - val_loss: 0.1691 - val_acc: 0.9205\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.16893 to 0.16880, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9201 - val_loss: 0.1688 - val_acc: 0.9207\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9193 - val_loss: 0.1702 - val_acc: 0.9226\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9183 - val_loss: 0.1700 - val_acc: 0.9203\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9169 - val_loss: 0.1690 - val_acc: 0.9184\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9179 - val_loss: 0.1695 - val_acc: 0.9228\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9167 - val_loss: 0.1694 - val_acc: 0.9205\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.16880 to 0.16869, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9196 - val_loss: 0.1687 - val_acc: 0.9209\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.16869 to 0.16803, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9178 - val_loss: 0.1680 - val_acc: 0.9201\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9182 - val_loss: 0.1685 - val_acc: 0.9191\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "1s - loss: 0.1752 - acc: 0.9175 - val_loss: 0.1688 - val_acc: 0.9220\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9199 - val_loss: 0.1687 - val_acc: 0.9191\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9193 - val_loss: 0.1688 - val_acc: 0.9215\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9190 - val_loss: 0.1684 - val_acc: 0.9224\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9173 - val_loss: 0.1685 - val_acc: 0.9193\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9178 - val_loss: 0.1692 - val_acc: 0.9222\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9189 - val_loss: 0.1683 - val_acc: 0.9197\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9194 - val_loss: 0.1683 - val_acc: 0.9193\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.16803 to 0.16792, saving model to best.model\n",
      "0s - loss: 0.1705 - acc: 0.9200 - val_loss: 0.1679 - val_acc: 0.9220\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33654, saving model to best.model\n",
      "0s - loss: 0.3979 - acc: 0.8752 - val_loss: 0.3365 - val_acc: 0.8884\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33654 to 0.25886, saving model to best.model\n",
      "0s - loss: 0.3262 - acc: 0.8913 - val_loss: 0.2589 - val_acc: 0.8884\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25886 to 0.20864, saving model to best.model\n",
      "0s - loss: 0.2623 - acc: 0.8956 - val_loss: 0.2086 - val_acc: 0.9069\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20864 to 0.19335, saving model to best.model\n",
      "0s - loss: 0.2319 - acc: 0.9025 - val_loss: 0.1933 - val_acc: 0.9134\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19335 to 0.18819, saving model to best.model\n",
      "0s - loss: 0.2205 - acc: 0.9044 - val_loss: 0.1882 - val_acc: 0.9145\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18819 to 0.18722, saving model to best.model\n",
      "0s - loss: 0.2129 - acc: 0.9037 - val_loss: 0.1872 - val_acc: 0.9161\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18722 to 0.18649, saving model to best.model\n",
      "0s - loss: 0.2084 - acc: 0.9056 - val_loss: 0.1865 - val_acc: 0.9161\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2059 - acc: 0.9063 - val_loss: 0.1870 - val_acc: 0.9143\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18649 to 0.18479, saving model to best.model\n",
      "0s - loss: 0.2051 - acc: 0.9068 - val_loss: 0.1848 - val_acc: 0.9147\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2019 - acc: 0.9066 - val_loss: 0.1861 - val_acc: 0.9157\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2020 - acc: 0.9056 - val_loss: 0.1849 - val_acc: 0.9157\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1993 - acc: 0.9074 - val_loss: 0.1863 - val_acc: 0.9163\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18479 to 0.18460, saving model to best.model\n",
      "0s - loss: 0.1988 - acc: 0.9088 - val_loss: 0.1846 - val_acc: 0.9147\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1998 - acc: 0.9057 - val_loss: 0.1847 - val_acc: 0.9159\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1990 - acc: 0.9076 - val_loss: 0.1847 - val_acc: 0.9153\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9060 - val_loss: 0.1848 - val_acc: 0.9134\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18460 to 0.18444, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9095 - val_loss: 0.1844 - val_acc: 0.9165\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18444 to 0.18433, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9076 - val_loss: 0.1843 - val_acc: 0.9159\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18433 to 0.18420, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9089 - val_loss: 0.1842 - val_acc: 0.9147\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18420 to 0.18410, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9098 - val_loss: 0.1841 - val_acc: 0.9168\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18410 to 0.18408, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9100 - val_loss: 0.1841 - val_acc: 0.9140\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18408 to 0.18394, saving model to best.model\n",
      "0s - loss: 0.1954 - acc: 0.9097 - val_loss: 0.1839 - val_acc: 0.9157\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1943 - acc: 0.9080 - val_loss: 0.1852 - val_acc: 0.9161\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18394 to 0.18295, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9099 - val_loss: 0.1829 - val_acc: 0.9142\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1952 - acc: 0.9093 - val_loss: 0.1835 - val_acc: 0.9159\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9076 - val_loss: 0.1831 - val_acc: 0.9167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9090 - val_loss: 0.1836 - val_acc: 0.9172\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9084 - val_loss: 0.1831 - val_acc: 0.9165\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18295 to 0.18241, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9102 - val_loss: 0.1824 - val_acc: 0.9161\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18241 to 0.18227, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9092 - val_loss: 0.1823 - val_acc: 0.9151\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9106 - val_loss: 0.1830 - val_acc: 0.9159\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18227 to 0.18226, saving model to best.model\n",
      "1s - loss: 0.1937 - acc: 0.9107 - val_loss: 0.1823 - val_acc: 0.9165\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18226 to 0.18204, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9088 - val_loss: 0.1820 - val_acc: 0.9159\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "1s - loss: 0.1897 - acc: 0.9119 - val_loss: 0.1822 - val_acc: 0.9163\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18204 to 0.18144, saving model to best.model\n",
      "1s - loss: 0.1916 - acc: 0.9096 - val_loss: 0.1814 - val_acc: 0.9159\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9121 - val_loss: 0.1817 - val_acc: 0.9163\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9106 - val_loss: 0.1821 - val_acc: 0.9167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9104 - val_loss: 0.1816 - val_acc: 0.9161\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1909 - acc: 0.9102 - val_loss: 0.1819 - val_acc: 0.9167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9100 - val_loss: 0.1839 - val_acc: 0.9165\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18144 to 0.18123, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9115 - val_loss: 0.1812 - val_acc: 0.9149\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18123 to 0.18093, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9125 - val_loss: 0.1809 - val_acc: 0.9138\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18093 to 0.18051, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9112 - val_loss: 0.1805 - val_acc: 0.9149\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9093 - val_loss: 0.1814 - val_acc: 0.9147\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18051 to 0.18017, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9104 - val_loss: 0.1802 - val_acc: 0.9157\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9127 - val_loss: 0.1804 - val_acc: 0.9149\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9107 - val_loss: 0.1806 - val_acc: 0.9151\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18017 to 0.17989, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9118 - val_loss: 0.1799 - val_acc: 0.9155\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9128 - val_loss: 0.1807 - val_acc: 0.9157\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "1s - loss: 0.1879 - acc: 0.9114 - val_loss: 0.1799 - val_acc: 0.9159\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17989 to 0.17981, saving model to best.model\n",
      "1s - loss: 0.1878 - acc: 0.9128 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "1s - loss: 0.1878 - acc: 0.9123 - val_loss: 0.1808 - val_acc: 0.9165\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9116 - val_loss: 0.1798 - val_acc: 0.9159\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9122 - val_loss: 0.1800 - val_acc: 0.9151\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9124 - val_loss: 0.1800 - val_acc: 0.9155\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.17981 to 0.17970, saving model to best.model\n",
      "0s - loss: 0.1869 - acc: 0.9126 - val_loss: 0.1797 - val_acc: 0.9155\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.17970 to 0.17961, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9128 - val_loss: 0.1796 - val_acc: 0.9157\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17961 to 0.17945, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9153 - val_loss: 0.1794 - val_acc: 0.9153\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1872 - acc: 0.9138 - val_loss: 0.1796 - val_acc: 0.9167\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.17945 to 0.17941, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9130 - val_loss: 0.1794 - val_acc: 0.9157\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17941 to 0.17910, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9126 - val_loss: 0.1791 - val_acc: 0.9149\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9128 - val_loss: 0.1794 - val_acc: 0.9149\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9122 - val_loss: 0.1801 - val_acc: 0.9161\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17910 to 0.17883, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9127 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9134 - val_loss: 0.1789 - val_acc: 0.9157\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9126 - val_loss: 0.1792 - val_acc: 0.9167\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9120 - val_loss: 0.1789 - val_acc: 0.9168\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9130 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17883 to 0.17825, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9120 - val_loss: 0.1782 - val_acc: 0.9157\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9124 - val_loss: 0.1786 - val_acc: 0.9163\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9134 - val_loss: 0.1784 - val_acc: 0.9155\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9122 - val_loss: 0.1791 - val_acc: 0.9155\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.17825 to 0.17821, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9139 - val_loss: 0.1782 - val_acc: 0.9167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17821 to 0.17791, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9145 - val_loss: 0.1779 - val_acc: 0.9167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17791 to 0.17762, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9126 - val_loss: 0.1776 - val_acc: 0.9161\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9143 - val_loss: 0.1776 - val_acc: 0.9170\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9127 - val_loss: 0.1783 - val_acc: 0.9168\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9126 - val_loss: 0.1778 - val_acc: 0.9180\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9132 - val_loss: 0.1781 - val_acc: 0.9167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9132 - val_loss: 0.1776 - val_acc: 0.9172\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17762 to 0.17721, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9135 - val_loss: 0.1772 - val_acc: 0.9157\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9138 - val_loss: 0.1784 - val_acc: 0.9153\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9137 - val_loss: 0.1782 - val_acc: 0.9157\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9142 - val_loss: 0.1772 - val_acc: 0.9157\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9147 - val_loss: 0.1775 - val_acc: 0.9167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17721 to 0.17701, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9153 - val_loss: 0.1770 - val_acc: 0.9157\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9150 - val_loss: 0.1778 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17701 to 0.17678, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9133 - val_loss: 0.1768 - val_acc: 0.9163\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17678 to 0.17664, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9148 - val_loss: 0.1766 - val_acc: 0.9161\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1830 - acc: 0.9144 - val_loss: 0.1769 - val_acc: 0.9167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9150 - val_loss: 0.1768 - val_acc: 0.9174\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9148 - val_loss: 0.1775 - val_acc: 0.9157\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9144 - val_loss: 0.1769 - val_acc: 0.9165\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9145 - val_loss: 0.1768 - val_acc: 0.9170\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17664 to 0.17623, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9146 - val_loss: 0.1762 - val_acc: 0.9163\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17623 to 0.17619, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9156 - val_loss: 0.1762 - val_acc: 0.9163\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17619 to 0.17614, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9140 - val_loss: 0.1761 - val_acc: 0.9159\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17614 to 0.17593, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9150 - val_loss: 0.1759 - val_acc: 0.9170\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9128 - val_loss: 0.1760 - val_acc: 0.9168\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17593 to 0.17569, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9156 - val_loss: 0.1757 - val_acc: 0.9167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9141 - val_loss: 0.1758 - val_acc: 0.9159\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9151 - val_loss: 0.1762 - val_acc: 0.9165\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9152 - val_loss: 0.1758 - val_acc: 0.9157\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17569 to 0.17512, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9147 - val_loss: 0.1751 - val_acc: 0.9174\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9146 - val_loss: 0.1753 - val_acc: 0.9157\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9149 - val_loss: 0.1752 - val_acc: 0.9165\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9145 - val_loss: 0.1753 - val_acc: 0.9168\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17512 to 0.17508, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9148 - val_loss: 0.1751 - val_acc: 0.9184\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9154 - val_loss: 0.1755 - val_acc: 0.9172\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9136 - val_loss: 0.1752 - val_acc: 0.9180\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9133 - val_loss: 0.1753 - val_acc: 0.9167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17508 to 0.17499, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9145 - val_loss: 0.1750 - val_acc: 0.9180\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9155 - val_loss: 0.1755 - val_acc: 0.9159\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9151 - val_loss: 0.1752 - val_acc: 0.9178\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9145 - val_loss: 0.1750 - val_acc: 0.9153\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9167 - val_loss: 0.1751 - val_acc: 0.9176\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17499 to 0.17495, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9145 - val_loss: 0.1749 - val_acc: 0.9184\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17495 to 0.17449, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9143 - val_loss: 0.1745 - val_acc: 0.9167\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9158 - val_loss: 0.1752 - val_acc: 0.9176\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9151 - val_loss: 0.1751 - val_acc: 0.9167\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9147 - val_loss: 0.1749 - val_acc: 0.9168\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17449 to 0.17420, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9163 - val_loss: 0.1742 - val_acc: 0.9174\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17420 to 0.17411, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9158 - val_loss: 0.1741 - val_acc: 0.9170\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9169 - val_loss: 0.1744 - val_acc: 0.9172\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9159 - val_loss: 0.1746 - val_acc: 0.9176\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9149 - val_loss: 0.1742 - val_acc: 0.9172\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9149 - val_loss: 0.1749 - val_acc: 0.9168\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9170 - val_loss: 0.1746 - val_acc: 0.9161\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9162 - val_loss: 0.1743 - val_acc: 0.9149\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9165 - val_loss: 0.1742 - val_acc: 0.9165\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9157 - val_loss: 0.1745 - val_acc: 0.9172\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17411 to 0.17369, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9163 - val_loss: 0.1737 - val_acc: 0.9167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9162 - val_loss: 0.1744 - val_acc: 0.9161\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17369 to 0.17353, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9174 - val_loss: 0.1735 - val_acc: 0.9195\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.17353 to 0.17341, saving model to best.model\n",
      "1s - loss: 0.1764 - acc: 0.9151 - val_loss: 0.1734 - val_acc: 0.9172\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17341 to 0.17301, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9156 - val_loss: 0.1730 - val_acc: 0.9205\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9163 - val_loss: 0.1733 - val_acc: 0.9176\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9170 - val_loss: 0.1737 - val_acc: 0.9153\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9164 - val_loss: 0.1733 - val_acc: 0.9165\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9171 - val_loss: 0.1732 - val_acc: 0.9161\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9162 - val_loss: 0.1733 - val_acc: 0.9165\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9159 - val_loss: 0.1732 - val_acc: 0.9157\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9172 - val_loss: 0.1734 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9150 - val_loss: 0.1732 - val_acc: 0.9178\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9164 - val_loss: 0.1732 - val_acc: 0.9180\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9165 - val_loss: 0.1742 - val_acc: 0.9157\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9163 - val_loss: 0.1734 - val_acc: 0.9174\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9169 - val_loss: 0.1732 - val_acc: 0.9188\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9160 - val_loss: 0.1732 - val_acc: 0.9168\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17301 to 0.17288, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9171 - val_loss: 0.1729 - val_acc: 0.9168\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.17288 to 0.17266, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9171 - val_loss: 0.1727 - val_acc: 0.9178\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9177 - val_loss: 0.1727 - val_acc: 0.9178\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17266 to 0.17257, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9194 - val_loss: 0.1726 - val_acc: 0.9174\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17257 to 0.17253, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9169 - val_loss: 0.1725 - val_acc: 0.9167\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9172 - val_loss: 0.1725 - val_acc: 0.9180\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.17253 to 0.17244, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9164 - val_loss: 0.1724 - val_acc: 0.9186\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17244 to 0.17228, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9164 - val_loss: 0.1723 - val_acc: 0.9197\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9179 - val_loss: 0.1724 - val_acc: 0.9193\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17228 to 0.17220, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9165 - val_loss: 0.1722 - val_acc: 0.9182\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17220 to 0.17218, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9176 - val_loss: 0.1722 - val_acc: 0.9190\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9167 - val_loss: 0.1723 - val_acc: 0.9195\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9184 - val_loss: 0.1724 - val_acc: 0.9174\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9187 - val_loss: 0.1729 - val_acc: 0.9170\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9173 - val_loss: 0.1725 - val_acc: 0.9176\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17218 to 0.17207, saving model to best.model\n",
      "1s - loss: 0.1747 - acc: 0.9155 - val_loss: 0.1721 - val_acc: 0.9203\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9181 - val_loss: 0.1723 - val_acc: 0.9188\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9183 - val_loss: 0.1722 - val_acc: 0.9180\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9171 - val_loss: 0.1725 - val_acc: 0.9199\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9181 - val_loss: 0.1724 - val_acc: 0.9195\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9182 - val_loss: 0.1723 - val_acc: 0.9191\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9173 - val_loss: 0.1725 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9179 - val_loss: 0.1723 - val_acc: 0.9193\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9178 - val_loss: 0.1722 - val_acc: 0.9207\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9177 - val_loss: 0.1724 - val_acc: 0.9172\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9175 - val_loss: 0.1722 - val_acc: 0.9180\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9178 - val_loss: 0.1725 - val_acc: 0.9193\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9180 - val_loss: 0.1724 - val_acc: 0.9174\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9190 - val_loss: 0.1723 - val_acc: 0.9188\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9171 - val_loss: 0.1727 - val_acc: 0.9201\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9187 - val_loss: 0.1723 - val_acc: 0.9184\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9173 - val_loss: 0.1724 - val_acc: 0.9178\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17207 to 0.17199, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9180 - val_loss: 0.1720 - val_acc: 0.9180\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17199 to 0.17188, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9187 - val_loss: 0.1719 - val_acc: 0.9201\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9190 - val_loss: 0.1727 - val_acc: 0.9197\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17188 to 0.17164, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9195 - val_loss: 0.1716 - val_acc: 0.9197\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9177 - val_loss: 0.1717 - val_acc: 0.9201\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9182 - val_loss: 0.1720 - val_acc: 0.9195\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9187 - val_loss: 0.1719 - val_acc: 0.9184\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9173 - val_loss: 0.1721 - val_acc: 0.9182\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "1s - loss: 0.1697 - acc: 0.9170 - val_loss: 0.1721 - val_acc: 0.9203\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9184 - val_loss: 0.1723 - val_acc: 0.9195\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9196 - val_loss: 0.1718 - val_acc: 0.9195\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9189 - val_loss: 0.1717 - val_acc: 0.9195\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9193 - val_loss: 0.1717 - val_acc: 0.9197\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9191 - val_loss: 0.1720 - val_acc: 0.9180\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9204 - val_loss: 0.1717 - val_acc: 0.9199\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.17164 to 0.17148, saving model to best.model\n",
      "0s - loss: 0.1704 - acc: 0.9180 - val_loss: 0.1715 - val_acc: 0.9188\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9188 - val_loss: 0.1716 - val_acc: 0.9191\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9195 - val_loss: 0.1722 - val_acc: 0.9199\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.17148 to 0.17131, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9191 - val_loss: 0.1713 - val_acc: 0.9188\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34349, saving model to best.model\n",
      "0s - loss: 0.4179 - acc: 0.8664 - val_loss: 0.3435 - val_acc: 0.8842\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34349 to 0.26745, saving model to best.model\n",
      "0s - loss: 0.3384 - acc: 0.8871 - val_loss: 0.2675 - val_acc: 0.8844\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26745 to 0.22166, saving model to best.model\n",
      "0s - loss: 0.2697 - acc: 0.8942 - val_loss: 0.2217 - val_acc: 0.8990\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22166 to 0.20349, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9015 - val_loss: 0.2035 - val_acc: 0.9076\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20349 to 0.19939, saving model to best.model\n",
      "0s - loss: 0.2221 - acc: 0.9039 - val_loss: 0.1994 - val_acc: 0.9072\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19939 to 0.19680, saving model to best.model\n",
      "0s - loss: 0.2151 - acc: 0.9041 - val_loss: 0.1968 - val_acc: 0.9082\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19680 to 0.19535, saving model to best.model\n",
      "0s - loss: 0.2087 - acc: 0.9072 - val_loss: 0.1954 - val_acc: 0.9063\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19535 to 0.19496, saving model to best.model\n",
      "0s - loss: 0.2078 - acc: 0.9052 - val_loss: 0.1950 - val_acc: 0.9063\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19496 to 0.19469, saving model to best.model\n",
      "0s - loss: 0.2058 - acc: 0.9064 - val_loss: 0.1947 - val_acc: 0.9061\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19469 to 0.19466, saving model to best.model\n",
      "0s - loss: 0.2015 - acc: 0.9072 - val_loss: 0.1947 - val_acc: 0.9053\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19466 to 0.19435, saving model to best.model\n",
      "0s - loss: 0.2006 - acc: 0.9076 - val_loss: 0.1943 - val_acc: 0.9049\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2008 - acc: 0.9052 - val_loss: 0.1944 - val_acc: 0.9084\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19435 to 0.19434, saving model to best.model\n",
      "0s - loss: 0.1998 - acc: 0.9079 - val_loss: 0.1943 - val_acc: 0.9069\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19434 to 0.19393, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9059 - val_loss: 0.1939 - val_acc: 0.9078\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1993 - acc: 0.9078 - val_loss: 0.1940 - val_acc: 0.9057\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19393 to 0.19366, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9083 - val_loss: 0.1937 - val_acc: 0.9076\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19366 to 0.19361, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9080 - val_loss: 0.1936 - val_acc: 0.9067\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1955 - acc: 0.9096 - val_loss: 0.1937 - val_acc: 0.9080\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19361 to 0.19340, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9098 - val_loss: 0.1934 - val_acc: 0.9065\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9084 - val_loss: 0.1943 - val_acc: 0.9059\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1941 - acc: 0.9075 - val_loss: 0.1938 - val_acc: 0.9074\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19340 to 0.19321, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9096 - val_loss: 0.1932 - val_acc: 0.9070\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19321 to 0.19301, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9095 - val_loss: 0.1930 - val_acc: 0.9069\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19301 to 0.19298, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9090 - val_loss: 0.1930 - val_acc: 0.9065\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19298 to 0.19285, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9101 - val_loss: 0.1928 - val_acc: 0.9065\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19285 to 0.19257, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9094 - val_loss: 0.1926 - val_acc: 0.9069\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19257 to 0.19230, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9114 - val_loss: 0.1923 - val_acc: 0.9070\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19230 to 0.19204, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9099 - val_loss: 0.1920 - val_acc: 0.9070\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19204 to 0.19189, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9092 - val_loss: 0.1919 - val_acc: 0.9074\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9092 - val_loss: 0.1920 - val_acc: 0.9070\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "1s - loss: 0.1909 - acc: 0.9102 - val_loss: 0.1919 - val_acc: 0.9074\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19189 to 0.19151, saving model to best.model\n",
      "1s - loss: 0.1916 - acc: 0.9103 - val_loss: 0.1915 - val_acc: 0.9078\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19151 to 0.19124, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9103 - val_loss: 0.1912 - val_acc: 0.9078\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19124 to 0.19113, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9095 - val_loss: 0.1911 - val_acc: 0.9076\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19113 to 0.19109, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9110 - val_loss: 0.1911 - val_acc: 0.9076\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19109 to 0.19095, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9103 - val_loss: 0.1910 - val_acc: 0.9080\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9101 - val_loss: 0.1916 - val_acc: 0.9072\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9100 - val_loss: 0.1913 - val_acc: 0.9076\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19095 to 0.19069, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9111 - val_loss: 0.1907 - val_acc: 0.9078\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9099 - val_loss: 0.1910 - val_acc: 0.9067\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19069 to 0.19039, saving model to best.model\n",
      "1s - loss: 0.1901 - acc: 0.9104 - val_loss: 0.1904 - val_acc: 0.9095\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9112 - val_loss: 0.1905 - val_acc: 0.9082\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "1s - loss: 0.1898 - acc: 0.9111 - val_loss: 0.1906 - val_acc: 0.9088\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.19039 to 0.19017, saving model to best.model\n",
      "1s - loss: 0.1891 - acc: 0.9128 - val_loss: 0.1902 - val_acc: 0.9078\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9101 - val_loss: 0.1908 - val_acc: 0.9094\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19017 to 0.18995, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9104 - val_loss: 0.1900 - val_acc: 0.9076\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9122 - val_loss: 0.1902 - val_acc: 0.9090\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9114 - val_loss: 0.1903 - val_acc: 0.9084\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9115 - val_loss: 0.1914 - val_acc: 0.9090\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1872 - acc: 0.9106 - val_loss: 0.1901 - val_acc: 0.9092\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18995 to 0.18973, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9126 - val_loss: 0.1897 - val_acc: 0.9090\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18973 to 0.18967, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9122 - val_loss: 0.1897 - val_acc: 0.9092\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9118 - val_loss: 0.1907 - val_acc: 0.9105\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18967 to 0.18924, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9138 - val_loss: 0.1892 - val_acc: 0.9092\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18924 to 0.18920, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9127 - val_loss: 0.1892 - val_acc: 0.9088\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9130 - val_loss: 0.1894 - val_acc: 0.9086\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9141 - val_loss: 0.1893 - val_acc: 0.9097\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9112 - val_loss: 0.1894 - val_acc: 0.9101\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18920 to 0.18899, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9117 - val_loss: 0.1890 - val_acc: 0.9095\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18899 to 0.18898, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9126 - val_loss: 0.1890 - val_acc: 0.9103\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18898 to 0.18882, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9140 - val_loss: 0.1888 - val_acc: 0.9080\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9124 - val_loss: 0.1892 - val_acc: 0.9074\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9128 - val_loss: 0.1892 - val_acc: 0.9115\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9129 - val_loss: 0.1891 - val_acc: 0.9076\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9118 - val_loss: 0.1889 - val_acc: 0.9097\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18882 to 0.18864, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9124 - val_loss: 0.1886 - val_acc: 0.9094\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9135 - val_loss: 0.1887 - val_acc: 0.9095\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18864 to 0.18861, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9133 - val_loss: 0.1886 - val_acc: 0.9099\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18861 to 0.18856, saving model to best.model\n",
      "1s - loss: 0.1836 - acc: 0.9133 - val_loss: 0.1886 - val_acc: 0.9090\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9125 - val_loss: 0.1886 - val_acc: 0.9095\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9142 - val_loss: 0.1888 - val_acc: 0.9101\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18856 to 0.18834, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9148 - val_loss: 0.1883 - val_acc: 0.9095\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18834 to 0.18814, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9150 - val_loss: 0.1881 - val_acc: 0.9097\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9149 - val_loss: 0.1882 - val_acc: 0.9094\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9130 - val_loss: 0.1884 - val_acc: 0.9092\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18814 to 0.18813, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9118 - val_loss: 0.1881 - val_acc: 0.9094\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9139 - val_loss: 0.1882 - val_acc: 0.9109\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.18813 to 0.18776, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9144 - val_loss: 0.1878 - val_acc: 0.9086\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18776 to 0.18764, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9150 - val_loss: 0.1876 - val_acc: 0.9103\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9168 - val_loss: 0.1879 - val_acc: 0.9084\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9154 - val_loss: 0.1881 - val_acc: 0.9113\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18764 to 0.18748, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9136 - val_loss: 0.1875 - val_acc: 0.9092\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9137 - val_loss: 0.1877 - val_acc: 0.9092\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9133 - val_loss: 0.1877 - val_acc: 0.9097\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.18748 to 0.18711, saving model to best.model\n",
      "0s - loss: 0.1820 - acc: 0.9150 - val_loss: 0.1871 - val_acc: 0.9099\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9147 - val_loss: 0.1879 - val_acc: 0.9084\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18711 to 0.18682, saving model to best.model\n",
      "1s - loss: 0.1814 - acc: 0.9139 - val_loss: 0.1868 - val_acc: 0.9094\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9155 - val_loss: 0.1872 - val_acc: 0.9097\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9152 - val_loss: 0.1871 - val_acc: 0.9101\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "1s - loss: 0.1788 - acc: 0.9154 - val_loss: 0.1873 - val_acc: 0.9103\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9147 - val_loss: 0.1869 - val_acc: 0.9097\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18682 to 0.18657, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9150 - val_loss: 0.1866 - val_acc: 0.9105\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9152 - val_loss: 0.1867 - val_acc: 0.9109\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9145 - val_loss: 0.1867 - val_acc: 0.9097\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9139 - val_loss: 0.1869 - val_acc: 0.9103\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18657 to 0.18630, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9150 - val_loss: 0.1863 - val_acc: 0.9095\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18630 to 0.18604, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9142 - val_loss: 0.1860 - val_acc: 0.9097\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9138 - val_loss: 0.1864 - val_acc: 0.9103\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9150 - val_loss: 0.1861 - val_acc: 0.9109\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9163 - val_loss: 0.1864 - val_acc: 0.9095\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9163 - val_loss: 0.1864 - val_acc: 0.9109\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9159 - val_loss: 0.1867 - val_acc: 0.9103\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18604 to 0.18586, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9155 - val_loss: 0.1859 - val_acc: 0.9113\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9168 - val_loss: 0.1860 - val_acc: 0.9107\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9170 - val_loss: 0.1859 - val_acc: 0.9103\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18586 to 0.18547, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9171 - val_loss: 0.1855 - val_acc: 0.9101\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9150 - val_loss: 0.1855 - val_acc: 0.9097\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9148 - val_loss: 0.1856 - val_acc: 0.9105\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9169 - val_loss: 0.1864 - val_acc: 0.9105\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9171 - val_loss: 0.1855 - val_acc: 0.9105\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9152 - val_loss: 0.1860 - val_acc: 0.9103\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9149 - val_loss: 0.1858 - val_acc: 0.9105\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9161 - val_loss: 0.1856 - val_acc: 0.9113\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9143 - val_loss: 0.1859 - val_acc: 0.9105\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.18547 to 0.18520, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9168 - val_loss: 0.1852 - val_acc: 0.9097\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9161 - val_loss: 0.1855 - val_acc: 0.9113\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9162 - val_loss: 0.1856 - val_acc: 0.9103\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18520 to 0.18491, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9157 - val_loss: 0.1849 - val_acc: 0.9117\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9171 - val_loss: 0.1850 - val_acc: 0.9101\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9152 - val_loss: 0.1850 - val_acc: 0.9107\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9169 - val_loss: 0.1854 - val_acc: 0.9111\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9159 - val_loss: 0.1860 - val_acc: 0.9105\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9169 - val_loss: 0.1855 - val_acc: 0.9109\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9150 - val_loss: 0.1849 - val_acc: 0.9115\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9153 - val_loss: 0.1857 - val_acc: 0.9115\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9175 - val_loss: 0.1850 - val_acc: 0.9117\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18491 to 0.18457, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9172 - val_loss: 0.1846 - val_acc: 0.9118\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9175 - val_loss: 0.1854 - val_acc: 0.9118\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9169 - val_loss: 0.1866 - val_acc: 0.9122\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.18457 to 0.18439, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9173 - val_loss: 0.1844 - val_acc: 0.9111\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9173 - val_loss: 0.1848 - val_acc: 0.9118\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9157 - val_loss: 0.1850 - val_acc: 0.9115\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.18439 to 0.18419, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9174 - val_loss: 0.1842 - val_acc: 0.9122\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9174 - val_loss: 0.1846 - val_acc: 0.9118\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9164 - val_loss: 0.1852 - val_acc: 0.9117\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9168 - val_loss: 0.1842 - val_acc: 0.9126\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.18419 to 0.18405, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9165 - val_loss: 0.1840 - val_acc: 0.9115\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.18405 to 0.18403, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9166 - val_loss: 0.1840 - val_acc: 0.9122\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9183 - val_loss: 0.1845 - val_acc: 0.9122\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9181 - val_loss: 0.1846 - val_acc: 0.9130\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9175 - val_loss: 0.1841 - val_acc: 0.9122\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "1s - loss: 0.1747 - acc: 0.9166 - val_loss: 0.1846 - val_acc: 0.9132\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9168 - val_loss: 0.1840 - val_acc: 0.9122\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9184 - val_loss: 0.1844 - val_acc: 0.9109\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9172 - val_loss: 0.1848 - val_acc: 0.9118\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.18403 to 0.18398, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9174 - val_loss: 0.1840 - val_acc: 0.9124\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18398 to 0.18366, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9177 - val_loss: 0.1837 - val_acc: 0.9115\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9173 - val_loss: 0.1842 - val_acc: 0.9122\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9188 - val_loss: 0.1837 - val_acc: 0.9126\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9211 - val_loss: 0.1838 - val_acc: 0.9124\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.18366 to 0.18346, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9192 - val_loss: 0.1835 - val_acc: 0.9111\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9176 - val_loss: 0.1840 - val_acc: 0.9117\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9164 - val_loss: 0.1855 - val_acc: 0.9109\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9187 - val_loss: 0.1841 - val_acc: 0.9120\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9192 - val_loss: 0.1849 - val_acc: 0.9120\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9183 - val_loss: 0.1862 - val_acc: 0.9120\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9181 - val_loss: 0.1837 - val_acc: 0.9120\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9185 - val_loss: 0.1835 - val_acc: 0.9122\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.18346 to 0.18344, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9181 - val_loss: 0.1834 - val_acc: 0.9115\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.18344 to 0.18339, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9191 - val_loss: 0.1834 - val_acc: 0.9124\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.18339 to 0.18324, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9184 - val_loss: 0.1832 - val_acc: 0.9126\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9188 - val_loss: 0.1838 - val_acc: 0.9122\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9188 - val_loss: 0.1835 - val_acc: 0.9117\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9187 - val_loss: 0.1833 - val_acc: 0.9122\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9189 - val_loss: 0.1835 - val_acc: 0.9117\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9181 - val_loss: 0.1835 - val_acc: 0.9120\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9182 - val_loss: 0.1833 - val_acc: 0.9113\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.18324 to 0.18319, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9180 - val_loss: 0.1832 - val_acc: 0.9111\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.18319 to 0.18292, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9194 - val_loss: 0.1829 - val_acc: 0.9118\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.18292 to 0.18289, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9193 - val_loss: 0.1829 - val_acc: 0.9120\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9186 - val_loss: 0.1830 - val_acc: 0.9122\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9187 - val_loss: 0.1830 - val_acc: 0.9120\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9190 - val_loss: 0.1856 - val_acc: 0.9118\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9195 - val_loss: 0.1838 - val_acc: 0.9113\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9177 - val_loss: 0.1835 - val_acc: 0.9115\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9188 - val_loss: 0.1832 - val_acc: 0.9128\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9178 - val_loss: 0.1839 - val_acc: 0.9115\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9182 - val_loss: 0.1834 - val_acc: 0.9120\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9206 - val_loss: 0.1830 - val_acc: 0.9107\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9184 - val_loss: 0.1838 - val_acc: 0.9111\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9205 - val_loss: 0.1834 - val_acc: 0.9111\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9207 - val_loss: 0.1837 - val_acc: 0.9113\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9191 - val_loss: 0.1832 - val_acc: 0.9115\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9208 - val_loss: 0.1841 - val_acc: 0.9126\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9194 - val_loss: 0.1829 - val_acc: 0.9107\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9200 - val_loss: 0.1838 - val_acc: 0.9118\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9198 - val_loss: 0.1838 - val_acc: 0.9111\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9198 - val_loss: 0.1841 - val_acc: 0.9115\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9190 - val_loss: 0.1840 - val_acc: 0.9117\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9191 - val_loss: 0.1846 - val_acc: 0.9115\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9191 - val_loss: 0.1838 - val_acc: 0.9122\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9199 - val_loss: 0.1833 - val_acc: 0.9107\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9196 - val_loss: 0.1840 - val_acc: 0.9113\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9205 - val_loss: 0.1838 - val_acc: 0.9107\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9197 - val_loss: 0.1833 - val_acc: 0.9120\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9199 - val_loss: 0.1829 - val_acc: 0.9117\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33230, saving model to best.model\n",
      "0s - loss: 0.4205 - acc: 0.8628 - val_loss: 0.3323 - val_acc: 0.8884\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33230 to 0.26696, saving model to best.model\n",
      "0s - loss: 0.3387 - acc: 0.8877 - val_loss: 0.2670 - val_acc: 0.8884\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26696 to 0.21594, saving model to best.model\n",
      "0s - loss: 0.2702 - acc: 0.8932 - val_loss: 0.2159 - val_acc: 0.9092\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21594 to 0.19520, saving model to best.model\n",
      "0s - loss: 0.2378 - acc: 0.8991 - val_loss: 0.1952 - val_acc: 0.9132\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19520 to 0.19179, saving model to best.model\n",
      "0s - loss: 0.2241 - acc: 0.9006 - val_loss: 0.1918 - val_acc: 0.9168\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19179 to 0.19017, saving model to best.model\n",
      "0s - loss: 0.2164 - acc: 0.8994 - val_loss: 0.1902 - val_acc: 0.9161\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19017 to 0.18794, saving model to best.model\n",
      "0s - loss: 0.2119 - acc: 0.9011 - val_loss: 0.1879 - val_acc: 0.9168\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2078 - acc: 0.9042 - val_loss: 0.1885 - val_acc: 0.9122\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18794 to 0.18706, saving model to best.model\n",
      "0s - loss: 0.2035 - acc: 0.9012 - val_loss: 0.1871 - val_acc: 0.9130\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2030 - acc: 0.9033 - val_loss: 0.1871 - val_acc: 0.9124\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18706 to 0.18691, saving model to best.model\n",
      "0s - loss: 0.2024 - acc: 0.9020 - val_loss: 0.1869 - val_acc: 0.9159\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2001 - acc: 0.9038 - val_loss: 0.1871 - val_acc: 0.9163\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9025 - val_loss: 0.1875 - val_acc: 0.9174\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18691 to 0.18684, saving model to best.model\n",
      "0s - loss: 0.2002 - acc: 0.9046 - val_loss: 0.1868 - val_acc: 0.9140\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.18684 to 0.18668, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9047 - val_loss: 0.1867 - val_acc: 0.9143\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1993 - acc: 0.9046 - val_loss: 0.1867 - val_acc: 0.9126\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18668 to 0.18638, saving model to best.model\n",
      "0s - loss: 0.1977 - acc: 0.9043 - val_loss: 0.1864 - val_acc: 0.9143\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18638 to 0.18630, saving model to best.model\n",
      "0s - loss: 0.1978 - acc: 0.9055 - val_loss: 0.1863 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18630 to 0.18622, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9041 - val_loss: 0.1862 - val_acc: 0.9149\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18622 to 0.18600, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9045 - val_loss: 0.1860 - val_acc: 0.9132\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1957 - acc: 0.9051 - val_loss: 0.1861 - val_acc: 0.9155\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9039 - val_loss: 0.1871 - val_acc: 0.9172\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18600 to 0.18552, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9062 - val_loss: 0.1855 - val_acc: 0.9145\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18552 to 0.18512, saving model to best.model\n",
      "0s - loss: 0.1960 - acc: 0.9068 - val_loss: 0.1851 - val_acc: 0.9163\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1946 - acc: 0.9062 - val_loss: 0.1857 - val_acc: 0.9136\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18512 to 0.18468, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9071 - val_loss: 0.1847 - val_acc: 0.9155\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1951 - acc: 0.9061 - val_loss: 0.1852 - val_acc: 0.9136\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18468 to 0.18419, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9066 - val_loss: 0.1842 - val_acc: 0.9138\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18419 to 0.18396, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9076 - val_loss: 0.1840 - val_acc: 0.9157\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1960 - acc: 0.9067 - val_loss: 0.1844 - val_acc: 0.9172\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18396 to 0.18385, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9067 - val_loss: 0.1839 - val_acc: 0.9167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18385 to 0.18368, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9064 - val_loss: 0.1837 - val_acc: 0.9176\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18368 to 0.18365, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9066 - val_loss: 0.1836 - val_acc: 0.9170\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18365 to 0.18356, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9077 - val_loss: 0.1836 - val_acc: 0.9182\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18356 to 0.18285, saving model to best.model\n",
      "0s - loss: 0.1936 - acc: 0.9074 - val_loss: 0.1828 - val_acc: 0.9172\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18285 to 0.18264, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9066 - val_loss: 0.1826 - val_acc: 0.9174\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18264 to 0.18246, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9082 - val_loss: 0.1825 - val_acc: 0.9178\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9090 - val_loss: 0.1827 - val_acc: 0.9186\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9072 - val_loss: 0.1829 - val_acc: 0.9178\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18246 to 0.18178, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9080 - val_loss: 0.1818 - val_acc: 0.9180\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1920 - acc: 0.9069 - val_loss: 0.1820 - val_acc: 0.9193\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9084 - val_loss: 0.1819 - val_acc: 0.9180\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18178 to 0.18156, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9076 - val_loss: 0.1816 - val_acc: 0.9170\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1907 - acc: 0.9069 - val_loss: 0.1816 - val_acc: 0.9182\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18156 to 0.18062, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9068 - val_loss: 0.1806 - val_acc: 0.9190\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9096 - val_loss: 0.1811 - val_acc: 0.9195\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18062 to 0.18050, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9089 - val_loss: 0.1805 - val_acc: 0.9191\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9098 - val_loss: 0.1812 - val_acc: 0.9168\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18050 to 0.18029, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9084 - val_loss: 0.1803 - val_acc: 0.9182\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9092 - val_loss: 0.1804 - val_acc: 0.9186\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9088 - val_loss: 0.1813 - val_acc: 0.9191\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18029 to 0.18015, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9098 - val_loss: 0.1802 - val_acc: 0.9176\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18015 to 0.17970, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9095 - val_loss: 0.1797 - val_acc: 0.9201\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.17970 to 0.17918, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9096 - val_loss: 0.1792 - val_acc: 0.9220\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9097 - val_loss: 0.1792 - val_acc: 0.9176\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.17918 to 0.17885, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9112 - val_loss: 0.1788 - val_acc: 0.9170\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9097 - val_loss: 0.1793 - val_acc: 0.9201\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17885 to 0.17842, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9100 - val_loss: 0.1784 - val_acc: 0.9205\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9117 - val_loss: 0.1790 - val_acc: 0.9203\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9105 - val_loss: 0.1784 - val_acc: 0.9209\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17842 to 0.17825, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9107 - val_loss: 0.1782 - val_acc: 0.9205\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9104 - val_loss: 0.1786 - val_acc: 0.9180\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9114 - val_loss: 0.1787 - val_acc: 0.9176\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17825 to 0.17731, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9104 - val_loss: 0.1773 - val_acc: 0.9197\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9100 - val_loss: 0.1783 - val_acc: 0.9184\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9113 - val_loss: 0.1777 - val_acc: 0.9203\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9112 - val_loss: 0.1780 - val_acc: 0.9207\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.17731 to 0.17711, saving model to best.model\n",
      "1s - loss: 0.1853 - acc: 0.9103 - val_loss: 0.1771 - val_acc: 0.9205\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17711 to 0.17697, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9117 - val_loss: 0.1770 - val_acc: 0.9197\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "1s - loss: 0.1851 - acc: 0.9099 - val_loss: 0.1771 - val_acc: 0.9201\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.17697 to 0.17646, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9131 - val_loss: 0.1765 - val_acc: 0.9193\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.17646 to 0.17640, saving model to best.model\n",
      "1s - loss: 0.1840 - acc: 0.9106 - val_loss: 0.1764 - val_acc: 0.9199\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9109 - val_loss: 0.1768 - val_acc: 0.9197\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9109 - val_loss: 0.1776 - val_acc: 0.9190\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9114 - val_loss: 0.1770 - val_acc: 0.9199\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.17640 to 0.17590, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9113 - val_loss: 0.1759 - val_acc: 0.9195\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9111 - val_loss: 0.1761 - val_acc: 0.9201\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9110 - val_loss: 0.1763 - val_acc: 0.9190\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.17590 to 0.17532, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9127 - val_loss: 0.1753 - val_acc: 0.9197\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9117 - val_loss: 0.1755 - val_acc: 0.9207\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9128 - val_loss: 0.1765 - val_acc: 0.9180\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9115 - val_loss: 0.1757 - val_acc: 0.9199\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9131 - val_loss: 0.1766 - val_acc: 0.9201\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17532 to 0.17523, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9125 - val_loss: 0.1752 - val_acc: 0.9199\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9132 - val_loss: 0.1754 - val_acc: 0.9205\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17523 to 0.17468, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9109 - val_loss: 0.1747 - val_acc: 0.9203\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "1s - loss: 0.1813 - acc: 0.9137 - val_loss: 0.1750 - val_acc: 0.9207\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17468 to 0.17463, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9134 - val_loss: 0.1746 - val_acc: 0.9201\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "1s - loss: 0.1821 - acc: 0.9141 - val_loss: 0.1753 - val_acc: 0.9209\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9132 - val_loss: 0.1747 - val_acc: 0.9209\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9114 - val_loss: 0.1754 - val_acc: 0.9199\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17463 to 0.17460, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9121 - val_loss: 0.1746 - val_acc: 0.9193\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9136 - val_loss: 0.1746 - val_acc: 0.9199\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17460 to 0.17430, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9128 - val_loss: 0.1743 - val_acc: 0.9211\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9117 - val_loss: 0.1743 - val_acc: 0.9193\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9120 - val_loss: 0.1747 - val_acc: 0.9191\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17430 to 0.17395, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9138 - val_loss: 0.1740 - val_acc: 0.9195\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9142 - val_loss: 0.1744 - val_acc: 0.9193\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17395 to 0.17361, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9152 - val_loss: 0.1736 - val_acc: 0.9197\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9121 - val_loss: 0.1739 - val_acc: 0.9195\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9137 - val_loss: 0.1742 - val_acc: 0.9193\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9102 - val_loss: 0.1752 - val_acc: 0.9193\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17361 to 0.17352, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9145 - val_loss: 0.1735 - val_acc: 0.9203\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9140 - val_loss: 0.1736 - val_acc: 0.9205\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9155 - val_loss: 0.1737 - val_acc: 0.9203\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17352 to 0.17327, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9131 - val_loss: 0.1733 - val_acc: 0.9186\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9133 - val_loss: 0.1733 - val_acc: 0.9195\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17327 to 0.17307, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9129 - val_loss: 0.1731 - val_acc: 0.9201\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9137 - val_loss: 0.1735 - val_acc: 0.9209\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "1s - loss: 0.1787 - acc: 0.9128 - val_loss: 0.1743 - val_acc: 0.9190\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9142 - val_loss: 0.1731 - val_acc: 0.9201\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17307 to 0.17246, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9153 - val_loss: 0.1725 - val_acc: 0.9209\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9144 - val_loss: 0.1726 - val_acc: 0.9203\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9153 - val_loss: 0.1726 - val_acc: 0.9205\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9142 - val_loss: 0.1730 - val_acc: 0.9188\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17246 to 0.17220, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9140 - val_loss: 0.1722 - val_acc: 0.9201\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17220 to 0.17215, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9126 - val_loss: 0.1721 - val_acc: 0.9197\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9150 - val_loss: 0.1729 - val_acc: 0.9199\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9146 - val_loss: 0.1724 - val_acc: 0.9186\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9135 - val_loss: 0.1723 - val_acc: 0.9193\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9158 - val_loss: 0.1726 - val_acc: 0.9199\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17215 to 0.17212, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9149 - val_loss: 0.1721 - val_acc: 0.9197\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9146 - val_loss: 0.1731 - val_acc: 0.9193\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17212 to 0.17204, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9154 - val_loss: 0.1720 - val_acc: 0.9186\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9140 - val_loss: 0.1721 - val_acc: 0.9201\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17204 to 0.17157, saving model to best.model\n",
      "1s - loss: 0.1772 - acc: 0.9140 - val_loss: 0.1716 - val_acc: 0.9203\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.17157 to 0.17140, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9144 - val_loss: 0.1714 - val_acc: 0.9203\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "1s - loss: 0.1764 - acc: 0.9135 - val_loss: 0.1724 - val_acc: 0.9191\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17140 to 0.17139, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9152 - val_loss: 0.1714 - val_acc: 0.9207\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9143 - val_loss: 0.1719 - val_acc: 0.9201\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9159 - val_loss: 0.1718 - val_acc: 0.9195\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17139 to 0.17114, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9157 - val_loss: 0.1711 - val_acc: 0.9201\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17114 to 0.17099, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9148 - val_loss: 0.1710 - val_acc: 0.9195\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "1s - loss: 0.1751 - acc: 0.9170 - val_loss: 0.1712 - val_acc: 0.9190\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9158 - val_loss: 0.1710 - val_acc: 0.9188\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9157 - val_loss: 0.1718 - val_acc: 0.9193\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9167 - val_loss: 0.1710 - val_acc: 0.9209\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17099 to 0.17089, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9165 - val_loss: 0.1709 - val_acc: 0.9203\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9156 - val_loss: 0.1713 - val_acc: 0.9190\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9150 - val_loss: 0.1711 - val_acc: 0.9190\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17089 to 0.17075, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9152 - val_loss: 0.1708 - val_acc: 0.9188\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9157 - val_loss: 0.1717 - val_acc: 0.9190\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9145 - val_loss: 0.1716 - val_acc: 0.9193\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17075 to 0.17051, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9159 - val_loss: 0.1705 - val_acc: 0.9197\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9176 - val_loss: 0.1706 - val_acc: 0.9195\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9171 - val_loss: 0.1706 - val_acc: 0.9182\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9163 - val_loss: 0.1706 - val_acc: 0.9193\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9161 - val_loss: 0.1707 - val_acc: 0.9186\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9152 - val_loss: 0.1706 - val_acc: 0.9182\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17051 to 0.17023, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9156 - val_loss: 0.1702 - val_acc: 0.9193\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9159 - val_loss: 0.1706 - val_acc: 0.9190\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9154 - val_loss: 0.1703 - val_acc: 0.9197\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "1s - loss: 0.1731 - acc: 0.9168 - val_loss: 0.1704 - val_acc: 0.9182\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9153 - val_loss: 0.1703 - val_acc: 0.9180\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9164 - val_loss: 0.1714 - val_acc: 0.9190\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9156 - val_loss: 0.1708 - val_acc: 0.9199\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9161 - val_loss: 0.1706 - val_acc: 0.9188\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9171 - val_loss: 0.1705 - val_acc: 0.9184\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.17023 to 0.16953, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9167 - val_loss: 0.1695 - val_acc: 0.9197\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9156 - val_loss: 0.1699 - val_acc: 0.9191\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9176 - val_loss: 0.1697 - val_acc: 0.9197\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9163 - val_loss: 0.1700 - val_acc: 0.9205\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9168 - val_loss: 0.1697 - val_acc: 0.9191\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9163 - val_loss: 0.1697 - val_acc: 0.9191\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9169 - val_loss: 0.1696 - val_acc: 0.9201\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9173 - val_loss: 0.1703 - val_acc: 0.9205\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.16953 to 0.16934, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9168 - val_loss: 0.1693 - val_acc: 0.9203\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9167 - val_loss: 0.1696 - val_acc: 0.9201\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9175 - val_loss: 0.1694 - val_acc: 0.9190\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9170 - val_loss: 0.1697 - val_acc: 0.9201\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.16934 to 0.16927, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9165 - val_loss: 0.1693 - val_acc: 0.9203\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.16927 to 0.16926, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9168 - val_loss: 0.1693 - val_acc: 0.9205\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.16926 to 0.16924, saving model to best.model\n",
      "0s - loss: 0.1712 - acc: 0.9169 - val_loss: 0.1692 - val_acc: 0.9203\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9158 - val_loss: 0.1693 - val_acc: 0.9199\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9158 - val_loss: 0.1697 - val_acc: 0.9203\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9158 - val_loss: 0.1707 - val_acc: 0.9197\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9175 - val_loss: 0.1695 - val_acc: 0.9199\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9177 - val_loss: 0.1693 - val_acc: 0.9201\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9175 - val_loss: 0.1693 - val_acc: 0.9207\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.16924 to 0.16916, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9167 - val_loss: 0.1692 - val_acc: 0.9180\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9164 - val_loss: 0.1698 - val_acc: 0.9209\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9177 - val_loss: 0.1700 - val_acc: 0.9213\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.16916 to 0.16902, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9172 - val_loss: 0.1690 - val_acc: 0.9199\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9169 - val_loss: 0.1693 - val_acc: 0.9193\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9189 - val_loss: 0.1703 - val_acc: 0.9211\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9178 - val_loss: 0.1696 - val_acc: 0.9211\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9165 - val_loss: 0.1694 - val_acc: 0.9197\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9191 - val_loss: 0.1691 - val_acc: 0.9207\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9184 - val_loss: 0.1692 - val_acc: 0.9215\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9183 - val_loss: 0.1693 - val_acc: 0.9205\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.16902 to 0.16895, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9192 - val_loss: 0.1689 - val_acc: 0.9209\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9191 - val_loss: 0.1695 - val_acc: 0.9207\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9198 - val_loss: 0.1690 - val_acc: 0.9201\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9179 - val_loss: 0.1690 - val_acc: 0.9224\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9189 - val_loss: 0.1697 - val_acc: 0.9207\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.16895 to 0.16861, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9182 - val_loss: 0.1686 - val_acc: 0.9211\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1673 - acc: 0.9193 - val_loss: 0.1689 - val_acc: 0.9220\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9171 - val_loss: 0.1696 - val_acc: 0.9207\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9199 - val_loss: 0.1687 - val_acc: 0.9211\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.16861 to 0.16849, saving model to best.model\n",
      "0s - loss: 0.1687 - acc: 0.9186 - val_loss: 0.1685 - val_acc: 0.9215\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34092, saving model to best.model\n",
      "1s - loss: 0.4231 - acc: 0.8636 - val_loss: 0.3409 - val_acc: 0.8865\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34092 to 0.27966, saving model to best.model\n",
      "0s - loss: 0.3415 - acc: 0.8861 - val_loss: 0.2797 - val_acc: 0.8865\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27966 to 0.22609, saving model to best.model\n",
      "0s - loss: 0.2789 - acc: 0.8917 - val_loss: 0.2261 - val_acc: 0.9044\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22609 to 0.20418, saving model to best.model\n",
      "0s - loss: 0.2408 - acc: 0.8980 - val_loss: 0.2042 - val_acc: 0.9069\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20418 to 0.19944, saving model to best.model\n",
      "0s - loss: 0.2246 - acc: 0.9024 - val_loss: 0.1994 - val_acc: 0.9094\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.2203 - acc: 0.9006 - val_loss: 0.2003 - val_acc: 0.9055\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19944 to 0.19597, saving model to best.model\n",
      "0s - loss: 0.2133 - acc: 0.9039 - val_loss: 0.1960 - val_acc: 0.9070\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19597 to 0.19333, saving model to best.model\n",
      "0s - loss: 0.2088 - acc: 0.9017 - val_loss: 0.1933 - val_acc: 0.9088\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19333 to 0.19280, saving model to best.model\n",
      "0s - loss: 0.2081 - acc: 0.9046 - val_loss: 0.1928 - val_acc: 0.9095\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2049 - acc: 0.9033 - val_loss: 0.1943 - val_acc: 0.9078\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19280 to 0.19232, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9045 - val_loss: 0.1923 - val_acc: 0.9090\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19232 to 0.19180, saving model to best.model\n",
      "0s - loss: 0.2022 - acc: 0.9038 - val_loss: 0.1918 - val_acc: 0.9088\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19180 to 0.19128, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9054 - val_loss: 0.1913 - val_acc: 0.9084\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19128 to 0.19123, saving model to best.model\n",
      "0s - loss: 0.2031 - acc: 0.9042 - val_loss: 0.1912 - val_acc: 0.9082\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19123 to 0.19102, saving model to best.model\n",
      "0s - loss: 0.2022 - acc: 0.9037 - val_loss: 0.1910 - val_acc: 0.9074\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19102 to 0.19071, saving model to best.model\n",
      "0s - loss: 0.2010 - acc: 0.9055 - val_loss: 0.1907 - val_acc: 0.9080\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19071 to 0.19070, saving model to best.model\n",
      "0s - loss: 0.2006 - acc: 0.9056 - val_loss: 0.1907 - val_acc: 0.9082\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19070 to 0.18995, saving model to best.model\n",
      "0s - loss: 0.1971 - acc: 0.9060 - val_loss: 0.1900 - val_acc: 0.9072\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18995 to 0.18991, saving model to best.model\n",
      "0s - loss: 0.1981 - acc: 0.9055 - val_loss: 0.1899 - val_acc: 0.9076\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1986 - acc: 0.9060 - val_loss: 0.1904 - val_acc: 0.9084\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18991 to 0.18944, saving model to best.model\n",
      "0s - loss: 0.1971 - acc: 0.9055 - val_loss: 0.1894 - val_acc: 0.9080\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18944 to 0.18943, saving model to best.model\n",
      "0s - loss: 0.1979 - acc: 0.9056 - val_loss: 0.1894 - val_acc: 0.9088\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9050 - val_loss: 0.1896 - val_acc: 0.9088\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18943 to 0.18931, saving model to best.model\n",
      "0s - loss: 0.1984 - acc: 0.9052 - val_loss: 0.1893 - val_acc: 0.9090\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18931 to 0.18914, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9052 - val_loss: 0.1891 - val_acc: 0.9069\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18914 to 0.18847, saving model to best.model\n",
      "0s - loss: 0.1948 - acc: 0.9057 - val_loss: 0.1885 - val_acc: 0.9080\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1963 - acc: 0.9069 - val_loss: 0.1887 - val_acc: 0.9088\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9066 - val_loss: 0.1887 - val_acc: 0.9092\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18847 to 0.18809, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9055 - val_loss: 0.1881 - val_acc: 0.9080\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18809 to 0.18764, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9053 - val_loss: 0.1876 - val_acc: 0.9090\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18764 to 0.18757, saving model to best.model\n",
      "0s - loss: 0.1962 - acc: 0.9067 - val_loss: 0.1876 - val_acc: 0.9082\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9078 - val_loss: 0.1876 - val_acc: 0.9099\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9073 - val_loss: 0.1876 - val_acc: 0.9080\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18757 to 0.18699, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9080 - val_loss: 0.1870 - val_acc: 0.9101\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9082 - val_loss: 0.1872 - val_acc: 0.9082\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18699 to 0.18680, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9090 - val_loss: 0.1868 - val_acc: 0.9086\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18680 to 0.18650, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9079 - val_loss: 0.1865 - val_acc: 0.9095\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18650 to 0.18611, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9074 - val_loss: 0.1861 - val_acc: 0.9097\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9076 - val_loss: 0.1868 - val_acc: 0.9067\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18611 to 0.18570, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9089 - val_loss: 0.1857 - val_acc: 0.9103\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18570 to 0.18547, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9068 - val_loss: 0.1855 - val_acc: 0.9122\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "1s - loss: 0.1910 - acc: 0.9102 - val_loss: 0.1856 - val_acc: 0.9105\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9074 - val_loss: 0.1872 - val_acc: 0.9088\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18547 to 0.18505, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9083 - val_loss: 0.1850 - val_acc: 0.9101\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18505 to 0.18490, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9087 - val_loss: 0.1849 - val_acc: 0.9105\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1908 - acc: 0.9077 - val_loss: 0.1854 - val_acc: 0.9111\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9101 - val_loss: 0.1862 - val_acc: 0.9107\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18490 to 0.18470, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9098 - val_loss: 0.1847 - val_acc: 0.9095\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18470 to 0.18456, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9083 - val_loss: 0.1846 - val_acc: 0.9097\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18456 to 0.18389, saving model to best.model\n",
      "0s - loss: 0.1903 - acc: 0.9096 - val_loss: 0.1839 - val_acc: 0.9118\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9086 - val_loss: 0.1846 - val_acc: 0.9090\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9087 - val_loss: 0.1841 - val_acc: 0.9095\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9103 - val_loss: 0.1844 - val_acc: 0.9111\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18389 to 0.18317, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9098 - val_loss: 0.1832 - val_acc: 0.9128\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18317 to 0.18309, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9096 - val_loss: 0.1831 - val_acc: 0.9113\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.18309 to 0.18295, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9098 - val_loss: 0.1830 - val_acc: 0.9103\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9103 - val_loss: 0.1831 - val_acc: 0.9109\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18295 to 0.18242, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9104 - val_loss: 0.1824 - val_acc: 0.9138\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18242 to 0.18242, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9080 - val_loss: 0.1824 - val_acc: 0.9128\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9103 - val_loss: 0.1831 - val_acc: 0.9124\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9111 - val_loss: 0.1835 - val_acc: 0.9109\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18242 to 0.18225, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9091 - val_loss: 0.1822 - val_acc: 0.9120\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18225 to 0.18188, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9102 - val_loss: 0.1819 - val_acc: 0.9147\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18188 to 0.18182, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9097 - val_loss: 0.1818 - val_acc: 0.9128\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18182 to 0.18173, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9103 - val_loss: 0.1817 - val_acc: 0.9117\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9113 - val_loss: 0.1823 - val_acc: 0.9128\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9118 - val_loss: 0.1818 - val_acc: 0.9128\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18173 to 0.18121, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9105 - val_loss: 0.1812 - val_acc: 0.9138\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9096 - val_loss: 0.1813 - val_acc: 0.9130\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9115 - val_loss: 0.1819 - val_acc: 0.9111\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18121 to 0.18070, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9091 - val_loss: 0.1807 - val_acc: 0.9138\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18070 to 0.18027, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9108 - val_loss: 0.1803 - val_acc: 0.9145\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9109 - val_loss: 0.1803 - val_acc: 0.9153\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9117 - val_loss: 0.1808 - val_acc: 0.9128\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.18027 to 0.18025, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9114 - val_loss: 0.1803 - val_acc: 0.9149\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9121 - val_loss: 0.1803 - val_acc: 0.9142\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18025 to 0.17993, saving model to best.model\n",
      "0s - loss: 0.1857 - acc: 0.9110 - val_loss: 0.1799 - val_acc: 0.9151\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9107 - val_loss: 0.1803 - val_acc: 0.9149\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9126 - val_loss: 0.1800 - val_acc: 0.9149\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9118 - val_loss: 0.1803 - val_acc: 0.9145\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17993 to 0.17979, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9118 - val_loss: 0.1798 - val_acc: 0.9147\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.17979 to 0.17920, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9124 - val_loss: 0.1792 - val_acc: 0.9153\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9126 - val_loss: 0.1797 - val_acc: 0.9151\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.17920 to 0.17919, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9117 - val_loss: 0.1792 - val_acc: 0.9155\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9125 - val_loss: 0.1793 - val_acc: 0.9143\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17919 to 0.17909, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9128 - val_loss: 0.1791 - val_acc: 0.9151\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17909 to 0.17878, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9114 - val_loss: 0.1788 - val_acc: 0.9155\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17878 to 0.17859, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9109 - val_loss: 0.1786 - val_acc: 0.9157\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9114 - val_loss: 0.1786 - val_acc: 0.9147\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.17859 to 0.17856, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9122 - val_loss: 0.1786 - val_acc: 0.9155\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17856 to 0.17782, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9117 - val_loss: 0.1778 - val_acc: 0.9157\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9125 - val_loss: 0.1787 - val_acc: 0.9153\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9111 - val_loss: 0.1796 - val_acc: 0.9151\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9130 - val_loss: 0.1787 - val_acc: 0.9151\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17782 to 0.17758, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9109 - val_loss: 0.1776 - val_acc: 0.9157\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9115 - val_loss: 0.1779 - val_acc: 0.9149\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17758 to 0.17731, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9139 - val_loss: 0.1773 - val_acc: 0.9157\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9120 - val_loss: 0.1787 - val_acc: 0.9157\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9125 - val_loss: 0.1777 - val_acc: 0.9153\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9130 - val_loss: 0.1774 - val_acc: 0.9165\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17731 to 0.17714, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9128 - val_loss: 0.1771 - val_acc: 0.9155\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17714 to 0.17698, saving model to best.model\n",
      "1s - loss: 0.1832 - acc: 0.9138 - val_loss: 0.1770 - val_acc: 0.9153\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17698 to 0.17697, saving model to best.model\n",
      "0s - loss: 0.1820 - acc: 0.9131 - val_loss: 0.1770 - val_acc: 0.9159\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9138 - val_loss: 0.1777 - val_acc: 0.9151\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9129 - val_loss: 0.1775 - val_acc: 0.9159\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9118 - val_loss: 0.1774 - val_acc: 0.9147\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17697 to 0.17680, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9130 - val_loss: 0.1768 - val_acc: 0.9149\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17680 to 0.17660, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9123 - val_loss: 0.1766 - val_acc: 0.9151\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17660 to 0.17659, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9130 - val_loss: 0.1766 - val_acc: 0.9172\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9138 - val_loss: 0.1772 - val_acc: 0.9168\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9141 - val_loss: 0.1767 - val_acc: 0.9170\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17659 to 0.17655, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9141 - val_loss: 0.1765 - val_acc: 0.9155\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9128 - val_loss: 0.1772 - val_acc: 0.9151\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17655 to 0.17595, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9139 - val_loss: 0.1760 - val_acc: 0.9174\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9150 - val_loss: 0.1763 - val_acc: 0.9159\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17595 to 0.17578, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9134 - val_loss: 0.1758 - val_acc: 0.9161\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17578 to 0.17562, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9142 - val_loss: 0.1756 - val_acc: 0.9167\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9146 - val_loss: 0.1757 - val_acc: 0.9174\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9141 - val_loss: 0.1761 - val_acc: 0.9151\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9161 - val_loss: 0.1758 - val_acc: 0.9163\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9143 - val_loss: 0.1758 - val_acc: 0.9165\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17562 to 0.17534, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9150 - val_loss: 0.1753 - val_acc: 0.9168\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17534 to 0.17506, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9146 - val_loss: 0.1751 - val_acc: 0.9165\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9145 - val_loss: 0.1752 - val_acc: 0.9172\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17506 to 0.17495, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9146 - val_loss: 0.1749 - val_acc: 0.9155\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9144 - val_loss: 0.1753 - val_acc: 0.9155\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9128 - val_loss: 0.1750 - val_acc: 0.9155\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17495 to 0.17480, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9146 - val_loss: 0.1748 - val_acc: 0.9178\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17480 to 0.17471, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9152 - val_loss: 0.1747 - val_acc: 0.9161\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17471 to 0.17429, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9160 - val_loss: 0.1743 - val_acc: 0.9172\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9151 - val_loss: 0.1748 - val_acc: 0.9149\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17429 to 0.17427, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9141 - val_loss: 0.1743 - val_acc: 0.9174\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17427 to 0.17426, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9152 - val_loss: 0.1743 - val_acc: 0.9172\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9145 - val_loss: 0.1744 - val_acc: 0.9155\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9160 - val_loss: 0.1758 - val_acc: 0.9161\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9145 - val_loss: 0.1745 - val_acc: 0.9157\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17426 to 0.17405, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9162 - val_loss: 0.1740 - val_acc: 0.9155\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.17405 to 0.17395, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9157 - val_loss: 0.1740 - val_acc: 0.9157\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17395 to 0.17381, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9146 - val_loss: 0.1738 - val_acc: 0.9157\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17381 to 0.17375, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9134 - val_loss: 0.1738 - val_acc: 0.9172\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9163 - val_loss: 0.1742 - val_acc: 0.9163\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9165 - val_loss: 0.1744 - val_acc: 0.9180\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9147 - val_loss: 0.1738 - val_acc: 0.9153\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9147 - val_loss: 0.1741 - val_acc: 0.9157\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9143 - val_loss: 0.1741 - val_acc: 0.9161\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17375 to 0.17353, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9158 - val_loss: 0.1735 - val_acc: 0.9178\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17353 to 0.17346, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9166 - val_loss: 0.1735 - val_acc: 0.9165\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9150 - val_loss: 0.1739 - val_acc: 0.9157\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17346 to 0.17344, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9170 - val_loss: 0.1734 - val_acc: 0.9176\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9165 - val_loss: 0.1738 - val_acc: 0.9149\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9149 - val_loss: 0.1740 - val_acc: 0.9155\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9150 - val_loss: 0.1739 - val_acc: 0.9157\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17344 to 0.17311, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9170 - val_loss: 0.1731 - val_acc: 0.9174\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9175 - val_loss: 0.1737 - val_acc: 0.9151\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9155 - val_loss: 0.1737 - val_acc: 0.9165\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9165 - val_loss: 0.1737 - val_acc: 0.9157\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9157 - val_loss: 0.1734 - val_acc: 0.9155\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17311 to 0.17307, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9169 - val_loss: 0.1731 - val_acc: 0.9170\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9163 - val_loss: 0.1736 - val_acc: 0.9161\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9170 - val_loss: 0.1737 - val_acc: 0.9159\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9160 - val_loss: 0.1733 - val_acc: 0.9157\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9159 - val_loss: 0.1734 - val_acc: 0.9159\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17307 to 0.17288, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9159 - val_loss: 0.1729 - val_acc: 0.9168\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9172 - val_loss: 0.1733 - val_acc: 0.9161\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9166 - val_loss: 0.1734 - val_acc: 0.9174\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9147 - val_loss: 0.1730 - val_acc: 0.9176\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9161 - val_loss: 0.1736 - val_acc: 0.9178\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9164 - val_loss: 0.1731 - val_acc: 0.9170\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9178 - val_loss: 0.1729 - val_acc: 0.9170\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.17288 to 0.17272, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9182 - val_loss: 0.1727 - val_acc: 0.9172\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9186 - val_loss: 0.1729 - val_acc: 0.9168\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9176 - val_loss: 0.1737 - val_acc: 0.9168\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17272 to 0.17253, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9166 - val_loss: 0.1725 - val_acc: 0.9172\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9180 - val_loss: 0.1736 - val_acc: 0.9170\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9169 - val_loss: 0.1735 - val_acc: 0.9161\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17253 to 0.17219, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9179 - val_loss: 0.1722 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9168 - val_loss: 0.1723 - val_acc: 0.9170\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9183 - val_loss: 0.1725 - val_acc: 0.9174\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17219 to 0.17217, saving model to best.model\n",
      "0s - loss: 0.1727 - acc: 0.9174 - val_loss: 0.1722 - val_acc: 0.9168\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9172 - val_loss: 0.1722 - val_acc: 0.9178\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.17217 to 0.17185, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9160 - val_loss: 0.1718 - val_acc: 0.9178\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9168 - val_loss: 0.1728 - val_acc: 0.9161\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9182 - val_loss: 0.1725 - val_acc: 0.9168\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9172 - val_loss: 0.1719 - val_acc: 0.9172\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9176 - val_loss: 0.1719 - val_acc: 0.9174\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9177 - val_loss: 0.1731 - val_acc: 0.9159\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9176 - val_loss: 0.1721 - val_acc: 0.9159\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9177 - val_loss: 0.1728 - val_acc: 0.9165\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9178 - val_loss: 0.1729 - val_acc: 0.9178\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9202 - val_loss: 0.1725 - val_acc: 0.9176\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9177 - val_loss: 0.1720 - val_acc: 0.9163\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9167 - val_loss: 0.1724 - val_acc: 0.9178\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9182 - val_loss: 0.1726 - val_acc: 0.9172\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9192 - val_loss: 0.1720 - val_acc: 0.9168\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9175 - val_loss: 0.1719 - val_acc: 0.9176\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9172 - val_loss: 0.1720 - val_acc: 0.9165\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9184 - val_loss: 0.1729 - val_acc: 0.9174\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9175 - val_loss: 0.1724 - val_acc: 0.9170\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9187 - val_loss: 0.1719 - val_acc: 0.9178\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9180 - val_loss: 0.1724 - val_acc: 0.9180\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.35120, saving model to best.model\n",
      "0s - loss: 0.3989 - acc: 0.8769 - val_loss: 0.3512 - val_acc: 0.8809\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.35120 to 0.26147, saving model to best.model\n",
      "0s - loss: 0.3232 - acc: 0.8875 - val_loss: 0.2615 - val_acc: 0.8961\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26147 to 0.21110, saving model to best.model\n",
      "0s - loss: 0.2535 - acc: 0.8975 - val_loss: 0.2111 - val_acc: 0.9063\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21110 to 0.19829, saving model to best.model\n",
      "0s - loss: 0.2243 - acc: 0.9040 - val_loss: 0.1983 - val_acc: 0.9120\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19829 to 0.19310, saving model to best.model\n",
      "0s - loss: 0.2139 - acc: 0.9077 - val_loss: 0.1931 - val_acc: 0.9138\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19310 to 0.19097, saving model to best.model\n",
      "0s - loss: 0.2070 - acc: 0.9068 - val_loss: 0.1910 - val_acc: 0.9136\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19097 to 0.19024, saving model to best.model\n",
      "0s - loss: 0.2025 - acc: 0.9083 - val_loss: 0.1902 - val_acc: 0.9138\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9100 - val_loss: 0.1942 - val_acc: 0.9134\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19024 to 0.18979, saving model to best.model\n",
      "0s - loss: 0.1991 - acc: 0.9102 - val_loss: 0.1898 - val_acc: 0.9153\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18979 to 0.18943, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9099 - val_loss: 0.1894 - val_acc: 0.9163\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.18943 to 0.18937, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9097 - val_loss: 0.1894 - val_acc: 0.9167\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9098 - val_loss: 0.1894 - val_acc: 0.9136\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18937 to 0.18927, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9103 - val_loss: 0.1893 - val_acc: 0.9142\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18927 to 0.18826, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9108 - val_loss: 0.1883 - val_acc: 0.9182\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.18826 to 0.18812, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9116 - val_loss: 0.1881 - val_acc: 0.9188\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.18812 to 0.18778, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9110 - val_loss: 0.1878 - val_acc: 0.9178\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18778 to 0.18755, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9104 - val_loss: 0.1875 - val_acc: 0.9174\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.18755 to 0.18700, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9127 - val_loss: 0.1870 - val_acc: 0.9186\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9126 - val_loss: 0.1875 - val_acc: 0.9190\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1928 - acc: 0.9110 - val_loss: 0.1871 - val_acc: 0.9159\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9117 - val_loss: 0.1878 - val_acc: 0.9147\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18700 to 0.18618, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9116 - val_loss: 0.1862 - val_acc: 0.9165\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18618 to 0.18542, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9136 - val_loss: 0.1854 - val_acc: 0.9182\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9142 - val_loss: 0.1861 - val_acc: 0.9157\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18542 to 0.18531, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9120 - val_loss: 0.1853 - val_acc: 0.9170\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9116 - val_loss: 0.1863 - val_acc: 0.9147\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18531 to 0.18504, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9123 - val_loss: 0.1850 - val_acc: 0.9180\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18504 to 0.18437, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9121 - val_loss: 0.1844 - val_acc: 0.9174\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9125 - val_loss: 0.1849 - val_acc: 0.9161\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18437 to 0.18432, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9148 - val_loss: 0.1843 - val_acc: 0.9174\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9126 - val_loss: 0.1851 - val_acc: 0.9155\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9136 - val_loss: 0.1866 - val_acc: 0.9151\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9137 - val_loss: 0.1845 - val_acc: 0.9167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9154 - val_loss: 0.1848 - val_acc: 0.9168\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18432 to 0.18367, saving model to best.model\n",
      "0s - loss: 0.1869 - acc: 0.9134 - val_loss: 0.1837 - val_acc: 0.9180\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1847 - acc: 0.9145 - val_loss: 0.1847 - val_acc: 0.9155\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9128 - val_loss: 0.1852 - val_acc: 0.9161\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18367 to 0.18323, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9133 - val_loss: 0.1832 - val_acc: 0.9186\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18323 to 0.18311, saving model to best.model\n",
      "0s - loss: 0.1852 - acc: 0.9141 - val_loss: 0.1831 - val_acc: 0.9184\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9140 - val_loss: 0.1841 - val_acc: 0.9161\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18311 to 0.18301, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9144 - val_loss: 0.1830 - val_acc: 0.9186\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9143 - val_loss: 0.1840 - val_acc: 0.9176\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18301 to 0.18223, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9138 - val_loss: 0.1822 - val_acc: 0.9176\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9149 - val_loss: 0.1845 - val_acc: 0.9136\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9143 - val_loss: 0.1824 - val_acc: 0.9180\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18223 to 0.18177, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9159 - val_loss: 0.1818 - val_acc: 0.9176\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18177 to 0.18171, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9158 - val_loss: 0.1817 - val_acc: 0.9190\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9147 - val_loss: 0.1824 - val_acc: 0.9174\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9161 - val_loss: 0.1823 - val_acc: 0.9163\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18171 to 0.18168, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9149 - val_loss: 0.1817 - val_acc: 0.9180\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9159 - val_loss: 0.1824 - val_acc: 0.9172\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9157 - val_loss: 0.1828 - val_acc: 0.9170\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18168 to 0.18064, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9149 - val_loss: 0.1806 - val_acc: 0.9195\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9153 - val_loss: 0.1811 - val_acc: 0.9170\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9166 - val_loss: 0.1814 - val_acc: 0.9172\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9170 - val_loss: 0.1816 - val_acc: 0.9180\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9176 - val_loss: 0.1821 - val_acc: 0.9170\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18064 to 0.18029, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9164 - val_loss: 0.1803 - val_acc: 0.9176\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18029 to 0.18018, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9167 - val_loss: 0.1802 - val_acc: 0.9176\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9160 - val_loss: 0.1816 - val_acc: 0.9170\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18018 to 0.17952, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9158 - val_loss: 0.1795 - val_acc: 0.9184\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.17952 to 0.17920, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9162 - val_loss: 0.1792 - val_acc: 0.9165\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9169 - val_loss: 0.1806 - val_acc: 0.9170\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17920 to 0.17917, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9169 - val_loss: 0.1792 - val_acc: 0.9170\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9175 - val_loss: 0.1806 - val_acc: 0.9167\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9167 - val_loss: 0.1806 - val_acc: 0.9170\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9160 - val_loss: 0.1801 - val_acc: 0.9170\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9184 - val_loss: 0.1796 - val_acc: 0.9180\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1797 - val_acc: 0.9172\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9171 - val_loss: 0.1817 - val_acc: 0.9165\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9173 - val_loss: 0.1795 - val_acc: 0.9176\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9183 - val_loss: 0.1818 - val_acc: 0.9172\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9175 - val_loss: 0.1802 - val_acc: 0.9182\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9179 - val_loss: 0.1803 - val_acc: 0.9174\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17917 to 0.17889, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9165 - val_loss: 0.1789 - val_acc: 0.9167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9171 - val_loss: 0.1800 - val_acc: 0.9176\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9171 - val_loss: 0.1790 - val_acc: 0.9165\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17889 to 0.17832, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9189 - val_loss: 0.1783 - val_acc: 0.9172\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9183 - val_loss: 0.1799 - val_acc: 0.9176\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9180 - val_loss: 0.1795 - val_acc: 0.9180\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9163 - val_loss: 0.1796 - val_acc: 0.9182\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9178 - val_loss: 0.1797 - val_acc: 0.9178\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9176 - val_loss: 0.1793 - val_acc: 0.9186\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1770 - acc: 0.9177 - val_loss: 0.1808 - val_acc: 0.9176\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9187 - val_loss: 0.1814 - val_acc: 0.9180\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9186 - val_loss: 0.1787 - val_acc: 0.9178\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17832 to 0.17783, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9191 - val_loss: 0.1778 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9181 - val_loss: 0.1779 - val_acc: 0.9167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17783 to 0.17755, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9189 - val_loss: 0.1775 - val_acc: 0.9167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9179 - val_loss: 0.1792 - val_acc: 0.9178\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9188 - val_loss: 0.1777 - val_acc: 0.9168\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9186 - val_loss: 0.1784 - val_acc: 0.9190\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.17755 to 0.17747, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9181 - val_loss: 0.1775 - val_acc: 0.9159\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17747 to 0.17699, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9187 - val_loss: 0.1770 - val_acc: 0.9170\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.17699 to 0.17677, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9197 - val_loss: 0.1768 - val_acc: 0.9174\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9181 - val_loss: 0.1778 - val_acc: 0.9176\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9189 - val_loss: 0.1785 - val_acc: 0.9176\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9198 - val_loss: 0.1774 - val_acc: 0.9178\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17677 to 0.17665, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9188 - val_loss: 0.1766 - val_acc: 0.9170\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9187 - val_loss: 0.1784 - val_acc: 0.9176\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9197 - val_loss: 0.1778 - val_acc: 0.9184\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17665 to 0.17658, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9189 - val_loss: 0.1766 - val_acc: 0.9176\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9191 - val_loss: 0.1778 - val_acc: 0.9184\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17658 to 0.17657, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9189 - val_loss: 0.1766 - val_acc: 0.9180\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9194 - val_loss: 0.1770 - val_acc: 0.9176\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9210 - val_loss: 0.1769 - val_acc: 0.9186\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17657 to 0.17588, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9194 - val_loss: 0.1759 - val_acc: 0.9174\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9184 - val_loss: 0.1761 - val_acc: 0.9180\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9186 - val_loss: 0.1766 - val_acc: 0.9184\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9226 - val_loss: 0.1772 - val_acc: 0.9176\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.17588 to 0.17560, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9220 - val_loss: 0.1756 - val_acc: 0.9195\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9212 - val_loss: 0.1768 - val_acc: 0.9188\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9218 - val_loss: 0.1756 - val_acc: 0.9188\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9211 - val_loss: 0.1756 - val_acc: 0.9186\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9204 - val_loss: 0.1757 - val_acc: 0.9186\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17560 to 0.17559, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9208 - val_loss: 0.1756 - val_acc: 0.9186\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9186 - val_loss: 0.1759 - val_acc: 0.9190\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17559 to 0.17544, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9212 - val_loss: 0.1754 - val_acc: 0.9190\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9210 - val_loss: 0.1766 - val_acc: 0.9191\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9197 - val_loss: 0.1766 - val_acc: 0.9199\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9196 - val_loss: 0.1762 - val_acc: 0.9195\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9206 - val_loss: 0.1756 - val_acc: 0.9195\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17544 to 0.17443, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9211 - val_loss: 0.1744 - val_acc: 0.9195\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9209 - val_loss: 0.1758 - val_acc: 0.9197\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9211 - val_loss: 0.1769 - val_acc: 0.9193\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9209 - val_loss: 0.1759 - val_acc: 0.9193\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9190 - val_loss: 0.1753 - val_acc: 0.9195\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9218 - val_loss: 0.1752 - val_acc: 0.9191\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9208 - val_loss: 0.1752 - val_acc: 0.9205\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.17443 to 0.17410, saving model to best.model\n",
      "0s - loss: 0.1712 - acc: 0.9223 - val_loss: 0.1741 - val_acc: 0.9201\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9206 - val_loss: 0.1754 - val_acc: 0.9205\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9207 - val_loss: 0.1753 - val_acc: 0.9203\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9210 - val_loss: 0.1748 - val_acc: 0.9205\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9215 - val_loss: 0.1746 - val_acc: 0.9203\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9214 - val_loss: 0.1761 - val_acc: 0.9195\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9210 - val_loss: 0.1745 - val_acc: 0.9203\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17410 to 0.17315, saving model to best.model\n",
      "0s - loss: 0.1705 - acc: 0.9202 - val_loss: 0.1732 - val_acc: 0.9211\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9195 - val_loss: 0.1738 - val_acc: 0.9211\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9210 - val_loss: 0.1743 - val_acc: 0.9203\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9217 - val_loss: 0.1734 - val_acc: 0.9215\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9206 - val_loss: 0.1757 - val_acc: 0.9199\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9222 - val_loss: 0.1744 - val_acc: 0.9191\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17315 to 0.17303, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9202 - val_loss: 0.1730 - val_acc: 0.9213\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9226 - val_loss: 0.1752 - val_acc: 0.9209\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9200 - val_loss: 0.1739 - val_acc: 0.9215\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9223 - val_loss: 0.1742 - val_acc: 0.9218\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9208 - val_loss: 0.1749 - val_acc: 0.9218\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9216 - val_loss: 0.1775 - val_acc: 0.9199\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9210 - val_loss: 0.1738 - val_acc: 0.9224\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9222 - val_loss: 0.1754 - val_acc: 0.9195\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9218 - val_loss: 0.1750 - val_acc: 0.9213\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9214 - val_loss: 0.1745 - val_acc: 0.9224\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9219 - val_loss: 0.1749 - val_acc: 0.9215\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9226 - val_loss: 0.1744 - val_acc: 0.9215\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9224 - val_loss: 0.1736 - val_acc: 0.9215\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9221 - val_loss: 0.1739 - val_acc: 0.9234\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9225 - val_loss: 0.1732 - val_acc: 0.9228\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9226 - val_loss: 0.1734 - val_acc: 0.9232\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9232 - val_loss: 0.1731 - val_acc: 0.9234\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9224 - val_loss: 0.1740 - val_acc: 0.9220\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.17303 to 0.17232, saving model to best.model\n",
      "0s - loss: 0.1679 - acc: 0.9211 - val_loss: 0.1723 - val_acc: 0.9234\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1663 - acc: 0.9223 - val_loss: 0.1725 - val_acc: 0.9234\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17232 to 0.17229, saving model to best.model\n",
      "0s - loss: 0.1670 - acc: 0.9222 - val_loss: 0.1723 - val_acc: 0.9238\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.17229 to 0.17206, saving model to best.model\n",
      "0s - loss: 0.1691 - acc: 0.9219 - val_loss: 0.1721 - val_acc: 0.9230\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17206 to 0.17179, saving model to best.model\n",
      "0s - loss: 0.1684 - acc: 0.9220 - val_loss: 0.1718 - val_acc: 0.9236\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1648 - acc: 0.9228 - val_loss: 0.1726 - val_acc: 0.9236\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17179 to 0.17156, saving model to best.model\n",
      "0s - loss: 0.1662 - acc: 0.9235 - val_loss: 0.1716 - val_acc: 0.9234\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9221 - val_loss: 0.1731 - val_acc: 0.9241\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9221 - val_loss: 0.1731 - val_acc: 0.9226\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1657 - acc: 0.9241 - val_loss: 0.1745 - val_acc: 0.9236\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1656 - acc: 0.9248 - val_loss: 0.1727 - val_acc: 0.9234\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9228 - val_loss: 0.1727 - val_acc: 0.9239\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1660 - acc: 0.9230 - val_loss: 0.1718 - val_acc: 0.9238\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1649 - acc: 0.9238 - val_loss: 0.1719 - val_acc: 0.9236\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9235 - val_loss: 0.1717 - val_acc: 0.9239\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1656 - acc: 0.9235 - val_loss: 0.1725 - val_acc: 0.9222\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1660 - acc: 0.9211 - val_loss: 0.1736 - val_acc: 0.9226\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1650 - acc: 0.9236 - val_loss: 0.1718 - val_acc: 0.9228\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1653 - acc: 0.9242 - val_loss: 0.1727 - val_acc: 0.9234\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9237 - val_loss: 0.1724 - val_acc: 0.9234\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1650 - acc: 0.9232 - val_loss: 0.1727 - val_acc: 0.9243\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1657 - acc: 0.9229 - val_loss: 0.1719 - val_acc: 0.9238\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17156 to 0.17062, saving model to best.model\n",
      "0s - loss: 0.1645 - acc: 0.9238 - val_loss: 0.1706 - val_acc: 0.9236\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1633 - acc: 0.9239 - val_loss: 0.1717 - val_acc: 0.9241\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1629 - acc: 0.9240 - val_loss: 0.1715 - val_acc: 0.9238\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1655 - acc: 0.9217 - val_loss: 0.1721 - val_acc: 0.9239\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1656 - acc: 0.9232 - val_loss: 0.1711 - val_acc: 0.9230\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1633 - acc: 0.9243 - val_loss: 0.1717 - val_acc: 0.9243\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1637 - acc: 0.9248 - val_loss: 0.1712 - val_acc: 0.9239\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9226 - val_loss: 0.1710 - val_acc: 0.9241\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1650 - acc: 0.9243 - val_loss: 0.1713 - val_acc: 0.9236\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1636 - acc: 0.9242 - val_loss: 0.1724 - val_acc: 0.9241\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1630 - acc: 0.9241 - val_loss: 0.1713 - val_acc: 0.9241\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1637 - acc: 0.9232 - val_loss: 0.1713 - val_acc: 0.9245\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1637 - acc: 0.9234 - val_loss: 0.1714 - val_acc: 0.9245\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.17062 to 0.17054, saving model to best.model\n",
      "0s - loss: 0.1618 - acc: 0.9238 - val_loss: 0.1705 - val_acc: 0.9245\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1635 - acc: 0.9245 - val_loss: 0.1724 - val_acc: 0.9238\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.17054 to 0.17009, saving model to best.model\n",
      "0s - loss: 0.1628 - acc: 0.9246 - val_loss: 0.1701 - val_acc: 0.9251\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1630 - acc: 0.9247 - val_loss: 0.1715 - val_acc: 0.9249\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1624 - acc: 0.9245 - val_loss: 0.1708 - val_acc: 0.9247\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33853, saving model to best.model\n",
      "0s - loss: 0.4402 - acc: 0.8507 - val_loss: 0.3385 - val_acc: 0.8886\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33853 to 0.28097, saving model to best.model\n",
      "0s - loss: 0.3449 - acc: 0.8873 - val_loss: 0.2810 - val_acc: 0.8886\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.28097 to 0.22355, saving model to best.model\n",
      "0s - loss: 0.2831 - acc: 0.8917 - val_loss: 0.2236 - val_acc: 0.9011\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22355 to 0.19747, saving model to best.model\n",
      "0s - loss: 0.2420 - acc: 0.8991 - val_loss: 0.1975 - val_acc: 0.9086\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19747 to 0.18873, saving model to best.model\n",
      "0s - loss: 0.2255 - acc: 0.9026 - val_loss: 0.1887 - val_acc: 0.9088\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18873 to 0.18642, saving model to best.model\n",
      "0s - loss: 0.2172 - acc: 0.9045 - val_loss: 0.1864 - val_acc: 0.9120\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18642 to 0.18560, saving model to best.model\n",
      "0s - loss: 0.2115 - acc: 0.9023 - val_loss: 0.1856 - val_acc: 0.9103\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18560 to 0.18404, saving model to best.model\n",
      "0s - loss: 0.2081 - acc: 0.9058 - val_loss: 0.1840 - val_acc: 0.9103\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18404 to 0.18353, saving model to best.model\n",
      "0s - loss: 0.2032 - acc: 0.9067 - val_loss: 0.1835 - val_acc: 0.9103\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.18353 to 0.18317, saving model to best.model\n",
      "0s - loss: 0.2025 - acc: 0.9060 - val_loss: 0.1832 - val_acc: 0.9094\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2012 - acc: 0.9067 - val_loss: 0.1834 - val_acc: 0.9111\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1992 - acc: 0.9071 - val_loss: 0.1833 - val_acc: 0.9097\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.18317 to 0.18304, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9079 - val_loss: 0.1830 - val_acc: 0.9095\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1986 - acc: 0.9062 - val_loss: 0.1831 - val_acc: 0.9109\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.18304 to 0.18268, saving model to best.model\n",
      "0s - loss: 0.1943 - acc: 0.9085 - val_loss: 0.1827 - val_acc: 0.9097\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1970 - acc: 0.9075 - val_loss: 0.1830 - val_acc: 0.9099\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1952 - acc: 0.9085 - val_loss: 0.1842 - val_acc: 0.9082\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1961 - acc: 0.9084 - val_loss: 0.1836 - val_acc: 0.9088\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9081 - val_loss: 0.1827 - val_acc: 0.9097\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9082 - val_loss: 0.1828 - val_acc: 0.9076\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1950 - acc: 0.9102 - val_loss: 0.1829 - val_acc: 0.9124\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1933 - acc: 0.9082 - val_loss: 0.1828 - val_acc: 0.9076\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18268 to 0.18252, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9090 - val_loss: 0.1825 - val_acc: 0.9097\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9100 - val_loss: 0.1825 - val_acc: 0.9099\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18252 to 0.18200, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9099 - val_loss: 0.1820 - val_acc: 0.9122\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9096 - val_loss: 0.1821 - val_acc: 0.9101\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1914 - acc: 0.9109 - val_loss: 0.1828 - val_acc: 0.9117\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18200 to 0.18162, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9107 - val_loss: 0.1816 - val_acc: 0.9103\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9104 - val_loss: 0.1817 - val_acc: 0.9103\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18162 to 0.18147, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9107 - val_loss: 0.1815 - val_acc: 0.9111\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9126 - val_loss: 0.1815 - val_acc: 0.9124\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18147 to 0.18139, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9106 - val_loss: 0.1814 - val_acc: 0.9101\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9109 - val_loss: 0.1817 - val_acc: 0.9111\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9116 - val_loss: 0.1821 - val_acc: 0.9107\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18139 to 0.18099, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9121 - val_loss: 0.1810 - val_acc: 0.9120\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9094 - val_loss: 0.1811 - val_acc: 0.9111\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18099 to 0.18069, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9100 - val_loss: 0.1807 - val_acc: 0.9118\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18069 to 0.18062, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9097 - val_loss: 0.1806 - val_acc: 0.9107\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18062 to 0.18054, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9115 - val_loss: 0.1805 - val_acc: 0.9107\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18054 to 0.18039, saving model to best.model\n",
      "0s - loss: 0.1886 - acc: 0.9127 - val_loss: 0.1804 - val_acc: 0.9115\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9121 - val_loss: 0.1805 - val_acc: 0.9117\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9109 - val_loss: 0.1804 - val_acc: 0.9111\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18039 to 0.18010, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9126 - val_loss: 0.1801 - val_acc: 0.9115\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18010 to 0.18010, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9137 - val_loss: 0.1801 - val_acc: 0.9124\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18010 to 0.17998, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9115 - val_loss: 0.1800 - val_acc: 0.9120\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9122 - val_loss: 0.1802 - val_acc: 0.9117\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9114 - val_loss: 0.1804 - val_acc: 0.9126\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17998 to 0.17998, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9130 - val_loss: 0.1800 - val_acc: 0.9117\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17998 to 0.17978, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9128 - val_loss: 0.1798 - val_acc: 0.9130\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17978 to 0.17959, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9122 - val_loss: 0.1796 - val_acc: 0.9118\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.17959 to 0.17944, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9129 - val_loss: 0.1794 - val_acc: 0.9134\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9138 - val_loss: 0.1796 - val_acc: 0.9149\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.17944 to 0.17936, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9133 - val_loss: 0.1794 - val_acc: 0.9147\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9131 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9131 - val_loss: 0.1802 - val_acc: 0.9120\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9123 - val_loss: 0.1796 - val_acc: 0.9151\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9129 - val_loss: 0.1800 - val_acc: 0.9155\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.17936 to 0.17911, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9141 - val_loss: 0.1791 - val_acc: 0.9143\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.17911 to 0.17908, saving model to best.model\n",
      "0s - loss: 0.1849 - acc: 0.9126 - val_loss: 0.1791 - val_acc: 0.9147\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9134 - val_loss: 0.1791 - val_acc: 0.9147\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.17908 to 0.17884, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9150 - val_loss: 0.1788 - val_acc: 0.9145\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9128 - val_loss: 0.1790 - val_acc: 0.9149\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9146 - val_loss: 0.1789 - val_acc: 0.9126\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9139 - val_loss: 0.1790 - val_acc: 0.9145\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9144 - val_loss: 0.1790 - val_acc: 0.9147\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9139 - val_loss: 0.1790 - val_acc: 0.9145\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.17884 to 0.17869, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9142 - val_loss: 0.1787 - val_acc: 0.9153\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9141 - val_loss: 0.1791 - val_acc: 0.9157\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.17869 to 0.17861, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9144 - val_loss: 0.1786 - val_acc: 0.9155\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9132 - val_loss: 0.1789 - val_acc: 0.9151\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9150 - val_loss: 0.1788 - val_acc: 0.9151\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9148 - val_loss: 0.1790 - val_acc: 0.9161\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9150 - val_loss: 0.1801 - val_acc: 0.9153\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.17861 to 0.17848, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9150 - val_loss: 0.1785 - val_acc: 0.9155\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9141 - val_loss: 0.1785 - val_acc: 0.9159\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9139 - val_loss: 0.1789 - val_acc: 0.9153\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.17848 to 0.17845, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9163 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17845 to 0.17823, saving model to best.model\n",
      "0s - loss: 0.1807 - acc: 0.9162 - val_loss: 0.1782 - val_acc: 0.9161\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9147 - val_loss: 0.1784 - val_acc: 0.9159\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9151 - val_loss: 0.1785 - val_acc: 0.9151\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9154 - val_loss: 0.1783 - val_acc: 0.9151\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9167 - val_loss: 0.1787 - val_acc: 0.9161\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.17823 to 0.17788, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9168 - val_loss: 0.1779 - val_acc: 0.9151\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9162 - val_loss: 0.1779 - val_acc: 0.9153\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9147 - val_loss: 0.1781 - val_acc: 0.9165\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.17788 to 0.17788, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9140 - val_loss: 0.1779 - val_acc: 0.9149\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9165 - val_loss: 0.1780 - val_acc: 0.9155\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17788 to 0.17766, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9161 - val_loss: 0.1777 - val_acc: 0.9147\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9155 - val_loss: 0.1784 - val_acc: 0.9132\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9145 - val_loss: 0.1779 - val_acc: 0.9163\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9160 - val_loss: 0.1785 - val_acc: 0.9159\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.17766 to 0.17763, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9158 - val_loss: 0.1776 - val_acc: 0.9159\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9148 - val_loss: 0.1777 - val_acc: 0.9151\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9159 - val_loss: 0.1780 - val_acc: 0.9153\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9164 - val_loss: 0.1783 - val_acc: 0.9163\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17763 to 0.17756, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9171 - val_loss: 0.1776 - val_acc: 0.9165\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9152 - val_loss: 0.1776 - val_acc: 0.9149\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9175 - val_loss: 0.1776 - val_acc: 0.9172\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17756 to 0.17734, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9168 - val_loss: 0.1773 - val_acc: 0.9157\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9164 - val_loss: 0.1774 - val_acc: 0.9149\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17734 to 0.17727, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9171 - val_loss: 0.1773 - val_acc: 0.9151\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17727 to 0.17721, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9168 - val_loss: 0.1772 - val_acc: 0.9149\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9181 - val_loss: 0.1773 - val_acc: 0.9157\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9165 - val_loss: 0.1773 - val_acc: 0.9170\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9167 - val_loss: 0.1774 - val_acc: 0.9149\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9175 - val_loss: 0.1774 - val_acc: 0.9172\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9174 - val_loss: 0.1774 - val_acc: 0.9153\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17721 to 0.17685, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9177 - val_loss: 0.1768 - val_acc: 0.9153\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.17685 to 0.17677, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9165 - val_loss: 0.1768 - val_acc: 0.9153\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9175 - val_loss: 0.1768 - val_acc: 0.9149\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9177 - val_loss: 0.1770 - val_acc: 0.9149\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17677 to 0.17654, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9167 - val_loss: 0.1765 - val_acc: 0.9151\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9173 - val_loss: 0.1768 - val_acc: 0.9149\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9179 - val_loss: 0.1767 - val_acc: 0.9155\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9175 - val_loss: 0.1767 - val_acc: 0.9165\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17654 to 0.17654, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9181 - val_loss: 0.1765 - val_acc: 0.9157\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9181 - val_loss: 0.1770 - val_acc: 0.9159\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9165 - val_loss: 0.1766 - val_acc: 0.9157\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17654 to 0.17651, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9183 - val_loss: 0.1765 - val_acc: 0.9161\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9175 - val_loss: 0.1769 - val_acc: 0.9167\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9175 - val_loss: 0.1770 - val_acc: 0.9165\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9177 - val_loss: 0.1768 - val_acc: 0.9170\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9175 - val_loss: 0.1767 - val_acc: 0.9161\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17651 to 0.17644, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9188 - val_loss: 0.1764 - val_acc: 0.9149\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9175 - val_loss: 0.1769 - val_acc: 0.9153\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17644 to 0.17629, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9176 - val_loss: 0.1763 - val_acc: 0.9168\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9183 - val_loss: 0.1764 - val_acc: 0.9159\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17629 to 0.17624, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9179 - val_loss: 0.1762 - val_acc: 0.9151\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9192 - val_loss: 0.1763 - val_acc: 0.9155\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9187 - val_loss: 0.1763 - val_acc: 0.9159\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17624 to 0.17613, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9192 - val_loss: 0.1761 - val_acc: 0.9172\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9193 - val_loss: 0.1763 - val_acc: 0.9157\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17613 to 0.17587, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9188 - val_loss: 0.1759 - val_acc: 0.9155\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9189 - val_loss: 0.1760 - val_acc: 0.9172\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9192 - val_loss: 0.1762 - val_acc: 0.9151\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17587 to 0.17584, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9201 - val_loss: 0.1758 - val_acc: 0.9161\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17584 to 0.17549, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9179 - val_loss: 0.1755 - val_acc: 0.9168\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9188 - val_loss: 0.1756 - val_acc: 0.9174\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9199 - val_loss: 0.1760 - val_acc: 0.9157\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9186 - val_loss: 0.1760 - val_acc: 0.9163\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9190 - val_loss: 0.1760 - val_acc: 0.9174\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9213 - val_loss: 0.1756 - val_acc: 0.9165\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9186 - val_loss: 0.1759 - val_acc: 0.9159\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9208 - val_loss: 0.1759 - val_acc: 0.9159\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9196 - val_loss: 0.1764 - val_acc: 0.9172\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9192 - val_loss: 0.1756 - val_acc: 0.9167\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17549 to 0.17536, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9199 - val_loss: 0.1754 - val_acc: 0.9163\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9187 - val_loss: 0.1755 - val_acc: 0.9172\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9176 - val_loss: 0.1762 - val_acc: 0.9149\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9190 - val_loss: 0.1755 - val_acc: 0.9153\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9180 - val_loss: 0.1759 - val_acc: 0.9178\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17536 to 0.17528, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9198 - val_loss: 0.1753 - val_acc: 0.9165\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.17528 to 0.17510, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9195 - val_loss: 0.1751 - val_acc: 0.9167\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9201 - val_loss: 0.1753 - val_acc: 0.9168\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9191 - val_loss: 0.1760 - val_acc: 0.9170\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9180 - val_loss: 0.1757 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9195 - val_loss: 0.1752 - val_acc: 0.9157\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17510 to 0.17505, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9205 - val_loss: 0.1750 - val_acc: 0.9165\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9205 - val_loss: 0.1753 - val_acc: 0.9172\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9209 - val_loss: 0.1759 - val_acc: 0.9151\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9195 - val_loss: 0.1752 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9208 - val_loss: 0.1752 - val_acc: 0.9172\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17505 to 0.17504, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9214 - val_loss: 0.1750 - val_acc: 0.9161\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.17504 to 0.17497, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9182 - val_loss: 0.1750 - val_acc: 0.9155\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9199 - val_loss: 0.1752 - val_acc: 0.9165\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9205 - val_loss: 0.1751 - val_acc: 0.9155\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17497 to 0.17484, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9199 - val_loss: 0.1748 - val_acc: 0.9165\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9214 - val_loss: 0.1750 - val_acc: 0.9174\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9207 - val_loss: 0.1751 - val_acc: 0.9151\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9205 - val_loss: 0.1751 - val_acc: 0.9149\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17484 to 0.17459, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9193 - val_loss: 0.1746 - val_acc: 0.9157\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.17459 to 0.17446, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9187 - val_loss: 0.1745 - val_acc: 0.9167\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9192 - val_loss: 0.1751 - val_acc: 0.9143\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.17446 to 0.17446, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9197 - val_loss: 0.1745 - val_acc: 0.9149\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9205 - val_loss: 0.1746 - val_acc: 0.9167\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17446 to 0.17407, saving model to best.model\n",
      "1s - loss: 0.1704 - acc: 0.9211 - val_loss: 0.1741 - val_acc: 0.9161\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9201 - val_loss: 0.1744 - val_acc: 0.9153\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.17407 to 0.17392, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9196 - val_loss: 0.1739 - val_acc: 0.9153\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9210 - val_loss: 0.1741 - val_acc: 0.9168\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9212 - val_loss: 0.1746 - val_acc: 0.9170\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9215 - val_loss: 0.1744 - val_acc: 0.9168\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9214 - val_loss: 0.1743 - val_acc: 0.9151\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9208 - val_loss: 0.1744 - val_acc: 0.9161\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9212 - val_loss: 0.1743 - val_acc: 0.9147\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9230 - val_loss: 0.1748 - val_acc: 0.9168\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9200 - val_loss: 0.1745 - val_acc: 0.9155\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9195 - val_loss: 0.1740 - val_acc: 0.9153\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9214 - val_loss: 0.1747 - val_acc: 0.9165\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9221 - val_loss: 0.1743 - val_acc: 0.9153\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9212 - val_loss: 0.1744 - val_acc: 0.9151\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9208 - val_loss: 0.1741 - val_acc: 0.9167\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9208 - val_loss: 0.1746 - val_acc: 0.9155\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9216 - val_loss: 0.1751 - val_acc: 0.9157\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9219 - val_loss: 0.1745 - val_acc: 0.9163\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9215 - val_loss: 0.1742 - val_acc: 0.9161\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9212 - val_loss: 0.1744 - val_acc: 0.9165\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9218 - val_loss: 0.1748 - val_acc: 0.9157\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.17392 to 0.17351, saving model to best.model\n",
      "0s - loss: 0.1690 - acc: 0.9208 - val_loss: 0.1735 - val_acc: 0.9163\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9206 - val_loss: 0.1741 - val_acc: 0.9163\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9219 - val_loss: 0.1738 - val_acc: 0.9163\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33784, saving model to best.model\n",
      "0s - loss: 0.3908 - acc: 0.8806 - val_loss: 0.3378 - val_acc: 0.8838\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33784 to 0.26925, saving model to best.model\n",
      "0s - loss: 0.3163 - acc: 0.8881 - val_loss: 0.2693 - val_acc: 0.8930\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26925 to 0.22594, saving model to best.model\n",
      "0s - loss: 0.2550 - acc: 0.8955 - val_loss: 0.2259 - val_acc: 0.8990\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.22594 to 0.21278, saving model to best.model\n",
      "0s - loss: 0.2273 - acc: 0.9022 - val_loss: 0.2128 - val_acc: 0.9005\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.21278 to 0.20840, saving model to best.model\n",
      "0s - loss: 0.2183 - acc: 0.9013 - val_loss: 0.2084 - val_acc: 0.9019\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20840 to 0.20594, saving model to best.model\n",
      "0s - loss: 0.2126 - acc: 0.9031 - val_loss: 0.2059 - val_acc: 0.9009\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.2064 - acc: 0.9062 - val_loss: 0.2079 - val_acc: 0.9021\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.20594 to 0.20455, saving model to best.model\n",
      "0s - loss: 0.2065 - acc: 0.9054 - val_loss: 0.2046 - val_acc: 0.9017\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2014 - acc: 0.9067 - val_loss: 0.2048 - val_acc: 0.9009\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.20455 to 0.20359, saving model to best.model\n",
      "0s - loss: 0.2015 - acc: 0.9065 - val_loss: 0.2036 - val_acc: 0.9015\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.20359 to 0.20343, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9067 - val_loss: 0.2034 - val_acc: 0.9015\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1981 - acc: 0.9065 - val_loss: 0.2045 - val_acc: 0.8976\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9075 - val_loss: 0.2039 - val_acc: 0.9019\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9078 - val_loss: 0.2052 - val_acc: 0.9011\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.20343 to 0.20255, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9064 - val_loss: 0.2026 - val_acc: 0.9032\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1973 - acc: 0.9079 - val_loss: 0.2032 - val_acc: 0.9013\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.20255 to 0.20246, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9079 - val_loss: 0.2025 - val_acc: 0.9026\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1968 - acc: 0.9084 - val_loss: 0.2025 - val_acc: 0.9021\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1973 - acc: 0.9080 - val_loss: 0.2028 - val_acc: 0.9021\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9090 - val_loss: 0.2026 - val_acc: 0.9007\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.20246 to 0.20144, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9084 - val_loss: 0.2014 - val_acc: 0.9021\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.20144 to 0.20104, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9078 - val_loss: 0.2010 - val_acc: 0.9022\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20104 to 0.20101, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9067 - val_loss: 0.2010 - val_acc: 0.9003\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9079 - val_loss: 0.2015 - val_acc: 0.9013\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20101 to 0.20052, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9089 - val_loss: 0.2005 - val_acc: 0.9011\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9098 - val_loss: 0.2009 - val_acc: 0.9015\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20052 to 0.20009, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9097 - val_loss: 0.2001 - val_acc: 0.8999\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20009 to 0.20007, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9112 - val_loss: 0.2001 - val_acc: 0.9009\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20007 to 0.19971, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9090 - val_loss: 0.1997 - val_acc: 0.9047\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9101 - val_loss: 0.2008 - val_acc: 0.9040\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9095 - val_loss: 0.2009 - val_acc: 0.9049\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9108 - val_loss: 0.1998 - val_acc: 0.9044\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9085 - val_loss: 0.2003 - val_acc: 0.9051\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19971 to 0.19946, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9105 - val_loss: 0.1995 - val_acc: 0.9024\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19946 to 0.19930, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9081 - val_loss: 0.1993 - val_acc: 0.9046\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19930 to 0.19853, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9112 - val_loss: 0.1985 - val_acc: 0.9036\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19853 to 0.19843, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9094 - val_loss: 0.1984 - val_acc: 0.9040\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9102 - val_loss: 0.1989 - val_acc: 0.9040\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9120 - val_loss: 0.1985 - val_acc: 0.9042\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19843 to 0.19835, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9109 - val_loss: 0.1983 - val_acc: 0.9038\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9099 - val_loss: 0.1987 - val_acc: 0.9036\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19835 to 0.19751, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9108 - val_loss: 0.1975 - val_acc: 0.9042\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9110 - val_loss: 0.1979 - val_acc: 0.9040\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9102 - val_loss: 0.1986 - val_acc: 0.9032\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.19751 to 0.19724, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9114 - val_loss: 0.1972 - val_acc: 0.9026\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19724 to 0.19695, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9126 - val_loss: 0.1970 - val_acc: 0.9053\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9121 - val_loss: 0.1991 - val_acc: 0.9032\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9122 - val_loss: 0.1982 - val_acc: 0.9026\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19695 to 0.19664, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9112 - val_loss: 0.1966 - val_acc: 0.9028\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9130 - val_loss: 0.1975 - val_acc: 0.9038\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9127 - val_loss: 0.1967 - val_acc: 0.9034\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9114 - val_loss: 0.1972 - val_acc: 0.9028\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9115 - val_loss: 0.1972 - val_acc: 0.9046\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.19664 to 0.19657, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9124 - val_loss: 0.1966 - val_acc: 0.9032\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9123 - val_loss: 0.1970 - val_acc: 0.9032\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9131 - val_loss: 0.1966 - val_acc: 0.9032\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9114 - val_loss: 0.1970 - val_acc: 0.9038\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9125 - val_loss: 0.1970 - val_acc: 0.9044\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.19657 to 0.19555, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9123 - val_loss: 0.1955 - val_acc: 0.9044\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9128 - val_loss: 0.1956 - val_acc: 0.9036\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9140 - val_loss: 0.1973 - val_acc: 0.9044\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9128 - val_loss: 0.1956 - val_acc: 0.9036\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.19555 to 0.19549, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9116 - val_loss: 0.1955 - val_acc: 0.9028\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9134 - val_loss: 0.1965 - val_acc: 0.9036\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9136 - val_loss: 0.1964 - val_acc: 0.9046\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9142 - val_loss: 0.1960 - val_acc: 0.9036\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9123 - val_loss: 0.1964 - val_acc: 0.9044\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.19549 to 0.19519, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9156 - val_loss: 0.1952 - val_acc: 0.9042\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.19519 to 0.19485, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9139 - val_loss: 0.1949 - val_acc: 0.9034\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9147 - val_loss: 0.1953 - val_acc: 0.9044\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.19485 to 0.19476, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9137 - val_loss: 0.1948 - val_acc: 0.9040\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1823 - acc: 0.9144 - val_loss: 0.1954 - val_acc: 0.9047\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9150 - val_loss: 0.1950 - val_acc: 0.9049\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1812 - acc: 0.9143 - val_loss: 0.1961 - val_acc: 0.9036\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9154 - val_loss: 0.1955 - val_acc: 0.9049\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9144 - val_loss: 0.1960 - val_acc: 0.9049\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9134 - val_loss: 0.1959 - val_acc: 0.9046\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9149 - val_loss: 0.1966 - val_acc: 0.9049\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.19476 to 0.19442, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9149 - val_loss: 0.1944 - val_acc: 0.9055\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9148 - val_loss: 0.1979 - val_acc: 0.9038\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9131 - val_loss: 0.1947 - val_acc: 0.9047\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9142 - val_loss: 0.1953 - val_acc: 0.9053\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9151 - val_loss: 0.1945 - val_acc: 0.9061\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9153 - val_loss: 0.1949 - val_acc: 0.9065\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9153 - val_loss: 0.1949 - val_acc: 0.9063\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.19442 to 0.19396, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9157 - val_loss: 0.1940 - val_acc: 0.9065\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9147 - val_loss: 0.1943 - val_acc: 0.9049\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9149 - val_loss: 0.1944 - val_acc: 0.9065\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9156 - val_loss: 0.1946 - val_acc: 0.9049\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.19396 to 0.19328, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9137 - val_loss: 0.1933 - val_acc: 0.9069\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9140 - val_loss: 0.1936 - val_acc: 0.9057\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9160 - val_loss: 0.1933 - val_acc: 0.9069\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9147 - val_loss: 0.1939 - val_acc: 0.9055\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9141 - val_loss: 0.1940 - val_acc: 0.9063\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9161 - val_loss: 0.1952 - val_acc: 0.9067\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9146 - val_loss: 0.1943 - val_acc: 0.9061\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9153 - val_loss: 0.1938 - val_acc: 0.9061\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9164 - val_loss: 0.1940 - val_acc: 0.9049\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9140 - val_loss: 0.1963 - val_acc: 0.9057\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9165 - val_loss: 0.1969 - val_acc: 0.9067\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.19328 to 0.19300, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9157 - val_loss: 0.1930 - val_acc: 0.9069\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.19300 to 0.19250, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9147 - val_loss: 0.1925 - val_acc: 0.9061\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9152 - val_loss: 0.1937 - val_acc: 0.9069\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9170 - val_loss: 0.1936 - val_acc: 0.9082\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9147 - val_loss: 0.1932 - val_acc: 0.9067\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9158 - val_loss: 0.1932 - val_acc: 0.9063\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9167 - val_loss: 0.1927 - val_acc: 0.9067\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.19250 to 0.19235, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9141 - val_loss: 0.1923 - val_acc: 0.9065\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9163 - val_loss: 0.1938 - val_acc: 0.9076\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9171 - val_loss: 0.1937 - val_acc: 0.9086\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9164 - val_loss: 0.1938 - val_acc: 0.9067\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.19235 to 0.19211, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9156 - val_loss: 0.1921 - val_acc: 0.9069\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9161 - val_loss: 0.1935 - val_acc: 0.9074\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9156 - val_loss: 0.1925 - val_acc: 0.9067\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9161 - val_loss: 0.1923 - val_acc: 0.9072\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9164 - val_loss: 0.1944 - val_acc: 0.9082\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9171 - val_loss: 0.1941 - val_acc: 0.9076\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.19211 to 0.19171, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9162 - val_loss: 0.1917 - val_acc: 0.9084\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9173 - val_loss: 0.1940 - val_acc: 0.9078\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.19171 to 0.19165, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9164 - val_loss: 0.1917 - val_acc: 0.9065\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9167 - val_loss: 0.1921 - val_acc: 0.9069\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9152 - val_loss: 0.1932 - val_acc: 0.9090\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9168 - val_loss: 0.1918 - val_acc: 0.9088\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9178 - val_loss: 0.1924 - val_acc: 0.9080\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.19165 to 0.19163, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9173 - val_loss: 0.1916 - val_acc: 0.9080\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9171 - val_loss: 0.1918 - val_acc: 0.9069\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9177 - val_loss: 0.1920 - val_acc: 0.9080\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.19163 to 0.19089, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9163 - val_loss: 0.1909 - val_acc: 0.9070\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9178 - val_loss: 0.1933 - val_acc: 0.9080\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9187 - val_loss: 0.1923 - val_acc: 0.9084\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9168 - val_loss: 0.1911 - val_acc: 0.9084\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9180 - val_loss: 0.1921 - val_acc: 0.9080\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9171 - val_loss: 0.1911 - val_acc: 0.9072\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.19089 to 0.19047, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9166 - val_loss: 0.1905 - val_acc: 0.9076\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9186 - val_loss: 0.1910 - val_acc: 0.9080\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9174 - val_loss: 0.1921 - val_acc: 0.9078\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9166 - val_loss: 0.1918 - val_acc: 0.9088\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9164 - val_loss: 0.1911 - val_acc: 0.9084\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9184 - val_loss: 0.1950 - val_acc: 0.9078\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9196 - val_loss: 0.1908 - val_acc: 0.9076\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9181 - val_loss: 0.1909 - val_acc: 0.9088\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9199 - val_loss: 0.1905 - val_acc: 0.9086\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.19047 to 0.19027, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9195 - val_loss: 0.1903 - val_acc: 0.9090\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.19027 to 0.18982, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9174 - val_loss: 0.1898 - val_acc: 0.9090\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9180 - val_loss: 0.1906 - val_acc: 0.9090\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9174 - val_loss: 0.1917 - val_acc: 0.9092\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9181 - val_loss: 0.1923 - val_acc: 0.9086\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9193 - val_loss: 0.1916 - val_acc: 0.9088\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9179 - val_loss: 0.1928 - val_acc: 0.9095\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9190 - val_loss: 0.1907 - val_acc: 0.9082\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9190 - val_loss: 0.1937 - val_acc: 0.9092\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9183 - val_loss: 0.1915 - val_acc: 0.9092\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9183 - val_loss: 0.1926 - val_acc: 0.9095\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9183 - val_loss: 0.1927 - val_acc: 0.9086\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9179 - val_loss: 0.1909 - val_acc: 0.9086\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9191 - val_loss: 0.1920 - val_acc: 0.9086\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9191 - val_loss: 0.1923 - val_acc: 0.9107\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9185 - val_loss: 0.1918 - val_acc: 0.9094\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9211 - val_loss: 0.1906 - val_acc: 0.9090\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9184 - val_loss: 0.1899 - val_acc: 0.9082\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9181 - val_loss: 0.1913 - val_acc: 0.9103\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9221 - val_loss: 0.1913 - val_acc: 0.9101\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9195 - val_loss: 0.1900 - val_acc: 0.9092\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9201 - val_loss: 0.1902 - val_acc: 0.9101\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9183 - val_loss: 0.1899 - val_acc: 0.9092\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9195 - val_loss: 0.1913 - val_acc: 0.9103\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9190 - val_loss: 0.1903 - val_acc: 0.9105\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1685 - acc: 0.9205 - val_loss: 0.1923 - val_acc: 0.9099\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9193 - val_loss: 0.1902 - val_acc: 0.9088\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9196 - val_loss: 0.1910 - val_acc: 0.9086\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32749, saving model to best.model\n",
      "0s - loss: 0.4220 - acc: 0.8619 - val_loss: 0.3275 - val_acc: 0.8915\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32749 to 0.26394, saving model to best.model\n",
      "0s - loss: 0.3405 - acc: 0.8845 - val_loss: 0.2639 - val_acc: 0.8915\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.26394 to 0.21831, saving model to best.model\n",
      "0s - loss: 0.2769 - acc: 0.8908 - val_loss: 0.2183 - val_acc: 0.9032\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21831 to 0.20304, saving model to best.model\n",
      "0s - loss: 0.2437 - acc: 0.8970 - val_loss: 0.2030 - val_acc: 0.9047\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20304 to 0.19693, saving model to best.model\n",
      "0s - loss: 0.2289 - acc: 0.9004 - val_loss: 0.1969 - val_acc: 0.9053\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19693 to 0.19463, saving model to best.model\n",
      "0s - loss: 0.2221 - acc: 0.8982 - val_loss: 0.1946 - val_acc: 0.9059\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19463 to 0.19321, saving model to best.model\n",
      "0s - loss: 0.2170 - acc: 0.9014 - val_loss: 0.1932 - val_acc: 0.9070\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19321 to 0.19150, saving model to best.model\n",
      "0s - loss: 0.2142 - acc: 0.9008 - val_loss: 0.1915 - val_acc: 0.9072\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19150 to 0.19142, saving model to best.model\n",
      "0s - loss: 0.2109 - acc: 0.9006 - val_loss: 0.1914 - val_acc: 0.9082\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19142 to 0.19066, saving model to best.model\n",
      "0s - loss: 0.2073 - acc: 0.9026 - val_loss: 0.1907 - val_acc: 0.9088\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19066 to 0.19055, saving model to best.model\n",
      "0s - loss: 0.2084 - acc: 0.9004 - val_loss: 0.1905 - val_acc: 0.9080\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2081 - acc: 0.9014 - val_loss: 0.1935 - val_acc: 0.9044\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2090 - acc: 0.9006 - val_loss: 0.1920 - val_acc: 0.9042\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19055 to 0.18962, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9014 - val_loss: 0.1896 - val_acc: 0.9084\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.18962 to 0.18940, saving model to best.model\n",
      "0s - loss: 0.2035 - acc: 0.9048 - val_loss: 0.1894 - val_acc: 0.9076\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2046 - acc: 0.9023 - val_loss: 0.1907 - val_acc: 0.9055\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18940 to 0.18928, saving model to best.model\n",
      "0s - loss: 0.2040 - acc: 0.9013 - val_loss: 0.1893 - val_acc: 0.9074\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2045 - acc: 0.9018 - val_loss: 0.1910 - val_acc: 0.9063\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18928 to 0.18904, saving model to best.model\n",
      "0s - loss: 0.2035 - acc: 0.9028 - val_loss: 0.1890 - val_acc: 0.9082\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18904 to 0.18903, saving model to best.model\n",
      "0s - loss: 0.2047 - acc: 0.9007 - val_loss: 0.1890 - val_acc: 0.9086\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2007 - acc: 0.9024 - val_loss: 0.1914 - val_acc: 0.9055\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18903 to 0.18837, saving model to best.model\n",
      "0s - loss: 0.2010 - acc: 0.9027 - val_loss: 0.1884 - val_acc: 0.9094\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9021 - val_loss: 0.1889 - val_acc: 0.9078\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2024 - acc: 0.9040 - val_loss: 0.1885 - val_acc: 0.9088\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2008 - acc: 0.9024 - val_loss: 0.1887 - val_acc: 0.9051\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18837 to 0.18764, saving model to best.model\n",
      "0s - loss: 0.2002 - acc: 0.9040 - val_loss: 0.1876 - val_acc: 0.9088\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2022 - acc: 0.9040 - val_loss: 0.1880 - val_acc: 0.9095\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18764 to 0.18752, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9043 - val_loss: 0.1875 - val_acc: 0.9076\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18752 to 0.18749, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9060 - val_loss: 0.1875 - val_acc: 0.9084\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1996 - acc: 0.9030 - val_loss: 0.1886 - val_acc: 0.9067\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18749 to 0.18718, saving model to best.model\n",
      "0s - loss: 0.2002 - acc: 0.9053 - val_loss: 0.1872 - val_acc: 0.9086\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18718 to 0.18708, saving model to best.model\n",
      "0s - loss: 0.1989 - acc: 0.9044 - val_loss: 0.1871 - val_acc: 0.9080\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9040 - val_loss: 0.1873 - val_acc: 0.9086\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18708 to 0.18631, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9057 - val_loss: 0.1863 - val_acc: 0.9092\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1996 - acc: 0.9029 - val_loss: 0.1884 - val_acc: 0.9088\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9046 - val_loss: 0.1870 - val_acc: 0.9082\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9059 - val_loss: 0.1870 - val_acc: 0.9086\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18631 to 0.18587, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9068 - val_loss: 0.1859 - val_acc: 0.9094\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9063 - val_loss: 0.1867 - val_acc: 0.9105\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1965 - acc: 0.9054 - val_loss: 0.1859 - val_acc: 0.9090\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18587 to 0.18472, saving model to best.model\n",
      "0s - loss: 0.1960 - acc: 0.9084 - val_loss: 0.1847 - val_acc: 0.9107\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1965 - acc: 0.9063 - val_loss: 0.1849 - val_acc: 0.9109\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1950 - acc: 0.9064 - val_loss: 0.1854 - val_acc: 0.9092\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18472 to 0.18451, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9066 - val_loss: 0.1845 - val_acc: 0.9109\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9071 - val_loss: 0.1846 - val_acc: 0.9097\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9069 - val_loss: 0.1860 - val_acc: 0.9092\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18451 to 0.18381, saving model to best.model\n",
      "0s - loss: 0.1961 - acc: 0.9064 - val_loss: 0.1838 - val_acc: 0.9117\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1938 - acc: 0.9077 - val_loss: 0.1839 - val_acc: 0.9118\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1956 - acc: 0.9060 - val_loss: 0.1842 - val_acc: 0.9111\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18381 to 0.18367, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9065 - val_loss: 0.1837 - val_acc: 0.9094\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18367 to 0.18358, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9080 - val_loss: 0.1836 - val_acc: 0.9107\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18358 to 0.18316, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9079 - val_loss: 0.1832 - val_acc: 0.9118\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1929 - acc: 0.9058 - val_loss: 0.1845 - val_acc: 0.9095\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18316 to 0.18272, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9076 - val_loss: 0.1827 - val_acc: 0.9115\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9072 - val_loss: 0.1828 - val_acc: 0.9101\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9079 - val_loss: 0.1833 - val_acc: 0.9090\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18272 to 0.18270, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9066 - val_loss: 0.1827 - val_acc: 0.9107\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.18270 to 0.18193, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9081 - val_loss: 0.1819 - val_acc: 0.9134\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9084 - val_loss: 0.1823 - val_acc: 0.9115\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9077 - val_loss: 0.1825 - val_acc: 0.9117\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9078 - val_loss: 0.1820 - val_acc: 0.9101\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18193 to 0.18161, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9088 - val_loss: 0.1816 - val_acc: 0.9128\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18161 to 0.18143, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9073 - val_loss: 0.1814 - val_acc: 0.9126\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9077 - val_loss: 0.1824 - val_acc: 0.9109\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18143 to 0.18092, saving model to best.model\n",
      "0s - loss: 0.1910 - acc: 0.9091 - val_loss: 0.1809 - val_acc: 0.9132\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18092 to 0.18085, saving model to best.model\n",
      "0s - loss: 0.1921 - acc: 0.9087 - val_loss: 0.1809 - val_acc: 0.9126\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9080 - val_loss: 0.1826 - val_acc: 0.9126\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18085 to 0.18079, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9093 - val_loss: 0.1808 - val_acc: 0.9124\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1901 - acc: 0.9101 - val_loss: 0.1808 - val_acc: 0.9126\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18079 to 0.18075, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9104 - val_loss: 0.1807 - val_acc: 0.9132\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9090 - val_loss: 0.1808 - val_acc: 0.9126\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18075 to 0.18055, saving model to best.model\n",
      "0s - loss: 0.1900 - acc: 0.9096 - val_loss: 0.1806 - val_acc: 0.9122\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9076 - val_loss: 0.1808 - val_acc: 0.9126\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18055 to 0.18042, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9107 - val_loss: 0.1804 - val_acc: 0.9138\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9086 - val_loss: 0.1811 - val_acc: 0.9107\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18042 to 0.18027, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9091 - val_loss: 0.1803 - val_acc: 0.9132\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1900 - acc: 0.9078 - val_loss: 0.1809 - val_acc: 0.9117\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9085 - val_loss: 0.1804 - val_acc: 0.9120\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18027 to 0.17972, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9097 - val_loss: 0.1797 - val_acc: 0.9134\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9093 - val_loss: 0.1803 - val_acc: 0.9132\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9092 - val_loss: 0.1802 - val_acc: 0.9136\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9110 - val_loss: 0.1807 - val_acc: 0.9117\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9103 - val_loss: 0.1803 - val_acc: 0.9132\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9098 - val_loss: 0.1801 - val_acc: 0.9142\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.17972 to 0.17918, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9102 - val_loss: 0.1792 - val_acc: 0.9143\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9108 - val_loss: 0.1794 - val_acc: 0.9143\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9094 - val_loss: 0.1796 - val_acc: 0.9136\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.17918 to 0.17889, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9114 - val_loss: 0.1789 - val_acc: 0.9140\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.17889 to 0.17873, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9118 - val_loss: 0.1787 - val_acc: 0.9138\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9113 - val_loss: 0.1795 - val_acc: 0.9128\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17873 to 0.17832, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9085 - val_loss: 0.1783 - val_acc: 0.9136\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9096 - val_loss: 0.1794 - val_acc: 0.9126\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9102 - val_loss: 0.1811 - val_acc: 0.9109\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.17832 to 0.17830, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9102 - val_loss: 0.1783 - val_acc: 0.9134\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9104 - val_loss: 0.1798 - val_acc: 0.9113\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17830 to 0.17815, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9103 - val_loss: 0.1782 - val_acc: 0.9138\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.17815 to 0.17802, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9107 - val_loss: 0.1780 - val_acc: 0.9132\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.17802 to 0.17768, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9123 - val_loss: 0.1777 - val_acc: 0.9132\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9105 - val_loss: 0.1781 - val_acc: 0.9122\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9091 - val_loss: 0.1782 - val_acc: 0.9117\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9114 - val_loss: 0.1780 - val_acc: 0.9126\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9113 - val_loss: 0.1783 - val_acc: 0.9122\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17768 to 0.17721, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9125 - val_loss: 0.1772 - val_acc: 0.9142\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9093 - val_loss: 0.1772 - val_acc: 0.9140\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9103 - val_loss: 0.1775 - val_acc: 0.9136\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9133 - val_loss: 0.1776 - val_acc: 0.9128\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17721 to 0.17690, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9125 - val_loss: 0.1769 - val_acc: 0.9134\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9109 - val_loss: 0.1769 - val_acc: 0.9132\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9113 - val_loss: 0.1775 - val_acc: 0.9136\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.17690 to 0.17678, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9120 - val_loss: 0.1768 - val_acc: 0.9134\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9103 - val_loss: 0.1771 - val_acc: 0.9126\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17678 to 0.17669, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9122 - val_loss: 0.1767 - val_acc: 0.9140\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9115 - val_loss: 0.1773 - val_acc: 0.9136\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.17669 to 0.17661, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9115 - val_loss: 0.1766 - val_acc: 0.9132\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.17661 to 0.17622, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9112 - val_loss: 0.1762 - val_acc: 0.9134\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9117 - val_loss: 0.1771 - val_acc: 0.9130\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9118 - val_loss: 0.1777 - val_acc: 0.9128\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.17622 to 0.17584, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9121 - val_loss: 0.1758 - val_acc: 0.9142\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17584 to 0.17560, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9121 - val_loss: 0.1756 - val_acc: 0.9142\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9106 - val_loss: 0.1763 - val_acc: 0.9136\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9120 - val_loss: 0.1765 - val_acc: 0.9124\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9142 - val_loss: 0.1757 - val_acc: 0.9134\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9126 - val_loss: 0.1757 - val_acc: 0.9126\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17560 to 0.17551, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9116 - val_loss: 0.1755 - val_acc: 0.9136\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9118 - val_loss: 0.1757 - val_acc: 0.9130\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17551 to 0.17504, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9100 - val_loss: 0.1750 - val_acc: 0.9142\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9110 - val_loss: 0.1768 - val_acc: 0.9134\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9121 - val_loss: 0.1753 - val_acc: 0.9138\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17504 to 0.17478, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9120 - val_loss: 0.1748 - val_acc: 0.9143\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1821 - acc: 0.9110 - val_loss: 0.1763 - val_acc: 0.9134\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17478 to 0.17468, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9137 - val_loss: 0.1747 - val_acc: 0.9140\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9115 - val_loss: 0.1754 - val_acc: 0.9143\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17468 to 0.17450, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9136 - val_loss: 0.1745 - val_acc: 0.9134\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9123 - val_loss: 0.1747 - val_acc: 0.9149\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9128 - val_loss: 0.1749 - val_acc: 0.9145\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17450 to 0.17444, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9125 - val_loss: 0.1744 - val_acc: 0.9149\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17444 to 0.17403, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9116 - val_loss: 0.1740 - val_acc: 0.9151\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9126 - val_loss: 0.1752 - val_acc: 0.9140\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9112 - val_loss: 0.1742 - val_acc: 0.9147\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.17403 to 0.17400, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9122 - val_loss: 0.1740 - val_acc: 0.9136\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.17400 to 0.17375, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9136 - val_loss: 0.1738 - val_acc: 0.9140\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17375 to 0.17374, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9114 - val_loss: 0.1737 - val_acc: 0.9149\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17374 to 0.17333, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9138 - val_loss: 0.1733 - val_acc: 0.9147\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17333 to 0.17327, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9136 - val_loss: 0.1733 - val_acc: 0.9142\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9125 - val_loss: 0.1738 - val_acc: 0.9145\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9144 - val_loss: 0.1737 - val_acc: 0.9143\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.17327 to 0.17293, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9133 - val_loss: 0.1729 - val_acc: 0.9138\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.17293 to 0.17277, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9128 - val_loss: 0.1728 - val_acc: 0.9138\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9136 - val_loss: 0.1735 - val_acc: 0.9145\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9137 - val_loss: 0.1728 - val_acc: 0.9142\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9137 - val_loss: 0.1732 - val_acc: 0.9140\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.17277 to 0.17246, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9133 - val_loss: 0.1725 - val_acc: 0.9138\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9133 - val_loss: 0.1726 - val_acc: 0.9153\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17246 to 0.17242, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9134 - val_loss: 0.1724 - val_acc: 0.9143\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9141 - val_loss: 0.1733 - val_acc: 0.9151\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9131 - val_loss: 0.1727 - val_acc: 0.9147\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9131 - val_loss: 0.1726 - val_acc: 0.9149\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9144 - val_loss: 0.1737 - val_acc: 0.9143\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9143 - val_loss: 0.1724 - val_acc: 0.9151\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17242 to 0.17202, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9130 - val_loss: 0.1720 - val_acc: 0.9149\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9152 - val_loss: 0.1721 - val_acc: 0.9145\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.17202 to 0.17169, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9140 - val_loss: 0.1717 - val_acc: 0.9136\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9126 - val_loss: 0.1719 - val_acc: 0.9153\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9124 - val_loss: 0.1721 - val_acc: 0.9145\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9150 - val_loss: 0.1718 - val_acc: 0.9145\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.17169 to 0.17163, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9138 - val_loss: 0.1716 - val_acc: 0.9140\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9153 - val_loss: 0.1721 - val_acc: 0.9149\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9125 - val_loss: 0.1717 - val_acc: 0.9149\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9128 - val_loss: 0.1729 - val_acc: 0.9136\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.17163 to 0.17156, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9145 - val_loss: 0.1716 - val_acc: 0.9155\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17156 to 0.17099, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9136 - val_loss: 0.1710 - val_acc: 0.9132\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9160 - val_loss: 0.1710 - val_acc: 0.9142\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9140 - val_loss: 0.1716 - val_acc: 0.9145\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9149 - val_loss: 0.1713 - val_acc: 0.9142\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.17099 to 0.17067, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9146 - val_loss: 0.1707 - val_acc: 0.9151\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9140 - val_loss: 0.1708 - val_acc: 0.9142\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9156 - val_loss: 0.1709 - val_acc: 0.9151\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9151 - val_loss: 0.1709 - val_acc: 0.9149\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17067 to 0.17065, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9135 - val_loss: 0.1707 - val_acc: 0.9140\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.17065 to 0.17054, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9138 - val_loss: 0.1705 - val_acc: 0.9155\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.17054 to 0.17044, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9144 - val_loss: 0.1704 - val_acc: 0.9140\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17044 to 0.17037, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9149 - val_loss: 0.1704 - val_acc: 0.9128\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9138 - val_loss: 0.1705 - val_acc: 0.9147\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9158 - val_loss: 0.1704 - val_acc: 0.9145\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9138 - val_loss: 0.1712 - val_acc: 0.9130\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.17037 to 0.17023, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9149 - val_loss: 0.1702 - val_acc: 0.9143\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9147 - val_loss: 0.1703 - val_acc: 0.9151\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9171 - val_loss: 0.1717 - val_acc: 0.9142\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.17023 to 0.17008, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9142 - val_loss: 0.1701 - val_acc: 0.9149\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9148 - val_loss: 0.1709 - val_acc: 0.9130\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9148 - val_loss: 0.1702 - val_acc: 0.9153\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9150 - val_loss: 0.1709 - val_acc: 0.9143\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9163 - val_loss: 0.1704 - val_acc: 0.9138\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9150 - val_loss: 0.1703 - val_acc: 0.9147\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.17008 to 0.17001, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9144 - val_loss: 0.1700 - val_acc: 0.9149\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.17001 to 0.16999, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9141 - val_loss: 0.1700 - val_acc: 0.9157\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.16999 to 0.16944, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9166 - val_loss: 0.1694 - val_acc: 0.9142\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9164 - val_loss: 0.1698 - val_acc: 0.9140\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9162 - val_loss: 0.1703 - val_acc: 0.9138\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9166 - val_loss: 0.1696 - val_acc: 0.9140\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.32938, saving model to best.model\n",
      "0s - loss: 0.3854 - acc: 0.8791 - val_loss: 0.3294 - val_acc: 0.8842\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.32938 to 0.23943, saving model to best.model\n",
      "0s - loss: 0.3074 - acc: 0.8864 - val_loss: 0.2394 - val_acc: 0.8996\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23943 to 0.20952, saving model to best.model\n",
      "0s - loss: 0.2568 - acc: 0.8959 - val_loss: 0.2095 - val_acc: 0.9092\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20952 to 0.20158, saving model to best.model\n",
      "0s - loss: 0.2334 - acc: 0.8988 - val_loss: 0.2016 - val_acc: 0.9117\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20158 to 0.19805, saving model to best.model\n",
      "0s - loss: 0.2236 - acc: 0.9000 - val_loss: 0.1980 - val_acc: 0.9117\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.2152 - acc: 0.9017 - val_loss: 0.1995 - val_acc: 0.9128\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19805 to 0.19724, saving model to best.model\n",
      "0s - loss: 0.2139 - acc: 0.9035 - val_loss: 0.1972 - val_acc: 0.9130\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19724 to 0.19617, saving model to best.model\n",
      "0s - loss: 0.2115 - acc: 0.9050 - val_loss: 0.1962 - val_acc: 0.9145\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.2090 - acc: 0.9024 - val_loss: 0.1973 - val_acc: 0.9132\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2100 - acc: 0.9050 - val_loss: 0.1962 - val_acc: 0.9130\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2051 - acc: 0.9044 - val_loss: 0.1963 - val_acc: 0.9126\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2070 - acc: 0.9029 - val_loss: 0.1975 - val_acc: 0.9111\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.2058 - acc: 0.9046 - val_loss: 0.1969 - val_acc: 0.9142\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2054 - acc: 0.9041 - val_loss: 0.1964 - val_acc: 0.9143\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.19617 to 0.19483, saving model to best.model\n",
      "0s - loss: 0.2049 - acc: 0.9052 - val_loss: 0.1948 - val_acc: 0.9142\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19483 to 0.19467, saving model to best.model\n",
      "0s - loss: 0.2024 - acc: 0.9056 - val_loss: 0.1947 - val_acc: 0.9124\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19467 to 0.19448, saving model to best.model\n",
      "0s - loss: 0.2039 - acc: 0.9046 - val_loss: 0.1945 - val_acc: 0.9122\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2043 - acc: 0.9054 - val_loss: 0.1947 - val_acc: 0.9128\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19448 to 0.19438, saving model to best.model\n",
      "0s - loss: 0.2008 - acc: 0.9075 - val_loss: 0.1944 - val_acc: 0.9117\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19438 to 0.19384, saving model to best.model\n",
      "1s - loss: 0.2014 - acc: 0.9057 - val_loss: 0.1938 - val_acc: 0.9147\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19384 to 0.19355, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9070 - val_loss: 0.1936 - val_acc: 0.9128\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1991 - acc: 0.9049 - val_loss: 0.1941 - val_acc: 0.9122\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1997 - acc: 0.9069 - val_loss: 0.1942 - val_acc: 0.9134\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19355 to 0.19295, saving model to best.model\n",
      "0s - loss: 0.1998 - acc: 0.9066 - val_loss: 0.1929 - val_acc: 0.9142\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1994 - acc: 0.9073 - val_loss: 0.1935 - val_acc: 0.9122\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19295 to 0.19261, saving model to best.model\n",
      "0s - loss: 0.1997 - acc: 0.9083 - val_loss: 0.1926 - val_acc: 0.9138\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19261 to 0.19216, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9077 - val_loss: 0.1922 - val_acc: 0.9124\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1978 - acc: 0.9055 - val_loss: 0.1925 - val_acc: 0.9149\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1966 - acc: 0.9068 - val_loss: 0.1924 - val_acc: 0.9147\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19216 to 0.19165, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9065 - val_loss: 0.1916 - val_acc: 0.9151\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19165 to 0.19152, saving model to best.model\n",
      "0s - loss: 0.1976 - acc: 0.9052 - val_loss: 0.1915 - val_acc: 0.9145\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1964 - acc: 0.9090 - val_loss: 0.1916 - val_acc: 0.9136\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9067 - val_loss: 0.1916 - val_acc: 0.9143\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19152 to 0.19132, saving model to best.model\n",
      "0s - loss: 0.1971 - acc: 0.9072 - val_loss: 0.1913 - val_acc: 0.9136\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1955 - acc: 0.9092 - val_loss: 0.1913 - val_acc: 0.9138\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1954 - acc: 0.9069 - val_loss: 0.1917 - val_acc: 0.9151\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19132 to 0.19040, saving model to best.model\n",
      "0s - loss: 0.1952 - acc: 0.9096 - val_loss: 0.1904 - val_acc: 0.9157\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9069 - val_loss: 0.1906 - val_acc: 0.9157\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9067 - val_loss: 0.1908 - val_acc: 0.9161\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19040 to 0.19018, saving model to best.model\n",
      "0s - loss: 0.1943 - acc: 0.9079 - val_loss: 0.1902 - val_acc: 0.9165\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9085 - val_loss: 0.1905 - val_acc: 0.9155\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9094 - val_loss: 0.1902 - val_acc: 0.9174\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9088 - val_loss: 0.1906 - val_acc: 0.9172\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1920 - acc: 0.9090 - val_loss: 0.1904 - val_acc: 0.9132\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9082 - val_loss: 0.1903 - val_acc: 0.9132\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.19018 to 0.19008, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9090 - val_loss: 0.1901 - val_acc: 0.9149\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1923 - acc: 0.9087 - val_loss: 0.1903 - val_acc: 0.9109\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9095 - val_loss: 0.1903 - val_acc: 0.9128\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.19008 to 0.18923, saving model to best.model\n",
      "0s - loss: 0.1910 - acc: 0.9098 - val_loss: 0.1892 - val_acc: 0.9167\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18923 to 0.18896, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9088 - val_loss: 0.1890 - val_acc: 0.9170\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9088 - val_loss: 0.1896 - val_acc: 0.9136\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9109 - val_loss: 0.1899 - val_acc: 0.9145\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9112 - val_loss: 0.1891 - val_acc: 0.9163\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18896 to 0.18837, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9102 - val_loss: 0.1884 - val_acc: 0.9161\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9111 - val_loss: 0.1888 - val_acc: 0.9143\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9100 - val_loss: 0.1891 - val_acc: 0.9142\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9096 - val_loss: 0.1888 - val_acc: 0.9155\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1911 - acc: 0.9099 - val_loss: 0.1885 - val_acc: 0.9143\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9105 - val_loss: 0.1884 - val_acc: 0.9147\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9105 - val_loss: 0.1885 - val_acc: 0.9145\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9107 - val_loss: 0.1885 - val_acc: 0.9147\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9130 - val_loss: 0.1885 - val_acc: 0.9145\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9100 - val_loss: 0.1886 - val_acc: 0.9142\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1891 - acc: 0.9111 - val_loss: 0.1887 - val_acc: 0.9153\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18837 to 0.18785, saving model to best.model\n",
      "0s - loss: 0.1891 - acc: 0.9102 - val_loss: 0.1878 - val_acc: 0.9147\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9109 - val_loss: 0.1882 - val_acc: 0.9138\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1868 - acc: 0.9112 - val_loss: 0.1886 - val_acc: 0.9149\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18785 to 0.18770, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9114 - val_loss: 0.1877 - val_acc: 0.9151\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18770 to 0.18756, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9098 - val_loss: 0.1876 - val_acc: 0.9153\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9095 - val_loss: 0.1877 - val_acc: 0.9143\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18756 to 0.18725, saving model to best.model\n",
      "1s - loss: 0.1852 - acc: 0.9109 - val_loss: 0.1872 - val_acc: 0.9145\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9105 - val_loss: 0.1873 - val_acc: 0.9153\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9102 - val_loss: 0.1877 - val_acc: 0.9143\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9117 - val_loss: 0.1877 - val_acc: 0.9161\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9119 - val_loss: 0.1888 - val_acc: 0.9140\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18725 to 0.18711, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9100 - val_loss: 0.1871 - val_acc: 0.9142\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18711 to 0.18700, saving model to best.model\n",
      "0s - loss: 0.1854 - acc: 0.9123 - val_loss: 0.1870 - val_acc: 0.9157\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.18700 to 0.18690, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9120 - val_loss: 0.1869 - val_acc: 0.9153\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18690 to 0.18669, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9121 - val_loss: 0.1867 - val_acc: 0.9142\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.18669 to 0.18661, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9125 - val_loss: 0.1866 - val_acc: 0.9153\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18661 to 0.18619, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9114 - val_loss: 0.1862 - val_acc: 0.9153\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9118 - val_loss: 0.1862 - val_acc: 0.9161\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1839 - acc: 0.9124 - val_loss: 0.1869 - val_acc: 0.9142\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9126 - val_loss: 0.1865 - val_acc: 0.9149\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9110 - val_loss: 0.1870 - val_acc: 0.9151\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9112 - val_loss: 0.1868 - val_acc: 0.9163\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1861 - acc: 0.9112 - val_loss: 0.1870 - val_acc: 0.9155\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9124 - val_loss: 0.1866 - val_acc: 0.9149\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9132 - val_loss: 0.1868 - val_acc: 0.9157\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.18619 to 0.18569, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9139 - val_loss: 0.1857 - val_acc: 0.9157\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.18569 to 0.18563, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9140 - val_loss: 0.1856 - val_acc: 0.9159\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.18563 to 0.18549, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9140 - val_loss: 0.1855 - val_acc: 0.9163\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9139 - val_loss: 0.1873 - val_acc: 0.9167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9127 - val_loss: 0.1861 - val_acc: 0.9161\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9120 - val_loss: 0.1860 - val_acc: 0.9165\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18549 to 0.18531, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9130 - val_loss: 0.1853 - val_acc: 0.9168\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18531 to 0.18514, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9147 - val_loss: 0.1851 - val_acc: 0.9155\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.18514 to 0.18501, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9139 - val_loss: 0.1850 - val_acc: 0.9153\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9138 - val_loss: 0.1852 - val_acc: 0.9170\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9111 - val_loss: 0.1859 - val_acc: 0.9161\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9128 - val_loss: 0.1868 - val_acc: 0.9155\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9138 - val_loss: 0.1852 - val_acc: 0.9149\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18501 to 0.18444, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9130 - val_loss: 0.1844 - val_acc: 0.9157\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18444 to 0.18437, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9130 - val_loss: 0.1844 - val_acc: 0.9176\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9126 - val_loss: 0.1846 - val_acc: 0.9155\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9144 - val_loss: 0.1850 - val_acc: 0.9188\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9131 - val_loss: 0.1846 - val_acc: 0.9188\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9126 - val_loss: 0.1848 - val_acc: 0.9153\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.18437 to 0.18375, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9146 - val_loss: 0.1838 - val_acc: 0.9157\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9132 - val_loss: 0.1844 - val_acc: 0.9191\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18375 to 0.18355, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9149 - val_loss: 0.1835 - val_acc: 0.9178\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9146 - val_loss: 0.1843 - val_acc: 0.9167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9164 - val_loss: 0.1840 - val_acc: 0.9163\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9140 - val_loss: 0.1837 - val_acc: 0.9168\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9137 - val_loss: 0.1841 - val_acc: 0.9153\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9123 - val_loss: 0.1839 - val_acc: 0.9168\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "1s - loss: 0.1802 - acc: 0.9150 - val_loss: 0.1838 - val_acc: 0.9167\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18355 to 0.18310, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9152 - val_loss: 0.1831 - val_acc: 0.9180\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9139 - val_loss: 0.1833 - val_acc: 0.9190\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9151 - val_loss: 0.1835 - val_acc: 0.9178\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9141 - val_loss: 0.1837 - val_acc: 0.9190\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9154 - val_loss: 0.1838 - val_acc: 0.9170\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1787 - acc: 0.9145 - val_loss: 0.1834 - val_acc: 0.9190\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.18310 to 0.18281, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9139 - val_loss: 0.1828 - val_acc: 0.9180\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9157 - val_loss: 0.1830 - val_acc: 0.9178\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9141 - val_loss: 0.1834 - val_acc: 0.9178\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9140 - val_loss: 0.1839 - val_acc: 0.9174\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9144 - val_loss: 0.1831 - val_acc: 0.9172\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9168 - val_loss: 0.1828 - val_acc: 0.9165\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9152 - val_loss: 0.1832 - val_acc: 0.9165\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9145 - val_loss: 0.1829 - val_acc: 0.9167\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.18281 to 0.18271, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9160 - val_loss: 0.1827 - val_acc: 0.9178\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.18271 to 0.18266, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9151 - val_loss: 0.1827 - val_acc: 0.9184\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9146 - val_loss: 0.1831 - val_acc: 0.9195\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9160 - val_loss: 0.1831 - val_acc: 0.9190\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9165 - val_loss: 0.1838 - val_acc: 0.9170\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9155 - val_loss: 0.1830 - val_acc: 0.9176\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9143 - val_loss: 0.1833 - val_acc: 0.9184\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9157 - val_loss: 0.1830 - val_acc: 0.9180\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9166 - val_loss: 0.1830 - val_acc: 0.9167\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9148 - val_loss: 0.1830 - val_acc: 0.9165\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9157 - val_loss: 0.1834 - val_acc: 0.9159\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9155 - val_loss: 0.1827 - val_acc: 0.9191\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9148 - val_loss: 0.1830 - val_acc: 0.9182\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9158 - val_loss: 0.1833 - val_acc: 0.9153\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.18266 to 0.18216, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9143 - val_loss: 0.1822 - val_acc: 0.9193\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9151 - val_loss: 0.1831 - val_acc: 0.9163\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1742 - acc: 0.9168 - val_loss: 0.1835 - val_acc: 0.9155\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9161 - val_loss: 0.1825 - val_acc: 0.9195\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.18216 to 0.18188, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9154 - val_loss: 0.1819 - val_acc: 0.9191\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9154 - val_loss: 0.1820 - val_acc: 0.9197\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.18188 to 0.18180, saving model to best.model\n",
      "0s - loss: 0.1759 - acc: 0.9144 - val_loss: 0.1818 - val_acc: 0.9197\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9156 - val_loss: 0.1819 - val_acc: 0.9186\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.18180 to 0.18179, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9150 - val_loss: 0.1818 - val_acc: 0.9174\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.18179 to 0.18152, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9163 - val_loss: 0.1815 - val_acc: 0.9182\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.18152 to 0.18147, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9169 - val_loss: 0.1815 - val_acc: 0.9178\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9158 - val_loss: 0.1815 - val_acc: 0.9182\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9153 - val_loss: 0.1826 - val_acc: 0.9159\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9160 - val_loss: 0.1815 - val_acc: 0.9193\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9157 - val_loss: 0.1819 - val_acc: 0.9188\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9166 - val_loss: 0.1820 - val_acc: 0.9193\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9174 - val_loss: 0.1816 - val_acc: 0.9172\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9154 - val_loss: 0.1819 - val_acc: 0.9188\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.18147 to 0.18103, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9162 - val_loss: 0.1810 - val_acc: 0.9195\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.18103 to 0.18048, saving model to best.model\n",
      "1s - loss: 0.1751 - acc: 0.9166 - val_loss: 0.1805 - val_acc: 0.9191\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.18048 to 0.18048, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9165 - val_loss: 0.1805 - val_acc: 0.9201\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9163 - val_loss: 0.1806 - val_acc: 0.9188\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.18048 to 0.18014, saving model to best.model\n",
      "0s - loss: 0.1738 - acc: 0.9167 - val_loss: 0.1801 - val_acc: 0.9193\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9167 - val_loss: 0.1802 - val_acc: 0.9195\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9173 - val_loss: 0.1802 - val_acc: 0.9193\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9167 - val_loss: 0.1810 - val_acc: 0.9197\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9187 - val_loss: 0.1809 - val_acc: 0.9172\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9174 - val_loss: 0.1805 - val_acc: 0.9199\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9164 - val_loss: 0.1807 - val_acc: 0.9197\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9161 - val_loss: 0.1802 - val_acc: 0.9203\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "1s - loss: 0.1737 - acc: 0.9161 - val_loss: 0.1804 - val_acc: 0.9195\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9166 - val_loss: 0.1803 - val_acc: 0.9180\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9175 - val_loss: 0.1803 - val_acc: 0.9195\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9173 - val_loss: 0.1806 - val_acc: 0.9199\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9168 - val_loss: 0.1806 - val_acc: 0.9207\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9156 - val_loss: 0.1813 - val_acc: 0.9203\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9172 - val_loss: 0.1804 - val_acc: 0.9159\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.18014 to 0.18003, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9165 - val_loss: 0.1800 - val_acc: 0.9186\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9162 - val_loss: 0.1802 - val_acc: 0.9178\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.18003 to 0.18000, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9193 - val_loss: 0.1800 - val_acc: 0.9205\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.18000 to 0.17984, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9180 - val_loss: 0.1798 - val_acc: 0.9197\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9176 - val_loss: 0.1800 - val_acc: 0.9197\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9186 - val_loss: 0.1804 - val_acc: 0.9197\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9178 - val_loss: 0.1800 - val_acc: 0.9207\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9185 - val_loss: 0.1801 - val_acc: 0.9201\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9192 - val_loss: 0.1805 - val_acc: 0.9201\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9184 - val_loss: 0.1801 - val_acc: 0.9201\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9198 - val_loss: 0.1800 - val_acc: 0.9205\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.17984 to 0.17954, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9176 - val_loss: 0.1795 - val_acc: 0.9203\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.17954 to 0.17944, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9171 - val_loss: 0.1794 - val_acc: 0.9207\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9170 - val_loss: 0.1799 - val_acc: 0.9205\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9183 - val_loss: 0.1796 - val_acc: 0.9213\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "1s - loss: 0.1718 - acc: 0.9180 - val_loss: 0.1794 - val_acc: 0.9190\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9192 - val_loss: 0.1804 - val_acc: 0.9199\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9184 - val_loss: 0.1799 - val_acc: 0.9191\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33330, saving model to best.model\n",
      "0s - loss: 0.3906 - acc: 0.8814 - val_loss: 0.3333 - val_acc: 0.8827\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33330 to 0.24284, saving model to best.model\n",
      "0s - loss: 0.3063 - acc: 0.8878 - val_loss: 0.2428 - val_acc: 0.9021\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.24284 to 0.20021, saving model to best.model\n",
      "0s - loss: 0.2497 - acc: 0.8973 - val_loss: 0.2002 - val_acc: 0.9076\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20021 to 0.19147, saving model to best.model\n",
      "0s - loss: 0.2255 - acc: 0.9021 - val_loss: 0.1915 - val_acc: 0.9117\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19147 to 0.18708, saving model to best.model\n",
      "0s - loss: 0.2159 - acc: 0.9040 - val_loss: 0.1871 - val_acc: 0.9122\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.18708 to 0.18507, saving model to best.model\n",
      "0s - loss: 0.2089 - acc: 0.9069 - val_loss: 0.1851 - val_acc: 0.9149\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.2052 - acc: 0.9073 - val_loss: 0.1854 - val_acc: 0.9149\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.18507 to 0.18373, saving model to best.model\n",
      "0s - loss: 0.2030 - acc: 0.9078 - val_loss: 0.1837 - val_acc: 0.9180\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18373 to 0.18356, saving model to best.model\n",
      "0s - loss: 0.2006 - acc: 0.9073 - val_loss: 0.1836 - val_acc: 0.9182\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.2027 - acc: 0.9065 - val_loss: 0.1842 - val_acc: 0.9172\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.1993 - acc: 0.9080 - val_loss: 0.1848 - val_acc: 0.9180\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.18356 to 0.18352, saving model to best.model\n",
      "0s - loss: 0.1979 - acc: 0.9083 - val_loss: 0.1835 - val_acc: 0.9178\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1985 - acc: 0.9093 - val_loss: 0.1845 - val_acc: 0.9178\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.18352 to 0.18323, saving model to best.model\n",
      "0s - loss: 0.1971 - acc: 0.9093 - val_loss: 0.1832 - val_acc: 0.9178\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9091 - val_loss: 0.1839 - val_acc: 0.9184\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1947 - acc: 0.9098 - val_loss: 0.1848 - val_acc: 0.9178\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.18323 to 0.18312, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9081 - val_loss: 0.1831 - val_acc: 0.9178\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1965 - acc: 0.9085 - val_loss: 0.1832 - val_acc: 0.9168\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1930 - acc: 0.9109 - val_loss: 0.1834 - val_acc: 0.9165\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18312 to 0.18285, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9096 - val_loss: 0.1828 - val_acc: 0.9176\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1945 - acc: 0.9092 - val_loss: 0.1834 - val_acc: 0.9165\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18285 to 0.18246, saving model to best.model\n",
      "0s - loss: 0.1944 - acc: 0.9108 - val_loss: 0.1825 - val_acc: 0.9170\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9102 - val_loss: 0.1827 - val_acc: 0.9167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9091 - val_loss: 0.1828 - val_acc: 0.9170\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1927 - acc: 0.9088 - val_loss: 0.1825 - val_acc: 0.9170\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18246 to 0.18224, saving model to best.model\n",
      "0s - loss: 0.1936 - acc: 0.9080 - val_loss: 0.1822 - val_acc: 0.9168\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1928 - acc: 0.9103 - val_loss: 0.1826 - val_acc: 0.9163\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18224 to 0.18192, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9109 - val_loss: 0.1819 - val_acc: 0.9165\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18192 to 0.18184, saving model to best.model\n",
      "0s - loss: 0.1925 - acc: 0.9111 - val_loss: 0.1818 - val_acc: 0.9168\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1923 - acc: 0.9097 - val_loss: 0.1820 - val_acc: 0.9157\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9106 - val_loss: 0.1826 - val_acc: 0.9142\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1913 - acc: 0.9110 - val_loss: 0.1819 - val_acc: 0.9155\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18184 to 0.18133, saving model to best.model\n",
      "0s - loss: 0.1916 - acc: 0.9098 - val_loss: 0.1813 - val_acc: 0.9176\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9104 - val_loss: 0.1819 - val_acc: 0.9151\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9102 - val_loss: 0.1817 - val_acc: 0.9147\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18133 to 0.18107, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9117 - val_loss: 0.1811 - val_acc: 0.9155\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9100 - val_loss: 0.1830 - val_acc: 0.9145\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18107 to 0.18068, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9105 - val_loss: 0.1807 - val_acc: 0.9159\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18068 to 0.18046, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9120 - val_loss: 0.1805 - val_acc: 0.9163\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9129 - val_loss: 0.1811 - val_acc: 0.9151\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9117 - val_loss: 0.1813 - val_acc: 0.9140\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9119 - val_loss: 0.1808 - val_acc: 0.9143\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9113 - val_loss: 0.1810 - val_acc: 0.9149\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9124 - val_loss: 0.1808 - val_acc: 0.9138\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18046 to 0.18019, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9125 - val_loss: 0.1802 - val_acc: 0.9161\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9118 - val_loss: 0.1809 - val_acc: 0.9136\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18019 to 0.17967, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9124 - val_loss: 0.1797 - val_acc: 0.9161\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9116 - val_loss: 0.1802 - val_acc: 0.9153\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9116 - val_loss: 0.1807 - val_acc: 0.9145\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1880 - acc: 0.9112 - val_loss: 0.1798 - val_acc: 0.9155\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9117 - val_loss: 0.1799 - val_acc: 0.9157\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9126 - val_loss: 0.1797 - val_acc: 0.9153\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9125 - val_loss: 0.1800 - val_acc: 0.9143\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1859 - acc: 0.9124 - val_loss: 0.1802 - val_acc: 0.9142\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.17967 to 0.17883, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9132 - val_loss: 0.1788 - val_acc: 0.9172\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1869 - acc: 0.9124 - val_loss: 0.1789 - val_acc: 0.9161\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.17883 to 0.17876, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9122 - val_loss: 0.1788 - val_acc: 0.9161\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9110 - val_loss: 0.1796 - val_acc: 0.9143\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9124 - val_loss: 0.1801 - val_acc: 0.9149\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9138 - val_loss: 0.1793 - val_acc: 0.9149\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9125 - val_loss: 0.1790 - val_acc: 0.9157\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9127 - val_loss: 0.1793 - val_acc: 0.9155\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.17876 to 0.17866, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9121 - val_loss: 0.1787 - val_acc: 0.9161\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.17866 to 0.17856, saving model to best.model\n",
      "0s - loss: 0.1871 - acc: 0.9133 - val_loss: 0.1786 - val_acc: 0.9163\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9128 - val_loss: 0.1807 - val_acc: 0.9128\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1863 - acc: 0.9110 - val_loss: 0.1791 - val_acc: 0.9170\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.17856 to 0.17833, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9149 - val_loss: 0.1783 - val_acc: 0.9159\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9130 - val_loss: 0.1791 - val_acc: 0.9155\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9127 - val_loss: 0.1789 - val_acc: 0.9163\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1846 - acc: 0.9136 - val_loss: 0.1802 - val_acc: 0.9132\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9123 - val_loss: 0.1784 - val_acc: 0.9165\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1838 - acc: 0.9136 - val_loss: 0.1794 - val_acc: 0.9136\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9149 - val_loss: 0.1786 - val_acc: 0.9165\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9142 - val_loss: 0.1790 - val_acc: 0.9172\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.17833 to 0.17832, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9144 - val_loss: 0.1783 - val_acc: 0.9167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "1s - loss: 0.1844 - acc: 0.9148 - val_loss: 0.1784 - val_acc: 0.9159\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.17832 to 0.17823, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9142 - val_loss: 0.1782 - val_acc: 0.9168\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.17823 to 0.17810, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9144 - val_loss: 0.1781 - val_acc: 0.9165\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1827 - acc: 0.9142 - val_loss: 0.1787 - val_acc: 0.9138\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9130 - val_loss: 0.1783 - val_acc: 0.9161\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.17810 to 0.17782, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9146 - val_loss: 0.1778 - val_acc: 0.9168\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.17782 to 0.17728, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9138 - val_loss: 0.1773 - val_acc: 0.9163\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9162 - val_loss: 0.1787 - val_acc: 0.9155\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9150 - val_loss: 0.1775 - val_acc: 0.9165\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9130 - val_loss: 0.1783 - val_acc: 0.9155\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9146 - val_loss: 0.1777 - val_acc: 0.9167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.17728 to 0.17696, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9158 - val_loss: 0.1770 - val_acc: 0.9163\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9150 - val_loss: 0.1780 - val_acc: 0.9168\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9145 - val_loss: 0.1774 - val_acc: 0.9168\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9142 - val_loss: 0.1771 - val_acc: 0.9168\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.17696 to 0.17692, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9152 - val_loss: 0.1769 - val_acc: 0.9172\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9143 - val_loss: 0.1777 - val_acc: 0.9168\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9137 - val_loss: 0.1780 - val_acc: 0.9159\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9138 - val_loss: 0.1770 - val_acc: 0.9172\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1809 - acc: 0.9141 - val_loss: 0.1770 - val_acc: 0.9172\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.17692 to 0.17670, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9158 - val_loss: 0.1767 - val_acc: 0.9168\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9143 - val_loss: 0.1768 - val_acc: 0.9168\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9140 - val_loss: 0.1772 - val_acc: 0.9170\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.17670 to 0.17662, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9147 - val_loss: 0.1766 - val_acc: 0.9167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.17662 to 0.17654, saving model to best.model\n",
      "1s - loss: 0.1801 - acc: 0.9159 - val_loss: 0.1765 - val_acc: 0.9182\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.17654 to 0.17635, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9147 - val_loss: 0.1763 - val_acc: 0.9165\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17635 to 0.17634, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9152 - val_loss: 0.1763 - val_acc: 0.9172\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.17634 to 0.17595, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9150 - val_loss: 0.1760 - val_acc: 0.9176\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9126 - val_loss: 0.1765 - val_acc: 0.9172\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9134 - val_loss: 0.1775 - val_acc: 0.9168\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.17595 to 0.17581, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9152 - val_loss: 0.1758 - val_acc: 0.9172\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9136 - val_loss: 0.1769 - val_acc: 0.9168\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.17581 to 0.17548, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9153 - val_loss: 0.1755 - val_acc: 0.9184\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9141 - val_loss: 0.1760 - val_acc: 0.9159\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9140 - val_loss: 0.1760 - val_acc: 0.9163\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9143 - val_loss: 0.1761 - val_acc: 0.9168\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9165 - val_loss: 0.1767 - val_acc: 0.9172\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9171 - val_loss: 0.1758 - val_acc: 0.9168\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9162 - val_loss: 0.1756 - val_acc: 0.9168\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1782 - acc: 0.9148 - val_loss: 0.1760 - val_acc: 0.9168\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.17548 to 0.17547, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9165 - val_loss: 0.1755 - val_acc: 0.9168\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.17547 to 0.17506, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9152 - val_loss: 0.1751 - val_acc: 0.9174\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9161 - val_loss: 0.1752 - val_acc: 0.9176\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9177 - val_loss: 0.1754 - val_acc: 0.9168\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1797 - acc: 0.9151 - val_loss: 0.1755 - val_acc: 0.9159\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.17506 to 0.17498, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9152 - val_loss: 0.1750 - val_acc: 0.9170\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1777 - acc: 0.9157 - val_loss: 0.1753 - val_acc: 0.9167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17498 to 0.17491, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9169 - val_loss: 0.1749 - val_acc: 0.9178\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17491 to 0.17488, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9166 - val_loss: 0.1749 - val_acc: 0.9174\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17488 to 0.17458, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9161 - val_loss: 0.1746 - val_acc: 0.9174\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.17458 to 0.17445, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9165 - val_loss: 0.1744 - val_acc: 0.9168\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9176 - val_loss: 0.1747 - val_acc: 0.9168\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9163 - val_loss: 0.1745 - val_acc: 0.9172\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9167 - val_loss: 0.1747 - val_acc: 0.9176\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9154 - val_loss: 0.1753 - val_acc: 0.9176\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "1s - loss: 0.1763 - acc: 0.9155 - val_loss: 0.1750 - val_acc: 0.9176\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.17445 to 0.17398, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9173 - val_loss: 0.1740 - val_acc: 0.9174\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9167 - val_loss: 0.1747 - val_acc: 0.9176\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9150 - val_loss: 0.1743 - val_acc: 0.9182\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9158 - val_loss: 0.1754 - val_acc: 0.9163\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17398 to 0.17394, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9164 - val_loss: 0.1739 - val_acc: 0.9180\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9171 - val_loss: 0.1740 - val_acc: 0.9176\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9161 - val_loss: 0.1741 - val_acc: 0.9178\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1752 - acc: 0.9175 - val_loss: 0.1741 - val_acc: 0.9191\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1745 - acc: 0.9176 - val_loss: 0.1747 - val_acc: 0.9174\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9174 - val_loss: 0.1745 - val_acc: 0.9170\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9169 - val_loss: 0.1743 - val_acc: 0.9180\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.17394 to 0.17321, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9175 - val_loss: 0.1732 - val_acc: 0.9180\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9189 - val_loss: 0.1734 - val_acc: 0.9186\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9184 - val_loss: 0.1736 - val_acc: 0.9186\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9181 - val_loss: 0.1737 - val_acc: 0.9193\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9182 - val_loss: 0.1736 - val_acc: 0.9178\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9173 - val_loss: 0.1747 - val_acc: 0.9190\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.17321 to 0.17300, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9181 - val_loss: 0.1730 - val_acc: 0.9184\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17300 to 0.17298, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9181 - val_loss: 0.1730 - val_acc: 0.9178\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9183 - val_loss: 0.1734 - val_acc: 0.9195\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9165 - val_loss: 0.1733 - val_acc: 0.9188\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9175 - val_loss: 0.1735 - val_acc: 0.9190\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9170 - val_loss: 0.1733 - val_acc: 0.9186\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9183 - val_loss: 0.1744 - val_acc: 0.9176\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9174 - val_loss: 0.1731 - val_acc: 0.9184\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9186 - val_loss: 0.1732 - val_acc: 0.9191\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17298 to 0.17295, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9175 - val_loss: 0.1730 - val_acc: 0.9184\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9170 - val_loss: 0.1732 - val_acc: 0.9186\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17295 to 0.17285, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9191 - val_loss: 0.1728 - val_acc: 0.9186\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.17285 to 0.17267, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9191 - val_loss: 0.1727 - val_acc: 0.9188\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9176 - val_loss: 0.1731 - val_acc: 0.9205\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9173 - val_loss: 0.1727 - val_acc: 0.9188\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9171 - val_loss: 0.1733 - val_acc: 0.9201\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17267 to 0.17261, saving model to best.model\n",
      "0s - loss: 0.1722 - acc: 0.9173 - val_loss: 0.1726 - val_acc: 0.9180\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9194 - val_loss: 0.1727 - val_acc: 0.9180\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9183 - val_loss: 0.1733 - val_acc: 0.9188\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9187 - val_loss: 0.1746 - val_acc: 0.9211\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17261 to 0.17252, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9196 - val_loss: 0.1725 - val_acc: 0.9190\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9187 - val_loss: 0.1730 - val_acc: 0.9201\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9193 - val_loss: 0.1731 - val_acc: 0.9191\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9180 - val_loss: 0.1727 - val_acc: 0.9195\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9201 - val_loss: 0.1737 - val_acc: 0.9186\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9189 - val_loss: 0.1725 - val_acc: 0.9188\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9196 - val_loss: 0.1732 - val_acc: 0.9207\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.17252 to 0.17240, saving model to best.model\n",
      "1s - loss: 0.1697 - acc: 0.9192 - val_loss: 0.1724 - val_acc: 0.9188\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.17240 to 0.17235, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9194 - val_loss: 0.1724 - val_acc: 0.9188\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.17235 to 0.17235, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9208 - val_loss: 0.1723 - val_acc: 0.9191\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9183 - val_loss: 0.1731 - val_acc: 0.9197\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9187 - val_loss: 0.1725 - val_acc: 0.9197\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9179 - val_loss: 0.1724 - val_acc: 0.9186\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9199 - val_loss: 0.1731 - val_acc: 0.9203\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9194 - val_loss: 0.1725 - val_acc: 0.9203\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.17235 to 0.17199, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9179 - val_loss: 0.1720 - val_acc: 0.9193\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9184 - val_loss: 0.1722 - val_acc: 0.9195\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9183 - val_loss: 0.1726 - val_acc: 0.9207\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9196 - val_loss: 0.1738 - val_acc: 0.9201\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9190 - val_loss: 0.1725 - val_acc: 0.9188\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9190 - val_loss: 0.1724 - val_acc: 0.9203\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9189 - val_loss: 0.1721 - val_acc: 0.9197\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.17199 to 0.17187, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9188 - val_loss: 0.1719 - val_acc: 0.9188\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9186 - val_loss: 0.1719 - val_acc: 0.9199\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9199 - val_loss: 0.1720 - val_acc: 0.9207\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9175 - val_loss: 0.1721 - val_acc: 0.9201\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9196 - val_loss: 0.1730 - val_acc: 0.9211\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9194 - val_loss: 0.1726 - val_acc: 0.9197\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9188 - val_loss: 0.1721 - val_acc: 0.9193\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1696 - acc: 0.9194 - val_loss: 0.1726 - val_acc: 0.9197\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9189 - val_loss: 0.1733 - val_acc: 0.9191\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9191 - val_loss: 0.1725 - val_acc: 0.9205\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34006, saving model to best.model\n",
      "0s - loss: 0.4789 - acc: 0.8324 - val_loss: 0.3401 - val_acc: 0.8880\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34006 to 0.27644, saving model to best.model\n",
      "0s - loss: 0.3560 - acc: 0.8802 - val_loss: 0.2764 - val_acc: 0.8880\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.27644 to 0.23146, saving model to best.model\n",
      "0s - loss: 0.2895 - acc: 0.8867 - val_loss: 0.2315 - val_acc: 0.9015\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.23146 to 0.20752, saving model to best.model\n",
      "0s - loss: 0.2475 - acc: 0.8955 - val_loss: 0.2075 - val_acc: 0.9026\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20752 to 0.20146, saving model to best.model\n",
      "0s - loss: 0.2289 - acc: 0.9005 - val_loss: 0.2015 - val_acc: 0.9026\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.20146 to 0.19839, saving model to best.model\n",
      "0s - loss: 0.2212 - acc: 0.9026 - val_loss: 0.1984 - val_acc: 0.9046\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19839 to 0.19723, saving model to best.model\n",
      "0s - loss: 0.2180 - acc: 0.9010 - val_loss: 0.1972 - val_acc: 0.9046\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19723 to 0.19649, saving model to best.model\n",
      "0s - loss: 0.2131 - acc: 0.9027 - val_loss: 0.1965 - val_acc: 0.9063\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19649 to 0.19528, saving model to best.model\n",
      "0s - loss: 0.2120 - acc: 0.9034 - val_loss: 0.1953 - val_acc: 0.9061\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19528 to 0.19462, saving model to best.model\n",
      "0s - loss: 0.2092 - acc: 0.9041 - val_loss: 0.1946 - val_acc: 0.9061\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2092 - acc: 0.9037 - val_loss: 0.1952 - val_acc: 0.9065\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19462 to 0.19411, saving model to best.model\n",
      "0s - loss: 0.2102 - acc: 0.9022 - val_loss: 0.1941 - val_acc: 0.9070\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.19411 to 0.19408, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9045 - val_loss: 0.1941 - val_acc: 0.9057\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19408 to 0.19390, saving model to best.model\n",
      "0s - loss: 0.2059 - acc: 0.9060 - val_loss: 0.1939 - val_acc: 0.9059\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "1s - loss: 0.2041 - acc: 0.9079 - val_loss: 0.1946 - val_acc: 0.9055\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19390 to 0.19351, saving model to best.model\n",
      "0s - loss: 0.2043 - acc: 0.9057 - val_loss: 0.1935 - val_acc: 0.9057\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19351 to 0.19340, saving model to best.model\n",
      "0s - loss: 0.2022 - acc: 0.9063 - val_loss: 0.1934 - val_acc: 0.9053\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19340 to 0.19287, saving model to best.model\n",
      "1s - loss: 0.2034 - acc: 0.9061 - val_loss: 0.1929 - val_acc: 0.9067\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19287 to 0.19276, saving model to best.model\n",
      "0s - loss: 0.2027 - acc: 0.9055 - val_loss: 0.1928 - val_acc: 0.9053\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19276 to 0.19267, saving model to best.model\n",
      "0s - loss: 0.2018 - acc: 0.9061 - val_loss: 0.1927 - val_acc: 0.9057\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1995 - acc: 0.9078 - val_loss: 0.1929 - val_acc: 0.9061\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19267 to 0.19245, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9077 - val_loss: 0.1925 - val_acc: 0.9070\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2024 - acc: 0.9077 - val_loss: 0.1927 - val_acc: 0.9067\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19245 to 0.19199, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9087 - val_loss: 0.1920 - val_acc: 0.9070\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1995 - acc: 0.9061 - val_loss: 0.1928 - val_acc: 0.9070\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.1999 - acc: 0.9082 - val_loss: 0.1920 - val_acc: 0.9065\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19199 to 0.19159, saving model to best.model\n",
      "0s - loss: 0.2006 - acc: 0.9092 - val_loss: 0.1916 - val_acc: 0.9074\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9080 - val_loss: 0.1920 - val_acc: 0.9069\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19159 to 0.19154, saving model to best.model\n",
      "0s - loss: 0.1996 - acc: 0.9083 - val_loss: 0.1915 - val_acc: 0.9069\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19154 to 0.19100, saving model to best.model\n",
      "0s - loss: 0.1976 - acc: 0.9097 - val_loss: 0.1910 - val_acc: 0.9063\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1968 - acc: 0.9106 - val_loss: 0.1910 - val_acc: 0.9065\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19100 to 0.19058, saving model to best.model\n",
      "1s - loss: 0.1960 - acc: 0.9090 - val_loss: 0.1906 - val_acc: 0.9069\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1974 - acc: 0.9090 - val_loss: 0.1909 - val_acc: 0.9061\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.1983 - acc: 0.9090 - val_loss: 0.1906 - val_acc: 0.9061\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19058 to 0.18994, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9083 - val_loss: 0.1899 - val_acc: 0.9059\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18994 to 0.18981, saving model to best.model\n",
      "0s - loss: 0.1960 - acc: 0.9104 - val_loss: 0.1898 - val_acc: 0.9074\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1940 - acc: 0.9102 - val_loss: 0.1899 - val_acc: 0.9074\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1958 - acc: 0.9086 - val_loss: 0.1899 - val_acc: 0.9063\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18981 to 0.18908, saving model to best.model\n",
      "0s - loss: 0.1958 - acc: 0.9088 - val_loss: 0.1891 - val_acc: 0.9061\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1934 - acc: 0.9093 - val_loss: 0.1892 - val_acc: 0.9069\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1939 - acc: 0.9100 - val_loss: 0.1895 - val_acc: 0.9069\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18908 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.1934 - acc: 0.9114 - val_loss: 0.1888 - val_acc: 0.9070\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18876 to 0.18842, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9090 - val_loss: 0.1884 - val_acc: 0.9059\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18842 to 0.18837, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9103 - val_loss: 0.1884 - val_acc: 0.9070\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18837 to 0.18795, saving model to best.model\n",
      "0s - loss: 0.1919 - acc: 0.9117 - val_loss: 0.1880 - val_acc: 0.9061\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9123 - val_loss: 0.1885 - val_acc: 0.9072\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9122 - val_loss: 0.1881 - val_acc: 0.9076\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18795 to 0.18752, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9121 - val_loss: 0.1875 - val_acc: 0.9065\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.18752 to 0.18729, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9119 - val_loss: 0.1873 - val_acc: 0.9074\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9114 - val_loss: 0.1877 - val_acc: 0.9074\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18729 to 0.18726, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9117 - val_loss: 0.1873 - val_acc: 0.9076\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9105 - val_loss: 0.1875 - val_acc: 0.9082\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "1s - loss: 0.1912 - acc: 0.9113 - val_loss: 0.1876 - val_acc: 0.9076\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.18726 to 0.18667, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9120 - val_loss: 0.1867 - val_acc: 0.9088\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1910 - acc: 0.9126 - val_loss: 0.1868 - val_acc: 0.9076\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9126 - val_loss: 0.1867 - val_acc: 0.9084\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1898 - acc: 0.9125 - val_loss: 0.1872 - val_acc: 0.9076\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9127 - val_loss: 0.1873 - val_acc: 0.9080\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18667 to 0.18653, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9120 - val_loss: 0.1865 - val_acc: 0.9094\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1902 - acc: 0.9120 - val_loss: 0.1867 - val_acc: 0.9070\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.18653 to 0.18610, saving model to best.model\n",
      "1s - loss: 0.1890 - acc: 0.9125 - val_loss: 0.1861 - val_acc: 0.9080\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18610 to 0.18585, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9127 - val_loss: 0.1858 - val_acc: 0.9084\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1892 - acc: 0.9130 - val_loss: 0.1858 - val_acc: 0.9080\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1903 - acc: 0.9134 - val_loss: 0.1859 - val_acc: 0.9074\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18585 to 0.18579, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9129 - val_loss: 0.1858 - val_acc: 0.9084\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9147 - val_loss: 0.1858 - val_acc: 0.9090\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "1s - loss: 0.1884 - acc: 0.9141 - val_loss: 0.1866 - val_acc: 0.9082\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18579 to 0.18578, saving model to best.model\n",
      "0s - loss: 0.1892 - acc: 0.9137 - val_loss: 0.1858 - val_acc: 0.9086\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18578 to 0.18562, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9137 - val_loss: 0.1856 - val_acc: 0.9080\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9125 - val_loss: 0.1863 - val_acc: 0.9084\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18562 to 0.18556, saving model to best.model\n",
      "0s - loss: 0.1873 - acc: 0.9131 - val_loss: 0.1856 - val_acc: 0.9099\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9137 - val_loss: 0.1858 - val_acc: 0.9101\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1887 - acc: 0.9137 - val_loss: 0.1859 - val_acc: 0.9105\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18556 to 0.18493, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9121 - val_loss: 0.1849 - val_acc: 0.9084\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9135 - val_loss: 0.1854 - val_acc: 0.9099\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9138 - val_loss: 0.1852 - val_acc: 0.9092\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18493 to 0.18470, saving model to best.model\n",
      "0s - loss: 0.1870 - acc: 0.9147 - val_loss: 0.1847 - val_acc: 0.9092\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9123 - val_loss: 0.1853 - val_acc: 0.9107\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1883 - acc: 0.9138 - val_loss: 0.1847 - val_acc: 0.9109\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.18470 to 0.18459, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9135 - val_loss: 0.1846 - val_acc: 0.9111\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18459 to 0.18431, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9126 - val_loss: 0.1843 - val_acc: 0.9097\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "1s - loss: 0.1879 - acc: 0.9138 - val_loss: 0.1844 - val_acc: 0.9105\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9130 - val_loss: 0.1846 - val_acc: 0.9097\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.18431 to 0.18421, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9132 - val_loss: 0.1842 - val_acc: 0.9090\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.18421 to 0.18406, saving model to best.model\n",
      "0s - loss: 0.1859 - acc: 0.9142 - val_loss: 0.1841 - val_acc: 0.9101\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9150 - val_loss: 0.1845 - val_acc: 0.9109\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9150 - val_loss: 0.1842 - val_acc: 0.9109\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18406 to 0.18388, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9132 - val_loss: 0.1839 - val_acc: 0.9097\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.18388 to 0.18345, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9150 - val_loss: 0.1834 - val_acc: 0.9107\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.18345 to 0.18327, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9155 - val_loss: 0.1833 - val_acc: 0.9095\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9168 - val_loss: 0.1834 - val_acc: 0.9105\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9148 - val_loss: 0.1836 - val_acc: 0.9111\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18327 to 0.18299, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9139 - val_loss: 0.1830 - val_acc: 0.9109\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.18299 to 0.18294, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9146 - val_loss: 0.1829 - val_acc: 0.9109\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9143 - val_loss: 0.1832 - val_acc: 0.9118\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1848 - acc: 0.9157 - val_loss: 0.1831 - val_acc: 0.9118\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9160 - val_loss: 0.1831 - val_acc: 0.9111\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9157 - val_loss: 0.1833 - val_acc: 0.9113\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9150 - val_loss: 0.1830 - val_acc: 0.9128\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18294 to 0.18272, saving model to best.model\n",
      "0s - loss: 0.1840 - acc: 0.9149 - val_loss: 0.1827 - val_acc: 0.9115\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18272 to 0.18269, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9161 - val_loss: 0.1827 - val_acc: 0.9111\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.18269 to 0.18234, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9157 - val_loss: 0.1823 - val_acc: 0.9111\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9146 - val_loss: 0.1826 - val_acc: 0.9113\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9152 - val_loss: 0.1824 - val_acc: 0.9122\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "1s - loss: 0.1838 - acc: 0.9170 - val_loss: 0.1827 - val_acc: 0.9113\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.18234 to 0.18217, saving model to best.model\n",
      "0s - loss: 0.1838 - acc: 0.9146 - val_loss: 0.1822 - val_acc: 0.9122\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9160 - val_loss: 0.1830 - val_acc: 0.9113\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.18217 to 0.18194, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9152 - val_loss: 0.1819 - val_acc: 0.9132\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.18194 to 0.18190, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9152 - val_loss: 0.1819 - val_acc: 0.9124\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9169 - val_loss: 0.1821 - val_acc: 0.9113\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.18190 to 0.18174, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9174 - val_loss: 0.1817 - val_acc: 0.9113\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9147 - val_loss: 0.1817 - val_acc: 0.9126\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.18174 to 0.18151, saving model to best.model\n",
      "0s - loss: 0.1823 - acc: 0.9159 - val_loss: 0.1815 - val_acc: 0.9130\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.18151 to 0.18138, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9159 - val_loss: 0.1814 - val_acc: 0.9120\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9160 - val_loss: 0.1823 - val_acc: 0.9122\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9163 - val_loss: 0.1817 - val_acc: 0.9111\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.18138 to 0.18114, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9167 - val_loss: 0.1811 - val_acc: 0.9124\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9160 - val_loss: 0.1812 - val_acc: 0.9126\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.18114 to 0.18110, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9161 - val_loss: 0.1811 - val_acc: 0.9118\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "1s - loss: 0.1813 - acc: 0.9152 - val_loss: 0.1818 - val_acc: 0.9115\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.18110 to 0.18069, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9156 - val_loss: 0.1807 - val_acc: 0.9126\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9176 - val_loss: 0.1818 - val_acc: 0.9126\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9178 - val_loss: 0.1808 - val_acc: 0.9128\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9159 - val_loss: 0.1810 - val_acc: 0.9134\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9181 - val_loss: 0.1824 - val_acc: 0.9128\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9171 - val_loss: 0.1808 - val_acc: 0.9134\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18069 to 0.18041, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9176 - val_loss: 0.1804 - val_acc: 0.9124\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9160 - val_loss: 0.1804 - val_acc: 0.9134\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1810 - acc: 0.9161 - val_loss: 0.1810 - val_acc: 0.9124\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9164 - val_loss: 0.1807 - val_acc: 0.9130\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.18041 to 0.18036, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9165 - val_loss: 0.1804 - val_acc: 0.9120\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.18036 to 0.18026, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9174 - val_loss: 0.1803 - val_acc: 0.9138\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.18026 to 0.18002, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9167 - val_loss: 0.1800 - val_acc: 0.9126\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.18002 to 0.17993, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9185 - val_loss: 0.1799 - val_acc: 0.9130\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9163 - val_loss: 0.1803 - val_acc: 0.9140\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "1s - loss: 0.1797 - acc: 0.9175 - val_loss: 0.1800 - val_acc: 0.9134\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9179 - val_loss: 0.1800 - val_acc: 0.9122\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "1s - loss: 0.1799 - acc: 0.9152 - val_loss: 0.1799 - val_acc: 0.9130\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17993 to 0.17959, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9177 - val_loss: 0.1796 - val_acc: 0.9122\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9156 - val_loss: 0.1797 - val_acc: 0.9130\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9161 - val_loss: 0.1796 - val_acc: 0.9130\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.17959 to 0.17923, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9170 - val_loss: 0.1792 - val_acc: 0.9138\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9166 - val_loss: 0.1796 - val_acc: 0.9130\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9190 - val_loss: 0.1803 - val_acc: 0.9140\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1789 - acc: 0.9168 - val_loss: 0.1792 - val_acc: 0.9128\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9162 - val_loss: 0.1796 - val_acc: 0.9143\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9171 - val_loss: 0.1794 - val_acc: 0.9136\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9166 - val_loss: 0.1795 - val_acc: 0.9126\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1796 - acc: 0.9160 - val_loss: 0.1796 - val_acc: 0.9128\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17923 to 0.17895, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9187 - val_loss: 0.1789 - val_acc: 0.9147\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9162 - val_loss: 0.1795 - val_acc: 0.9134\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9183 - val_loss: 0.1796 - val_acc: 0.9134\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9190 - val_loss: 0.1795 - val_acc: 0.9142\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "1s - loss: 0.1762 - acc: 0.9177 - val_loss: 0.1791 - val_acc: 0.9128\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9187 - val_loss: 0.1792 - val_acc: 0.9140\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9188 - val_loss: 0.1790 - val_acc: 0.9142\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.17895 to 0.17884, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9177 - val_loss: 0.1788 - val_acc: 0.9147\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9174 - val_loss: 0.1791 - val_acc: 0.9151\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9170 - val_loss: 0.1790 - val_acc: 0.9140\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9192 - val_loss: 0.1792 - val_acc: 0.9130\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9175 - val_loss: 0.1791 - val_acc: 0.9130\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.17884 to 0.17881, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9197 - val_loss: 0.1788 - val_acc: 0.9140\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.17881 to 0.17823, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9183 - val_loss: 0.1782 - val_acc: 0.9143\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9187 - val_loss: 0.1786 - val_acc: 0.9124\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.17823 to 0.17816, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9193 - val_loss: 0.1782 - val_acc: 0.9132\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9176 - val_loss: 0.1783 - val_acc: 0.9132\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9170 - val_loss: 0.1785 - val_acc: 0.9130\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9184 - val_loss: 0.1787 - val_acc: 0.9138\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9197 - val_loss: 0.1792 - val_acc: 0.9134\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9204 - val_loss: 0.1791 - val_acc: 0.9136\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.17816 to 0.17803, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9174 - val_loss: 0.1780 - val_acc: 0.9142\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9188 - val_loss: 0.1785 - val_acc: 0.9134\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9189 - val_loss: 0.1788 - val_acc: 0.9138\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9175 - val_loss: 0.1783 - val_acc: 0.9128\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.17803 to 0.17801, saving model to best.model\n",
      "0s - loss: 0.1758 - acc: 0.9198 - val_loss: 0.1780 - val_acc: 0.9128\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9187 - val_loss: 0.1784 - val_acc: 0.9142\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9200 - val_loss: 0.1780 - val_acc: 0.9136\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9191 - val_loss: 0.1781 - val_acc: 0.9132\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17801 to 0.17793, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9183 - val_loss: 0.1779 - val_acc: 0.9140\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "1s - loss: 0.1744 - acc: 0.9187 - val_loss: 0.1781 - val_acc: 0.9140\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9182 - val_loss: 0.1789 - val_acc: 0.9151\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9199 - val_loss: 0.1781 - val_acc: 0.9142\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.17793 to 0.17754, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9175 - val_loss: 0.1775 - val_acc: 0.9134\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9177 - val_loss: 0.1776 - val_acc: 0.9128\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17754 to 0.17734, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9190 - val_loss: 0.1773 - val_acc: 0.9138\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9207 - val_loss: 0.1783 - val_acc: 0.9134\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.17734 to 0.17712, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9183 - val_loss: 0.1771 - val_acc: 0.9134\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9185 - val_loss: 0.1778 - val_acc: 0.9128\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9185 - val_loss: 0.1773 - val_acc: 0.9132\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.17712 to 0.17687, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9193 - val_loss: 0.1769 - val_acc: 0.9142\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9189 - val_loss: 0.1780 - val_acc: 0.9142\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9211 - val_loss: 0.1773 - val_acc: 0.9134\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9199 - val_loss: 0.1771 - val_acc: 0.9138\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9179 - val_loss: 0.1772 - val_acc: 0.9128\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1720 - acc: 0.9201 - val_loss: 0.1776 - val_acc: 0.9153\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9204 - val_loss: 0.1770 - val_acc: 0.9147\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9202 - val_loss: 0.1780 - val_acc: 0.9136\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9210 - val_loss: 0.1772 - val_acc: 0.9132\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9188 - val_loss: 0.1780 - val_acc: 0.9147\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "1s - loss: 0.1711 - acc: 0.9208 - val_loss: 0.1774 - val_acc: 0.9142\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.34921, saving model to best.model\n",
      "0s - loss: 0.4908 - acc: 0.8292 - val_loss: 0.3492 - val_acc: 0.8850\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.34921 to 0.29276, saving model to best.model\n",
      "0s - loss: 0.3650 - acc: 0.8819 - val_loss: 0.2928 - val_acc: 0.8850\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.29276 to 0.23768, saving model to best.model\n",
      "0s - loss: 0.2983 - acc: 0.8871 - val_loss: 0.2377 - val_acc: 0.8982\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.23768 to 0.20570, saving model to best.model\n",
      "0s - loss: 0.2529 - acc: 0.8948 - val_loss: 0.2057 - val_acc: 0.9063\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20570 to 0.19518, saving model to best.model\n",
      "0s - loss: 0.2305 - acc: 0.8993 - val_loss: 0.1952 - val_acc: 0.9113\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.2195 - acc: 0.9001 - val_loss: 0.1958 - val_acc: 0.9124\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19518 to 0.19169, saving model to best.model\n",
      "0s - loss: 0.2174 - acc: 0.9012 - val_loss: 0.1917 - val_acc: 0.9111\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19169 to 0.19079, saving model to best.model\n",
      "0s - loss: 0.2145 - acc: 0.9023 - val_loss: 0.1908 - val_acc: 0.9105\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19079 to 0.19058, saving model to best.model\n",
      "0s - loss: 0.2100 - acc: 0.9029 - val_loss: 0.1906 - val_acc: 0.9094\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19058 to 0.19024, saving model to best.model\n",
      "0s - loss: 0.2077 - acc: 0.9020 - val_loss: 0.1902 - val_acc: 0.9132\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19024 to 0.19012, saving model to best.model\n",
      "0s - loss: 0.2047 - acc: 0.9050 - val_loss: 0.1901 - val_acc: 0.9122\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.2045 - acc: 0.9050 - val_loss: 0.1904 - val_acc: 0.9128\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "1s - loss: 0.2037 - acc: 0.9047 - val_loss: 0.1908 - val_acc: 0.9122\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.2020 - acc: 0.9046 - val_loss: 0.1920 - val_acc: 0.9072\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.2026 - acc: 0.9049 - val_loss: 0.1905 - val_acc: 0.9120\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2000 - acc: 0.9044 - val_loss: 0.1903 - val_acc: 0.9109\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1997 - acc: 0.9073 - val_loss: 0.1903 - val_acc: 0.9120\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1998 - acc: 0.9053 - val_loss: 0.1903 - val_acc: 0.9118\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.19012 to 0.19009, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9059 - val_loss: 0.1901 - val_acc: 0.9118\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19009 to 0.19006, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9075 - val_loss: 0.1901 - val_acc: 0.9092\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.19006 to 0.18992, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9069 - val_loss: 0.1899 - val_acc: 0.9120\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9062 - val_loss: 0.1905 - val_acc: 0.9124\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1975 - acc: 0.9078 - val_loss: 0.1904 - val_acc: 0.9082\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18992 to 0.18965, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9080 - val_loss: 0.1896 - val_acc: 0.9111\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9061 - val_loss: 0.1897 - val_acc: 0.9122\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18965 to 0.18926, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9082 - val_loss: 0.1893 - val_acc: 0.9109\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "1s - loss: 0.1962 - acc: 0.9066 - val_loss: 0.1895 - val_acc: 0.9084\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18926 to 0.18909, saving model to best.model\n",
      "0s - loss: 0.1967 - acc: 0.9072 - val_loss: 0.1891 - val_acc: 0.9120\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1961 - acc: 0.9076 - val_loss: 0.1901 - val_acc: 0.9101\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1965 - acc: 0.9083 - val_loss: 0.1891 - val_acc: 0.9124\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18909 to 0.18887, saving model to best.model\n",
      "1s - loss: 0.1945 - acc: 0.9078 - val_loss: 0.1889 - val_acc: 0.9124\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18887 to 0.18876, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9058 - val_loss: 0.1888 - val_acc: 0.9118\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18876 to 0.18871, saving model to best.model\n",
      "0s - loss: 0.1978 - acc: 0.9066 - val_loss: 0.1887 - val_acc: 0.9130\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18871 to 0.18850, saving model to best.model\n",
      "0s - loss: 0.1945 - acc: 0.9068 - val_loss: 0.1885 - val_acc: 0.9118\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.1936 - acc: 0.9075 - val_loss: 0.1894 - val_acc: 0.9099\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18850 to 0.18826, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9078 - val_loss: 0.1883 - val_acc: 0.9126\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9080 - val_loss: 0.1883 - val_acc: 0.9130\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "1s - loss: 0.1932 - acc: 0.9102 - val_loss: 0.1883 - val_acc: 0.9124\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18826 to 0.18818, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9079 - val_loss: 0.1882 - val_acc: 0.9109\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18818 to 0.18795, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9073 - val_loss: 0.1880 - val_acc: 0.9120\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18795 to 0.18779, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9101 - val_loss: 0.1878 - val_acc: 0.9132\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18779 to 0.18771, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9083 - val_loss: 0.1877 - val_acc: 0.9142\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18771 to 0.18751, saving model to best.model\n",
      "1s - loss: 0.1928 - acc: 0.9090 - val_loss: 0.1875 - val_acc: 0.9115\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18751 to 0.18716, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9097 - val_loss: 0.1872 - val_acc: 0.9132\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1922 - acc: 0.9104 - val_loss: 0.1875 - val_acc: 0.9120\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9082 - val_loss: 0.1873 - val_acc: 0.9142\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18716 to 0.18682, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9099 - val_loss: 0.1868 - val_acc: 0.9130\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18682 to 0.18669, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9102 - val_loss: 0.1867 - val_acc: 0.9130\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "1s - loss: 0.1886 - acc: 0.9109 - val_loss: 0.1879 - val_acc: 0.9113\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1914 - acc: 0.9107 - val_loss: 0.1870 - val_acc: 0.9140\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.18669 to 0.18653, saving model to best.model\n",
      "0s - loss: 0.1903 - acc: 0.9083 - val_loss: 0.1865 - val_acc: 0.9130\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.18653 to 0.18643, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9096 - val_loss: 0.1864 - val_acc: 0.9132\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18643 to 0.18626, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9103 - val_loss: 0.1863 - val_acc: 0.9124\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1885 - acc: 0.9103 - val_loss: 0.1866 - val_acc: 0.9124\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18626 to 0.18610, saving model to best.model\n",
      "0s - loss: 0.1879 - acc: 0.9118 - val_loss: 0.1861 - val_acc: 0.9134\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9114 - val_loss: 0.1861 - val_acc: 0.9120\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.18610 to 0.18596, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9097 - val_loss: 0.1860 - val_acc: 0.9140\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1890 - acc: 0.9116 - val_loss: 0.1861 - val_acc: 0.9109\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18596 to 0.18592, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9123 - val_loss: 0.1859 - val_acc: 0.9109\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9115 - val_loss: 0.1860 - val_acc: 0.9136\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "1s - loss: 0.1877 - acc: 0.9113 - val_loss: 0.1863 - val_acc: 0.9143\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18592 to 0.18561, saving model to best.model\n",
      "0s - loss: 0.1881 - acc: 0.9118 - val_loss: 0.1856 - val_acc: 0.9124\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9131 - val_loss: 0.1858 - val_acc: 0.9122\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9117 - val_loss: 0.1858 - val_acc: 0.9115\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9111 - val_loss: 0.1858 - val_acc: 0.9115\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1875 - acc: 0.9120 - val_loss: 0.1859 - val_acc: 0.9132\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9096 - val_loss: 0.1857 - val_acc: 0.9130\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18561 to 0.18520, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9114 - val_loss: 0.1852 - val_acc: 0.9115\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18520 to 0.18510, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9116 - val_loss: 0.1851 - val_acc: 0.9130\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9124 - val_loss: 0.1856 - val_acc: 0.9120\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.18510 to 0.18449, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9116 - val_loss: 0.1845 - val_acc: 0.9118\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1874 - acc: 0.9115 - val_loss: 0.1854 - val_acc: 0.9138\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9110 - val_loss: 0.1849 - val_acc: 0.9126\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9121 - val_loss: 0.1857 - val_acc: 0.9115\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "1s - loss: 0.1844 - acc: 0.9126 - val_loss: 0.1847 - val_acc: 0.9128\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "1s - loss: 0.1832 - acc: 0.9141 - val_loss: 0.1846 - val_acc: 0.9126\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18449 to 0.18436, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9117 - val_loss: 0.1844 - val_acc: 0.9122\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1853 - acc: 0.9119 - val_loss: 0.1847 - val_acc: 0.9130\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.18436 to 0.18426, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9119 - val_loss: 0.1843 - val_acc: 0.9120\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "1s - loss: 0.1838 - acc: 0.9118 - val_loss: 0.1847 - val_acc: 0.9124\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.18426 to 0.18400, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9134 - val_loss: 0.1840 - val_acc: 0.9120\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9138 - val_loss: 0.1847 - val_acc: 0.9134\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9126 - val_loss: 0.1841 - val_acc: 0.9122\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9131 - val_loss: 0.1845 - val_acc: 0.9128\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.18400 to 0.18389, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9136 - val_loss: 0.1839 - val_acc: 0.9122\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.18389 to 0.18359, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9130 - val_loss: 0.1836 - val_acc: 0.9126\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1837 - acc: 0.9118 - val_loss: 0.1841 - val_acc: 0.9120\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9133 - val_loss: 0.1841 - val_acc: 0.9134\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9130 - val_loss: 0.1838 - val_acc: 0.9124\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.18359 to 0.18323, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9135 - val_loss: 0.1832 - val_acc: 0.9128\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9118 - val_loss: 0.1839 - val_acc: 0.9132\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9130 - val_loss: 0.1835 - val_acc: 0.9122\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9117 - val_loss: 0.1834 - val_acc: 0.9134\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.18323 to 0.18319, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9144 - val_loss: 0.1832 - val_acc: 0.9122\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.1804 - acc: 0.9140 - val_loss: 0.1836 - val_acc: 0.9155\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18319 to 0.18267, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9139 - val_loss: 0.1827 - val_acc: 0.9124\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1807 - acc: 0.9151 - val_loss: 0.1828 - val_acc: 0.9124\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1831 - acc: 0.9126 - val_loss: 0.1831 - val_acc: 0.9145\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.18267 to 0.18254, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9127 - val_loss: 0.1825 - val_acc: 0.9124\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1811 - acc: 0.9139 - val_loss: 0.1834 - val_acc: 0.9147\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18254 to 0.18253, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9151 - val_loss: 0.1825 - val_acc: 0.9128\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9140 - val_loss: 0.1827 - val_acc: 0.9136\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9157 - val_loss: 0.1826 - val_acc: 0.9124\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.18253 to 0.18237, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9132 - val_loss: 0.1824 - val_acc: 0.9134\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9148 - val_loss: 0.1827 - val_acc: 0.9122\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9142 - val_loss: 0.1827 - val_acc: 0.9157\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "1s - loss: 0.1805 - acc: 0.9139 - val_loss: 0.1825 - val_acc: 0.9130\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1802 - acc: 0.9152 - val_loss: 0.1825 - val_acc: 0.9140\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1799 - acc: 0.9143 - val_loss: 0.1825 - val_acc: 0.9130\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18237 to 0.18210, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9146 - val_loss: 0.1821 - val_acc: 0.9136\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9152 - val_loss: 0.1824 - val_acc: 0.9134\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.18210 to 0.18207, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9134 - val_loss: 0.1821 - val_acc: 0.9138\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.18207 to 0.18197, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9151 - val_loss: 0.1820 - val_acc: 0.9128\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.18197 to 0.18191, saving model to best.model\n",
      "0s - loss: 0.1797 - acc: 0.9128 - val_loss: 0.1819 - val_acc: 0.9142\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.18191 to 0.18186, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9158 - val_loss: 0.1819 - val_acc: 0.9138\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.18186 to 0.18185, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9152 - val_loss: 0.1819 - val_acc: 0.9128\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9141 - val_loss: 0.1820 - val_acc: 0.9134\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18185 to 0.18182, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9138 - val_loss: 0.1818 - val_acc: 0.9134\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9141 - val_loss: 0.1820 - val_acc: 0.9134\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9141 - val_loss: 0.1819 - val_acc: 0.9134\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.18182 to 0.18176, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9147 - val_loss: 0.1818 - val_acc: 0.9138\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.18176 to 0.18173, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9125 - val_loss: 0.1817 - val_acc: 0.9136\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.18173 to 0.18164, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9154 - val_loss: 0.1816 - val_acc: 0.9134\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9154 - val_loss: 0.1819 - val_acc: 0.9140\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9144 - val_loss: 0.1819 - val_acc: 0.9136\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9154 - val_loss: 0.1821 - val_acc: 0.9138\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.18164 to 0.18135, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9158 - val_loss: 0.1814 - val_acc: 0.9132\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.18135 to 0.18123, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9159 - val_loss: 0.1812 - val_acc: 0.9140\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9149 - val_loss: 0.1814 - val_acc: 0.9132\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.18123 to 0.18089, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9175 - val_loss: 0.1809 - val_acc: 0.9134\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9140 - val_loss: 0.1811 - val_acc: 0.9142\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.18089 to 0.18085, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9164 - val_loss: 0.1808 - val_acc: 0.9142\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1755 - acc: 0.9165 - val_loss: 0.1809 - val_acc: 0.9142\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1766 - acc: 0.9160 - val_loss: 0.1811 - val_acc: 0.9145\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9162 - val_loss: 0.1809 - val_acc: 0.9151\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9163 - val_loss: 0.1813 - val_acc: 0.9142\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.18085 to 0.18075, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9152 - val_loss: 0.1807 - val_acc: 0.9147\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1753 - acc: 0.9171 - val_loss: 0.1809 - val_acc: 0.9147\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.18075 to 0.18023, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9154 - val_loss: 0.1802 - val_acc: 0.9130\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9154 - val_loss: 0.1806 - val_acc: 0.9145\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9149 - val_loss: 0.1807 - val_acc: 0.9142\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1764 - acc: 0.9156 - val_loss: 0.1808 - val_acc: 0.9138\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1765 - acc: 0.9158 - val_loss: 0.1802 - val_acc: 0.9145\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9158 - val_loss: 0.1806 - val_acc: 0.9142\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9168 - val_loss: 0.1803 - val_acc: 0.9142\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.18023 to 0.18016, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9155 - val_loss: 0.1802 - val_acc: 0.9155\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.18016 to 0.18014, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9150 - val_loss: 0.1801 - val_acc: 0.9145\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9170 - val_loss: 0.1803 - val_acc: 0.9153\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.18014 to 0.17971, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9162 - val_loss: 0.1797 - val_acc: 0.9157\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9151 - val_loss: 0.1798 - val_acc: 0.9149\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9161 - val_loss: 0.1802 - val_acc: 0.9140\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9164 - val_loss: 0.1801 - val_acc: 0.9138\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9174 - val_loss: 0.1801 - val_acc: 0.9145\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17971 to 0.17927, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9175 - val_loss: 0.1793 - val_acc: 0.9147\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1746 - acc: 0.9178 - val_loss: 0.1794 - val_acc: 0.9136\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9161 - val_loss: 0.1801 - val_acc: 0.9155\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9172 - val_loss: 0.1800 - val_acc: 0.9149\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9176 - val_loss: 0.1795 - val_acc: 0.9132\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9165 - val_loss: 0.1796 - val_acc: 0.9147\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9174 - val_loss: 0.1810 - val_acc: 0.9151\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1734 - acc: 0.9172 - val_loss: 0.1798 - val_acc: 0.9130\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9174 - val_loss: 0.1800 - val_acc: 0.9126\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9160 - val_loss: 0.1800 - val_acc: 0.9147\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9163 - val_loss: 0.1793 - val_acc: 0.9155\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9163 - val_loss: 0.1793 - val_acc: 0.9153\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9172 - val_loss: 0.1801 - val_acc: 0.9155\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.17927 to 0.17898, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9173 - val_loss: 0.1790 - val_acc: 0.9153\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9158 - val_loss: 0.1795 - val_acc: 0.9142\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9176 - val_loss: 0.1793 - val_acc: 0.9142\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9171 - val_loss: 0.1790 - val_acc: 0.9140\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9176 - val_loss: 0.1794 - val_acc: 0.9149\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1728 - acc: 0.9163 - val_loss: 0.1792 - val_acc: 0.9138\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.17898 to 0.17872, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9183 - val_loss: 0.1787 - val_acc: 0.9142\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.17872 to 0.17846, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9181 - val_loss: 0.1785 - val_acc: 0.9149\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9177 - val_loss: 0.1787 - val_acc: 0.9151\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9178 - val_loss: 0.1788 - val_acc: 0.9138\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.17846 to 0.17845, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9187 - val_loss: 0.1785 - val_acc: 0.9147\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9184 - val_loss: 0.1786 - val_acc: 0.9147\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.17845 to 0.17837, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9169 - val_loss: 0.1784 - val_acc: 0.9140\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.17837 to 0.17805, saving model to best.model\n",
      "0s - loss: 0.1707 - acc: 0.9185 - val_loss: 0.1781 - val_acc: 0.9151\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9178 - val_loss: 0.1789 - val_acc: 0.9147\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1725 - acc: 0.9174 - val_loss: 0.1789 - val_acc: 0.9167\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9193 - val_loss: 0.1786 - val_acc: 0.9143\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9187 - val_loss: 0.1792 - val_acc: 0.9145\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9193 - val_loss: 0.1786 - val_acc: 0.9145\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9180 - val_loss: 0.1786 - val_acc: 0.9157\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.17805 to 0.17788, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9189 - val_loss: 0.1779 - val_acc: 0.9143\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9203 - val_loss: 0.1786 - val_acc: 0.9155\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9195 - val_loss: 0.1790 - val_acc: 0.9151\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9174 - val_loss: 0.1788 - val_acc: 0.9157\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9190 - val_loss: 0.1780 - val_acc: 0.9178\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9183 - val_loss: 0.1780 - val_acc: 0.9153\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9197 - val_loss: 0.1782 - val_acc: 0.9157\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9180 - val_loss: 0.1786 - val_acc: 0.9147\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1703 - acc: 0.9188 - val_loss: 0.1785 - val_acc: 0.9153\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9174 - val_loss: 0.1784 - val_acc: 0.9157\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9184 - val_loss: 0.1780 - val_acc: 0.9159\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9183 - val_loss: 0.1782 - val_acc: 0.9151\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9196 - val_loss: 0.1779 - val_acc: 0.9168\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9185 - val_loss: 0.1781 - val_acc: 0.9170\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.31790, saving model to best.model\n",
      "0s - loss: 0.3788 - acc: 0.8847 - val_loss: 0.3179 - val_acc: 0.8898\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.31790 to 0.23895, saving model to best.model\n",
      "0s - loss: 0.3004 - acc: 0.8896 - val_loss: 0.2390 - val_acc: 0.9030\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.23895 to 0.20691, saving model to best.model\n",
      "0s - loss: 0.2436 - acc: 0.8981 - val_loss: 0.2069 - val_acc: 0.9078\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.20691 to 0.19685, saving model to best.model\n",
      "0s - loss: 0.2231 - acc: 0.9003 - val_loss: 0.1969 - val_acc: 0.9094\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.19685 to 0.19393, saving model to best.model\n",
      "0s - loss: 0.2130 - acc: 0.9014 - val_loss: 0.1939 - val_acc: 0.9094\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.19393 to 0.19251, saving model to best.model\n",
      "0s - loss: 0.2057 - acc: 0.9063 - val_loss: 0.1925 - val_acc: 0.9094\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19251 to 0.19203, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9047 - val_loss: 0.1920 - val_acc: 0.9094\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.19203 to 0.19148, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9047 - val_loss: 0.1915 - val_acc: 0.9097\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19148 to 0.19059, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9061 - val_loss: 0.1906 - val_acc: 0.9105\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.1982 - acc: 0.9085 - val_loss: 0.1915 - val_acc: 0.9094\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.19059 to 0.19044, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9049 - val_loss: 0.1904 - val_acc: 0.9094\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.1961 - acc: 0.9077 - val_loss: 0.1912 - val_acc: 0.9082\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1977 - acc: 0.9055 - val_loss: 0.1907 - val_acc: 0.9088\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19044 to 0.19001, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9058 - val_loss: 0.1900 - val_acc: 0.9094\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1964 - acc: 0.9064 - val_loss: 0.1903 - val_acc: 0.9097\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.1960 - acc: 0.9086 - val_loss: 0.1900 - val_acc: 0.9088\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1959 - acc: 0.9071 - val_loss: 0.1904 - val_acc: 0.9105\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1947 - acc: 0.9077 - val_loss: 0.1901 - val_acc: 0.9111\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.1949 - acc: 0.9083 - val_loss: 0.1908 - val_acc: 0.9084\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.19001 to 0.18949, saving model to best.model\n",
      "1s - loss: 0.1947 - acc: 0.9067 - val_loss: 0.1895 - val_acc: 0.9103\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.1951 - acc: 0.9069 - val_loss: 0.1895 - val_acc: 0.9103\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18949 to 0.18927, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9091 - val_loss: 0.1893 - val_acc: 0.9109\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.18927 to 0.18913, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9106 - val_loss: 0.1891 - val_acc: 0.9097\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.1931 - acc: 0.9092 - val_loss: 0.1894 - val_acc: 0.9107\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1926 - acc: 0.9078 - val_loss: 0.1898 - val_acc: 0.9092\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18913 to 0.18893, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9089 - val_loss: 0.1889 - val_acc: 0.9103\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18893 to 0.18878, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9087 - val_loss: 0.1888 - val_acc: 0.9103\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.1905 - acc: 0.9108 - val_loss: 0.1895 - val_acc: 0.9094\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18878 to 0.18804, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9094 - val_loss: 0.1880 - val_acc: 0.9113\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.1896 - acc: 0.9098 - val_loss: 0.1881 - val_acc: 0.9103\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.1912 - acc: 0.9088 - val_loss: 0.1883 - val_acc: 0.9105\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18804 to 0.18771, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9102 - val_loss: 0.1877 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9098 - val_loss: 0.1886 - val_acc: 0.9099\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18771 to 0.18750, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9091 - val_loss: 0.1875 - val_acc: 0.9101\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18750 to 0.18708, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9108 - val_loss: 0.1871 - val_acc: 0.9103\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18708 to 0.18691, saving model to best.model\n",
      "0s - loss: 0.1903 - acc: 0.9095 - val_loss: 0.1869 - val_acc: 0.9101\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9103 - val_loss: 0.1872 - val_acc: 0.9103\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9102 - val_loss: 0.1875 - val_acc: 0.9109\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9096 - val_loss: 0.1870 - val_acc: 0.9118\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1889 - acc: 0.9096 - val_loss: 0.1873 - val_acc: 0.9115\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18691 to 0.18634, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9107 - val_loss: 0.1863 - val_acc: 0.9113\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9104 - val_loss: 0.1867 - val_acc: 0.9101\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18634 to 0.18596, saving model to best.model\n",
      "1s - loss: 0.1867 - acc: 0.9109 - val_loss: 0.1860 - val_acc: 0.9107\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1873 - acc: 0.9107 - val_loss: 0.1860 - val_acc: 0.9120\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18596 to 0.18593, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9102 - val_loss: 0.1859 - val_acc: 0.9115\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18593 to 0.18528, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9121 - val_loss: 0.1853 - val_acc: 0.9111\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9107 - val_loss: 0.1855 - val_acc: 0.9092\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9112 - val_loss: 0.1856 - val_acc: 0.9120\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9108 - val_loss: 0.1855 - val_acc: 0.9109\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18528 to 0.18493, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9104 - val_loss: 0.1849 - val_acc: 0.9094\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1857 - acc: 0.9130 - val_loss: 0.1849 - val_acc: 0.9120\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9113 - val_loss: 0.1852 - val_acc: 0.9134\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.18493 to 0.18490, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9118 - val_loss: 0.1849 - val_acc: 0.9128\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1867 - acc: 0.9108 - val_loss: 0.1859 - val_acc: 0.9124\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18490 to 0.18404, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9122 - val_loss: 0.1840 - val_acc: 0.9103\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1852 - acc: 0.9106 - val_loss: 0.1842 - val_acc: 0.9126\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1843 - acc: 0.9134 - val_loss: 0.1844 - val_acc: 0.9138\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1845 - acc: 0.9112 - val_loss: 0.1847 - val_acc: 0.9097\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1850 - acc: 0.9114 - val_loss: 0.1843 - val_acc: 0.9132\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.18404 to 0.18369, saving model to best.model\n",
      "0s - loss: 0.1855 - acc: 0.9102 - val_loss: 0.1837 - val_acc: 0.9101\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1851 - acc: 0.9115 - val_loss: 0.1837 - val_acc: 0.9138\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18369 to 0.18350, saving model to best.model\n",
      "1s - loss: 0.1832 - acc: 0.9115 - val_loss: 0.1835 - val_acc: 0.9101\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18350 to 0.18333, saving model to best.model\n",
      "0s - loss: 0.1834 - acc: 0.9124 - val_loss: 0.1833 - val_acc: 0.9124\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.18333 to 0.18320, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9123 - val_loss: 0.1832 - val_acc: 0.9099\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.18320 to 0.18299, saving model to best.model\n",
      "0s - loss: 0.1844 - acc: 0.9121 - val_loss: 0.1830 - val_acc: 0.9103\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.18299 to 0.18277, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9121 - val_loss: 0.1828 - val_acc: 0.9103\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1834 - acc: 0.9132 - val_loss: 0.1830 - val_acc: 0.9107\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9133 - val_loss: 0.1835 - val_acc: 0.9105\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.18277 to 0.18262, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9137 - val_loss: 0.1826 - val_acc: 0.9109\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1826 - acc: 0.9117 - val_loss: 0.1831 - val_acc: 0.9115\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9119 - val_loss: 0.1827 - val_acc: 0.9115\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1829 - acc: 0.9109 - val_loss: 0.1827 - val_acc: 0.9136\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18262 to 0.18262, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9142 - val_loss: 0.1826 - val_acc: 0.9118\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.18262 to 0.18188, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9129 - val_loss: 0.1819 - val_acc: 0.9105\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1820 - acc: 0.9131 - val_loss: 0.1822 - val_acc: 0.9115\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9143 - val_loss: 0.1822 - val_acc: 0.9113\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9145 - val_loss: 0.1819 - val_acc: 0.9130\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9131 - val_loss: 0.1820 - val_acc: 0.9124\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1824 - acc: 0.9124 - val_loss: 0.1821 - val_acc: 0.9124\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.18188 to 0.18160, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9141 - val_loss: 0.1816 - val_acc: 0.9124\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1822 - acc: 0.9124 - val_loss: 0.1817 - val_acc: 0.9126\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1798 - acc: 0.9151 - val_loss: 0.1836 - val_acc: 0.9134\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.18160 to 0.18124, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9126 - val_loss: 0.1812 - val_acc: 0.9115\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9148 - val_loss: 0.1818 - val_acc: 0.9130\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9133 - val_loss: 0.1813 - val_acc: 0.9130\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1800 - acc: 0.9138 - val_loss: 0.1818 - val_acc: 0.9120\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.18124 to 0.18097, saving model to best.model\n",
      "0s - loss: 0.1788 - acc: 0.9148 - val_loss: 0.1810 - val_acc: 0.9124\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18097 to 0.18059, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9131 - val_loss: 0.1806 - val_acc: 0.9132\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "1s - loss: 0.1805 - acc: 0.9142 - val_loss: 0.1808 - val_acc: 0.9118\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9150 - val_loss: 0.1808 - val_acc: 0.9122\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1792 - acc: 0.9143 - val_loss: 0.1811 - val_acc: 0.9124\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "1s - loss: 0.1798 - acc: 0.9133 - val_loss: 0.1813 - val_acc: 0.9128\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.18059 to 0.18034, saving model to best.model\n",
      "0s - loss: 0.1796 - acc: 0.9131 - val_loss: 0.1803 - val_acc: 0.9130\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.1784 - acc: 0.9146 - val_loss: 0.1808 - val_acc: 0.9132\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.18034 to 0.18019, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9138 - val_loss: 0.1802 - val_acc: 0.9126\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9150 - val_loss: 0.1804 - val_acc: 0.9126\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.18019 to 0.17990, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9145 - val_loss: 0.1799 - val_acc: 0.9126\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9138 - val_loss: 0.1810 - val_acc: 0.9122\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9141 - val_loss: 0.1804 - val_acc: 0.9120\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9162 - val_loss: 0.1809 - val_acc: 0.9126\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9140 - val_loss: 0.1802 - val_acc: 0.9134\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.17990 to 0.17959, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9150 - val_loss: 0.1796 - val_acc: 0.9120\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.1774 - acc: 0.9140 - val_loss: 0.1802 - val_acc: 0.9128\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.17959 to 0.17935, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9152 - val_loss: 0.1794 - val_acc: 0.9124\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9143 - val_loss: 0.1808 - val_acc: 0.9126\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1761 - acc: 0.9163 - val_loss: 0.1797 - val_acc: 0.9120\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.17935 to 0.17904, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9142 - val_loss: 0.1790 - val_acc: 0.9113\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9157 - val_loss: 0.1798 - val_acc: 0.9126\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9161 - val_loss: 0.1795 - val_acc: 0.9122\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.1780 - acc: 0.9150 - val_loss: 0.1794 - val_acc: 0.9122\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9143 - val_loss: 0.1803 - val_acc: 0.9128\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.17904 to 0.17895, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9168 - val_loss: 0.1790 - val_acc: 0.9122\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9173 - val_loss: 0.1792 - val_acc: 0.9113\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9147 - val_loss: 0.1790 - val_acc: 0.9120\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9158 - val_loss: 0.1791 - val_acc: 0.9130\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1762 - acc: 0.9149 - val_loss: 0.1791 - val_acc: 0.9130\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9165 - val_loss: 0.1801 - val_acc: 0.9126\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.1772 - acc: 0.9148 - val_loss: 0.1792 - val_acc: 0.9126\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.1759 - acc: 0.9147 - val_loss: 0.1791 - val_acc: 0.9124\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "1s - loss: 0.1746 - acc: 0.9158 - val_loss: 0.1791 - val_acc: 0.9120\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9141 - val_loss: 0.1799 - val_acc: 0.9142\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.1749 - acc: 0.9148 - val_loss: 0.1792 - val_acc: 0.9136\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.17895 to 0.17854, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9150 - val_loss: 0.1785 - val_acc: 0.9134\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.17854 to 0.17843, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9141 - val_loss: 0.1784 - val_acc: 0.9130\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.1748 - acc: 0.9156 - val_loss: 0.1787 - val_acc: 0.9130\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9157 - val_loss: 0.1787 - val_acc: 0.9128\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1750 - acc: 0.9163 - val_loss: 0.1786 - val_acc: 0.9126\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.17843 to 0.17841, saving model to best.model\n",
      "0s - loss: 0.1742 - acc: 0.9153 - val_loss: 0.1784 - val_acc: 0.9134\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.17841 to 0.17807, saving model to best.model\n",
      "0s - loss: 0.1746 - acc: 0.9178 - val_loss: 0.1781 - val_acc: 0.9136\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1743 - acc: 0.9163 - val_loss: 0.1789 - val_acc: 0.9138\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.17807 to 0.17786, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9157 - val_loss: 0.1779 - val_acc: 0.9147\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9161 - val_loss: 0.1782 - val_acc: 0.9136\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9148 - val_loss: 0.1789 - val_acc: 0.9132\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9159 - val_loss: 0.1785 - val_acc: 0.9134\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9169 - val_loss: 0.1789 - val_acc: 0.9134\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.1729 - acc: 0.9165 - val_loss: 0.1782 - val_acc: 0.9136\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17786 to 0.17760, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9156 - val_loss: 0.1776 - val_acc: 0.9142\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9159 - val_loss: 0.1782 - val_acc: 0.9128\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.17760 to 0.17750, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9168 - val_loss: 0.1775 - val_acc: 0.9138\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1731 - acc: 0.9160 - val_loss: 0.1786 - val_acc: 0.9128\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9179 - val_loss: 0.1776 - val_acc: 0.9132\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1733 - acc: 0.9153 - val_loss: 0.1785 - val_acc: 0.9134\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9173 - val_loss: 0.1783 - val_acc: 0.9134\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9180 - val_loss: 0.1789 - val_acc: 0.9130\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1715 - acc: 0.9182 - val_loss: 0.1796 - val_acc: 0.9134\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.17750 to 0.17746, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9168 - val_loss: 0.1775 - val_acc: 0.9140\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1721 - acc: 0.9149 - val_loss: 0.1778 - val_acc: 0.9128\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1724 - acc: 0.9162 - val_loss: 0.1776 - val_acc: 0.9130\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1717 - acc: 0.9153 - val_loss: 0.1775 - val_acc: 0.9138\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.17746 to 0.17717, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9173 - val_loss: 0.1772 - val_acc: 0.9142\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9175 - val_loss: 0.1773 - val_acc: 0.9128\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1714 - acc: 0.9164 - val_loss: 0.1781 - val_acc: 0.9138\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9177 - val_loss: 0.1780 - val_acc: 0.9122\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.1709 - acc: 0.9177 - val_loss: 0.1774 - val_acc: 0.9132\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9179 - val_loss: 0.1780 - val_acc: 0.9130\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9185 - val_loss: 0.1778 - val_acc: 0.9134\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1719 - acc: 0.9143 - val_loss: 0.1774 - val_acc: 0.9136\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9183 - val_loss: 0.1780 - val_acc: 0.9140\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1708 - acc: 0.9184 - val_loss: 0.1775 - val_acc: 0.9142\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.17717 to 0.17704, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9164 - val_loss: 0.1770 - val_acc: 0.9132\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.1702 - acc: 0.9176 - val_loss: 0.1780 - val_acc: 0.9134\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9159 - val_loss: 0.1774 - val_acc: 0.9147\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1705 - acc: 0.9165 - val_loss: 0.1780 - val_acc: 0.9132\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9175 - val_loss: 0.1775 - val_acc: 0.9142\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9181 - val_loss: 0.1777 - val_acc: 0.9142\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.1704 - acc: 0.9174 - val_loss: 0.1773 - val_acc: 0.9161\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9196 - val_loss: 0.1775 - val_acc: 0.9145\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1694 - acc: 0.9173 - val_loss: 0.1778 - val_acc: 0.9161\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.17704 to 0.17661, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9185 - val_loss: 0.1766 - val_acc: 0.9134\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9178 - val_loss: 0.1768 - val_acc: 0.9142\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1691 - acc: 0.9180 - val_loss: 0.1770 - val_acc: 0.9143\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9192 - val_loss: 0.1771 - val_acc: 0.9149\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9193 - val_loss: 0.1774 - val_acc: 0.9143\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.17661 to 0.17624, saving model to best.model\n",
      "0s - loss: 0.1687 - acc: 0.9169 - val_loss: 0.1762 - val_acc: 0.9151\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9170 - val_loss: 0.1767 - val_acc: 0.9143\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9194 - val_loss: 0.1767 - val_acc: 0.9142\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9171 - val_loss: 0.1770 - val_acc: 0.9136\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1692 - acc: 0.9179 - val_loss: 0.1764 - val_acc: 0.9149\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9177 - val_loss: 0.1776 - val_acc: 0.9138\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "1s - loss: 0.1690 - acc: 0.9182 - val_loss: 0.1771 - val_acc: 0.9143\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1689 - acc: 0.9192 - val_loss: 0.1766 - val_acc: 0.9143\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9196 - val_loss: 0.1767 - val_acc: 0.9143\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9177 - val_loss: 0.1769 - val_acc: 0.9149\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1679 - acc: 0.9184 - val_loss: 0.1765 - val_acc: 0.9161\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.17624 to 0.17596, saving model to best.model\n",
      "1s - loss: 0.1696 - acc: 0.9168 - val_loss: 0.1760 - val_acc: 0.9140\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9187 - val_loss: 0.1767 - val_acc: 0.9151\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1672 - acc: 0.9192 - val_loss: 0.1764 - val_acc: 0.9149\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9190 - val_loss: 0.1768 - val_acc: 0.9157\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "1s - loss: 0.1667 - acc: 0.9189 - val_loss: 0.1761 - val_acc: 0.9155\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.17596 to 0.17565, saving model to best.model\n",
      "0s - loss: 0.1659 - acc: 0.9200 - val_loss: 0.1757 - val_acc: 0.9153\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9183 - val_loss: 0.1769 - val_acc: 0.9149\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9187 - val_loss: 0.1763 - val_acc: 0.9163\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.1654 - acc: 0.9203 - val_loss: 0.1760 - val_acc: 0.9157\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9190 - val_loss: 0.1769 - val_acc: 0.9161\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9199 - val_loss: 0.1757 - val_acc: 0.9159\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1674 - acc: 0.9187 - val_loss: 0.1762 - val_acc: 0.9153\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1662 - acc: 0.9199 - val_loss: 0.1763 - val_acc: 0.9149\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9167 - val_loss: 0.1758 - val_acc: 0.9165\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9183 - val_loss: 0.1766 - val_acc: 0.9147\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9192 - val_loss: 0.1767 - val_acc: 0.9142\n",
      "Train on 20824 samples, validate on 5207 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.33337, saving model to best.model\n",
      "0s - loss: 0.3934 - acc: 0.8779 - val_loss: 0.3334 - val_acc: 0.8852\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.33337 to 0.25133, saving model to best.model\n",
      "0s - loss: 0.3170 - acc: 0.8876 - val_loss: 0.2513 - val_acc: 0.9009\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.25133 to 0.21024, saving model to best.model\n",
      "0s - loss: 0.2539 - acc: 0.8952 - val_loss: 0.2102 - val_acc: 0.9080\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.21024 to 0.20198, saving model to best.model\n",
      "0s - loss: 0.2234 - acc: 0.9022 - val_loss: 0.2020 - val_acc: 0.9101\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.20198 to 0.19531, saving model to best.model\n",
      "0s - loss: 0.2169 - acc: 0.9031 - val_loss: 0.1953 - val_acc: 0.9126\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.2120 - acc: 0.9025 - val_loss: 0.1966 - val_acc: 0.9126\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.19531 to 0.19234, saving model to best.model\n",
      "0s - loss: 0.2099 - acc: 0.9024 - val_loss: 0.1923 - val_acc: 0.9107\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2034 - acc: 0.9043 - val_loss: 0.1939 - val_acc: 0.9120\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.19234 to 0.19191, saving model to best.model\n",
      "0s - loss: 0.2018 - acc: 0.9033 - val_loss: 0.1919 - val_acc: 0.9145\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.19191 to 0.19116, saving model to best.model\n",
      "0s - loss: 0.1998 - acc: 0.9058 - val_loss: 0.1912 - val_acc: 0.9132\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.2010 - acc: 0.9051 - val_loss: 0.1914 - val_acc: 0.9140\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.19116 to 0.19085, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9066 - val_loss: 0.1909 - val_acc: 0.9134\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.1979 - acc: 0.9052 - val_loss: 0.1913 - val_acc: 0.9111\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.19085 to 0.19054, saving model to best.model\n",
      "0s - loss: 0.1974 - acc: 0.9064 - val_loss: 0.1905 - val_acc: 0.9115\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9056 - val_loss: 0.1911 - val_acc: 0.9128\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.19054 to 0.19032, saving model to best.model\n",
      "0s - loss: 0.1981 - acc: 0.9053 - val_loss: 0.1903 - val_acc: 0.9130\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19032 to 0.18979, saving model to best.model\n",
      "0s - loss: 0.1963 - acc: 0.9057 - val_loss: 0.1898 - val_acc: 0.9122\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.1962 - acc: 0.9058 - val_loss: 0.1900 - val_acc: 0.9126\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18979 to 0.18915, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9068 - val_loss: 0.1892 - val_acc: 0.9113\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1949 - acc: 0.9064 - val_loss: 0.1896 - val_acc: 0.9134\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.18915 to 0.18908, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9077 - val_loss: 0.1891 - val_acc: 0.9117\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.18908 to 0.18886, saving model to best.model\n",
      "0s - loss: 0.1971 - acc: 0.9051 - val_loss: 0.1889 - val_acc: 0.9117\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.1937 - acc: 0.9054 - val_loss: 0.1889 - val_acc: 0.9128\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18886 to 0.18843, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9066 - val_loss: 0.1884 - val_acc: 0.9126\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.1935 - acc: 0.9066 - val_loss: 0.1889 - val_acc: 0.9134\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18843 to 0.18772, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9086 - val_loss: 0.1877 - val_acc: 0.9124\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.1921 - acc: 0.9066 - val_loss: 0.1879 - val_acc: 0.9118\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18772 to 0.18754, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9085 - val_loss: 0.1875 - val_acc: 0.9124\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.1916 - acc: 0.9079 - val_loss: 0.1879 - val_acc: 0.9138\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18754 to 0.18730, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9058 - val_loss: 0.1873 - val_acc: 0.9124\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18730 to 0.18686, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9085 - val_loss: 0.1869 - val_acc: 0.9130\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9085 - val_loss: 0.1870 - val_acc: 0.9117\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18686 to 0.18677, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9069 - val_loss: 0.1868 - val_acc: 0.9122\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18677 to 0.18648, saving model to best.model\n",
      "0s - loss: 0.1913 - acc: 0.9078 - val_loss: 0.1865 - val_acc: 0.9124\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18648 to 0.18618, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9086 - val_loss: 0.1862 - val_acc: 0.9126\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9090 - val_loss: 0.1867 - val_acc: 0.9153\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18618 to 0.18604, saving model to best.model\n",
      "0s - loss: 0.1894 - acc: 0.9089 - val_loss: 0.1860 - val_acc: 0.9126\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1895 - acc: 0.9079 - val_loss: 0.1873 - val_acc: 0.9151\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18604 to 0.18585, saving model to best.model\n",
      "0s - loss: 0.1898 - acc: 0.9085 - val_loss: 0.1859 - val_acc: 0.9117\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1894 - acc: 0.9071 - val_loss: 0.1865 - val_acc: 0.9149\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18585 to 0.18564, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9088 - val_loss: 0.1856 - val_acc: 0.9126\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1888 - acc: 0.9091 - val_loss: 0.1860 - val_acc: 0.9149\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9103 - val_loss: 0.1858 - val_acc: 0.9149\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18564 to 0.18562, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9092 - val_loss: 0.1856 - val_acc: 0.9138\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1878 - acc: 0.9110 - val_loss: 0.1862 - val_acc: 0.9159\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1876 - acc: 0.9086 - val_loss: 0.1859 - val_acc: 0.9155\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18562 to 0.18508, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9091 - val_loss: 0.1851 - val_acc: 0.9149\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1893 - acc: 0.9079 - val_loss: 0.1853 - val_acc: 0.9136\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1881 - acc: 0.9082 - val_loss: 0.1858 - val_acc: 0.9155\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.18508 to 0.18486, saving model to best.model\n",
      "0s - loss: 0.1869 - acc: 0.9105 - val_loss: 0.1849 - val_acc: 0.9155\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1871 - acc: 0.9102 - val_loss: 0.1854 - val_acc: 0.9153\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9090 - val_loss: 0.1854 - val_acc: 0.9147\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1877 - acc: 0.9083 - val_loss: 0.1852 - val_acc: 0.9151\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1865 - acc: 0.9106 - val_loss: 0.1857 - val_acc: 0.9149\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.18486 to 0.18409, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9120 - val_loss: 0.1841 - val_acc: 0.9138\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1886 - acc: 0.9101 - val_loss: 0.1842 - val_acc: 0.9142\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9121 - val_loss: 0.1844 - val_acc: 0.9143\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1860 - acc: 0.9119 - val_loss: 0.1841 - val_acc: 0.9149\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.18409 to 0.18403, saving model to best.model\n",
      "0s - loss: 0.1858 - acc: 0.9114 - val_loss: 0.1840 - val_acc: 0.9153\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9113 - val_loss: 0.1840 - val_acc: 0.9155\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1862 - acc: 0.9109 - val_loss: 0.1847 - val_acc: 0.9132\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.18403 to 0.18350, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9113 - val_loss: 0.1835 - val_acc: 0.9147\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.18350 to 0.18348, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9117 - val_loss: 0.1835 - val_acc: 0.9155\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "1s - loss: 0.1860 - acc: 0.9095 - val_loss: 0.1857 - val_acc: 0.9151\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1842 - acc: 0.9123 - val_loss: 0.1836 - val_acc: 0.9155\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9118 - val_loss: 0.1841 - val_acc: 0.9138\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1840 - acc: 0.9117 - val_loss: 0.1843 - val_acc: 0.9155\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.18348 to 0.18319, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9108 - val_loss: 0.1832 - val_acc: 0.9153\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1841 - acc: 0.9126 - val_loss: 0.1844 - val_acc: 0.9147\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.18319 to 0.18305, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9117 - val_loss: 0.1831 - val_acc: 0.9153\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9125 - val_loss: 0.1836 - val_acc: 0.9145\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.18305 to 0.18300, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9116 - val_loss: 0.1830 - val_acc: 0.9155\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.18300 to 0.18277, saving model to best.model\n",
      "0s - loss: 0.1829 - acc: 0.9128 - val_loss: 0.1828 - val_acc: 0.9143\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1815 - acc: 0.9130 - val_loss: 0.1828 - val_acc: 0.9151\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1819 - acc: 0.9130 - val_loss: 0.1842 - val_acc: 0.9142\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.18277 to 0.18261, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9118 - val_loss: 0.1826 - val_acc: 0.9155\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.18261 to 0.18242, saving model to best.model\n",
      "0s - loss: 0.1827 - acc: 0.9124 - val_loss: 0.1824 - val_acc: 0.9155\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1805 - acc: 0.9131 - val_loss: 0.1831 - val_acc: 0.9157\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9114 - val_loss: 0.1829 - val_acc: 0.9151\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1818 - acc: 0.9134 - val_loss: 0.1827 - val_acc: 0.9161\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9142 - val_loss: 0.1829 - val_acc: 0.9147\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.18242 to 0.18187, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9137 - val_loss: 0.1819 - val_acc: 0.9151\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9137 - val_loss: 0.1821 - val_acc: 0.9168\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.1817 - acc: 0.9129 - val_loss: 0.1828 - val_acc: 0.9153\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1808 - acc: 0.9139 - val_loss: 0.1825 - val_acc: 0.9165\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.18187 to 0.18164, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9146 - val_loss: 0.1816 - val_acc: 0.9170\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9135 - val_loss: 0.1822 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.18164 to 0.18150, saving model to best.model\n",
      "0s - loss: 0.1817 - acc: 0.9148 - val_loss: 0.1815 - val_acc: 0.9170\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9125 - val_loss: 0.1816 - val_acc: 0.9159\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.1794 - acc: 0.9138 - val_loss: 0.1818 - val_acc: 0.9165\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9142 - val_loss: 0.1816 - val_acc: 0.9163\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.1801 - acc: 0.9151 - val_loss: 0.1816 - val_acc: 0.9159\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.1790 - acc: 0.9148 - val_loss: 0.1817 - val_acc: 0.9174\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.18150 to 0.18136, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9141 - val_loss: 0.1814 - val_acc: 0.9168\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.18136 to 0.18132, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9146 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.18132 to 0.18124, saving model to best.model\n",
      "0s - loss: 0.1790 - acc: 0.9134 - val_loss: 0.1812 - val_acc: 0.9167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.1791 - acc: 0.9139 - val_loss: 0.1813 - val_acc: 0.9170\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.1785 - acc: 0.9130 - val_loss: 0.1816 - val_acc: 0.9176\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.1793 - acc: 0.9133 - val_loss: 0.1821 - val_acc: 0.9155\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.18124 to 0.18078, saving model to best.model\n",
      "0s - loss: 0.1778 - acc: 0.9152 - val_loss: 0.1808 - val_acc: 0.9176\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.18078 to 0.18075, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9149 - val_loss: 0.1808 - val_acc: 0.9170\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.1786 - acc: 0.9140 - val_loss: 0.1810 - val_acc: 0.9178\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.18075 to 0.18074, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9147 - val_loss: 0.1807 - val_acc: 0.9174\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9156 - val_loss: 0.1815 - val_acc: 0.9159\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.18074 to 0.18064, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9143 - val_loss: 0.1806 - val_acc: 0.9165\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.1779 - acc: 0.9142 - val_loss: 0.1808 - val_acc: 0.9157\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.1771 - acc: 0.9141 - val_loss: 0.1817 - val_acc: 0.9161\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.18064 to 0.18033, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9148 - val_loss: 0.1803 - val_acc: 0.9180\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "1s - loss: 0.1771 - acc: 0.9149 - val_loss: 0.1805 - val_acc: 0.9172\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.18033 to 0.18009, saving model to best.model\n",
      "1s - loss: 0.1775 - acc: 0.9155 - val_loss: 0.1801 - val_acc: 0.9178\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.1778 - acc: 0.9143 - val_loss: 0.1801 - val_acc: 0.9172\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9147 - val_loss: 0.1803 - val_acc: 0.9176\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9148 - val_loss: 0.1828 - val_acc: 0.9159\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.1744 - acc: 0.9166 - val_loss: 0.1801 - val_acc: 0.9176\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.1751 - acc: 0.9158 - val_loss: 0.1812 - val_acc: 0.9180\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.1767 - acc: 0.9148 - val_loss: 0.1809 - val_acc: 0.9159\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9150 - val_loss: 0.1806 - val_acc: 0.9167\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.18009 to 0.17957, saving model to best.model\n",
      "0s - loss: 0.1774 - acc: 0.9158 - val_loss: 0.1796 - val_acc: 0.9170\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.17957 to 0.17956, saving model to best.model\n",
      "0s - loss: 0.1764 - acc: 0.9150 - val_loss: 0.1796 - val_acc: 0.9182\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.1776 - acc: 0.9153 - val_loss: 0.1797 - val_acc: 0.9176\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9166 - val_loss: 0.1797 - val_acc: 0.9174\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.17956 to 0.17948, saving model to best.model\n",
      "0s - loss: 0.1772 - acc: 0.9156 - val_loss: 0.1795 - val_acc: 0.9176\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.1741 - acc: 0.9171 - val_loss: 0.1797 - val_acc: 0.9174\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9148 - val_loss: 0.1796 - val_acc: 0.9176\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.17948 to 0.17900, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9164 - val_loss: 0.1790 - val_acc: 0.9182\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9160 - val_loss: 0.1806 - val_acc: 0.9182\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9175 - val_loss: 0.1802 - val_acc: 0.9191\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.1757 - acc: 0.9156 - val_loss: 0.1802 - val_acc: 0.9170\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9173 - val_loss: 0.1791 - val_acc: 0.9191\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.1736 - acc: 0.9175 - val_loss: 0.1796 - val_acc: 0.9190\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9171 - val_loss: 0.1793 - val_acc: 0.9186\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9171 - val_loss: 0.1791 - val_acc: 0.9188\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.17900 to 0.17898, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9175 - val_loss: 0.1790 - val_acc: 0.9197\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.17898 to 0.17877, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9172 - val_loss: 0.1788 - val_acc: 0.9188\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9167 - val_loss: 0.1798 - val_acc: 0.9184\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.17877 to 0.17874, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9179 - val_loss: 0.1787 - val_acc: 0.9191\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.17874 to 0.17826, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9174 - val_loss: 0.1783 - val_acc: 0.9205\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9175 - val_loss: 0.1791 - val_acc: 0.9191\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9172 - val_loss: 0.1794 - val_acc: 0.9172\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.1732 - acc: 0.9176 - val_loss: 0.1791 - val_acc: 0.9186\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9158 - val_loss: 0.1786 - val_acc: 0.9174\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.1738 - acc: 0.9162 - val_loss: 0.1786 - val_acc: 0.9191\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9169 - val_loss: 0.1783 - val_acc: 0.9191\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.17826 to 0.17800, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9190 - val_loss: 0.1780 - val_acc: 0.9193\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.1711 - acc: 0.9180 - val_loss: 0.1784 - val_acc: 0.9193\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.1727 - acc: 0.9178 - val_loss: 0.1784 - val_acc: 0.9191\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9181 - val_loss: 0.1789 - val_acc: 0.9182\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.1726 - acc: 0.9168 - val_loss: 0.1783 - val_acc: 0.9193\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.1713 - acc: 0.9176 - val_loss: 0.1788 - val_acc: 0.9172\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.1723 - acc: 0.9145 - val_loss: 0.1789 - val_acc: 0.9188\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9183 - val_loss: 0.1784 - val_acc: 0.9199\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.1737 - acc: 0.9162 - val_loss: 0.1781 - val_acc: 0.9195\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.1688 - acc: 0.9191 - val_loss: 0.1799 - val_acc: 0.9197\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.17800 to 0.17747, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9170 - val_loss: 0.1775 - val_acc: 0.9191\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9187 - val_loss: 0.1782 - val_acc: 0.9190\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9177 - val_loss: 0.1784 - val_acc: 0.9191\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9193 - val_loss: 0.1781 - val_acc: 0.9182\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.17747 to 0.17744, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9159 - val_loss: 0.1774 - val_acc: 0.9195\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9179 - val_loss: 0.1781 - val_acc: 0.9199\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.1706 - acc: 0.9178 - val_loss: 0.1797 - val_acc: 0.9174\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "1s - loss: 0.1691 - acc: 0.9182 - val_loss: 0.1777 - val_acc: 0.9190\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9202 - val_loss: 0.1783 - val_acc: 0.9193\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.1678 - acc: 0.9191 - val_loss: 0.1783 - val_acc: 0.9209\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.1697 - acc: 0.9180 - val_loss: 0.1797 - val_acc: 0.9178\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9179 - val_loss: 0.1788 - val_acc: 0.9213\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.17744 to 0.17738, saving model to best.model\n",
      "0s - loss: 0.1702 - acc: 0.9184 - val_loss: 0.1774 - val_acc: 0.9182\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9185 - val_loss: 0.1784 - val_acc: 0.9201\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.1698 - acc: 0.9177 - val_loss: 0.1782 - val_acc: 0.9197\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9191 - val_loss: 0.1782 - val_acc: 0.9199\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9184 - val_loss: 0.1801 - val_acc: 0.9207\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9185 - val_loss: 0.1788 - val_acc: 0.9195\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.1693 - acc: 0.9192 - val_loss: 0.1787 - val_acc: 0.9193\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.1707 - acc: 0.9182 - val_loss: 0.1785 - val_acc: 0.9180\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.1682 - acc: 0.9186 - val_loss: 0.1780 - val_acc: 0.9188\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9193 - val_loss: 0.1777 - val_acc: 0.9186\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9193 - val_loss: 0.1780 - val_acc: 0.9201\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9169 - val_loss: 0.1775 - val_acc: 0.9193\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9197 - val_loss: 0.1777 - val_acc: 0.9215\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.1675 - acc: 0.9198 - val_loss: 0.1775 - val_acc: 0.9203\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.1690 - acc: 0.9191 - val_loss: 0.1777 - val_acc: 0.9195\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9192 - val_loss: 0.1789 - val_acc: 0.9205\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.17738 to 0.17700, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9188 - val_loss: 0.1770 - val_acc: 0.9199\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9204 - val_loss: 0.1778 - val_acc: 0.9209\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.1680 - acc: 0.9191 - val_loss: 0.1773 - val_acc: 0.9184\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.1669 - acc: 0.9195 - val_loss: 0.1773 - val_acc: 0.9203\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9198 - val_loss: 0.1777 - val_acc: 0.9191\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.1681 - acc: 0.9186 - val_loss: 0.1772 - val_acc: 0.9193\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.1671 - acc: 0.9195 - val_loss: 0.1777 - val_acc: 0.9197\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.1667 - acc: 0.9200 - val_loss: 0.1797 - val_acc: 0.9180\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.1668 - acc: 0.9187 - val_loss: 0.1771 - val_acc: 0.9209\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.17700 to 0.17693, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9189 - val_loss: 0.1769 - val_acc: 0.9203\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.1676 - acc: 0.9209 - val_loss: 0.1779 - val_acc: 0.9182\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.17693 to 0.17626, saving model to best.model\n",
      "0s - loss: 0.1671 - acc: 0.9202 - val_loss: 0.1763 - val_acc: 0.9211\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.1661 - acc: 0.9187 - val_loss: 0.1764 - val_acc: 0.9207\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.1659 - acc: 0.9186 - val_loss: 0.1772 - val_acc: 0.9207\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.1653 - acc: 0.9199 - val_loss: 0.1779 - val_acc: 0.9184\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1652 - acc: 0.9198 - val_loss: 0.1780 - val_acc: 0.9182\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1658 - acc: 0.9203 - val_loss: 0.1775 - val_acc: 0.9205\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1642 - acc: 0.9202 - val_loss: 0.1781 - val_acc: 0.9197\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1657 - acc: 0.9195 - val_loss: 0.1772 - val_acc: 0.9199\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(50):\n",
    "    y_pred=train_nn_simple(train,X_val,y_val)\n",
    "    result.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new=np.array(result)\n",
    "result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  0,  0, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new1=result_new.sum(axis=0)\n",
    "result_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 39,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 9,\n",
       " 37,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 21,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 49,\n",
       " 47,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 48,\n",
       " 45,\n",
       " 45,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 34,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 37,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 30,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 39,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 47,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 40,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 47,\n",
       " 0,\n",
       " 39,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 24,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 17,\n",
       " 49,\n",
       " 18,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 16,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 47,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 23,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 40,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 49,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 50,\n",
       " 0,\n",
       " 40,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 37,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 33,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 37,\n",
       " 0,\n",
       " 2,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 38,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 23,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 39,\n",
       " 26,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=result_new1.tolist()\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for each in re:\n",
    "    if each>=25:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8821  311]\n",
      " [ 532  633]]\n",
      "91.813149461\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95      9132\n",
      "          1       0.67      0.54      0.60      1165\n",
      "\n",
      "avg / total       0.91      0.92      0.91     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(y_val, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_val, y_pred) * 100) \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
