{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_list=['Class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "           'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring',\n",
    "           'stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type',\n",
    "           'veil-color','ring-number','ring-type','spore-print-color','population','habitat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",names=name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color   ...   stalk-surface-below-ring  \\\n",
       "0            c         n          k   ...                          s   \n",
       "1            c         b          k   ...                          s   \n",
       "2            c         b          n   ...                          s   \n",
       "3            c         n          n   ...                          s   \n",
       "4            w         b          k   ...                          s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                       0\n",
       "cap-shape                   0\n",
       "cap-surface                 0\n",
       "cap-color                   0\n",
       "bruises                     0\n",
       "odor                        0\n",
       "gill-attachment             0\n",
       "gill-spacing                0\n",
       "gill-size                   0\n",
       "gill-color                  0\n",
       "stalk-shape                 0\n",
       "stalk-root                  0\n",
       "stalk-surface-above-ring    0\n",
       "stalk-surface-below-ring    0\n",
       "stalk-color-above-ring      0\n",
       "stalk-color-below-ring      0\n",
       "veil-type                   0\n",
       "veil-color                  0\n",
       "ring-number                 0\n",
       "ring-type                   0\n",
       "spore-print-color           0\n",
       "population                  0\n",
       "habitat                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFGCAYAAACls9yvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0Ix+ywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115057410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Class'].value_counts().sort_index().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "for col in train.columns:\n",
    "    train[col] = labelencoder.fit_transform(train[col])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color   ...     stalk-surface-below-ring  \\\n",
       "0             0          1           4   ...                            2   \n",
       "1             0          0           4   ...                            2   \n",
       "2             0          0           5   ...                            2   \n",
       "3             0          1           5   ...                            2   \n",
       "4             1          0           4   ...                            2   \n",
       "\n",
       "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
       "0                       7                       7          0           2   \n",
       "1                       7                       7          0           2   \n",
       "2                       7                       7          0           2   \n",
       "3                       7                       7          0           2   \n",
       "4                       7                       7          0           2   \n",
       "\n",
       "   ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0            1          4                  2           3        5  \n",
       "1            1          4                  3           2        1  \n",
       "2            1          4                  3           2        3  \n",
       "3            1          4                  2           3        5  \n",
       "4            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFlCAYAAADRdSCHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwyicRUREHEbhLCIi4jD/D0tjV+M0/neSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115037750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x='Class', y='stalk-color-above-ring', \n",
    "                data=train)\n",
    "ax = sns.stripplot(x=\"Class\", y='stalk-color-above-ring',\n",
    "                   data=train, jitter=True,\n",
    "                   edgecolor=\"gray\")\n",
    "sns.plt.title(\"Class w.r.t stalkcolor above ring\",fontsize=12)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0          5            2          4        1     6                1   \n",
       "1          5            2          9        1     0                1   \n",
       "2          0            2          8        1     3                1   \n",
       "3          5            3          8        1     6                1   \n",
       "4          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  stalk-shape   ...     \\\n",
       "0             0          1           4            0   ...      \n",
       "1             0          0           4            0   ...      \n",
       "2             0          0           5            0   ...      \n",
       "3             0          1           5            0   ...      \n",
       "4             1          0           4            1   ...      \n",
       "\n",
       "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
       "0                         2                       7                       7   \n",
       "1                         2                       7                       7   \n",
       "2                         2                       7                       7   \n",
       "3                         2                       7                       7   \n",
       "4                         2                       7                       7   \n",
       "\n",
       "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
       "0          0           2            1          4                  2   \n",
       "1          0           2            1          4                  3   \n",
       "2          0           2            1          4                  3   \n",
       "3          0           2            1          4                  2   \n",
       "4          0           2            1          0                  3   \n",
       "\n",
       "   population  habitat  \n",
       "0           3        5  \n",
       "1           2        1  \n",
       "2           2        3  \n",
       "3           3        5  \n",
       "4           0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=train.drop(\"Class\",axis=1)\n",
    "outcomes=train[\"Class\"].values\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, outcomes, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranom Forest         100.00 (+/-) 0.00 \n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=5)\n",
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "cv_result = cross_val_score(model,X_train,Y_train, cv = kfold,scoring = \"accuracy\")\n",
    "results=[\"Ranom Forest\",cv_result.mean(),cv_result.std()]\n",
    "\n",
    "print('{:20s} {:2.2f} (+/-) {:2.2f} '.format(results[0] , results[1] * 100, results[2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [  15  944]]\n",
      "99.2614475628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      1072\n",
      "          1       1.00      0.98      0.99       959\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100,max_features='auto',bootstrap=True,oob_score=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1046   26]\n",
      " [   8  951]]\n",
      "98.325947809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      1072\n",
      "          1       0.97      0.99      0.98       959\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=1,max_features=None,bootstrap=False,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   8  951]]\n",
      "99.6061053668\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      1072\n",
      "          1       1.00      0.99      1.00       959\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100,max_features=None,bootstrap=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest by Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1072\n",
      "          1       1.00      1.00      1.00       959\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=5,subsample=0.632,colsample_bytree=0.375)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree by Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1046   26]\n",
      " [   8  951]]\n",
      "98.325947809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      1072\n",
      "          1       0.97      0.99      0.98       959\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=1,num_boost_round=1,max_depth=5,subsample=1,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagged decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1072\n",
      "          1       1.00      1.00      1.00       959\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=2,subsample=0.632,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras import optimizers\n",
    "history=History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(128, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(128, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(len(np.unique(Y_train)), activation='softmax'))\n",
    "    \n",
    "m.compile(\n",
    "    optimizer=optimizers.adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5483 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.65178, saving model to best.model\n",
      "0s - loss: 0.7802 - acc: 0.5234 - val_loss: 0.6518 - val_acc: 0.6738\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.65178 to 0.58066, saving model to best.model\n",
      "0s - loss: 0.7004 - acc: 0.5732 - val_loss: 0.5807 - val_acc: 0.7738\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.58066 to 0.46719, saving model to best.model\n",
      "0s - loss: 0.5901 - acc: 0.6949 - val_loss: 0.4672 - val_acc: 0.8213\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.46719 to 0.40527, saving model to best.model\n",
      "0s - loss: 0.4965 - acc: 0.7711 - val_loss: 0.4053 - val_acc: 0.8492\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.40527 to 0.36482, saving model to best.model\n",
      "0s - loss: 0.4346 - acc: 0.8182 - val_loss: 0.3648 - val_acc: 0.8738\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.36482 to 0.33988, saving model to best.model\n",
      "0s - loss: 0.4045 - acc: 0.8337 - val_loss: 0.3399 - val_acc: 0.8754\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.33988 to 0.30562, saving model to best.model\n",
      "0s - loss: 0.3716 - acc: 0.8519 - val_loss: 0.3056 - val_acc: 0.8918\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.30562 to 0.28396, saving model to best.model\n",
      "0s - loss: 0.3584 - acc: 0.8592 - val_loss: 0.2840 - val_acc: 0.8967\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.28396 to 0.26519, saving model to best.model\n",
      "0s - loss: 0.3300 - acc: 0.8714 - val_loss: 0.2652 - val_acc: 0.9033\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.26519 to 0.24937, saving model to best.model\n",
      "0s - loss: 0.3143 - acc: 0.8802 - val_loss: 0.2494 - val_acc: 0.9115\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.24937 to 0.24639, saving model to best.model\n",
      "0s - loss: 0.3057 - acc: 0.8853 - val_loss: 0.2464 - val_acc: 0.9197\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.24639 to 0.22750, saving model to best.model\n",
      "0s - loss: 0.2911 - acc: 0.8944 - val_loss: 0.2275 - val_acc: 0.9279\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.22750 to 0.22127, saving model to best.model\n",
      "0s - loss: 0.2805 - acc: 0.8962 - val_loss: 0.2213 - val_acc: 0.9311\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.22127 to 0.21446, saving model to best.model\n",
      "0s - loss: 0.2700 - acc: 0.9017 - val_loss: 0.2145 - val_acc: 0.9328\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.21446 to 0.20733, saving model to best.model\n",
      "0s - loss: 0.2597 - acc: 0.9042 - val_loss: 0.2073 - val_acc: 0.9328\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.20733 to 0.19780, saving model to best.model\n",
      "0s - loss: 0.2563 - acc: 0.9081 - val_loss: 0.1978 - val_acc: 0.9410\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.19780 to 0.19209, saving model to best.model\n",
      "0s - loss: 0.2501 - acc: 0.9083 - val_loss: 0.1921 - val_acc: 0.9410\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.19209 to 0.18646, saving model to best.model\n",
      "0s - loss: 0.2463 - acc: 0.9106 - val_loss: 0.1865 - val_acc: 0.9426\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.18646 to 0.18061, saving model to best.model\n",
      "0s - loss: 0.2390 - acc: 0.9121 - val_loss: 0.1806 - val_acc: 0.9410\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.18061 to 0.17563, saving model to best.model\n",
      "0s - loss: 0.2339 - acc: 0.9117 - val_loss: 0.1756 - val_acc: 0.9410\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.17563 to 0.16984, saving model to best.model\n",
      "0s - loss: 0.2262 - acc: 0.9148 - val_loss: 0.1698 - val_acc: 0.9426\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.16984 to 0.16617, saving model to best.model\n",
      "0s - loss: 0.2182 - acc: 0.9192 - val_loss: 0.1662 - val_acc: 0.9393\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.16617 to 0.15781, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9239 - val_loss: 0.1578 - val_acc: 0.9426\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.15781 to 0.15373, saving model to best.model\n",
      "0s - loss: 0.2076 - acc: 0.9212 - val_loss: 0.1537 - val_acc: 0.9443\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.15373 to 0.14553, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9261 - val_loss: 0.1455 - val_acc: 0.9426\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.14553 to 0.14298, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9272 - val_loss: 0.1430 - val_acc: 0.9459\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.14298 to 0.13278, saving model to best.model\n",
      "0s - loss: 0.1791 - acc: 0.9300 - val_loss: 0.1328 - val_acc: 0.9475\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.13278 to 0.12757, saving model to best.model\n",
      "0s - loss: 0.1782 - acc: 0.9312 - val_loss: 0.1276 - val_acc: 0.9492\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.12757 to 0.12210, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9314 - val_loss: 0.1221 - val_acc: 0.9508\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.12210 to 0.11525, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9349 - val_loss: 0.1152 - val_acc: 0.9541\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.11525 to 0.11056, saving model to best.model\n",
      "0s - loss: 0.1641 - acc: 0.9373 - val_loss: 0.1106 - val_acc: 0.9541\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.1579 - acc: 0.9374 - val_loss: 0.1162 - val_acc: 0.9508\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.11056 to 0.10232, saving model to best.model\n",
      "0s - loss: 0.1548 - acc: 0.9416 - val_loss: 0.1023 - val_acc: 0.9557\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.10232 to 0.09382, saving model to best.model\n",
      "0s - loss: 0.1419 - acc: 0.9455 - val_loss: 0.0938 - val_acc: 0.9672\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.09382 to 0.09308, saving model to best.model\n",
      "0s - loss: 0.1452 - acc: 0.9458 - val_loss: 0.0931 - val_acc: 0.9656\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.09308 to 0.09164, saving model to best.model\n",
      "0s - loss: 0.1424 - acc: 0.9424 - val_loss: 0.0916 - val_acc: 0.9639\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.09164 to 0.08407, saving model to best.model\n",
      "0s - loss: 0.1335 - acc: 0.9489 - val_loss: 0.0841 - val_acc: 0.9721\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.08407 to 0.07974, saving model to best.model\n",
      "0s - loss: 0.1304 - acc: 0.9535 - val_loss: 0.0797 - val_acc: 0.9787\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.07974 to 0.07566, saving model to best.model\n",
      "0s - loss: 0.1279 - acc: 0.9515 - val_loss: 0.0757 - val_acc: 0.9820\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.07566 to 0.07338, saving model to best.model\n",
      "0s - loss: 0.1168 - acc: 0.9566 - val_loss: 0.0734 - val_acc: 0.9787\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.07338 to 0.07031, saving model to best.model\n",
      "0s - loss: 0.1160 - acc: 0.9555 - val_loss: 0.0703 - val_acc: 0.9820\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.07031 to 0.06851, saving model to best.model\n",
      "0s - loss: 0.1147 - acc: 0.9564 - val_loss: 0.0685 - val_acc: 0.9836\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.06851 to 0.06250, saving model to best.model\n",
      "0s - loss: 0.1073 - acc: 0.9610 - val_loss: 0.0625 - val_acc: 0.9836\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.06250 to 0.06200, saving model to best.model\n",
      "0s - loss: 0.1041 - acc: 0.9591 - val_loss: 0.0620 - val_acc: 0.9852\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1031 - acc: 0.9622 - val_loss: 0.0634 - val_acc: 0.9836\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.06200 to 0.05668, saving model to best.model\n",
      "0s - loss: 0.1034 - acc: 0.9604 - val_loss: 0.0567 - val_acc: 0.9852\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.05668 to 0.05228, saving model to best.model\n",
      "0s - loss: 0.0949 - acc: 0.9655 - val_loss: 0.0523 - val_acc: 0.9852\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.05228 to 0.05073, saving model to best.model\n",
      "0s - loss: 0.0978 - acc: 0.9639 - val_loss: 0.0507 - val_acc: 0.9852\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.05073 to 0.04885, saving model to best.model\n",
      "0s - loss: 0.0964 - acc: 0.9624 - val_loss: 0.0488 - val_acc: 0.9852\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.04885 to 0.04754, saving model to best.model\n",
      "0s - loss: 0.0969 - acc: 0.9639 - val_loss: 0.0475 - val_acc: 0.9836\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.04754 to 0.04598, saving model to best.model\n",
      "0s - loss: 0.0883 - acc: 0.9675 - val_loss: 0.0460 - val_acc: 0.9836\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.0819 - acc: 0.9674 - val_loss: 0.0468 - val_acc: 0.9852\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.04598 to 0.04567, saving model to best.model\n",
      "0s - loss: 0.0891 - acc: 0.9664 - val_loss: 0.0457 - val_acc: 0.9852\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.04567 to 0.04323, saving model to best.model\n",
      "0s - loss: 0.0897 - acc: 0.9668 - val_loss: 0.0432 - val_acc: 0.9852\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.04323 to 0.04058, saving model to best.model\n",
      "0s - loss: 0.0822 - acc: 0.9692 - val_loss: 0.0406 - val_acc: 0.9885\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.04058 to 0.03887, saving model to best.model\n",
      "0s - loss: 0.0811 - acc: 0.9697 - val_loss: 0.0389 - val_acc: 0.9852\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.03887 to 0.03697, saving model to best.model\n",
      "0s - loss: 0.0733 - acc: 0.9726 - val_loss: 0.0370 - val_acc: 0.9885\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.03697 to 0.03614, saving model to best.model\n",
      "0s - loss: 0.0753 - acc: 0.9723 - val_loss: 0.0361 - val_acc: 0.9869\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.03614 to 0.03564, saving model to best.model\n",
      "0s - loss: 0.0757 - acc: 0.9721 - val_loss: 0.0356 - val_acc: 0.9869\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.03564 to 0.03412, saving model to best.model\n",
      "0s - loss: 0.0680 - acc: 0.9739 - val_loss: 0.0341 - val_acc: 0.9885\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.03412 to 0.03355, saving model to best.model\n",
      "0s - loss: 0.0753 - acc: 0.9706 - val_loss: 0.0336 - val_acc: 0.9885\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.03355 to 0.03213, saving model to best.model\n",
      "0s - loss: 0.0683 - acc: 0.9757 - val_loss: 0.0321 - val_acc: 0.9885\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.03213 to 0.03071, saving model to best.model\n",
      "0s - loss: 0.0711 - acc: 0.9723 - val_loss: 0.0307 - val_acc: 0.9885\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.03071 to 0.03060, saving model to best.model\n",
      "0s - loss: 0.0664 - acc: 0.9770 - val_loss: 0.0306 - val_acc: 0.9885\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.0622 - acc: 0.9745 - val_loss: 0.0315 - val_acc: 0.9869\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.03060 to 0.02940, saving model to best.model\n",
      "0s - loss: 0.0658 - acc: 0.9743 - val_loss: 0.0294 - val_acc: 0.9885\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.02940 to 0.02661, saving model to best.model\n",
      "0s - loss: 0.0684 - acc: 0.9719 - val_loss: 0.0266 - val_acc: 0.9885\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.02661 to 0.02572, saving model to best.model\n",
      "0s - loss: 0.0606 - acc: 0.9767 - val_loss: 0.0257 - val_acc: 0.9885\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.02572 to 0.02534, saving model to best.model\n",
      "0s - loss: 0.0600 - acc: 0.9790 - val_loss: 0.0253 - val_acc: 0.9885\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.0633 - acc: 0.9759 - val_loss: 0.0255 - val_acc: 0.9885\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.02534 to 0.02363, saving model to best.model\n",
      "0s - loss: 0.0639 - acc: 0.9752 - val_loss: 0.0236 - val_acc: 0.9885\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.02363 to 0.02230, saving model to best.model\n",
      "0s - loss: 0.0581 - acc: 0.9787 - val_loss: 0.0223 - val_acc: 0.9902\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.02230 to 0.02224, saving model to best.model\n",
      "0s - loss: 0.0583 - acc: 0.9781 - val_loss: 0.0222 - val_acc: 0.9902\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.02224 to 0.02105, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9807 - val_loss: 0.0210 - val_acc: 0.9885\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.02105 to 0.02081, saving model to best.model\n",
      "0s - loss: 0.0561 - acc: 0.9787 - val_loss: 0.0208 - val_acc: 0.9902\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.02081 to 0.02075, saving model to best.model\n",
      "0s - loss: 0.0521 - acc: 0.9808 - val_loss: 0.0208 - val_acc: 0.9902\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.02075 to 0.02073, saving model to best.model\n",
      "0s - loss: 0.0497 - acc: 0.9794 - val_loss: 0.0207 - val_acc: 0.9902\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0485 - acc: 0.9807 - val_loss: 0.0223 - val_acc: 0.9902\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.02073 to 0.01823, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9807 - val_loss: 0.0182 - val_acc: 0.9918\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9827 - val_loss: 0.0195 - val_acc: 0.9902\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0529 - acc: 0.9801 - val_loss: 0.0188 - val_acc: 0.9918\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9807 - val_loss: 0.0225 - val_acc: 0.9902\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9801 - val_loss: 0.0230 - val_acc: 0.9902\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9798 - val_loss: 0.0221 - val_acc: 0.9902\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.01823 to 0.01637, saving model to best.model\n",
      "0s - loss: 0.0426 - acc: 0.9832 - val_loss: 0.0164 - val_acc: 0.9934\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.01637 to 0.01627, saving model to best.model\n",
      "0s - loss: 0.0422 - acc: 0.9841 - val_loss: 0.0163 - val_acc: 0.9934\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.01627 to 0.01559, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9827 - val_loss: 0.0156 - val_acc: 0.9934\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.01559 to 0.01491, saving model to best.model\n",
      "0s - loss: 0.0412 - acc: 0.9840 - val_loss: 0.0149 - val_acc: 0.9934\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9843 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9823 - val_loss: 0.0169 - val_acc: 0.9918\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.01491 to 0.01413, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9825 - val_loss: 0.0141 - val_acc: 0.9934\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.01413 to 0.01367, saving model to best.model\n",
      "0s - loss: 0.0388 - acc: 0.9850 - val_loss: 0.0137 - val_acc: 0.9934\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9845 - val_loss: 0.0143 - val_acc: 0.9934\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.01367 to 0.01286, saving model to best.model\n",
      "0s - loss: 0.0472 - acc: 0.9829 - val_loss: 0.0129 - val_acc: 0.9934\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.01286 to 0.01263, saving model to best.model\n",
      "0s - loss: 0.0390 - acc: 0.9858 - val_loss: 0.0126 - val_acc: 0.9934\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.01263 to 0.01236, saving model to best.model\n",
      "0s - loss: 0.0432 - acc: 0.9832 - val_loss: 0.0124 - val_acc: 0.9934\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9865 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9850 - val_loss: 0.0124 - val_acc: 0.9951\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9847 - val_loss: 0.0128 - val_acc: 0.9934\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9847 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9876 - val_loss: 0.0131 - val_acc: 0.9934\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.01236 to 0.01095, saving model to best.model\n",
      "0s - loss: 0.0370 - acc: 0.9867 - val_loss: 0.0109 - val_acc: 0.9934\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9880 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9880 - val_loss: 0.0123 - val_acc: 0.9934\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9861 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9861 - val_loss: 0.0123 - val_acc: 0.9934\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9871 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9881 - val_loss: 0.0156 - val_acc: 0.9934\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.01095 to 0.01005, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9858 - val_loss: 0.0101 - val_acc: 0.9934\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9860 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9872 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9881 - val_loss: 0.0112 - val_acc: 0.9934\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0300 - acc: 0.9889 - val_loss: 0.0113 - val_acc: 0.9934\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9880 - val_loss: 0.0108 - val_acc: 0.9934\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.01005 to 0.00991, saving model to best.model\n",
      "0s - loss: 0.0291 - acc: 0.9869 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9874 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.00991 to 0.00951, saving model to best.model\n",
      "0s - loss: 0.0314 - acc: 0.9881 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.00951 to 0.00896, saving model to best.model\n",
      "0s - loss: 0.0281 - acc: 0.9896 - val_loss: 0.0090 - val_acc: 0.9984\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.00896 to 0.00849, saving model to best.model\n",
      "0s - loss: 0.0263 - acc: 0.9902 - val_loss: 0.0085 - val_acc: 0.9984\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.00849 to 0.00798, saving model to best.model\n",
      "0s - loss: 0.0304 - acc: 0.9881 - val_loss: 0.0080 - val_acc: 0.9984\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9898 - val_loss: 0.0083 - val_acc: 0.9951\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9889 - val_loss: 0.0084 - val_acc: 0.9951\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.00798 to 0.00796, saving model to best.model\n",
      "0s - loss: 0.0317 - acc: 0.9887 - val_loss: 0.0080 - val_acc: 0.9967\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.00796 to 0.00748, saving model to best.model\n",
      "0s - loss: 0.0227 - acc: 0.9911 - val_loss: 0.0075 - val_acc: 0.9984\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0258 - acc: 0.9900 - val_loss: 0.0076 - val_acc: 0.9984\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.00748 to 0.00738, saving model to best.model\n",
      "0s - loss: 0.0272 - acc: 0.9907 - val_loss: 0.0074 - val_acc: 0.9967\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9881 - val_loss: 0.0074 - val_acc: 0.9967\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9892 - val_loss: 0.0075 - val_acc: 0.9984\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0264 - acc: 0.9907 - val_loss: 0.0077 - val_acc: 0.9967\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.00738 to 0.00710, saving model to best.model\n",
      "0s - loss: 0.0270 - acc: 0.9892 - val_loss: 0.0071 - val_acc: 0.9984\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9878 - val_loss: 0.0073 - val_acc: 0.9967\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0257 - acc: 0.9902 - val_loss: 0.0075 - val_acc: 0.9967\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0076 - val_acc: 0.9967\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0246 - acc: 0.9902 - val_loss: 0.0080 - val_acc: 0.9951\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.00710 to 0.00697, saving model to best.model\n",
      "0s - loss: 0.0215 - acc: 0.9933 - val_loss: 0.0070 - val_acc: 0.9984\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.00697 to 0.00686, saving model to best.model\n",
      "0s - loss: 0.0206 - acc: 0.9922 - val_loss: 0.0069 - val_acc: 0.9967\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.00686 to 0.00641, saving model to best.model\n",
      "0s - loss: 0.0260 - acc: 0.9898 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0223 - acc: 0.9912 - val_loss: 0.0073 - val_acc: 0.9984\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0073 - val_acc: 0.9967\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0195 - acc: 0.9922 - val_loss: 0.0073 - val_acc: 0.9984\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0227 - acc: 0.9916 - val_loss: 0.0074 - val_acc: 0.9967\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0261 - acc: 0.9903 - val_loss: 0.0068 - val_acc: 0.9967\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0232 - acc: 0.9912 - val_loss: 0.0070 - val_acc: 0.9967\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0188 - acc: 0.9927 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.00641 to 0.00601, saving model to best.model\n",
      "0s - loss: 0.0244 - acc: 0.9900 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0221 - acc: 0.9923 - val_loss: 0.0066 - val_acc: 0.9984\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0225 - acc: 0.9918 - val_loss: 0.0066 - val_acc: 0.9984\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0230 - acc: 0.9894 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0215 - acc: 0.9918 - val_loss: 0.0066 - val_acc: 0.9967\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0231 - acc: 0.9918 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0196 - acc: 0.9931 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0186 - acc: 0.9929 - val_loss: 0.0062 - val_acc: 0.9967\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.00601 to 0.00542, saving model to best.model\n",
      "0s - loss: 0.0222 - acc: 0.9909 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0198 - acc: 0.9923 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.00542 to 0.00522, saving model to best.model\n",
      "0s - loss: 0.0216 - acc: 0.9914 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0192 - acc: 0.9934 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0231 - acc: 0.9912 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0176 - acc: 0.9936 - val_loss: 0.0060 - val_acc: 0.9967\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.00522 to 0.00466, saving model to best.model\n",
      "0s - loss: 0.0195 - acc: 0.9927 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0222 - acc: 0.9925 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.00466 to 0.00451, saving model to best.model\n",
      "0s - loss: 0.0169 - acc: 0.9943 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0216 - acc: 0.9916 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0231 - acc: 0.9912 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0185 - acc: 0.9927 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0047 - val_acc: 0.9984\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0207 - acc: 0.9927 - val_loss: 0.0047 - val_acc: 0.9984\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0175 - acc: 0.9936 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0174 - acc: 0.9925 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.00451 to 0.00422, saving model to best.model\n",
      "0s - loss: 0.0172 - acc: 0.9925 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0169 - acc: 0.9929 - val_loss: 0.0055 - val_acc: 0.9967\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0228 - acc: 0.9927 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0179 - acc: 0.9936 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0187 - acc: 0.9936 - val_loss: 0.0043 - val_acc: 0.9984\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0161 - acc: 0.9943 - val_loss: 0.0050 - val_acc: 0.9967\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.00422 to 0.00383, saving model to best.model\n",
      "0s - loss: 0.0181 - acc: 0.9927 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0187 - acc: 0.9934 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0143 - acc: 0.9945 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0154 - acc: 0.9943 - val_loss: 0.0040 - val_acc: 0.9984\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0160 - acc: 0.9940 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0146 - acc: 0.9943 - val_loss: 0.0043 - val_acc: 0.9984\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0149 - acc: 0.9942 - val_loss: 0.0057 - val_acc: 0.9967\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00383 to 0.00334, saving model to best.model\n",
      "0s - loss: 0.0145 - acc: 0.9945 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0191 - acc: 0.9914 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0178 - acc: 0.9934 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00334 to 0.00305, saving model to best.model\n",
      "0s - loss: 0.0144 - acc: 0.9945 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0036 - val_acc: 0.9984\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0160 - acc: 0.9942 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0123 - acc: 0.9942 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0105 - acc: 0.9956 - val_loss: 0.0040 - val_acc: 0.9984\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0123 - acc: 0.9951 - val_loss: 0.0037 - val_acc: 0.9984\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00305 to 0.00274, saving model to best.model\n",
      "0s - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0126 - acc: 0.9949 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0139 - acc: 0.9947 - val_loss: 0.0048 - val_acc: 0.9967\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.00274 to 0.00255, saving model to best.model\n",
      "0s - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0116 - acc: 0.9949 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0124 - acc: 0.9958 - val_loss: 0.0026 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist=m.fit(\n",
    "    # Feature matrix\n",
    "    X_train.values, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        history,\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFlCAYAAADComBzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c18410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.load_weights(\"best.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in m.predict(X_test.values).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1072\n",
      "          1       1.00      1.00      1.00       959\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Class', u'cap-shape', u'cap-surface', u'cap-color', u'bruises',\n",
       "       u'odor', u'gill-attachment', u'gill-spacing', u'gill-size',\n",
       "       u'gill-color', u'stalk-shape', u'stalk-root',\n",
       "       u'stalk-surface-above-ring', u'stalk-surface-below-ring',\n",
       "       u'stalk-color-above-ring', u'stalk-color-below-ring', u'veil-type',\n",
       "       u'veil-color', u'ring-number', u'ring-type', u'spore-print-color',\n",
       "       u'population', u'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5483 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.41683, saving model to best.model\n",
      "0s - loss: 0.4869 - acc: 0.7828 - val_loss: 0.4168 - val_acc: 0.8459\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.41683 to 0.30246, saving model to best.model\n",
      "0s - loss: 0.3440 - acc: 0.8669 - val_loss: 0.3025 - val_acc: 0.9016\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.30246 to 0.25298, saving model to best.model\n",
      "0s - loss: 0.2898 - acc: 0.8849 - val_loss: 0.2530 - val_acc: 0.9131\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.25298 to 0.22284, saving model to best.model\n",
      "0s - loss: 0.2574 - acc: 0.8959 - val_loss: 0.2228 - val_acc: 0.9164\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.22284 to 0.21261, saving model to best.model\n",
      "0s - loss: 0.2308 - acc: 0.9134 - val_loss: 0.2126 - val_acc: 0.9262\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.21261 to 0.18542, saving model to best.model\n",
      "0s - loss: 0.2325 - acc: 0.9167 - val_loss: 0.1854 - val_acc: 0.9328\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.18542 to 0.18455, saving model to best.model\n",
      "0s - loss: 0.2063 - acc: 0.9269 - val_loss: 0.1846 - val_acc: 0.9328\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.2040 - acc: 0.9269 - val_loss: 0.1994 - val_acc: 0.9295\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.18455 to 0.16256, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9320 - val_loss: 0.1626 - val_acc: 0.9492\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.16256 to 0.15436, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9358 - val_loss: 0.1544 - val_acc: 0.9508\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.15436 to 0.14495, saving model to best.model\n",
      "0s - loss: 0.1826 - acc: 0.9331 - val_loss: 0.1449 - val_acc: 0.9393\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.14495 to 0.14054, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9413 - val_loss: 0.1405 - val_acc: 0.9492\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.14054 to 0.13860, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9380 - val_loss: 0.1386 - val_acc: 0.9525\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.13860 to 0.13225, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9405 - val_loss: 0.1323 - val_acc: 0.9492\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.13225 to 0.11852, saving model to best.model\n",
      "0s - loss: 0.1529 - acc: 0.9457 - val_loss: 0.1185 - val_acc: 0.9557\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.11852 to 0.11471, saving model to best.model\n",
      "0s - loss: 0.1484 - acc: 0.9467 - val_loss: 0.1147 - val_acc: 0.9574\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.1385 - acc: 0.9502 - val_loss: 0.1150 - val_acc: 0.9508\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.11471 to 0.09898, saving model to best.model\n",
      "0s - loss: 0.1296 - acc: 0.9515 - val_loss: 0.0990 - val_acc: 0.9656\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.09898 to 0.08936, saving model to best.model\n",
      "0s - loss: 0.1207 - acc: 0.9535 - val_loss: 0.0894 - val_acc: 0.9738\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.1105 - acc: 0.9581 - val_loss: 0.1083 - val_acc: 0.9607\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.08936 to 0.07674, saving model to best.model\n",
      "0s - loss: 0.1007 - acc: 0.9617 - val_loss: 0.0767 - val_acc: 0.9738\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.07674 to 0.06322, saving model to best.model\n",
      "0s - loss: 0.0839 - acc: 0.9677 - val_loss: 0.0632 - val_acc: 0.9803\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.06322 to 0.05926, saving model to best.model\n",
      "0s - loss: 0.0736 - acc: 0.9717 - val_loss: 0.0593 - val_acc: 0.9787\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.0635 - acc: 0.9768 - val_loss: 0.0982 - val_acc: 0.9639\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.05926 to 0.03793, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9810 - val_loss: 0.0379 - val_acc: 0.9902\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.03793 to 0.03613, saving model to best.model\n",
      "0s - loss: 0.0444 - acc: 0.9852 - val_loss: 0.0361 - val_acc: 0.9918\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.03613 to 0.03133, saving model to best.model\n",
      "0s - loss: 0.0357 - acc: 0.9887 - val_loss: 0.0313 - val_acc: 0.9934\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.03133 to 0.02408, saving model to best.model\n",
      "0s - loss: 0.0325 - acc: 0.9907 - val_loss: 0.0241 - val_acc: 0.9918\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9929 - val_loss: 0.0286 - val_acc: 0.9918\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.02408 to 0.01924, saving model to best.model\n",
      "0s - loss: 0.0252 - acc: 0.9931 - val_loss: 0.0192 - val_acc: 0.9951\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.0202 - acc: 0.9956 - val_loss: 0.0203 - val_acc: 0.9951\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.0180 - acc: 0.9958 - val_loss: 0.0328 - val_acc: 0.9836\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.01924 to 0.01592, saving model to best.model\n",
      "0s - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0159 - val_acc: 0.9967\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.01592 to 0.01567, saving model to best.model\n",
      "0s - loss: 0.0130 - acc: 0.9969 - val_loss: 0.0157 - val_acc: 0.9951\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.01567 to 0.01182, saving model to best.model\n",
      "0s - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0118 - val_acc: 0.9967\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.01182 to 0.00938, saving model to best.model\n",
      "0s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0094 - val_acc: 0.9984\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.00938 to 0.00882, saving model to best.model\n",
      "0s - loss: 0.0099 - acc: 0.9976 - val_loss: 0.0088 - val_acc: 0.9967\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.00882 to 0.00761, saving model to best.model\n",
      "0s - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0076 - val_acc: 0.9967\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.00761 to 0.00659, saving model to best.model\n",
      "0s - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0066 - val_acc: 0.9984\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.0075 - acc: 0.9984 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.00659 to 0.00634, saving model to best.model\n",
      "0s - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0063 - val_acc: 0.9967\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0128 - val_acc: 0.9967\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.00634 to 0.00540, saving model to best.model\n",
      "0s - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0136 - val_acc: 0.9918\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.00540 to 0.00337, saving model to best.model\n",
      "0s - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.0044 - acc: 0.9993 - val_loss: 0.0044 - val_acc: 0.9984\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0128 - val_acc: 0.9934\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0053 - val_acc: 0.9967\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0123 - val_acc: 0.9934\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.00337 to 0.00199, saving model to best.model\n",
      "0s - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0026 - val_acc: 0.9984\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0023 - val_acc: 0.9984\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.00199 to 0.00165, saving model to best.model\n",
      "0s - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0067 - val_acc: 0.9967\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0028 - val_acc: 0.9984\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.00165 to 0.00113, saving model to best.model\n",
      "0s - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.0039 - acc: 0.9982 - val_loss: 0.0083 - val_acc: 0.9951\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0115 - val_acc: 0.9934\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0028 - val_acc: 0.9984\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0077 - val_acc: 0.9967\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.0022 - acc: 0.9987 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0019 - val_acc: 0.9984\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.00113 to 0.00063, saving model to best.model\n",
      "0s - loss: 9.9012e-04 - acc: 0.9996 - val_loss: 6.3233e-04 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.0028 - acc: 0.9991 - val_loss: 6.7091e-04 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.0014 - acc: 0.9993 - val_loss: 0.0019 - val_acc: 0.9984\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "1s - loss: 0.0034 - acc: 0.9985 - val_loss: 0.0041 - val_acc: 0.9984\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0029 - acc: 0.9989 - val_loss: 7.7432e-04 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0023 - acc: 0.9993 - val_loss: 7.9787e-04 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 9.8843e-04 - acc: 0.9996 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 7.7625e-04 - acc: 0.9998 - val_loss: 0.0015 - val_acc: 0.9984\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 0.9984\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.00063 to 0.00040, saving model to best.model\n",
      "0s - loss: 0.0018 - acc: 0.9996 - val_loss: 3.9582e-04 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.00040 to 0.00030, saving model to best.model\n",
      "0s - loss: 8.2514e-04 - acc: 0.9996 - val_loss: 3.0044e-04 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 7.3456e-04 - acc: 0.9998 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 7.8256e-04 - acc: 0.9998 - val_loss: 0.0036 - val_acc: 0.9984\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0028 - acc: 0.9987 - val_loss: 8.9470e-04 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0021 - acc: 0.9991 - val_loss: 3.0749e-04 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 5.2431e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9984\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0014 - acc: 0.9993 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0039 - acc: 0.9993 - val_loss: 3.5618e-04 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0017 - acc: 0.9993 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 8.4935e-04 - acc: 0.9998 - val_loss: 5.3598e-04 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0040 - val_acc: 0.9984\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 8.7300e-04 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0116 - val_acc: 0.9934\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.00030 to 0.00021, saving model to best.model\n",
      "0s - loss: 0.0016 - acc: 0.9993 - val_loss: 2.1350e-04 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0010 - acc: 0.9995 - val_loss: 0.0173 - val_acc: 0.9934\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 7.7015e-04 - acc: 0.9998 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.00021 to 0.00014, saving model to best.model\n",
      "0s - loss: 4.3878e-04 - acc: 0.9998 - val_loss: 1.4093e-04 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0023 - acc: 0.9991 - val_loss: 1.9538e-04 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.00014 to 0.00013, saving model to best.model\n",
      "0s - loss: 1.8113e-04 - acc: 1.0000 - val_loss: 1.3104e-04 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 6.4034e-04 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 5.8681e-04 - acc: 0.9996 - val_loss: 1.5491e-04 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 3.9434e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9984\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 7.0114e-04 - acc: 0.9998 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0031 - val_acc: 0.9984\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0024 - acc: 0.9993 - val_loss: 3.9474e-04 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0011 - acc: 0.9995 - val_loss: 0.0016 - val_acc: 0.9984\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 4.9826e-04 - acc: 1.0000 - val_loss: 7.9833e-04 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 1.8458e-04 - acc: 1.0000 - val_loss: 5.0223e-04 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 2.7943e-04 - acc: 1.0000 - val_loss: 2.1078e-04 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 7.3982e-04 - acc: 0.9998 - val_loss: 0.0015 - val_acc: 0.9984\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0013 - acc: 0.9995 - val_loss: 5.6266e-04 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 6.8330e-04 - acc: 0.9998 - val_loss: 3.1875e-04 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 2.5429e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9984\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 5.0311e-04 - acc: 0.9998 - val_loss: 0.0067 - val_acc: 0.9984\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 8.1651e-04 - acc: 0.9996 - val_loss: 5.1441e-04 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.00013 to 0.00008, saving model to best.model\n",
      "0s - loss: 5.3689e-04 - acc: 0.9998 - val_loss: 7.6418e-05 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 2.5160e-04 - acc: 1.0000 - val_loss: 6.2080e-04 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 6.6292e-04 - acc: 0.9996 - val_loss: 5.6309e-04 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 1.4772e-04 - acc: 1.0000 - val_loss: 8.8556e-05 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 2.2632e-04 - acc: 1.0000 - val_loss: 7.3235e-04 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 2.6832e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9984\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 5.6140e-04 - acc: 0.9996 - val_loss: 0.0029 - val_acc: 0.9984\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 4.1120e-04 - acc: 0.9998 - val_loss: 1.0933e-04 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 1.7088e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9984\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0048 - acc: 0.9980 - val_loss: 0.0022 - val_acc: 0.9984\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 2.5951e-04 - acc: 1.0000 - val_loss: 1.5133e-04 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 1.1533e-04 - acc: 1.0000 - val_loss: 1.5950e-04 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 1.2338e-04 - acc: 1.0000 - val_loss: 9.0779e-05 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.00008 to 0.00007, saving model to best.model\n",
      "0s - loss: 2.1460e-04 - acc: 1.0000 - val_loss: 6.9558e-05 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 7.1781e-04 - acc: 0.9996 - val_loss: 2.1267e-04 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 1.2851e-04 - acc: 1.0000 - val_loss: 2.7952e-04 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 2.1665e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 4.0094e-04 - acc: 1.0000 - val_loss: 3.7054e-04 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 5.4970e-05 - acc: 1.0000 - val_loss: 2.1748e-04 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 4.0562e-05 - acc: 1.0000 - val_loss: 3.3224e-04 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 2.0243e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9984\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.00007 to 0.00002, saving model to best.model\n",
      "0s - loss: 6.9183e-05 - acc: 1.0000 - val_loss: 1.8827e-05 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0018 - acc: 0.9993 - val_loss: 4.9977e-05 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 8.0068e-05 - acc: 1.0000 - val_loss: 3.2674e-04 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 4.4532e-05 - acc: 1.0000 - val_loss: 4.1407e-05 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 1.1010e-04 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9984\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 1.7796e-04 - acc: 1.0000 - val_loss: 1.4973e-04 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 8.0200e-05 - acc: 1.0000 - val_loss: 8.0786e-05 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 6.0753e-05 - acc: 1.0000 - val_loss: 2.0379e-04 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 4.6361e-05 - acc: 1.0000 - val_loss: 1.9787e-04 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 3.8336e-05 - acc: 1.0000 - val_loss: 3.2189e-04 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 3.5222e-05 - acc: 1.0000 - val_loss: 1.5653e-04 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 2.5986e-05 - acc: 1.0000 - val_loss: 3.6792e-04 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 9.4989e-05 - acc: 1.0000 - val_loss: 3.6411e-04 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 2.6379e-05 - acc: 1.0000 - val_loss: 2.1965e-04 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 2.6337e-05 - acc: 1.0000 - val_loss: 2.1648e-05 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 1.7490e-05 - acc: 1.0000 - val_loss: 2.0976e-04 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0017 - acc: 0.9991 - val_loss: 7.7826e-05 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0018 - acc: 0.9995 - val_loss: 7.6354e-05 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 7.1117e-05 - acc: 1.0000 - val_loss: 1.6395e-04 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 5.0698e-05 - acc: 1.0000 - val_loss: 2.3059e-04 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 4.7353e-05 - acc: 1.0000 - val_loss: 1.8225e-04 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 3.6744e-05 - acc: 1.0000 - val_loss: 1.5567e-04 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 3.0480e-05 - acc: 1.0000 - val_loss: 7.1332e-05 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 2.5609e-05 - acc: 1.0000 - val_loss: 7.0583e-05 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 2.6375e-05 - acc: 1.0000 - val_loss: 2.5141e-04 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 2.2097e-05 - acc: 1.0000 - val_loss: 4.6661e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.models import Model\n",
    "import keras\n",
    "history = History()\n",
    "\n",
    "\n",
    "input_1 = Input(shape=(1,))\n",
    "input_2 = Input(shape=(1,))\n",
    "input_3 = Input(shape=(1,))\n",
    "input_4 = Input(shape=(1,))\n",
    "input_5 = Input(shape=(1,))\n",
    "input_6 = Input(shape=(1,))\n",
    "input_7 = Input(shape=(1,))\n",
    "input_8 = Input(shape=(1,))\n",
    "input_9 = Input(shape=(1,))\n",
    "input_10 = Input(shape=(1,))\n",
    "input_11 = Input(shape=(1,))\n",
    "input_12 = Input(shape=(1,))\n",
    "input_13 = Input(shape=(1,))\n",
    "input_14= Input(shape=(1,))\n",
    "input_15 = Input(shape=(1,))\n",
    "input_16 = Input(shape=(1,))\n",
    "input_17 = Input(shape=(1,))\n",
    "input_18 = Input(shape=(1,))\n",
    "input_19 = Input(shape=(1,))\n",
    "input_20= Input(shape=(1,))\n",
    "input_21= Input(shape=(1,))\n",
    "input_22 = Input(shape=(1,))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_1 = Dense(32, activation='sigmoid')(input_1)\n",
    "hidden_2 = Dense(32, activation='sigmoid')(input_2)\n",
    "hidden_3 = Dense(32, activation='sigmoid')(input_3)\n",
    "hidden_4 = Dense(32, activation='sigmoid')(input_4)\n",
    "hidden_5 = Dense(32, activation='sigmoid')(input_5)\n",
    "hidden_6 = Dense(32, activation='sigmoid')(input_6)\n",
    "hidden_7 = Dense(32, activation='sigmoid')(input_7)\n",
    "hidden_8 = Dense(32, activation='sigmoid')(input_8)\n",
    "hidden_9 = Dense(32, activation='sigmoid')(input_9)\n",
    "hidden_10 = Dense(32, activation='sigmoid')(input_10)\n",
    "hidden_11= Dense(32, activation='sigmoid')(input_11)\n",
    "hidden_12 = Dense(32, activation='sigmoid')(input_12)\n",
    "hidden_13= Dense(32, activation='sigmoid')(input_13)\n",
    "hidden_14= Dense(32, activation='sigmoid')(input_14)\n",
    "hidden_15= Dense(32, activation='sigmoid')(input_15)\n",
    "hidden_16= Dense(32, activation='sigmoid')(input_16)\n",
    "hidden_17= Dense(32, activation='sigmoid')(input_17)\n",
    "hidden_18= Dense(32, activation='sigmoid')(input_18)\n",
    "hidden_19= Dense(32, activation='sigmoid')(input_19)\n",
    "hidden_20= Dense(32, activation='sigmoid')(input_20)\n",
    "hidden_21= Dense(32, activation='sigmoid')(input_21)\n",
    "hidden_22= Dense(32, activation='sigmoid')(input_22)\n",
    "\n",
    "\n",
    "\n",
    "value_list=[X_train[['cap-shape']].values,\n",
    "            X_train[['cap-surface']].values,\n",
    "            X_train[['cap-color']].values,\n",
    "            X_train[['bruises']].values,\n",
    "            X_train[['odor']].values,\n",
    "            X_train[['gill-attachment']].values,\n",
    "            X_train[['gill-spacing']].values,\n",
    "            X_train[['gill-size']].values,\n",
    "            X_train[['gill-color']].values,\n",
    "            X_train[['stalk-shape']].values,\n",
    "            X_train[['stalk-root']].values,\n",
    "            X_train[['stalk-surface-above-ring']].values,\n",
    "            X_train[['stalk-surface-below-ring']].values,\n",
    "            X_train[['stalk-color-above-ring']].values,\n",
    "            X_train[['stalk-color-below-ring']].values,\n",
    "            X_train[['ring-number']].values,\n",
    "            X_train[['ring-type']].values,\n",
    "            X_train[['spore-print-color']].values,\n",
    "            X_train[['population']].values,\n",
    "            X_train[['habitat']].values,\n",
    "            X_train[['veil-type']].values,\n",
    "            X_train[['veil-color']].values,\n",
    "           ]\n",
    "\n",
    "value_list_test=[X_test[['cap-shape']].values,\n",
    "            X_test[['cap-surface']].values,\n",
    "            X_test[['cap-color']].values,\n",
    "            X_test[['bruises']].values,\n",
    "            X_test[['odor']].values,\n",
    "            X_test[['gill-attachment']].values,\n",
    "            X_test[['gill-spacing']].values,\n",
    "            X_test[['gill-size']].values,\n",
    "            X_test[['gill-color']].values,\n",
    "            X_test[['stalk-shape']].values,\n",
    "            X_test[['stalk-root']].values,\n",
    "            X_test[['stalk-surface-above-ring']].values,\n",
    "            X_test[['stalk-surface-below-ring']].values,\n",
    "            X_test[['stalk-color-above-ring']].values,\n",
    "            X_test[['stalk-color-below-ring']].values,\n",
    "            X_test[['ring-number']].values,\n",
    "            X_test[['ring-type']].values,\n",
    "            X_test[['spore-print-color']].values,\n",
    "            X_test[['population']].values,\n",
    "            X_test[['habitat']].values,\n",
    "            X_test[['veil-type']].values,\n",
    "            X_test[['veil-color']].values,\n",
    "           ]\n",
    "\n",
    "\n",
    "\n",
    "x = keras.layers.concatenate([hidden_1,hidden_2,hidden_3,hidden_4,hidden_5,hidden_6,hidden_7,hidden_8,\n",
    "                             hidden_9,hidden_10,hidden_11,hidden_12,hidden_13,hidden_14,hidden_15,hidden_16,\n",
    "                             hidden_17,hidden_18,hidden_19,hidden_20,hidden_21,hidden_22])\n",
    "\n",
    "x = Dense(96, activation='sigmoid')(x)\n",
    "output = Dense(len(np.unique(Y_train)), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[input_1,input_2,input_3,input_4,input_5,input_6,input_7,input_8,\n",
    "                     input_9,input_10,input_11,input_12,input_13,input_14,input_15,input_16,\n",
    "                     input_17,input_18,input_19,input_20,input_21,input_22], outputs=[output])\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "hist=model.fit(\n",
    "    # Feature matrix\n",
    "    value_list, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        history,\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=, \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFlCAYAAADComBzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1174cf750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best.model\")\n",
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in model.predict(value_list_test).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   0  959]]\n",
      "100.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1072\n",
      "          1       1.00      1.00      1.00       959\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train,data_val=train_test_split(train,test_size=0.25, random_state=10)\n",
    "X_val=data_val.drop(['Class'], axis=1).values\n",
    "y_val=data_val['Class'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_nn_simple(data_train,X_val,y_val):\n",
    "    \n",
    "\n",
    "    data_train_new=data_train.sample(frac=0.632,replace=True)\n",
    "    X_train=data_train_new.drop(['Class'], axis=1).values\n",
    "    y_train=data_train_new['Class'].ravel()\n",
    "    \n",
    "    m = Sequential()\n",
    "    m.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='sigmoid'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='sigmoid'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "    \n",
    "    m.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    m.fit(\n",
    "    # Feature matrix\n",
    "    X_train, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.2,\n",
    "    batch_size=256, \n",
    "    )\n",
    "    m.load_weights(\"best.model\")\n",
    "    mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    "    )\n",
    "    y_pred = [mapping[pred] for pred in m.predict(X_val).argmax(axis=1)]\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68318, saving model to best.model\n",
      "0s - loss: 0.8463 - acc: 0.5103 - val_loss: 0.6832 - val_acc: 0.5355\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68318 to 0.65780, saving model to best.model\n",
      "0s - loss: 0.7681 - acc: 0.5240 - val_loss: 0.6578 - val_acc: 0.7352\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65780 to 0.62107, saving model to best.model\n",
      "0s - loss: 0.7346 - acc: 0.5466 - val_loss: 0.6211 - val_acc: 0.8043\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.62107 to 0.56654, saving model to best.model\n",
      "0s - loss: 0.6855 - acc: 0.5866 - val_loss: 0.5665 - val_acc: 0.8004\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.56654 to 0.48540, saving model to best.model\n",
      "0s - loss: 0.6101 - acc: 0.6672 - val_loss: 0.4854 - val_acc: 0.8199\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.48540 to 0.42027, saving model to best.model\n",
      "0s - loss: 0.5495 - acc: 0.7285 - val_loss: 0.4203 - val_acc: 0.8296\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.42027 to 0.38362, saving model to best.model\n",
      "0s - loss: 0.4753 - acc: 0.7916 - val_loss: 0.3836 - val_acc: 0.8364\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38362 to 0.34863, saving model to best.model\n",
      "0s - loss: 0.4335 - acc: 0.8128 - val_loss: 0.3486 - val_acc: 0.8627\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34863 to 0.32823, saving model to best.model\n",
      "0s - loss: 0.4089 - acc: 0.8347 - val_loss: 0.3282 - val_acc: 0.8647\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32823 to 0.31544, saving model to best.model\n",
      "0s - loss: 0.3830 - acc: 0.8427 - val_loss: 0.3154 - val_acc: 0.8734\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31544 to 0.30281, saving model to best.model\n",
      "0s - loss: 0.3654 - acc: 0.8585 - val_loss: 0.3028 - val_acc: 0.8773\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30281 to 0.28850, saving model to best.model\n",
      "0s - loss: 0.3572 - acc: 0.8563 - val_loss: 0.2885 - val_acc: 0.8812\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28850 to 0.27866, saving model to best.model\n",
      "0s - loss: 0.3418 - acc: 0.8585 - val_loss: 0.2787 - val_acc: 0.8851\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27866 to 0.26499, saving model to best.model\n",
      "0s - loss: 0.3407 - acc: 0.8661 - val_loss: 0.2650 - val_acc: 0.8890\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26499 to 0.25946, saving model to best.model\n",
      "0s - loss: 0.3181 - acc: 0.8831 - val_loss: 0.2595 - val_acc: 0.8919\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25946 to 0.24844, saving model to best.model\n",
      "0s - loss: 0.3146 - acc: 0.8785 - val_loss: 0.2484 - val_acc: 0.8987\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24844 to 0.24029, saving model to best.model\n",
      "0s - loss: 0.2993 - acc: 0.8841 - val_loss: 0.2403 - val_acc: 0.9007\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24029 to 0.23284, saving model to best.model\n",
      "0s - loss: 0.2941 - acc: 0.8863 - val_loss: 0.2328 - val_acc: 0.9046\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23284 to 0.22554, saving model to best.model\n",
      "0s - loss: 0.2891 - acc: 0.8882 - val_loss: 0.2255 - val_acc: 0.9065\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22554 to 0.21979, saving model to best.model\n",
      "0s - loss: 0.2900 - acc: 0.8897 - val_loss: 0.2198 - val_acc: 0.9104\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.21979 to 0.21621, saving model to best.model\n",
      "0s - loss: 0.2726 - acc: 0.8963 - val_loss: 0.2162 - val_acc: 0.9153\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21621 to 0.20989, saving model to best.model\n",
      "0s - loss: 0.2711 - acc: 0.8992 - val_loss: 0.2099 - val_acc: 0.9172\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20989 to 0.20569, saving model to best.model\n",
      "0s - loss: 0.2634 - acc: 0.8992 - val_loss: 0.2057 - val_acc: 0.9172\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20569 to 0.20216, saving model to best.model\n",
      "0s - loss: 0.2665 - acc: 0.9016 - val_loss: 0.2022 - val_acc: 0.9182\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20216 to 0.19831, saving model to best.model\n",
      "0s - loss: 0.2603 - acc: 0.8997 - val_loss: 0.1983 - val_acc: 0.9211\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19831 to 0.19378, saving model to best.model\n",
      "0s - loss: 0.2499 - acc: 0.9050 - val_loss: 0.1938 - val_acc: 0.9221\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19378 to 0.18962, saving model to best.model\n",
      "0s - loss: 0.2548 - acc: 0.9065 - val_loss: 0.1896 - val_acc: 0.9211\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18962 to 0.18593, saving model to best.model\n",
      "0s - loss: 0.2447 - acc: 0.9087 - val_loss: 0.1859 - val_acc: 0.9202\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18593 to 0.18380, saving model to best.model\n",
      "0s - loss: 0.2432 - acc: 0.9070 - val_loss: 0.1838 - val_acc: 0.9202\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18380 to 0.17958, saving model to best.model\n",
      "0s - loss: 0.2380 - acc: 0.9114 - val_loss: 0.1796 - val_acc: 0.9231\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.17958 to 0.17440, saving model to best.model\n",
      "0s - loss: 0.2370 - acc: 0.9094 - val_loss: 0.1744 - val_acc: 0.9270\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.17440 to 0.17077, saving model to best.model\n",
      "0s - loss: 0.2275 - acc: 0.9138 - val_loss: 0.1708 - val_acc: 0.9299\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17077 to 0.16894, saving model to best.model\n",
      "0s - loss: 0.2285 - acc: 0.9099 - val_loss: 0.1689 - val_acc: 0.9279\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.16894 to 0.16813, saving model to best.model\n",
      "0s - loss: 0.2200 - acc: 0.9143 - val_loss: 0.1681 - val_acc: 0.9250\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.16813 to 0.16132, saving model to best.model\n",
      "0s - loss: 0.2243 - acc: 0.9106 - val_loss: 0.1613 - val_acc: 0.9318\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.16132 to 0.15845, saving model to best.model\n",
      "0s - loss: 0.2092 - acc: 0.9175 - val_loss: 0.1584 - val_acc: 0.9357\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.15845 to 0.15345, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9204 - val_loss: 0.1535 - val_acc: 0.9367\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.15345 to 0.15284, saving model to best.model\n",
      "0s - loss: 0.2021 - acc: 0.9243 - val_loss: 0.1528 - val_acc: 0.9328\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.15284 to 0.14595, saving model to best.model\n",
      "0s - loss: 0.2007 - acc: 0.9235 - val_loss: 0.1459 - val_acc: 0.9426\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.14595 to 0.14491, saving model to best.model\n",
      "0s - loss: 0.1974 - acc: 0.9267 - val_loss: 0.1449 - val_acc: 0.9328\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.14491 to 0.13896, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9277 - val_loss: 0.1390 - val_acc: 0.9445\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1919 - acc: 0.9294 - val_loss: 0.1408 - val_acc: 0.9338\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.13896 to 0.13414, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9279 - val_loss: 0.1341 - val_acc: 0.9533\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13414 to 0.13087, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9299 - val_loss: 0.1309 - val_acc: 0.9523\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13087 to 0.12962, saving model to best.model\n",
      "0s - loss: 0.1744 - acc: 0.9372 - val_loss: 0.1296 - val_acc: 0.9435\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.12962 to 0.12499, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9330 - val_loss: 0.1250 - val_acc: 0.9513\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.12499 to 0.12206, saving model to best.model\n",
      "0s - loss: 0.1752 - acc: 0.9299 - val_loss: 0.1221 - val_acc: 0.9562\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9311 - val_loss: 0.1360 - val_acc: 0.9328\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12206 to 0.11697, saving model to best.model\n",
      "0s - loss: 0.1830 - acc: 0.9294 - val_loss: 0.1170 - val_acc: 0.9542\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.11697 to 0.11280, saving model to best.model\n",
      "0s - loss: 0.1651 - acc: 0.9364 - val_loss: 0.1128 - val_acc: 0.9533\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11280 to 0.10913, saving model to best.model\n",
      "0s - loss: 0.1488 - acc: 0.9435 - val_loss: 0.1091 - val_acc: 0.9542\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.10913 to 0.10859, saving model to best.model\n",
      "0s - loss: 0.1535 - acc: 0.9418 - val_loss: 0.1086 - val_acc: 0.9533\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.10859 to 0.10416, saving model to best.model\n",
      "0s - loss: 0.1606 - acc: 0.9382 - val_loss: 0.1042 - val_acc: 0.9620\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10416 to 0.10063, saving model to best.model\n",
      "0s - loss: 0.1514 - acc: 0.9413 - val_loss: 0.1006 - val_acc: 0.9611\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10063 to 0.09975, saving model to best.model\n",
      "0s - loss: 0.1493 - acc: 0.9394 - val_loss: 0.0997 - val_acc: 0.9611\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.09975 to 0.09803, saving model to best.model\n",
      "0s - loss: 0.1477 - acc: 0.9459 - val_loss: 0.0980 - val_acc: 0.9611\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09803 to 0.09373, saving model to best.model\n",
      "0s - loss: 0.1467 - acc: 0.9403 - val_loss: 0.0937 - val_acc: 0.9649\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09373 to 0.08928, saving model to best.model\n",
      "0s - loss: 0.1366 - acc: 0.9520 - val_loss: 0.0893 - val_acc: 0.9659\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1472 - acc: 0.9433 - val_loss: 0.0938 - val_acc: 0.9630\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.08928 to 0.08748, saving model to best.model\n",
      "0s - loss: 0.1407 - acc: 0.9452 - val_loss: 0.0875 - val_acc: 0.9688\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08748 to 0.08395, saving model to best.model\n",
      "0s - loss: 0.1340 - acc: 0.9491 - val_loss: 0.0839 - val_acc: 0.9698\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08395 to 0.08289, saving model to best.model\n",
      "0s - loss: 0.1412 - acc: 0.9477 - val_loss: 0.0829 - val_acc: 0.9708\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08289 to 0.08011, saving model to best.model\n",
      "0s - loss: 0.1343 - acc: 0.9489 - val_loss: 0.0801 - val_acc: 0.9698\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08011 to 0.07722, saving model to best.model\n",
      "0s - loss: 0.1219 - acc: 0.9540 - val_loss: 0.0772 - val_acc: 0.9727\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07722 to 0.07551, saving model to best.model\n",
      "0s - loss: 0.1159 - acc: 0.9598 - val_loss: 0.0755 - val_acc: 0.9698\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07551 to 0.07441, saving model to best.model\n",
      "0s - loss: 0.1169 - acc: 0.9528 - val_loss: 0.0744 - val_acc: 0.9737\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07441 to 0.07124, saving model to best.model\n",
      "0s - loss: 0.1199 - acc: 0.9540 - val_loss: 0.0712 - val_acc: 0.9698\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07124 to 0.07016, saving model to best.model\n",
      "0s - loss: 0.1167 - acc: 0.9574 - val_loss: 0.0702 - val_acc: 0.9708\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07016 to 0.06765, saving model to best.model\n",
      "0s - loss: 0.1161 - acc: 0.9540 - val_loss: 0.0677 - val_acc: 0.9757\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06765 to 0.06633, saving model to best.model\n",
      "0s - loss: 0.1115 - acc: 0.9557 - val_loss: 0.0663 - val_acc: 0.9757\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06633 to 0.06424, saving model to best.model\n",
      "0s - loss: 0.1129 - acc: 0.9559 - val_loss: 0.0642 - val_acc: 0.9757\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06424 to 0.06140, saving model to best.model\n",
      "0s - loss: 0.1062 - acc: 0.9586 - val_loss: 0.0614 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06140 to 0.05992, saving model to best.model\n",
      "0s - loss: 0.1093 - acc: 0.9571 - val_loss: 0.0599 - val_acc: 0.9766\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.05992 to 0.05821, saving model to best.model\n",
      "0s - loss: 0.1132 - acc: 0.9567 - val_loss: 0.0582 - val_acc: 0.9786\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.05821 to 0.05654, saving model to best.model\n",
      "0s - loss: 0.1066 - acc: 0.9606 - val_loss: 0.0565 - val_acc: 0.9796\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1068 - acc: 0.9613 - val_loss: 0.0592 - val_acc: 0.9786\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05654 to 0.05507, saving model to best.model\n",
      "0s - loss: 0.0989 - acc: 0.9627 - val_loss: 0.0551 - val_acc: 0.9844\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.05507 to 0.05285, saving model to best.model\n",
      "0s - loss: 0.1021 - acc: 0.9620 - val_loss: 0.0528 - val_acc: 0.9825\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0980 - acc: 0.9620 - val_loss: 0.0538 - val_acc: 0.9796\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0953 - acc: 0.9657 - val_loss: 0.0540 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05285 to 0.04838, saving model to best.model\n",
      "0s - loss: 0.0934 - acc: 0.9657 - val_loss: 0.0484 - val_acc: 0.9834\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0997 - acc: 0.9642 - val_loss: 0.0500 - val_acc: 0.9834\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04838 to 0.04629, saving model to best.model\n",
      "0s - loss: 0.0890 - acc: 0.9679 - val_loss: 0.0463 - val_acc: 0.9825\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.04629 to 0.04618, saving model to best.model\n",
      "0s - loss: 0.0886 - acc: 0.9649 - val_loss: 0.0462 - val_acc: 0.9834\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04618 to 0.04443, saving model to best.model\n",
      "0s - loss: 0.0890 - acc: 0.9649 - val_loss: 0.0444 - val_acc: 0.9844\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04443 to 0.04321, saving model to best.model\n",
      "0s - loss: 0.0824 - acc: 0.9703 - val_loss: 0.0432 - val_acc: 0.9844\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0894 - acc: 0.9654 - val_loss: 0.0454 - val_acc: 0.9834\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0990 - acc: 0.9586 - val_loss: 0.0475 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04321 to 0.04033, saving model to best.model\n",
      "0s - loss: 0.0970 - acc: 0.9649 - val_loss: 0.0403 - val_acc: 0.9873\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0856 - acc: 0.9696 - val_loss: 0.0406 - val_acc: 0.9864\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04033 to 0.03955, saving model to best.model\n",
      "0s - loss: 0.0824 - acc: 0.9691 - val_loss: 0.0396 - val_acc: 0.9864\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0843 - acc: 0.9669 - val_loss: 0.0404 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03955 to 0.03816, saving model to best.model\n",
      "0s - loss: 0.0838 - acc: 0.9679 - val_loss: 0.0382 - val_acc: 0.9864\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.03816 to 0.03712, saving model to best.model\n",
      "0s - loss: 0.0763 - acc: 0.9710 - val_loss: 0.0371 - val_acc: 0.9864\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0750 - acc: 0.9718 - val_loss: 0.0388 - val_acc: 0.9893\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.03712 to 0.03613, saving model to best.model\n",
      "0s - loss: 0.0787 - acc: 0.9691 - val_loss: 0.0361 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.03613 to 0.03460, saving model to best.model\n",
      "0s - loss: 0.0758 - acc: 0.9725 - val_loss: 0.0346 - val_acc: 0.9912\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.03460 to 0.03390, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9742 - val_loss: 0.0339 - val_acc: 0.9893\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0709 - acc: 0.9742 - val_loss: 0.0349 - val_acc: 0.9864\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03390 to 0.03315, saving model to best.model\n",
      "0s - loss: 0.0700 - acc: 0.9730 - val_loss: 0.0331 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03315 to 0.03295, saving model to best.model\n",
      "0s - loss: 0.0749 - acc: 0.9710 - val_loss: 0.0330 - val_acc: 0.9864\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03295 to 0.03220, saving model to best.model\n",
      "0s - loss: 0.0665 - acc: 0.9747 - val_loss: 0.0322 - val_acc: 0.9903\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0668 - acc: 0.9737 - val_loss: 0.0323 - val_acc: 0.9893\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0670 - acc: 0.9752 - val_loss: 0.0349 - val_acc: 0.9864\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03220 to 0.03124, saving model to best.model\n",
      "0s - loss: 0.0711 - acc: 0.9722 - val_loss: 0.0312 - val_acc: 0.9883\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03124 to 0.03083, saving model to best.model\n",
      "0s - loss: 0.0713 - acc: 0.9737 - val_loss: 0.0308 - val_acc: 0.9903\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03083 to 0.03070, saving model to best.model\n",
      "0s - loss: 0.0667 - acc: 0.9749 - val_loss: 0.0307 - val_acc: 0.9864\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03070 to 0.02930, saving model to best.model\n",
      "0s - loss: 0.0709 - acc: 0.9754 - val_loss: 0.0293 - val_acc: 0.9912\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02930 to 0.02856, saving model to best.model\n",
      "0s - loss: 0.0647 - acc: 0.9732 - val_loss: 0.0286 - val_acc: 0.9912\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.02856 to 0.02799, saving model to best.model\n",
      "0s - loss: 0.0626 - acc: 0.9764 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02799 to 0.02773, saving model to best.model\n",
      "0s - loss: 0.0701 - acc: 0.9718 - val_loss: 0.0277 - val_acc: 0.9932\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0701 - acc: 0.9735 - val_loss: 0.0279 - val_acc: 0.9893\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02773 to 0.02670, saving model to best.model\n",
      "0s - loss: 0.0649 - acc: 0.9771 - val_loss: 0.0267 - val_acc: 0.9922\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9803 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02670 to 0.02621, saving model to best.model\n",
      "0s - loss: 0.0670 - acc: 0.9778 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02621 to 0.02599, saving model to best.model\n",
      "0s - loss: 0.0630 - acc: 0.9744 - val_loss: 0.0260 - val_acc: 0.9922\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02599 to 0.02593, saving model to best.model\n",
      "0s - loss: 0.0581 - acc: 0.9781 - val_loss: 0.0259 - val_acc: 0.9932\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02593 to 0.02465, saving model to best.model\n",
      "0s - loss: 0.0592 - acc: 0.9791 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0654 - acc: 0.9752 - val_loss: 0.0268 - val_acc: 0.9912\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0555 - acc: 0.9795 - val_loss: 0.0263 - val_acc: 0.9903\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0592 - acc: 0.9769 - val_loss: 0.0251 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02465 to 0.02425, saving model to best.model\n",
      "0s - loss: 0.0577 - acc: 0.9776 - val_loss: 0.0243 - val_acc: 0.9912\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02425 to 0.02378, saving model to best.model\n",
      "0s - loss: 0.0499 - acc: 0.9800 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02378 to 0.02346, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9803 - val_loss: 0.0235 - val_acc: 0.9932\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02346 to 0.02250, saving model to best.model\n",
      "0s - loss: 0.0490 - acc: 0.9810 - val_loss: 0.0225 - val_acc: 0.9942\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9781 - val_loss: 0.0233 - val_acc: 0.9893\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02250 to 0.02240, saving model to best.model\n",
      "0s - loss: 0.0566 - acc: 0.9795 - val_loss: 0.0224 - val_acc: 0.9932\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0665 - acc: 0.9747 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02240 to 0.01993, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9805 - val_loss: 0.0199 - val_acc: 0.9912\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0528 - acc: 0.9798 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0591 - acc: 0.9759 - val_loss: 0.0227 - val_acc: 0.9903\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9805 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0568 - acc: 0.9747 - val_loss: 0.0242 - val_acc: 0.9903\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0473 - acc: 0.9827 - val_loss: 0.0227 - val_acc: 0.9942\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0538 - acc: 0.9810 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9800 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0488 - acc: 0.9830 - val_loss: 0.0207 - val_acc: 0.9932\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0536 - acc: 0.9795 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01993 to 0.01940, saving model to best.model\n",
      "0s - loss: 0.0481 - acc: 0.9839 - val_loss: 0.0194 - val_acc: 0.9942\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01940 to 0.01833, saving model to best.model\n",
      "0s - loss: 0.0490 - acc: 0.9813 - val_loss: 0.0183 - val_acc: 0.9942\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01833 to 0.01811, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9844 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9822 - val_loss: 0.0186 - val_acc: 0.9942\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9837 - val_loss: 0.0184 - val_acc: 0.9942\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01811 to 0.01770, saving model to best.model\n",
      "0s - loss: 0.0491 - acc: 0.9813 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9817 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01770 to 0.01653, saving model to best.model\n",
      "0s - loss: 0.0419 - acc: 0.9837 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0515 - acc: 0.9795 - val_loss: 0.0170 - val_acc: 0.9922\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01653 to 0.01629, saving model to best.model\n",
      "0s - loss: 0.0450 - acc: 0.9839 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01629 to 0.01599, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9842 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01599 to 0.01574, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9817 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9825 - val_loss: 0.0166 - val_acc: 0.9932\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9827 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01574 to 0.01295, saving model to best.model\n",
      "0s - loss: 0.0437 - acc: 0.9837 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9861 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9849 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9827 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9834 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9830 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9873 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01295 to 0.01243, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9854 - val_loss: 0.0124 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01243 to 0.01231, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9861 - val_loss: 0.0123 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9844 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01231 to 0.01218, saving model to best.model\n",
      "0s - loss: 0.0389 - acc: 0.9851 - val_loss: 0.0122 - val_acc: 0.9951\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0465 - acc: 0.9825 - val_loss: 0.0137 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9815 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9834 - val_loss: 0.0123 - val_acc: 0.9942\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9842 - val_loss: 0.0124 - val_acc: 0.9942\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9842 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9876 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.01218 to 0.01187, saving model to best.model\n",
      "0s - loss: 0.0375 - acc: 0.9873 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9849 - val_loss: 0.0121 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01187 to 0.01184, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01184 to 0.01132, saving model to best.model\n",
      "0s - loss: 0.0374 - acc: 0.9847 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9859 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9856 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01132 to 0.01122, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9856 - val_loss: 0.0112 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01122 to 0.01080, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9883 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01080 to 0.01004, saving model to best.model\n",
      "0s - loss: 0.0324 - acc: 0.9881 - val_loss: 0.0100 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01004 to 0.00980, saving model to best.model\n",
      "0s - loss: 0.0340 - acc: 0.9861 - val_loss: 0.0098 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9873 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9873 - val_loss: 0.0102 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.00980 to 0.00953, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9869 - val_loss: 0.0095 - val_acc: 0.9961\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9856 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9876 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9876 - val_loss: 0.0104 - val_acc: 0.9961\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9883 - val_loss: 0.0102 - val_acc: 0.9961\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.00953 to 0.00941, saving model to best.model\n",
      "0s - loss: 0.0309 - acc: 0.9883 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00941 to 0.00884, saving model to best.model\n",
      "0s - loss: 0.0323 - acc: 0.9893 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.00884 to 0.00857, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9883 - val_loss: 0.0086 - val_acc: 0.9981\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00857 to 0.00849, saving model to best.model\n",
      "0s - loss: 0.0334 - acc: 0.9869 - val_loss: 0.0085 - val_acc: 0.9981\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9876 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9910 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9893 - val_loss: 0.0085 - val_acc: 0.9961\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00849 to 0.00842, saving model to best.model\n",
      "0s - loss: 0.0242 - acc: 0.9912 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00842 to 0.00826, saving model to best.model\n",
      "0s - loss: 0.0281 - acc: 0.9905 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9888 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.00826 to 0.00815, saving model to best.model\n",
      "0s - loss: 0.0284 - acc: 0.9890 - val_loss: 0.0081 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.00815 to 0.00802, saving model to best.model\n",
      "0s - loss: 0.0318 - acc: 0.9895 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9878 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9910 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66719, saving model to best.model\n",
      "0s - loss: 0.7862 - acc: 0.5086 - val_loss: 0.6672 - val_acc: 0.7176\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66719 to 0.64012, saving model to best.model\n",
      "0s - loss: 0.7347 - acc: 0.5313 - val_loss: 0.6401 - val_acc: 0.7537\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64012 to 0.59509, saving model to best.model\n",
      "0s - loss: 0.6889 - acc: 0.5810 - val_loss: 0.5951 - val_acc: 0.7673\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59509 to 0.51449, saving model to best.model\n",
      "0s - loss: 0.6168 - acc: 0.6596 - val_loss: 0.5145 - val_acc: 0.8228\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51449 to 0.43965, saving model to best.model\n",
      "0s - loss: 0.5436 - acc: 0.7314 - val_loss: 0.4396 - val_acc: 0.8462\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.43965 to 0.38346, saving model to best.model\n",
      "0s - loss: 0.4953 - acc: 0.7770 - val_loss: 0.3835 - val_acc: 0.8491\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.38346 to 0.35568, saving model to best.model\n",
      "0s - loss: 0.4522 - acc: 0.8020 - val_loss: 0.3557 - val_acc: 0.8656\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35568 to 0.33219, saving model to best.model\n",
      "0s - loss: 0.4259 - acc: 0.8232 - val_loss: 0.3322 - val_acc: 0.8763\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33219 to 0.31194, saving model to best.model\n",
      "0s - loss: 0.4118 - acc: 0.8305 - val_loss: 0.3119 - val_acc: 0.8812\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31194 to 0.29663, saving model to best.model\n",
      "0s - loss: 0.3844 - acc: 0.8447 - val_loss: 0.2966 - val_acc: 0.8812\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29663 to 0.28302, saving model to best.model\n",
      "0s - loss: 0.3736 - acc: 0.8534 - val_loss: 0.2830 - val_acc: 0.8822\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28302 to 0.27374, saving model to best.model\n",
      "0s - loss: 0.3522 - acc: 0.8602 - val_loss: 0.2737 - val_acc: 0.8851\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27374 to 0.26654, saving model to best.model\n",
      "0s - loss: 0.3405 - acc: 0.8666 - val_loss: 0.2665 - val_acc: 0.8929\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26654 to 0.25511, saving model to best.model\n",
      "0s - loss: 0.3294 - acc: 0.8673 - val_loss: 0.2551 - val_acc: 0.8909\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25511 to 0.25007, saving model to best.model\n",
      "0s - loss: 0.3155 - acc: 0.8758 - val_loss: 0.2501 - val_acc: 0.8909\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25007 to 0.24283, saving model to best.model\n",
      "0s - loss: 0.3129 - acc: 0.8783 - val_loss: 0.2428 - val_acc: 0.9056\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24283 to 0.23639, saving model to best.model\n",
      "0s - loss: 0.3052 - acc: 0.8804 - val_loss: 0.2364 - val_acc: 0.9056\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.23639 to 0.23029, saving model to best.model\n",
      "0s - loss: 0.3013 - acc: 0.8814 - val_loss: 0.2303 - val_acc: 0.9075\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23029 to 0.22609, saving model to best.model\n",
      "0s - loss: 0.2920 - acc: 0.8887 - val_loss: 0.2261 - val_acc: 0.9094\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22609 to 0.22176, saving model to best.model\n",
      "0s - loss: 0.2845 - acc: 0.8977 - val_loss: 0.2218 - val_acc: 0.9124\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22176 to 0.21614, saving model to best.model\n",
      "0s - loss: 0.2812 - acc: 0.8960 - val_loss: 0.2161 - val_acc: 0.9124\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21614 to 0.21477, saving model to best.model\n",
      "0s - loss: 0.2719 - acc: 0.8965 - val_loss: 0.2148 - val_acc: 0.9153\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21477 to 0.20906, saving model to best.model\n",
      "0s - loss: 0.2656 - acc: 0.9036 - val_loss: 0.2091 - val_acc: 0.9241\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20906 to 0.20419, saving model to best.model\n",
      "0s - loss: 0.2653 - acc: 0.8999 - val_loss: 0.2042 - val_acc: 0.9211\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20419 to 0.20249, saving model to best.model\n",
      "0s - loss: 0.2579 - acc: 0.9055 - val_loss: 0.2025 - val_acc: 0.9202\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20249 to 0.19739, saving model to best.model\n",
      "0s - loss: 0.2487 - acc: 0.9077 - val_loss: 0.1974 - val_acc: 0.9250\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19739 to 0.19534, saving model to best.model\n",
      "0s - loss: 0.2471 - acc: 0.9092 - val_loss: 0.1953 - val_acc: 0.9270\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19534 to 0.19287, saving model to best.model\n",
      "0s - loss: 0.2489 - acc: 0.9075 - val_loss: 0.1929 - val_acc: 0.9279\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19287 to 0.18911, saving model to best.model\n",
      "0s - loss: 0.2408 - acc: 0.9111 - val_loss: 0.1891 - val_acc: 0.9270\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18911 to 0.18572, saving model to best.model\n",
      "0s - loss: 0.2352 - acc: 0.9119 - val_loss: 0.1857 - val_acc: 0.9279\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18572 to 0.18256, saving model to best.model\n",
      "0s - loss: 0.2370 - acc: 0.9109 - val_loss: 0.1826 - val_acc: 0.9309\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18256 to 0.17897, saving model to best.model\n",
      "0s - loss: 0.2304 - acc: 0.9150 - val_loss: 0.1790 - val_acc: 0.9289\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17897 to 0.17542, saving model to best.model\n",
      "0s - loss: 0.2231 - acc: 0.9209 - val_loss: 0.1754 - val_acc: 0.9309\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17542 to 0.17312, saving model to best.model\n",
      "0s - loss: 0.2251 - acc: 0.9192 - val_loss: 0.1731 - val_acc: 0.9318\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17312 to 0.17051, saving model to best.model\n",
      "0s - loss: 0.2128 - acc: 0.9226 - val_loss: 0.1705 - val_acc: 0.9377\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2237 - acc: 0.9196 - val_loss: 0.1710 - val_acc: 0.9289\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17051 to 0.16486, saving model to best.model\n",
      "0s - loss: 0.2151 - acc: 0.9255 - val_loss: 0.1649 - val_acc: 0.9435\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16486 to 0.16208, saving model to best.model\n",
      "0s - loss: 0.2103 - acc: 0.9248 - val_loss: 0.1621 - val_acc: 0.9445\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.2018 - acc: 0.9257 - val_loss: 0.1630 - val_acc: 0.9299\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16208 to 0.15661, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9240 - val_loss: 0.1566 - val_acc: 0.9377\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15661 to 0.15389, saving model to best.model\n",
      "0s - loss: 0.1971 - acc: 0.9299 - val_loss: 0.1539 - val_acc: 0.9474\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15389 to 0.15060, saving model to best.model\n",
      "0s - loss: 0.1972 - acc: 0.9289 - val_loss: 0.1506 - val_acc: 0.9377\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15060 to 0.14794, saving model to best.model\n",
      "0s - loss: 0.1937 - acc: 0.9306 - val_loss: 0.1479 - val_acc: 0.9387\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14794 to 0.14529, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9333 - val_loss: 0.1453 - val_acc: 0.9523\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14529 to 0.14110, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9350 - val_loss: 0.1411 - val_acc: 0.9455\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14110 to 0.13781, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9330 - val_loss: 0.1378 - val_acc: 0.9523\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13781 to 0.13722, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9333 - val_loss: 0.1372 - val_acc: 0.9377\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13722 to 0.13077, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9323 - val_loss: 0.1308 - val_acc: 0.9513\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13077 to 0.12923, saving model to best.model\n",
      "0s - loss: 0.1770 - acc: 0.9330 - val_loss: 0.1292 - val_acc: 0.9572\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12923 to 0.12332, saving model to best.model\n",
      "0s - loss: 0.1731 - acc: 0.9340 - val_loss: 0.1233 - val_acc: 0.9572\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1763 - acc: 0.9318 - val_loss: 0.1240 - val_acc: 0.9367\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12332 to 0.11556, saving model to best.model\n",
      "0s - loss: 0.1628 - acc: 0.9403 - val_loss: 0.1156 - val_acc: 0.9552\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11556 to 0.11145, saving model to best.model\n",
      "0s - loss: 0.1544 - acc: 0.9416 - val_loss: 0.1115 - val_acc: 0.9552\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11145 to 0.10823, saving model to best.model\n",
      "0s - loss: 0.1552 - acc: 0.9440 - val_loss: 0.1082 - val_acc: 0.9503\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10823 to 0.10340, saving model to best.model\n",
      "0s - loss: 0.1519 - acc: 0.9457 - val_loss: 0.1034 - val_acc: 0.9601\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.10340 to 0.09926, saving model to best.model\n",
      "0s - loss: 0.1535 - acc: 0.9416 - val_loss: 0.0993 - val_acc: 0.9591\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1458 - acc: 0.9469 - val_loss: 0.1000 - val_acc: 0.9494\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09926 to 0.09318, saving model to best.model\n",
      "0s - loss: 0.1518 - acc: 0.9411 - val_loss: 0.0932 - val_acc: 0.9611\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09318 to 0.08864, saving model to best.model\n",
      "0s - loss: 0.1378 - acc: 0.9486 - val_loss: 0.0886 - val_acc: 0.9601\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.08864 to 0.08497, saving model to best.model\n",
      "0s - loss: 0.1364 - acc: 0.9489 - val_loss: 0.0850 - val_acc: 0.9591\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08497 to 0.08244, saving model to best.model\n",
      "0s - loss: 0.1420 - acc: 0.9469 - val_loss: 0.0824 - val_acc: 0.9620\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08244 to 0.08036, saving model to best.model\n",
      "0s - loss: 0.1326 - acc: 0.9494 - val_loss: 0.0804 - val_acc: 0.9611\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1403 - acc: 0.9474 - val_loss: 0.0830 - val_acc: 0.9659\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08036 to 0.07787, saving model to best.model\n",
      "0s - loss: 0.1321 - acc: 0.9525 - val_loss: 0.0779 - val_acc: 0.9659\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07787 to 0.07374, saving model to best.model\n",
      "0s - loss: 0.1318 - acc: 0.9513 - val_loss: 0.0737 - val_acc: 0.9718\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07374 to 0.07287, saving model to best.model\n",
      "0s - loss: 0.1226 - acc: 0.9540 - val_loss: 0.0729 - val_acc: 0.9679\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07287 to 0.06794, saving model to best.model\n",
      "0s - loss: 0.1169 - acc: 0.9554 - val_loss: 0.0679 - val_acc: 0.9669\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.06794 to 0.06516, saving model to best.model\n",
      "0s - loss: 0.1141 - acc: 0.9569 - val_loss: 0.0652 - val_acc: 0.9698\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1156 - acc: 0.9581 - val_loss: 0.0655 - val_acc: 0.9727\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06516 to 0.06491, saving model to best.model\n",
      "0s - loss: 0.1196 - acc: 0.9533 - val_loss: 0.0649 - val_acc: 0.9708\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06491 to 0.06341, saving model to best.model\n",
      "0s - loss: 0.1154 - acc: 0.9579 - val_loss: 0.0634 - val_acc: 0.9718\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06341 to 0.05955, saving model to best.model\n",
      "0s - loss: 0.1154 - acc: 0.9562 - val_loss: 0.0595 - val_acc: 0.9737\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.05955 to 0.05782, saving model to best.model\n",
      "0s - loss: 0.1124 - acc: 0.9554 - val_loss: 0.0578 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.05782 to 0.05575, saving model to best.model\n",
      "0s - loss: 0.1041 - acc: 0.9613 - val_loss: 0.0557 - val_acc: 0.9737\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.05575 to 0.05339, saving model to best.model\n",
      "0s - loss: 0.1013 - acc: 0.9591 - val_loss: 0.0534 - val_acc: 0.9757\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.05339 to 0.05253, saving model to best.model\n",
      "0s - loss: 0.1007 - acc: 0.9608 - val_loss: 0.0525 - val_acc: 0.9747\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05253 to 0.04860, saving model to best.model\n",
      "0s - loss: 0.0955 - acc: 0.9647 - val_loss: 0.0486 - val_acc: 0.9766\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.04860 to 0.04747, saving model to best.model\n",
      "0s - loss: 0.0916 - acc: 0.9649 - val_loss: 0.0475 - val_acc: 0.9776\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0919 - acc: 0.9640 - val_loss: 0.0484 - val_acc: 0.9815\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.04747 to 0.04393, saving model to best.model\n",
      "0s - loss: 0.1055 - acc: 0.9603 - val_loss: 0.0439 - val_acc: 0.9776\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0910 - acc: 0.9671 - val_loss: 0.0444 - val_acc: 0.9776\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.04393 to 0.04384, saving model to best.model\n",
      "0s - loss: 0.0823 - acc: 0.9683 - val_loss: 0.0438 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04384 to 0.04178, saving model to best.model\n",
      "0s - loss: 0.0913 - acc: 0.9640 - val_loss: 0.0418 - val_acc: 0.9825\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0922 - acc: 0.9625 - val_loss: 0.0454 - val_acc: 0.9834\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04178 to 0.03769, saving model to best.model\n",
      "0s - loss: 0.0933 - acc: 0.9645 - val_loss: 0.0377 - val_acc: 0.9844\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.03769 to 0.03650, saving model to best.model\n",
      "0s - loss: 0.0827 - acc: 0.9659 - val_loss: 0.0365 - val_acc: 0.9844\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0841 - acc: 0.9659 - val_loss: 0.0367 - val_acc: 0.9844\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.03650 to 0.03251, saving model to best.model\n",
      "0s - loss: 0.0746 - acc: 0.9698 - val_loss: 0.0325 - val_acc: 0.9854\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.03251 to 0.03226, saving model to best.model\n",
      "0s - loss: 0.0813 - acc: 0.9696 - val_loss: 0.0323 - val_acc: 0.9883\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03226 to 0.02881, saving model to best.model\n",
      "0s - loss: 0.0765 - acc: 0.9693 - val_loss: 0.0288 - val_acc: 0.9893\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0800 - acc: 0.9688 - val_loss: 0.0326 - val_acc: 0.9864\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0782 - acc: 0.9686 - val_loss: 0.0301 - val_acc: 0.9864\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.02881 to 0.02671, saving model to best.model\n",
      "0s - loss: 0.0795 - acc: 0.9701 - val_loss: 0.0267 - val_acc: 0.9893\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0796 - acc: 0.9710 - val_loss: 0.0306 - val_acc: 0.9873\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0750 - acc: 0.9713 - val_loss: 0.0326 - val_acc: 0.9873\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0740 - acc: 0.9701 - val_loss: 0.0285 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.02671 to 0.02652, saving model to best.model\n",
      "0s - loss: 0.0713 - acc: 0.9703 - val_loss: 0.0265 - val_acc: 0.9893\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0754 - acc: 0.9691 - val_loss: 0.0330 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.02652 to 0.02566, saving model to best.model\n",
      "0s - loss: 0.0748 - acc: 0.9744 - val_loss: 0.0257 - val_acc: 0.9903\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02566 to 0.02418, saving model to best.model\n",
      "0s - loss: 0.0669 - acc: 0.9752 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0698 - acc: 0.9727 - val_loss: 0.0262 - val_acc: 0.9893\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.02418 to 0.02289, saving model to best.model\n",
      "0s - loss: 0.0718 - acc: 0.9720 - val_loss: 0.0229 - val_acc: 0.9903\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.02289 to 0.02264, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9739 - val_loss: 0.0226 - val_acc: 0.9912\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.02264 to 0.02138, saving model to best.model\n",
      "0s - loss: 0.0646 - acc: 0.9774 - val_loss: 0.0214 - val_acc: 0.9932\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0676 - acc: 0.9732 - val_loss: 0.0231 - val_acc: 0.9912\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0605 - acc: 0.9771 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.02138 to 0.01941, saving model to best.model\n",
      "0s - loss: 0.0572 - acc: 0.9771 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0645 - acc: 0.9766 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.01941 to 0.01920, saving model to best.model\n",
      "0s - loss: 0.0652 - acc: 0.9759 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.01920 to 0.01785, saving model to best.model\n",
      "0s - loss: 0.0629 - acc: 0.9752 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9817 - val_loss: 0.0184 - val_acc: 0.9932\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.01785 to 0.01632, saving model to best.model\n",
      "0s - loss: 0.0624 - acc: 0.9749 - val_loss: 0.0163 - val_acc: 0.9981\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0545 - acc: 0.9783 - val_loss: 0.0177 - val_acc: 0.9932\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0601 - acc: 0.9786 - val_loss: 0.0177 - val_acc: 0.9912\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.01632 to 0.01569, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9788 - val_loss: 0.0157 - val_acc: 0.9951\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0590 - acc: 0.9769 - val_loss: 0.0166 - val_acc: 0.9971\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0541 - acc: 0.9808 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.01569 to 0.01427, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9769 - val_loss: 0.0143 - val_acc: 0.9951\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.01427 to 0.01364, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9837 - val_loss: 0.0136 - val_acc: 0.9961\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0537 - acc: 0.9778 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0592 - acc: 0.9766 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.01364 to 0.01319, saving model to best.model\n",
      "0s - loss: 0.0486 - acc: 0.9820 - val_loss: 0.0132 - val_acc: 0.9961\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.01319 to 0.01267, saving model to best.model\n",
      "0s - loss: 0.0590 - acc: 0.9781 - val_loss: 0.0127 - val_acc: 0.9981\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9810 - val_loss: 0.0185 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0539 - acc: 0.9791 - val_loss: 0.0143 - val_acc: 0.9990\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0479 - acc: 0.9820 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.01267 to 0.01261, saving model to best.model\n",
      "0s - loss: 0.0620 - acc: 0.9747 - val_loss: 0.0126 - val_acc: 0.9981\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0425 - acc: 0.9822 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.01261 to 0.01213, saving model to best.model\n",
      "0s - loss: 0.0430 - acc: 0.9842 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.01213 to 0.01130, saving model to best.model\n",
      "0s - loss: 0.0440 - acc: 0.9825 - val_loss: 0.0113 - val_acc: 0.9981\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01130 to 0.00967, saving model to best.model\n",
      "0s - loss: 0.0473 - acc: 0.9803 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9842 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.00967 to 0.00901, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9803 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9834 - val_loss: 0.0093 - val_acc: 0.9981\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9832 - val_loss: 0.0096 - val_acc: 0.9990\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9849 - val_loss: 0.0122 - val_acc: 0.9951\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9832 - val_loss: 0.0110 - val_acc: 0.9981\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9820 - val_loss: 0.0116 - val_acc: 0.9981\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0487 - acc: 0.9832 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9844 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.00901 to 0.00885, saving model to best.model\n",
      "0s - loss: 0.0425 - acc: 0.9834 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.00885 to 0.00851, saving model to best.model\n",
      "0s - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9869 - val_loss: 0.0085 - val_acc: 0.9981\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9851 - val_loss: 0.0090 - val_acc: 0.9981\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.00851 to 0.00769, saving model to best.model\n",
      "0s - loss: 0.0450 - acc: 0.9832 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9886 - val_loss: 0.0077 - val_acc: 0.9990\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9842 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9851 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9849 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.00769 to 0.00760, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9847 - val_loss: 0.0076 - val_acc: 0.9990\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0419 - acc: 0.9837 - val_loss: 0.0084 - val_acc: 0.9981\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9854 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0434 - acc: 0.9820 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0370 - acc: 0.9847 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9851 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.00760 to 0.00734, saving model to best.model\n",
      "0s - loss: 0.0317 - acc: 0.9881 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.00734 to 0.00715, saving model to best.model\n",
      "0s - loss: 0.0306 - acc: 0.9878 - val_loss: 0.0071 - val_acc: 0.9981\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.00715 to 0.00624, saving model to best.model\n",
      "0s - loss: 0.0350 - acc: 0.9856 - val_loss: 0.0062 - val_acc: 0.9990\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.00624 to 0.00608, saving model to best.model\n",
      "0s - loss: 0.0330 - acc: 0.9876 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9890 - val_loss: 0.0063 - val_acc: 0.9981\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9861 - val_loss: 0.0064 - val_acc: 0.9990\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.00608 to 0.00588, saving model to best.model\n",
      "0s - loss: 0.0384 - acc: 0.9854 - val_loss: 0.0059 - val_acc: 0.9990\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9888 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9878 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.00588 to 0.00525, saving model to best.model\n",
      "0s - loss: 0.0340 - acc: 0.9864 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9883 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9873 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9866 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9903 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9888 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9866 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9856 - val_loss: 0.0070 - val_acc: 0.9990\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9881 - val_loss: 0.0072 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9878 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9878 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9873 - val_loss: 0.0065 - val_acc: 0.9990\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9876 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9905 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9864 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.00525 to 0.00470, saving model to best.model\n",
      "0s - loss: 0.0247 - acc: 0.9890 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.00470 to 0.00459, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9864 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9873 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.00459 to 0.00442, saving model to best.model\n",
      "0s - loss: 0.0292 - acc: 0.9883 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9910 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00442 to 0.00440, saving model to best.model\n",
      "0s - loss: 0.0222 - acc: 0.9915 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.00440 to 0.00370, saving model to best.model\n",
      "0s - loss: 0.0235 - acc: 0.9907 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.00370 to 0.00368, saving model to best.model\n",
      "0s - loss: 0.0253 - acc: 0.9912 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9839 - val_loss: 0.0061 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9883 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9876 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0252 - acc: 0.9910 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9871 - val_loss: 0.0052 - val_acc: 0.9990\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0227 - acc: 0.9920 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9903 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00368 to 0.00367, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9893 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0222 - acc: 0.9907 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9888 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9915 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.00367 to 0.00362, saving model to best.model\n",
      "0s - loss: 0.0234 - acc: 0.9903 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0214 - acc: 0.9910 - val_loss: 0.0037 - val_acc: 0.9990\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66821, saving model to best.model\n",
      "0s - loss: 0.7722 - acc: 0.5271 - val_loss: 0.6682 - val_acc: 0.7235\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66821 to 0.64072, saving model to best.model\n",
      "0s - loss: 0.7284 - acc: 0.5301 - val_loss: 0.6407 - val_acc: 0.7283\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64072 to 0.59919, saving model to best.model\n",
      "0s - loss: 0.6773 - acc: 0.5878 - val_loss: 0.5992 - val_acc: 0.7274\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59919 to 0.52910, saving model to best.model\n",
      "0s - loss: 0.6055 - acc: 0.6710 - val_loss: 0.5291 - val_acc: 0.7712\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52910 to 0.45645, saving model to best.model\n",
      "0s - loss: 0.5254 - acc: 0.7514 - val_loss: 0.4565 - val_acc: 0.7945\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.45645 to 0.40806, saving model to best.model\n",
      "0s - loss: 0.4608 - acc: 0.8001 - val_loss: 0.4081 - val_acc: 0.8169\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40806 to 0.37347, saving model to best.model\n",
      "0s - loss: 0.4240 - acc: 0.8257 - val_loss: 0.3735 - val_acc: 0.8510\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37347 to 0.34389, saving model to best.model\n",
      "0s - loss: 0.3921 - acc: 0.8461 - val_loss: 0.3439 - val_acc: 0.8598\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34389 to 0.32375, saving model to best.model\n",
      "0s - loss: 0.3720 - acc: 0.8602 - val_loss: 0.3237 - val_acc: 0.8685\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32375 to 0.30683, saving model to best.model\n",
      "0s - loss: 0.3408 - acc: 0.8685 - val_loss: 0.3068 - val_acc: 0.8763\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.3170 - acc: 0.8790 - val_loss: 0.3192 - val_acc: 0.8832\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30683 to 0.28988, saving model to best.model\n",
      "0s - loss: 0.3189 - acc: 0.8778 - val_loss: 0.2899 - val_acc: 0.8861\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28988 to 0.27404, saving model to best.model\n",
      "0s - loss: 0.3148 - acc: 0.8853 - val_loss: 0.2740 - val_acc: 0.8890\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27404 to 0.26393, saving model to best.model\n",
      "0s - loss: 0.2946 - acc: 0.8916 - val_loss: 0.2639 - val_acc: 0.8958\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26393 to 0.26162, saving model to best.model\n",
      "0s - loss: 0.2864 - acc: 0.8912 - val_loss: 0.2616 - val_acc: 0.9007\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26162 to 0.25106, saving model to best.model\n",
      "0s - loss: 0.2769 - acc: 0.9026 - val_loss: 0.2511 - val_acc: 0.9036\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.2718 - acc: 0.9031 - val_loss: 0.2629 - val_acc: 0.9007\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25106 to 0.24142, saving model to best.model\n",
      "0s - loss: 0.2654 - acc: 0.9087 - val_loss: 0.2414 - val_acc: 0.9085\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.2662 - acc: 0.9021 - val_loss: 0.2653 - val_acc: 0.8968\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24142 to 0.23677, saving model to best.model\n",
      "0s - loss: 0.2637 - acc: 0.9094 - val_loss: 0.2368 - val_acc: 0.9094\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23677 to 0.23354, saving model to best.model\n",
      "0s - loss: 0.2598 - acc: 0.9099 - val_loss: 0.2335 - val_acc: 0.9114\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2479 - acc: 0.9111 - val_loss: 0.2411 - val_acc: 0.9075\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23354 to 0.22565, saving model to best.model\n",
      "0s - loss: 0.2432 - acc: 0.9177 - val_loss: 0.2257 - val_acc: 0.9133\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22565 to 0.22456, saving model to best.model\n",
      "0s - loss: 0.2306 - acc: 0.9170 - val_loss: 0.2246 - val_acc: 0.9094\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22456 to 0.21953, saving model to best.model\n",
      "0s - loss: 0.2235 - acc: 0.9231 - val_loss: 0.2195 - val_acc: 0.9124\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2297 - acc: 0.9189 - val_loss: 0.2209 - val_acc: 0.9104\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21953 to 0.20774, saving model to best.model\n",
      "0s - loss: 0.2313 - acc: 0.9209 - val_loss: 0.2077 - val_acc: 0.9143\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2260 - acc: 0.9221 - val_loss: 0.2140 - val_acc: 0.9104\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20774 to 0.20199, saving model to best.model\n",
      "0s - loss: 0.2174 - acc: 0.9209 - val_loss: 0.2020 - val_acc: 0.9163\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20199 to 0.19879, saving model to best.model\n",
      "0s - loss: 0.2248 - acc: 0.9189 - val_loss: 0.1988 - val_acc: 0.9153\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2143 - acc: 0.9257 - val_loss: 0.2145 - val_acc: 0.9075\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19879 to 0.18927, saving model to best.model\n",
      "0s - loss: 0.2202 - acc: 0.9240 - val_loss: 0.1893 - val_acc: 0.9241\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2012 - acc: 0.9289 - val_loss: 0.1925 - val_acc: 0.9182\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18927 to 0.18815, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9311 - val_loss: 0.1881 - val_acc: 0.9211\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18815 to 0.18128, saving model to best.model\n",
      "0s - loss: 0.2019 - acc: 0.9272 - val_loss: 0.1813 - val_acc: 0.9289\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18128 to 0.17813, saving model to best.model\n",
      "0s - loss: 0.2019 - acc: 0.9279 - val_loss: 0.1781 - val_acc: 0.9299\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1989 - acc: 0.9313 - val_loss: 0.1985 - val_acc: 0.9163\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17813 to 0.17170, saving model to best.model\n",
      "0s - loss: 0.1940 - acc: 0.9306 - val_loss: 0.1717 - val_acc: 0.9338\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1897 - acc: 0.9306 - val_loss: 0.1773 - val_acc: 0.9260\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1858 - acc: 0.9345 - val_loss: 0.1752 - val_acc: 0.9270\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17170 to 0.16756, saving model to best.model\n",
      "0s - loss: 0.1988 - acc: 0.9289 - val_loss: 0.1676 - val_acc: 0.9513\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1884 - acc: 0.9362 - val_loss: 0.1830 - val_acc: 0.9192\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1816 - acc: 0.9391 - val_loss: 0.1708 - val_acc: 0.9260\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16756 to 0.16107, saving model to best.model\n",
      "0s - loss: 0.1816 - acc: 0.9403 - val_loss: 0.1611 - val_acc: 0.9406\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1795 - acc: 0.9377 - val_loss: 0.1611 - val_acc: 0.9357\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.16107 to 0.15586, saving model to best.model\n",
      "0s - loss: 0.1693 - acc: 0.9425 - val_loss: 0.1559 - val_acc: 0.9455\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15586 to 0.15182, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9430 - val_loss: 0.1518 - val_acc: 0.9503\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1687 - acc: 0.9442 - val_loss: 0.1591 - val_acc: 0.9338\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15182 to 0.14850, saving model to best.model\n",
      "0s - loss: 0.1673 - acc: 0.9438 - val_loss: 0.1485 - val_acc: 0.9503\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14850 to 0.14528, saving model to best.model\n",
      "0s - loss: 0.1583 - acc: 0.9513 - val_loss: 0.1453 - val_acc: 0.9572\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1648 - acc: 0.9435 - val_loss: 0.1536 - val_acc: 0.9396\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.14528 to 0.14312, saving model to best.model\n",
      "0s - loss: 0.1621 - acc: 0.9438 - val_loss: 0.1431 - val_acc: 0.9562\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14312 to 0.14045, saving model to best.model\n",
      "0s - loss: 0.1672 - acc: 0.9425 - val_loss: 0.1404 - val_acc: 0.9581\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.14045 to 0.13908, saving model to best.model\n",
      "0s - loss: 0.1593 - acc: 0.9464 - val_loss: 0.1391 - val_acc: 0.9620\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1561 - acc: 0.9479 - val_loss: 0.1408 - val_acc: 0.9523\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1599 - acc: 0.9472 - val_loss: 0.1424 - val_acc: 0.9484\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.13908 to 0.13456, saving model to best.model\n",
      "0s - loss: 0.1544 - acc: 0.9508 - val_loss: 0.1346 - val_acc: 0.9620\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.13456 to 0.13429, saving model to best.model\n",
      "0s - loss: 0.1499 - acc: 0.9501 - val_loss: 0.1343 - val_acc: 0.9591\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1498 - acc: 0.9525 - val_loss: 0.1377 - val_acc: 0.9533\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.13429 to 0.12842, saving model to best.model\n",
      "0s - loss: 0.1423 - acc: 0.9547 - val_loss: 0.1284 - val_acc: 0.9640\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1452 - acc: 0.9528 - val_loss: 0.1316 - val_acc: 0.9591\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.12842 to 0.12562, saving model to best.model\n",
      "0s - loss: 0.1396 - acc: 0.9528 - val_loss: 0.1256 - val_acc: 0.9640\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.12562 to 0.12550, saving model to best.model\n",
      "0s - loss: 0.1365 - acc: 0.9557 - val_loss: 0.1255 - val_acc: 0.9630\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.12550 to 0.12160, saving model to best.model\n",
      "0s - loss: 0.1385 - acc: 0.9554 - val_loss: 0.1216 - val_acc: 0.9640\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1308 - acc: 0.9550 - val_loss: 0.1230 - val_acc: 0.9659\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.12160 to 0.11945, saving model to best.model\n",
      "0s - loss: 0.1327 - acc: 0.9589 - val_loss: 0.1195 - val_acc: 0.9659\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.11945 to 0.11566, saving model to best.model\n",
      "0s - loss: 0.1280 - acc: 0.9586 - val_loss: 0.1157 - val_acc: 0.9649\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.11566 to 0.11461, saving model to best.model\n",
      "0s - loss: 0.1285 - acc: 0.9547 - val_loss: 0.1146 - val_acc: 0.9640\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1346 - acc: 0.9550 - val_loss: 0.1190 - val_acc: 0.9698\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.11461 to 0.11058, saving model to best.model\n",
      "0s - loss: 0.1263 - acc: 0.9569 - val_loss: 0.1106 - val_acc: 0.9659\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1186 - acc: 0.9606 - val_loss: 0.1113 - val_acc: 0.9679\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.11058 to 0.10595, saving model to best.model\n",
      "0s - loss: 0.1212 - acc: 0.9620 - val_loss: 0.1059 - val_acc: 0.9649\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1183 - acc: 0.9579 - val_loss: 0.1085 - val_acc: 0.9718\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.10595 to 0.10379, saving model to best.model\n",
      "0s - loss: 0.1177 - acc: 0.9608 - val_loss: 0.1038 - val_acc: 0.9727\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.10379 to 0.10075, saving model to best.model\n",
      "0s - loss: 0.1156 - acc: 0.9601 - val_loss: 0.1008 - val_acc: 0.9679\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1148 - acc: 0.9620 - val_loss: 0.1012 - val_acc: 0.9718\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1111 - acc: 0.9645 - val_loss: 0.1026 - val_acc: 0.9708\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.10075 to 0.09735, saving model to best.model\n",
      "0s - loss: 0.1154 - acc: 0.9593 - val_loss: 0.0973 - val_acc: 0.9688\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1176 - acc: 0.9579 - val_loss: 0.1016 - val_acc: 0.9708\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1154 - acc: 0.9623 - val_loss: 0.0978 - val_acc: 0.9727\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.09735 to 0.09084, saving model to best.model\n",
      "0s - loss: 0.1036 - acc: 0.9679 - val_loss: 0.0908 - val_acc: 0.9688\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.09084 to 0.09026, saving model to best.model\n",
      "0s - loss: 0.1111 - acc: 0.9642 - val_loss: 0.0903 - val_acc: 0.9727\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.09026 to 0.09018, saving model to best.model\n",
      "0s - loss: 0.1028 - acc: 0.9657 - val_loss: 0.0902 - val_acc: 0.9737\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0999 - acc: 0.9691 - val_loss: 0.0903 - val_acc: 0.9737\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.09018 to 0.08679, saving model to best.model\n",
      "0s - loss: 0.0992 - acc: 0.9676 - val_loss: 0.0868 - val_acc: 0.9737\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0965 - acc: 0.9698 - val_loss: 0.0886 - val_acc: 0.9737\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.08679 to 0.08568, saving model to best.model\n",
      "0s - loss: 0.0984 - acc: 0.9679 - val_loss: 0.0857 - val_acc: 0.9766\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.08568 to 0.08247, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9681 - val_loss: 0.0825 - val_acc: 0.9776\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0977 - acc: 0.9686 - val_loss: 0.0846 - val_acc: 0.9747\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.08247 to 0.08153, saving model to best.model\n",
      "0s - loss: 0.0917 - acc: 0.9715 - val_loss: 0.0815 - val_acc: 0.9757\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.08153 to 0.08018, saving model to best.model\n",
      "0s - loss: 0.0926 - acc: 0.9683 - val_loss: 0.0802 - val_acc: 0.9776\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.08018 to 0.07983, saving model to best.model\n",
      "0s - loss: 0.0902 - acc: 0.9669 - val_loss: 0.0798 - val_acc: 0.9776\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0850 - acc: 0.9722 - val_loss: 0.0806 - val_acc: 0.9757\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.07983 to 0.07634, saving model to best.model\n",
      "0s - loss: 0.0887 - acc: 0.9693 - val_loss: 0.0763 - val_acc: 0.9776\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0815 - acc: 0.9749 - val_loss: 0.0776 - val_acc: 0.9766\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.07634 to 0.07514, saving model to best.model\n",
      "0s - loss: 0.0852 - acc: 0.9722 - val_loss: 0.0751 - val_acc: 0.9776\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0801 - acc: 0.9744 - val_loss: 0.0785 - val_acc: 0.9757\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.07514 to 0.07262, saving model to best.model\n",
      "0s - loss: 0.0845 - acc: 0.9708 - val_loss: 0.0726 - val_acc: 0.9776\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0834 - acc: 0.9730 - val_loss: 0.0737 - val_acc: 0.9776\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.07262 to 0.06868, saving model to best.model\n",
      "0s - loss: 0.0888 - acc: 0.9713 - val_loss: 0.0687 - val_acc: 0.9776\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.06868 to 0.06788, saving model to best.model\n",
      "0s - loss: 0.0827 - acc: 0.9720 - val_loss: 0.0679 - val_acc: 0.9776\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0824 - acc: 0.9730 - val_loss: 0.0696 - val_acc: 0.9776\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.06788 to 0.06646, saving model to best.model\n",
      "0s - loss: 0.0767 - acc: 0.9742 - val_loss: 0.0665 - val_acc: 0.9776\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.06646 to 0.06503, saving model to best.model\n",
      "0s - loss: 0.0785 - acc: 0.9749 - val_loss: 0.0650 - val_acc: 0.9776\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.06503 to 0.06476, saving model to best.model\n",
      "0s - loss: 0.0772 - acc: 0.9754 - val_loss: 0.0648 - val_acc: 0.9805\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.06476 to 0.06351, saving model to best.model\n",
      "0s - loss: 0.0758 - acc: 0.9735 - val_loss: 0.0635 - val_acc: 0.9786\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0722 - acc: 0.9786 - val_loss: 0.0679 - val_acc: 0.9805\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.06351 to 0.06093, saving model to best.model\n",
      "0s - loss: 0.0780 - acc: 0.9752 - val_loss: 0.0609 - val_acc: 0.9786\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.06093 to 0.06009, saving model to best.model\n",
      "0s - loss: 0.0693 - acc: 0.9749 - val_loss: 0.0601 - val_acc: 0.9786\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9798 - val_loss: 0.0620 - val_acc: 0.9805\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.06009 to 0.05864, saving model to best.model\n",
      "0s - loss: 0.0741 - acc: 0.9752 - val_loss: 0.0586 - val_acc: 0.9786\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.05864 to 0.05807, saving model to best.model\n",
      "0s - loss: 0.0765 - acc: 0.9727 - val_loss: 0.0581 - val_acc: 0.9825\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.05807 to 0.05749, saving model to best.model\n",
      "0s - loss: 0.0638 - acc: 0.9793 - val_loss: 0.0575 - val_acc: 0.9825\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.05749 to 0.05687, saving model to best.model\n",
      "0s - loss: 0.0645 - acc: 0.9781 - val_loss: 0.0569 - val_acc: 0.9815\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.05687 to 0.05653, saving model to best.model\n",
      "0s - loss: 0.0645 - acc: 0.9783 - val_loss: 0.0565 - val_acc: 0.9825\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.05653 to 0.05144, saving model to best.model\n",
      "0s - loss: 0.0687 - acc: 0.9774 - val_loss: 0.0514 - val_acc: 0.9825\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.05144 to 0.04993, saving model to best.model\n",
      "0s - loss: 0.0632 - acc: 0.9791 - val_loss: 0.0499 - val_acc: 0.9825\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.04993 to 0.04909, saving model to best.model\n",
      "0s - loss: 0.0664 - acc: 0.9766 - val_loss: 0.0491 - val_acc: 0.9825\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9820 - val_loss: 0.0502 - val_acc: 0.9825\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.04909 to 0.04609, saving model to best.model\n",
      "0s - loss: 0.0541 - acc: 0.9822 - val_loss: 0.0461 - val_acc: 0.9825\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0590 - acc: 0.9795 - val_loss: 0.0467 - val_acc: 0.9825\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0634 - acc: 0.9783 - val_loss: 0.0466 - val_acc: 0.9825\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.04609 to 0.04514, saving model to best.model\n",
      "0s - loss: 0.0556 - acc: 0.9820 - val_loss: 0.0451 - val_acc: 0.9825\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9776 - val_loss: 0.0453 - val_acc: 0.9825\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.04514 to 0.04319, saving model to best.model\n",
      "0s - loss: 0.0548 - acc: 0.9805 - val_loss: 0.0432 - val_acc: 0.9825\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.04319 to 0.04213, saving model to best.model\n",
      "0s - loss: 0.0606 - acc: 0.9788 - val_loss: 0.0421 - val_acc: 0.9834\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0570 - acc: 0.9813 - val_loss: 0.0436 - val_acc: 0.9834\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.04213 to 0.04066, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9805 - val_loss: 0.0407 - val_acc: 0.9825\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0601 - acc: 0.9783 - val_loss: 0.0414 - val_acc: 0.9834\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.04066 to 0.04062, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9820 - val_loss: 0.0406 - val_acc: 0.9796\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.04062 to 0.03787, saving model to best.model\n",
      "0s - loss: 0.0537 - acc: 0.9798 - val_loss: 0.0379 - val_acc: 0.9805\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0562 - acc: 0.9761 - val_loss: 0.0419 - val_acc: 0.9864\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.03787 to 0.03560, saving model to best.model\n",
      "0s - loss: 0.0438 - acc: 0.9851 - val_loss: 0.0356 - val_acc: 0.9825\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9793 - val_loss: 0.0398 - val_acc: 0.9844\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0595 - acc: 0.9798 - val_loss: 0.0370 - val_acc: 0.9854\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.03560 to 0.03482, saving model to best.model\n",
      "0s - loss: 0.0467 - acc: 0.9837 - val_loss: 0.0348 - val_acc: 0.9844\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.03482 to 0.03393, saving model to best.model\n",
      "0s - loss: 0.0562 - acc: 0.9815 - val_loss: 0.0339 - val_acc: 0.9854\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.03393 to 0.03290, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9786 - val_loss: 0.0329 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.03290 to 0.03147, saving model to best.model\n",
      "0s - loss: 0.0405 - acc: 0.9839 - val_loss: 0.0315 - val_acc: 0.9864\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9839 - val_loss: 0.0351 - val_acc: 0.9864\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.03147 to 0.03018, saving model to best.model\n",
      "0s - loss: 0.0459 - acc: 0.9854 - val_loss: 0.0302 - val_acc: 0.9864\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9827 - val_loss: 0.0369 - val_acc: 0.9873\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.03018 to 0.03011, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9827 - val_loss: 0.0301 - val_acc: 0.9834\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0471 - acc: 0.9810 - val_loss: 0.0311 - val_acc: 0.9883\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.03011 to 0.02893, saving model to best.model\n",
      "0s - loss: 0.0439 - acc: 0.9832 - val_loss: 0.0289 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9851 - val_loss: 0.0292 - val_acc: 0.9883\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.02893 to 0.02818, saving model to best.model\n",
      "0s - loss: 0.0400 - acc: 0.9859 - val_loss: 0.0282 - val_acc: 0.9854\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02818 to 0.02697, saving model to best.model\n",
      "0s - loss: 0.0385 - acc: 0.9851 - val_loss: 0.0270 - val_acc: 0.9864\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0435 - acc: 0.9832 - val_loss: 0.0280 - val_acc: 0.9864\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9859 - val_loss: 0.0286 - val_acc: 0.9854\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.02697 to 0.02623, saving model to best.model\n",
      "0s - loss: 0.0457 - acc: 0.9820 - val_loss: 0.0262 - val_acc: 0.9864\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0435 - acc: 0.9834 - val_loss: 0.0278 - val_acc: 0.9883\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9827 - val_loss: 0.0263 - val_acc: 0.9864\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02623 to 0.02428, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9849 - val_loss: 0.0243 - val_acc: 0.9873\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9854 - val_loss: 0.0249 - val_acc: 0.9873\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9859 - val_loss: 0.0246 - val_acc: 0.9864\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.02428 to 0.02418, saving model to best.model\n",
      "0s - loss: 0.0362 - acc: 0.9886 - val_loss: 0.0242 - val_acc: 0.9864\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9871 - val_loss: 0.0245 - val_acc: 0.9864\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.02418 to 0.02371, saving model to best.model\n",
      "0s - loss: 0.0373 - acc: 0.9866 - val_loss: 0.0237 - val_acc: 0.9883\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.02371 to 0.02185, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9847 - val_loss: 0.0218 - val_acc: 0.9864\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9837 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0234 - val_acc: 0.9873\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9869 - val_loss: 0.0220 - val_acc: 0.9873\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.02185 to 0.01995, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9861 - val_loss: 0.0200 - val_acc: 0.9903\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9842 - val_loss: 0.0209 - val_acc: 0.9893\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01995 to 0.01941, saving model to best.model\n",
      "0s - loss: 0.0326 - acc: 0.9888 - val_loss: 0.0194 - val_acc: 0.9893\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9886 - val_loss: 0.0216 - val_acc: 0.9873\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9893 - val_loss: 0.0210 - val_acc: 0.9903\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9883 - val_loss: 0.0227 - val_acc: 0.9903\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.01941 to 0.01871, saving model to best.model\n",
      "0s - loss: 0.0370 - acc: 0.9864 - val_loss: 0.0187 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9871 - val_loss: 0.0192 - val_acc: 0.9903\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9869 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9873 - val_loss: 0.0228 - val_acc: 0.9893\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01871 to 0.01827, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9825 - val_loss: 0.0183 - val_acc: 0.9912\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9881 - val_loss: 0.0208 - val_acc: 0.9903\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01827 to 0.01804, saving model to best.model\n",
      "0s - loss: 0.0333 - acc: 0.9873 - val_loss: 0.0180 - val_acc: 0.9912\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9869 - val_loss: 0.0208 - val_acc: 0.9903\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9890 - val_loss: 0.0186 - val_acc: 0.9893\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9895 - val_loss: 0.0182 - val_acc: 0.9912\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01804 to 0.01639, saving model to best.model\n",
      "0s - loss: 0.0299 - acc: 0.9895 - val_loss: 0.0164 - val_acc: 0.9932\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9886 - val_loss: 0.0171 - val_acc: 0.9912\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9900 - val_loss: 0.0200 - val_acc: 0.9893\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9881 - val_loss: 0.0185 - val_acc: 0.9893\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0171 - val_acc: 0.9922\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9905 - val_loss: 0.0172 - val_acc: 0.9912\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9895 - val_loss: 0.0189 - val_acc: 0.9912\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9895 - val_loss: 0.0180 - val_acc: 0.9893\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9881 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01639 to 0.01637, saving model to best.model\n",
      "0s - loss: 0.0260 - acc: 0.9900 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.01637 to 0.01564, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0156 - val_acc: 0.9922\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9895 - val_loss: 0.0193 - val_acc: 0.9912\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.01564 to 0.01548, saving model to best.model\n",
      "0s - loss: 0.0271 - acc: 0.9903 - val_loss: 0.0155 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9903 - val_loss: 0.0160 - val_acc: 0.9912\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9905 - val_loss: 0.0166 - val_acc: 0.9912\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9903 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9890 - val_loss: 0.0206 - val_acc: 0.9883\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0220 - acc: 0.9912 - val_loss: 0.0163 - val_acc: 0.9912\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9898 - val_loss: 0.0167 - val_acc: 0.9903\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.01548 to 0.01412, saving model to best.model\n",
      "0s - loss: 0.0253 - acc: 0.9910 - val_loss: 0.0141 - val_acc: 0.9932\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0228 - acc: 0.9920 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68163, saving model to best.model\n",
      "0s - loss: 0.8980 - acc: 0.4940 - val_loss: 0.6816 - val_acc: 0.5424\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68163 to 0.66931, saving model to best.model\n",
      "0s - loss: 0.7804 - acc: 0.5135 - val_loss: 0.6693 - val_acc: 0.5424\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66931 to 0.65916, saving model to best.model\n",
      "0s - loss: 0.7595 - acc: 0.5237 - val_loss: 0.6592 - val_acc: 0.6631\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.65916 to 0.62090, saving model to best.model\n",
      "0s - loss: 0.7210 - acc: 0.5432 - val_loss: 0.6209 - val_acc: 0.7235\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.62090 to 0.57221, saving model to best.model\n",
      "0s - loss: 0.6660 - acc: 0.5936 - val_loss: 0.5722 - val_acc: 0.7984\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.57221 to 0.51497, saving model to best.model\n",
      "0s - loss: 0.6213 - acc: 0.6586 - val_loss: 0.5150 - val_acc: 0.8072\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.51497 to 0.46565, saving model to best.model\n",
      "0s - loss: 0.5733 - acc: 0.7083 - val_loss: 0.4657 - val_acc: 0.8257\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.46565 to 0.43094, saving model to best.model\n",
      "0s - loss: 0.5125 - acc: 0.7565 - val_loss: 0.4309 - val_acc: 0.8277\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.43094 to 0.39610, saving model to best.model\n",
      "0s - loss: 0.4734 - acc: 0.7896 - val_loss: 0.3961 - val_acc: 0.8481\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.39610 to 0.37041, saving model to best.model\n",
      "0s - loss: 0.4439 - acc: 0.8084 - val_loss: 0.3704 - val_acc: 0.8569\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.37041 to 0.34681, saving model to best.model\n",
      "0s - loss: 0.4250 - acc: 0.8240 - val_loss: 0.3468 - val_acc: 0.8647\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.34681 to 0.32887, saving model to best.model\n",
      "0s - loss: 0.3905 - acc: 0.8393 - val_loss: 0.3289 - val_acc: 0.8695\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.32887 to 0.31316, saving model to best.model\n",
      "0s - loss: 0.3712 - acc: 0.8503 - val_loss: 0.3132 - val_acc: 0.8793\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.31316 to 0.30036, saving model to best.model\n",
      "0s - loss: 0.3588 - acc: 0.8544 - val_loss: 0.3004 - val_acc: 0.8870\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.30036 to 0.28994, saving model to best.model\n",
      "0s - loss: 0.3435 - acc: 0.8666 - val_loss: 0.2899 - val_acc: 0.8968\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.28994 to 0.28253, saving model to best.model\n",
      "0s - loss: 0.3333 - acc: 0.8724 - val_loss: 0.2825 - val_acc: 0.8987\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.3298 - acc: 0.8809 - val_loss: 0.2922 - val_acc: 0.8919\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.28253 to 0.27158, saving model to best.model\n",
      "0s - loss: 0.3067 - acc: 0.8882 - val_loss: 0.2716 - val_acc: 0.9036\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.27158 to 0.27080, saving model to best.model\n",
      "0s - loss: 0.3030 - acc: 0.8868 - val_loss: 0.2708 - val_acc: 0.9065\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.27080 to 0.26545, saving model to best.model\n",
      "0s - loss: 0.2951 - acc: 0.8902 - val_loss: 0.2655 - val_acc: 0.9056\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.26545 to 0.26217, saving model to best.model\n",
      "0s - loss: 0.2799 - acc: 0.8977 - val_loss: 0.2622 - val_acc: 0.9114\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2841 - acc: 0.8955 - val_loss: 0.2770 - val_acc: 0.9036\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.26217 to 0.25665, saving model to best.model\n",
      "0s - loss: 0.2824 - acc: 0.8936 - val_loss: 0.2566 - val_acc: 0.9104\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.25665 to 0.25274, saving model to best.model\n",
      "0s - loss: 0.2774 - acc: 0.8990 - val_loss: 0.2527 - val_acc: 0.9094\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.25274 to 0.24858, saving model to best.model\n",
      "0s - loss: 0.2620 - acc: 0.9041 - val_loss: 0.2486 - val_acc: 0.9065\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.24858 to 0.24618, saving model to best.model\n",
      "0s - loss: 0.2736 - acc: 0.8985 - val_loss: 0.2462 - val_acc: 0.9094\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.24618 to 0.24402, saving model to best.model\n",
      "0s - loss: 0.2553 - acc: 0.9089 - val_loss: 0.2440 - val_acc: 0.9114\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.24402 to 0.24277, saving model to best.model\n",
      "0s - loss: 0.2532 - acc: 0.9084 - val_loss: 0.2428 - val_acc: 0.9143\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.24277 to 0.23706, saving model to best.model\n",
      "0s - loss: 0.2492 - acc: 0.9111 - val_loss: 0.2371 - val_acc: 0.9104\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2463 - acc: 0.9119 - val_loss: 0.2371 - val_acc: 0.9143\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.23706 to 0.23168, saving model to best.model\n",
      "0s - loss: 0.2419 - acc: 0.9131 - val_loss: 0.2317 - val_acc: 0.9153\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.23168 to 0.23047, saving model to best.model\n",
      "0s - loss: 0.2340 - acc: 0.9143 - val_loss: 0.2305 - val_acc: 0.9211\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.23047 to 0.22461, saving model to best.model\n",
      "0s - loss: 0.2363 - acc: 0.9126 - val_loss: 0.2246 - val_acc: 0.9114\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.22461 to 0.22220, saving model to best.model\n",
      "0s - loss: 0.2303 - acc: 0.9167 - val_loss: 0.2222 - val_acc: 0.9241\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.22220 to 0.21808, saving model to best.model\n",
      "0s - loss: 0.2347 - acc: 0.9182 - val_loss: 0.2181 - val_acc: 0.9182\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.21808 to 0.21446, saving model to best.model\n",
      "0s - loss: 0.2212 - acc: 0.9182 - val_loss: 0.2145 - val_acc: 0.9172\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.21446 to 0.21102, saving model to best.model\n",
      "0s - loss: 0.2187 - acc: 0.9243 - val_loss: 0.2110 - val_acc: 0.9241\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2114 - acc: 0.9255 - val_loss: 0.2112 - val_acc: 0.9367\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.21102 to 0.20307, saving model to best.model\n",
      "0s - loss: 0.2107 - acc: 0.9243 - val_loss: 0.2031 - val_acc: 0.9270\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.20307 to 0.19897, saving model to best.model\n",
      "0s - loss: 0.2051 - acc: 0.9270 - val_loss: 0.1990 - val_acc: 0.9426\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19897 to 0.19487, saving model to best.model\n",
      "0s - loss: 0.2019 - acc: 0.9274 - val_loss: 0.1949 - val_acc: 0.9299\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19487 to 0.19045, saving model to best.model\n",
      "0s - loss: 0.2027 - acc: 0.9282 - val_loss: 0.1904 - val_acc: 0.9426\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19045 to 0.18790, saving model to best.model\n",
      "0s - loss: 0.1901 - acc: 0.9330 - val_loss: 0.1879 - val_acc: 0.9435\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18790 to 0.18264, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9330 - val_loss: 0.1826 - val_acc: 0.9435\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9316 - val_loss: 0.1836 - val_acc: 0.9231\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18264 to 0.17650, saving model to best.model\n",
      "0s - loss: 0.1956 - acc: 0.9321 - val_loss: 0.1765 - val_acc: 0.9445\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.17650 to 0.17440, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9345 - val_loss: 0.1744 - val_acc: 0.9455\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17440 to 0.16748, saving model to best.model\n",
      "0s - loss: 0.1805 - acc: 0.9338 - val_loss: 0.1675 - val_acc: 0.9435\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.16748 to 0.16275, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9362 - val_loss: 0.1627 - val_acc: 0.9445\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.16275 to 0.15989, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9347 - val_loss: 0.1599 - val_acc: 0.9474\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.15989 to 0.15554, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9413 - val_loss: 0.1555 - val_acc: 0.9474\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.15554 to 0.14934, saving model to best.model\n",
      "0s - loss: 0.1628 - acc: 0.9423 - val_loss: 0.1493 - val_acc: 0.9513\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14934 to 0.14923, saving model to best.model\n",
      "0s - loss: 0.1595 - acc: 0.9445 - val_loss: 0.1492 - val_acc: 0.9513\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.14923 to 0.14555, saving model to best.model\n",
      "0s - loss: 0.1678 - acc: 0.9386 - val_loss: 0.1455 - val_acc: 0.9562\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.14555 to 0.14086, saving model to best.model\n",
      "0s - loss: 0.1590 - acc: 0.9467 - val_loss: 0.1409 - val_acc: 0.9562\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.14086 to 0.13874, saving model to best.model\n",
      "0s - loss: 0.1519 - acc: 0.9496 - val_loss: 0.1387 - val_acc: 0.9601\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.13874 to 0.13699, saving model to best.model\n",
      "0s - loss: 0.1489 - acc: 0.9435 - val_loss: 0.1370 - val_acc: 0.9620\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1512 - acc: 0.9501 - val_loss: 0.1419 - val_acc: 0.9601\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.13699 to 0.13476, saving model to best.model\n",
      "0s - loss: 0.1432 - acc: 0.9486 - val_loss: 0.1348 - val_acc: 0.9611\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.13476 to 0.13084, saving model to best.model\n",
      "0s - loss: 0.1451 - acc: 0.9513 - val_loss: 0.1308 - val_acc: 0.9630\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1393 - acc: 0.9525 - val_loss: 0.1331 - val_acc: 0.9630\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.13084 to 0.12876, saving model to best.model\n",
      "0s - loss: 0.1358 - acc: 0.9513 - val_loss: 0.1288 - val_acc: 0.9630\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.12876 to 0.12508, saving model to best.model\n",
      "0s - loss: 0.1381 - acc: 0.9535 - val_loss: 0.1251 - val_acc: 0.9649\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.12508 to 0.12222, saving model to best.model\n",
      "0s - loss: 0.1327 - acc: 0.9523 - val_loss: 0.1222 - val_acc: 0.9659\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1388 - acc: 0.9533 - val_loss: 0.1270 - val_acc: 0.9620\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.12222 to 0.11708, saving model to best.model\n",
      "0s - loss: 0.1338 - acc: 0.9569 - val_loss: 0.1171 - val_acc: 0.9679\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.11708 to 0.11661, saving model to best.model\n",
      "0s - loss: 0.1316 - acc: 0.9569 - val_loss: 0.1166 - val_acc: 0.9679\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.11661 to 0.11504, saving model to best.model\n",
      "0s - loss: 0.1265 - acc: 0.9552 - val_loss: 0.1150 - val_acc: 0.9708\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.11504 to 0.11361, saving model to best.model\n",
      "0s - loss: 0.1292 - acc: 0.9601 - val_loss: 0.1136 - val_acc: 0.9708\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.11361 to 0.11200, saving model to best.model\n",
      "0s - loss: 0.1298 - acc: 0.9579 - val_loss: 0.1120 - val_acc: 0.9688\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.11200 to 0.11059, saving model to best.model\n",
      "0s - loss: 0.1255 - acc: 0.9537 - val_loss: 0.1106 - val_acc: 0.9708\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1282 - acc: 0.9581 - val_loss: 0.1138 - val_acc: 0.9679\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.11059 to 0.10661, saving model to best.model\n",
      "0s - loss: 0.1220 - acc: 0.9581 - val_loss: 0.1066 - val_acc: 0.9688\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.10661 to 0.10631, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9623 - val_loss: 0.1063 - val_acc: 0.9708\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.10631 to 0.10540, saving model to best.model\n",
      "0s - loss: 0.1188 - acc: 0.9618 - val_loss: 0.1054 - val_acc: 0.9718\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.10540 to 0.10260, saving model to best.model\n",
      "0s - loss: 0.1191 - acc: 0.9581 - val_loss: 0.1026 - val_acc: 0.9718\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.10260 to 0.10029, saving model to best.model\n",
      "0s - loss: 0.1132 - acc: 0.9618 - val_loss: 0.1003 - val_acc: 0.9727\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1120 - acc: 0.9647 - val_loss: 0.1004 - val_acc: 0.9708\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.10029 to 0.09660, saving model to best.model\n",
      "0s - loss: 0.1104 - acc: 0.9642 - val_loss: 0.0966 - val_acc: 0.9757\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.09660 to 0.09645, saving model to best.model\n",
      "0s - loss: 0.1102 - acc: 0.9620 - val_loss: 0.0965 - val_acc: 0.9757\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.09645 to 0.09411, saving model to best.model\n",
      "0s - loss: 0.1083 - acc: 0.9608 - val_loss: 0.0941 - val_acc: 0.9747\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1053 - acc: 0.9666 - val_loss: 0.0965 - val_acc: 0.9747\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.09411 to 0.09373, saving model to best.model\n",
      "0s - loss: 0.1120 - acc: 0.9601 - val_loss: 0.0937 - val_acc: 0.9747\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.09373 to 0.09369, saving model to best.model\n",
      "0s - loss: 0.1049 - acc: 0.9671 - val_loss: 0.0937 - val_acc: 0.9747\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.09369 to 0.09023, saving model to best.model\n",
      "0s - loss: 0.1017 - acc: 0.9645 - val_loss: 0.0902 - val_acc: 0.9757\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1004 - acc: 0.9662 - val_loss: 0.0903 - val_acc: 0.9757\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.09023 to 0.08888, saving model to best.model\n",
      "0s - loss: 0.0968 - acc: 0.9664 - val_loss: 0.0889 - val_acc: 0.9757\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0929 - acc: 0.9671 - val_loss: 0.0898 - val_acc: 0.9757\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.08888 to 0.08536, saving model to best.model\n",
      "0s - loss: 0.0933 - acc: 0.9681 - val_loss: 0.0854 - val_acc: 0.9757\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.08536 to 0.08486, saving model to best.model\n",
      "0s - loss: 0.0957 - acc: 0.9688 - val_loss: 0.0849 - val_acc: 0.9757\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.08486 to 0.08413, saving model to best.model\n",
      "0s - loss: 0.0952 - acc: 0.9669 - val_loss: 0.0841 - val_acc: 0.9757\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.08413 to 0.08064, saving model to best.model\n",
      "0s - loss: 0.0976 - acc: 0.9693 - val_loss: 0.0806 - val_acc: 0.9757\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0943 - acc: 0.9676 - val_loss: 0.0811 - val_acc: 0.9757\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.08064 to 0.08052, saving model to best.model\n",
      "0s - loss: 0.0946 - acc: 0.9679 - val_loss: 0.0805 - val_acc: 0.9766\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0921 - acc: 0.9691 - val_loss: 0.0807 - val_acc: 0.9766\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.08052 to 0.07616, saving model to best.model\n",
      "0s - loss: 0.0962 - acc: 0.9645 - val_loss: 0.0762 - val_acc: 0.9766\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.07616 to 0.07560, saving model to best.model\n",
      "0s - loss: 0.0895 - acc: 0.9683 - val_loss: 0.0756 - val_acc: 0.9776\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.07560 to 0.07405, saving model to best.model\n",
      "0s - loss: 0.0903 - acc: 0.9701 - val_loss: 0.0741 - val_acc: 0.9757\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.07405 to 0.07223, saving model to best.model\n",
      "0s - loss: 0.0852 - acc: 0.9710 - val_loss: 0.0722 - val_acc: 0.9766\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.07223 to 0.07191, saving model to best.model\n",
      "0s - loss: 0.0840 - acc: 0.9698 - val_loss: 0.0719 - val_acc: 0.9776\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.07191 to 0.07020, saving model to best.model\n",
      "0s - loss: 0.0830 - acc: 0.9720 - val_loss: 0.0702 - val_acc: 0.9776\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.07020 to 0.07014, saving model to best.model\n",
      "0s - loss: 0.0836 - acc: 0.9722 - val_loss: 0.0701 - val_acc: 0.9766\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.07014 to 0.06526, saving model to best.model\n",
      "0s - loss: 0.0775 - acc: 0.9735 - val_loss: 0.0653 - val_acc: 0.9796\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.06526 to 0.06339, saving model to best.model\n",
      "0s - loss: 0.0830 - acc: 0.9701 - val_loss: 0.0634 - val_acc: 0.9786\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0824 - acc: 0.9713 - val_loss: 0.0674 - val_acc: 0.9786\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0851 - acc: 0.9688 - val_loss: 0.0658 - val_acc: 0.9796\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0747 - acc: 0.9735 - val_loss: 0.0636 - val_acc: 0.9786\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.06339 to 0.06272, saving model to best.model\n",
      "0s - loss: 0.0790 - acc: 0.9730 - val_loss: 0.0627 - val_acc: 0.9796\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.06272 to 0.05833, saving model to best.model\n",
      "0s - loss: 0.0791 - acc: 0.9739 - val_loss: 0.0583 - val_acc: 0.9786\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.05833 to 0.05714, saving model to best.model\n",
      "0s - loss: 0.0743 - acc: 0.9742 - val_loss: 0.0571 - val_acc: 0.9786\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0704 - acc: 0.9735 - val_loss: 0.0583 - val_acc: 0.9786\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.05714 to 0.05639, saving model to best.model\n",
      "0s - loss: 0.0707 - acc: 0.9744 - val_loss: 0.0564 - val_acc: 0.9786\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0799 - acc: 0.9744 - val_loss: 0.0591 - val_acc: 0.9805\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.05639 to 0.05186, saving model to best.model\n",
      "0s - loss: 0.0756 - acc: 0.9722 - val_loss: 0.0519 - val_acc: 0.9796\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0745 - acc: 0.9727 - val_loss: 0.0519 - val_acc: 0.9796\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.05186 to 0.04955, saving model to best.model\n",
      "0s - loss: 0.0753 - acc: 0.9720 - val_loss: 0.0495 - val_acc: 0.9805\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.04955 to 0.04725, saving model to best.model\n",
      "0s - loss: 0.0685 - acc: 0.9744 - val_loss: 0.0472 - val_acc: 0.9805\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.04725 to 0.04590, saving model to best.model\n",
      "0s - loss: 0.0754 - acc: 0.9754 - val_loss: 0.0459 - val_acc: 0.9805\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.04590 to 0.04342, saving model to best.model\n",
      "0s - loss: 0.0681 - acc: 0.9761 - val_loss: 0.0434 - val_acc: 0.9825\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9771 - val_loss: 0.0488 - val_acc: 0.9796\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0667 - acc: 0.9747 - val_loss: 0.0443 - val_acc: 0.9805\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9795 - val_loss: 0.0437 - val_acc: 0.9815\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.04342 to 0.04141, saving model to best.model\n",
      "0s - loss: 0.0616 - acc: 0.9776 - val_loss: 0.0414 - val_acc: 0.9825\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.04141 to 0.03785, saving model to best.model\n",
      "0s - loss: 0.0627 - acc: 0.9786 - val_loss: 0.0378 - val_acc: 0.9844\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0721 - acc: 0.9742 - val_loss: 0.0429 - val_acc: 0.9815\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.03785 to 0.03663, saving model to best.model\n",
      "0s - loss: 0.0585 - acc: 0.9791 - val_loss: 0.0366 - val_acc: 0.9854\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0645 - acc: 0.9742 - val_loss: 0.0410 - val_acc: 0.9815\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.03663 to 0.03575, saving model to best.model\n",
      "0s - loss: 0.0603 - acc: 0.9774 - val_loss: 0.0358 - val_acc: 0.9854\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0697 - acc: 0.9742 - val_loss: 0.0465 - val_acc: 0.9805\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.03575 to 0.03459, saving model to best.model\n",
      "0s - loss: 0.0618 - acc: 0.9781 - val_loss: 0.0346 - val_acc: 0.9864\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0586 - acc: 0.9793 - val_loss: 0.0381 - val_acc: 0.9844\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9783 - val_loss: 0.0351 - val_acc: 0.9844\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.03459 to 0.03187, saving model to best.model\n",
      "0s - loss: 0.0537 - acc: 0.9808 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0553 - acc: 0.9815 - val_loss: 0.0334 - val_acc: 0.9864\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.03187 to 0.03015, saving model to best.model\n",
      "0s - loss: 0.0540 - acc: 0.9815 - val_loss: 0.0302 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9769 - val_loss: 0.0319 - val_acc: 0.9883\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.03015 to 0.02960, saving model to best.model\n",
      "0s - loss: 0.0556 - acc: 0.9808 - val_loss: 0.0296 - val_acc: 0.9912\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02960 to 0.02750, saving model to best.model\n",
      "0s - loss: 0.0538 - acc: 0.9808 - val_loss: 0.0275 - val_acc: 0.9912\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02750 to 0.02573, saving model to best.model\n",
      "0s - loss: 0.0510 - acc: 0.9817 - val_loss: 0.0257 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9803 - val_loss: 0.0284 - val_acc: 0.9922\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02573 to 0.02557, saving model to best.model\n",
      "0s - loss: 0.0437 - acc: 0.9822 - val_loss: 0.0256 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9810 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02557 to 0.02462, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9842 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0554 - acc: 0.9817 - val_loss: 0.0275 - val_acc: 0.9922\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.02462 to 0.02321, saving model to best.model\n",
      "0s - loss: 0.0486 - acc: 0.9827 - val_loss: 0.0232 - val_acc: 0.9912\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02321 to 0.02262, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9769 - val_loss: 0.0226 - val_acc: 0.9912\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.02262 to 0.02115, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9825 - val_loss: 0.0211 - val_acc: 0.9912\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0473 - acc: 0.9825 - val_loss: 0.0220 - val_acc: 0.9922\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9820 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0478 - acc: 0.9813 - val_loss: 0.0224 - val_acc: 0.9912\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9825 - val_loss: 0.0250 - val_acc: 0.9903\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9827 - val_loss: 0.0265 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9834 - val_loss: 0.0218 - val_acc: 0.9912\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9873 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9827 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9851 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.02115 to 0.02048, saving model to best.model\n",
      "0s - loss: 0.0442 - acc: 0.9830 - val_loss: 0.0205 - val_acc: 0.9922\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02048 to 0.01906, saving model to best.model\n",
      "0s - loss: 0.0403 - acc: 0.9861 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9834 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01906 to 0.01862, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9849 - val_loss: 0.0186 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9839 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9844 - val_loss: 0.0191 - val_acc: 0.9922\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01862 to 0.01736, saving model to best.model\n",
      "0s - loss: 0.0404 - acc: 0.9854 - val_loss: 0.0174 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01736 to 0.01728, saving model to best.model\n",
      "0s - loss: 0.0456 - acc: 0.9827 - val_loss: 0.0173 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01728 to 0.01723, saving model to best.model\n",
      "0s - loss: 0.0393 - acc: 0.9849 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01723 to 0.01539, saving model to best.model\n",
      "0s - loss: 0.0439 - acc: 0.9842 - val_loss: 0.0154 - val_acc: 0.9912\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9847 - val_loss: 0.0178 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01539 to 0.01397, saving model to best.model\n",
      "0s - loss: 0.0391 - acc: 0.9861 - val_loss: 0.0140 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01397 to 0.01364, saving model to best.model\n",
      "0s - loss: 0.0344 - acc: 0.9869 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9878 - val_loss: 0.0146 - val_acc: 0.9922\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01364 to 0.01298, saving model to best.model\n",
      "0s - loss: 0.0367 - acc: 0.9876 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0391 - acc: 0.9866 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9864 - val_loss: 0.0132 - val_acc: 0.9922\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9876 - val_loss: 0.0139 - val_acc: 0.9922\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.01298 to 0.01240, saving model to best.model\n",
      "0s - loss: 0.0390 - acc: 0.9866 - val_loss: 0.0124 - val_acc: 0.9922\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01240 to 0.01201, saving model to best.model\n",
      "0s - loss: 0.0313 - acc: 0.9876 - val_loss: 0.0120 - val_acc: 0.9922\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01201 to 0.01138, saving model to best.model\n",
      "0s - loss: 0.0315 - acc: 0.9883 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9856 - val_loss: 0.0123 - val_acc: 0.9932\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01138 to 0.01100, saving model to best.model\n",
      "0s - loss: 0.0310 - acc: 0.9893 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01100 to 0.01088, saving model to best.model\n",
      "0s - loss: 0.0368 - acc: 0.9847 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01088 to 0.01074, saving model to best.model\n",
      "0s - loss: 0.0293 - acc: 0.9903 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9910 - val_loss: 0.0111 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01074 to 0.01046, saving model to best.model\n",
      "0s - loss: 0.0389 - acc: 0.9871 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.01046 to 0.01046, saving model to best.model\n",
      "0s - loss: 0.0277 - acc: 0.9895 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01046 to 0.00918, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9869 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9864 - val_loss: 0.0106 - val_acc: 0.9932\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9888 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00918 to 0.00898, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9881 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00898 to 0.00893, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9878 - val_loss: 0.0089 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9888 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00893 to 0.00856, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0086 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9888 - val_loss: 0.0103 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9883 - val_loss: 0.0100 - val_acc: 0.9951\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00856 to 0.00811, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9881 - val_loss: 0.0081 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9888 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9866 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0242 - acc: 0.9903 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9905 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00811 to 0.00751, saving model to best.model\n",
      "0s - loss: 0.0287 - acc: 0.9886 - val_loss: 0.0075 - val_acc: 0.9990\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67885, saving model to best.model\n",
      "0s - loss: 0.8178 - acc: 0.5040 - val_loss: 0.6788 - val_acc: 0.4898\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67885 to 0.65304, saving model to best.model\n",
      "0s - loss: 0.7411 - acc: 0.5342 - val_loss: 0.6530 - val_acc: 0.7799\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65304 to 0.62006, saving model to best.model\n",
      "0s - loss: 0.7112 - acc: 0.5403 - val_loss: 0.6201 - val_acc: 0.7770\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.62006 to 0.57942, saving model to best.model\n",
      "0s - loss: 0.6658 - acc: 0.6199 - val_loss: 0.5794 - val_acc: 0.7468\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.57942 to 0.48967, saving model to best.model\n",
      "0s - loss: 0.6085 - acc: 0.6737 - val_loss: 0.4897 - val_acc: 0.8121\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.48967 to 0.42645, saving model to best.model\n",
      "0s - loss: 0.5397 - acc: 0.7409 - val_loss: 0.4265 - val_acc: 0.8238\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.42645 to 0.38853, saving model to best.model\n",
      "0s - loss: 0.4821 - acc: 0.7860 - val_loss: 0.3885 - val_acc: 0.8374\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38853 to 0.35526, saving model to best.model\n",
      "0s - loss: 0.4499 - acc: 0.8057 - val_loss: 0.3553 - val_acc: 0.8647\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35526 to 0.33578, saving model to best.model\n",
      "0s - loss: 0.4207 - acc: 0.8186 - val_loss: 0.3358 - val_acc: 0.8744\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33578 to 0.33371, saving model to best.model\n",
      "0s - loss: 0.3983 - acc: 0.8388 - val_loss: 0.3337 - val_acc: 0.8793\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33371 to 0.30499, saving model to best.model\n",
      "0s - loss: 0.3688 - acc: 0.8486 - val_loss: 0.3050 - val_acc: 0.8841\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30499 to 0.29919, saving model to best.model\n",
      "0s - loss: 0.3601 - acc: 0.8532 - val_loss: 0.2992 - val_acc: 0.8861\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29919 to 0.29400, saving model to best.model\n",
      "0s - loss: 0.3449 - acc: 0.8649 - val_loss: 0.2940 - val_acc: 0.8880\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.29400 to 0.28068, saving model to best.model\n",
      "0s - loss: 0.3290 - acc: 0.8741 - val_loss: 0.2807 - val_acc: 0.8978\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.3236 - acc: 0.8829 - val_loss: 0.2855 - val_acc: 0.8968\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.3124 - acc: 0.8812 - val_loss: 0.2839 - val_acc: 0.9007\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.28068 to 0.26564, saving model to best.model\n",
      "0s - loss: 0.3163 - acc: 0.8834 - val_loss: 0.2656 - val_acc: 0.9065\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.26564 to 0.26299, saving model to best.model\n",
      "0s - loss: 0.2911 - acc: 0.8958 - val_loss: 0.2630 - val_acc: 0.9124\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.2982 - acc: 0.8914 - val_loss: 0.2634 - val_acc: 0.9085\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2865 - acc: 0.8960 - val_loss: 0.2669 - val_acc: 0.9046\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.26299 to 0.25976, saving model to best.model\n",
      "0s - loss: 0.2859 - acc: 0.8997 - val_loss: 0.2598 - val_acc: 0.9094\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25976 to 0.25006, saving model to best.model\n",
      "0s - loss: 0.2739 - acc: 0.9026 - val_loss: 0.2501 - val_acc: 0.9172\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.25006 to 0.24869, saving model to best.model\n",
      "0s - loss: 0.2746 - acc: 0.9016 - val_loss: 0.2487 - val_acc: 0.9182\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2743 - acc: 0.8994 - val_loss: 0.2560 - val_acc: 0.9075\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.24869 to 0.24195, saving model to best.model\n",
      "0s - loss: 0.2686 - acc: 0.9021 - val_loss: 0.2420 - val_acc: 0.9202\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2581 - acc: 0.9104 - val_loss: 0.2423 - val_acc: 0.9163\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2550 - acc: 0.9106 - val_loss: 0.2433 - val_acc: 0.9153\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.24195 to 0.23897, saving model to best.model\n",
      "0s - loss: 0.2476 - acc: 0.9128 - val_loss: 0.2390 - val_acc: 0.9172\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.23897 to 0.23861, saving model to best.model\n",
      "0s - loss: 0.2426 - acc: 0.9143 - val_loss: 0.2386 - val_acc: 0.9172\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.23861 to 0.22887, saving model to best.model\n",
      "0s - loss: 0.2534 - acc: 0.9133 - val_loss: 0.2289 - val_acc: 0.9221\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2398 - acc: 0.9158 - val_loss: 0.2343 - val_acc: 0.9172\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.22887 to 0.22308, saving model to best.model\n",
      "0s - loss: 0.2458 - acc: 0.9126 - val_loss: 0.2231 - val_acc: 0.9231\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.22308 to 0.21968, saving model to best.model\n",
      "0s - loss: 0.2336 - acc: 0.9133 - val_loss: 0.2197 - val_acc: 0.9231\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.2351 - acc: 0.9170 - val_loss: 0.2216 - val_acc: 0.9192\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.2360 - acc: 0.9175 - val_loss: 0.2231 - val_acc: 0.9182\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.21968 to 0.20864, saving model to best.model\n",
      "0s - loss: 0.2281 - acc: 0.9196 - val_loss: 0.2086 - val_acc: 0.9241\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.20864 to 0.20762, saving model to best.model\n",
      "0s - loss: 0.2251 - acc: 0.9211 - val_loss: 0.2076 - val_acc: 0.9211\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2231 - acc: 0.9199 - val_loss: 0.2109 - val_acc: 0.9192\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.20762 to 0.20237, saving model to best.model\n",
      "0s - loss: 0.2184 - acc: 0.9209 - val_loss: 0.2024 - val_acc: 0.9221\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.2106 - acc: 0.9245 - val_loss: 0.2043 - val_acc: 0.9211\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.20237 to 0.19384, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9270 - val_loss: 0.1938 - val_acc: 0.9279\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.2049 - acc: 0.9243 - val_loss: 0.1962 - val_acc: 0.9250\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19384 to 0.18998, saving model to best.model\n",
      "0s - loss: 0.2021 - acc: 0.9250 - val_loss: 0.1900 - val_acc: 0.9289\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18998 to 0.18955, saving model to best.model\n",
      "0s - loss: 0.1955 - acc: 0.9301 - val_loss: 0.1895 - val_acc: 0.9260\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18955 to 0.17936, saving model to best.model\n",
      "0s - loss: 0.2002 - acc: 0.9250 - val_loss: 0.1794 - val_acc: 0.9328\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17936 to 0.17863, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9277 - val_loss: 0.1786 - val_acc: 0.9338\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.17863 to 0.17353, saving model to best.model\n",
      "0s - loss: 0.1926 - acc: 0.9272 - val_loss: 0.1735 - val_acc: 0.9377\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1879 - acc: 0.9382 - val_loss: 0.1819 - val_acc: 0.9299\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17353 to 0.16699, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9318 - val_loss: 0.1670 - val_acc: 0.9406\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9350 - val_loss: 0.1797 - val_acc: 0.9270\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.16699 to 0.16532, saving model to best.model\n",
      "0s - loss: 0.1814 - acc: 0.9326 - val_loss: 0.1653 - val_acc: 0.9406\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1735 - acc: 0.9401 - val_loss: 0.1673 - val_acc: 0.9406\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.16532 to 0.16050, saving model to best.model\n",
      "0s - loss: 0.1733 - acc: 0.9347 - val_loss: 0.1605 - val_acc: 0.9416\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1665 - acc: 0.9372 - val_loss: 0.1706 - val_acc: 0.9348\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.16050 to 0.15995, saving model to best.model\n",
      "0s - loss: 0.1820 - acc: 0.9357 - val_loss: 0.1600 - val_acc: 0.9396\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.15995 to 0.14995, saving model to best.model\n",
      "0s - loss: 0.1642 - acc: 0.9372 - val_loss: 0.1500 - val_acc: 0.9503\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.14995 to 0.14805, saving model to best.model\n",
      "0s - loss: 0.1496 - acc: 0.9459 - val_loss: 0.1480 - val_acc: 0.9484\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1597 - acc: 0.9425 - val_loss: 0.1550 - val_acc: 0.9406\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1626 - acc: 0.9416 - val_loss: 0.1501 - val_acc: 0.9426\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.14805 to 0.13699, saving model to best.model\n",
      "0s - loss: 0.1624 - acc: 0.9406 - val_loss: 0.1370 - val_acc: 0.9562\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1556 - acc: 0.9399 - val_loss: 0.1437 - val_acc: 0.9435\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1553 - acc: 0.9413 - val_loss: 0.1409 - val_acc: 0.9455\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1542 - acc: 0.9433 - val_loss: 0.1387 - val_acc: 0.9474\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.13699 to 0.13440, saving model to best.model\n",
      "0s - loss: 0.1451 - acc: 0.9450 - val_loss: 0.1344 - val_acc: 0.9494\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.13440 to 0.12367, saving model to best.model\n",
      "0s - loss: 0.1411 - acc: 0.9459 - val_loss: 0.1237 - val_acc: 0.9591\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1455 - acc: 0.9484 - val_loss: 0.1306 - val_acc: 0.9494\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1416 - acc: 0.9464 - val_loss: 0.1249 - val_acc: 0.9552\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.12367 to 0.11762, saving model to best.model\n",
      "0s - loss: 0.1378 - acc: 0.9486 - val_loss: 0.1176 - val_acc: 0.9591\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1339 - acc: 0.9528 - val_loss: 0.1309 - val_acc: 0.9494\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1358 - acc: 0.9503 - val_loss: 0.1191 - val_acc: 0.9572\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.11762 to 0.11727, saving model to best.model\n",
      "0s - loss: 0.1244 - acc: 0.9564 - val_loss: 0.1173 - val_acc: 0.9581\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.11727 to 0.10809, saving model to best.model\n",
      "0s - loss: 0.1248 - acc: 0.9552 - val_loss: 0.1081 - val_acc: 0.9611\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1226 - acc: 0.9550 - val_loss: 0.1109 - val_acc: 0.9581\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.10809 to 0.10244, saving model to best.model\n",
      "0s - loss: 0.1204 - acc: 0.9559 - val_loss: 0.1024 - val_acc: 0.9640\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1261 - acc: 0.9542 - val_loss: 0.1076 - val_acc: 0.9630\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.10244 to 0.09682, saving model to best.model\n",
      "0s - loss: 0.1180 - acc: 0.9564 - val_loss: 0.0968 - val_acc: 0.9640\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1152 - acc: 0.9559 - val_loss: 0.1003 - val_acc: 0.9640\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.09682 to 0.09026, saving model to best.model\n",
      "0s - loss: 0.1110 - acc: 0.9574 - val_loss: 0.0903 - val_acc: 0.9649\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1081 - acc: 0.9613 - val_loss: 0.0928 - val_acc: 0.9649\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1047 - acc: 0.9601 - val_loss: 0.0952 - val_acc: 0.9688\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.09026 to 0.08949, saving model to best.model\n",
      "0s - loss: 0.1099 - acc: 0.9591 - val_loss: 0.0895 - val_acc: 0.9708\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.08949 to 0.07636, saving model to best.model\n",
      "0s - loss: 0.1002 - acc: 0.9620 - val_loss: 0.0764 - val_acc: 0.9698\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0968 - acc: 0.9642 - val_loss: 0.0768 - val_acc: 0.9708\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0971 - acc: 0.9640 - val_loss: 0.0783 - val_acc: 0.9698\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.07636 to 0.06959, saving model to best.model\n",
      "0s - loss: 0.0923 - acc: 0.9647 - val_loss: 0.0696 - val_acc: 0.9708\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0894 - acc: 0.9683 - val_loss: 0.0956 - val_acc: 0.9649\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06959 to 0.06297, saving model to best.model\n",
      "0s - loss: 0.0898 - acc: 0.9632 - val_loss: 0.0630 - val_acc: 0.9747\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0898 - acc: 0.9674 - val_loss: 0.0644 - val_acc: 0.9757\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.06297 to 0.06011, saving model to best.model\n",
      "0s - loss: 0.0863 - acc: 0.9693 - val_loss: 0.0601 - val_acc: 0.9776\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0936 - acc: 0.9652 - val_loss: 0.0619 - val_acc: 0.9776\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.06011 to 0.05375, saving model to best.model\n",
      "0s - loss: 0.0893 - acc: 0.9662 - val_loss: 0.0537 - val_acc: 0.9776\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0876 - acc: 0.9666 - val_loss: 0.0570 - val_acc: 0.9796\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0829 - acc: 0.9693 - val_loss: 0.0550 - val_acc: 0.9815\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0855 - acc: 0.9657 - val_loss: 0.0655 - val_acc: 0.9757\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.05375 to 0.04679, saving model to best.model\n",
      "0s - loss: 0.0863 - acc: 0.9698 - val_loss: 0.0468 - val_acc: 0.9854\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0793 - acc: 0.9681 - val_loss: 0.0506 - val_acc: 0.9805\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0768 - acc: 0.9718 - val_loss: 0.0472 - val_acc: 0.9883\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0848 - acc: 0.9693 - val_loss: 0.0524 - val_acc: 0.9776\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04679 to 0.04483, saving model to best.model\n",
      "0s - loss: 0.0765 - acc: 0.9749 - val_loss: 0.0448 - val_acc: 0.9834\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0748 - acc: 0.9705 - val_loss: 0.0498 - val_acc: 0.9805\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0776 - acc: 0.9708 - val_loss: 0.0487 - val_acc: 0.9805\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04483 to 0.04324, saving model to best.model\n",
      "0s - loss: 0.0724 - acc: 0.9761 - val_loss: 0.0432 - val_acc: 0.9815\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0710 - acc: 0.9761 - val_loss: 0.0443 - val_acc: 0.9815\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0730 - acc: 0.9722 - val_loss: 0.0437 - val_acc: 0.9815\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.04324 to 0.04213, saving model to best.model\n",
      "0s - loss: 0.0632 - acc: 0.9769 - val_loss: 0.0421 - val_acc: 0.9815\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.04213 to 0.03673, saving model to best.model\n",
      "0s - loss: 0.0703 - acc: 0.9735 - val_loss: 0.0367 - val_acc: 0.9893\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0729 - acc: 0.9718 - val_loss: 0.0389 - val_acc: 0.9825\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0689 - acc: 0.9737 - val_loss: 0.0440 - val_acc: 0.9834\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03673 to 0.03566, saving model to best.model\n",
      "0s - loss: 0.0625 - acc: 0.9769 - val_loss: 0.0357 - val_acc: 0.9854\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03566 to 0.03374, saving model to best.model\n",
      "0s - loss: 0.0639 - acc: 0.9735 - val_loss: 0.0337 - val_acc: 0.9893\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0593 - acc: 0.9781 - val_loss: 0.0442 - val_acc: 0.9815\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0648 - acc: 0.9752 - val_loss: 0.0387 - val_acc: 0.9834\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9781 - val_loss: 0.0366 - val_acc: 0.9844\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0641 - acc: 0.9754 - val_loss: 0.0359 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9771 - val_loss: 0.0408 - val_acc: 0.9815\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.03374 to 0.03244, saving model to best.model\n",
      "0s - loss: 0.0549 - acc: 0.9788 - val_loss: 0.0324 - val_acc: 0.9893\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0535 - acc: 0.9817 - val_loss: 0.0387 - val_acc: 0.9815\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.03244 to 0.02917, saving model to best.model\n",
      "0s - loss: 0.0577 - acc: 0.9798 - val_loss: 0.0292 - val_acc: 0.9893\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0668 - acc: 0.9752 - val_loss: 0.0387 - val_acc: 0.9844\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0552 - acc: 0.9778 - val_loss: 0.0316 - val_acc: 0.9854\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0585 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0614 - acc: 0.9771 - val_loss: 0.0350 - val_acc: 0.9854\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9813 - val_loss: 0.0328 - val_acc: 0.9883\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9837 - val_loss: 0.0399 - val_acc: 0.9834\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9793 - val_loss: 0.0302 - val_acc: 0.9854\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02917 to 0.02670, saving model to best.model\n",
      "0s - loss: 0.0544 - acc: 0.9778 - val_loss: 0.0267 - val_acc: 0.9912\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0528 - acc: 0.9813 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9791 - val_loss: 0.0281 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9822 - val_loss: 0.0295 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9830 - val_loss: 0.0298 - val_acc: 0.9844\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9817 - val_loss: 0.0268 - val_acc: 0.9893\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0562 - acc: 0.9805 - val_loss: 0.0317 - val_acc: 0.9883\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9817 - val_loss: 0.0291 - val_acc: 0.9883\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02670 to 0.02629, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9893\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9837 - val_loss: 0.0267 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.02629 to 0.02597, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9832 - val_loss: 0.0260 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02597 to 0.02590, saving model to best.model\n",
      "0s - loss: 0.0476 - acc: 0.9808 - val_loss: 0.0259 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0478 - acc: 0.9805 - val_loss: 0.0337 - val_acc: 0.9873\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02590 to 0.02203, saving model to best.model\n",
      "0s - loss: 0.0539 - acc: 0.9825 - val_loss: 0.0220 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9861 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02203 to 0.02156, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9822 - val_loss: 0.0216 - val_acc: 0.9932\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9856 - val_loss: 0.0273 - val_acc: 0.9883\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9839 - val_loss: 0.0243 - val_acc: 0.9922\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9813 - val_loss: 0.0232 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9834 - val_loss: 0.0262 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0454 - acc: 0.9847 - val_loss: 0.0234 - val_acc: 0.9922\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9832 - val_loss: 0.0269 - val_acc: 0.9883\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02156 to 0.02148, saving model to best.model\n",
      "0s - loss: 0.0420 - acc: 0.9834 - val_loss: 0.0215 - val_acc: 0.9912\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9878 - val_loss: 0.0224 - val_acc: 0.9912\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9876 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9844 - val_loss: 0.0261 - val_acc: 0.9903\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.02148 to 0.01944, saving model to best.model\n",
      "0s - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9839 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9851 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9851 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9883 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9869 - val_loss: 0.0206 - val_acc: 0.9912\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01944 to 0.01796, saving model to best.model\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0180 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9890 - val_loss: 0.0200 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9859 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01796 to 0.01627, saving model to best.model\n",
      "0s - loss: 0.0376 - acc: 0.9869 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9859 - val_loss: 0.0185 - val_acc: 0.9932\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9859 - val_loss: 0.0186 - val_acc: 0.9932\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9873 - val_loss: 0.0182 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9869 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01627 to 0.01602, saving model to best.model\n",
      "0s - loss: 0.0390 - acc: 0.9876 - val_loss: 0.0160 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0250 - acc: 0.9905 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01602 to 0.01490, saving model to best.model\n",
      "0s - loss: 0.0332 - acc: 0.9869 - val_loss: 0.0149 - val_acc: 0.9951\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9861 - val_loss: 0.0208 - val_acc: 0.9922\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9851 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9883 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01490 to 0.01434, saving model to best.model\n",
      "0s - loss: 0.0324 - acc: 0.9907 - val_loss: 0.0143 - val_acc: 0.9951\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9888 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9888 - val_loss: 0.0159 - val_acc: 0.9932\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9903 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9900 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01434 to 0.01315, saving model to best.model\n",
      "0s - loss: 0.0318 - acc: 0.9883 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9871 - val_loss: 0.0166 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9888 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01315 to 0.01222, saving model to best.model\n",
      "0s - loss: 0.0293 - acc: 0.9910 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9883 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01222 to 0.01205, saving model to best.model\n",
      "0s - loss: 0.0303 - acc: 0.9890 - val_loss: 0.0120 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0239 - acc: 0.9903 - val_loss: 0.0148 - val_acc: 0.9942\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01205 to 0.01069, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9905 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9878 - val_loss: 0.0200 - val_acc: 0.9932\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9866 - val_loss: 0.0178 - val_acc: 0.9932\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9871 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9905 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9895 - val_loss: 0.0132 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9890 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0266 - acc: 0.9912 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9883 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0211 - acc: 0.9932 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9883 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9873 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.0139 - val_acc: 0.9932\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9876 - val_loss: 0.0160 - val_acc: 0.9932\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9881 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9890 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68155, saving model to best.model\n",
      "0s - loss: 0.7967 - acc: 0.5167 - val_loss: 0.6815 - val_acc: 0.4907\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68155 to 0.65649, saving model to best.model\n",
      "0s - loss: 0.7497 - acc: 0.5284 - val_loss: 0.6565 - val_acc: 0.8121\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65649 to 0.62772, saving model to best.model\n",
      "0s - loss: 0.7057 - acc: 0.5573 - val_loss: 0.6277 - val_acc: 0.7089\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.62772 to 0.55301, saving model to best.model\n",
      "0s - loss: 0.6477 - acc: 0.6272 - val_loss: 0.5530 - val_acc: 0.8150\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55301 to 0.47285, saving model to best.model\n",
      "0s - loss: 0.5863 - acc: 0.6869 - val_loss: 0.4728 - val_acc: 0.8208\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47285 to 0.41484, saving model to best.model\n",
      "0s - loss: 0.5137 - acc: 0.7672 - val_loss: 0.4148 - val_acc: 0.8393\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41484 to 0.38299, saving model to best.model\n",
      "0s - loss: 0.4607 - acc: 0.8033 - val_loss: 0.3830 - val_acc: 0.8539\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38299 to 0.35249, saving model to best.model\n",
      "0s - loss: 0.4248 - acc: 0.8296 - val_loss: 0.3525 - val_acc: 0.8676\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35249 to 0.33437, saving model to best.model\n",
      "0s - loss: 0.4075 - acc: 0.8320 - val_loss: 0.3344 - val_acc: 0.8705\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33437 to 0.31972, saving model to best.model\n",
      "0s - loss: 0.3806 - acc: 0.8486 - val_loss: 0.3197 - val_acc: 0.8822\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31972 to 0.30312, saving model to best.model\n",
      "0s - loss: 0.3589 - acc: 0.8576 - val_loss: 0.3031 - val_acc: 0.8822\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30312 to 0.28872, saving model to best.model\n",
      "0s - loss: 0.3555 - acc: 0.8600 - val_loss: 0.2887 - val_acc: 0.8890\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28872 to 0.27831, saving model to best.model\n",
      "0s - loss: 0.3355 - acc: 0.8690 - val_loss: 0.2783 - val_acc: 0.8900\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27831 to 0.27590, saving model to best.model\n",
      "0s - loss: 0.3144 - acc: 0.8766 - val_loss: 0.2759 - val_acc: 0.8978\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27590 to 0.26229, saving model to best.model\n",
      "0s - loss: 0.3093 - acc: 0.8785 - val_loss: 0.2623 - val_acc: 0.9036\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26229 to 0.26028, saving model to best.model\n",
      "0s - loss: 0.3042 - acc: 0.8870 - val_loss: 0.2603 - val_acc: 0.9007\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26028 to 0.25000, saving model to best.model\n",
      "0s - loss: 0.2934 - acc: 0.8921 - val_loss: 0.2500 - val_acc: 0.9114\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25000 to 0.24580, saving model to best.model\n",
      "0s - loss: 0.2871 - acc: 0.8960 - val_loss: 0.2458 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24580 to 0.24376, saving model to best.model\n",
      "0s - loss: 0.2740 - acc: 0.8963 - val_loss: 0.2438 - val_acc: 0.9143\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24376 to 0.23723, saving model to best.model\n",
      "0s - loss: 0.2817 - acc: 0.8936 - val_loss: 0.2372 - val_acc: 0.9143\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23723 to 0.23371, saving model to best.model\n",
      "0s - loss: 0.2707 - acc: 0.9033 - val_loss: 0.2337 - val_acc: 0.9153\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23371 to 0.23012, saving model to best.model\n",
      "0s - loss: 0.2624 - acc: 0.9055 - val_loss: 0.2301 - val_acc: 0.9163\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23012 to 0.22531, saving model to best.model\n",
      "0s - loss: 0.2632 - acc: 0.9011 - val_loss: 0.2253 - val_acc: 0.9163\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22531 to 0.22217, saving model to best.model\n",
      "0s - loss: 0.2521 - acc: 0.9050 - val_loss: 0.2222 - val_acc: 0.9172\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22217 to 0.21809, saving model to best.model\n",
      "0s - loss: 0.2468 - acc: 0.9077 - val_loss: 0.2181 - val_acc: 0.9172\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21809 to 0.21749, saving model to best.model\n",
      "0s - loss: 0.2409 - acc: 0.9065 - val_loss: 0.2175 - val_acc: 0.9172\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21749 to 0.21142, saving model to best.model\n",
      "0s - loss: 0.2369 - acc: 0.9121 - val_loss: 0.2114 - val_acc: 0.9182\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21142 to 0.20711, saving model to best.model\n",
      "0s - loss: 0.2389 - acc: 0.9119 - val_loss: 0.2071 - val_acc: 0.9182\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20711 to 0.20433, saving model to best.model\n",
      "0s - loss: 0.2351 - acc: 0.9104 - val_loss: 0.2043 - val_acc: 0.9211\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20433 to 0.19968, saving model to best.model\n",
      "0s - loss: 0.2245 - acc: 0.9123 - val_loss: 0.1997 - val_acc: 0.9202\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19968 to 0.19710, saving model to best.model\n",
      "0s - loss: 0.2204 - acc: 0.9221 - val_loss: 0.1971 - val_acc: 0.9182\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19710 to 0.19382, saving model to best.model\n",
      "0s - loss: 0.2257 - acc: 0.9143 - val_loss: 0.1938 - val_acc: 0.9250\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19382 to 0.18829, saving model to best.model\n",
      "0s - loss: 0.2234 - acc: 0.9187 - val_loss: 0.1883 - val_acc: 0.9172\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18829 to 0.18354, saving model to best.model\n",
      "0s - loss: 0.2147 - acc: 0.9184 - val_loss: 0.1835 - val_acc: 0.9182\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18354 to 0.17999, saving model to best.model\n",
      "0s - loss: 0.2100 - acc: 0.9206 - val_loss: 0.1800 - val_acc: 0.9260\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17999 to 0.17522, saving model to best.model\n",
      "0s - loss: 0.2121 - acc: 0.9167 - val_loss: 0.1752 - val_acc: 0.9279\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17522 to 0.17142, saving model to best.model\n",
      "0s - loss: 0.1985 - acc: 0.9260 - val_loss: 0.1714 - val_acc: 0.9211\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17142 to 0.16858, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9262 - val_loss: 0.1686 - val_acc: 0.9357\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16858 to 0.16488, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9233 - val_loss: 0.1649 - val_acc: 0.9270\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16488 to 0.15809, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9299 - val_loss: 0.1581 - val_acc: 0.9348\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15809 to 0.15530, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9262 - val_loss: 0.1553 - val_acc: 0.9309\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15530 to 0.15344, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9321 - val_loss: 0.1534 - val_acc: 0.9464\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1870 - acc: 0.9296 - val_loss: 0.1545 - val_acc: 0.9299\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15344 to 0.14250, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9262 - val_loss: 0.1425 - val_acc: 0.9474\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14250 to 0.13464, saving model to best.model\n",
      "0s - loss: 0.1818 - acc: 0.9282 - val_loss: 0.1346 - val_acc: 0.9387\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1835 - acc: 0.9250 - val_loss: 0.1415 - val_acc: 0.9299\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13464 to 0.13043, saving model to best.model\n",
      "0s - loss: 0.1637 - acc: 0.9399 - val_loss: 0.1304 - val_acc: 0.9416\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1647 - acc: 0.9377 - val_loss: 0.1310 - val_acc: 0.9494\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13043 to 0.12504, saving model to best.model\n",
      "0s - loss: 0.1571 - acc: 0.9425 - val_loss: 0.1250 - val_acc: 0.9396\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12504 to 0.11958, saving model to best.model\n",
      "0s - loss: 0.1569 - acc: 0.9413 - val_loss: 0.1196 - val_acc: 0.9494\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11958 to 0.11444, saving model to best.model\n",
      "0s - loss: 0.1588 - acc: 0.9423 - val_loss: 0.1144 - val_acc: 0.9513\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1574 - acc: 0.9418 - val_loss: 0.1146 - val_acc: 0.9552\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11444 to 0.11002, saving model to best.model\n",
      "0s - loss: 0.1546 - acc: 0.9418 - val_loss: 0.1100 - val_acc: 0.9542\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11002 to 0.10673, saving model to best.model\n",
      "0s - loss: 0.1440 - acc: 0.9484 - val_loss: 0.1067 - val_acc: 0.9572\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10673 to 0.10122, saving model to best.model\n",
      "0s - loss: 0.1360 - acc: 0.9486 - val_loss: 0.1012 - val_acc: 0.9601\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.10122 to 0.10112, saving model to best.model\n",
      "0s - loss: 0.1401 - acc: 0.9481 - val_loss: 0.1011 - val_acc: 0.9591\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10112 to 0.09959, saving model to best.model\n",
      "0s - loss: 0.1387 - acc: 0.9481 - val_loss: 0.0996 - val_acc: 0.9572\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1364 - acc: 0.9445 - val_loss: 0.1059 - val_acc: 0.9562\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09959 to 0.09203, saving model to best.model\n",
      "0s - loss: 0.1427 - acc: 0.9425 - val_loss: 0.0920 - val_acc: 0.9640\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09203 to 0.08884, saving model to best.model\n",
      "0s - loss: 0.1334 - acc: 0.9469 - val_loss: 0.0888 - val_acc: 0.9640\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1303 - acc: 0.9506 - val_loss: 0.0890 - val_acc: 0.9640\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1207 - acc: 0.9535 - val_loss: 0.0894 - val_acc: 0.9718\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1277 - acc: 0.9508 - val_loss: 0.0890 - val_acc: 0.9630\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08884 to 0.08133, saving model to best.model\n",
      "0s - loss: 0.1237 - acc: 0.9537 - val_loss: 0.0813 - val_acc: 0.9747\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08133 to 0.07649, saving model to best.model\n",
      "0s - loss: 0.1221 - acc: 0.9515 - val_loss: 0.0765 - val_acc: 0.9737\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07649 to 0.07441, saving model to best.model\n",
      "0s - loss: 0.1147 - acc: 0.9545 - val_loss: 0.0744 - val_acc: 0.9766\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07441 to 0.07250, saving model to best.model\n",
      "0s - loss: 0.1124 - acc: 0.9554 - val_loss: 0.0725 - val_acc: 0.9747\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1220 - acc: 0.9542 - val_loss: 0.0741 - val_acc: 0.9815\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07250 to 0.07133, saving model to best.model\n",
      "0s - loss: 0.1161 - acc: 0.9554 - val_loss: 0.0713 - val_acc: 0.9718\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07133 to 0.06744, saving model to best.model\n",
      "0s - loss: 0.1044 - acc: 0.9625 - val_loss: 0.0674 - val_acc: 0.9834\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06744 to 0.06355, saving model to best.model\n",
      "0s - loss: 0.1063 - acc: 0.9613 - val_loss: 0.0635 - val_acc: 0.9834\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06355 to 0.06196, saving model to best.model\n",
      "0s - loss: 0.1028 - acc: 0.9601 - val_loss: 0.0620 - val_acc: 0.9854\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06196 to 0.06149, saving model to best.model\n",
      "0s - loss: 0.1031 - acc: 0.9608 - val_loss: 0.0615 - val_acc: 0.9854\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06149 to 0.06110, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9601 - val_loss: 0.0611 - val_acc: 0.9873\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06110 to 0.06035, saving model to best.model\n",
      "0s - loss: 0.1013 - acc: 0.9589 - val_loss: 0.0603 - val_acc: 0.9786\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06035 to 0.05961, saving model to best.model\n",
      "0s - loss: 0.1048 - acc: 0.9610 - val_loss: 0.0596 - val_acc: 0.9864\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05961 to 0.05552, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9659 - val_loss: 0.0555 - val_acc: 0.9854\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1021 - acc: 0.9635 - val_loss: 0.0570 - val_acc: 0.9834\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05552 to 0.05490, saving model to best.model\n",
      "0s - loss: 0.0961 - acc: 0.9664 - val_loss: 0.0549 - val_acc: 0.9864\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05490 to 0.05258, saving model to best.model\n",
      "0s - loss: 0.0944 - acc: 0.9647 - val_loss: 0.0526 - val_acc: 0.9873\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05258 to 0.05143, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9654 - val_loss: 0.0514 - val_acc: 0.9864\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05143 to 0.04995, saving model to best.model\n",
      "0s - loss: 0.0898 - acc: 0.9679 - val_loss: 0.0499 - val_acc: 0.9873\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04995 to 0.04989, saving model to best.model\n",
      "0s - loss: 0.0922 - acc: 0.9666 - val_loss: 0.0499 - val_acc: 0.9854\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0951 - acc: 0.9620 - val_loss: 0.0509 - val_acc: 0.9883\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04989 to 0.04833, saving model to best.model\n",
      "0s - loss: 0.0886 - acc: 0.9671 - val_loss: 0.0483 - val_acc: 0.9873\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04833 to 0.04665, saving model to best.model\n",
      "0s - loss: 0.0824 - acc: 0.9693 - val_loss: 0.0466 - val_acc: 0.9864\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04665 to 0.04589, saving model to best.model\n",
      "0s - loss: 0.0803 - acc: 0.9698 - val_loss: 0.0459 - val_acc: 0.9873\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04589 to 0.04425, saving model to best.model\n",
      "0s - loss: 0.0772 - acc: 0.9710 - val_loss: 0.0443 - val_acc: 0.9854\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04425 to 0.04395, saving model to best.model\n",
      "0s - loss: 0.0790 - acc: 0.9737 - val_loss: 0.0439 - val_acc: 0.9864\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0875 - acc: 0.9666 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0817 - acc: 0.9688 - val_loss: 0.0440 - val_acc: 0.9883\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0804 - acc: 0.9722 - val_loss: 0.0447 - val_acc: 0.9864\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04395 to 0.04302, saving model to best.model\n",
      "0s - loss: 0.0768 - acc: 0.9744 - val_loss: 0.0430 - val_acc: 0.9854\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04302 to 0.04166, saving model to best.model\n",
      "0s - loss: 0.0754 - acc: 0.9737 - val_loss: 0.0417 - val_acc: 0.9873\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04166 to 0.04141, saving model to best.model\n",
      "0s - loss: 0.0810 - acc: 0.9701 - val_loss: 0.0414 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0760 - acc: 0.9744 - val_loss: 0.0420 - val_acc: 0.9883\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04141 to 0.04029, saving model to best.model\n",
      "0s - loss: 0.0731 - acc: 0.9725 - val_loss: 0.0403 - val_acc: 0.9854\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0709 - acc: 0.9742 - val_loss: 0.0403 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04029 to 0.03842, saving model to best.model\n",
      "0s - loss: 0.0727 - acc: 0.9715 - val_loss: 0.0384 - val_acc: 0.9873\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03842 to 0.03648, saving model to best.model\n",
      "0s - loss: 0.0695 - acc: 0.9735 - val_loss: 0.0365 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03648 to 0.03565, saving model to best.model\n",
      "0s - loss: 0.0693 - acc: 0.9744 - val_loss: 0.0356 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03565 to 0.03549, saving model to best.model\n",
      "0s - loss: 0.0721 - acc: 0.9759 - val_loss: 0.0355 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03549 to 0.03493, saving model to best.model\n",
      "0s - loss: 0.0676 - acc: 0.9735 - val_loss: 0.0349 - val_acc: 0.9883\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03493 to 0.03459, saving model to best.model\n",
      "0s - loss: 0.0653 - acc: 0.9752 - val_loss: 0.0346 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03459 to 0.03371, saving model to best.model\n",
      "0s - loss: 0.0639 - acc: 0.9766 - val_loss: 0.0337 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03371 to 0.03371, saving model to best.model\n",
      "0s - loss: 0.0703 - acc: 0.9752 - val_loss: 0.0337 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03371 to 0.03247, saving model to best.model\n",
      "0s - loss: 0.0628 - acc: 0.9764 - val_loss: 0.0325 - val_acc: 0.9873\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0680 - acc: 0.9742 - val_loss: 0.0346 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0624 - acc: 0.9764 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03247 to 0.03183, saving model to best.model\n",
      "0s - loss: 0.0651 - acc: 0.9766 - val_loss: 0.0318 - val_acc: 0.9854\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0681 - acc: 0.9727 - val_loss: 0.0324 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03183 to 0.03108, saving model to best.model\n",
      "0s - loss: 0.0559 - acc: 0.9771 - val_loss: 0.0311 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03108 to 0.03007, saving model to best.model\n",
      "0s - loss: 0.0667 - acc: 0.9766 - val_loss: 0.0301 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0627 - acc: 0.9774 - val_loss: 0.0303 - val_acc: 0.9873\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0673 - acc: 0.9742 - val_loss: 0.0340 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0595 - acc: 0.9764 - val_loss: 0.0344 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9774 - val_loss: 0.0322 - val_acc: 0.9873\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0646 - acc: 0.9764 - val_loss: 0.0302 - val_acc: 0.9883\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0614 - acc: 0.9759 - val_loss: 0.0327 - val_acc: 0.9864\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0629 - acc: 0.9781 - val_loss: 0.0314 - val_acc: 0.9873\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.03007 to 0.02948, saving model to best.model\n",
      "0s - loss: 0.0561 - acc: 0.9810 - val_loss: 0.0295 - val_acc: 0.9873\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02948 to 0.02776, saving model to best.model\n",
      "0s - loss: 0.0629 - acc: 0.9761 - val_loss: 0.0278 - val_acc: 0.9893\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9761 - val_loss: 0.0286 - val_acc: 0.9893\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0604 - acc: 0.9791 - val_loss: 0.0295 - val_acc: 0.9864\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9805 - val_loss: 0.0284 - val_acc: 0.9864\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0539 - acc: 0.9783 - val_loss: 0.0294 - val_acc: 0.9883\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02776 to 0.02707, saving model to best.model\n",
      "0s - loss: 0.0540 - acc: 0.9808 - val_loss: 0.0271 - val_acc: 0.9893\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02707 to 0.02639, saving model to best.model\n",
      "0s - loss: 0.0541 - acc: 0.9781 - val_loss: 0.0264 - val_acc: 0.9873\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9788 - val_loss: 0.0295 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9837 - val_loss: 0.0277 - val_acc: 0.9883\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02639 to 0.02613, saving model to best.model\n",
      "0s - loss: 0.0472 - acc: 0.9820 - val_loss: 0.0261 - val_acc: 0.9873\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02613 to 0.02603, saving model to best.model\n",
      "0s - loss: 0.0494 - acc: 0.9813 - val_loss: 0.0260 - val_acc: 0.9883\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02603 to 0.02539, saving model to best.model\n",
      "0s - loss: 0.0540 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02539 to 0.02344, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9798 - val_loss: 0.0234 - val_acc: 0.9893\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.02344 to 0.02337, saving model to best.model\n",
      "0s - loss: 0.0526 - acc: 0.9810 - val_loss: 0.0234 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9815 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02337 to 0.02267, saving model to best.model\n",
      "0s - loss: 0.0480 - acc: 0.9798 - val_loss: 0.0227 - val_acc: 0.9893\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0448 - acc: 0.9815 - val_loss: 0.0230 - val_acc: 0.9893\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02267 to 0.02193, saving model to best.model\n",
      "0s - loss: 0.0493 - acc: 0.9817 - val_loss: 0.0219 - val_acc: 0.9893\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9808 - val_loss: 0.0223 - val_acc: 0.9893\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9866 - val_loss: 0.0225 - val_acc: 0.9893\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02193 to 0.02164, saving model to best.model\n",
      "0s - loss: 0.0476 - acc: 0.9820 - val_loss: 0.0216 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02164 to 0.02096, saving model to best.model\n",
      "0s - loss: 0.0482 - acc: 0.9822 - val_loss: 0.0210 - val_acc: 0.9893\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9844 - val_loss: 0.0223 - val_acc: 0.9893\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.02096 to 0.02001, saving model to best.model\n",
      "0s - loss: 0.0446 - acc: 0.9825 - val_loss: 0.0200 - val_acc: 0.9893\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02001 to 0.01997, saving model to best.model\n",
      "0s - loss: 0.0467 - acc: 0.9827 - val_loss: 0.0200 - val_acc: 0.9893\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0370 - acc: 0.9856 - val_loss: 0.0204 - val_acc: 0.9893\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01997 to 0.01963, saving model to best.model\n",
      "0s - loss: 0.0459 - acc: 0.9854 - val_loss: 0.0196 - val_acc: 0.9893\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9842 - val_loss: 0.0203 - val_acc: 0.9893\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9849 - val_loss: 0.0197 - val_acc: 0.9893\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01963 to 0.01850, saving model to best.model\n",
      "0s - loss: 0.0466 - acc: 0.9815 - val_loss: 0.0185 - val_acc: 0.9903\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0433 - acc: 0.9851 - val_loss: 0.0210 - val_acc: 0.9893\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0456 - acc: 0.9830 - val_loss: 0.0209 - val_acc: 0.9893\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01850 to 0.01821, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9839 - val_loss: 0.0182 - val_acc: 0.9912\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9837 - val_loss: 0.0204 - val_acc: 0.9893\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9844 - val_loss: 0.0186 - val_acc: 0.9893\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9820 - val_loss: 0.0197 - val_acc: 0.9893\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01821 to 0.01697, saving model to best.model\n",
      "0s - loss: 0.0397 - acc: 0.9866 - val_loss: 0.0170 - val_acc: 0.9912\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9830 - val_loss: 0.0182 - val_acc: 0.9903\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9830 - val_loss: 0.0188 - val_acc: 0.9893\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9866 - val_loss: 0.0207 - val_acc: 0.9893\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01697 to 0.01665, saving model to best.model\n",
      "0s - loss: 0.0382 - acc: 0.9849 - val_loss: 0.0166 - val_acc: 0.9903\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9825 - val_loss: 0.0175 - val_acc: 0.9893\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01665 to 0.01582, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9854 - val_loss: 0.0158 - val_acc: 0.9912\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9834 - val_loss: 0.0184 - val_acc: 0.9893\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9827 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9859 - val_loss: 0.0173 - val_acc: 0.9893\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01582 to 0.01537, saving model to best.model\n",
      "0s - loss: 0.0277 - acc: 0.9898 - val_loss: 0.0154 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01537 to 0.01471, saving model to best.model\n",
      "0s - loss: 0.0417 - acc: 0.9834 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9871 - val_loss: 0.0169 - val_acc: 0.9893\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01471 to 0.01298, saving model to best.model\n",
      "0s - loss: 0.0330 - acc: 0.9864 - val_loss: 0.0130 - val_acc: 0.9932\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9851 - val_loss: 0.0150 - val_acc: 0.9903\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9876 - val_loss: 0.0133 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9864 - val_loss: 0.0164 - val_acc: 0.9893\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9859 - val_loss: 0.0143 - val_acc: 0.9912\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9861 - val_loss: 0.0132 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9849 - val_loss: 0.0139 - val_acc: 0.9912\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9849 - val_loss: 0.0149 - val_acc: 0.9912\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9881 - val_loss: 0.0133 - val_acc: 0.9922\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01298 to 0.01294, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9864 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01294 to 0.01294, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9866 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9883 - val_loss: 0.0134 - val_acc: 0.9922\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01294 to 0.01194, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9873 - val_loss: 0.0119 - val_acc: 0.9922\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9876 - val_loss: 0.0149 - val_acc: 0.9912\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01194 to 0.01082, saving model to best.model\n",
      "0s - loss: 0.0334 - acc: 0.9878 - val_loss: 0.0108 - val_acc: 0.9961\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9878 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0391 - acc: 0.9861 - val_loss: 0.0127 - val_acc: 0.9961\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9881 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9866 - val_loss: 0.0132 - val_acc: 0.9922\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9861 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0132 - val_acc: 0.9922\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9866 - val_loss: 0.0118 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9886 - val_loss: 0.0130 - val_acc: 0.9912\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0242 - acc: 0.9905 - val_loss: 0.0119 - val_acc: 0.9912\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9893 - val_loss: 0.0116 - val_acc: 0.9912\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.01082 to 0.01037, saving model to best.model\n",
      "0s - loss: 0.0322 - acc: 0.9890 - val_loss: 0.0104 - val_acc: 0.9942\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.01037 to 0.00946, saving model to best.model\n",
      "0s - loss: 0.0299 - acc: 0.9859 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9881 - val_loss: 0.0132 - val_acc: 0.9912\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00946 to 0.00887, saving model to best.model\n",
      "0s - loss: 0.0297 - acc: 0.9881 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66357, saving model to best.model\n",
      "0s - loss: 0.7950 - acc: 0.5026 - val_loss: 0.6636 - val_acc: 0.7702\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66357 to 0.63122, saving model to best.model\n",
      "0s - loss: 0.7180 - acc: 0.5573 - val_loss: 0.6312 - val_acc: 0.7614\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63122 to 0.57599, saving model to best.model\n",
      "0s - loss: 0.6738 - acc: 0.5941 - val_loss: 0.5760 - val_acc: 0.7926\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.57599 to 0.50268, saving model to best.model\n",
      "0s - loss: 0.5960 - acc: 0.6815 - val_loss: 0.5027 - val_acc: 0.7770\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50268 to 0.44133, saving model to best.model\n",
      "0s - loss: 0.5084 - acc: 0.7655 - val_loss: 0.4413 - val_acc: 0.8014\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44133 to 0.40038, saving model to best.model\n",
      "0s - loss: 0.4442 - acc: 0.8025 - val_loss: 0.4004 - val_acc: 0.8306\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40038 to 0.37001, saving model to best.model\n",
      "0s - loss: 0.4135 - acc: 0.8235 - val_loss: 0.3700 - val_acc: 0.8471\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37001 to 0.34721, saving model to best.model\n",
      "0s - loss: 0.3911 - acc: 0.8364 - val_loss: 0.3472 - val_acc: 0.8608\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34721 to 0.33054, saving model to best.model\n",
      "0s - loss: 0.3747 - acc: 0.8551 - val_loss: 0.3305 - val_acc: 0.8705\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33054 to 0.31379, saving model to best.model\n",
      "0s - loss: 0.3423 - acc: 0.8629 - val_loss: 0.3138 - val_acc: 0.8754\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31379 to 0.29965, saving model to best.model\n",
      "0s - loss: 0.3338 - acc: 0.8710 - val_loss: 0.2997 - val_acc: 0.8822\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29965 to 0.28983, saving model to best.model\n",
      "0s - loss: 0.3292 - acc: 0.8724 - val_loss: 0.2898 - val_acc: 0.8832\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28983 to 0.27556, saving model to best.model\n",
      "0s - loss: 0.3112 - acc: 0.8856 - val_loss: 0.2756 - val_acc: 0.8909\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27556 to 0.26871, saving model to best.model\n",
      "0s - loss: 0.3021 - acc: 0.8865 - val_loss: 0.2687 - val_acc: 0.8958\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26871 to 0.26006, saving model to best.model\n",
      "0s - loss: 0.2978 - acc: 0.8895 - val_loss: 0.2601 - val_acc: 0.9036\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2896 - acc: 0.8909 - val_loss: 0.2607 - val_acc: 0.9036\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26006 to 0.24869, saving model to best.model\n",
      "0s - loss: 0.2770 - acc: 0.8958 - val_loss: 0.2487 - val_acc: 0.9094\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24869 to 0.24309, saving model to best.model\n",
      "0s - loss: 0.2750 - acc: 0.8963 - val_loss: 0.2431 - val_acc: 0.9163\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24309 to 0.23803, saving model to best.model\n",
      "0s - loss: 0.2717 - acc: 0.8965 - val_loss: 0.2380 - val_acc: 0.9182\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23803 to 0.23366, saving model to best.model\n",
      "0s - loss: 0.2728 - acc: 0.9002 - val_loss: 0.2337 - val_acc: 0.9163\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23366 to 0.22826, saving model to best.model\n",
      "0s - loss: 0.2530 - acc: 0.9070 - val_loss: 0.2283 - val_acc: 0.9192\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22826 to 0.22434, saving model to best.model\n",
      "0s - loss: 0.2574 - acc: 0.9050 - val_loss: 0.2243 - val_acc: 0.9202\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2495 - acc: 0.9089 - val_loss: 0.2265 - val_acc: 0.9163\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22434 to 0.21603, saving model to best.model\n",
      "0s - loss: 0.2387 - acc: 0.9123 - val_loss: 0.2160 - val_acc: 0.9202\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21603 to 0.21306, saving model to best.model\n",
      "0s - loss: 0.2443 - acc: 0.9097 - val_loss: 0.2131 - val_acc: 0.9202\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21306 to 0.20974, saving model to best.model\n",
      "0s - loss: 0.2320 - acc: 0.9148 - val_loss: 0.2097 - val_acc: 0.9241\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20974 to 0.20635, saving model to best.model\n",
      "0s - loss: 0.2306 - acc: 0.9114 - val_loss: 0.2064 - val_acc: 0.9241\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20635 to 0.20226, saving model to best.model\n",
      "0s - loss: 0.2251 - acc: 0.9119 - val_loss: 0.2023 - val_acc: 0.9289\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20226 to 0.19795, saving model to best.model\n",
      "0s - loss: 0.2287 - acc: 0.9145 - val_loss: 0.1980 - val_acc: 0.9289\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19795 to 0.19564, saving model to best.model\n",
      "0s - loss: 0.2241 - acc: 0.9187 - val_loss: 0.1956 - val_acc: 0.9250\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19564 to 0.19395, saving model to best.model\n",
      "0s - loss: 0.2159 - acc: 0.9177 - val_loss: 0.1939 - val_acc: 0.9250\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19395 to 0.18717, saving model to best.model\n",
      "0s - loss: 0.2223 - acc: 0.9136 - val_loss: 0.1872 - val_acc: 0.9328\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18717 to 0.18402, saving model to best.model\n",
      "0s - loss: 0.2105 - acc: 0.9172 - val_loss: 0.1840 - val_acc: 0.9309\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18402 to 0.18020, saving model to best.model\n",
      "0s - loss: 0.2070 - acc: 0.9206 - val_loss: 0.1802 - val_acc: 0.9328\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18020 to 0.17507, saving model to best.model\n",
      "0s - loss: 0.2099 - acc: 0.9211 - val_loss: 0.1751 - val_acc: 0.9328\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2000 - acc: 0.9238 - val_loss: 0.1802 - val_acc: 0.9279\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17507 to 0.16863, saving model to best.model\n",
      "0s - loss: 0.2000 - acc: 0.9250 - val_loss: 0.1686 - val_acc: 0.9328\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16863 to 0.16519, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9245 - val_loss: 0.1652 - val_acc: 0.9357\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16519 to 0.16100, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9289 - val_loss: 0.1610 - val_acc: 0.9348\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16100 to 0.15685, saving model to best.model\n",
      "0s - loss: 0.1841 - acc: 0.9311 - val_loss: 0.1568 - val_acc: 0.9367\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15685 to 0.15395, saving model to best.model\n",
      "0s - loss: 0.1809 - acc: 0.9328 - val_loss: 0.1540 - val_acc: 0.9367\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15395 to 0.14866, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9328 - val_loss: 0.1487 - val_acc: 0.9387\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.14866 to 0.14803, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9318 - val_loss: 0.1480 - val_acc: 0.9367\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14803 to 0.14046, saving model to best.model\n",
      "0s - loss: 0.1687 - acc: 0.9379 - val_loss: 0.1405 - val_acc: 0.9416\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14046 to 0.14021, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9350 - val_loss: 0.1402 - val_acc: 0.9348\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14021 to 0.13308, saving model to best.model\n",
      "0s - loss: 0.1601 - acc: 0.9423 - val_loss: 0.1331 - val_acc: 0.9377\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13308 to 0.12833, saving model to best.model\n",
      "0s - loss: 0.1559 - acc: 0.9433 - val_loss: 0.1283 - val_acc: 0.9464\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.12833 to 0.12765, saving model to best.model\n",
      "0s - loss: 0.1563 - acc: 0.9401 - val_loss: 0.1277 - val_acc: 0.9387\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12765 to 0.12629, saving model to best.model\n",
      "0s - loss: 0.1524 - acc: 0.9464 - val_loss: 0.1263 - val_acc: 0.9396\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12629 to 0.11979, saving model to best.model\n",
      "0s - loss: 0.1487 - acc: 0.9423 - val_loss: 0.1198 - val_acc: 0.9533\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11979 to 0.11904, saving model to best.model\n",
      "0s - loss: 0.1475 - acc: 0.9469 - val_loss: 0.1190 - val_acc: 0.9474\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11904 to 0.11209, saving model to best.model\n",
      "0s - loss: 0.1450 - acc: 0.9479 - val_loss: 0.1121 - val_acc: 0.9572\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11209 to 0.10965, saving model to best.model\n",
      "0s - loss: 0.1455 - acc: 0.9469 - val_loss: 0.1096 - val_acc: 0.9591\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1461 - acc: 0.9496 - val_loss: 0.1101 - val_acc: 0.9542\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10965 to 0.10504, saving model to best.model\n",
      "0s - loss: 0.1377 - acc: 0.9501 - val_loss: 0.1050 - val_acc: 0.9611\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.10504 to 0.10304, saving model to best.model\n",
      "0s - loss: 0.1399 - acc: 0.9518 - val_loss: 0.1030 - val_acc: 0.9591\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10304 to 0.10012, saving model to best.model\n",
      "0s - loss: 0.1306 - acc: 0.9537 - val_loss: 0.1001 - val_acc: 0.9630\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1311 - acc: 0.9518 - val_loss: 0.1029 - val_acc: 0.9620\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.10012 to 0.09547, saving model to best.model\n",
      "0s - loss: 0.1344 - acc: 0.9459 - val_loss: 0.0955 - val_acc: 0.9630\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09547 to 0.09390, saving model to best.model\n",
      "0s - loss: 0.1258 - acc: 0.9528 - val_loss: 0.0939 - val_acc: 0.9640\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09390 to 0.09145, saving model to best.model\n",
      "0s - loss: 0.1234 - acc: 0.9494 - val_loss: 0.0915 - val_acc: 0.9659\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.09145 to 0.08921, saving model to best.model\n",
      "0s - loss: 0.1250 - acc: 0.9518 - val_loss: 0.0892 - val_acc: 0.9649\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08921 to 0.08651, saving model to best.model\n",
      "0s - loss: 0.1165 - acc: 0.9564 - val_loss: 0.0865 - val_acc: 0.9659\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08651 to 0.08596, saving model to best.model\n",
      "0s - loss: 0.1164 - acc: 0.9574 - val_loss: 0.0860 - val_acc: 0.9727\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08596 to 0.08117, saving model to best.model\n",
      "0s - loss: 0.1118 - acc: 0.9589 - val_loss: 0.0812 - val_acc: 0.9669\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08117 to 0.08031, saving model to best.model\n",
      "0s - loss: 0.1049 - acc: 0.9627 - val_loss: 0.0803 - val_acc: 0.9727\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.08031 to 0.07813, saving model to best.model\n",
      "0s - loss: 0.1044 - acc: 0.9603 - val_loss: 0.0781 - val_acc: 0.9727\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07813 to 0.07771, saving model to best.model\n",
      "0s - loss: 0.1092 - acc: 0.9601 - val_loss: 0.0777 - val_acc: 0.9757\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07771 to 0.07460, saving model to best.model\n",
      "0s - loss: 0.1177 - acc: 0.9584 - val_loss: 0.0746 - val_acc: 0.9757\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07460 to 0.07281, saving model to best.model\n",
      "0s - loss: 0.1012 - acc: 0.9610 - val_loss: 0.0728 - val_acc: 0.9757\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1028 - acc: 0.9610 - val_loss: 0.0774 - val_acc: 0.9786\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07281 to 0.07241, saving model to best.model\n",
      "0s - loss: 0.1109 - acc: 0.9593 - val_loss: 0.0724 - val_acc: 0.9727\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.0954 - acc: 0.9632 - val_loss: 0.0743 - val_acc: 0.9796\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07241 to 0.06719, saving model to best.model\n",
      "0s - loss: 0.0969 - acc: 0.9664 - val_loss: 0.0672 - val_acc: 0.9776\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06719 to 0.06521, saving model to best.model\n",
      "0s - loss: 0.1024 - acc: 0.9618 - val_loss: 0.0652 - val_acc: 0.9766\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06521 to 0.06444, saving model to best.model\n",
      "0s - loss: 0.0944 - acc: 0.9669 - val_loss: 0.0644 - val_acc: 0.9805\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06444 to 0.06272, saving model to best.model\n",
      "0s - loss: 0.1011 - acc: 0.9657 - val_loss: 0.0627 - val_acc: 0.9815\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06272 to 0.06041, saving model to best.model\n",
      "0s - loss: 0.0895 - acc: 0.9671 - val_loss: 0.0604 - val_acc: 0.9805\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0968 - acc: 0.9657 - val_loss: 0.0662 - val_acc: 0.9776\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06041 to 0.05992, saving model to best.model\n",
      "0s - loss: 0.0932 - acc: 0.9686 - val_loss: 0.0599 - val_acc: 0.9825\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05992 to 0.05718, saving model to best.model\n",
      "0s - loss: 0.0824 - acc: 0.9698 - val_loss: 0.0572 - val_acc: 0.9825\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05718 to 0.05595, saving model to best.model\n",
      "0s - loss: 0.0881 - acc: 0.9681 - val_loss: 0.0560 - val_acc: 0.9825\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05595 to 0.05444, saving model to best.model\n",
      "0s - loss: 0.0813 - acc: 0.9705 - val_loss: 0.0544 - val_acc: 0.9825\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05444 to 0.05288, saving model to best.model\n",
      "0s - loss: 0.0850 - acc: 0.9698 - val_loss: 0.0529 - val_acc: 0.9825\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0775 - acc: 0.9722 - val_loss: 0.0531 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05288 to 0.05105, saving model to best.model\n",
      "0s - loss: 0.0809 - acc: 0.9725 - val_loss: 0.0510 - val_acc: 0.9805\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0787 - acc: 0.9737 - val_loss: 0.0552 - val_acc: 0.9834\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05105 to 0.04910, saving model to best.model\n",
      "0s - loss: 0.0771 - acc: 0.9720 - val_loss: 0.0491 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0713 - acc: 0.9757 - val_loss: 0.0505 - val_acc: 0.9825\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0756 - acc: 0.9730 - val_loss: 0.0495 - val_acc: 0.9825\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04910 to 0.04654, saving model to best.model\n",
      "0s - loss: 0.0781 - acc: 0.9725 - val_loss: 0.0465 - val_acc: 0.9834\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04654 to 0.04592, saving model to best.model\n",
      "0s - loss: 0.0715 - acc: 0.9735 - val_loss: 0.0459 - val_acc: 0.9844\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0732 - acc: 0.9710 - val_loss: 0.0461 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04592 to 0.04489, saving model to best.model\n",
      "0s - loss: 0.0702 - acc: 0.9752 - val_loss: 0.0449 - val_acc: 0.9844\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0697 - acc: 0.9747 - val_loss: 0.0451 - val_acc: 0.9844\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04489 to 0.04278, saving model to best.model\n",
      "0s - loss: 0.0580 - acc: 0.9805 - val_loss: 0.0428 - val_acc: 0.9854\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04278 to 0.04094, saving model to best.model\n",
      "0s - loss: 0.0779 - acc: 0.9720 - val_loss: 0.0409 - val_acc: 0.9864\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0752 - acc: 0.9727 - val_loss: 0.0488 - val_acc: 0.9825\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0673 - acc: 0.9732 - val_loss: 0.0410 - val_acc: 0.9864\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04094 to 0.04066, saving model to best.model\n",
      "0s - loss: 0.0636 - acc: 0.9771 - val_loss: 0.0407 - val_acc: 0.9864\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04066 to 0.04011, saving model to best.model\n",
      "0s - loss: 0.0637 - acc: 0.9764 - val_loss: 0.0401 - val_acc: 0.9864\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04011 to 0.03764, saving model to best.model\n",
      "0s - loss: 0.0667 - acc: 0.9730 - val_loss: 0.0376 - val_acc: 0.9873\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0617 - acc: 0.9761 - val_loss: 0.0388 - val_acc: 0.9864\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03764 to 0.03741, saving model to best.model\n",
      "0s - loss: 0.0607 - acc: 0.9781 - val_loss: 0.0374 - val_acc: 0.9864\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0647 - acc: 0.9757 - val_loss: 0.0424 - val_acc: 0.9864\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03741 to 0.03641, saving model to best.model\n",
      "0s - loss: 0.0616 - acc: 0.9783 - val_loss: 0.0364 - val_acc: 0.9864\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0625 - acc: 0.9769 - val_loss: 0.0373 - val_acc: 0.9864\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03641 to 0.03438, saving model to best.model\n",
      "0s - loss: 0.0573 - acc: 0.9800 - val_loss: 0.0344 - val_acc: 0.9864\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0542 - acc: 0.9798 - val_loss: 0.0348 - val_acc: 0.9864\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03438 to 0.03343, saving model to best.model\n",
      "0s - loss: 0.0582 - acc: 0.9791 - val_loss: 0.0334 - val_acc: 0.9873\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0577 - acc: 0.9791 - val_loss: 0.0334 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0660 - acc: 0.9761 - val_loss: 0.0385 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03343 to 0.03219, saving model to best.model\n",
      "0s - loss: 0.0521 - acc: 0.9810 - val_loss: 0.0322 - val_acc: 0.9864\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.03219 to 0.03211, saving model to best.model\n",
      "0s - loss: 0.0520 - acc: 0.9813 - val_loss: 0.0321 - val_acc: 0.9873\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03211 to 0.03138, saving model to best.model\n",
      "0s - loss: 0.0560 - acc: 0.9788 - val_loss: 0.0314 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0557 - acc: 0.9800 - val_loss: 0.0327 - val_acc: 0.9864\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.03138 to 0.02861, saving model to best.model\n",
      "0s - loss: 0.0523 - acc: 0.9813 - val_loss: 0.0286 - val_acc: 0.9864\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0549 - acc: 0.9808 - val_loss: 0.0320 - val_acc: 0.9893\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02861 to 0.02725, saving model to best.model\n",
      "0s - loss: 0.0517 - acc: 0.9825 - val_loss: 0.0272 - val_acc: 0.9864\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9834 - val_loss: 0.0324 - val_acc: 0.9893\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0499 - acc: 0.9815 - val_loss: 0.0276 - val_acc: 0.9873\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02725 to 0.02672, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9834 - val_loss: 0.0267 - val_acc: 0.9883\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9817 - val_loss: 0.0338 - val_acc: 0.9883\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02672 to 0.02605, saving model to best.model\n",
      "0s - loss: 0.0526 - acc: 0.9820 - val_loss: 0.0260 - val_acc: 0.9864\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02605 to 0.02547, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9822 - val_loss: 0.0255 - val_acc: 0.9873\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9820 - val_loss: 0.0264 - val_acc: 0.9873\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0550 - acc: 0.9820 - val_loss: 0.0274 - val_acc: 0.9883\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02547 to 0.02520, saving model to best.model\n",
      "0s - loss: 0.0487 - acc: 0.9822 - val_loss: 0.0252 - val_acc: 0.9893\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02520 to 0.02518, saving model to best.model\n",
      "0s - loss: 0.0448 - acc: 0.9839 - val_loss: 0.0252 - val_acc: 0.9883\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9844 - val_loss: 0.0256 - val_acc: 0.9883\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02518 to 0.02360, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9847 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9837 - val_loss: 0.0259 - val_acc: 0.9903\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02360 to 0.02221, saving model to best.model\n",
      "0s - loss: 0.0491 - acc: 0.9822 - val_loss: 0.0222 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0505 - acc: 0.9795 - val_loss: 0.0224 - val_acc: 0.9893\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0532 - acc: 0.9815 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9832 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9825 - val_loss: 0.0235 - val_acc: 0.9883\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9844 - val_loss: 0.0233 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9859 - val_loss: 0.0228 - val_acc: 0.9893\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0476 - acc: 0.9815 - val_loss: 0.0300 - val_acc: 0.9873\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9830 - val_loss: 0.0233 - val_acc: 0.9893\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9861 - val_loss: 0.0257 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9876 - val_loss: 0.0224 - val_acc: 0.9883\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9864 - val_loss: 0.0238 - val_acc: 0.9903\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.02221 to 0.01999, saving model to best.model\n",
      "0s - loss: 0.0408 - acc: 0.9844 - val_loss: 0.0200 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9837 - val_loss: 0.0205 - val_acc: 0.9903\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9830 - val_loss: 0.0212 - val_acc: 0.9903\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9876 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0457 - acc: 0.9837 - val_loss: 0.0205 - val_acc: 0.9903\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9847 - val_loss: 0.0203 - val_acc: 0.9922\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01999 to 0.01993, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9849 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.01993 to 0.01779, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9859 - val_loss: 0.0178 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9873 - val_loss: 0.0180 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9854 - val_loss: 0.0186 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9876 - val_loss: 0.0197 - val_acc: 0.9912\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01779 to 0.01767, saving model to best.model\n",
      "0s - loss: 0.0435 - acc: 0.9851 - val_loss: 0.0177 - val_acc: 0.9912\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0296 - acc: 0.9890 - val_loss: 0.0180 - val_acc: 0.9903\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01767 to 0.01619, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0162 - val_acc: 0.9922\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01619 to 0.01519, saving model to best.model\n",
      "0s - loss: 0.0351 - acc: 0.9856 - val_loss: 0.0152 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9854 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9864 - val_loss: 0.0158 - val_acc: 0.9912\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9873 - val_loss: 0.0189 - val_acc: 0.9912\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9878 - val_loss: 0.0164 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9900 - val_loss: 0.0157 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01519 to 0.01435, saving model to best.model\n",
      "0s - loss: 0.0297 - acc: 0.9883 - val_loss: 0.0144 - val_acc: 0.9922\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9886 - val_loss: 0.0189 - val_acc: 0.9903\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01435 to 0.01316, saving model to best.model\n",
      "0s - loss: 0.0273 - acc: 0.9903 - val_loss: 0.0132 - val_acc: 0.9922\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9900 - val_loss: 0.0148 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01316 to 0.01203, saving model to best.model\n",
      "0s - loss: 0.0378 - acc: 0.9854 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9873 - val_loss: 0.0184 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0141 - val_acc: 0.9912\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9898 - val_loss: 0.0121 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9886 - val_loss: 0.0131 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9893 - val_loss: 0.0154 - val_acc: 0.9912\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9876 - val_loss: 0.0124 - val_acc: 0.9922\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0138 - val_acc: 0.9922\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01203 to 0.01098, saving model to best.model\n",
      "0s - loss: 0.0322 - acc: 0.9873 - val_loss: 0.0110 - val_acc: 0.9942\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9869 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9895 - val_loss: 0.0150 - val_acc: 0.9903\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01098 to 0.01069, saving model to best.model\n",
      "0s - loss: 0.0324 - acc: 0.9871 - val_loss: 0.0107 - val_acc: 0.9942\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9888 - val_loss: 0.0150 - val_acc: 0.9912\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01069 to 0.01066, saving model to best.model\n",
      "0s - loss: 0.0320 - acc: 0.9905 - val_loss: 0.0107 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9878 - val_loss: 0.0134 - val_acc: 0.9912\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.01066 to 0.01028, saving model to best.model\n",
      "0s - loss: 0.0292 - acc: 0.9890 - val_loss: 0.0103 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0238 - acc: 0.9905 - val_loss: 0.0118 - val_acc: 0.9922\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0251 - acc: 0.9905 - val_loss: 0.0118 - val_acc: 0.9922\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.01028 to 0.00947, saving model to best.model\n",
      "0s - loss: 0.0372 - acc: 0.9864 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0300 - acc: 0.9886 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9856 - val_loss: 0.0118 - val_acc: 0.9932\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9895 - val_loss: 0.0111 - val_acc: 0.9932\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9847 - val_loss: 0.0109 - val_acc: 0.9922\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0236 - acc: 0.9922 - val_loss: 0.0106 - val_acc: 0.9932\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0222 - acc: 0.9917 - val_loss: 0.0101 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9893 - val_loss: 0.0112 - val_acc: 0.9932\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9873 - val_loss: 0.0115 - val_acc: 0.9932\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0259 - acc: 0.9881 - val_loss: 0.0112 - val_acc: 0.9932\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0220 - acc: 0.9915 - val_loss: 0.0101 - val_acc: 0.9942\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0266 - acc: 0.9890 - val_loss: 0.0116 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.00947 to 0.00882, saving model to best.model\n",
      "0s - loss: 0.0306 - acc: 0.9883 - val_loss: 0.0088 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0247 - acc: 0.9927 - val_loss: 0.0100 - val_acc: 0.9922\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.69460, saving model to best.model\n",
      "0s - loss: 0.8610 - acc: 0.5052 - val_loss: 0.6946 - val_acc: 0.4576\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.69460 to 0.65981, saving model to best.model\n",
      "0s - loss: 0.7833 - acc: 0.5174 - val_loss: 0.6598 - val_acc: 0.5424\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65981 to 0.61770, saving model to best.model\n",
      "0s - loss: 0.7313 - acc: 0.5478 - val_loss: 0.6177 - val_acc: 0.7945\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61770 to 0.54826, saving model to best.model\n",
      "0s - loss: 0.6609 - acc: 0.6114 - val_loss: 0.5483 - val_acc: 0.8160\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54826 to 0.47388, saving model to best.model\n",
      "0s - loss: 0.5968 - acc: 0.6859 - val_loss: 0.4739 - val_acc: 0.8247\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47388 to 0.41523, saving model to best.model\n",
      "0s - loss: 0.5188 - acc: 0.7495 - val_loss: 0.4152 - val_acc: 0.8442\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41523 to 0.37311, saving model to best.model\n",
      "0s - loss: 0.4803 - acc: 0.7828 - val_loss: 0.3731 - val_acc: 0.8578\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37311 to 0.34573, saving model to best.model\n",
      "0s - loss: 0.4377 - acc: 0.8057 - val_loss: 0.3457 - val_acc: 0.8783\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34573 to 0.32536, saving model to best.model\n",
      "0s - loss: 0.4064 - acc: 0.8352 - val_loss: 0.3254 - val_acc: 0.8812\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32536 to 0.32000, saving model to best.model\n",
      "0s - loss: 0.3857 - acc: 0.8432 - val_loss: 0.3200 - val_acc: 0.8880\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.32000 to 0.29910, saving model to best.model\n",
      "0s - loss: 0.3790 - acc: 0.8461 - val_loss: 0.2991 - val_acc: 0.8870\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29910 to 0.28739, saving model to best.model\n",
      "0s - loss: 0.3611 - acc: 0.8602 - val_loss: 0.2874 - val_acc: 0.8890\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28739 to 0.27939, saving model to best.model\n",
      "0s - loss: 0.3372 - acc: 0.8688 - val_loss: 0.2794 - val_acc: 0.8900\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27939 to 0.27141, saving model to best.model\n",
      "0s - loss: 0.3253 - acc: 0.8756 - val_loss: 0.2714 - val_acc: 0.8919\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27141 to 0.26465, saving model to best.model\n",
      "0s - loss: 0.3154 - acc: 0.8763 - val_loss: 0.2647 - val_acc: 0.8968\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26465 to 0.25891, saving model to best.model\n",
      "0s - loss: 0.3092 - acc: 0.8822 - val_loss: 0.2589 - val_acc: 0.9104\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25891 to 0.25612, saving model to best.model\n",
      "0s - loss: 0.3001 - acc: 0.8848 - val_loss: 0.2561 - val_acc: 0.9085\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25612 to 0.25179, saving model to best.model\n",
      "0s - loss: 0.2927 - acc: 0.8907 - val_loss: 0.2518 - val_acc: 0.9104\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.25179 to 0.24757, saving model to best.model\n",
      "0s - loss: 0.2974 - acc: 0.8916 - val_loss: 0.2476 - val_acc: 0.9202\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24757 to 0.24312, saving model to best.model\n",
      "0s - loss: 0.2815 - acc: 0.8987 - val_loss: 0.2431 - val_acc: 0.9211\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.24312 to 0.23939, saving model to best.model\n",
      "0s - loss: 0.2701 - acc: 0.9011 - val_loss: 0.2394 - val_acc: 0.9231\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23939 to 0.23737, saving model to best.model\n",
      "0s - loss: 0.2612 - acc: 0.9011 - val_loss: 0.2374 - val_acc: 0.9221\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23737 to 0.23468, saving model to best.model\n",
      "0s - loss: 0.2712 - acc: 0.9011 - val_loss: 0.2347 - val_acc: 0.9221\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.23468 to 0.23207, saving model to best.model\n",
      "0s - loss: 0.2559 - acc: 0.9097 - val_loss: 0.2321 - val_acc: 0.9231\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.23207 to 0.22756, saving model to best.model\n",
      "0s - loss: 0.2563 - acc: 0.9014 - val_loss: 0.2276 - val_acc: 0.9241\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.22756 to 0.22682, saving model to best.model\n",
      "0s - loss: 0.2575 - acc: 0.9048 - val_loss: 0.2268 - val_acc: 0.9241\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.22682 to 0.22331, saving model to best.model\n",
      "0s - loss: 0.2485 - acc: 0.9106 - val_loss: 0.2233 - val_acc: 0.9250\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.22331 to 0.21901, saving model to best.model\n",
      "0s - loss: 0.2439 - acc: 0.9099 - val_loss: 0.2190 - val_acc: 0.9250\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.21901 to 0.21824, saving model to best.model\n",
      "0s - loss: 0.2383 - acc: 0.9145 - val_loss: 0.2182 - val_acc: 0.9260\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2329 - acc: 0.9155 - val_loss: 0.2187 - val_acc: 0.9250\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.21824 to 0.21415, saving model to best.model\n",
      "0s - loss: 0.2367 - acc: 0.9158 - val_loss: 0.2142 - val_acc: 0.9279\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.21415 to 0.21403, saving model to best.model\n",
      "0s - loss: 0.2212 - acc: 0.9216 - val_loss: 0.2140 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.21403 to 0.20734, saving model to best.model\n",
      "0s - loss: 0.2231 - acc: 0.9209 - val_loss: 0.2073 - val_acc: 0.9289\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.20734 to 0.20477, saving model to best.model\n",
      "0s - loss: 0.2201 - acc: 0.9170 - val_loss: 0.2048 - val_acc: 0.9299\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.20477 to 0.20182, saving model to best.model\n",
      "0s - loss: 0.2194 - acc: 0.9226 - val_loss: 0.2018 - val_acc: 0.9309\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.20182 to 0.19785, saving model to best.model\n",
      "0s - loss: 0.2131 - acc: 0.9214 - val_loss: 0.1979 - val_acc: 0.9318\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19785 to 0.19731, saving model to best.model\n",
      "0s - loss: 0.2059 - acc: 0.9282 - val_loss: 0.1973 - val_acc: 0.9270\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19731 to 0.19584, saving model to best.model\n",
      "0s - loss: 0.2019 - acc: 0.9267 - val_loss: 0.1958 - val_acc: 0.9299\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19584 to 0.19288, saving model to best.model\n",
      "0s - loss: 0.2076 - acc: 0.9265 - val_loss: 0.1929 - val_acc: 0.9328\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19288 to 0.19147, saving model to best.model\n",
      "0s - loss: 0.2060 - acc: 0.9279 - val_loss: 0.1915 - val_acc: 0.9416\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19147 to 0.18750, saving model to best.model\n",
      "0s - loss: 0.1994 - acc: 0.9257 - val_loss: 0.1875 - val_acc: 0.9357\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18750 to 0.18536, saving model to best.model\n",
      "0s - loss: 0.1917 - acc: 0.9364 - val_loss: 0.1854 - val_acc: 0.9328\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18536 to 0.18291, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9350 - val_loss: 0.1829 - val_acc: 0.9348\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18291 to 0.18195, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9352 - val_loss: 0.1820 - val_acc: 0.9348\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.18195 to 0.17592, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9384 - val_loss: 0.1759 - val_acc: 0.9426\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1844 - acc: 0.9343 - val_loss: 0.1762 - val_acc: 0.9338\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.17592 to 0.16780, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9357 - val_loss: 0.1678 - val_acc: 0.9445\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.16780 to 0.16670, saving model to best.model\n",
      "0s - loss: 0.1721 - acc: 0.9379 - val_loss: 0.1667 - val_acc: 0.9426\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.16670 to 0.16468, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9369 - val_loss: 0.1647 - val_acc: 0.9464\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1712 - acc: 0.9401 - val_loss: 0.1661 - val_acc: 0.9348\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.16468 to 0.15577, saving model to best.model\n",
      "0s - loss: 0.1656 - acc: 0.9423 - val_loss: 0.1558 - val_acc: 0.9484\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.15577 to 0.15340, saving model to best.model\n",
      "0s - loss: 0.1659 - acc: 0.9413 - val_loss: 0.1534 - val_acc: 0.9474\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.15340 to 0.14923, saving model to best.model\n",
      "0s - loss: 0.1556 - acc: 0.9423 - val_loss: 0.1492 - val_acc: 0.9503\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.14923 to 0.14582, saving model to best.model\n",
      "0s - loss: 0.1560 - acc: 0.9416 - val_loss: 0.1458 - val_acc: 0.9533\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9401 - val_loss: 0.1565 - val_acc: 0.9367\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.14582 to 0.13847, saving model to best.model\n",
      "0s - loss: 0.1595 - acc: 0.9440 - val_loss: 0.1385 - val_acc: 0.9542\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.13847 to 0.13487, saving model to best.model\n",
      "0s - loss: 0.1479 - acc: 0.9457 - val_loss: 0.1349 - val_acc: 0.9523\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1465 - acc: 0.9486 - val_loss: 0.1352 - val_acc: 0.9503\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1512 - acc: 0.9494 - val_loss: 0.1450 - val_acc: 0.9435\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.13487 to 0.12871, saving model to best.model\n",
      "0s - loss: 0.1592 - acc: 0.9428 - val_loss: 0.1287 - val_acc: 0.9620\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.12871 to 0.12770, saving model to best.model\n",
      "0s - loss: 0.1403 - acc: 0.9459 - val_loss: 0.1277 - val_acc: 0.9562\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.12770 to 0.12304, saving model to best.model\n",
      "0s - loss: 0.1401 - acc: 0.9513 - val_loss: 0.1230 - val_acc: 0.9562\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.12304 to 0.11879, saving model to best.model\n",
      "0s - loss: 0.1393 - acc: 0.9503 - val_loss: 0.1188 - val_acc: 0.9562\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.11879 to 0.11596, saving model to best.model\n",
      "0s - loss: 0.1318 - acc: 0.9469 - val_loss: 0.1160 - val_acc: 0.9581\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.11596 to 0.11055, saving model to best.model\n",
      "0s - loss: 0.1377 - acc: 0.9464 - val_loss: 0.1105 - val_acc: 0.9630\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1245 - acc: 0.9520 - val_loss: 0.1119 - val_acc: 0.9620\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.11055 to 0.10892, saving model to best.model\n",
      "0s - loss: 0.1263 - acc: 0.9552 - val_loss: 0.1089 - val_acc: 0.9640\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1265 - acc: 0.9564 - val_loss: 0.1154 - val_acc: 0.9630\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1226 - acc: 0.9569 - val_loss: 0.1092 - val_acc: 0.9640\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.10892 to 0.10198, saving model to best.model\n",
      "0s - loss: 0.1243 - acc: 0.9530 - val_loss: 0.1020 - val_acc: 0.9640\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1227 - acc: 0.9591 - val_loss: 0.1081 - val_acc: 0.9640\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1178 - acc: 0.9574 - val_loss: 0.1021 - val_acc: 0.9620\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.10198 to 0.09924, saving model to best.model\n",
      "0s - loss: 0.1167 - acc: 0.9589 - val_loss: 0.0992 - val_acc: 0.9659\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.09924 to 0.09644, saving model to best.model\n",
      "0s - loss: 0.1141 - acc: 0.9610 - val_loss: 0.0964 - val_acc: 0.9640\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1183 - acc: 0.9608 - val_loss: 0.1026 - val_acc: 0.9679\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.09644 to 0.09292, saving model to best.model\n",
      "0s - loss: 0.1042 - acc: 0.9642 - val_loss: 0.0929 - val_acc: 0.9669\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1033 - acc: 0.9630 - val_loss: 0.0946 - val_acc: 0.9698\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.09292 to 0.08975, saving model to best.model\n",
      "0s - loss: 0.1004 - acc: 0.9610 - val_loss: 0.0898 - val_acc: 0.9679\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1044 - acc: 0.9640 - val_loss: 0.0915 - val_acc: 0.9708\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.08975 to 0.08623, saving model to best.model\n",
      "0s - loss: 0.0946 - acc: 0.9649 - val_loss: 0.0862 - val_acc: 0.9679\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0934 - acc: 0.9664 - val_loss: 0.0878 - val_acc: 0.9737\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.08623 to 0.08366, saving model to best.model\n",
      "0s - loss: 0.1000 - acc: 0.9652 - val_loss: 0.0837 - val_acc: 0.9727\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.08366 to 0.07705, saving model to best.model\n",
      "0s - loss: 0.0998 - acc: 0.9637 - val_loss: 0.0770 - val_acc: 0.9708\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0978 - acc: 0.9647 - val_loss: 0.0844 - val_acc: 0.9718\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.07705 to 0.07420, saving model to best.model\n",
      "0s - loss: 0.0936 - acc: 0.9645 - val_loss: 0.0742 - val_acc: 0.9727\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.07420 to 0.07277, saving model to best.model\n",
      "0s - loss: 0.0997 - acc: 0.9603 - val_loss: 0.0728 - val_acc: 0.9698\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0898 - acc: 0.9662 - val_loss: 0.0753 - val_acc: 0.9757\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0944 - acc: 0.9632 - val_loss: 0.0812 - val_acc: 0.9786\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.07277 to 0.07019, saving model to best.model\n",
      "0s - loss: 0.0955 - acc: 0.9642 - val_loss: 0.0702 - val_acc: 0.9708\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0864 - acc: 0.9679 - val_loss: 0.0726 - val_acc: 0.9776\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0762 - acc: 0.9720 - val_loss: 0.0729 - val_acc: 0.9786\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.07019 to 0.06685, saving model to best.model\n",
      "0s - loss: 0.0850 - acc: 0.9718 - val_loss: 0.0669 - val_acc: 0.9786\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.06685 to 0.06602, saving model to best.model\n",
      "0s - loss: 0.0836 - acc: 0.9725 - val_loss: 0.0660 - val_acc: 0.9786\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.06602 to 0.06228, saving model to best.model\n",
      "0s - loss: 0.0813 - acc: 0.9691 - val_loss: 0.0623 - val_acc: 0.9786\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.06228 to 0.06115, saving model to best.model\n",
      "0s - loss: 0.0865 - acc: 0.9681 - val_loss: 0.0612 - val_acc: 0.9796\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0863 - acc: 0.9666 - val_loss: 0.0616 - val_acc: 0.9805\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0805 - acc: 0.9722 - val_loss: 0.0626 - val_acc: 0.9805\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.06115 to 0.05800, saving model to best.model\n",
      "0s - loss: 0.0791 - acc: 0.9705 - val_loss: 0.0580 - val_acc: 0.9815\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0707 - acc: 0.9757 - val_loss: 0.0593 - val_acc: 0.9805\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0837 - acc: 0.9693 - val_loss: 0.0646 - val_acc: 0.9805\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0803 - acc: 0.9688 - val_loss: 0.0602 - val_acc: 0.9805\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.05800 to 0.05682, saving model to best.model\n",
      "0s - loss: 0.0748 - acc: 0.9701 - val_loss: 0.0568 - val_acc: 0.9805\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.05682 to 0.05276, saving model to best.model\n",
      "0s - loss: 0.0688 - acc: 0.9722 - val_loss: 0.0528 - val_acc: 0.9805\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.05276 to 0.05021, saving model to best.model\n",
      "0s - loss: 0.0668 - acc: 0.9766 - val_loss: 0.0502 - val_acc: 0.9825\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0687 - acc: 0.9766 - val_loss: 0.0517 - val_acc: 0.9805\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.05021 to 0.04739, saving model to best.model\n",
      "0s - loss: 0.0726 - acc: 0.9747 - val_loss: 0.0474 - val_acc: 0.9815\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.04739 to 0.04729, saving model to best.model\n",
      "0s - loss: 0.0665 - acc: 0.9739 - val_loss: 0.0473 - val_acc: 0.9815\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0716 - acc: 0.9737 - val_loss: 0.0557 - val_acc: 0.9805\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0687 - acc: 0.9749 - val_loss: 0.0476 - val_acc: 0.9825\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.04729 to 0.04542, saving model to best.model\n",
      "0s - loss: 0.0685 - acc: 0.9732 - val_loss: 0.0454 - val_acc: 0.9825\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0639 - acc: 0.9766 - val_loss: 0.0477 - val_acc: 0.9815\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.04542 to 0.04383, saving model to best.model\n",
      "0s - loss: 0.0652 - acc: 0.9754 - val_loss: 0.0438 - val_acc: 0.9825\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9769 - val_loss: 0.0451 - val_acc: 0.9815\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0584 - acc: 0.9813 - val_loss: 0.0446 - val_acc: 0.9825\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.04383 to 0.04259, saving model to best.model\n",
      "0s - loss: 0.0595 - acc: 0.9798 - val_loss: 0.0426 - val_acc: 0.9825\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9739 - val_loss: 0.0471 - val_acc: 0.9815\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9800 - val_loss: 0.0452 - val_acc: 0.9825\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0604 - acc: 0.9783 - val_loss: 0.0450 - val_acc: 0.9815\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0618 - acc: 0.9771 - val_loss: 0.0471 - val_acc: 0.9815\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.04259 to 0.04187, saving model to best.model\n",
      "0s - loss: 0.0611 - acc: 0.9776 - val_loss: 0.0419 - val_acc: 0.9825\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0547 - acc: 0.9793 - val_loss: 0.0429 - val_acc: 0.9825\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.04187 to 0.04072, saving model to best.model\n",
      "0s - loss: 0.0576 - acc: 0.9800 - val_loss: 0.0407 - val_acc: 0.9825\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9793 - val_loss: 0.0439 - val_acc: 0.9815\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.04072 to 0.03787, saving model to best.model\n",
      "0s - loss: 0.0505 - acc: 0.9813 - val_loss: 0.0379 - val_acc: 0.9825\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9839 - val_loss: 0.0386 - val_acc: 0.9825\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.03787 to 0.03500, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9808 - val_loss: 0.0350 - val_acc: 0.9834\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9813 - val_loss: 0.0359 - val_acc: 0.9834\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0569 - acc: 0.9776 - val_loss: 0.0380 - val_acc: 0.9825\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9803 - val_loss: 0.0357 - val_acc: 0.9834\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0550 - acc: 0.9800 - val_loss: 0.0417 - val_acc: 0.9805\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.03500 to 0.03499, saving model to best.model\n",
      "0s - loss: 0.0525 - acc: 0.9815 - val_loss: 0.0350 - val_acc: 0.9825\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9815 - val_loss: 0.0368 - val_acc: 0.9844\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.03499 to 0.03024, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9813 - val_loss: 0.0302 - val_acc: 0.9834\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9791 - val_loss: 0.0329 - val_acc: 0.9834\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0564 - acc: 0.9791 - val_loss: 0.0306 - val_acc: 0.9834\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0525 - acc: 0.9810 - val_loss: 0.0349 - val_acc: 0.9834\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.03024 to 0.02917, saving model to best.model\n",
      "0s - loss: 0.0558 - acc: 0.9803 - val_loss: 0.0292 - val_acc: 0.9834\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02917 to 0.02671, saving model to best.model\n",
      "0s - loss: 0.0497 - acc: 0.9805 - val_loss: 0.0267 - val_acc: 0.9844\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0471 - acc: 0.9832 - val_loss: 0.0321 - val_acc: 0.9854\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9817 - val_loss: 0.0268 - val_acc: 0.9854\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9844 - val_loss: 0.0277 - val_acc: 0.9834\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0421 - acc: 0.9871 - val_loss: 0.0280 - val_acc: 0.9834\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02671 to 0.02533, saving model to best.model\n",
      "0s - loss: 0.0495 - acc: 0.9815 - val_loss: 0.0253 - val_acc: 0.9854\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9847 - val_loss: 0.0319 - val_acc: 0.9844\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9851 - val_loss: 0.0282 - val_acc: 0.9854\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9830 - val_loss: 0.0277 - val_acc: 0.9854\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9827 - val_loss: 0.0272 - val_acc: 0.9854\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9854 - val_loss: 0.0255 - val_acc: 0.9854\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9847 - val_loss: 0.0264 - val_acc: 0.9854\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9822 - val_loss: 0.0307 - val_acc: 0.9854\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9861 - val_loss: 0.0271 - val_acc: 0.9854\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9856 - val_loss: 0.0272 - val_acc: 0.9854\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.02533 to 0.02360, saving model to best.model\n",
      "0s - loss: 0.0382 - acc: 0.9856 - val_loss: 0.0236 - val_acc: 0.9864\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02360 to 0.02044, saving model to best.model\n",
      "0s - loss: 0.0381 - acc: 0.9866 - val_loss: 0.0204 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0224 - val_acc: 0.9883\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0425 - acc: 0.9854 - val_loss: 0.0243 - val_acc: 0.9864\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9866 - val_loss: 0.0237 - val_acc: 0.9864\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02044 to 0.01829, saving model to best.model\n",
      "0s - loss: 0.0534 - acc: 0.9795 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9815 - val_loss: 0.0278 - val_acc: 0.9854\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9878 - val_loss: 0.0259 - val_acc: 0.9854\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9844 - val_loss: 0.0225 - val_acc: 0.9873\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9856 - val_loss: 0.0231 - val_acc: 0.9854\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9895 - val_loss: 0.0229 - val_acc: 0.9873\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01829 to 0.01627, saving model to best.model\n",
      "0s - loss: 0.0387 - acc: 0.9849 - val_loss: 0.0163 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9881 - val_loss: 0.0223 - val_acc: 0.9873\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9856 - val_loss: 0.0192 - val_acc: 0.9903\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9871 - val_loss: 0.0206 - val_acc: 0.9883\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9849 - val_loss: 0.0232 - val_acc: 0.9854\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9861 - val_loss: 0.0245 - val_acc: 0.9854\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9830 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9893 - val_loss: 0.0278 - val_acc: 0.9854\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9866 - val_loss: 0.0203 - val_acc: 0.9883\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9881 - val_loss: 0.0204 - val_acc: 0.9883\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9898 - val_loss: 0.0185 - val_acc: 0.9893\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9866 - val_loss: 0.0217 - val_acc: 0.9883\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9907 - val_loss: 0.0179 - val_acc: 0.9893\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01627 to 0.01500, saving model to best.model\n",
      "0s - loss: 0.0373 - acc: 0.9871 - val_loss: 0.0150 - val_acc: 0.9912\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0181 - val_acc: 0.9883\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9856 - val_loss: 0.0179 - val_acc: 0.9883\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01500 to 0.01432, saving model to best.model\n",
      "0s - loss: 0.0337 - acc: 0.9878 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0204 - val_acc: 0.9873\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01432 to 0.01318, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9883 - val_loss: 0.0132 - val_acc: 0.9961\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9864 - val_loss: 0.0248 - val_acc: 0.9873\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.01318 to 0.01262, saving model to best.model\n",
      "0s - loss: 0.0365 - acc: 0.9861 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9859 - val_loss: 0.0183 - val_acc: 0.9883\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0170 - val_acc: 0.9912\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9876 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9876 - val_loss: 0.0167 - val_acc: 0.9912\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9881 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9900 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9893 - val_loss: 0.0140 - val_acc: 0.9922\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9886 - val_loss: 0.0153 - val_acc: 0.9912\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9900 - val_loss: 0.0131 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9888 - val_loss: 0.0140 - val_acc: 0.9912\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0138 - val_acc: 0.9912\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9903 - val_loss: 0.0145 - val_acc: 0.9912\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.01262 to 0.01041, saving model to best.model\n",
      "0s - loss: 0.0250 - acc: 0.9905 - val_loss: 0.0104 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0300 - acc: 0.9893 - val_loss: 0.0215 - val_acc: 0.9893\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9907 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9886 - val_loss: 0.0166 - val_acc: 0.9903\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.65766, saving model to best.model\n",
      "0s - loss: 0.7930 - acc: 0.5013 - val_loss: 0.6577 - val_acc: 0.5433\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.65766 to 0.61548, saving model to best.model\n",
      "0s - loss: 0.7353 - acc: 0.5483 - val_loss: 0.6155 - val_acc: 0.8228\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.61548 to 0.55025, saving model to best.model\n",
      "0s - loss: 0.6677 - acc: 0.6041 - val_loss: 0.5503 - val_acc: 0.8189\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.55025 to 0.46950, saving model to best.model\n",
      "0s - loss: 0.5917 - acc: 0.6879 - val_loss: 0.4695 - val_acc: 0.8286\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.46950 to 0.40935, saving model to best.model\n",
      "0s - loss: 0.5145 - acc: 0.7663 - val_loss: 0.4094 - val_acc: 0.8442\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.40935 to 0.36721, saving model to best.model\n",
      "0s - loss: 0.4744 - acc: 0.7906 - val_loss: 0.3672 - val_acc: 0.8666\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.36721 to 0.34145, saving model to best.model\n",
      "0s - loss: 0.4263 - acc: 0.8254 - val_loss: 0.3415 - val_acc: 0.8802\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.34145 to 0.31797, saving model to best.model\n",
      "0s - loss: 0.4014 - acc: 0.8371 - val_loss: 0.3180 - val_acc: 0.8890\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.31797 to 0.30194, saving model to best.model\n",
      "0s - loss: 0.3715 - acc: 0.8520 - val_loss: 0.3019 - val_acc: 0.8939\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.30194 to 0.29094, saving model to best.model\n",
      "0s - loss: 0.3690 - acc: 0.8566 - val_loss: 0.2909 - val_acc: 0.8939\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29094 to 0.28129, saving model to best.model\n",
      "0s - loss: 0.3396 - acc: 0.8666 - val_loss: 0.2813 - val_acc: 0.8939\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28129 to 0.27245, saving model to best.model\n",
      "0s - loss: 0.3428 - acc: 0.8739 - val_loss: 0.2724 - val_acc: 0.8929\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27245 to 0.26542, saving model to best.model\n",
      "0s - loss: 0.3279 - acc: 0.8763 - val_loss: 0.2654 - val_acc: 0.8968\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26542 to 0.26042, saving model to best.model\n",
      "0s - loss: 0.3093 - acc: 0.8843 - val_loss: 0.2604 - val_acc: 0.9007\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26042 to 0.25254, saving model to best.model\n",
      "0s - loss: 0.3010 - acc: 0.8873 - val_loss: 0.2525 - val_acc: 0.9046\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25254 to 0.24810, saving model to best.model\n",
      "0s - loss: 0.2894 - acc: 0.8943 - val_loss: 0.2481 - val_acc: 0.9085\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24810 to 0.24555, saving model to best.model\n",
      "0s - loss: 0.2878 - acc: 0.8946 - val_loss: 0.2456 - val_acc: 0.9104\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24555 to 0.24169, saving model to best.model\n",
      "0s - loss: 0.2849 - acc: 0.8943 - val_loss: 0.2417 - val_acc: 0.9133\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24169 to 0.23719, saving model to best.model\n",
      "0s - loss: 0.2803 - acc: 0.8943 - val_loss: 0.2372 - val_acc: 0.9153\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23719 to 0.23221, saving model to best.model\n",
      "0s - loss: 0.2694 - acc: 0.9021 - val_loss: 0.2322 - val_acc: 0.9172\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23221 to 0.22856, saving model to best.model\n",
      "0s - loss: 0.2755 - acc: 0.8968 - val_loss: 0.2286 - val_acc: 0.9163\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22856 to 0.22545, saving model to best.model\n",
      "0s - loss: 0.2589 - acc: 0.9026 - val_loss: 0.2255 - val_acc: 0.9192\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22545 to 0.22203, saving model to best.model\n",
      "0s - loss: 0.2499 - acc: 0.9072 - val_loss: 0.2220 - val_acc: 0.9211\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22203 to 0.21807, saving model to best.model\n",
      "0s - loss: 0.2467 - acc: 0.9087 - val_loss: 0.2181 - val_acc: 0.9211\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21807 to 0.21397, saving model to best.model\n",
      "0s - loss: 0.2380 - acc: 0.9119 - val_loss: 0.2140 - val_acc: 0.9231\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21397 to 0.21273, saving model to best.model\n",
      "0s - loss: 0.2381 - acc: 0.9121 - val_loss: 0.2127 - val_acc: 0.9231\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21273 to 0.20884, saving model to best.model\n",
      "0s - loss: 0.2340 - acc: 0.9165 - val_loss: 0.2088 - val_acc: 0.9211\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20884 to 0.20351, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9196 - val_loss: 0.2035 - val_acc: 0.9231\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20351 to 0.20146, saving model to best.model\n",
      "0s - loss: 0.2269 - acc: 0.9221 - val_loss: 0.2015 - val_acc: 0.9221\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20146 to 0.20118, saving model to best.model\n",
      "0s - loss: 0.2256 - acc: 0.9153 - val_loss: 0.2012 - val_acc: 0.9260\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20118 to 0.19698, saving model to best.model\n",
      "0s - loss: 0.2191 - acc: 0.9231 - val_loss: 0.1970 - val_acc: 0.9241\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19698 to 0.19219, saving model to best.model\n",
      "0s - loss: 0.2140 - acc: 0.9209 - val_loss: 0.1922 - val_acc: 0.9241\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19219 to 0.19091, saving model to best.model\n",
      "0s - loss: 0.2189 - acc: 0.9196 - val_loss: 0.1909 - val_acc: 0.9299\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19091 to 0.18665, saving model to best.model\n",
      "0s - loss: 0.2111 - acc: 0.9243 - val_loss: 0.1867 - val_acc: 0.9250\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18665 to 0.18592, saving model to best.model\n",
      "0s - loss: 0.2160 - acc: 0.9214 - val_loss: 0.1859 - val_acc: 0.9279\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18592 to 0.18338, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9282 - val_loss: 0.1834 - val_acc: 0.9338\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18338 to 0.17857, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9262 - val_loss: 0.1786 - val_acc: 0.9289\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17857 to 0.17784, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9304 - val_loss: 0.1778 - val_acc: 0.9396\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17784 to 0.17342, saving model to best.model\n",
      "0s - loss: 0.1927 - acc: 0.9289 - val_loss: 0.1734 - val_acc: 0.9387\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17342 to 0.17035, saving model to best.model\n",
      "0s - loss: 0.1962 - acc: 0.9289 - val_loss: 0.1703 - val_acc: 0.9338\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17035 to 0.16757, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9389 - val_loss: 0.1676 - val_acc: 0.9328\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.16757 to 0.16468, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9311 - val_loss: 0.1647 - val_acc: 0.9318\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.16468 to 0.16197, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9352 - val_loss: 0.1620 - val_acc: 0.9416\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16197 to 0.15980, saving model to best.model\n",
      "0s - loss: 0.1754 - acc: 0.9364 - val_loss: 0.1598 - val_acc: 0.9416\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15980 to 0.15772, saving model to best.model\n",
      "0s - loss: 0.1813 - acc: 0.9360 - val_loss: 0.1577 - val_acc: 0.9445\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15772 to 0.15657, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9421 - val_loss: 0.1566 - val_acc: 0.9426\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15657 to 0.15344, saving model to best.model\n",
      "0s - loss: 0.1662 - acc: 0.9416 - val_loss: 0.1534 - val_acc: 0.9367\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15344 to 0.14967, saving model to best.model\n",
      "0s - loss: 0.1695 - acc: 0.9369 - val_loss: 0.1497 - val_acc: 0.9513\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14967 to 0.14576, saving model to best.model\n",
      "0s - loss: 0.1715 - acc: 0.9403 - val_loss: 0.1458 - val_acc: 0.9396\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14576 to 0.14218, saving model to best.model\n",
      "0s - loss: 0.1588 - acc: 0.9418 - val_loss: 0.1422 - val_acc: 0.9572\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14218 to 0.13853, saving model to best.model\n",
      "0s - loss: 0.1573 - acc: 0.9428 - val_loss: 0.1385 - val_acc: 0.9542\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13853 to 0.13702, saving model to best.model\n",
      "0s - loss: 0.1574 - acc: 0.9411 - val_loss: 0.1370 - val_acc: 0.9513\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13702 to 0.13410, saving model to best.model\n",
      "0s - loss: 0.1482 - acc: 0.9462 - val_loss: 0.1341 - val_acc: 0.9562\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13410 to 0.13236, saving model to best.model\n",
      "0s - loss: 0.1488 - acc: 0.9452 - val_loss: 0.1324 - val_acc: 0.9523\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13236 to 0.12811, saving model to best.model\n",
      "0s - loss: 0.1555 - acc: 0.9445 - val_loss: 0.1281 - val_acc: 0.9523\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12811 to 0.12560, saving model to best.model\n",
      "0s - loss: 0.1461 - acc: 0.9467 - val_loss: 0.1256 - val_acc: 0.9523\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12560 to 0.12361, saving model to best.model\n",
      "0s - loss: 0.1380 - acc: 0.9508 - val_loss: 0.1236 - val_acc: 0.9542\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12361 to 0.11943, saving model to best.model\n",
      "0s - loss: 0.1512 - acc: 0.9494 - val_loss: 0.1194 - val_acc: 0.9581\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11943 to 0.11829, saving model to best.model\n",
      "0s - loss: 0.1434 - acc: 0.9518 - val_loss: 0.1183 - val_acc: 0.9708\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11829 to 0.11284, saving model to best.model\n",
      "0s - loss: 0.1344 - acc: 0.9520 - val_loss: 0.1128 - val_acc: 0.9698\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11284 to 0.11014, saving model to best.model\n",
      "0s - loss: 0.1350 - acc: 0.9547 - val_loss: 0.1101 - val_acc: 0.9727\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1296 - acc: 0.9537 - val_loss: 0.1102 - val_acc: 0.9718\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11014 to 0.10867, saving model to best.model\n",
      "0s - loss: 0.1293 - acc: 0.9547 - val_loss: 0.1087 - val_acc: 0.9727\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10867 to 0.10772, saving model to best.model\n",
      "0s - loss: 0.1243 - acc: 0.9564 - val_loss: 0.1077 - val_acc: 0.9688\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10772 to 0.10333, saving model to best.model\n",
      "0s - loss: 0.1213 - acc: 0.9569 - val_loss: 0.1033 - val_acc: 0.9747\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10333 to 0.10252, saving model to best.model\n",
      "0s - loss: 0.1173 - acc: 0.9589 - val_loss: 0.1025 - val_acc: 0.9718\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.10252 to 0.09847, saving model to best.model\n",
      "0s - loss: 0.1217 - acc: 0.9571 - val_loss: 0.0985 - val_acc: 0.9776\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09847 to 0.09534, saving model to best.model\n",
      "0s - loss: 0.1195 - acc: 0.9557 - val_loss: 0.0953 - val_acc: 0.9776\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09534 to 0.09267, saving model to best.model\n",
      "0s - loss: 0.1117 - acc: 0.9593 - val_loss: 0.0927 - val_acc: 0.9796\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09267 to 0.08960, saving model to best.model\n",
      "0s - loss: 0.1173 - acc: 0.9584 - val_loss: 0.0896 - val_acc: 0.9796\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08960 to 0.08888, saving model to best.model\n",
      "0s - loss: 0.1110 - acc: 0.9606 - val_loss: 0.0889 - val_acc: 0.9796\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08888 to 0.08655, saving model to best.model\n",
      "0s - loss: 0.1073 - acc: 0.9630 - val_loss: 0.0866 - val_acc: 0.9796\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08655 to 0.08327, saving model to best.model\n",
      "0s - loss: 0.1110 - acc: 0.9615 - val_loss: 0.0833 - val_acc: 0.9796\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.0959 - acc: 0.9666 - val_loss: 0.0834 - val_acc: 0.9805\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08327 to 0.08256, saving model to best.model\n",
      "0s - loss: 0.1027 - acc: 0.9627 - val_loss: 0.0826 - val_acc: 0.9805\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.08256 to 0.07905, saving model to best.model\n",
      "0s - loss: 0.1037 - acc: 0.9623 - val_loss: 0.0791 - val_acc: 0.9796\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07905 to 0.07860, saving model to best.model\n",
      "0s - loss: 0.0959 - acc: 0.9664 - val_loss: 0.0786 - val_acc: 0.9796\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07860 to 0.07838, saving model to best.model\n",
      "0s - loss: 0.1032 - acc: 0.9601 - val_loss: 0.0784 - val_acc: 0.9786\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07838 to 0.07171, saving model to best.model\n",
      "0s - loss: 0.0935 - acc: 0.9640 - val_loss: 0.0717 - val_acc: 0.9805\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07171 to 0.06988, saving model to best.model\n",
      "0s - loss: 0.0955 - acc: 0.9654 - val_loss: 0.0699 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06988 to 0.06881, saving model to best.model\n",
      "0s - loss: 0.0912 - acc: 0.9679 - val_loss: 0.0688 - val_acc: 0.9805\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06881 to 0.06751, saving model to best.model\n",
      "0s - loss: 0.0870 - acc: 0.9683 - val_loss: 0.0675 - val_acc: 0.9805\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06751 to 0.06418, saving model to best.model\n",
      "0s - loss: 0.0921 - acc: 0.9681 - val_loss: 0.0642 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06418 to 0.06372, saving model to best.model\n",
      "0s - loss: 0.0919 - acc: 0.9664 - val_loss: 0.0637 - val_acc: 0.9805\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06372 to 0.06151, saving model to best.model\n",
      "0s - loss: 0.0842 - acc: 0.9732 - val_loss: 0.0615 - val_acc: 0.9815\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0877 - acc: 0.9679 - val_loss: 0.0696 - val_acc: 0.9796\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06151 to 0.05823, saving model to best.model\n",
      "0s - loss: 0.0851 - acc: 0.9698 - val_loss: 0.0582 - val_acc: 0.9815\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0855 - acc: 0.9676 - val_loss: 0.0598 - val_acc: 0.9805\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0795 - acc: 0.9686 - val_loss: 0.0585 - val_acc: 0.9805\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05823 to 0.05509, saving model to best.model\n",
      "0s - loss: 0.0858 - acc: 0.9681 - val_loss: 0.0551 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05509 to 0.05366, saving model to best.model\n",
      "0s - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0537 - val_acc: 0.9815\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05366 to 0.05181, saving model to best.model\n",
      "0s - loss: 0.0770 - acc: 0.9730 - val_loss: 0.0518 - val_acc: 0.9834\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.05181 to 0.04875, saving model to best.model\n",
      "0s - loss: 0.0786 - acc: 0.9713 - val_loss: 0.0487 - val_acc: 0.9873\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0843 - acc: 0.9703 - val_loss: 0.0490 - val_acc: 0.9873\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04875 to 0.04737, saving model to best.model\n",
      "0s - loss: 0.0728 - acc: 0.9735 - val_loss: 0.0474 - val_acc: 0.9873\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04737 to 0.04599, saving model to best.model\n",
      "0s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0460 - val_acc: 0.9883\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0758 - acc: 0.9730 - val_loss: 0.0489 - val_acc: 0.9834\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0840 - acc: 0.9696 - val_loss: 0.0496 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04599 to 0.04367, saving model to best.model\n",
      "0s - loss: 0.0702 - acc: 0.9754 - val_loss: 0.0437 - val_acc: 0.9883\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0757 - acc: 0.9722 - val_loss: 0.0451 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04367 to 0.04340, saving model to best.model\n",
      "0s - loss: 0.0789 - acc: 0.9720 - val_loss: 0.0434 - val_acc: 0.9903\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04340 to 0.04318, saving model to best.model\n",
      "0s - loss: 0.0646 - acc: 0.9761 - val_loss: 0.0432 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.04318 to 0.04244, saving model to best.model\n",
      "0s - loss: 0.0713 - acc: 0.9744 - val_loss: 0.0424 - val_acc: 0.9893\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.04244 to 0.04243, saving model to best.model\n",
      "0s - loss: 0.0682 - acc: 0.9759 - val_loss: 0.0424 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.04243 to 0.03896, saving model to best.model\n",
      "0s - loss: 0.0630 - acc: 0.9776 - val_loss: 0.0390 - val_acc: 0.9903\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03896 to 0.03779, saving model to best.model\n",
      "0s - loss: 0.0640 - acc: 0.9769 - val_loss: 0.0378 - val_acc: 0.9883\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0635 - acc: 0.9778 - val_loss: 0.0402 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0603 - acc: 0.9771 - val_loss: 0.0392 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9786 - val_loss: 0.0388 - val_acc: 0.9873\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0596 - acc: 0.9788 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0615 - acc: 0.9781 - val_loss: 0.0390 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03779 to 0.03667, saving model to best.model\n",
      "0s - loss: 0.0551 - acc: 0.9808 - val_loss: 0.0367 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9778 - val_loss: 0.0375 - val_acc: 0.9883\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.03667 to 0.03481, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9783 - val_loss: 0.0348 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03481 to 0.03414, saving model to best.model\n",
      "0s - loss: 0.0603 - acc: 0.9769 - val_loss: 0.0341 - val_acc: 0.9912\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.03414 to 0.03285, saving model to best.model\n",
      "0s - loss: 0.0525 - acc: 0.9810 - val_loss: 0.0328 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0599 - acc: 0.9778 - val_loss: 0.0335 - val_acc: 0.9912\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0586 - acc: 0.9793 - val_loss: 0.0329 - val_acc: 0.9912\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.03285 to 0.03165, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9781 - val_loss: 0.0317 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.03165 to 0.03139, saving model to best.model\n",
      "0s - loss: 0.0586 - acc: 0.9783 - val_loss: 0.0314 - val_acc: 0.9922\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.03139 to 0.03120, saving model to best.model\n",
      "0s - loss: 0.0588 - acc: 0.9793 - val_loss: 0.0312 - val_acc: 0.9922\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.03120 to 0.03081, saving model to best.model\n",
      "0s - loss: 0.0502 - acc: 0.9817 - val_loss: 0.0308 - val_acc: 0.9922\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.03081 to 0.03028, saving model to best.model\n",
      "0s - loss: 0.0551 - acc: 0.9795 - val_loss: 0.0303 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.03028 to 0.02900, saving model to best.model\n",
      "0s - loss: 0.0488 - acc: 0.9817 - val_loss: 0.0290 - val_acc: 0.9912\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0487 - acc: 0.9825 - val_loss: 0.0292 - val_acc: 0.9912\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02900 to 0.02889, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9808 - val_loss: 0.0289 - val_acc: 0.9912\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0561 - acc: 0.9810 - val_loss: 0.0312 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02889 to 0.02847, saving model to best.model\n",
      "0s - loss: 0.0512 - acc: 0.9793 - val_loss: 0.0285 - val_acc: 0.9912\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02847 to 0.02819, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9810 - val_loss: 0.0282 - val_acc: 0.9912\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02819 to 0.02761, saving model to best.model\n",
      "0s - loss: 0.0577 - acc: 0.9788 - val_loss: 0.0276 - val_acc: 0.9912\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0529 - acc: 0.9805 - val_loss: 0.0278 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02761 to 0.02740, saving model to best.model\n",
      "0s - loss: 0.0512 - acc: 0.9808 - val_loss: 0.0274 - val_acc: 0.9922\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02740 to 0.02675, saving model to best.model\n",
      "0s - loss: 0.0445 - acc: 0.9834 - val_loss: 0.0267 - val_acc: 0.9922\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02675 to 0.02601, saving model to best.model\n",
      "0s - loss: 0.0497 - acc: 0.9817 - val_loss: 0.0260 - val_acc: 0.9922\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.02601 to 0.02436, saving model to best.model\n",
      "0s - loss: 0.0509 - acc: 0.9817 - val_loss: 0.0244 - val_acc: 0.9912\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.02436 to 0.02412, saving model to best.model\n",
      "0s - loss: 0.0496 - acc: 0.9803 - val_loss: 0.0241 - val_acc: 0.9912\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9851 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02412 to 0.02357, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9822 - val_loss: 0.0236 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9825 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.02357 to 0.02319, saving model to best.model\n",
      "0s - loss: 0.0410 - acc: 0.9849 - val_loss: 0.0232 - val_acc: 0.9922\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02319 to 0.02304, saving model to best.model\n",
      "0s - loss: 0.0424 - acc: 0.9834 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9808 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02304 to 0.02195, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9834 - val_loss: 0.0220 - val_acc: 0.9922\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.02195 to 0.02135, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9827 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9839 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9854 - val_loss: 0.0234 - val_acc: 0.9922\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9871 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9856 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0473 - acc: 0.9822 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9820 - val_loss: 0.0238 - val_acc: 0.9932\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0440 - acc: 0.9847 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.02135 to 0.02121, saving model to best.model\n",
      "0s - loss: 0.0371 - acc: 0.9871 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9866 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02121 to 0.01933, saving model to best.model\n",
      "0s - loss: 0.0419 - acc: 0.9834 - val_loss: 0.0193 - val_acc: 0.9932\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9837 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9847 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0195 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9844 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0434 - acc: 0.9856 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9866 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9871 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01933 to 0.01917, saving model to best.model\n",
      "0s - loss: 0.0367 - acc: 0.9866 - val_loss: 0.0192 - val_acc: 0.9922\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0370 - acc: 0.9866 - val_loss: 0.0202 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01917 to 0.01847, saving model to best.model\n",
      "0s - loss: 0.0336 - acc: 0.9881 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9886 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01847 to 0.01800, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9893 - val_loss: 0.0180 - val_acc: 0.9951\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9864 - val_loss: 0.0199 - val_acc: 0.9922\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01800 to 0.01738, saving model to best.model\n",
      "0s - loss: 0.0310 - acc: 0.9869 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9834 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9866 - val_loss: 0.0186 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9851 - val_loss: 0.0187 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9873 - val_loss: 0.0177 - val_acc: 0.9932\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9876 - val_loss: 0.0176 - val_acc: 0.9951\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9856 - val_loss: 0.0175 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01738 to 0.01727, saving model to best.model\n",
      "0s - loss: 0.0367 - acc: 0.9888 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01727 to 0.01631, saving model to best.model\n",
      "0s - loss: 0.0367 - acc: 0.9866 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9871 - val_loss: 0.0164 - val_acc: 0.9932\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01631 to 0.01619, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01619 to 0.01572, saving model to best.model\n",
      "0s - loss: 0.0352 - acc: 0.9881 - val_loss: 0.0157 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01572 to 0.01498, saving model to best.model\n",
      "0s - loss: 0.0350 - acc: 0.9895 - val_loss: 0.0150 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0265 - acc: 0.9907 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9881 - val_loss: 0.0159 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9881 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9859 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9873 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01498 to 0.01477, saving model to best.model\n",
      "0s - loss: 0.0313 - acc: 0.9895 - val_loss: 0.0148 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.01477 to 0.01365, saving model to best.model\n",
      "0s - loss: 0.0287 - acc: 0.9888 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9910 - val_loss: 0.0140 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9866 - val_loss: 0.0156 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9881 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.01365 to 0.01269, saving model to best.model\n",
      "0s - loss: 0.0297 - acc: 0.9898 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.01269 to 0.01230, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9886 - val_loss: 0.0123 - val_acc: 0.9961\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.01230 to 0.01203, saving model to best.model\n",
      "0s - loss: 0.0286 - acc: 0.9886 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0138 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0247 - acc: 0.9895 - val_loss: 0.0123 - val_acc: 0.9951\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9886 - val_loss: 0.0139 - val_acc: 0.9961\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9876 - val_loss: 0.0143 - val_acc: 0.9961\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67883, saving model to best.model\n",
      "0s - loss: 0.7942 - acc: 0.5203 - val_loss: 0.6788 - val_acc: 0.4761\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67883 to 0.64304, saving model to best.model\n",
      "0s - loss: 0.7450 - acc: 0.5354 - val_loss: 0.6430 - val_acc: 0.6095\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64304 to 0.57996, saving model to best.model\n",
      "0s - loss: 0.6943 - acc: 0.5678 - val_loss: 0.5800 - val_acc: 0.8092\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.57996 to 0.50696, saving model to best.model\n",
      "0s - loss: 0.6243 - acc: 0.6552 - val_loss: 0.5070 - val_acc: 0.8189\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50696 to 0.44413, saving model to best.model\n",
      "0s - loss: 0.5454 - acc: 0.7280 - val_loss: 0.4441 - val_acc: 0.8306\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44413 to 0.39677, saving model to best.model\n",
      "0s - loss: 0.4894 - acc: 0.7721 - val_loss: 0.3968 - val_acc: 0.8520\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39677 to 0.37372, saving model to best.model\n",
      "0s - loss: 0.4510 - acc: 0.8008 - val_loss: 0.3737 - val_acc: 0.8578\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37372 to 0.34316, saving model to best.model\n",
      "0s - loss: 0.4180 - acc: 0.8237 - val_loss: 0.3432 - val_acc: 0.8793\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34316 to 0.32192, saving model to best.model\n",
      "0s - loss: 0.3955 - acc: 0.8439 - val_loss: 0.3219 - val_acc: 0.8870\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32192 to 0.30860, saving model to best.model\n",
      "0s - loss: 0.3781 - acc: 0.8512 - val_loss: 0.3086 - val_acc: 0.8890\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30860 to 0.29954, saving model to best.model\n",
      "0s - loss: 0.3549 - acc: 0.8629 - val_loss: 0.2995 - val_acc: 0.8939\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29954 to 0.28456, saving model to best.model\n",
      "0s - loss: 0.3450 - acc: 0.8697 - val_loss: 0.2846 - val_acc: 0.8909\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28456 to 0.27341, saving model to best.model\n",
      "0s - loss: 0.3306 - acc: 0.8746 - val_loss: 0.2734 - val_acc: 0.8958\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27341 to 0.27197, saving model to best.model\n",
      "0s - loss: 0.3132 - acc: 0.8819 - val_loss: 0.2720 - val_acc: 0.8997\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27197 to 0.26369, saving model to best.model\n",
      "0s - loss: 0.3103 - acc: 0.8858 - val_loss: 0.2637 - val_acc: 0.9017\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26369 to 0.25534, saving model to best.model\n",
      "0s - loss: 0.3035 - acc: 0.8880 - val_loss: 0.2553 - val_acc: 0.9085\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25534 to 0.25213, saving model to best.model\n",
      "0s - loss: 0.2892 - acc: 0.8948 - val_loss: 0.2521 - val_acc: 0.9114\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25213 to 0.24694, saving model to best.model\n",
      "0s - loss: 0.2874 - acc: 0.8931 - val_loss: 0.2469 - val_acc: 0.9114\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24694 to 0.23536, saving model to best.model\n",
      "0s - loss: 0.2813 - acc: 0.8948 - val_loss: 0.2354 - val_acc: 0.9133\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2792 - acc: 0.9004 - val_loss: 0.2388 - val_acc: 0.9124\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23536 to 0.22914, saving model to best.model\n",
      "0s - loss: 0.2668 - acc: 0.9028 - val_loss: 0.2291 - val_acc: 0.9153\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22914 to 0.22555, saving model to best.model\n",
      "0s - loss: 0.2678 - acc: 0.9019 - val_loss: 0.2256 - val_acc: 0.9153\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22555 to 0.22037, saving model to best.model\n",
      "0s - loss: 0.2550 - acc: 0.9038 - val_loss: 0.2204 - val_acc: 0.9202\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22037 to 0.21753, saving model to best.model\n",
      "0s - loss: 0.2550 - acc: 0.9036 - val_loss: 0.2175 - val_acc: 0.9192\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2486 - acc: 0.9109 - val_loss: 0.2186 - val_acc: 0.9182\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21753 to 0.21434, saving model to best.model\n",
      "0s - loss: 0.2438 - acc: 0.9092 - val_loss: 0.2143 - val_acc: 0.9172\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21434 to 0.20631, saving model to best.model\n",
      "0s - loss: 0.2398 - acc: 0.9126 - val_loss: 0.2063 - val_acc: 0.9231\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2415 - acc: 0.9138 - val_loss: 0.2131 - val_acc: 0.9163\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20631 to 0.20084, saving model to best.model\n",
      "0s - loss: 0.2297 - acc: 0.9133 - val_loss: 0.2008 - val_acc: 0.9192\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20084 to 0.19686, saving model to best.model\n",
      "0s - loss: 0.2199 - acc: 0.9196 - val_loss: 0.1969 - val_acc: 0.9211\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2254 - acc: 0.9158 - val_loss: 0.1976 - val_acc: 0.9192\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19686 to 0.19374, saving model to best.model\n",
      "0s - loss: 0.2181 - acc: 0.9187 - val_loss: 0.1937 - val_acc: 0.9192\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19374 to 0.19111, saving model to best.model\n",
      "0s - loss: 0.2203 - acc: 0.9177 - val_loss: 0.1911 - val_acc: 0.9172\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19111 to 0.19017, saving model to best.model\n",
      "0s - loss: 0.2197 - acc: 0.9182 - val_loss: 0.1902 - val_acc: 0.9192\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19017 to 0.18144, saving model to best.model\n",
      "0s - loss: 0.2126 - acc: 0.9226 - val_loss: 0.1814 - val_acc: 0.9241\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18144 to 0.17619, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9238 - val_loss: 0.1762 - val_acc: 0.9279\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17619 to 0.17511, saving model to best.model\n",
      "0s - loss: 0.2065 - acc: 0.9255 - val_loss: 0.1751 - val_acc: 0.9202\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17511 to 0.17494, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9214 - val_loss: 0.1749 - val_acc: 0.9192\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17494 to 0.16692, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9267 - val_loss: 0.1669 - val_acc: 0.9396\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9296 - val_loss: 0.1712 - val_acc: 0.9192\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16692 to 0.15666, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9279 - val_loss: 0.1567 - val_acc: 0.9377\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15666 to 0.15569, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9274 - val_loss: 0.1557 - val_acc: 0.9338\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15569 to 0.15361, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9345 - val_loss: 0.1536 - val_acc: 0.9318\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15361 to 0.14868, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9343 - val_loss: 0.1487 - val_acc: 0.9328\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14868 to 0.14074, saving model to best.model\n",
      "0s - loss: 0.1779 - acc: 0.9289 - val_loss: 0.1407 - val_acc: 0.9396\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14074 to 0.14013, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9333 - val_loss: 0.1401 - val_acc: 0.9357\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14013 to 0.13647, saving model to best.model\n",
      "0s - loss: 0.1685 - acc: 0.9357 - val_loss: 0.1365 - val_acc: 0.9357\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13647 to 0.13603, saving model to best.model\n",
      "0s - loss: 0.1693 - acc: 0.9330 - val_loss: 0.1360 - val_acc: 0.9328\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13603 to 0.12338, saving model to best.model\n",
      "0s - loss: 0.1604 - acc: 0.9386 - val_loss: 0.1234 - val_acc: 0.9416\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12338 to 0.12161, saving model to best.model\n",
      "0s - loss: 0.1545 - acc: 0.9433 - val_loss: 0.1216 - val_acc: 0.9396\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1491 - acc: 0.9421 - val_loss: 0.1259 - val_acc: 0.9387\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12161 to 0.11438, saving model to best.model\n",
      "0s - loss: 0.1604 - acc: 0.9396 - val_loss: 0.1144 - val_acc: 0.9435\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11438 to 0.11141, saving model to best.model\n",
      "0s - loss: 0.1507 - acc: 0.9406 - val_loss: 0.1114 - val_acc: 0.9464\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1506 - acc: 0.9384 - val_loss: 0.1148 - val_acc: 0.9396\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.11141 to 0.10656, saving model to best.model\n",
      "0s - loss: 0.1492 - acc: 0.9428 - val_loss: 0.1066 - val_acc: 0.9474\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.10656 to 0.09822, saving model to best.model\n",
      "0s - loss: 0.1489 - acc: 0.9440 - val_loss: 0.0982 - val_acc: 0.9572\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09822 to 0.09454, saving model to best.model\n",
      "0s - loss: 0.1382 - acc: 0.9472 - val_loss: 0.0945 - val_acc: 0.9591\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09454 to 0.09173, saving model to best.model\n",
      "0s - loss: 0.1353 - acc: 0.9481 - val_loss: 0.0917 - val_acc: 0.9581\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09173 to 0.08753, saving model to best.model\n",
      "0s - loss: 0.1325 - acc: 0.9477 - val_loss: 0.0875 - val_acc: 0.9630\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1256 - acc: 0.9515 - val_loss: 0.0883 - val_acc: 0.9611\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08753 to 0.08629, saving model to best.model\n",
      "0s - loss: 0.1314 - acc: 0.9484 - val_loss: 0.0863 - val_acc: 0.9640\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1336 - acc: 0.9515 - val_loss: 0.0937 - val_acc: 0.9620\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08629 to 0.07986, saving model to best.model\n",
      "0s - loss: 0.1225 - acc: 0.9523 - val_loss: 0.0799 - val_acc: 0.9669\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.07986 to 0.07764, saving model to best.model\n",
      "0s - loss: 0.1208 - acc: 0.9550 - val_loss: 0.0776 - val_acc: 0.9679\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07764 to 0.07566, saving model to best.model\n",
      "0s - loss: 0.1194 - acc: 0.9550 - val_loss: 0.0757 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1175 - acc: 0.9554 - val_loss: 0.0837 - val_acc: 0.9659\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07566 to 0.07163, saving model to best.model\n",
      "0s - loss: 0.1055 - acc: 0.9598 - val_loss: 0.0716 - val_acc: 0.9708\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07163 to 0.06690, saving model to best.model\n",
      "0s - loss: 0.1023 - acc: 0.9581 - val_loss: 0.0669 - val_acc: 0.9737\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1112 - acc: 0.9584 - val_loss: 0.0683 - val_acc: 0.9757\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06690 to 0.06634, saving model to best.model\n",
      "0s - loss: 0.1205 - acc: 0.9533 - val_loss: 0.0663 - val_acc: 0.9747\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1020 - acc: 0.9579 - val_loss: 0.0684 - val_acc: 0.9737\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06634 to 0.06498, saving model to best.model\n",
      "0s - loss: 0.1000 - acc: 0.9623 - val_loss: 0.0650 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06498 to 0.06084, saving model to best.model\n",
      "0s - loss: 0.0974 - acc: 0.9635 - val_loss: 0.0608 - val_acc: 0.9747\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1011 - acc: 0.9627 - val_loss: 0.0611 - val_acc: 0.9776\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06084 to 0.05627, saving model to best.model\n",
      "0s - loss: 0.0969 - acc: 0.9635 - val_loss: 0.0563 - val_acc: 0.9805\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.0868 - acc: 0.9645 - val_loss: 0.0593 - val_acc: 0.9815\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05627 to 0.05156, saving model to best.model\n",
      "0s - loss: 0.0920 - acc: 0.9681 - val_loss: 0.0516 - val_acc: 0.9766\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.05156 to 0.04976, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9642 - val_loss: 0.0498 - val_acc: 0.9805\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0994 - acc: 0.9615 - val_loss: 0.0549 - val_acc: 0.9805\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.04976 to 0.04852, saving model to best.model\n",
      "0s - loss: 0.0886 - acc: 0.9659 - val_loss: 0.0485 - val_acc: 0.9825\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.04852 to 0.04819, saving model to best.model\n",
      "0s - loss: 0.0880 - acc: 0.9676 - val_loss: 0.0482 - val_acc: 0.9854\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.04819 to 0.04636, saving model to best.model\n",
      "0s - loss: 0.0881 - acc: 0.9679 - val_loss: 0.0464 - val_acc: 0.9854\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04636 to 0.04280, saving model to best.model\n",
      "0s - loss: 0.0840 - acc: 0.9683 - val_loss: 0.0428 - val_acc: 0.9825\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.04280 to 0.04216, saving model to best.model\n",
      "0s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0422 - val_acc: 0.9864\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0802 - acc: 0.9688 - val_loss: 0.0436 - val_acc: 0.9854\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0749 - acc: 0.9718 - val_loss: 0.0425 - val_acc: 0.9854\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04216 to 0.03991, saving model to best.model\n",
      "0s - loss: 0.0856 - acc: 0.9657 - val_loss: 0.0399 - val_acc: 0.9786\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0842 - acc: 0.9664 - val_loss: 0.0478 - val_acc: 0.9815\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.03991 to 0.03683, saving model to best.model\n",
      "0s - loss: 0.0775 - acc: 0.9722 - val_loss: 0.0368 - val_acc: 0.9893\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03683 to 0.03609, saving model to best.model\n",
      "0s - loss: 0.0758 - acc: 0.9720 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.03609 to 0.03527, saving model to best.model\n",
      "0s - loss: 0.0737 - acc: 0.9737 - val_loss: 0.0353 - val_acc: 0.9883\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0773 - acc: 0.9698 - val_loss: 0.0357 - val_acc: 0.9893\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03527 to 0.03520, saving model to best.model\n",
      "0s - loss: 0.0740 - acc: 0.9720 - val_loss: 0.0352 - val_acc: 0.9883\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.03520 to 0.03170, saving model to best.model\n",
      "0s - loss: 0.0754 - acc: 0.9713 - val_loss: 0.0317 - val_acc: 0.9883\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0734 - acc: 0.9715 - val_loss: 0.0367 - val_acc: 0.9873\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.03170 to 0.03168, saving model to best.model\n",
      "0s - loss: 0.0697 - acc: 0.9761 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.03168 to 0.03119, saving model to best.model\n",
      "0s - loss: 0.0624 - acc: 0.9783 - val_loss: 0.0312 - val_acc: 0.9883\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.03119 to 0.02935, saving model to best.model\n",
      "0s - loss: 0.0684 - acc: 0.9730 - val_loss: 0.0294 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0697 - acc: 0.9739 - val_loss: 0.0295 - val_acc: 0.9873\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02935 to 0.02717, saving model to best.model\n",
      "0s - loss: 0.0671 - acc: 0.9757 - val_loss: 0.0272 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.02717 to 0.02630, saving model to best.model\n",
      "0s - loss: 0.0571 - acc: 0.9786 - val_loss: 0.0263 - val_acc: 0.9903\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0578 - acc: 0.9778 - val_loss: 0.0299 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0581 - acc: 0.9783 - val_loss: 0.0274 - val_acc: 0.9893\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.02630 to 0.02419, saving model to best.model\n",
      "0s - loss: 0.0611 - acc: 0.9781 - val_loss: 0.0242 - val_acc: 0.9903\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0556 - acc: 0.9776 - val_loss: 0.0277 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.02419 to 0.02306, saving model to best.model\n",
      "0s - loss: 0.0633 - acc: 0.9776 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0506 - acc: 0.9805 - val_loss: 0.0252 - val_acc: 0.9903\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0643 - acc: 0.9769 - val_loss: 0.0243 - val_acc: 0.9903\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02306 to 0.02103, saving model to best.model\n",
      "0s - loss: 0.0635 - acc: 0.9749 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9737 - val_loss: 0.0282 - val_acc: 0.9903\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0567 - acc: 0.9805 - val_loss: 0.0237 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02103 to 0.02101, saving model to best.model\n",
      "0s - loss: 0.0571 - acc: 0.9781 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0567 - acc: 0.9791 - val_loss: 0.0240 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9757 - val_loss: 0.0212 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0529 - acc: 0.9781 - val_loss: 0.0216 - val_acc: 0.9893\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02101 to 0.01861, saving model to best.model\n",
      "0s - loss: 0.0559 - acc: 0.9795 - val_loss: 0.0186 - val_acc: 0.9912\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0557 - acc: 0.9808 - val_loss: 0.0219 - val_acc: 0.9912\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.01861 to 0.01792, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9781 - val_loss: 0.0179 - val_acc: 0.9912\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9842 - val_loss: 0.0179 - val_acc: 0.9912\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.01792 to 0.01636, saving model to best.model\n",
      "0s - loss: 0.0469 - acc: 0.9830 - val_loss: 0.0164 - val_acc: 0.9932\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0567 - acc: 0.9776 - val_loss: 0.0171 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.01636 to 0.01555, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9844 - val_loss: 0.0156 - val_acc: 0.9942\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0581 - acc: 0.9786 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0587 - acc: 0.9788 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.01555 to 0.01461, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9827 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9813 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.01461 to 0.01410, saving model to best.model\n",
      "0s - loss: 0.0445 - acc: 0.9851 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0476 - acc: 0.9820 - val_loss: 0.0147 - val_acc: 0.9942\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.01410 to 0.01308, saving model to best.model\n",
      "0s - loss: 0.0447 - acc: 0.9830 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9817 - val_loss: 0.0186 - val_acc: 0.9912\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01308 to 0.01248, saving model to best.model\n",
      "0s - loss: 0.0473 - acc: 0.9808 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9849 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9817 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0473 - acc: 0.9813 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9851 - val_loss: 0.0135 - val_acc: 0.9942\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.01248 to 0.01201, saving model to best.model\n",
      "0s - loss: 0.0441 - acc: 0.9808 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9866 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0396 - acc: 0.9839 - val_loss: 0.0126 - val_acc: 0.9942\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9803 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01201 to 0.01132, saving model to best.model\n",
      "0s - loss: 0.0392 - acc: 0.9844 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9834 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9854 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9817 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9815 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01132 to 0.01078, saving model to best.model\n",
      "0s - loss: 0.0388 - acc: 0.9856 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0421 - acc: 0.9847 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9825 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9856 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01078 to 0.00979, saving model to best.model\n",
      "0s - loss: 0.0391 - acc: 0.9856 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9832 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9878 - val_loss: 0.0103 - val_acc: 0.9951\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9822 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9847 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.00979 to 0.00944, saving model to best.model\n",
      "0s - loss: 0.0394 - acc: 0.9842 - val_loss: 0.0094 - val_acc: 0.9951\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9849 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9861 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.00944 to 0.00909, saving model to best.model\n",
      "0s - loss: 0.0341 - acc: 0.9869 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9837 - val_loss: 0.0093 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9878 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.00909 to 0.00840, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0084 - val_acc: 0.9961\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.00840 to 0.00828, saving model to best.model\n",
      "0s - loss: 0.0314 - acc: 0.9881 - val_loss: 0.0083 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9849 - val_loss: 0.0101 - val_acc: 0.9951\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.00828 to 0.00745, saving model to best.model\n",
      "0s - loss: 0.0330 - acc: 0.9869 - val_loss: 0.0074 - val_acc: 0.9971\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9886 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9878 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.00745 to 0.00727, saving model to best.model\n",
      "0s - loss: 0.0387 - acc: 0.9861 - val_loss: 0.0073 - val_acc: 0.9990\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.00727 to 0.00694, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9861 - val_loss: 0.0069 - val_acc: 0.9990\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9873 - val_loss: 0.0079 - val_acc: 0.9961\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9869 - val_loss: 0.0074 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.00694 to 0.00691, saving model to best.model\n",
      "0s - loss: 0.0335 - acc: 0.9871 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9890 - val_loss: 0.0093 - val_acc: 0.9961\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9888 - val_loss: 0.0080 - val_acc: 0.9961\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9859 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9893 - val_loss: 0.0076 - val_acc: 0.9971\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0259 - acc: 0.9905 - val_loss: 0.0069 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9873 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.00691 to 0.00679, saving model to best.model\n",
      "0s - loss: 0.0375 - acc: 0.9856 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9873 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9842 - val_loss: 0.0094 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9873 - val_loss: 0.0077 - val_acc: 0.9961\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.00679 to 0.00675, saving model to best.model\n",
      "0s - loss: 0.0295 - acc: 0.9900 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9871 - val_loss: 0.0073 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.00675 to 0.00630, saving model to best.model\n",
      "0s - loss: 0.0312 - acc: 0.9876 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9886 - val_loss: 0.0070 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9869 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.00630 to 0.00613, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9898 - val_loss: 0.0061 - val_acc: 0.9990\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9883 - val_loss: 0.0090 - val_acc: 0.9961\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9873 - val_loss: 0.0067 - val_acc: 0.9990\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9881 - val_loss: 0.0089 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9907 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9886 - val_loss: 0.0062 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00613 to 0.00588, saving model to best.model\n",
      "0s - loss: 0.0301 - acc: 0.9900 - val_loss: 0.0059 - val_acc: 0.9990\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9890 - val_loss: 0.0075 - val_acc: 0.9961\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00588 to 0.00559, saving model to best.model\n",
      "0s - loss: 0.0260 - acc: 0.9900 - val_loss: 0.0056 - val_acc: 0.9990\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0257 - acc: 0.9915 - val_loss: 0.0058 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00559 to 0.00505, saving model to best.model\n",
      "0s - loss: 0.0267 - acc: 0.9905 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0257 - acc: 0.9893 - val_loss: 0.0061 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.00505 to 0.00478, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9893 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0241 - acc: 0.9903 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9883 - val_loss: 0.0054 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66279, saving model to best.model\n",
      "0s - loss: 0.7846 - acc: 0.5191 - val_loss: 0.6628 - val_acc: 0.7274\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66279 to 0.63149, saving model to best.model\n",
      "0s - loss: 0.7385 - acc: 0.5457 - val_loss: 0.6315 - val_acc: 0.7488\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63149 to 0.58782, saving model to best.model\n",
      "0s - loss: 0.6921 - acc: 0.5778 - val_loss: 0.5878 - val_acc: 0.7868\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58782 to 0.51823, saving model to best.model\n",
      "0s - loss: 0.6305 - acc: 0.6460 - val_loss: 0.5182 - val_acc: 0.8043\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51823 to 0.44813, saving model to best.model\n",
      "0s - loss: 0.5502 - acc: 0.7273 - val_loss: 0.4481 - val_acc: 0.8208\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44813 to 0.39999, saving model to best.model\n",
      "0s - loss: 0.4993 - acc: 0.7711 - val_loss: 0.4000 - val_acc: 0.8403\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39999 to 0.37112, saving model to best.model\n",
      "0s - loss: 0.4538 - acc: 0.8059 - val_loss: 0.3711 - val_acc: 0.8520\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37112 to 0.34012, saving model to best.model\n",
      "0s - loss: 0.4232 - acc: 0.8247 - val_loss: 0.3401 - val_acc: 0.8754\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34012 to 0.32157, saving model to best.model\n",
      "0s - loss: 0.4102 - acc: 0.8359 - val_loss: 0.3216 - val_acc: 0.8832\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32157 to 0.31095, saving model to best.model\n",
      "0s - loss: 0.3718 - acc: 0.8500 - val_loss: 0.3109 - val_acc: 0.8861\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31095 to 0.29243, saving model to best.model\n",
      "0s - loss: 0.3593 - acc: 0.8683 - val_loss: 0.2924 - val_acc: 0.8880\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29243 to 0.27338, saving model to best.model\n",
      "0s - loss: 0.3435 - acc: 0.8649 - val_loss: 0.2734 - val_acc: 0.8958\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27338 to 0.26004, saving model to best.model\n",
      "0s - loss: 0.3349 - acc: 0.8724 - val_loss: 0.2600 - val_acc: 0.8997\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26004 to 0.24979, saving model to best.model\n",
      "0s - loss: 0.3228 - acc: 0.8824 - val_loss: 0.2498 - val_acc: 0.9075\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.24979 to 0.23970, saving model to best.model\n",
      "0s - loss: 0.3176 - acc: 0.8892 - val_loss: 0.2397 - val_acc: 0.9085\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.23970 to 0.22912, saving model to best.model\n",
      "0s - loss: 0.3128 - acc: 0.8853 - val_loss: 0.2291 - val_acc: 0.9202\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.22912 to 0.22159, saving model to best.model\n",
      "0s - loss: 0.2960 - acc: 0.8914 - val_loss: 0.2216 - val_acc: 0.9260\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2956 - acc: 0.8926 - val_loss: 0.2246 - val_acc: 0.9192\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22159 to 0.21825, saving model to best.model\n",
      "0s - loss: 0.2879 - acc: 0.8946 - val_loss: 0.2182 - val_acc: 0.9250\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.21825 to 0.20671, saving model to best.model\n",
      "0s - loss: 0.2766 - acc: 0.9050 - val_loss: 0.2067 - val_acc: 0.9328\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.20671 to 0.20173, saving model to best.model\n",
      "0s - loss: 0.2765 - acc: 0.9014 - val_loss: 0.2017 - val_acc: 0.9309\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2770 - acc: 0.9024 - val_loss: 0.2123 - val_acc: 0.9241\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20173 to 0.19395, saving model to best.model\n",
      "0s - loss: 0.2613 - acc: 0.9063 - val_loss: 0.1939 - val_acc: 0.9318\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2570 - acc: 0.9077 - val_loss: 0.1942 - val_acc: 0.9338\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.19395 to 0.18940, saving model to best.model\n",
      "0s - loss: 0.2560 - acc: 0.9080 - val_loss: 0.1894 - val_acc: 0.9328\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18940 to 0.18625, saving model to best.model\n",
      "0s - loss: 0.2561 - acc: 0.9050 - val_loss: 0.1862 - val_acc: 0.9357\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18625 to 0.18489, saving model to best.model\n",
      "0s - loss: 0.2457 - acc: 0.9092 - val_loss: 0.1849 - val_acc: 0.9338\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18489 to 0.17948, saving model to best.model\n",
      "0s - loss: 0.2469 - acc: 0.9116 - val_loss: 0.1795 - val_acc: 0.9357\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.17948 to 0.17731, saving model to best.model\n",
      "0s - loss: 0.2492 - acc: 0.9160 - val_loss: 0.1773 - val_acc: 0.9387\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.17731 to 0.17714, saving model to best.model\n",
      "0s - loss: 0.2282 - acc: 0.9167 - val_loss: 0.1771 - val_acc: 0.9357\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.17714 to 0.16906, saving model to best.model\n",
      "0s - loss: 0.2343 - acc: 0.9160 - val_loss: 0.1691 - val_acc: 0.9387\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.2278 - acc: 0.9165 - val_loss: 0.1694 - val_acc: 0.9387\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.16906 to 0.16747, saving model to best.model\n",
      "0s - loss: 0.2355 - acc: 0.9162 - val_loss: 0.1675 - val_acc: 0.9387\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.16747 to 0.16228, saving model to best.model\n",
      "0s - loss: 0.2296 - acc: 0.9184 - val_loss: 0.1623 - val_acc: 0.9435\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.16228 to 0.15989, saving model to best.model\n",
      "0s - loss: 0.2168 - acc: 0.9231 - val_loss: 0.1599 - val_acc: 0.9416\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.15989 to 0.15668, saving model to best.model\n",
      "0s - loss: 0.2126 - acc: 0.9231 - val_loss: 0.1567 - val_acc: 0.9416\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.15668 to 0.15348, saving model to best.model\n",
      "0s - loss: 0.2170 - acc: 0.9226 - val_loss: 0.1535 - val_acc: 0.9416\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2132 - acc: 0.9245 - val_loss: 0.1601 - val_acc: 0.9387\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.15348 to 0.14769, saving model to best.model\n",
      "0s - loss: 0.2112 - acc: 0.9233 - val_loss: 0.1477 - val_acc: 0.9445\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.14769 to 0.14478, saving model to best.model\n",
      "0s - loss: 0.2062 - acc: 0.9214 - val_loss: 0.1448 - val_acc: 0.9455\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.14478 to 0.14131, saving model to best.model\n",
      "0s - loss: 0.2027 - acc: 0.9277 - val_loss: 0.1413 - val_acc: 0.9474\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.2022 - acc: 0.9214 - val_loss: 0.1495 - val_acc: 0.9387\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.14131 to 0.13667, saving model to best.model\n",
      "0s - loss: 0.2025 - acc: 0.9245 - val_loss: 0.1367 - val_acc: 0.9474\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13667 to 0.13460, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9277 - val_loss: 0.1346 - val_acc: 0.9542\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1906 - acc: 0.9279 - val_loss: 0.1434 - val_acc: 0.9387\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.13460 to 0.12744, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9291 - val_loss: 0.1274 - val_acc: 0.9552\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.12744 to 0.12457, saving model to best.model\n",
      "0s - loss: 0.1878 - acc: 0.9284 - val_loss: 0.1246 - val_acc: 0.9552\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1813 - acc: 0.9299 - val_loss: 0.1257 - val_acc: 0.9474\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12457 to 0.12237, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9296 - val_loss: 0.1224 - val_acc: 0.9484\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12237 to 0.11963, saving model to best.model\n",
      "0s - loss: 0.1730 - acc: 0.9340 - val_loss: 0.1196 - val_acc: 0.9533\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11963 to 0.11767, saving model to best.model\n",
      "0s - loss: 0.1688 - acc: 0.9323 - val_loss: 0.1177 - val_acc: 0.9494\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11767 to 0.11105, saving model to best.model\n",
      "0s - loss: 0.1694 - acc: 0.9330 - val_loss: 0.1110 - val_acc: 0.9562\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1701 - acc: 0.9321 - val_loss: 0.1113 - val_acc: 0.9533\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11105 to 0.10544, saving model to best.model\n",
      "0s - loss: 0.1663 - acc: 0.9318 - val_loss: 0.1054 - val_acc: 0.9581\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1597 - acc: 0.9382 - val_loss: 0.1058 - val_acc: 0.9533\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1586 - acc: 0.9345 - val_loss: 0.1069 - val_acc: 0.9523\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10544 to 0.10039, saving model to best.model\n",
      "0s - loss: 0.1568 - acc: 0.9391 - val_loss: 0.1004 - val_acc: 0.9601\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10039 to 0.09516, saving model to best.model\n",
      "0s - loss: 0.1542 - acc: 0.9403 - val_loss: 0.0952 - val_acc: 0.9640\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1509 - acc: 0.9408 - val_loss: 0.0956 - val_acc: 0.9630\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09516 to 0.09006, saving model to best.model\n",
      "0s - loss: 0.1473 - acc: 0.9408 - val_loss: 0.0901 - val_acc: 0.9688\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09006 to 0.08931, saving model to best.model\n",
      "0s - loss: 0.1457 - acc: 0.9455 - val_loss: 0.0893 - val_acc: 0.9688\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08931 to 0.08673, saving model to best.model\n",
      "0s - loss: 0.1441 - acc: 0.9450 - val_loss: 0.0867 - val_acc: 0.9747\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1381 - acc: 0.9481 - val_loss: 0.0871 - val_acc: 0.9727\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08673 to 0.08461, saving model to best.model\n",
      "0s - loss: 0.1417 - acc: 0.9472 - val_loss: 0.0846 - val_acc: 0.9737\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08461 to 0.08072, saving model to best.model\n",
      "0s - loss: 0.1353 - acc: 0.9506 - val_loss: 0.0807 - val_acc: 0.9776\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08072 to 0.07978, saving model to best.model\n",
      "0s - loss: 0.1300 - acc: 0.9511 - val_loss: 0.0798 - val_acc: 0.9776\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07978 to 0.07617, saving model to best.model\n",
      "0s - loss: 0.1283 - acc: 0.9506 - val_loss: 0.0762 - val_acc: 0.9786\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1282 - acc: 0.9501 - val_loss: 0.0784 - val_acc: 0.9757\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07617 to 0.07313, saving model to best.model\n",
      "0s - loss: 0.1178 - acc: 0.9530 - val_loss: 0.0731 - val_acc: 0.9786\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07313 to 0.07200, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9542 - val_loss: 0.0720 - val_acc: 0.9766\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.07200 to 0.07063, saving model to best.model\n",
      "0s - loss: 0.1236 - acc: 0.9564 - val_loss: 0.0706 - val_acc: 0.9776\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07063 to 0.06727, saving model to best.model\n",
      "0s - loss: 0.1246 - acc: 0.9552 - val_loss: 0.0673 - val_acc: 0.9786\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1193 - acc: 0.9552 - val_loss: 0.0693 - val_acc: 0.9805\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1152 - acc: 0.9523 - val_loss: 0.0682 - val_acc: 0.9815\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06727 to 0.06532, saving model to best.model\n",
      "0s - loss: 0.1106 - acc: 0.9562 - val_loss: 0.0653 - val_acc: 0.9815\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06532 to 0.06380, saving model to best.model\n",
      "0s - loss: 0.1071 - acc: 0.9596 - val_loss: 0.0638 - val_acc: 0.9825\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06380 to 0.06292, saving model to best.model\n",
      "0s - loss: 0.1102 - acc: 0.9610 - val_loss: 0.0629 - val_acc: 0.9825\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06292 to 0.06231, saving model to best.model\n",
      "0s - loss: 0.1112 - acc: 0.9567 - val_loss: 0.0623 - val_acc: 0.9825\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06231 to 0.05977, saving model to best.model\n",
      "0s - loss: 0.1113 - acc: 0.9601 - val_loss: 0.0598 - val_acc: 0.9805\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05977 to 0.05858, saving model to best.model\n",
      "0s - loss: 0.1076 - acc: 0.9569 - val_loss: 0.0586 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05858 to 0.05651, saving model to best.model\n",
      "0s - loss: 0.1049 - acc: 0.9637 - val_loss: 0.0565 - val_acc: 0.9805\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05651 to 0.05438, saving model to best.model\n",
      "0s - loss: 0.1023 - acc: 0.9615 - val_loss: 0.0544 - val_acc: 0.9815\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1105 - acc: 0.9584 - val_loss: 0.0639 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05438 to 0.05357, saving model to best.model\n",
      "0s - loss: 0.1004 - acc: 0.9632 - val_loss: 0.0536 - val_acc: 0.9815\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05357 to 0.05208, saving model to best.model\n",
      "0s - loss: 0.0963 - acc: 0.9615 - val_loss: 0.0521 - val_acc: 0.9815\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05208 to 0.05205, saving model to best.model\n",
      "0s - loss: 0.0965 - acc: 0.9640 - val_loss: 0.0521 - val_acc: 0.9834\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.1042 - acc: 0.9581 - val_loss: 0.0598 - val_acc: 0.9854\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05205 to 0.05185, saving model to best.model\n",
      "0s - loss: 0.1009 - acc: 0.9618 - val_loss: 0.0518 - val_acc: 0.9805\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05185 to 0.05107, saving model to best.model\n",
      "0s - loss: 0.0962 - acc: 0.9659 - val_loss: 0.0511 - val_acc: 0.9854\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05107 to 0.04904, saving model to best.model\n",
      "0s - loss: 0.0924 - acc: 0.9664 - val_loss: 0.0490 - val_acc: 0.9844\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04904 to 0.04857, saving model to best.model\n",
      "0s - loss: 0.0920 - acc: 0.9662 - val_loss: 0.0486 - val_acc: 0.9844\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0934 - acc: 0.9674 - val_loss: 0.0486 - val_acc: 0.9844\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04857 to 0.04851, saving model to best.model\n",
      "0s - loss: 0.0915 - acc: 0.9659 - val_loss: 0.0485 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04851 to 0.04527, saving model to best.model\n",
      "0s - loss: 0.0873 - acc: 0.9662 - val_loss: 0.0453 - val_acc: 0.9854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04527 to 0.04476, saving model to best.model\n",
      "0s - loss: 0.0846 - acc: 0.9666 - val_loss: 0.0448 - val_acc: 0.9854\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04476 to 0.04358, saving model to best.model\n",
      "0s - loss: 0.0791 - acc: 0.9737 - val_loss: 0.0436 - val_acc: 0.9854\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04358 to 0.04255, saving model to best.model\n",
      "0s - loss: 0.0783 - acc: 0.9701 - val_loss: 0.0426 - val_acc: 0.9834\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04255 to 0.04029, saving model to best.model\n",
      "0s - loss: 0.0784 - acc: 0.9679 - val_loss: 0.0403 - val_acc: 0.9825\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0864 - acc: 0.9683 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04029 to 0.03804, saving model to best.model\n",
      "0s - loss: 0.0776 - acc: 0.9701 - val_loss: 0.0380 - val_acc: 0.9854\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0728 - acc: 0.9727 - val_loss: 0.0404 - val_acc: 0.9854\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0789 - acc: 0.9710 - val_loss: 0.0385 - val_acc: 0.9844\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0769 - acc: 0.9710 - val_loss: 0.0394 - val_acc: 0.9844\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0746 - acc: 0.9722 - val_loss: 0.0391 - val_acc: 0.9854\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03804 to 0.03641, saving model to best.model\n",
      "0s - loss: 0.0663 - acc: 0.9778 - val_loss: 0.0364 - val_acc: 0.9854\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0752 - acc: 0.9703 - val_loss: 0.0368 - val_acc: 0.9844\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03641 to 0.03384, saving model to best.model\n",
      "0s - loss: 0.0726 - acc: 0.9705 - val_loss: 0.0338 - val_acc: 0.9864\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0706 - acc: 0.9722 - val_loss: 0.0347 - val_acc: 0.9854\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03384 to 0.03278, saving model to best.model\n",
      "0s - loss: 0.0710 - acc: 0.9713 - val_loss: 0.0328 - val_acc: 0.9864\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0737 - acc: 0.9725 - val_loss: 0.0361 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0653 - acc: 0.9747 - val_loss: 0.0341 - val_acc: 0.9854\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0662 - acc: 0.9747 - val_loss: 0.0337 - val_acc: 0.9864\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03278 to 0.02977, saving model to best.model\n",
      "0s - loss: 0.0714 - acc: 0.9715 - val_loss: 0.0298 - val_acc: 0.9864\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02977 to 0.02842, saving model to best.model\n",
      "0s - loss: 0.0688 - acc: 0.9739 - val_loss: 0.0284 - val_acc: 0.9864\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0757 - acc: 0.9696 - val_loss: 0.0437 - val_acc: 0.9844\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0873 - acc: 0.9662 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0718 - acc: 0.9713 - val_loss: 0.0342 - val_acc: 0.9873\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0673 - acc: 0.9744 - val_loss: 0.0310 - val_acc: 0.9873\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0668 - acc: 0.9759 - val_loss: 0.0322 - val_acc: 0.9864\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02842 to 0.02817, saving model to best.model\n",
      "0s - loss: 0.0595 - acc: 0.9771 - val_loss: 0.0282 - val_acc: 0.9873\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.02817 to 0.02687, saving model to best.model\n",
      "0s - loss: 0.0602 - acc: 0.9774 - val_loss: 0.0269 - val_acc: 0.9873\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0588 - acc: 0.9788 - val_loss: 0.0346 - val_acc: 0.9864\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02687 to 0.02589, saving model to best.model\n",
      "0s - loss: 0.0675 - acc: 0.9722 - val_loss: 0.0259 - val_acc: 0.9883\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0588 - acc: 0.9766 - val_loss: 0.0273 - val_acc: 0.9873\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9795 - val_loss: 0.0283 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0553 - acc: 0.9793 - val_loss: 0.0264 - val_acc: 0.9864\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0524 - acc: 0.9808 - val_loss: 0.0264 - val_acc: 0.9873\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02589 to 0.02491, saving model to best.model\n",
      "0s - loss: 0.0544 - acc: 0.9793 - val_loss: 0.0249 - val_acc: 0.9864\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9793 - val_loss: 0.0253 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02491 to 0.02364, saving model to best.model\n",
      "0s - loss: 0.0492 - acc: 0.9822 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02364 to 0.02196, saving model to best.model\n",
      "0s - loss: 0.0523 - acc: 0.9788 - val_loss: 0.0220 - val_acc: 0.9883\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9776 - val_loss: 0.0227 - val_acc: 0.9873\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02196 to 0.02146, saving model to best.model\n",
      "0s - loss: 0.0511 - acc: 0.9803 - val_loss: 0.0215 - val_acc: 0.9873\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9793 - val_loss: 0.0220 - val_acc: 0.9883\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.02146 to 0.02061, saving model to best.model\n",
      "0s - loss: 0.0597 - acc: 0.9771 - val_loss: 0.0206 - val_acc: 0.9873\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.02061 to 0.02039, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9793 - val_loss: 0.0204 - val_acc: 0.9883\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0492 - acc: 0.9825 - val_loss: 0.0217 - val_acc: 0.9883\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02039 to 0.01957, saving model to best.model\n",
      "0s - loss: 0.0517 - acc: 0.9800 - val_loss: 0.0196 - val_acc: 0.9873\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01957 to 0.01908, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9793 - val_loss: 0.0191 - val_acc: 0.9883\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0555 - acc: 0.9783 - val_loss: 0.0233 - val_acc: 0.9873\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0547 - acc: 0.9795 - val_loss: 0.0194 - val_acc: 0.9883\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9813 - val_loss: 0.0198 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01908 to 0.01767, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9842 - val_loss: 0.0177 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0492 - acc: 0.9813 - val_loss: 0.0213 - val_acc: 0.9893\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9817 - val_loss: 0.0179 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9800 - val_loss: 0.0208 - val_acc: 0.9893\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9803 - val_loss: 0.0181 - val_acc: 0.9903\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0489 - acc: 0.9815 - val_loss: 0.0190 - val_acc: 0.9893\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01767 to 0.01668, saving model to best.model\n",
      "0s - loss: 0.0417 - acc: 0.9839 - val_loss: 0.0167 - val_acc: 0.9893\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9856 - val_loss: 0.0171 - val_acc: 0.9893\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01668 to 0.01667, saving model to best.model\n",
      "0s - loss: 0.0441 - acc: 0.9844 - val_loss: 0.0167 - val_acc: 0.9893\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0448 - acc: 0.9822 - val_loss: 0.0167 - val_acc: 0.9903\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01667 to 0.01514, saving model to best.model\n",
      "0s - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0151 - val_acc: 0.9903\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01514 to 0.01446, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9839 - val_loss: 0.0145 - val_acc: 0.9912\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.01446 to 0.01380, saving model to best.model\n",
      "0s - loss: 0.0417 - acc: 0.9815 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9830 - val_loss: 0.0162 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9827 - val_loss: 0.0148 - val_acc: 0.9903\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0441 - acc: 0.9832 - val_loss: 0.0150 - val_acc: 0.9912\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0425 - acc: 0.9847 - val_loss: 0.0144 - val_acc: 0.9912\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9842 - val_loss: 0.0139 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0419 - acc: 0.9849 - val_loss: 0.0146 - val_acc: 0.9912\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01380 to 0.01309, saving model to best.model\n",
      "0s - loss: 0.0478 - acc: 0.9822 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9871 - val_loss: 0.0162 - val_acc: 0.9903\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9830 - val_loss: 0.0134 - val_acc: 0.9912\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9854 - val_loss: 0.0153 - val_acc: 0.9922\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9849 - val_loss: 0.0143 - val_acc: 0.9912\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9861 - val_loss: 0.0135 - val_acc: 0.9922\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0370 - acc: 0.9861 - val_loss: 0.0137 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01309 to 0.01256, saving model to best.model\n",
      "0s - loss: 0.0394 - acc: 0.9861 - val_loss: 0.0126 - val_acc: 0.9922\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9832 - val_loss: 0.0134 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9859 - val_loss: 0.0134 - val_acc: 0.9922\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01256 to 0.01255, saving model to best.model\n",
      "0s - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0126 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9842 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9859 - val_loss: 0.0181 - val_acc: 0.9873\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9856 - val_loss: 0.0140 - val_acc: 0.9903\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9832 - val_loss: 0.0165 - val_acc: 0.9893\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01255 to 0.01073, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9844 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9851 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9859 - val_loss: 0.0150 - val_acc: 0.9903\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9849 - val_loss: 0.0140 - val_acc: 0.9912\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9849 - val_loss: 0.0132 - val_acc: 0.9912\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9866 - val_loss: 0.0131 - val_acc: 0.9912\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9851 - val_loss: 0.0145 - val_acc: 0.9912\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9847 - val_loss: 0.0112 - val_acc: 0.9961\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9861 - val_loss: 0.0136 - val_acc: 0.9912\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9888 - val_loss: 0.0129 - val_acc: 0.9912\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9876 - val_loss: 0.0123 - val_acc: 0.9912\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9869 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9854 - val_loss: 0.0114 - val_acc: 0.9922\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9883 - val_loss: 0.0121 - val_acc: 0.9912\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.01073 to 0.00874, saving model to best.model\n",
      "0s - loss: 0.0309 - acc: 0.9881 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9866 - val_loss: 0.0094 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9886 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9869 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00874 to 0.00809, saving model to best.model\n",
      "0s - loss: 0.0306 - acc: 0.9886 - val_loss: 0.0081 - val_acc: 0.9951\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9886 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0260 - acc: 0.9905 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9873 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9856 - val_loss: 0.0099 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00809 to 0.00741, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9876 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68956, saving model to best.model\n",
      "0s - loss: 0.8519 - acc: 0.5006 - val_loss: 0.6896 - val_acc: 0.5112\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68956 to 0.65481, saving model to best.model\n",
      "0s - loss: 0.7702 - acc: 0.5230 - val_loss: 0.6548 - val_acc: 0.4888\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65481 to 0.59771, saving model to best.model\n",
      "0s - loss: 0.7125 - acc: 0.5542 - val_loss: 0.5977 - val_acc: 0.8364\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59771 to 0.52302, saving model to best.model\n",
      "0s - loss: 0.6475 - acc: 0.6228 - val_loss: 0.5230 - val_acc: 0.8277\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52302 to 0.44780, saving model to best.model\n",
      "0s - loss: 0.5650 - acc: 0.7163 - val_loss: 0.4478 - val_acc: 0.8481\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44780 to 0.40157, saving model to best.model\n",
      "0s - loss: 0.4951 - acc: 0.7762 - val_loss: 0.4016 - val_acc: 0.8510\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40157 to 0.37867, saving model to best.model\n",
      "0s - loss: 0.4485 - acc: 0.8055 - val_loss: 0.3787 - val_acc: 0.8627\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37867 to 0.36056, saving model to best.model\n",
      "0s - loss: 0.4165 - acc: 0.8254 - val_loss: 0.3606 - val_acc: 0.8627\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36056 to 0.34573, saving model to best.model\n",
      "0s - loss: 0.3934 - acc: 0.8432 - val_loss: 0.3457 - val_acc: 0.8656\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34573 to 0.33516, saving model to best.model\n",
      "0s - loss: 0.3712 - acc: 0.8527 - val_loss: 0.3352 - val_acc: 0.8695\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33516 to 0.32472, saving model to best.model\n",
      "0s - loss: 0.3631 - acc: 0.8636 - val_loss: 0.3247 - val_acc: 0.8705\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.32472 to 0.31121, saving model to best.model\n",
      "0s - loss: 0.3376 - acc: 0.8697 - val_loss: 0.3112 - val_acc: 0.8793\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.31121 to 0.30634, saving model to best.model\n",
      "0s - loss: 0.3361 - acc: 0.8692 - val_loss: 0.3063 - val_acc: 0.8822\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.30634 to 0.29416, saving model to best.model\n",
      "0s - loss: 0.3317 - acc: 0.8717 - val_loss: 0.2942 - val_acc: 0.8841\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.3193 - acc: 0.8804 - val_loss: 0.2946 - val_acc: 0.8900\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.29416 to 0.27937, saving model to best.model\n",
      "0s - loss: 0.3099 - acc: 0.8853 - val_loss: 0.2794 - val_acc: 0.8890\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.27937 to 0.27897, saving model to best.model\n",
      "0s - loss: 0.2967 - acc: 0.8916 - val_loss: 0.2790 - val_acc: 0.8948\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.27897 to 0.26872, saving model to best.model\n",
      "0s - loss: 0.2951 - acc: 0.8912 - val_loss: 0.2687 - val_acc: 0.8909\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26872 to 0.26150, saving model to best.model\n",
      "0s - loss: 0.2862 - acc: 0.8968 - val_loss: 0.2615 - val_acc: 0.8997\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2841 - acc: 0.8946 - val_loss: 0.2664 - val_acc: 0.8997\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.26150 to 0.25430, saving model to best.model\n",
      "0s - loss: 0.2825 - acc: 0.8965 - val_loss: 0.2543 - val_acc: 0.9046\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25430 to 0.24941, saving model to best.model\n",
      "0s - loss: 0.2675 - acc: 0.8990 - val_loss: 0.2494 - val_acc: 0.9065\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.24941 to 0.23950, saving model to best.model\n",
      "0s - loss: 0.2605 - acc: 0.9067 - val_loss: 0.2395 - val_acc: 0.9114\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2584 - acc: 0.9089 - val_loss: 0.2401 - val_acc: 0.9104\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.23950 to 0.23507, saving model to best.model\n",
      "0s - loss: 0.2563 - acc: 0.9097 - val_loss: 0.2351 - val_acc: 0.9133\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23507 to 0.22429, saving model to best.model\n",
      "0s - loss: 0.2526 - acc: 0.9109 - val_loss: 0.2243 - val_acc: 0.9143\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2441 - acc: 0.9097 - val_loss: 0.2267 - val_acc: 0.9124\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.22429 to 0.21366, saving model to best.model\n",
      "0s - loss: 0.2428 - acc: 0.9150 - val_loss: 0.2137 - val_acc: 0.9153\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.21366 to 0.21057, saving model to best.model\n",
      "0s - loss: 0.2340 - acc: 0.9140 - val_loss: 0.2106 - val_acc: 0.9172\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.21057 to 0.20773, saving model to best.model\n",
      "0s - loss: 0.2384 - acc: 0.9133 - val_loss: 0.2077 - val_acc: 0.9143\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20773 to 0.20109, saving model to best.model\n",
      "0s - loss: 0.2292 - acc: 0.9167 - val_loss: 0.2011 - val_acc: 0.9163\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20109 to 0.19653, saving model to best.model\n",
      "0s - loss: 0.2244 - acc: 0.9179 - val_loss: 0.1965 - val_acc: 0.9153\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2288 - acc: 0.9143 - val_loss: 0.2005 - val_acc: 0.9153\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19653 to 0.18807, saving model to best.model\n",
      "0s - loss: 0.2184 - acc: 0.9199 - val_loss: 0.1881 - val_acc: 0.9202\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18807 to 0.18603, saving model to best.model\n",
      "0s - loss: 0.2159 - acc: 0.9211 - val_loss: 0.1860 - val_acc: 0.9182\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18603 to 0.18500, saving model to best.model\n",
      "0s - loss: 0.2058 - acc: 0.9257 - val_loss: 0.1850 - val_acc: 0.9192\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18500 to 0.17554, saving model to best.model\n",
      "0s - loss: 0.2075 - acc: 0.9216 - val_loss: 0.1755 - val_acc: 0.9289\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2010 - acc: 0.9252 - val_loss: 0.1770 - val_acc: 0.9241\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17554 to 0.17195, saving model to best.model\n",
      "0s - loss: 0.1966 - acc: 0.9294 - val_loss: 0.1720 - val_acc: 0.9260\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17195 to 0.16536, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9260 - val_loss: 0.1654 - val_acc: 0.9289\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16536 to 0.16361, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9274 - val_loss: 0.1636 - val_acc: 0.9299\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.16361 to 0.15942, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9328 - val_loss: 0.1594 - val_acc: 0.9309\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15942 to 0.15505, saving model to best.model\n",
      "0s - loss: 0.1872 - acc: 0.9313 - val_loss: 0.1550 - val_acc: 0.9377\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1833 - acc: 0.9328 - val_loss: 0.1566 - val_acc: 0.9309\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15505 to 0.14872, saving model to best.model\n",
      "0s - loss: 0.1832 - acc: 0.9330 - val_loss: 0.1487 - val_acc: 0.9494\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14872 to 0.14607, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9389 - val_loss: 0.1461 - val_acc: 0.9474\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14607 to 0.14565, saving model to best.model\n",
      "0s - loss: 0.1714 - acc: 0.9350 - val_loss: 0.1457 - val_acc: 0.9464\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14565 to 0.13684, saving model to best.model\n",
      "0s - loss: 0.1623 - acc: 0.9416 - val_loss: 0.1368 - val_acc: 0.9533\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1618 - acc: 0.9401 - val_loss: 0.1388 - val_acc: 0.9533\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.13684 to 0.13521, saving model to best.model\n",
      "0s - loss: 0.1590 - acc: 0.9435 - val_loss: 0.1352 - val_acc: 0.9542\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.13521 to 0.12827, saving model to best.model\n",
      "0s - loss: 0.1550 - acc: 0.9391 - val_loss: 0.1283 - val_acc: 0.9542\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12827 to 0.12597, saving model to best.model\n",
      "0s - loss: 0.1575 - acc: 0.9447 - val_loss: 0.1260 - val_acc: 0.9562\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.12597 to 0.12547, saving model to best.model\n",
      "0s - loss: 0.1397 - acc: 0.9481 - val_loss: 0.1255 - val_acc: 0.9591\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.12547 to 0.11853, saving model to best.model\n",
      "0s - loss: 0.1502 - acc: 0.9447 - val_loss: 0.1185 - val_acc: 0.9572\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1499 - acc: 0.9462 - val_loss: 0.1252 - val_acc: 0.9611\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.11853 to 0.11464, saving model to best.model\n",
      "0s - loss: 0.1457 - acc: 0.9484 - val_loss: 0.1146 - val_acc: 0.9581\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1452 - acc: 0.9479 - val_loss: 0.1154 - val_acc: 0.9630\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.11464 to 0.10983, saving model to best.model\n",
      "0s - loss: 0.1390 - acc: 0.9506 - val_loss: 0.1098 - val_acc: 0.9630\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.10983 to 0.10706, saving model to best.model\n",
      "0s - loss: 0.1315 - acc: 0.9523 - val_loss: 0.1071 - val_acc: 0.9620\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.10706 to 0.10523, saving model to best.model\n",
      "0s - loss: 0.1296 - acc: 0.9545 - val_loss: 0.1052 - val_acc: 0.9630\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1321 - acc: 0.9545 - val_loss: 0.1078 - val_acc: 0.9679\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1285 - acc: 0.9559 - val_loss: 0.1105 - val_acc: 0.9659\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1360 - acc: 0.9491 - val_loss: 0.1069 - val_acc: 0.9679\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10523 to 0.09995, saving model to best.model\n",
      "0s - loss: 0.1283 - acc: 0.9540 - val_loss: 0.0999 - val_acc: 0.9640\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1216 - acc: 0.9576 - val_loss: 0.1008 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09995 to 0.09448, saving model to best.model\n",
      "0s - loss: 0.1191 - acc: 0.9581 - val_loss: 0.0945 - val_acc: 0.9630\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09448 to 0.09304, saving model to best.model\n",
      "0s - loss: 0.1198 - acc: 0.9581 - val_loss: 0.0930 - val_acc: 0.9688\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09304 to 0.08792, saving model to best.model\n",
      "0s - loss: 0.1174 - acc: 0.9586 - val_loss: 0.0879 - val_acc: 0.9640\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1132 - acc: 0.9579 - val_loss: 0.0941 - val_acc: 0.9679\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08792 to 0.08432, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9593 - val_loss: 0.0843 - val_acc: 0.9649\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1124 - acc: 0.9606 - val_loss: 0.0881 - val_acc: 0.9727\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08432 to 0.08323, saving model to best.model\n",
      "0s - loss: 0.1141 - acc: 0.9557 - val_loss: 0.0832 - val_acc: 0.9688\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1063 - acc: 0.9606 - val_loss: 0.0878 - val_acc: 0.9718\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08323 to 0.08228, saving model to best.model\n",
      "0s - loss: 0.0981 - acc: 0.9652 - val_loss: 0.0823 - val_acc: 0.9727\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08228 to 0.07923, saving model to best.model\n",
      "0s - loss: 0.1015 - acc: 0.9659 - val_loss: 0.0792 - val_acc: 0.9727\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07923 to 0.07665, saving model to best.model\n",
      "0s - loss: 0.1039 - acc: 0.9625 - val_loss: 0.0767 - val_acc: 0.9737\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07665 to 0.07323, saving model to best.model\n",
      "0s - loss: 0.0980 - acc: 0.9662 - val_loss: 0.0732 - val_acc: 0.9727\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0982 - acc: 0.9671 - val_loss: 0.0742 - val_acc: 0.9757\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07323 to 0.07164, saving model to best.model\n",
      "0s - loss: 0.0942 - acc: 0.9662 - val_loss: 0.0716 - val_acc: 0.9737\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07164 to 0.07098, saving model to best.model\n",
      "0s - loss: 0.0908 - acc: 0.9666 - val_loss: 0.0710 - val_acc: 0.9737\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0938 - acc: 0.9657 - val_loss: 0.0719 - val_acc: 0.9757\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.07098 to 0.06594, saving model to best.model\n",
      "0s - loss: 0.0863 - acc: 0.9696 - val_loss: 0.0659 - val_acc: 0.9757\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0889 - acc: 0.9659 - val_loss: 0.0686 - val_acc: 0.9757\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06594 to 0.06520, saving model to best.model\n",
      "0s - loss: 0.0871 - acc: 0.9676 - val_loss: 0.0652 - val_acc: 0.9757\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06520 to 0.06137, saving model to best.model\n",
      "0s - loss: 0.0841 - acc: 0.9718 - val_loss: 0.0614 - val_acc: 0.9766\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0850 - acc: 0.9705 - val_loss: 0.0641 - val_acc: 0.9757\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06137 to 0.05930, saving model to best.model\n",
      "0s - loss: 0.0818 - acc: 0.9708 - val_loss: 0.0593 - val_acc: 0.9766\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0864 - acc: 0.9688 - val_loss: 0.0675 - val_acc: 0.9776\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05930 to 0.05734, saving model to best.model\n",
      "0s - loss: 0.0840 - acc: 0.9688 - val_loss: 0.0573 - val_acc: 0.9766\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05734 to 0.05461, saving model to best.model\n",
      "0s - loss: 0.0843 - acc: 0.9696 - val_loss: 0.0546 - val_acc: 0.9766\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0892 - acc: 0.9683 - val_loss: 0.0576 - val_acc: 0.9766\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0811 - acc: 0.9730 - val_loss: 0.0595 - val_acc: 0.9776\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0817 - acc: 0.9710 - val_loss: 0.0587 - val_acc: 0.9776\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05461 to 0.05270, saving model to best.model\n",
      "0s - loss: 0.0690 - acc: 0.9744 - val_loss: 0.0527 - val_acc: 0.9776\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0769 - acc: 0.9739 - val_loss: 0.0544 - val_acc: 0.9776\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.05270 to 0.05050, saving model to best.model\n",
      "0s - loss: 0.0731 - acc: 0.9739 - val_loss: 0.0505 - val_acc: 0.9776\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0717 - acc: 0.9749 - val_loss: 0.0542 - val_acc: 0.9796\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0727 - acc: 0.9747 - val_loss: 0.0513 - val_acc: 0.9776\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.05050 to 0.04893, saving model to best.model\n",
      "0s - loss: 0.0711 - acc: 0.9757 - val_loss: 0.0489 - val_acc: 0.9776\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9778 - val_loss: 0.0537 - val_acc: 0.9776\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04893 to 0.04557, saving model to best.model\n",
      "0s - loss: 0.0676 - acc: 0.9757 - val_loss: 0.0456 - val_acc: 0.9776\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0784 - acc: 0.9720 - val_loss: 0.0591 - val_acc: 0.9776\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0702 - acc: 0.9735 - val_loss: 0.0515 - val_acc: 0.9776\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9754 - val_loss: 0.0516 - val_acc: 0.9796\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0649 - acc: 0.9766 - val_loss: 0.0471 - val_acc: 0.9776\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0655 - acc: 0.9752 - val_loss: 0.0481 - val_acc: 0.9776\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.04557 to 0.04386, saving model to best.model\n",
      "0s - loss: 0.0649 - acc: 0.9761 - val_loss: 0.0439 - val_acc: 0.9786\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0634 - acc: 0.9766 - val_loss: 0.0478 - val_acc: 0.9776\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0628 - acc: 0.9774 - val_loss: 0.0439 - val_acc: 0.9776\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.04386 to 0.04129, saving model to best.model\n",
      "0s - loss: 0.0619 - acc: 0.9776 - val_loss: 0.0413 - val_acc: 0.9786\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9781 - val_loss: 0.0449 - val_acc: 0.9776\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0692 - acc: 0.9754 - val_loss: 0.0519 - val_acc: 0.9796\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0675 - acc: 0.9752 - val_loss: 0.0428 - val_acc: 0.9786\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9805 - val_loss: 0.0449 - val_acc: 0.9796\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.04129 to 0.03970, saving model to best.model\n",
      "0s - loss: 0.0603 - acc: 0.9766 - val_loss: 0.0397 - val_acc: 0.9796\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.03970 to 0.03901, saving model to best.model\n",
      "0s - loss: 0.0577 - acc: 0.9769 - val_loss: 0.0390 - val_acc: 0.9796\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0595 - acc: 0.9808 - val_loss: 0.0400 - val_acc: 0.9796\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.03901 to 0.03797, saving model to best.model\n",
      "0s - loss: 0.0531 - acc: 0.9817 - val_loss: 0.0380 - val_acc: 0.9786\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0551 - acc: 0.9791 - val_loss: 0.0447 - val_acc: 0.9796\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.03797 to 0.03596, saving model to best.model\n",
      "0s - loss: 0.0570 - acc: 0.9798 - val_loss: 0.0360 - val_acc: 0.9796\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.03596 to 0.03356, saving model to best.model\n",
      "0s - loss: 0.0569 - acc: 0.9778 - val_loss: 0.0336 - val_acc: 0.9805\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0542 - acc: 0.9810 - val_loss: 0.0446 - val_acc: 0.9796\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9839 - val_loss: 0.0352 - val_acc: 0.9786\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0547 - acc: 0.9793 - val_loss: 0.0394 - val_acc: 0.9805\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03356 to 0.03177, saving model to best.model\n",
      "0s - loss: 0.0511 - acc: 0.9800 - val_loss: 0.0318 - val_acc: 0.9796\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0550 - acc: 0.9788 - val_loss: 0.0333 - val_acc: 0.9815\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.03177 to 0.02976, saving model to best.model\n",
      "0s - loss: 0.0573 - acc: 0.9783 - val_loss: 0.0298 - val_acc: 0.9815\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0563 - acc: 0.9795 - val_loss: 0.0324 - val_acc: 0.9796\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9813 - val_loss: 0.0390 - val_acc: 0.9805\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9803 - val_loss: 0.0362 - val_acc: 0.9805\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02976 to 0.02956, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9786 - val_loss: 0.0296 - val_acc: 0.9825\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0489 - acc: 0.9827 - val_loss: 0.0353 - val_acc: 0.9815\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0441 - acc: 0.9830 - val_loss: 0.0328 - val_acc: 0.9815\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02956 to 0.02821, saving model to best.model\n",
      "0s - loss: 0.0484 - acc: 0.9834 - val_loss: 0.0282 - val_acc: 0.9825\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9832 - val_loss: 0.0333 - val_acc: 0.9815\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9837 - val_loss: 0.0300 - val_acc: 0.9834\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02821 to 0.02755, saving model to best.model\n",
      "0s - loss: 0.0506 - acc: 0.9808 - val_loss: 0.0276 - val_acc: 0.9805\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0457 - acc: 0.9837 - val_loss: 0.0305 - val_acc: 0.9796\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02755 to 0.02662, saving model to best.model\n",
      "0s - loss: 0.0499 - acc: 0.9827 - val_loss: 0.0266 - val_acc: 0.9825\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0523 - acc: 0.9813 - val_loss: 0.0326 - val_acc: 0.9825\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9856 - val_loss: 0.0273 - val_acc: 0.9844\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02662 to 0.02618, saving model to best.model\n",
      "0s - loss: 0.0444 - acc: 0.9849 - val_loss: 0.0262 - val_acc: 0.9854\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9820 - val_loss: 0.0303 - val_acc: 0.9825\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.02618 to 0.02398, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9861 - val_loss: 0.0240 - val_acc: 0.9825\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9832 - val_loss: 0.0271 - val_acc: 0.9844\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02398 to 0.02360, saving model to best.model\n",
      "0s - loss: 0.0371 - acc: 0.9856 - val_loss: 0.0236 - val_acc: 0.9864\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.02360 to 0.02294, saving model to best.model\n",
      "0s - loss: 0.0454 - acc: 0.9847 - val_loss: 0.0229 - val_acc: 0.9854\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0433 - acc: 0.9832 - val_loss: 0.0358 - val_acc: 0.9844\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9856 - val_loss: 0.0266 - val_acc: 0.9864\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9842 - val_loss: 0.0257 - val_acc: 0.9864\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9864 - val_loss: 0.0264 - val_acc: 0.9854\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9842 - val_loss: 0.0276 - val_acc: 0.9854\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9810 - val_loss: 0.0242 - val_acc: 0.9864\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9864 - val_loss: 0.0242 - val_acc: 0.9864\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.02294 to 0.02261, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9878 - val_loss: 0.0226 - val_acc: 0.9854\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0435 - acc: 0.9851 - val_loss: 0.0227 - val_acc: 0.9854\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9854 - val_loss: 0.0237 - val_acc: 0.9864\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02261 to 0.02094, saving model to best.model\n",
      "0s - loss: 0.0402 - acc: 0.9856 - val_loss: 0.0209 - val_acc: 0.9854\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9859 - val_loss: 0.0258 - val_acc: 0.9844\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9842 - val_loss: 0.0225 - val_acc: 0.9864\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.02094 to 0.01952, saving model to best.model\n",
      "0s - loss: 0.0453 - acc: 0.9832 - val_loss: 0.0195 - val_acc: 0.9864\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9859 - val_loss: 0.0220 - val_acc: 0.9864\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9886 - val_loss: 0.0210 - val_acc: 0.9864\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9849 - val_loss: 0.0221 - val_acc: 0.9854\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9888 - val_loss: 0.0225 - val_acc: 0.9854\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9864 - val_loss: 0.0206 - val_acc: 0.9864\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01952 to 0.01890, saving model to best.model\n",
      "0s - loss: 0.0374 - acc: 0.9844 - val_loss: 0.0189 - val_acc: 0.9883\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9881 - val_loss: 0.0240 - val_acc: 0.9864\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01890 to 0.01805, saving model to best.model\n",
      "0s - loss: 0.0364 - acc: 0.9878 - val_loss: 0.0181 - val_acc: 0.9864\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0300 - acc: 0.9890 - val_loss: 0.0244 - val_acc: 0.9864\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9886 - val_loss: 0.0206 - val_acc: 0.9864\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9851 - val_loss: 0.0216 - val_acc: 0.9854\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01805 to 0.01762, saving model to best.model\n",
      "0s - loss: 0.0348 - acc: 0.9898 - val_loss: 0.0176 - val_acc: 0.9903\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9842 - val_loss: 0.0283 - val_acc: 0.9844\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.01762 to 0.01692, saving model to best.model\n",
      "0s - loss: 0.0404 - acc: 0.9866 - val_loss: 0.0169 - val_acc: 0.9903\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9859 - val_loss: 0.0193 - val_acc: 0.9864\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9869 - val_loss: 0.0188 - val_acc: 0.9864\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9876 - val_loss: 0.0175 - val_acc: 0.9883\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9886 - val_loss: 0.0185 - val_acc: 0.9873\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9873 - val_loss: 0.0175 - val_acc: 0.9883\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01692 to 0.01440, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0144 - val_acc: 0.9922\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0265 - acc: 0.9903 - val_loss: 0.0195 - val_acc: 0.9873\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9883 - val_loss: 0.0153 - val_acc: 0.9903\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9881 - val_loss: 0.0230 - val_acc: 0.9864\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01440 to 0.01414, saving model to best.model\n",
      "0s - loss: 0.0311 - acc: 0.9866 - val_loss: 0.0141 - val_acc: 0.9912\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9903 - val_loss: 0.0183 - val_acc: 0.9864\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9903 - val_loss: 0.0172 - val_acc: 0.9864\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9907 - val_loss: 0.0166 - val_acc: 0.9883\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0278 - acc: 0.9883 - val_loss: 0.0147 - val_acc: 0.9903\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.01414 to 0.01317, saving model to best.model\n",
      "0s - loss: 0.0287 - acc: 0.9900 - val_loss: 0.0132 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9910 - val_loss: 0.0156 - val_acc: 0.9903\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.01317 to 0.01204, saving model to best.model\n",
      "0s - loss: 0.0262 - acc: 0.9898 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9898 - val_loss: 0.0168 - val_acc: 0.9883\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9915 - val_loss: 0.0132 - val_acc: 0.9922\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0145 - val_acc: 0.9903\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0260 - acc: 0.9907 - val_loss: 0.0134 - val_acc: 0.9912\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9903 - val_loss: 0.0227 - val_acc: 0.9864\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9881 - val_loss: 0.0150 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9876 - val_loss: 0.0171 - val_acc: 0.9864\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0264 - acc: 0.9907 - val_loss: 0.0157 - val_acc: 0.9903\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67870, saving model to best.model\n",
      "0s - loss: 0.8674 - acc: 0.5065 - val_loss: 0.6787 - val_acc: 0.5375\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67870 to 0.66453, saving model to best.model\n",
      "0s - loss: 0.7643 - acc: 0.5267 - val_loss: 0.6645 - val_acc: 0.6913\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66453 to 0.63066, saving model to best.model\n",
      "0s - loss: 0.7403 - acc: 0.5308 - val_loss: 0.6307 - val_acc: 0.8043\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.63066 to 0.57958, saving model to best.model\n",
      "0s - loss: 0.6767 - acc: 0.5883 - val_loss: 0.5796 - val_acc: 0.8092\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.57958 to 0.50898, saving model to best.model\n",
      "0s - loss: 0.6147 - acc: 0.6611 - val_loss: 0.5090 - val_acc: 0.8111\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.50898 to 0.45258, saving model to best.model\n",
      "0s - loss: 0.5343 - acc: 0.7460 - val_loss: 0.4526 - val_acc: 0.8199\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.45258 to 0.41370, saving model to best.model\n",
      "0s - loss: 0.4781 - acc: 0.7923 - val_loss: 0.4137 - val_acc: 0.8354\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.41370 to 0.39049, saving model to best.model\n",
      "0s - loss: 0.4340 - acc: 0.8213 - val_loss: 0.3905 - val_acc: 0.8520\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.39049 to 0.38096, saving model to best.model\n",
      "0s - loss: 0.4042 - acc: 0.8386 - val_loss: 0.3810 - val_acc: 0.8569\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.38096 to 0.36017, saving model to best.model\n",
      "0s - loss: 0.3833 - acc: 0.8554 - val_loss: 0.3602 - val_acc: 0.8676\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.36017 to 0.33534, saving model to best.model\n",
      "0s - loss: 0.3606 - acc: 0.8624 - val_loss: 0.3353 - val_acc: 0.8695\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.33534 to 0.32621, saving model to best.model\n",
      "0s - loss: 0.3541 - acc: 0.8598 - val_loss: 0.3262 - val_acc: 0.8744\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.32621 to 0.31230, saving model to best.model\n",
      "0s - loss: 0.3309 - acc: 0.8768 - val_loss: 0.3123 - val_acc: 0.8763\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.31230 to 0.30485, saving model to best.model\n",
      "0s - loss: 0.3220 - acc: 0.8804 - val_loss: 0.3048 - val_acc: 0.8861\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.30485 to 0.30065, saving model to best.model\n",
      "0s - loss: 0.2964 - acc: 0.8914 - val_loss: 0.3006 - val_acc: 0.8870\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.30065 to 0.29958, saving model to best.model\n",
      "0s - loss: 0.2920 - acc: 0.8887 - val_loss: 0.2996 - val_acc: 0.8909\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.29958 to 0.27273, saving model to best.model\n",
      "0s - loss: 0.2931 - acc: 0.9016 - val_loss: 0.2727 - val_acc: 0.8997\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2783 - acc: 0.9024 - val_loss: 0.2729 - val_acc: 0.9007\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.27273 to 0.25897, saving model to best.model\n",
      "0s - loss: 0.2747 - acc: 0.9009 - val_loss: 0.2590 - val_acc: 0.9094\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2696 - acc: 0.9075 - val_loss: 0.2676 - val_acc: 0.9065\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.25897 to 0.25198, saving model to best.model\n",
      "0s - loss: 0.2657 - acc: 0.9077 - val_loss: 0.2520 - val_acc: 0.9094\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25198 to 0.24878, saving model to best.model\n",
      "0s - loss: 0.2611 - acc: 0.9099 - val_loss: 0.2488 - val_acc: 0.9133\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2521 - acc: 0.9099 - val_loss: 0.2601 - val_acc: 0.9094\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24878 to 0.23896, saving model to best.model\n",
      "0s - loss: 0.2487 - acc: 0.9119 - val_loss: 0.2390 - val_acc: 0.9163\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2507 - acc: 0.9148 - val_loss: 0.2445 - val_acc: 0.9114\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23896 to 0.22630, saving model to best.model\n",
      "0s - loss: 0.2492 - acc: 0.9128 - val_loss: 0.2263 - val_acc: 0.9221\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2419 - acc: 0.9165 - val_loss: 0.2381 - val_acc: 0.9104\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.22630 to 0.22115, saving model to best.model\n",
      "0s - loss: 0.2319 - acc: 0.9194 - val_loss: 0.2211 - val_acc: 0.9202\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2277 - acc: 0.9204 - val_loss: 0.2245 - val_acc: 0.9172\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22115 to 0.21435, saving model to best.model\n",
      "0s - loss: 0.2245 - acc: 0.9221 - val_loss: 0.2143 - val_acc: 0.9221\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2251 - acc: 0.9201 - val_loss: 0.2216 - val_acc: 0.9172\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.21435 to 0.21035, saving model to best.model\n",
      "0s - loss: 0.2241 - acc: 0.9223 - val_loss: 0.2103 - val_acc: 0.9221\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2227 - acc: 0.9233 - val_loss: 0.2200 - val_acc: 0.9153\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.21035 to 0.20249, saving model to best.model\n",
      "0s - loss: 0.2149 - acc: 0.9226 - val_loss: 0.2025 - val_acc: 0.9250\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.2081 - acc: 0.9267 - val_loss: 0.2126 - val_acc: 0.9163\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.20249 to 0.19778, saving model to best.model\n",
      "0s - loss: 0.2065 - acc: 0.9265 - val_loss: 0.1978 - val_acc: 0.9221\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.19778 to 0.19112, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9308 - val_loss: 0.1911 - val_acc: 0.9211\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1976 - acc: 0.9284 - val_loss: 0.1944 - val_acc: 0.9192\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19112 to 0.17983, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9282 - val_loss: 0.1798 - val_acc: 0.9318\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1974 - acc: 0.9306 - val_loss: 0.1814 - val_acc: 0.9270\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17983 to 0.17591, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9316 - val_loss: 0.1759 - val_acc: 0.9289\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17591 to 0.17498, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9296 - val_loss: 0.1750 - val_acc: 0.9318\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17498 to 0.17150, saving model to best.model\n",
      "0s - loss: 0.1880 - acc: 0.9316 - val_loss: 0.1715 - val_acc: 0.9377\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.17150 to 0.16905, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9360 - val_loss: 0.1690 - val_acc: 0.9357\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16905 to 0.16519, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9338 - val_loss: 0.1652 - val_acc: 0.9387\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1828 - acc: 0.9316 - val_loss: 0.1661 - val_acc: 0.9357\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1769 - acc: 0.9367 - val_loss: 0.1673 - val_acc: 0.9318\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.16519 to 0.15722, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9323 - val_loss: 0.1572 - val_acc: 0.9357\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15722 to 0.14952, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9347 - val_loss: 0.1495 - val_acc: 0.9416\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1747 - acc: 0.9382 - val_loss: 0.1567 - val_acc: 0.9318\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14952 to 0.14232, saving model to best.model\n",
      "0s - loss: 0.1672 - acc: 0.9391 - val_loss: 0.1423 - val_acc: 0.9455\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1651 - acc: 0.9408 - val_loss: 0.1632 - val_acc: 0.9279\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14232 to 0.13893, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9386 - val_loss: 0.1389 - val_acc: 0.9435\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1595 - acc: 0.9425 - val_loss: 0.1407 - val_acc: 0.9435\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1624 - acc: 0.9421 - val_loss: 0.1400 - val_acc: 0.9435\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13893 to 0.13405, saving model to best.model\n",
      "0s - loss: 0.1600 - acc: 0.9403 - val_loss: 0.1341 - val_acc: 0.9445\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.13405 to 0.13246, saving model to best.model\n",
      "0s - loss: 0.1474 - acc: 0.9464 - val_loss: 0.1325 - val_acc: 0.9426\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1540 - acc: 0.9452 - val_loss: 0.1356 - val_acc: 0.9464\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.13246 to 0.12547, saving model to best.model\n",
      "0s - loss: 0.1431 - acc: 0.9474 - val_loss: 0.1255 - val_acc: 0.9455\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1416 - acc: 0.9472 - val_loss: 0.1336 - val_acc: 0.9435\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.12547 to 0.11721, saving model to best.model\n",
      "0s - loss: 0.1465 - acc: 0.9457 - val_loss: 0.1172 - val_acc: 0.9513\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1415 - acc: 0.9474 - val_loss: 0.1261 - val_acc: 0.9474\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11721 to 0.11376, saving model to best.model\n",
      "0s - loss: 0.1424 - acc: 0.9459 - val_loss: 0.1138 - val_acc: 0.9513\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1353 - acc: 0.9506 - val_loss: 0.1195 - val_acc: 0.9494\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.11376 to 0.11112, saving model to best.model\n",
      "0s - loss: 0.1315 - acc: 0.9523 - val_loss: 0.1111 - val_acc: 0.9513\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.11112 to 0.09922, saving model to best.model\n",
      "0s - loss: 0.1332 - acc: 0.9486 - val_loss: 0.0992 - val_acc: 0.9659\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1321 - acc: 0.9501 - val_loss: 0.1085 - val_acc: 0.9562\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09922 to 0.09285, saving model to best.model\n",
      "0s - loss: 0.1328 - acc: 0.9506 - val_loss: 0.0929 - val_acc: 0.9659\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1379 - acc: 0.9513 - val_loss: 0.0963 - val_acc: 0.9649\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1221 - acc: 0.9540 - val_loss: 0.0984 - val_acc: 0.9640\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1198 - acc: 0.9547 - val_loss: 0.1024 - val_acc: 0.9630\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.09285 to 0.08523, saving model to best.model\n",
      "0s - loss: 0.1277 - acc: 0.9528 - val_loss: 0.0852 - val_acc: 0.9669\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1249 - acc: 0.9518 - val_loss: 0.0930 - val_acc: 0.9649\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08523 to 0.08183, saving model to best.model\n",
      "0s - loss: 0.1180 - acc: 0.9552 - val_loss: 0.0818 - val_acc: 0.9698\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1199 - acc: 0.9540 - val_loss: 0.0827 - val_acc: 0.9718\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1136 - acc: 0.9591 - val_loss: 0.0931 - val_acc: 0.9630\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.08183 to 0.07510, saving model to best.model\n",
      "0s - loss: 0.1079 - acc: 0.9584 - val_loss: 0.0751 - val_acc: 0.9757\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1068 - acc: 0.9589 - val_loss: 0.0753 - val_acc: 0.9747\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07510 to 0.07395, saving model to best.model\n",
      "0s - loss: 0.1002 - acc: 0.9618 - val_loss: 0.0739 - val_acc: 0.9757\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07395 to 0.07091, saving model to best.model\n",
      "0s - loss: 0.1019 - acc: 0.9591 - val_loss: 0.0709 - val_acc: 0.9757\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07091 to 0.06776, saving model to best.model\n",
      "0s - loss: 0.0908 - acc: 0.9671 - val_loss: 0.0678 - val_acc: 0.9757\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06776 to 0.06751, saving model to best.model\n",
      "0s - loss: 0.0997 - acc: 0.9632 - val_loss: 0.0675 - val_acc: 0.9757\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06751 to 0.06488, saving model to best.model\n",
      "0s - loss: 0.0980 - acc: 0.9657 - val_loss: 0.0649 - val_acc: 0.9757\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06488 to 0.06231, saving model to best.model\n",
      "0s - loss: 0.0903 - acc: 0.9662 - val_loss: 0.0623 - val_acc: 0.9757\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06231 to 0.06005, saving model to best.model\n",
      "0s - loss: 0.0959 - acc: 0.9659 - val_loss: 0.0600 - val_acc: 0.9776\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.1016 - acc: 0.9618 - val_loss: 0.0608 - val_acc: 0.9757\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06005 to 0.05349, saving model to best.model\n",
      "0s - loss: 0.0889 - acc: 0.9679 - val_loss: 0.0535 - val_acc: 0.9796\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0868 - acc: 0.9691 - val_loss: 0.0604 - val_acc: 0.9757\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0839 - acc: 0.9720 - val_loss: 0.0536 - val_acc: 0.9776\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0871 - acc: 0.9669 - val_loss: 0.0657 - val_acc: 0.9815\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05349 to 0.05014, saving model to best.model\n",
      "0s - loss: 0.0888 - acc: 0.9669 - val_loss: 0.0501 - val_acc: 0.9776\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0829 - acc: 0.9688 - val_loss: 0.0529 - val_acc: 0.9786\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0802 - acc: 0.9722 - val_loss: 0.0557 - val_acc: 0.9815\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05014 to 0.04675, saving model to best.model\n",
      "0s - loss: 0.0742 - acc: 0.9739 - val_loss: 0.0468 - val_acc: 0.9815\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0861 - acc: 0.9696 - val_loss: 0.0578 - val_acc: 0.9805\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04675 to 0.04564, saving model to best.model\n",
      "0s - loss: 0.0820 - acc: 0.9710 - val_loss: 0.0456 - val_acc: 0.9796\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0806 - acc: 0.9686 - val_loss: 0.0561 - val_acc: 0.9815\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04564 to 0.04268, saving model to best.model\n",
      "0s - loss: 0.0861 - acc: 0.9679 - val_loss: 0.0427 - val_acc: 0.9815\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0778 - acc: 0.9688 - val_loss: 0.0523 - val_acc: 0.9815\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04268 to 0.04116, saving model to best.model\n",
      "0s - loss: 0.0795 - acc: 0.9718 - val_loss: 0.0412 - val_acc: 0.9825\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0690 - acc: 0.9749 - val_loss: 0.0416 - val_acc: 0.9854\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04116 to 0.04035, saving model to best.model\n",
      "0s - loss: 0.0661 - acc: 0.9754 - val_loss: 0.0404 - val_acc: 0.9854\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0624 - acc: 0.9791 - val_loss: 0.0424 - val_acc: 0.9834\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.04035 to 0.03501, saving model to best.model\n",
      "0s - loss: 0.0669 - acc: 0.9747 - val_loss: 0.0350 - val_acc: 0.9844\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0707 - acc: 0.9730 - val_loss: 0.0431 - val_acc: 0.9825\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03501 to 0.03494, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9739 - val_loss: 0.0349 - val_acc: 0.9854\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9778 - val_loss: 0.0376 - val_acc: 0.9864\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0702 - acc: 0.9737 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0642 - acc: 0.9754 - val_loss: 0.0393 - val_acc: 0.9854\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0609 - acc: 0.9776 - val_loss: 0.0364 - val_acc: 0.9864\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03494 to 0.03014, saving model to best.model\n",
      "0s - loss: 0.0578 - acc: 0.9774 - val_loss: 0.0301 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0570 - acc: 0.9771 - val_loss: 0.0414 - val_acc: 0.9854\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0652 - acc: 0.9769 - val_loss: 0.0345 - val_acc: 0.9864\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0539 - acc: 0.9810 - val_loss: 0.0332 - val_acc: 0.9864\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0595 - acc: 0.9793 - val_loss: 0.0390 - val_acc: 0.9864\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9803 - val_loss: 0.0306 - val_acc: 0.9864\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0561 - acc: 0.9800 - val_loss: 0.0349 - val_acc: 0.9873\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.03014 to 0.02809, saving model to best.model\n",
      "0s - loss: 0.0562 - acc: 0.9817 - val_loss: 0.0281 - val_acc: 0.9922\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0624 - acc: 0.9761 - val_loss: 0.0310 - val_acc: 0.9893\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9791 - val_loss: 0.0282 - val_acc: 0.9903\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9810 - val_loss: 0.0289 - val_acc: 0.9903\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0533 - acc: 0.9810 - val_loss: 0.0310 - val_acc: 0.9864\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0518 - acc: 0.9798 - val_loss: 0.0296 - val_acc: 0.9873\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02809 to 0.02678, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9827 - val_loss: 0.0268 - val_acc: 0.9922\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02678 to 0.02613, saving model to best.model\n",
      "0s - loss: 0.0526 - acc: 0.9822 - val_loss: 0.0261 - val_acc: 0.9932\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9805 - val_loss: 0.0280 - val_acc: 0.9893\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9847 - val_loss: 0.0273 - val_acc: 0.9893\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0490 - acc: 0.9844 - val_loss: 0.0288 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9834 - val_loss: 0.0306 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02613 to 0.02334, saving model to best.model\n",
      "0s - loss: 0.0505 - acc: 0.9815 - val_loss: 0.0233 - val_acc: 0.9932\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9834 - val_loss: 0.0268 - val_acc: 0.9893\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9864 - val_loss: 0.0244 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02334 to 0.02253, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9820 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9825 - val_loss: 0.0288 - val_acc: 0.9903\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9859 - val_loss: 0.0240 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9844 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0404 - acc: 0.9861 - val_loss: 0.0270 - val_acc: 0.9893\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0237 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9837 - val_loss: 0.0259 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9827 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9842 - val_loss: 0.0232 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02253 to 0.02002, saving model to best.model\n",
      "0s - loss: 0.0401 - acc: 0.9859 - val_loss: 0.0200 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9844 - val_loss: 0.0281 - val_acc: 0.9883\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.02002 to 0.01974, saving model to best.model\n",
      "0s - loss: 0.0421 - acc: 0.9842 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9834 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9849 - val_loss: 0.0272 - val_acc: 0.9893\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9849 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9837 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9883 - val_loss: 0.0280 - val_acc: 0.9883\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01974 to 0.01860, saving model to best.model\n",
      "0s - loss: 0.0345 - acc: 0.9873 - val_loss: 0.0186 - val_acc: 0.9951\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9839 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9886 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9856 - val_loss: 0.0241 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0498 - acc: 0.9815 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9866 - val_loss: 0.0252 - val_acc: 0.9903\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01860 to 0.01817, saving model to best.model\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01817 to 0.01768, saving model to best.model\n",
      "0s - loss: 0.0388 - acc: 0.9864 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9861 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9844 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9873 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9878 - val_loss: 0.0183 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9898 - val_loss: 0.0196 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9854 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9888 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01768 to 0.01605, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9864 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9871 - val_loss: 0.0184 - val_acc: 0.9942\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0257 - acc: 0.9917 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9866 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9873 - val_loss: 0.0210 - val_acc: 0.9922\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9907 - val_loss: 0.0209 - val_acc: 0.9922\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9886 - val_loss: 0.0184 - val_acc: 0.9932\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9893 - val_loss: 0.0187 - val_acc: 0.9932\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01605 to 0.01371, saving model to best.model\n",
      "0s - loss: 0.0321 - acc: 0.9890 - val_loss: 0.0137 - val_acc: 0.9951\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9859 - val_loss: 0.0178 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9900 - val_loss: 0.0147 - val_acc: 0.9951\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9878 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9883 - val_loss: 0.0151 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9912 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9881 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9893 - val_loss: 0.0182 - val_acc: 0.9922\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9881 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9905 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9854 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9888 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9883 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9895 - val_loss: 0.0148 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9895 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9893 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0258 - acc: 0.9907 - val_loss: 0.0168 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0227 - acc: 0.9907 - val_loss: 0.0186 - val_acc: 0.9942\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0228 - acc: 0.9927 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0255 - acc: 0.9915 - val_loss: 0.0152 - val_acc: 0.9942\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0188 - acc: 0.9915 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0259 - acc: 0.9900 - val_loss: 0.0186 - val_acc: 0.9942\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0239 - acc: 0.9890 - val_loss: 0.0156 - val_acc: 0.9942\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0278 - acc: 0.9881 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9907 - val_loss: 0.0239 - val_acc: 0.9932\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.01371 to 0.01265, saving model to best.model\n",
      "0s - loss: 0.0261 - acc: 0.9893 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9883 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.72344, saving model to best.model\n",
      "0s - loss: 0.8167 - acc: 0.5057 - val_loss: 0.7234 - val_acc: 0.4742\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.72344 to 0.65099, saving model to best.model\n",
      "0s - loss: 0.7573 - acc: 0.5369 - val_loss: 0.6510 - val_acc: 0.7459\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65099 to 0.60798, saving model to best.model\n",
      "0s - loss: 0.7106 - acc: 0.5561 - val_loss: 0.6080 - val_acc: 0.7936\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.60798 to 0.54210, saving model to best.model\n",
      "0s - loss: 0.6520 - acc: 0.6177 - val_loss: 0.5421 - val_acc: 0.7907\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54210 to 0.48015, saving model to best.model\n",
      "0s - loss: 0.5856 - acc: 0.7020 - val_loss: 0.4801 - val_acc: 0.8062\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.48015 to 0.43140, saving model to best.model\n",
      "0s - loss: 0.5156 - acc: 0.7575 - val_loss: 0.4314 - val_acc: 0.8218\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.43140 to 0.39981, saving model to best.model\n",
      "0s - loss: 0.4692 - acc: 0.7977 - val_loss: 0.3998 - val_acc: 0.8364\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.39981 to 0.36677, saving model to best.model\n",
      "0s - loss: 0.4374 - acc: 0.8193 - val_loss: 0.3668 - val_acc: 0.8442\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36677 to 0.34943, saving model to best.model\n",
      "0s - loss: 0.4174 - acc: 0.8252 - val_loss: 0.3494 - val_acc: 0.8491\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34943 to 0.33328, saving model to best.model\n",
      "0s - loss: 0.4019 - acc: 0.8352 - val_loss: 0.3333 - val_acc: 0.8608\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33328 to 0.32269, saving model to best.model\n",
      "0s - loss: 0.3769 - acc: 0.8459 - val_loss: 0.3227 - val_acc: 0.8637\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.32269 to 0.30200, saving model to best.model\n",
      "0s - loss: 0.3532 - acc: 0.8590 - val_loss: 0.3020 - val_acc: 0.8715\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.30200 to 0.29040, saving model to best.model\n",
      "0s - loss: 0.3565 - acc: 0.8583 - val_loss: 0.2904 - val_acc: 0.8763\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.29040 to 0.28450, saving model to best.model\n",
      "0s - loss: 0.3383 - acc: 0.8685 - val_loss: 0.2845 - val_acc: 0.8793\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.28450 to 0.27184, saving model to best.model\n",
      "0s - loss: 0.3286 - acc: 0.8724 - val_loss: 0.2718 - val_acc: 0.8832\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.27184 to 0.26369, saving model to best.model\n",
      "0s - loss: 0.3093 - acc: 0.8775 - val_loss: 0.2637 - val_acc: 0.8900\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26369 to 0.25706, saving model to best.model\n",
      "0s - loss: 0.3022 - acc: 0.8775 - val_loss: 0.2571 - val_acc: 0.8958\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25706 to 0.24835, saving model to best.model\n",
      "0s - loss: 0.2974 - acc: 0.8834 - val_loss: 0.2483 - val_acc: 0.8987\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24835 to 0.24511, saving model to best.model\n",
      "0s - loss: 0.2961 - acc: 0.8858 - val_loss: 0.2451 - val_acc: 0.9017\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2857 - acc: 0.8890 - val_loss: 0.2502 - val_acc: 0.8987\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.24511 to 0.23589, saving model to best.model\n",
      "0s - loss: 0.2900 - acc: 0.8897 - val_loss: 0.2359 - val_acc: 0.9133\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23589 to 0.23004, saving model to best.model\n",
      "0s - loss: 0.2726 - acc: 0.8965 - val_loss: 0.2300 - val_acc: 0.9114\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23004 to 0.22976, saving model to best.model\n",
      "0s - loss: 0.2754 - acc: 0.8899 - val_loss: 0.2298 - val_acc: 0.9046\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22976 to 0.22110, saving model to best.model\n",
      "0s - loss: 0.2629 - acc: 0.9028 - val_loss: 0.2211 - val_acc: 0.9172\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22110 to 0.21726, saving model to best.model\n",
      "0s - loss: 0.2543 - acc: 0.9060 - val_loss: 0.2173 - val_acc: 0.9143\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21726 to 0.21206, saving model to best.model\n",
      "0s - loss: 0.2550 - acc: 0.9053 - val_loss: 0.2121 - val_acc: 0.9250\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2577 - acc: 0.9046 - val_loss: 0.2134 - val_acc: 0.9172\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21206 to 0.20626, saving model to best.model\n",
      "0s - loss: 0.2565 - acc: 0.9055 - val_loss: 0.2063 - val_acc: 0.9260\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20626 to 0.20416, saving model to best.model\n",
      "0s - loss: 0.2423 - acc: 0.9092 - val_loss: 0.2042 - val_acc: 0.9241\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20416 to 0.19802, saving model to best.model\n",
      "0s - loss: 0.2404 - acc: 0.9092 - val_loss: 0.1980 - val_acc: 0.9289\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19802 to 0.19391, saving model to best.model\n",
      "0s - loss: 0.2318 - acc: 0.9121 - val_loss: 0.1939 - val_acc: 0.9289\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19391 to 0.19179, saving model to best.model\n",
      "0s - loss: 0.2260 - acc: 0.9123 - val_loss: 0.1918 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19179 to 0.18733, saving model to best.model\n",
      "0s - loss: 0.2281 - acc: 0.9150 - val_loss: 0.1873 - val_acc: 0.9338\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18733 to 0.18532, saving model to best.model\n",
      "0s - loss: 0.2268 - acc: 0.9184 - val_loss: 0.1853 - val_acc: 0.9250\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18532 to 0.17999, saving model to best.model\n",
      "0s - loss: 0.2195 - acc: 0.9218 - val_loss: 0.1800 - val_acc: 0.9464\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17999 to 0.17987, saving model to best.model\n",
      "0s - loss: 0.2182 - acc: 0.9216 - val_loss: 0.1799 - val_acc: 0.9348\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17987 to 0.17522, saving model to best.model\n",
      "0s - loss: 0.2067 - acc: 0.9272 - val_loss: 0.1752 - val_acc: 0.9387\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17522 to 0.16957, saving model to best.model\n",
      "0s - loss: 0.2091 - acc: 0.9228 - val_loss: 0.1696 - val_acc: 0.9513\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.2048 - acc: 0.9260 - val_loss: 0.1703 - val_acc: 0.9328\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16957 to 0.16750, saving model to best.model\n",
      "0s - loss: 0.1976 - acc: 0.9299 - val_loss: 0.1675 - val_acc: 0.9309\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16750 to 0.15720, saving model to best.model\n",
      "0s - loss: 0.2013 - acc: 0.9284 - val_loss: 0.1572 - val_acc: 0.9533\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15720 to 0.15468, saving model to best.model\n",
      "0s - loss: 0.1978 - acc: 0.9291 - val_loss: 0.1547 - val_acc: 0.9494\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.2016 - acc: 0.9272 - val_loss: 0.1561 - val_acc: 0.9406\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15468 to 0.14890, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9284 - val_loss: 0.1489 - val_acc: 0.9562\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14890 to 0.14685, saving model to best.model\n",
      "0s - loss: 0.1934 - acc: 0.9304 - val_loss: 0.1469 - val_acc: 0.9445\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14685 to 0.13974, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9316 - val_loss: 0.1397 - val_acc: 0.9474\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13974 to 0.13609, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9355 - val_loss: 0.1361 - val_acc: 0.9494\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13609 to 0.12913, saving model to best.model\n",
      "0s - loss: 0.1724 - acc: 0.9369 - val_loss: 0.1291 - val_acc: 0.9552\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12913 to 0.12831, saving model to best.model\n",
      "0s - loss: 0.1670 - acc: 0.9360 - val_loss: 0.1283 - val_acc: 0.9503\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12831 to 0.12291, saving model to best.model\n",
      "0s - loss: 0.1681 - acc: 0.9416 - val_loss: 0.1229 - val_acc: 0.9503\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.12291 to 0.11613, saving model to best.model\n",
      "0s - loss: 0.1631 - acc: 0.9386 - val_loss: 0.1161 - val_acc: 0.9562\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11613 to 0.11553, saving model to best.model\n",
      "0s - loss: 0.1579 - acc: 0.9396 - val_loss: 0.1155 - val_acc: 0.9552\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11553 to 0.11259, saving model to best.model\n",
      "0s - loss: 0.1636 - acc: 0.9386 - val_loss: 0.1126 - val_acc: 0.9552\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11259 to 0.10880, saving model to best.model\n",
      "0s - loss: 0.1628 - acc: 0.9403 - val_loss: 0.1088 - val_acc: 0.9669\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10880 to 0.10300, saving model to best.model\n",
      "0s - loss: 0.1509 - acc: 0.9462 - val_loss: 0.1030 - val_acc: 0.9669\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1599 - acc: 0.9386 - val_loss: 0.1122 - val_acc: 0.9523\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10300 to 0.09892, saving model to best.model\n",
      "0s - loss: 0.1476 - acc: 0.9472 - val_loss: 0.0989 - val_acc: 0.9649\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09892 to 0.09511, saving model to best.model\n",
      "0s - loss: 0.1410 - acc: 0.9486 - val_loss: 0.0951 - val_acc: 0.9669\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09511 to 0.09095, saving model to best.model\n",
      "0s - loss: 0.1370 - acc: 0.9479 - val_loss: 0.0910 - val_acc: 0.9679\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09095 to 0.09000, saving model to best.model\n",
      "0s - loss: 0.1372 - acc: 0.9494 - val_loss: 0.0900 - val_acc: 0.9669\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09000 to 0.08657, saving model to best.model\n",
      "0s - loss: 0.1418 - acc: 0.9467 - val_loss: 0.0866 - val_acc: 0.9669\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08657 to 0.08420, saving model to best.model\n",
      "0s - loss: 0.1261 - acc: 0.9542 - val_loss: 0.0842 - val_acc: 0.9679\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08420 to 0.08178, saving model to best.model\n",
      "0s - loss: 0.1269 - acc: 0.9523 - val_loss: 0.0818 - val_acc: 0.9679\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08178 to 0.07878, saving model to best.model\n",
      "0s - loss: 0.1268 - acc: 0.9535 - val_loss: 0.0788 - val_acc: 0.9688\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07878 to 0.07493, saving model to best.model\n",
      "0s - loss: 0.1201 - acc: 0.9557 - val_loss: 0.0749 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07493 to 0.07318, saving model to best.model\n",
      "0s - loss: 0.1234 - acc: 0.9550 - val_loss: 0.0732 - val_acc: 0.9688\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1279 - acc: 0.9528 - val_loss: 0.0751 - val_acc: 0.9718\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07318 to 0.07107, saving model to best.model\n",
      "0s - loss: 0.1218 - acc: 0.9567 - val_loss: 0.0711 - val_acc: 0.9708\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07107 to 0.06822, saving model to best.model\n",
      "0s - loss: 0.1140 - acc: 0.9540 - val_loss: 0.0682 - val_acc: 0.9688\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06822 to 0.06718, saving model to best.model\n",
      "0s - loss: 0.1180 - acc: 0.9564 - val_loss: 0.0672 - val_acc: 0.9698\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06718 to 0.06587, saving model to best.model\n",
      "0s - loss: 0.1094 - acc: 0.9564 - val_loss: 0.0659 - val_acc: 0.9757\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06587 to 0.06231, saving model to best.model\n",
      "0s - loss: 0.1070 - acc: 0.9581 - val_loss: 0.0623 - val_acc: 0.9727\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06231 to 0.05913, saving model to best.model\n",
      "0s - loss: 0.1075 - acc: 0.9584 - val_loss: 0.0591 - val_acc: 0.9708\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.05913 to 0.05810, saving model to best.model\n",
      "0s - loss: 0.1208 - acc: 0.9550 - val_loss: 0.0581 - val_acc: 0.9727\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.05810 to 0.05720, saving model to best.model\n",
      "0s - loss: 0.0969 - acc: 0.9632 - val_loss: 0.0572 - val_acc: 0.9757\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.05720 to 0.05577, saving model to best.model\n",
      "0s - loss: 0.1050 - acc: 0.9623 - val_loss: 0.0558 - val_acc: 0.9737\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05577 to 0.05431, saving model to best.model\n",
      "0s - loss: 0.0991 - acc: 0.9640 - val_loss: 0.0543 - val_acc: 0.9776\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.05431 to 0.05211, saving model to best.model\n",
      "0s - loss: 0.1001 - acc: 0.9596 - val_loss: 0.0521 - val_acc: 0.9786\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05211 to 0.04958, saving model to best.model\n",
      "0s - loss: 0.0956 - acc: 0.9635 - val_loss: 0.0496 - val_acc: 0.9796\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1001 - acc: 0.9630 - val_loss: 0.0513 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.04958 to 0.04811, saving model to best.model\n",
      "0s - loss: 0.0917 - acc: 0.9645 - val_loss: 0.0481 - val_acc: 0.9796\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.04811 to 0.04563, saving model to best.model\n",
      "0s - loss: 0.0927 - acc: 0.9635 - val_loss: 0.0456 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04563 to 0.04543, saving model to best.model\n",
      "0s - loss: 0.0877 - acc: 0.9679 - val_loss: 0.0454 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0952 - acc: 0.9640 - val_loss: 0.0479 - val_acc: 0.9834\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04543 to 0.04333, saving model to best.model\n",
      "0s - loss: 0.0912 - acc: 0.9669 - val_loss: 0.0433 - val_acc: 0.9805\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04333 to 0.04153, saving model to best.model\n",
      "0s - loss: 0.0894 - acc: 0.9671 - val_loss: 0.0415 - val_acc: 0.9815\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0954 - acc: 0.9630 - val_loss: 0.0477 - val_acc: 0.9815\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04153 to 0.04150, saving model to best.model\n",
      "0s - loss: 0.0925 - acc: 0.9642 - val_loss: 0.0415 - val_acc: 0.9825\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04150 to 0.03966, saving model to best.model\n",
      "0s - loss: 0.0823 - acc: 0.9737 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03966 to 0.03724, saving model to best.model\n",
      "0s - loss: 0.0825 - acc: 0.9683 - val_loss: 0.0372 - val_acc: 0.9844\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.03724 to 0.03515, saving model to best.model\n",
      "0s - loss: 0.0754 - acc: 0.9710 - val_loss: 0.0352 - val_acc: 0.9864\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.03515 to 0.03355, saving model to best.model\n",
      "0s - loss: 0.0774 - acc: 0.9713 - val_loss: 0.0336 - val_acc: 0.9864\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03355 to 0.03329, saving model to best.model\n",
      "0s - loss: 0.0816 - acc: 0.9681 - val_loss: 0.0333 - val_acc: 0.9864\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.03329 to 0.03313, saving model to best.model\n",
      "0s - loss: 0.0722 - acc: 0.9718 - val_loss: 0.0331 - val_acc: 0.9864\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.03313 to 0.03135, saving model to best.model\n",
      "0s - loss: 0.0686 - acc: 0.9742 - val_loss: 0.0313 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.03135 to 0.02920, saving model to best.model\n",
      "0s - loss: 0.0678 - acc: 0.9715 - val_loss: 0.0292 - val_acc: 0.9883\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0735 - acc: 0.9725 - val_loss: 0.0301 - val_acc: 0.9864\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0662 - acc: 0.9757 - val_loss: 0.0322 - val_acc: 0.9883\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.02920 to 0.02819, saving model to best.model\n",
      "0s - loss: 0.0715 - acc: 0.9727 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0670 - acc: 0.9744 - val_loss: 0.0304 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.02819 to 0.02675, saving model to best.model\n",
      "0s - loss: 0.0727 - acc: 0.9715 - val_loss: 0.0268 - val_acc: 0.9873\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9759 - val_loss: 0.0323 - val_acc: 0.9864\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0676 - acc: 0.9737 - val_loss: 0.0269 - val_acc: 0.9883\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.02675 to 0.02651, saving model to best.model\n",
      "0s - loss: 0.0636 - acc: 0.9761 - val_loss: 0.0265 - val_acc: 0.9893\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.02651 to 0.02384, saving model to best.model\n",
      "0s - loss: 0.0717 - acc: 0.9735 - val_loss: 0.0238 - val_acc: 0.9883\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0679 - acc: 0.9735 - val_loss: 0.0246 - val_acc: 0.9903\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0604 - acc: 0.9769 - val_loss: 0.0258 - val_acc: 0.9893\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0603 - acc: 0.9798 - val_loss: 0.0257 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02384 to 0.02383, saving model to best.model\n",
      "0s - loss: 0.0647 - acc: 0.9781 - val_loss: 0.0238 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.02383 to 0.02228, saving model to best.model\n",
      "0s - loss: 0.0556 - acc: 0.9798 - val_loss: 0.0223 - val_acc: 0.9883\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0632 - acc: 0.9759 - val_loss: 0.0260 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02228 to 0.02161, saving model to best.model\n",
      "0s - loss: 0.0596 - acc: 0.9791 - val_loss: 0.0216 - val_acc: 0.9932\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0631 - acc: 0.9764 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02161 to 0.02129, saving model to best.model\n",
      "0s - loss: 0.0646 - acc: 0.9747 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02129 to 0.02082, saving model to best.model\n",
      "0s - loss: 0.0607 - acc: 0.9791 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0560 - acc: 0.9798 - val_loss: 0.0225 - val_acc: 0.9893\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9832 - val_loss: 0.0210 - val_acc: 0.9903\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0538 - acc: 0.9810 - val_loss: 0.0210 - val_acc: 0.9893\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02082 to 0.01818, saving model to best.model\n",
      "0s - loss: 0.0519 - acc: 0.9798 - val_loss: 0.0182 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0471 - acc: 0.9847 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.01818 to 0.01696, saving model to best.model\n",
      "0s - loss: 0.0548 - acc: 0.9783 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9810 - val_loss: 0.0192 - val_acc: 0.9912\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0485 - acc: 0.9827 - val_loss: 0.0180 - val_acc: 0.9912\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.01696 to 0.01678, saving model to best.model\n",
      "0s - loss: 0.0541 - acc: 0.9798 - val_loss: 0.0168 - val_acc: 0.9922\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0498 - acc: 0.9788 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0553 - acc: 0.9810 - val_loss: 0.0175 - val_acc: 0.9942\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0533 - acc: 0.9808 - val_loss: 0.0206 - val_acc: 0.9903\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.01678 to 0.01672, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9822 - val_loss: 0.0167 - val_acc: 0.9922\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0480 - acc: 0.9820 - val_loss: 0.0196 - val_acc: 0.9893\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.01672 to 0.01491, saving model to best.model\n",
      "0s - loss: 0.0495 - acc: 0.9805 - val_loss: 0.0149 - val_acc: 0.9981\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9817 - val_loss: 0.0178 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01491 to 0.01450, saving model to best.model\n",
      "0s - loss: 0.0464 - acc: 0.9822 - val_loss: 0.0145 - val_acc: 0.9981\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0537 - acc: 0.9808 - val_loss: 0.0210 - val_acc: 0.9903\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9810 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9859 - val_loss: 0.0157 - val_acc: 0.9912\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.01450 to 0.01356, saving model to best.model\n",
      "0s - loss: 0.0494 - acc: 0.9813 - val_loss: 0.0136 - val_acc: 0.9961\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9813 - val_loss: 0.0189 - val_acc: 0.9903\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9854 - val_loss: 0.0168 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0480 - acc: 0.9810 - val_loss: 0.0154 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9795 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9832 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01356 to 0.01262, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9822 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9859 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9837 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01262 to 0.01195, saving model to best.model\n",
      "0s - loss: 0.0392 - acc: 0.9844 - val_loss: 0.0119 - val_acc: 0.9961\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01195 to 0.01156, saving model to best.model\n",
      "0s - loss: 0.0424 - acc: 0.9851 - val_loss: 0.0116 - val_acc: 0.9961\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9864 - val_loss: 0.0124 - val_acc: 0.9922\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9886 - val_loss: 0.0118 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01156 to 0.01068, saving model to best.model\n",
      "0s - loss: 0.0368 - acc: 0.9839 - val_loss: 0.0107 - val_acc: 0.9981\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9881 - val_loss: 0.0128 - val_acc: 0.9922\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9854 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0396 - acc: 0.9851 - val_loss: 0.0119 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01068 to 0.00983, saving model to best.model\n",
      "0s - loss: 0.0400 - acc: 0.9847 - val_loss: 0.0098 - val_acc: 0.9981\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9854 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9869 - val_loss: 0.0109 - val_acc: 0.9981\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.00983 to 0.00977, saving model to best.model\n",
      "0s - loss: 0.0372 - acc: 0.9871 - val_loss: 0.0098 - val_acc: 0.9981\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.00977 to 0.00906, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9854 - val_loss: 0.0091 - val_acc: 0.9981\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9839 - val_loss: 0.0112 - val_acc: 0.9922\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9888 - val_loss: 0.0096 - val_acc: 0.9981\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9830 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9832 - val_loss: 0.0098 - val_acc: 0.9981\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9849 - val_loss: 0.0109 - val_acc: 0.9971\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.00906 to 0.00864, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9881 - val_loss: 0.0086 - val_acc: 0.9981\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9861 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.00864 to 0.00820, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9861 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0122 - val_acc: 0.9932\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9851 - val_loss: 0.0098 - val_acc: 0.9951\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9866 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9861 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9859 - val_loss: 0.0101 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.00820 to 0.00791, saving model to best.model\n",
      "0s - loss: 0.0323 - acc: 0.9844 - val_loss: 0.0079 - val_acc: 0.9981\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9910 - val_loss: 0.0090 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.00791 to 0.00758, saving model to best.model\n",
      "0s - loss: 0.0293 - acc: 0.9898 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9881 - val_loss: 0.0079 - val_acc: 0.9981\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9893 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9898 - val_loss: 0.0090 - val_acc: 0.9951\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.00758 to 0.00679, saving model to best.model\n",
      "0s - loss: 0.0344 - acc: 0.9851 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9893 - val_loss: 0.0104 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9893 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9864 - val_loss: 0.0071 - val_acc: 0.9981\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9890 - val_loss: 0.0087 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.00679 to 0.00626, saving model to best.model\n",
      "0s - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9888 - val_loss: 0.0088 - val_acc: 0.9942\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.00626 to 0.00599, saving model to best.model\n",
      "0s - loss: 0.0341 - acc: 0.9888 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9864 - val_loss: 0.0066 - val_acc: 0.9981\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0243 - acc: 0.9912 - val_loss: 0.0072 - val_acc: 0.9981\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9878 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00599 to 0.00560, saving model to best.model\n",
      "0s - loss: 0.0328 - acc: 0.9886 - val_loss: 0.0056 - val_acc: 0.9990\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9881 - val_loss: 0.0063 - val_acc: 0.9981\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9886 - val_loss: 0.0066 - val_acc: 0.9981\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00560 to 0.00557, saving model to best.model\n",
      "0s - loss: 0.0232 - acc: 0.9912 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00557 to 0.00543, saving model to best.model\n",
      "0s - loss: 0.0293 - acc: 0.9903 - val_loss: 0.0054 - val_acc: 0.9981\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9881 - val_loss: 0.0071 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00543 to 0.00526, saving model to best.model\n",
      "0s - loss: 0.0263 - acc: 0.9898 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9881 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0235 - acc: 0.9898 - val_loss: 0.0055 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9903 - val_loss: 0.0101 - val_acc: 0.9932\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0257 - acc: 0.9905 - val_loss: 0.0066 - val_acc: 0.9981\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9895 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0249 - acc: 0.9915 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66487, saving model to best.model\n",
      "0s - loss: 0.7810 - acc: 0.5147 - val_loss: 0.6649 - val_acc: 0.6436\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66487 to 0.64578, saving model to best.model\n",
      "0s - loss: 0.7399 - acc: 0.5242 - val_loss: 0.6458 - val_acc: 0.6767\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64578 to 0.59276, saving model to best.model\n",
      "0s - loss: 0.6839 - acc: 0.5822 - val_loss: 0.5928 - val_acc: 0.7984\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59276 to 0.50208, saving model to best.model\n",
      "0s - loss: 0.6252 - acc: 0.6596 - val_loss: 0.5021 - val_acc: 0.8364\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50208 to 0.42408, saving model to best.model\n",
      "0s - loss: 0.5605 - acc: 0.7227 - val_loss: 0.4241 - val_acc: 0.8462\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.42408 to 0.37824, saving model to best.model\n",
      "0s - loss: 0.5027 - acc: 0.7611 - val_loss: 0.3782 - val_acc: 0.8559\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.37824 to 0.35344, saving model to best.model\n",
      "0s - loss: 0.4592 - acc: 0.8018 - val_loss: 0.3534 - val_acc: 0.8617\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35344 to 0.32406, saving model to best.model\n",
      "0s - loss: 0.4272 - acc: 0.8174 - val_loss: 0.3241 - val_acc: 0.8763\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.32406 to 0.31707, saving model to best.model\n",
      "0s - loss: 0.3991 - acc: 0.8408 - val_loss: 0.3171 - val_acc: 0.8754\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31707 to 0.29168, saving model to best.model\n",
      "0s - loss: 0.3919 - acc: 0.8405 - val_loss: 0.2917 - val_acc: 0.8841\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29168 to 0.27728, saving model to best.model\n",
      "0s - loss: 0.3665 - acc: 0.8534 - val_loss: 0.2773 - val_acc: 0.8919\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.27728 to 0.26678, saving model to best.model\n",
      "0s - loss: 0.3500 - acc: 0.8651 - val_loss: 0.2668 - val_acc: 0.8929\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.26678 to 0.25634, saving model to best.model\n",
      "0s - loss: 0.3431 - acc: 0.8692 - val_loss: 0.2563 - val_acc: 0.8978\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.25634 to 0.25183, saving model to best.model\n",
      "0s - loss: 0.3318 - acc: 0.8705 - val_loss: 0.2518 - val_acc: 0.8997\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.3246 - acc: 0.8705 - val_loss: 0.2567 - val_acc: 0.9026\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25183 to 0.23212, saving model to best.model\n",
      "0s - loss: 0.3197 - acc: 0.8814 - val_loss: 0.2321 - val_acc: 0.9094\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.23212 to 0.22895, saving model to best.model\n",
      "0s - loss: 0.3150 - acc: 0.8809 - val_loss: 0.2290 - val_acc: 0.9124\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.22895 to 0.22424, saving model to best.model\n",
      "0s - loss: 0.3029 - acc: 0.8885 - val_loss: 0.2242 - val_acc: 0.9163\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22424 to 0.21540, saving model to best.model\n",
      "0s - loss: 0.2979 - acc: 0.8853 - val_loss: 0.2154 - val_acc: 0.9182\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.21540 to 0.21007, saving model to best.model\n",
      "0s - loss: 0.2975 - acc: 0.8916 - val_loss: 0.2101 - val_acc: 0.9231\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2863 - acc: 0.8951 - val_loss: 0.2101 - val_acc: 0.9182\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21007 to 0.20290, saving model to best.model\n",
      "0s - loss: 0.2889 - acc: 0.8929 - val_loss: 0.2029 - val_acc: 0.9231\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20290 to 0.19485, saving model to best.model\n",
      "0s - loss: 0.2826 - acc: 0.9002 - val_loss: 0.1948 - val_acc: 0.9318\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19485 to 0.18976, saving model to best.model\n",
      "0s - loss: 0.2668 - acc: 0.9048 - val_loss: 0.1898 - val_acc: 0.9318\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18976 to 0.18819, saving model to best.model\n",
      "0s - loss: 0.2710 - acc: 0.8999 - val_loss: 0.1882 - val_acc: 0.9338\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18819 to 0.18787, saving model to best.model\n",
      "0s - loss: 0.2678 - acc: 0.9048 - val_loss: 0.1879 - val_acc: 0.9289\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18787 to 0.18376, saving model to best.model\n",
      "0s - loss: 0.2684 - acc: 0.8999 - val_loss: 0.1838 - val_acc: 0.9328\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18376 to 0.17674, saving model to best.model\n",
      "0s - loss: 0.2575 - acc: 0.9070 - val_loss: 0.1767 - val_acc: 0.9348\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.17674 to 0.17366, saving model to best.model\n",
      "0s - loss: 0.2485 - acc: 0.9099 - val_loss: 0.1737 - val_acc: 0.9406\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2458 - acc: 0.9111 - val_loss: 0.1749 - val_acc: 0.9338\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.17366 to 0.16764, saving model to best.model\n",
      "0s - loss: 0.2463 - acc: 0.9123 - val_loss: 0.1676 - val_acc: 0.9416\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.16764 to 0.16454, saving model to best.model\n",
      "0s - loss: 0.2430 - acc: 0.9116 - val_loss: 0.1645 - val_acc: 0.9377\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.16454 to 0.16110, saving model to best.model\n",
      "0s - loss: 0.2418 - acc: 0.9094 - val_loss: 0.1611 - val_acc: 0.9426\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.16110 to 0.15947, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9148 - val_loss: 0.1595 - val_acc: 0.9396\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.15947 to 0.15455, saving model to best.model\n",
      "0s - loss: 0.2333 - acc: 0.9143 - val_loss: 0.1546 - val_acc: 0.9426\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.15455 to 0.15096, saving model to best.model\n",
      "0s - loss: 0.2321 - acc: 0.9143 - val_loss: 0.1510 - val_acc: 0.9426\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.15096 to 0.14792, saving model to best.model\n",
      "0s - loss: 0.2237 - acc: 0.9196 - val_loss: 0.1479 - val_acc: 0.9435\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.14792 to 0.14467, saving model to best.model\n",
      "0s - loss: 0.2204 - acc: 0.9158 - val_loss: 0.1447 - val_acc: 0.9416\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.14467 to 0.14010, saving model to best.model\n",
      "0s - loss: 0.2181 - acc: 0.9170 - val_loss: 0.1401 - val_acc: 0.9464\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.14010 to 0.13698, saving model to best.model\n",
      "0s - loss: 0.2183 - acc: 0.9216 - val_loss: 0.1370 - val_acc: 0.9464\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.13698 to 0.13348, saving model to best.model\n",
      "0s - loss: 0.2139 - acc: 0.9187 - val_loss: 0.1335 - val_acc: 0.9484\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.13348 to 0.13116, saving model to best.model\n",
      "0s - loss: 0.2117 - acc: 0.9184 - val_loss: 0.1312 - val_acc: 0.9513\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.13116 to 0.12835, saving model to best.model\n",
      "0s - loss: 0.1980 - acc: 0.9265 - val_loss: 0.1284 - val_acc: 0.9464\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.12835 to 0.12433, saving model to best.model\n",
      "0s - loss: 0.1990 - acc: 0.9238 - val_loss: 0.1243 - val_acc: 0.9474\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.12433 to 0.11862, saving model to best.model\n",
      "0s - loss: 0.1907 - acc: 0.9284 - val_loss: 0.1186 - val_acc: 0.9533\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.11862 to 0.11593, saving model to best.model\n",
      "0s - loss: 0.1925 - acc: 0.9267 - val_loss: 0.1159 - val_acc: 0.9513\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.11593 to 0.11039, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9265 - val_loss: 0.1104 - val_acc: 0.9562\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.11039 to 0.10528, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9313 - val_loss: 0.1053 - val_acc: 0.9533\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.10528 to 0.10140, saving model to best.model\n",
      "0s - loss: 0.1789 - acc: 0.9335 - val_loss: 0.1014 - val_acc: 0.9562\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.10140 to 0.09950, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9362 - val_loss: 0.0995 - val_acc: 0.9659\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.09950 to 0.09603, saving model to best.model\n",
      "0s - loss: 0.1688 - acc: 0.9345 - val_loss: 0.0960 - val_acc: 0.9581\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.09603 to 0.09098, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9352 - val_loss: 0.0910 - val_acc: 0.9611\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.09098 to 0.08675, saving model to best.model\n",
      "0s - loss: 0.1600 - acc: 0.9357 - val_loss: 0.0867 - val_acc: 0.9679\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1576 - acc: 0.9399 - val_loss: 0.0885 - val_acc: 0.9620\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1684 - acc: 0.9311 - val_loss: 0.1027 - val_acc: 0.9533\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.08675 to 0.08462, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9369 - val_loss: 0.0846 - val_acc: 0.9718\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.08462 to 0.08144, saving model to best.model\n",
      "0s - loss: 0.1616 - acc: 0.9362 - val_loss: 0.0814 - val_acc: 0.9727\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.08144 to 0.07705, saving model to best.model\n",
      "0s - loss: 0.1463 - acc: 0.9438 - val_loss: 0.0771 - val_acc: 0.9737\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.07705 to 0.07441, saving model to best.model\n",
      "0s - loss: 0.1432 - acc: 0.9440 - val_loss: 0.0744 - val_acc: 0.9737\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.07441 to 0.07162, saving model to best.model\n",
      "0s - loss: 0.1495 - acc: 0.9386 - val_loss: 0.0716 - val_acc: 0.9737\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.07162 to 0.06953, saving model to best.model\n",
      "0s - loss: 0.1427 - acc: 0.9452 - val_loss: 0.0695 - val_acc: 0.9747\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.06953 to 0.06735, saving model to best.model\n",
      "0s - loss: 0.1300 - acc: 0.9462 - val_loss: 0.0673 - val_acc: 0.9757\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.06735 to 0.06525, saving model to best.model\n",
      "0s - loss: 0.1368 - acc: 0.9467 - val_loss: 0.0653 - val_acc: 0.9776\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1462 - acc: 0.9411 - val_loss: 0.0736 - val_acc: 0.9757\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1386 - acc: 0.9408 - val_loss: 0.0661 - val_acc: 0.9747\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.06525 to 0.06150, saving model to best.model\n",
      "0s - loss: 0.1239 - acc: 0.9525 - val_loss: 0.0615 - val_acc: 0.9796\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.06150 to 0.05731, saving model to best.model\n",
      "0s - loss: 0.1302 - acc: 0.9472 - val_loss: 0.0573 - val_acc: 0.9825\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.05731 to 0.05653, saving model to best.model\n",
      "0s - loss: 0.1224 - acc: 0.9513 - val_loss: 0.0565 - val_acc: 0.9825\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.05653 to 0.05490, saving model to best.model\n",
      "0s - loss: 0.1248 - acc: 0.9518 - val_loss: 0.0549 - val_acc: 0.9854\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.05490 to 0.05173, saving model to best.model\n",
      "0s - loss: 0.1140 - acc: 0.9557 - val_loss: 0.0517 - val_acc: 0.9864\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.05173 to 0.05129, saving model to best.model\n",
      "0s - loss: 0.1154 - acc: 0.9550 - val_loss: 0.0513 - val_acc: 0.9864\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1117 - acc: 0.9552 - val_loss: 0.0518 - val_acc: 0.9844\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1120 - acc: 0.9542 - val_loss: 0.0526 - val_acc: 0.9796\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.05129 to 0.04930, saving model to best.model\n",
      "0s - loss: 0.1140 - acc: 0.9537 - val_loss: 0.0493 - val_acc: 0.9893\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.04930 to 0.04669, saving model to best.model\n",
      "0s - loss: 0.1150 - acc: 0.9571 - val_loss: 0.0467 - val_acc: 0.9893\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.04669 to 0.04365, saving model to best.model\n",
      "0s - loss: 0.1049 - acc: 0.9610 - val_loss: 0.0437 - val_acc: 0.9883\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.04365 to 0.04281, saving model to best.model\n",
      "0s - loss: 0.1045 - acc: 0.9601 - val_loss: 0.0428 - val_acc: 0.9883\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.04281 to 0.04124, saving model to best.model\n",
      "0s - loss: 0.1051 - acc: 0.9567 - val_loss: 0.0412 - val_acc: 0.9903\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.04124 to 0.04024, saving model to best.model\n",
      "0s - loss: 0.0978 - acc: 0.9642 - val_loss: 0.0402 - val_acc: 0.9893\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.04024 to 0.04019, saving model to best.model\n",
      "0s - loss: 0.0990 - acc: 0.9625 - val_loss: 0.0402 - val_acc: 0.9912\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.04019 to 0.03778, saving model to best.model\n",
      "0s - loss: 0.0975 - acc: 0.9615 - val_loss: 0.0378 - val_acc: 0.9903\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1024 - acc: 0.9630 - val_loss: 0.0396 - val_acc: 0.9903\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.03778 to 0.03745, saving model to best.model\n",
      "0s - loss: 0.1020 - acc: 0.9608 - val_loss: 0.0375 - val_acc: 0.9932\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.03745 to 0.03553, saving model to best.model\n",
      "0s - loss: 0.0878 - acc: 0.9652 - val_loss: 0.0355 - val_acc: 0.9912\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0927 - acc: 0.9630 - val_loss: 0.0371 - val_acc: 0.9903\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.03553 to 0.03280, saving model to best.model\n",
      "0s - loss: 0.0901 - acc: 0.9627 - val_loss: 0.0328 - val_acc: 0.9932\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.03280 to 0.03162, saving model to best.model\n",
      "0s - loss: 0.0912 - acc: 0.9666 - val_loss: 0.0316 - val_acc: 0.9922\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.03162 to 0.03028, saving model to best.model\n",
      "0s - loss: 0.0907 - acc: 0.9642 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0851 - acc: 0.9647 - val_loss: 0.0305 - val_acc: 0.9932\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03028 to 0.02933, saving model to best.model\n",
      "0s - loss: 0.0874 - acc: 0.9662 - val_loss: 0.0293 - val_acc: 0.9932\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.02933 to 0.02821, saving model to best.model\n",
      "0s - loss: 0.0778 - acc: 0.9698 - val_loss: 0.0282 - val_acc: 0.9932\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.02821 to 0.02693, saving model to best.model\n",
      "0s - loss: 0.0841 - acc: 0.9686 - val_loss: 0.0269 - val_acc: 0.9942\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.02693 to 0.02675, saving model to best.model\n",
      "0s - loss: 0.0836 - acc: 0.9686 - val_loss: 0.0267 - val_acc: 0.9932\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.02675 to 0.02558, saving model to best.model\n",
      "0s - loss: 0.0788 - acc: 0.9708 - val_loss: 0.0256 - val_acc: 0.9932\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.02558 to 0.02428, saving model to best.model\n",
      "0s - loss: 0.0719 - acc: 0.9727 - val_loss: 0.0243 - val_acc: 0.9922\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0771 - acc: 0.9696 - val_loss: 0.0246 - val_acc: 0.9932\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0728 - acc: 0.9732 - val_loss: 0.0247 - val_acc: 0.9942\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0767 - acc: 0.9730 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.02428 to 0.02421, saving model to best.model\n",
      "0s - loss: 0.0751 - acc: 0.9715 - val_loss: 0.0242 - val_acc: 0.9932\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02421 to 0.02397, saving model to best.model\n",
      "0s - loss: 0.0703 - acc: 0.9742 - val_loss: 0.0240 - val_acc: 0.9932\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.02397 to 0.02257, saving model to best.model\n",
      "0s - loss: 0.0728 - acc: 0.9752 - val_loss: 0.0226 - val_acc: 0.9942\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0780 - acc: 0.9698 - val_loss: 0.0232 - val_acc: 0.9932\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.02257 to 0.02206, saving model to best.model\n",
      "0s - loss: 0.0690 - acc: 0.9737 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0714 - acc: 0.9722 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.02206 to 0.01992, saving model to best.model\n",
      "0s - loss: 0.0732 - acc: 0.9730 - val_loss: 0.0199 - val_acc: 0.9961\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0712 - acc: 0.9727 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.01992 to 0.01876, saving model to best.model\n",
      "0s - loss: 0.0649 - acc: 0.9742 - val_loss: 0.0188 - val_acc: 0.9951\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0710 - acc: 0.9742 - val_loss: 0.0190 - val_acc: 0.9961\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.01876 to 0.01721, saving model to best.model\n",
      "0s - loss: 0.0708 - acc: 0.9718 - val_loss: 0.0172 - val_acc: 0.9951\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0722 - acc: 0.9737 - val_loss: 0.0174 - val_acc: 0.9961\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0661 - acc: 0.9730 - val_loss: 0.0175 - val_acc: 0.9961\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.01721 to 0.01652, saving model to best.model\n",
      "0s - loss: 0.0659 - acc: 0.9752 - val_loss: 0.0165 - val_acc: 0.9961\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0642 - acc: 0.9766 - val_loss: 0.0181 - val_acc: 0.9942\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.01652 to 0.01622, saving model to best.model\n",
      "0s - loss: 0.0629 - acc: 0.9757 - val_loss: 0.0162 - val_acc: 0.9961\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.01622 to 0.01521, saving model to best.model\n",
      "0s - loss: 0.0655 - acc: 0.9737 - val_loss: 0.0152 - val_acc: 0.9981\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0673 - acc: 0.9747 - val_loss: 0.0164 - val_acc: 0.9942\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.01521 to 0.01426, saving model to best.model\n",
      "0s - loss: 0.0506 - acc: 0.9825 - val_loss: 0.0143 - val_acc: 0.9971\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9781 - val_loss: 0.0150 - val_acc: 0.9961\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.01426 to 0.01370, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9849 - val_loss: 0.0137 - val_acc: 0.9961\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0611 - acc: 0.9771 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.01370 to 0.01283, saving model to best.model\n",
      "0s - loss: 0.0564 - acc: 0.9783 - val_loss: 0.0128 - val_acc: 0.9981\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0591 - acc: 0.9781 - val_loss: 0.0142 - val_acc: 0.9961\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9778 - val_loss: 0.0142 - val_acc: 0.9961\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.01283 to 0.01263, saving model to best.model\n",
      "0s - loss: 0.0555 - acc: 0.9805 - val_loss: 0.0126 - val_acc: 0.9981\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.01263 to 0.01232, saving model to best.model\n",
      "0s - loss: 0.0468 - acc: 0.9851 - val_loss: 0.0123 - val_acc: 0.9971\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0552 - acc: 0.9786 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.01232 to 0.01131, saving model to best.model\n",
      "0s - loss: 0.0554 - acc: 0.9786 - val_loss: 0.0113 - val_acc: 0.9981\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0567 - acc: 0.9786 - val_loss: 0.0128 - val_acc: 0.9981\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9815 - val_loss: 0.0140 - val_acc: 0.9961\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9805 - val_loss: 0.0132 - val_acc: 0.9961\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9808 - val_loss: 0.0121 - val_acc: 0.9981\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0550 - acc: 0.9793 - val_loss: 0.0123 - val_acc: 0.9961\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01131 to 0.01098, saving model to best.model\n",
      "0s - loss: 0.0496 - acc: 0.9815 - val_loss: 0.0110 - val_acc: 0.9981\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0116 - val_acc: 0.9971\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.01098 to 0.00997, saving model to best.model\n",
      "0s - loss: 0.0457 - acc: 0.9827 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9839 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9820 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9817 - val_loss: 0.0109 - val_acc: 0.9981\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0524 - acc: 0.9793 - val_loss: 0.0123 - val_acc: 0.9961\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9847 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0487 - acc: 0.9827 - val_loss: 0.0110 - val_acc: 0.9961\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0479 - acc: 0.9827 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0520 - acc: 0.9800 - val_loss: 0.0106 - val_acc: 0.9971\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9788 - val_loss: 0.0114 - val_acc: 0.9961\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.00997 to 0.00995, saving model to best.model\n",
      "0s - loss: 0.0446 - acc: 0.9810 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.00995 to 0.00989, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9791 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.00989 to 0.00920, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9808 - val_loss: 0.0092 - val_acc: 0.9981\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9822 - val_loss: 0.0103 - val_acc: 0.9971\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9837 - val_loss: 0.0092 - val_acc: 0.9981\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.00920 to 0.00904, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9822 - val_loss: 0.0090 - val_acc: 0.9981\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.00904 to 0.00818, saving model to best.model\n",
      "0s - loss: 0.0396 - acc: 0.9847 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9837 - val_loss: 0.0097 - val_acc: 0.9971\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9820 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0414 - acc: 0.9856 - val_loss: 0.0105 - val_acc: 0.9971\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0433 - acc: 0.9825 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9864 - val_loss: 0.0083 - val_acc: 0.9981\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9864 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.00818 to 0.00815, saving model to best.model\n",
      "0s - loss: 0.0437 - acc: 0.9849 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.00815 to 0.00779, saving model to best.model\n",
      "0s - loss: 0.0345 - acc: 0.9851 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9842 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.00779 to 0.00763, saving model to best.model\n",
      "0s - loss: 0.0410 - acc: 0.9830 - val_loss: 0.0076 - val_acc: 0.9990\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9842 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9842 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9832 - val_loss: 0.0085 - val_acc: 0.9981\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.00763 to 0.00740, saving model to best.model\n",
      "0s - loss: 0.0426 - acc: 0.9830 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.00740 to 0.00712, saving model to best.model\n",
      "0s - loss: 0.0392 - acc: 0.9869 - val_loss: 0.0071 - val_acc: 0.9981\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9844 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9825 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9849 - val_loss: 0.0075 - val_acc: 0.9990\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9839 - val_loss: 0.0093 - val_acc: 0.9981\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.00712 to 0.00683, saving model to best.model\n",
      "0s - loss: 0.0363 - acc: 0.9871 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9888 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9839 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.00683 to 0.00619, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0062 - val_acc: 0.9990\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9842 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9854 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9864 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.00619 to 0.00509, saving model to best.model\n",
      "0s - loss: 0.0335 - acc: 0.9890 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.00509 to 0.00494, saving model to best.model\n",
      "0s - loss: 0.0354 - acc: 0.9864 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9861 - val_loss: 0.0081 - val_acc: 0.9981\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9847 - val_loss: 0.0061 - val_acc: 0.9990\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9864 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9888 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9878 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0300 - acc: 0.9893 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9854 - val_loss: 0.0055 - val_acc: 0.9990\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9883 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00494 to 0.00492, saving model to best.model\n",
      "0s - loss: 0.0322 - acc: 0.9881 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9895 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00492 to 0.00490, saving model to best.model\n",
      "0s - loss: 0.0301 - acc: 0.9876 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9886 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9881 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9905 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9861 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9886 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9881 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.00490 to 0.00469, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9890 - val_loss: 0.0047 - val_acc: 0.9990\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.00469 to 0.00441, saving model to best.model\n",
      "0s - loss: 0.0333 - acc: 0.9866 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.00441 to 0.00386, saving model to best.model\n",
      "0s - loss: 0.0317 - acc: 0.9878 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9888 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68479, saving model to best.model\n",
      "0s - loss: 0.8396 - acc: 0.5157 - val_loss: 0.6848 - val_acc: 0.4693\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68479 to 0.66622, saving model to best.model\n",
      "0s - loss: 0.7788 - acc: 0.5181 - val_loss: 0.6662 - val_acc: 0.5307\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66622 to 0.64346, saving model to best.model\n",
      "0s - loss: 0.7229 - acc: 0.5576 - val_loss: 0.6435 - val_acc: 0.5307\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.64346 to 0.58845, saving model to best.model\n",
      "0s - loss: 0.6786 - acc: 0.5929 - val_loss: 0.5884 - val_acc: 0.7809\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.58845 to 0.52294, saving model to best.model\n",
      "0s - loss: 0.6167 - acc: 0.6676 - val_loss: 0.5229 - val_acc: 0.7770\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.52294 to 0.46390, saving model to best.model\n",
      "0s - loss: 0.5478 - acc: 0.7392 - val_loss: 0.4639 - val_acc: 0.8033\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.46390 to 0.42759, saving model to best.model\n",
      "0s - loss: 0.4864 - acc: 0.7826 - val_loss: 0.4276 - val_acc: 0.8286\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.42759 to 0.40306, saving model to best.model\n",
      "0s - loss: 0.4535 - acc: 0.8101 - val_loss: 0.4031 - val_acc: 0.8413\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.40306 to 0.36683, saving model to best.model\n",
      "0s - loss: 0.4235 - acc: 0.8318 - val_loss: 0.3668 - val_acc: 0.8608\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.36683 to 0.34758, saving model to best.model\n",
      "0s - loss: 0.3911 - acc: 0.8439 - val_loss: 0.3476 - val_acc: 0.8637\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.34758 to 0.34156, saving model to best.model\n",
      "0s - loss: 0.3647 - acc: 0.8554 - val_loss: 0.3416 - val_acc: 0.8666\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.34156 to 0.32152, saving model to best.model\n",
      "0s - loss: 0.3556 - acc: 0.8622 - val_loss: 0.3215 - val_acc: 0.8695\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.32152 to 0.30564, saving model to best.model\n",
      "0s - loss: 0.3424 - acc: 0.8654 - val_loss: 0.3056 - val_acc: 0.8695\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.30564 to 0.29524, saving model to best.model\n",
      "0s - loss: 0.3251 - acc: 0.8773 - val_loss: 0.2952 - val_acc: 0.8744\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.29524 to 0.28451, saving model to best.model\n",
      "0s - loss: 0.3135 - acc: 0.8817 - val_loss: 0.2845 - val_acc: 0.8812\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.28451 to 0.27146, saving model to best.model\n",
      "0s - loss: 0.3030 - acc: 0.8887 - val_loss: 0.2715 - val_acc: 0.8958\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.27146 to 0.26613, saving model to best.model\n",
      "0s - loss: 0.3060 - acc: 0.8880 - val_loss: 0.2661 - val_acc: 0.9017\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.26613 to 0.26509, saving model to best.model\n",
      "0s - loss: 0.2889 - acc: 0.8907 - val_loss: 0.2651 - val_acc: 0.9007\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26509 to 0.25675, saving model to best.model\n",
      "0s - loss: 0.2879 - acc: 0.8963 - val_loss: 0.2567 - val_acc: 0.9094\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.25675 to 0.25106, saving model to best.model\n",
      "0s - loss: 0.2813 - acc: 0.8994 - val_loss: 0.2511 - val_acc: 0.9133\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2759 - acc: 0.8982 - val_loss: 0.2595 - val_acc: 0.9036\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25106 to 0.24425, saving model to best.model\n",
      "0s - loss: 0.2685 - acc: 0.9053 - val_loss: 0.2443 - val_acc: 0.9182\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.24425 to 0.24303, saving model to best.model\n",
      "0s - loss: 0.2683 - acc: 0.9002 - val_loss: 0.2430 - val_acc: 0.9153\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24303 to 0.23795, saving model to best.model\n",
      "0s - loss: 0.2531 - acc: 0.9143 - val_loss: 0.2379 - val_acc: 0.9192\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2559 - acc: 0.9106 - val_loss: 0.2381 - val_acc: 0.9192\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23795 to 0.23094, saving model to best.model\n",
      "0s - loss: 0.2540 - acc: 0.9158 - val_loss: 0.2309 - val_acc: 0.9279\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.23094 to 0.23045, saving model to best.model\n",
      "0s - loss: 0.2460 - acc: 0.9172 - val_loss: 0.2305 - val_acc: 0.9241\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.23045 to 0.22494, saving model to best.model\n",
      "0s - loss: 0.2485 - acc: 0.9172 - val_loss: 0.2249 - val_acc: 0.9279\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.22494 to 0.22411, saving model to best.model\n",
      "0s - loss: 0.2448 - acc: 0.9182 - val_loss: 0.2241 - val_acc: 0.9279\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22411 to 0.22167, saving model to best.model\n",
      "0s - loss: 0.2391 - acc: 0.9177 - val_loss: 0.2217 - val_acc: 0.9279\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.22167 to 0.22086, saving model to best.model\n",
      "0s - loss: 0.2327 - acc: 0.9187 - val_loss: 0.2209 - val_acc: 0.9260\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.22086 to 0.21473, saving model to best.model\n",
      "0s - loss: 0.2310 - acc: 0.9199 - val_loss: 0.2147 - val_acc: 0.9270\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.21473 to 0.21159, saving model to best.model\n",
      "0s - loss: 0.2234 - acc: 0.9265 - val_loss: 0.2116 - val_acc: 0.9289\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.21159 to 0.20756, saving model to best.model\n",
      "0s - loss: 0.2290 - acc: 0.9201 - val_loss: 0.2076 - val_acc: 0.9289\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.20756 to 0.20486, saving model to best.model\n",
      "0s - loss: 0.2240 - acc: 0.9248 - val_loss: 0.2049 - val_acc: 0.9270\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2215 - acc: 0.9250 - val_loss: 0.2068 - val_acc: 0.9289\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.20486 to 0.19973, saving model to best.model\n",
      "0s - loss: 0.2217 - acc: 0.9216 - val_loss: 0.1997 - val_acc: 0.9396\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19973 to 0.19554, saving model to best.model\n",
      "0s - loss: 0.2120 - acc: 0.9270 - val_loss: 0.1955 - val_acc: 0.9348\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19554 to 0.19481, saving model to best.model\n",
      "0s - loss: 0.2180 - acc: 0.9248 - val_loss: 0.1948 - val_acc: 0.9318\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19481 to 0.19295, saving model to best.model\n",
      "0s - loss: 0.2134 - acc: 0.9223 - val_loss: 0.1930 - val_acc: 0.9299\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19295 to 0.18760, saving model to best.model\n",
      "0s - loss: 0.2005 - acc: 0.9308 - val_loss: 0.1876 - val_acc: 0.9387\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1948 - acc: 0.9357 - val_loss: 0.1892 - val_acc: 0.9299\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18760 to 0.18080, saving model to best.model\n",
      "0s - loss: 0.1968 - acc: 0.9335 - val_loss: 0.1808 - val_acc: 0.9445\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18080 to 0.17883, saving model to best.model\n",
      "0s - loss: 0.1970 - acc: 0.9318 - val_loss: 0.1788 - val_acc: 0.9426\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.17883 to 0.17773, saving model to best.model\n",
      "0s - loss: 0.1995 - acc: 0.9299 - val_loss: 0.1777 - val_acc: 0.9426\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17773 to 0.17457, saving model to best.model\n",
      "0s - loss: 0.1888 - acc: 0.9362 - val_loss: 0.1746 - val_acc: 0.9426\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.17457 to 0.17261, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9379 - val_loss: 0.1726 - val_acc: 0.9455\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.17261 to 0.17130, saving model to best.model\n",
      "0s - loss: 0.1839 - acc: 0.9374 - val_loss: 0.1713 - val_acc: 0.9426\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17130 to 0.16807, saving model to best.model\n",
      "0s - loss: 0.1866 - acc: 0.9364 - val_loss: 0.1681 - val_acc: 0.9474\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.16807 to 0.16492, saving model to best.model\n",
      "0s - loss: 0.1895 - acc: 0.9384 - val_loss: 0.1649 - val_acc: 0.9513\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.16492 to 0.16168, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9396 - val_loss: 0.1617 - val_acc: 0.9494\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.16168 to 0.16035, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9403 - val_loss: 0.1603 - val_acc: 0.9474\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.16035 to 0.16010, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9423 - val_loss: 0.1601 - val_acc: 0.9474\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.16010 to 0.15329, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9447 - val_loss: 0.1533 - val_acc: 0.9503\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.15329 to 0.15027, saving model to best.model\n",
      "0s - loss: 0.1683 - acc: 0.9464 - val_loss: 0.1503 - val_acc: 0.9562\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.15027 to 0.14942, saving model to best.model\n",
      "0s - loss: 0.1612 - acc: 0.9433 - val_loss: 0.1494 - val_acc: 0.9542\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.14942 to 0.14597, saving model to best.model\n",
      "0s - loss: 0.1654 - acc: 0.9442 - val_loss: 0.1460 - val_acc: 0.9572\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.14597 to 0.14249, saving model to best.model\n",
      "0s - loss: 0.1541 - acc: 0.9477 - val_loss: 0.1425 - val_acc: 0.9581\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.14249 to 0.14005, saving model to best.model\n",
      "0s - loss: 0.1627 - acc: 0.9447 - val_loss: 0.1401 - val_acc: 0.9591\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.14005 to 0.13635, saving model to best.model\n",
      "0s - loss: 0.1575 - acc: 0.9464 - val_loss: 0.1363 - val_acc: 0.9601\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.13635 to 0.13178, saving model to best.model\n",
      "0s - loss: 0.1433 - acc: 0.9523 - val_loss: 0.1318 - val_acc: 0.9581\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.13178 to 0.12907, saving model to best.model\n",
      "0s - loss: 0.1467 - acc: 0.9494 - val_loss: 0.1291 - val_acc: 0.9620\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1419 - acc: 0.9523 - val_loss: 0.1295 - val_acc: 0.9620\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.12907 to 0.12355, saving model to best.model\n",
      "0s - loss: 0.1494 - acc: 0.9513 - val_loss: 0.1236 - val_acc: 0.9591\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.12355 to 0.12121, saving model to best.model\n",
      "0s - loss: 0.1467 - acc: 0.9515 - val_loss: 0.1212 - val_acc: 0.9649\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1397 - acc: 0.9515 - val_loss: 0.1219 - val_acc: 0.9659\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.12121 to 0.11553, saving model to best.model\n",
      "0s - loss: 0.1339 - acc: 0.9542 - val_loss: 0.1155 - val_acc: 0.9688\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.11553 to 0.10994, saving model to best.model\n",
      "0s - loss: 0.1308 - acc: 0.9547 - val_loss: 0.1099 - val_acc: 0.9698\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.10994 to 0.10730, saving model to best.model\n",
      "0s - loss: 0.1229 - acc: 0.9584 - val_loss: 0.1073 - val_acc: 0.9698\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1259 - acc: 0.9540 - val_loss: 0.1118 - val_acc: 0.9679\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.10730 to 0.10483, saving model to best.model\n",
      "0s - loss: 0.1263 - acc: 0.9559 - val_loss: 0.1048 - val_acc: 0.9737\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.10483 to 0.10259, saving model to best.model\n",
      "0s - loss: 0.1282 - acc: 0.9576 - val_loss: 0.1026 - val_acc: 0.9747\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.10259 to 0.10125, saving model to best.model\n",
      "0s - loss: 0.1204 - acc: 0.9562 - val_loss: 0.1013 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1220 - acc: 0.9586 - val_loss: 0.1029 - val_acc: 0.9737\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.10125 to 0.09646, saving model to best.model\n",
      "0s - loss: 0.1168 - acc: 0.9557 - val_loss: 0.0965 - val_acc: 0.9757\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.09646 to 0.09355, saving model to best.model\n",
      "0s - loss: 0.1152 - acc: 0.9562 - val_loss: 0.0936 - val_acc: 0.9757\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1162 - acc: 0.9620 - val_loss: 0.0941 - val_acc: 0.9766\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.09355 to 0.09175, saving model to best.model\n",
      "0s - loss: 0.1183 - acc: 0.9601 - val_loss: 0.0918 - val_acc: 0.9776\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.09175 to 0.09035, saving model to best.model\n",
      "0s - loss: 0.1089 - acc: 0.9625 - val_loss: 0.0904 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1078 - acc: 0.9610 - val_loss: 0.0905 - val_acc: 0.9747\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.09035 to 0.08469, saving model to best.model\n",
      "0s - loss: 0.1102 - acc: 0.9584 - val_loss: 0.0847 - val_acc: 0.9805\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1166 - acc: 0.9603 - val_loss: 0.0856 - val_acc: 0.9747\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.08469 to 0.08422, saving model to best.model\n",
      "0s - loss: 0.1052 - acc: 0.9627 - val_loss: 0.0842 - val_acc: 0.9766\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.08422 to 0.08118, saving model to best.model\n",
      "0s - loss: 0.1004 - acc: 0.9662 - val_loss: 0.0812 - val_acc: 0.9786\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0973 - acc: 0.9640 - val_loss: 0.0817 - val_acc: 0.9766\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.08118 to 0.07779, saving model to best.model\n",
      "0s - loss: 0.0990 - acc: 0.9686 - val_loss: 0.0778 - val_acc: 0.9786\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0967 - acc: 0.9657 - val_loss: 0.0781 - val_acc: 0.9776\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.07779 to 0.07655, saving model to best.model\n",
      "0s - loss: 0.0948 - acc: 0.9681 - val_loss: 0.0765 - val_acc: 0.9776\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.07655 to 0.07446, saving model to best.model\n",
      "0s - loss: 0.1016 - acc: 0.9640 - val_loss: 0.0745 - val_acc: 0.9776\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.07446 to 0.07318, saving model to best.model\n",
      "0s - loss: 0.1019 - acc: 0.9627 - val_loss: 0.0732 - val_acc: 0.9776\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.07318 to 0.07120, saving model to best.model\n",
      "0s - loss: 0.0962 - acc: 0.9666 - val_loss: 0.0712 - val_acc: 0.9796\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.07120 to 0.07075, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9640 - val_loss: 0.0708 - val_acc: 0.9825\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0877 - acc: 0.9681 - val_loss: 0.0715 - val_acc: 0.9786\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.07075 to 0.06890, saving model to best.model\n",
      "0s - loss: 0.0911 - acc: 0.9679 - val_loss: 0.0689 - val_acc: 0.9796\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.06890 to 0.06535, saving model to best.model\n",
      "0s - loss: 0.0854 - acc: 0.9683 - val_loss: 0.0653 - val_acc: 0.9796\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0886 - acc: 0.9696 - val_loss: 0.0657 - val_acc: 0.9766\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.06535 to 0.06309, saving model to best.model\n",
      "0s - loss: 0.0933 - acc: 0.9669 - val_loss: 0.0631 - val_acc: 0.9825\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.06309 to 0.06271, saving model to best.model\n",
      "0s - loss: 0.0951 - acc: 0.9645 - val_loss: 0.0627 - val_acc: 0.9825\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0874 - acc: 0.9679 - val_loss: 0.0642 - val_acc: 0.9796\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0823 - acc: 0.9715 - val_loss: 0.0628 - val_acc: 0.9796\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.06271 to 0.06133, saving model to best.model\n",
      "0s - loss: 0.0803 - acc: 0.9696 - val_loss: 0.0613 - val_acc: 0.9796\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.06133 to 0.06078, saving model to best.model\n",
      "0s - loss: 0.0715 - acc: 0.9757 - val_loss: 0.0608 - val_acc: 0.9796\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.06078 to 0.05759, saving model to best.model\n",
      "0s - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0576 - val_acc: 0.9796\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.05759 to 0.05639, saving model to best.model\n",
      "0s - loss: 0.0718 - acc: 0.9744 - val_loss: 0.0564 - val_acc: 0.9825\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.05639 to 0.05594, saving model to best.model\n",
      "0s - loss: 0.0850 - acc: 0.9722 - val_loss: 0.0559 - val_acc: 0.9805\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.05594 to 0.05570, saving model to best.model\n",
      "0s - loss: 0.0753 - acc: 0.9703 - val_loss: 0.0557 - val_acc: 0.9825\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0738 - acc: 0.9722 - val_loss: 0.0567 - val_acc: 0.9815\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0797 - acc: 0.9713 - val_loss: 0.0562 - val_acc: 0.9825\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.05570 to 0.05431, saving model to best.model\n",
      "0s - loss: 0.0696 - acc: 0.9759 - val_loss: 0.0543 - val_acc: 0.9834\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.05431 to 0.05264, saving model to best.model\n",
      "0s - loss: 0.0739 - acc: 0.9747 - val_loss: 0.0526 - val_acc: 0.9854\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.05264 to 0.05023, saving model to best.model\n",
      "0s - loss: 0.0714 - acc: 0.9761 - val_loss: 0.0502 - val_acc: 0.9854\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.05023 to 0.05000, saving model to best.model\n",
      "0s - loss: 0.0728 - acc: 0.9725 - val_loss: 0.0500 - val_acc: 0.9854\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.05000 to 0.04876, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9722 - val_loss: 0.0488 - val_acc: 0.9854\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.04876 to 0.04782, saving model to best.model\n",
      "0s - loss: 0.0736 - acc: 0.9730 - val_loss: 0.0478 - val_acc: 0.9844\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.04782 to 0.04685, saving model to best.model\n",
      "0s - loss: 0.0679 - acc: 0.9757 - val_loss: 0.0469 - val_acc: 0.9825\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.04685 to 0.04335, saving model to best.model\n",
      "0s - loss: 0.0678 - acc: 0.9757 - val_loss: 0.0434 - val_acc: 0.9864\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0656 - acc: 0.9766 - val_loss: 0.0442 - val_acc: 0.9873\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0656 - acc: 0.9732 - val_loss: 0.0463 - val_acc: 0.9864\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0700 - acc: 0.9737 - val_loss: 0.0456 - val_acc: 0.9844\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0647 - acc: 0.9783 - val_loss: 0.0443 - val_acc: 0.9854\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.04335 to 0.04111, saving model to best.model\n",
      "0s - loss: 0.0685 - acc: 0.9754 - val_loss: 0.0411 - val_acc: 0.9844\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.04111 to 0.03934, saving model to best.model\n",
      "0s - loss: 0.0617 - acc: 0.9774 - val_loss: 0.0393 - val_acc: 0.9844\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0616 - acc: 0.9749 - val_loss: 0.0399 - val_acc: 0.9864\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.03934 to 0.03664, saving model to best.model\n",
      "0s - loss: 0.0588 - acc: 0.9815 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03664 to 0.03597, saving model to best.model\n",
      "0s - loss: 0.0602 - acc: 0.9788 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0564 - acc: 0.9791 - val_loss: 0.0369 - val_acc: 0.9883\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0579 - acc: 0.9776 - val_loss: 0.0363 - val_acc: 0.9883\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0592 - acc: 0.9798 - val_loss: 0.0376 - val_acc: 0.9873\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0588 - acc: 0.9781 - val_loss: 0.0368 - val_acc: 0.9883\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.03597 to 0.03320, saving model to best.model\n",
      "0s - loss: 0.0553 - acc: 0.9830 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.03320 to 0.03310, saving model to best.model\n",
      "0s - loss: 0.0600 - acc: 0.9795 - val_loss: 0.0331 - val_acc: 0.9883\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.03310 to 0.03293, saving model to best.model\n",
      "0s - loss: 0.0571 - acc: 0.9766 - val_loss: 0.0329 - val_acc: 0.9873\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.03293 to 0.03135, saving model to best.model\n",
      "0s - loss: 0.0543 - acc: 0.9817 - val_loss: 0.0314 - val_acc: 0.9873\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.03135 to 0.02981, saving model to best.model\n",
      "0s - loss: 0.0513 - acc: 0.9803 - val_loss: 0.0298 - val_acc: 0.9883\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0507 - acc: 0.9800 - val_loss: 0.0299 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.02981 to 0.02669, saving model to best.model\n",
      "0s - loss: 0.0524 - acc: 0.9822 - val_loss: 0.0267 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0583 - acc: 0.9776 - val_loss: 0.0309 - val_acc: 0.9873\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0510 - acc: 0.9815 - val_loss: 0.0294 - val_acc: 0.9873\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0510 - acc: 0.9810 - val_loss: 0.0269 - val_acc: 0.9893\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02669 to 0.02441, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9849 - val_loss: 0.0244 - val_acc: 0.9873\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02441 to 0.02393, saving model to best.model\n",
      "0s - loss: 0.0447 - acc: 0.9849 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02393 to 0.02344, saving model to best.model\n",
      "0s - loss: 0.0445 - acc: 0.9810 - val_loss: 0.0234 - val_acc: 0.9893\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9825 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9847 - val_loss: 0.0234 - val_acc: 0.9893\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02344 to 0.02296, saving model to best.model\n",
      "0s - loss: 0.0461 - acc: 0.9827 - val_loss: 0.0230 - val_acc: 0.9893\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9825 - val_loss: 0.0242 - val_acc: 0.9873\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9837 - val_loss: 0.0235 - val_acc: 0.9893\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.02296 to 0.02187, saving model to best.model\n",
      "0s - loss: 0.0509 - acc: 0.9815 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.02187 to 0.02150, saving model to best.model\n",
      "0s - loss: 0.0429 - acc: 0.9844 - val_loss: 0.0215 - val_acc: 0.9893\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9856 - val_loss: 0.0219 - val_acc: 0.9893\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9866 - val_loss: 0.0246 - val_acc: 0.9893\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9834 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02150 to 0.02074, saving model to best.model\n",
      "0s - loss: 0.0444 - acc: 0.9849 - val_loss: 0.0207 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.02074 to 0.02056, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9856 - val_loss: 0.0206 - val_acc: 0.9893\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.02056 to 0.02004, saving model to best.model\n",
      "0s - loss: 0.0369 - acc: 0.9861 - val_loss: 0.0200 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.02004 to 0.01865, saving model to best.model\n",
      "0s - loss: 0.0413 - acc: 0.9871 - val_loss: 0.0186 - val_acc: 0.9893\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01865 to 0.01811, saving model to best.model\n",
      "0s - loss: 0.0481 - acc: 0.9822 - val_loss: 0.0181 - val_acc: 0.9912\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01811 to 0.01766, saving model to best.model\n",
      "0s - loss: 0.0398 - acc: 0.9842 - val_loss: 0.0177 - val_acc: 0.9893\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9834 - val_loss: 0.0179 - val_acc: 0.9903\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9844 - val_loss: 0.0177 - val_acc: 0.9893\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01766 to 0.01630, saving model to best.model\n",
      "0s - loss: 0.0432 - acc: 0.9849 - val_loss: 0.0163 - val_acc: 0.9922\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0170 - val_acc: 0.9903\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9854 - val_loss: 0.0182 - val_acc: 0.9893\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9834 - val_loss: 0.0206 - val_acc: 0.9883\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9832 - val_loss: 0.0221 - val_acc: 0.9883\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01630 to 0.01617, saving model to best.model\n",
      "0s - loss: 0.0387 - acc: 0.9851 - val_loss: 0.0162 - val_acc: 0.9903\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9881 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01617 to 0.01522, saving model to best.model\n",
      "0s - loss: 0.0469 - acc: 0.9817 - val_loss: 0.0152 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0396 - acc: 0.9842 - val_loss: 0.0163 - val_acc: 0.9893\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9861 - val_loss: 0.0158 - val_acc: 0.9893\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9859 - val_loss: 0.0159 - val_acc: 0.9893\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01522 to 0.01518, saving model to best.model\n",
      "0s - loss: 0.0395 - acc: 0.9837 - val_loss: 0.0152 - val_acc: 0.9893\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01518 to 0.01439, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0144 - val_acc: 0.9932\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9844 - val_loss: 0.0192 - val_acc: 0.9922\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9827 - val_loss: 0.0149 - val_acc: 0.9922\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01439 to 0.01419, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9876 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01419 to 0.01356, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9837 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01356 to 0.01332, saving model to best.model\n",
      "0s - loss: 0.0478 - acc: 0.9822 - val_loss: 0.0133 - val_acc: 0.9932\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9842 - val_loss: 0.0139 - val_acc: 0.9922\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9832 - val_loss: 0.0151 - val_acc: 0.9912\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0136 - val_acc: 0.9903\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01332 to 0.01259, saving model to best.model\n",
      "0s - loss: 0.0346 - acc: 0.9881 - val_loss: 0.0126 - val_acc: 0.9942\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.01259 to 0.01173, saving model to best.model\n",
      "0s - loss: 0.0304 - acc: 0.9886 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9854 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9869 - val_loss: 0.0136 - val_acc: 0.9942\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9856 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9871 - val_loss: 0.0130 - val_acc: 0.9932\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01173 to 0.01037, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9881 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.01037 to 0.00962, saving model to best.model\n",
      "0s - loss: 0.0289 - acc: 0.9888 - val_loss: 0.0096 - val_acc: 0.9951\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9888 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9878 - val_loss: 0.0103 - val_acc: 0.9942\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9866 - val_loss: 0.0102 - val_acc: 0.9942\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00962 to 0.00786, saving model to best.model\n",
      "0s - loss: 0.0281 - acc: 0.9886 - val_loss: 0.0079 - val_acc: 0.9990\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9893 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9869 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9895 - val_loss: 0.0080 - val_acc: 0.9990\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9878 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9873 - val_loss: 0.0081 - val_acc: 0.9981\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9881 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.69700, saving model to best.model\n",
      "0s - loss: 0.8110 - acc: 0.5096 - val_loss: 0.6970 - val_acc: 0.4645\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.69700 to 0.65219, saving model to best.model\n",
      "0s - loss: 0.7604 - acc: 0.5235 - val_loss: 0.6522 - val_acc: 0.7293\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65219 to 0.61942, saving model to best.model\n",
      "0s - loss: 0.7167 - acc: 0.5495 - val_loss: 0.6194 - val_acc: 0.8101\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61942 to 0.56994, saving model to best.model\n",
      "0s - loss: 0.6724 - acc: 0.5953 - val_loss: 0.5699 - val_acc: 0.7751\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.56994 to 0.49256, saving model to best.model\n",
      "0s - loss: 0.6157 - acc: 0.6567 - val_loss: 0.4926 - val_acc: 0.8082\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.49256 to 0.42927, saving model to best.model\n",
      "0s - loss: 0.5347 - acc: 0.7383 - val_loss: 0.4293 - val_acc: 0.8267\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.42927 to 0.40438, saving model to best.model\n",
      "0s - loss: 0.4816 - acc: 0.7908 - val_loss: 0.4044 - val_acc: 0.8296\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.40438 to 0.36696, saving model to best.model\n",
      "0s - loss: 0.4559 - acc: 0.7984 - val_loss: 0.3670 - val_acc: 0.8520\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36696 to 0.34924, saving model to best.model\n",
      "0s - loss: 0.4162 - acc: 0.8252 - val_loss: 0.3492 - val_acc: 0.8627\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34924 to 0.33834, saving model to best.model\n",
      "0s - loss: 0.3924 - acc: 0.8347 - val_loss: 0.3383 - val_acc: 0.8656\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33834 to 0.31880, saving model to best.model\n",
      "0s - loss: 0.3741 - acc: 0.8515 - val_loss: 0.3188 - val_acc: 0.8763\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31880 to 0.30747, saving model to best.model\n",
      "0s - loss: 0.3617 - acc: 0.8571 - val_loss: 0.3075 - val_acc: 0.8802\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.30747 to 0.29769, saving model to best.model\n",
      "0s - loss: 0.3547 - acc: 0.8610 - val_loss: 0.2977 - val_acc: 0.8802\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.29769 to 0.28874, saving model to best.model\n",
      "0s - loss: 0.3434 - acc: 0.8685 - val_loss: 0.2887 - val_acc: 0.8890\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.28874 to 0.28154, saving model to best.model\n",
      "0s - loss: 0.3285 - acc: 0.8758 - val_loss: 0.2815 - val_acc: 0.8939\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.28154 to 0.27563, saving model to best.model\n",
      "0s - loss: 0.3181 - acc: 0.8846 - val_loss: 0.2756 - val_acc: 0.8968\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.27563 to 0.27197, saving model to best.model\n",
      "0s - loss: 0.3093 - acc: 0.8870 - val_loss: 0.2720 - val_acc: 0.9017\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.27197 to 0.26605, saving model to best.model\n",
      "0s - loss: 0.3108 - acc: 0.8843 - val_loss: 0.2661 - val_acc: 0.8958\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26605 to 0.26085, saving model to best.model\n",
      "0s - loss: 0.2934 - acc: 0.8960 - val_loss: 0.2608 - val_acc: 0.9046\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.26085 to 0.25757, saving model to best.model\n",
      "0s - loss: 0.2804 - acc: 0.8982 - val_loss: 0.2576 - val_acc: 0.9065\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.25757 to 0.25401, saving model to best.model\n",
      "0s - loss: 0.2803 - acc: 0.8992 - val_loss: 0.2540 - val_acc: 0.9085\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25401 to 0.25090, saving model to best.model\n",
      "0s - loss: 0.2652 - acc: 0.9060 - val_loss: 0.2509 - val_acc: 0.9056\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.25090 to 0.24528, saving model to best.model\n",
      "0s - loss: 0.2676 - acc: 0.9024 - val_loss: 0.2453 - val_acc: 0.9046\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24528 to 0.24122, saving model to best.model\n",
      "0s - loss: 0.2571 - acc: 0.9060 - val_loss: 0.2412 - val_acc: 0.9056\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.24122 to 0.24038, saving model to best.model\n",
      "0s - loss: 0.2569 - acc: 0.9082 - val_loss: 0.2404 - val_acc: 0.9075\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.24038 to 0.23927, saving model to best.model\n",
      "0s - loss: 0.2549 - acc: 0.9094 - val_loss: 0.2393 - val_acc: 0.9065\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.23927 to 0.23533, saving model to best.model\n",
      "0s - loss: 0.2522 - acc: 0.9089 - val_loss: 0.2353 - val_acc: 0.9065\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.23533 to 0.23219, saving model to best.model\n",
      "0s - loss: 0.2445 - acc: 0.9143 - val_loss: 0.2322 - val_acc: 0.9065\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.23219 to 0.22761, saving model to best.model\n",
      "0s - loss: 0.2532 - acc: 0.9072 - val_loss: 0.2276 - val_acc: 0.9075\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22761 to 0.22544, saving model to best.model\n",
      "0s - loss: 0.2400 - acc: 0.9119 - val_loss: 0.2254 - val_acc: 0.9075\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.22544 to 0.22101, saving model to best.model\n",
      "0s - loss: 0.2396 - acc: 0.9126 - val_loss: 0.2210 - val_acc: 0.9065\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.22101 to 0.21797, saving model to best.model\n",
      "0s - loss: 0.2387 - acc: 0.9109 - val_loss: 0.2180 - val_acc: 0.9056\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.21797 to 0.21409, saving model to best.model\n",
      "0s - loss: 0.2380 - acc: 0.9131 - val_loss: 0.2141 - val_acc: 0.9075\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.21409 to 0.21037, saving model to best.model\n",
      "0s - loss: 0.2278 - acc: 0.9145 - val_loss: 0.2104 - val_acc: 0.9085\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.21037 to 0.20621, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9170 - val_loss: 0.2062 - val_acc: 0.9094\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.20621 to 0.20292, saving model to best.model\n",
      "0s - loss: 0.2167 - acc: 0.9245 - val_loss: 0.2029 - val_acc: 0.9143\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.2153 - acc: 0.9196 - val_loss: 0.2038 - val_acc: 0.9211\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.20292 to 0.19793, saving model to best.model\n",
      "0s - loss: 0.2222 - acc: 0.9153 - val_loss: 0.1979 - val_acc: 0.9163\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19793 to 0.19322, saving model to best.model\n",
      "0s - loss: 0.2081 - acc: 0.9231 - val_loss: 0.1932 - val_acc: 0.9231\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19322 to 0.18966, saving model to best.model\n",
      "0s - loss: 0.2088 - acc: 0.9221 - val_loss: 0.1897 - val_acc: 0.9182\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18966 to 0.18464, saving model to best.model\n",
      "0s - loss: 0.2031 - acc: 0.9274 - val_loss: 0.1846 - val_acc: 0.9192\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18464 to 0.18236, saving model to best.model\n",
      "0s - loss: 0.2059 - acc: 0.9231 - val_loss: 0.1824 - val_acc: 0.9299\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18236 to 0.17811, saving model to best.model\n",
      "0s - loss: 0.1909 - acc: 0.9282 - val_loss: 0.1781 - val_acc: 0.9221\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.17811 to 0.17772, saving model to best.model\n",
      "0s - loss: 0.2000 - acc: 0.9228 - val_loss: 0.1777 - val_acc: 0.9309\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.17772 to 0.17015, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9252 - val_loss: 0.1702 - val_acc: 0.9260\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17015 to 0.16604, saving model to best.model\n",
      "0s - loss: 0.1920 - acc: 0.9294 - val_loss: 0.1660 - val_acc: 0.9250\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.16604 to 0.16379, saving model to best.model\n",
      "0s - loss: 0.1777 - acc: 0.9311 - val_loss: 0.1638 - val_acc: 0.9348\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.16379 to 0.15853, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9313 - val_loss: 0.1585 - val_acc: 0.9348\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15853 to 0.15489, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9386 - val_loss: 0.1549 - val_acc: 0.9328\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.15489 to 0.15158, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9357 - val_loss: 0.1516 - val_acc: 0.9338\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.15158 to 0.15064, saving model to best.model\n",
      "0s - loss: 0.1608 - acc: 0.9364 - val_loss: 0.1506 - val_acc: 0.9309\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.15064 to 0.14822, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9352 - val_loss: 0.1482 - val_acc: 0.9406\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14822 to 0.14040, saving model to best.model\n",
      "0s - loss: 0.1652 - acc: 0.9403 - val_loss: 0.1404 - val_acc: 0.9377\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.14040 to 0.13615, saving model to best.model\n",
      "0s - loss: 0.1633 - acc: 0.9408 - val_loss: 0.1361 - val_acc: 0.9435\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13615 to 0.13138, saving model to best.model\n",
      "0s - loss: 0.1616 - acc: 0.9374 - val_loss: 0.1314 - val_acc: 0.9387\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13138 to 0.12672, saving model to best.model\n",
      "0s - loss: 0.1615 - acc: 0.9394 - val_loss: 0.1267 - val_acc: 0.9396\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12672 to 0.12575, saving model to best.model\n",
      "0s - loss: 0.1419 - acc: 0.9418 - val_loss: 0.1257 - val_acc: 0.9406\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12575 to 0.12368, saving model to best.model\n",
      "0s - loss: 0.1467 - acc: 0.9428 - val_loss: 0.1237 - val_acc: 0.9396\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.12368 to 0.11951, saving model to best.model\n",
      "0s - loss: 0.1444 - acc: 0.9457 - val_loss: 0.1195 - val_acc: 0.9503\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11951 to 0.11391, saving model to best.model\n",
      "0s - loss: 0.1425 - acc: 0.9467 - val_loss: 0.1139 - val_acc: 0.9523\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11391 to 0.10892, saving model to best.model\n",
      "0s - loss: 0.1441 - acc: 0.9452 - val_loss: 0.1089 - val_acc: 0.9552\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10892 to 0.10714, saving model to best.model\n",
      "0s - loss: 0.1406 - acc: 0.9455 - val_loss: 0.1071 - val_acc: 0.9542\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10714 to 0.10291, saving model to best.model\n",
      "0s - loss: 0.1332 - acc: 0.9511 - val_loss: 0.1029 - val_acc: 0.9591\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10291 to 0.09993, saving model to best.model\n",
      "0s - loss: 0.1308 - acc: 0.9530 - val_loss: 0.0999 - val_acc: 0.9601\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.09993 to 0.09711, saving model to best.model\n",
      "0s - loss: 0.1194 - acc: 0.9540 - val_loss: 0.0971 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09711 to 0.09298, saving model to best.model\n",
      "0s - loss: 0.1229 - acc: 0.9562 - val_loss: 0.0930 - val_acc: 0.9640\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09298 to 0.09141, saving model to best.model\n",
      "0s - loss: 0.1178 - acc: 0.9537 - val_loss: 0.0914 - val_acc: 0.9611\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09141 to 0.08642, saving model to best.model\n",
      "0s - loss: 0.1241 - acc: 0.9501 - val_loss: 0.0864 - val_acc: 0.9757\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.08642 to 0.08405, saving model to best.model\n",
      "0s - loss: 0.1187 - acc: 0.9545 - val_loss: 0.0840 - val_acc: 0.9679\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08405 to 0.08170, saving model to best.model\n",
      "0s - loss: 0.1200 - acc: 0.9520 - val_loss: 0.0817 - val_acc: 0.9698\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08170 to 0.07950, saving model to best.model\n",
      "0s - loss: 0.1205 - acc: 0.9540 - val_loss: 0.0795 - val_acc: 0.9786\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07950 to 0.07669, saving model to best.model\n",
      "0s - loss: 0.1042 - acc: 0.9613 - val_loss: 0.0767 - val_acc: 0.9718\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07669 to 0.07575, saving model to best.model\n",
      "0s - loss: 0.1079 - acc: 0.9618 - val_loss: 0.0758 - val_acc: 0.9727\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1145 - acc: 0.9554 - val_loss: 0.0761 - val_acc: 0.9718\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.07575 to 0.07342, saving model to best.model\n",
      "0s - loss: 0.1093 - acc: 0.9598 - val_loss: 0.0734 - val_acc: 0.9796\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07342 to 0.07149, saving model to best.model\n",
      "0s - loss: 0.0984 - acc: 0.9615 - val_loss: 0.0715 - val_acc: 0.9747\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07149 to 0.06831, saving model to best.model\n",
      "0s - loss: 0.1018 - acc: 0.9623 - val_loss: 0.0683 - val_acc: 0.9757\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06831 to 0.06468, saving model to best.model\n",
      "0s - loss: 0.0958 - acc: 0.9630 - val_loss: 0.0647 - val_acc: 0.9757\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06468 to 0.06235, saving model to best.model\n",
      "0s - loss: 0.1045 - acc: 0.9581 - val_loss: 0.0623 - val_acc: 0.9815\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06235 to 0.06190, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9613 - val_loss: 0.0619 - val_acc: 0.9825\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06190 to 0.05959, saving model to best.model\n",
      "0s - loss: 0.0941 - acc: 0.9625 - val_loss: 0.0596 - val_acc: 0.9815\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05959 to 0.05791, saving model to best.model\n",
      "0s - loss: 0.0919 - acc: 0.9681 - val_loss: 0.0579 - val_acc: 0.9815\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05791 to 0.05556, saving model to best.model\n",
      "0s - loss: 0.0918 - acc: 0.9645 - val_loss: 0.0556 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05556 to 0.05387, saving model to best.model\n",
      "0s - loss: 0.0846 - acc: 0.9671 - val_loss: 0.0539 - val_acc: 0.9825\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05387 to 0.05294, saving model to best.model\n",
      "0s - loss: 0.0900 - acc: 0.9674 - val_loss: 0.0529 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05294 to 0.05252, saving model to best.model\n",
      "0s - loss: 0.0869 - acc: 0.9679 - val_loss: 0.0525 - val_acc: 0.9834\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05252 to 0.05112, saving model to best.model\n",
      "0s - loss: 0.0847 - acc: 0.9693 - val_loss: 0.0511 - val_acc: 0.9815\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05112 to 0.05045, saving model to best.model\n",
      "0s - loss: 0.0834 - acc: 0.9683 - val_loss: 0.0504 - val_acc: 0.9825\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05045 to 0.04970, saving model to best.model\n",
      "0s - loss: 0.0798 - acc: 0.9742 - val_loss: 0.0497 - val_acc: 0.9825\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04970 to 0.04886, saving model to best.model\n",
      "0s - loss: 0.0751 - acc: 0.9713 - val_loss: 0.0489 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0844 - acc: 0.9688 - val_loss: 0.0493 - val_acc: 0.9844\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04886 to 0.04759, saving model to best.model\n",
      "0s - loss: 0.0830 - acc: 0.9691 - val_loss: 0.0476 - val_acc: 0.9825\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04759 to 0.04503, saving model to best.model\n",
      "0s - loss: 0.0769 - acc: 0.9720 - val_loss: 0.0450 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04503 to 0.04308, saving model to best.model\n",
      "0s - loss: 0.0764 - acc: 0.9715 - val_loss: 0.0431 - val_acc: 0.9844\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04308 to 0.04128, saving model to best.model\n",
      "0s - loss: 0.0800 - acc: 0.9698 - val_loss: 0.0413 - val_acc: 0.9844\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0696 - acc: 0.9744 - val_loss: 0.0420 - val_acc: 0.9854\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04128 to 0.04048, saving model to best.model\n",
      "0s - loss: 0.0661 - acc: 0.9759 - val_loss: 0.0405 - val_acc: 0.9834\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0693 - acc: 0.9739 - val_loss: 0.0438 - val_acc: 0.9854\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04048 to 0.03735, saving model to best.model\n",
      "0s - loss: 0.0739 - acc: 0.9718 - val_loss: 0.0374 - val_acc: 0.9844\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03735 to 0.03675, saving model to best.model\n",
      "0s - loss: 0.0725 - acc: 0.9742 - val_loss: 0.0367 - val_acc: 0.9864\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0733 - acc: 0.9730 - val_loss: 0.0386 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03675 to 0.03523, saving model to best.model\n",
      "0s - loss: 0.0691 - acc: 0.9737 - val_loss: 0.0352 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03523 to 0.03373, saving model to best.model\n",
      "0s - loss: 0.0700 - acc: 0.9759 - val_loss: 0.0337 - val_acc: 0.9864\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03373 to 0.03272, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9747 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9754 - val_loss: 0.0329 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03272 to 0.03221, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9730 - val_loss: 0.0322 - val_acc: 0.9883\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9769 - val_loss: 0.0322 - val_acc: 0.9873\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03221 to 0.03214, saving model to best.model\n",
      "0s - loss: 0.0594 - acc: 0.9774 - val_loss: 0.0321 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03214 to 0.02881, saving model to best.model\n",
      "0s - loss: 0.0605 - acc: 0.9798 - val_loss: 0.0288 - val_acc: 0.9864\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9749 - val_loss: 0.0290 - val_acc: 0.9864\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02881 to 0.02880, saving model to best.model\n",
      "0s - loss: 0.0543 - acc: 0.9798 - val_loss: 0.0288 - val_acc: 0.9883\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0538 - acc: 0.9803 - val_loss: 0.0301 - val_acc: 0.9883\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02880 to 0.02693, saving model to best.model\n",
      "0s - loss: 0.0570 - acc: 0.9793 - val_loss: 0.0269 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9805 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0540 - acc: 0.9810 - val_loss: 0.0288 - val_acc: 0.9883\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0759 - acc: 0.9713 - val_loss: 0.0323 - val_acc: 0.9912\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0669 - acc: 0.9742 - val_loss: 0.0357 - val_acc: 0.9873\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02693 to 0.02670, saving model to best.model\n",
      "0s - loss: 0.0538 - acc: 0.9795 - val_loss: 0.0267 - val_acc: 0.9883\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0562 - acc: 0.9800 - val_loss: 0.0278 - val_acc: 0.9883\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0518 - acc: 0.9822 - val_loss: 0.0269 - val_acc: 0.9883\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.02670 to 0.02490, saving model to best.model\n",
      "0s - loss: 0.0511 - acc: 0.9832 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0569 - acc: 0.9786 - val_loss: 0.0348 - val_acc: 0.9864\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0601 - acc: 0.9774 - val_loss: 0.0275 - val_acc: 0.9893\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0573 - acc: 0.9786 - val_loss: 0.0252 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9808 - val_loss: 0.0269 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02490 to 0.02404, saving model to best.model\n",
      "0s - loss: 0.0579 - acc: 0.9791 - val_loss: 0.0240 - val_acc: 0.9893\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9813 - val_loss: 0.0247 - val_acc: 0.9883\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02404 to 0.02237, saving model to best.model\n",
      "0s - loss: 0.0444 - acc: 0.9834 - val_loss: 0.0224 - val_acc: 0.9893\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02237 to 0.02209, saving model to best.model\n",
      "0s - loss: 0.0402 - acc: 0.9854 - val_loss: 0.0221 - val_acc: 0.9893\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02209 to 0.01987, saving model to best.model\n",
      "0s - loss: 0.0534 - acc: 0.9808 - val_loss: 0.0199 - val_acc: 0.9922\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0485 - acc: 0.9820 - val_loss: 0.0234 - val_acc: 0.9893\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01987 to 0.01927, saving model to best.model\n",
      "0s - loss: 0.0515 - acc: 0.9781 - val_loss: 0.0193 - val_acc: 0.9912\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9832 - val_loss: 0.0199 - val_acc: 0.9912\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9822 - val_loss: 0.0211 - val_acc: 0.9912\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9834 - val_loss: 0.0211 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9847 - val_loss: 0.0202 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9856 - val_loss: 0.0230 - val_acc: 0.9883\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9827 - val_loss: 0.0200 - val_acc: 0.9893\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0492 - acc: 0.9813 - val_loss: 0.0219 - val_acc: 0.9883\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0479 - acc: 0.9827 - val_loss: 0.0196 - val_acc: 0.9893\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01927 to 0.01865, saving model to best.model\n",
      "0s - loss: 0.0422 - acc: 0.9849 - val_loss: 0.0187 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01865 to 0.01790, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9866 - val_loss: 0.0179 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01790 to 0.01720, saving model to best.model\n",
      "0s - loss: 0.0382 - acc: 0.9856 - val_loss: 0.0172 - val_acc: 0.9912\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0506 - acc: 0.9786 - val_loss: 0.0175 - val_acc: 0.9912\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9864 - val_loss: 0.0184 - val_acc: 0.9893\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01720 to 0.01682, saving model to best.model\n",
      "0s - loss: 0.0340 - acc: 0.9851 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9837 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01682 to 0.01578, saving model to best.model\n",
      "0s - loss: 0.0456 - acc: 0.9851 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9856 - val_loss: 0.0175 - val_acc: 0.9912\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9847 - val_loss: 0.0162 - val_acc: 0.9912\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9842 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.01578 to 0.01543, saving model to best.model\n",
      "0s - loss: 0.0392 - acc: 0.9861 - val_loss: 0.0154 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9859 - val_loss: 0.0185 - val_acc: 0.9912\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01543 to 0.01512, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9851 - val_loss: 0.0151 - val_acc: 0.9922\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0151 - val_acc: 0.9922\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9864 - val_loss: 0.0162 - val_acc: 0.9922\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01512 to 0.01387, saving model to best.model\n",
      "0s - loss: 0.0372 - acc: 0.9866 - val_loss: 0.0139 - val_acc: 0.9922\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9888 - val_loss: 0.0149 - val_acc: 0.9922\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9878 - val_loss: 0.0159 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01387 to 0.01355, saving model to best.model\n",
      "0s - loss: 0.0291 - acc: 0.9869 - val_loss: 0.0136 - val_acc: 0.9922\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9890 - val_loss: 0.0159 - val_acc: 0.9922\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9876 - val_loss: 0.0141 - val_acc: 0.9922\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9893 - val_loss: 0.0139 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9873 - val_loss: 0.0141 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9876 - val_loss: 0.0152 - val_acc: 0.9903\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01355 to 0.01345, saving model to best.model\n",
      "0s - loss: 0.0361 - acc: 0.9871 - val_loss: 0.0134 - val_acc: 0.9922\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9883 - val_loss: 0.0144 - val_acc: 0.9903\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0144 - val_acc: 0.9922\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01345 to 0.01287, saving model to best.model\n",
      "0s - loss: 0.0318 - acc: 0.9893 - val_loss: 0.0129 - val_acc: 0.9922\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9869 - val_loss: 0.0134 - val_acc: 0.9922\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01287 to 0.01185, saving model to best.model\n",
      "0s - loss: 0.0260 - acc: 0.9886 - val_loss: 0.0118 - val_acc: 0.9922\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01185 to 0.01117, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9866 - val_loss: 0.0112 - val_acc: 0.9932\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9864 - val_loss: 0.0159 - val_acc: 0.9903\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01117 to 0.01087, saving model to best.model\n",
      "0s - loss: 0.0347 - acc: 0.9866 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9905 - val_loss: 0.0110 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01087 to 0.01077, saving model to best.model\n",
      "0s - loss: 0.0306 - acc: 0.9890 - val_loss: 0.0108 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0121 - val_acc: 0.9922\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01077 to 0.00993, saving model to best.model\n",
      "0s - loss: 0.0296 - acc: 0.9878 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9895 - val_loss: 0.0116 - val_acc: 0.9922\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9851 - val_loss: 0.0120 - val_acc: 0.9922\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0272 - acc: 0.9900 - val_loss: 0.0120 - val_acc: 0.9932\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9864 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0213 - acc: 0.9927 - val_loss: 0.0102 - val_acc: 0.9932\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9903 - val_loss: 0.0104 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00993 to 0.00865, saving model to best.model\n",
      "0s - loss: 0.0263 - acc: 0.9893 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9878 - val_loss: 0.0122 - val_acc: 0.9922\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9890 - val_loss: 0.0096 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9895 - val_loss: 0.0118 - val_acc: 0.9922\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0265 - acc: 0.9895 - val_loss: 0.0127 - val_acc: 0.9922\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9886 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9893 - val_loss: 0.0094 - val_acc: 0.9942\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9898 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0245 - acc: 0.9895 - val_loss: 0.0100 - val_acc: 0.9932\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9890 - val_loss: 0.0091 - val_acc: 0.9951\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.00865 to 0.00859, saving model to best.model\n",
      "0s - loss: 0.0230 - acc: 0.9917 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0237 - acc: 0.9898 - val_loss: 0.0114 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0107 - val_acc: 0.9922\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9881 - val_loss: 0.0094 - val_acc: 0.9951\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66985, saving model to best.model\n",
      "0s - loss: 0.8026 - acc: 0.4977 - val_loss: 0.6698 - val_acc: 0.5940\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66985 to 0.63096, saving model to best.model\n",
      "0s - loss: 0.7324 - acc: 0.5381 - val_loss: 0.6310 - val_acc: 0.8179\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63096 to 0.57035, saving model to best.model\n",
      "0s - loss: 0.6737 - acc: 0.5948 - val_loss: 0.5703 - val_acc: 0.8257\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.57035 to 0.47864, saving model to best.model\n",
      "0s - loss: 0.6058 - acc: 0.6710 - val_loss: 0.4786 - val_acc: 0.8335\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.47864 to 0.40843, saving model to best.model\n",
      "0s - loss: 0.5341 - acc: 0.7407 - val_loss: 0.4084 - val_acc: 0.8491\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.40843 to 0.36705, saving model to best.model\n",
      "0s - loss: 0.4796 - acc: 0.7811 - val_loss: 0.3670 - val_acc: 0.8627\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.36705 to 0.33518, saving model to best.model\n",
      "0s - loss: 0.4402 - acc: 0.8115 - val_loss: 0.3352 - val_acc: 0.8783\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.33518 to 0.31758, saving model to best.model\n",
      "0s - loss: 0.4142 - acc: 0.8264 - val_loss: 0.3176 - val_acc: 0.8832\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.31758 to 0.30095, saving model to best.model\n",
      "0s - loss: 0.3954 - acc: 0.8369 - val_loss: 0.3009 - val_acc: 0.8802\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.30095 to 0.28939, saving model to best.model\n",
      "0s - loss: 0.3726 - acc: 0.8490 - val_loss: 0.2894 - val_acc: 0.8832\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.28939 to 0.27659, saving model to best.model\n",
      "0s - loss: 0.3557 - acc: 0.8580 - val_loss: 0.2766 - val_acc: 0.8939\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.27659 to 0.26704, saving model to best.model\n",
      "0s - loss: 0.3493 - acc: 0.8607 - val_loss: 0.2670 - val_acc: 0.8958\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.26704 to 0.26236, saving model to best.model\n",
      "0s - loss: 0.3355 - acc: 0.8678 - val_loss: 0.2624 - val_acc: 0.8939\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26236 to 0.25080, saving model to best.model\n",
      "0s - loss: 0.3256 - acc: 0.8700 - val_loss: 0.2508 - val_acc: 0.9026\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25080 to 0.24472, saving model to best.model\n",
      "0s - loss: 0.3189 - acc: 0.8778 - val_loss: 0.2447 - val_acc: 0.9075\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.24472 to 0.23837, saving model to best.model\n",
      "0s - loss: 0.3023 - acc: 0.8819 - val_loss: 0.2384 - val_acc: 0.9104\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.23837 to 0.23433, saving model to best.model\n",
      "0s - loss: 0.2979 - acc: 0.8826 - val_loss: 0.2343 - val_acc: 0.9182\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.23433 to 0.22838, saving model to best.model\n",
      "0s - loss: 0.2966 - acc: 0.8904 - val_loss: 0.2284 - val_acc: 0.9192\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22838 to 0.22511, saving model to best.model\n",
      "0s - loss: 0.2855 - acc: 0.8899 - val_loss: 0.2251 - val_acc: 0.9211\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22511 to 0.22094, saving model to best.model\n",
      "0s - loss: 0.2842 - acc: 0.8914 - val_loss: 0.2209 - val_acc: 0.9260\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22094 to 0.21863, saving model to best.model\n",
      "0s - loss: 0.2699 - acc: 0.8972 - val_loss: 0.2186 - val_acc: 0.9221\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21863 to 0.21256, saving model to best.model\n",
      "0s - loss: 0.2632 - acc: 0.9016 - val_loss: 0.2126 - val_acc: 0.9260\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21256 to 0.20834, saving model to best.model\n",
      "0s - loss: 0.2583 - acc: 0.9028 - val_loss: 0.2083 - val_acc: 0.9270\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20834 to 0.20463, saving model to best.model\n",
      "0s - loss: 0.2589 - acc: 0.9067 - val_loss: 0.2046 - val_acc: 0.9250\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2613 - acc: 0.9007 - val_loss: 0.2063 - val_acc: 0.9241\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20463 to 0.19791, saving model to best.model\n",
      "0s - loss: 0.2460 - acc: 0.9077 - val_loss: 0.1979 - val_acc: 0.9299\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19791 to 0.19596, saving model to best.model\n",
      "0s - loss: 0.2465 - acc: 0.9104 - val_loss: 0.1960 - val_acc: 0.9279\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19596 to 0.19282, saving model to best.model\n",
      "0s - loss: 0.2333 - acc: 0.9099 - val_loss: 0.1928 - val_acc: 0.9289\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2379 - acc: 0.9106 - val_loss: 0.1947 - val_acc: 0.9387\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19282 to 0.18980, saving model to best.model\n",
      "0s - loss: 0.2285 - acc: 0.9133 - val_loss: 0.1898 - val_acc: 0.9289\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18980 to 0.18338, saving model to best.model\n",
      "0s - loss: 0.2229 - acc: 0.9136 - val_loss: 0.1834 - val_acc: 0.9338\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18338 to 0.18006, saving model to best.model\n",
      "0s - loss: 0.2222 - acc: 0.9150 - val_loss: 0.1801 - val_acc: 0.9328\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2094 - acc: 0.9218 - val_loss: 0.1815 - val_acc: 0.9299\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18006 to 0.17501, saving model to best.model\n",
      "0s - loss: 0.2195 - acc: 0.9196 - val_loss: 0.1750 - val_acc: 0.9338\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17501 to 0.17294, saving model to best.model\n",
      "0s - loss: 0.2149 - acc: 0.9165 - val_loss: 0.1729 - val_acc: 0.9338\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17294 to 0.16932, saving model to best.model\n",
      "0s - loss: 0.2000 - acc: 0.9238 - val_loss: 0.1693 - val_acc: 0.9377\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16932 to 0.16616, saving model to best.model\n",
      "0s - loss: 0.2033 - acc: 0.9214 - val_loss: 0.1662 - val_acc: 0.9435\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16616 to 0.16323, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9262 - val_loss: 0.1632 - val_acc: 0.9387\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16323 to 0.15983, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9287 - val_loss: 0.1598 - val_acc: 0.9426\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15983 to 0.15661, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9304 - val_loss: 0.1566 - val_acc: 0.9396\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15661 to 0.15421, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9357 - val_loss: 0.1542 - val_acc: 0.9445\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15421 to 0.15411, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9308 - val_loss: 0.1541 - val_acc: 0.9426\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15411 to 0.14846, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9372 - val_loss: 0.1485 - val_acc: 0.9494\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14846 to 0.14728, saving model to best.model\n",
      "0s - loss: 0.1741 - acc: 0.9377 - val_loss: 0.1473 - val_acc: 0.9494\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1730 - acc: 0.9360 - val_loss: 0.1503 - val_acc: 0.9426\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14728 to 0.14135, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9355 - val_loss: 0.1413 - val_acc: 0.9533\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14135 to 0.13940, saving model to best.model\n",
      "0s - loss: 0.1636 - acc: 0.9372 - val_loss: 0.1394 - val_acc: 0.9533\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13940 to 0.13670, saving model to best.model\n",
      "0s - loss: 0.1691 - acc: 0.9384 - val_loss: 0.1367 - val_acc: 0.9542\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1596 - acc: 0.9384 - val_loss: 0.1374 - val_acc: 0.9552\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1603 - acc: 0.9433 - val_loss: 0.1408 - val_acc: 0.9513\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1532 - acc: 0.9481 - val_loss: 0.1370 - val_acc: 0.9562\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13670 to 0.12809, saving model to best.model\n",
      "0s - loss: 0.1532 - acc: 0.9472 - val_loss: 0.1281 - val_acc: 0.9591\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.12809 to 0.12616, saving model to best.model\n",
      "0s - loss: 0.1512 - acc: 0.9438 - val_loss: 0.1262 - val_acc: 0.9601\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1548 - acc: 0.9423 - val_loss: 0.1296 - val_acc: 0.9620\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1399 - acc: 0.9491 - val_loss: 0.1296 - val_acc: 0.9630\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12616 to 0.12512, saving model to best.model\n",
      "0s - loss: 0.1375 - acc: 0.9508 - val_loss: 0.1251 - val_acc: 0.9669\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12512 to 0.12331, saving model to best.model\n",
      "0s - loss: 0.1409 - acc: 0.9462 - val_loss: 0.1233 - val_acc: 0.9611\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12331 to 0.11994, saving model to best.model\n",
      "0s - loss: 0.1347 - acc: 0.9518 - val_loss: 0.1199 - val_acc: 0.9659\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1291 - acc: 0.9554 - val_loss: 0.1220 - val_acc: 0.9659\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11994 to 0.11888, saving model to best.model\n",
      "0s - loss: 0.1217 - acc: 0.9581 - val_loss: 0.1189 - val_acc: 0.9688\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11888 to 0.11257, saving model to best.model\n",
      "0s - loss: 0.1257 - acc: 0.9535 - val_loss: 0.1126 - val_acc: 0.9640\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1211 - acc: 0.9610 - val_loss: 0.1158 - val_acc: 0.9688\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11257 to 0.11168, saving model to best.model\n",
      "0s - loss: 0.1125 - acc: 0.9610 - val_loss: 0.1117 - val_acc: 0.9688\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1219 - acc: 0.9596 - val_loss: 0.1137 - val_acc: 0.9688\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.11168 to 0.11011, saving model to best.model\n",
      "0s - loss: 0.1186 - acc: 0.9528 - val_loss: 0.1101 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.11011 to 0.10748, saving model to best.model\n",
      "0s - loss: 0.1055 - acc: 0.9620 - val_loss: 0.1075 - val_acc: 0.9698\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.10748 to 0.10405, saving model to best.model\n",
      "0s - loss: 0.1120 - acc: 0.9593 - val_loss: 0.1041 - val_acc: 0.9698\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.10405 to 0.10191, saving model to best.model\n",
      "0s - loss: 0.1058 - acc: 0.9601 - val_loss: 0.1019 - val_acc: 0.9708\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1041 - acc: 0.9615 - val_loss: 0.1086 - val_acc: 0.9688\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.10191 to 0.10055, saving model to best.model\n",
      "0s - loss: 0.1036 - acc: 0.9620 - val_loss: 0.1005 - val_acc: 0.9708\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.0990 - acc: 0.9645 - val_loss: 0.1010 - val_acc: 0.9698\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.10055 to 0.09543, saving model to best.model\n",
      "0s - loss: 0.0970 - acc: 0.9671 - val_loss: 0.0954 - val_acc: 0.9718\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.0939 - acc: 0.9686 - val_loss: 0.1042 - val_acc: 0.9688\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.09543 to 0.09287, saving model to best.model\n",
      "0s - loss: 0.0971 - acc: 0.9654 - val_loss: 0.0929 - val_acc: 0.9727\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1026 - acc: 0.9610 - val_loss: 0.1045 - val_acc: 0.9688\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.09287 to 0.09105, saving model to best.model\n",
      "0s - loss: 0.1059 - acc: 0.9608 - val_loss: 0.0911 - val_acc: 0.9708\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.0846 - acc: 0.9713 - val_loss: 0.0979 - val_acc: 0.9698\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0919 - acc: 0.9681 - val_loss: 0.0921 - val_acc: 0.9708\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.09105 to 0.08949, saving model to best.model\n",
      "0s - loss: 0.0898 - acc: 0.9683 - val_loss: 0.0895 - val_acc: 0.9708\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.08949 to 0.08374, saving model to best.model\n",
      "0s - loss: 0.0856 - acc: 0.9683 - val_loss: 0.0837 - val_acc: 0.9708\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.08374 to 0.08035, saving model to best.model\n",
      "0s - loss: 0.0869 - acc: 0.9698 - val_loss: 0.0803 - val_acc: 0.9727\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0878 - acc: 0.9676 - val_loss: 0.0808 - val_acc: 0.9727\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0808 - acc: 0.9720 - val_loss: 0.0809 - val_acc: 0.9727\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.08035 to 0.07487, saving model to best.model\n",
      "0s - loss: 0.0839 - acc: 0.9691 - val_loss: 0.0749 - val_acc: 0.9776\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0747 - acc: 0.9720 - val_loss: 0.0792 - val_acc: 0.9747\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0731 - acc: 0.9725 - val_loss: 0.0826 - val_acc: 0.9737\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0790 - acc: 0.9718 - val_loss: 0.0808 - val_acc: 0.9737\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0712 - acc: 0.9759 - val_loss: 0.0784 - val_acc: 0.9737\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0832 - val_acc: 0.9718\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0730 - acc: 0.9725 - val_loss: 0.0791 - val_acc: 0.9757\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.07487 to 0.06567, saving model to best.model\n",
      "0s - loss: 0.0728 - acc: 0.9735 - val_loss: 0.0657 - val_acc: 0.9776\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0710 - acc: 0.9744 - val_loss: 0.0696 - val_acc: 0.9776\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0642 - acc: 0.9783 - val_loss: 0.0680 - val_acc: 0.9786\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0632 - acc: 0.9778 - val_loss: 0.0735 - val_acc: 0.9757\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0645 - acc: 0.9771 - val_loss: 0.0728 - val_acc: 0.9757\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0642 - acc: 0.9781 - val_loss: 0.0672 - val_acc: 0.9786\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0590 - acc: 0.9798 - val_loss: 0.0742 - val_acc: 0.9786\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.06567 to 0.06353, saving model to best.model\n",
      "0s - loss: 0.0594 - acc: 0.9781 - val_loss: 0.0635 - val_acc: 0.9805\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0698 - acc: 0.9749 - val_loss: 0.0655 - val_acc: 0.9796\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0629 - acc: 0.9771 - val_loss: 0.0760 - val_acc: 0.9786\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.06353 to 0.06008, saving model to best.model\n",
      "0s - loss: 0.0620 - acc: 0.9781 - val_loss: 0.0601 - val_acc: 0.9796\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0622 - acc: 0.9803 - val_loss: 0.0667 - val_acc: 0.9786\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9805 - val_loss: 0.0658 - val_acc: 0.9786\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0608 - acc: 0.9795 - val_loss: 0.0633 - val_acc: 0.9796\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.06008 to 0.05863, saving model to best.model\n",
      "0s - loss: 0.0575 - acc: 0.9791 - val_loss: 0.0586 - val_acc: 0.9825\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0614 - acc: 0.9771 - val_loss: 0.0689 - val_acc: 0.9786\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.05863 to 0.05713, saving model to best.model\n",
      "0s - loss: 0.0591 - acc: 0.9781 - val_loss: 0.0571 - val_acc: 0.9815\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.05713 to 0.05555, saving model to best.model\n",
      "0s - loss: 0.0576 - acc: 0.9803 - val_loss: 0.0556 - val_acc: 0.9825\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9805 - val_loss: 0.0598 - val_acc: 0.9786\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0504 - acc: 0.9803 - val_loss: 0.0580 - val_acc: 0.9786\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9813 - val_loss: 0.0640 - val_acc: 0.9796\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0552 - acc: 0.9805 - val_loss: 0.0582 - val_acc: 0.9834\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0601 - acc: 0.9788 - val_loss: 0.0623 - val_acc: 0.9796\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9820 - val_loss: 0.0579 - val_acc: 0.9825\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.05555 to 0.05394, saving model to best.model\n",
      "0s - loss: 0.0561 - acc: 0.9817 - val_loss: 0.0539 - val_acc: 0.9834\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9832 - val_loss: 0.0606 - val_acc: 0.9805\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9839 - val_loss: 0.0593 - val_acc: 0.9805\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9839 - val_loss: 0.0590 - val_acc: 0.9805\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0485 - acc: 0.9832 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9822 - val_loss: 0.0582 - val_acc: 0.9805\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.05394 to 0.05323, saving model to best.model\n",
      "0s - loss: 0.0550 - acc: 0.9817 - val_loss: 0.0532 - val_acc: 0.9815\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.05323 to 0.04609, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9776 - val_loss: 0.0461 - val_acc: 0.9834\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0480 - acc: 0.9827 - val_loss: 0.0571 - val_acc: 0.9805\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9827 - val_loss: 0.0513 - val_acc: 0.9834\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9854 - val_loss: 0.0517 - val_acc: 0.9805\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0520 - val_acc: 0.9805\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9832 - val_loss: 0.0487 - val_acc: 0.9834\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9859 - val_loss: 0.0498 - val_acc: 0.9834\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0489 - acc: 0.9830 - val_loss: 0.0521 - val_acc: 0.9834\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9830 - val_loss: 0.0537 - val_acc: 0.9825\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9866 - val_loss: 0.0531 - val_acc: 0.9825\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9820 - val_loss: 0.0584 - val_acc: 0.9796\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9830 - val_loss: 0.0526 - val_acc: 0.9834\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9847 - val_loss: 0.0511 - val_acc: 0.9834\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9876 - val_loss: 0.0541 - val_acc: 0.9825\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9873 - val_loss: 0.0522 - val_acc: 0.9834\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9827 - val_loss: 0.0531 - val_acc: 0.9834\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9861 - val_loss: 0.0515 - val_acc: 0.9825\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9851 - val_loss: 0.0530 - val_acc: 0.9815\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9851 - val_loss: 0.0465 - val_acc: 0.9825\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9869 - val_loss: 0.0516 - val_acc: 0.9825\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.04609 to 0.04434, saving model to best.model\n",
      "0s - loss: 0.0413 - acc: 0.9844 - val_loss: 0.0443 - val_acc: 0.9844\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0440 - acc: 0.9827 - val_loss: 0.0626 - val_acc: 0.9805\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9849 - val_loss: 0.0446 - val_acc: 0.9844\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9830 - val_loss: 0.0570 - val_acc: 0.9815\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9895 - val_loss: 0.0473 - val_acc: 0.9834\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9881 - val_loss: 0.0516 - val_acc: 0.9825\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9849 - val_loss: 0.0470 - val_acc: 0.9834\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9861 - val_loss: 0.0478 - val_acc: 0.9825\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9878 - val_loss: 0.0482 - val_acc: 0.9815\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9842 - val_loss: 0.0454 - val_acc: 0.9825\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0435 - acc: 0.9847 - val_loss: 0.0531 - val_acc: 0.9815\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9878 - val_loss: 0.0514 - val_acc: 0.9815\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.04434 to 0.03476, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9866 - val_loss: 0.0348 - val_acc: 0.9854\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.0358 - val_acc: 0.9854\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9844 - val_loss: 0.0522 - val_acc: 0.9825\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9854 - val_loss: 0.0440 - val_acc: 0.9844\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9864 - val_loss: 0.0531 - val_acc: 0.9825\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9876 - val_loss: 0.0465 - val_acc: 0.9834\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9864 - val_loss: 0.0497 - val_acc: 0.9834\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0278 - acc: 0.9886 - val_loss: 0.0466 - val_acc: 0.9834\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9859 - val_loss: 0.0438 - val_acc: 0.9844\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0489 - val_acc: 0.9834\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9893 - val_loss: 0.0479 - val_acc: 0.9834\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9883 - val_loss: 0.0469 - val_acc: 0.9834\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9873 - val_loss: 0.0467 - val_acc: 0.9834\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9856 - val_loss: 0.0424 - val_acc: 0.9834\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9881 - val_loss: 0.0493 - val_acc: 0.9825\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9893 - val_loss: 0.0439 - val_acc: 0.9834\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9886 - val_loss: 0.0388 - val_acc: 0.9844\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9898 - val_loss: 0.0423 - val_acc: 0.9834\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9873 - val_loss: 0.0437 - val_acc: 0.9834\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9854 - val_loss: 0.0393 - val_acc: 0.9834\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9903 - val_loss: 0.0456 - val_acc: 0.9834\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0246 - acc: 0.9895 - val_loss: 0.0352 - val_acc: 0.9854\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9890 - val_loss: 0.0458 - val_acc: 0.9844\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9890 - val_loss: 0.0380 - val_acc: 0.9844\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9893 - val_loss: 0.0378 - val_acc: 0.9834\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9878 - val_loss: 0.0383 - val_acc: 0.9834\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9893 - val_loss: 0.0372 - val_acc: 0.9844\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66395, saving model to best.model\n",
      "0s - loss: 0.7946 - acc: 0.5040 - val_loss: 0.6639 - val_acc: 0.7176\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66395 to 0.63151, saving model to best.model\n",
      "0s - loss: 0.7436 - acc: 0.5291 - val_loss: 0.6315 - val_acc: 0.7984\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63151 to 0.57517, saving model to best.model\n",
      "0s - loss: 0.6803 - acc: 0.5810 - val_loss: 0.5752 - val_acc: 0.8092\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.57517 to 0.51139, saving model to best.model\n",
      "0s - loss: 0.6089 - acc: 0.6623 - val_loss: 0.5114 - val_acc: 0.7965\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51139 to 0.42786, saving model to best.model\n",
      "0s - loss: 0.5549 - acc: 0.7263 - val_loss: 0.4279 - val_acc: 0.8238\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.42786 to 0.38608, saving model to best.model\n",
      "0s - loss: 0.4858 - acc: 0.7799 - val_loss: 0.3861 - val_acc: 0.8364\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.38608 to 0.35416, saving model to best.model\n",
      "0s - loss: 0.4469 - acc: 0.8132 - val_loss: 0.3542 - val_acc: 0.8559\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35416 to 0.33218, saving model to best.model\n",
      "0s - loss: 0.4179 - acc: 0.8281 - val_loss: 0.3322 - val_acc: 0.8676\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33218 to 0.31593, saving model to best.model\n",
      "0s - loss: 0.3946 - acc: 0.8437 - val_loss: 0.3159 - val_acc: 0.8734\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31593 to 0.29524, saving model to best.model\n",
      "0s - loss: 0.3770 - acc: 0.8539 - val_loss: 0.2952 - val_acc: 0.8812\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29524 to 0.29146, saving model to best.model\n",
      "0s - loss: 0.3707 - acc: 0.8539 - val_loss: 0.2915 - val_acc: 0.8861\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29146 to 0.28721, saving model to best.model\n",
      "0s - loss: 0.3481 - acc: 0.8612 - val_loss: 0.2872 - val_acc: 0.8841\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28721 to 0.26100, saving model to best.model\n",
      "0s - loss: 0.3332 - acc: 0.8763 - val_loss: 0.2610 - val_acc: 0.8968\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26100 to 0.25499, saving model to best.model\n",
      "0s - loss: 0.3295 - acc: 0.8756 - val_loss: 0.2550 - val_acc: 0.9017\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25499 to 0.24759, saving model to best.model\n",
      "0s - loss: 0.3119 - acc: 0.8824 - val_loss: 0.2476 - val_acc: 0.9085\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2916 - acc: 0.8951 - val_loss: 0.2490 - val_acc: 0.9075\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24759 to 0.23190, saving model to best.model\n",
      "0s - loss: 0.2893 - acc: 0.8972 - val_loss: 0.2319 - val_acc: 0.9133\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2896 - acc: 0.8897 - val_loss: 0.2384 - val_acc: 0.9094\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23190 to 0.22903, saving model to best.model\n",
      "0s - loss: 0.2786 - acc: 0.8987 - val_loss: 0.2290 - val_acc: 0.9104\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22903 to 0.21917, saving model to best.model\n",
      "0s - loss: 0.2852 - acc: 0.8972 - val_loss: 0.2192 - val_acc: 0.9192\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.21917 to 0.21780, saving model to best.model\n",
      "0s - loss: 0.2732 - acc: 0.9028 - val_loss: 0.2178 - val_acc: 0.9153\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21780 to 0.21489, saving model to best.model\n",
      "0s - loss: 0.2645 - acc: 0.9043 - val_loss: 0.2149 - val_acc: 0.9163\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2611 - acc: 0.9067 - val_loss: 0.2172 - val_acc: 0.9153\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21489 to 0.20522, saving model to best.model\n",
      "0s - loss: 0.2558 - acc: 0.9084 - val_loss: 0.2052 - val_acc: 0.9260\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2564 - acc: 0.9109 - val_loss: 0.2093 - val_acc: 0.9192\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20522 to 0.19897, saving model to best.model\n",
      "0s - loss: 0.2499 - acc: 0.9136 - val_loss: 0.1990 - val_acc: 0.9299\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19897 to 0.19635, saving model to best.model\n",
      "0s - loss: 0.2387 - acc: 0.9145 - val_loss: 0.1963 - val_acc: 0.9309\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2422 - acc: 0.9111 - val_loss: 0.2047 - val_acc: 0.9163\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19635 to 0.19018, saving model to best.model\n",
      "0s - loss: 0.2423 - acc: 0.9126 - val_loss: 0.1902 - val_acc: 0.9328\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19018 to 0.18979, saving model to best.model\n",
      "0s - loss: 0.2398 - acc: 0.9155 - val_loss: 0.1898 - val_acc: 0.9309\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18979 to 0.18746, saving model to best.model\n",
      "0s - loss: 0.2324 - acc: 0.9175 - val_loss: 0.1875 - val_acc: 0.9309\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18746 to 0.17984, saving model to best.model\n",
      "0s - loss: 0.2347 - acc: 0.9162 - val_loss: 0.1798 - val_acc: 0.9338\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2310 - acc: 0.9194 - val_loss: 0.1872 - val_acc: 0.9270\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17984 to 0.17648, saving model to best.model\n",
      "0s - loss: 0.2281 - acc: 0.9199 - val_loss: 0.1765 - val_acc: 0.9387\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17648 to 0.17315, saving model to best.model\n",
      "0s - loss: 0.2281 - acc: 0.9177 - val_loss: 0.1731 - val_acc: 0.9377\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17315 to 0.17013, saving model to best.model\n",
      "0s - loss: 0.2180 - acc: 0.9214 - val_loss: 0.1701 - val_acc: 0.9367\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17013 to 0.16998, saving model to best.model\n",
      "0s - loss: 0.2160 - acc: 0.9196 - val_loss: 0.1700 - val_acc: 0.9338\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16998 to 0.16203, saving model to best.model\n",
      "0s - loss: 0.2085 - acc: 0.9226 - val_loss: 0.1620 - val_acc: 0.9367\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16203 to 0.15815, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9238 - val_loss: 0.1581 - val_acc: 0.9396\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.2054 - acc: 0.9260 - val_loss: 0.1597 - val_acc: 0.9357\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15815 to 0.15742, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9211 - val_loss: 0.1574 - val_acc: 0.9357\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15742 to 0.15083, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9250 - val_loss: 0.1508 - val_acc: 0.9328\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15083 to 0.14695, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9260 - val_loss: 0.1469 - val_acc: 0.9338\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1856 - acc: 0.9304 - val_loss: 0.1478 - val_acc: 0.9348\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14695 to 0.13740, saving model to best.model\n",
      "0s - loss: 0.1918 - acc: 0.9279 - val_loss: 0.1374 - val_acc: 0.9484\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1814 - acc: 0.9294 - val_loss: 0.1382 - val_acc: 0.9357\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13740 to 0.13203, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9313 - val_loss: 0.1320 - val_acc: 0.9426\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13203 to 0.12973, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9323 - val_loss: 0.1297 - val_acc: 0.9464\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12973 to 0.12864, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9357 - val_loss: 0.1286 - val_acc: 0.9367\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12864 to 0.12582, saving model to best.model\n",
      "0s - loss: 0.1723 - acc: 0.9350 - val_loss: 0.1258 - val_acc: 0.9377\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.12582 to 0.11953, saving model to best.model\n",
      "0s - loss: 0.1667 - acc: 0.9347 - val_loss: 0.1195 - val_acc: 0.9484\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11953 to 0.11541, saving model to best.model\n",
      "0s - loss: 0.1604 - acc: 0.9391 - val_loss: 0.1154 - val_acc: 0.9494\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11541 to 0.11218, saving model to best.model\n",
      "0s - loss: 0.1587 - acc: 0.9418 - val_loss: 0.1122 - val_acc: 0.9611\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11218 to 0.10829, saving model to best.model\n",
      "0s - loss: 0.1554 - acc: 0.9403 - val_loss: 0.1083 - val_acc: 0.9630\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10829 to 0.10573, saving model to best.model\n",
      "0s - loss: 0.1587 - acc: 0.9384 - val_loss: 0.1057 - val_acc: 0.9649\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1540 - acc: 0.9394 - val_loss: 0.1094 - val_acc: 0.9474\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10573 to 0.10195, saving model to best.model\n",
      "0s - loss: 0.1535 - acc: 0.9386 - val_loss: 0.1019 - val_acc: 0.9640\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10195 to 0.10042, saving model to best.model\n",
      "0s - loss: 0.1531 - acc: 0.9406 - val_loss: 0.1004 - val_acc: 0.9659\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1434 - acc: 0.9450 - val_loss: 0.1025 - val_acc: 0.9494\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.10042 to 0.09684, saving model to best.model\n",
      "0s - loss: 0.1455 - acc: 0.9413 - val_loss: 0.0968 - val_acc: 0.9601\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09684 to 0.09285, saving model to best.model\n",
      "0s - loss: 0.1379 - acc: 0.9450 - val_loss: 0.0929 - val_acc: 0.9727\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.09285 to 0.09144, saving model to best.model\n",
      "0s - loss: 0.1405 - acc: 0.9447 - val_loss: 0.0914 - val_acc: 0.9649\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.09144 to 0.08866, saving model to best.model\n",
      "0s - loss: 0.1411 - acc: 0.9452 - val_loss: 0.0887 - val_acc: 0.9669\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08866 to 0.08601, saving model to best.model\n",
      "0s - loss: 0.1336 - acc: 0.9496 - val_loss: 0.0860 - val_acc: 0.9630\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08601 to 0.08248, saving model to best.model\n",
      "0s - loss: 0.1314 - acc: 0.9486 - val_loss: 0.0825 - val_acc: 0.9747\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1369 - acc: 0.9481 - val_loss: 0.0869 - val_acc: 0.9611\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.08248 to 0.07892, saving model to best.model\n",
      "0s - loss: 0.1304 - acc: 0.9496 - val_loss: 0.0789 - val_acc: 0.9737\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07892 to 0.07583, saving model to best.model\n",
      "0s - loss: 0.1163 - acc: 0.9579 - val_loss: 0.0758 - val_acc: 0.9747\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1208 - acc: 0.9528 - val_loss: 0.0768 - val_acc: 0.9708\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07583 to 0.07229, saving model to best.model\n",
      "0s - loss: 0.1259 - acc: 0.9535 - val_loss: 0.0723 - val_acc: 0.9747\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1158 - acc: 0.9574 - val_loss: 0.0760 - val_acc: 0.9698\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07229 to 0.06777, saving model to best.model\n",
      "0s - loss: 0.1066 - acc: 0.9581 - val_loss: 0.0678 - val_acc: 0.9747\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06777 to 0.06622, saving model to best.model\n",
      "0s - loss: 0.1168 - acc: 0.9584 - val_loss: 0.0662 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06622 to 0.06585, saving model to best.model\n",
      "0s - loss: 0.1178 - acc: 0.9533 - val_loss: 0.0659 - val_acc: 0.9766\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06585 to 0.06365, saving model to best.model\n",
      "0s - loss: 0.1099 - acc: 0.9552 - val_loss: 0.0636 - val_acc: 0.9747\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06365 to 0.06312, saving model to best.model\n",
      "0s - loss: 0.1159 - acc: 0.9569 - val_loss: 0.0631 - val_acc: 0.9766\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1075 - acc: 0.9581 - val_loss: 0.0652 - val_acc: 0.9786\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06312 to 0.06042, saving model to best.model\n",
      "0s - loss: 0.1026 - acc: 0.9608 - val_loss: 0.0604 - val_acc: 0.9786\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06042 to 0.05906, saving model to best.model\n",
      "0s - loss: 0.1059 - acc: 0.9579 - val_loss: 0.0591 - val_acc: 0.9766\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05906 to 0.05809, saving model to best.model\n",
      "0s - loss: 0.1026 - acc: 0.9589 - val_loss: 0.0581 - val_acc: 0.9815\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05809 to 0.05351, saving model to best.model\n",
      "0s - loss: 0.1086 - acc: 0.9574 - val_loss: 0.0535 - val_acc: 0.9766\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0994 - acc: 0.9593 - val_loss: 0.0538 - val_acc: 0.9825\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05351 to 0.05095, saving model to best.model\n",
      "0s - loss: 0.0947 - acc: 0.9608 - val_loss: 0.0509 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05095 to 0.05030, saving model to best.model\n",
      "0s - loss: 0.0907 - acc: 0.9674 - val_loss: 0.0503 - val_acc: 0.9854\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05030 to 0.04789, saving model to best.model\n",
      "0s - loss: 0.0972 - acc: 0.9642 - val_loss: 0.0479 - val_acc: 0.9834\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04789 to 0.04623, saving model to best.model\n",
      "0s - loss: 0.0894 - acc: 0.9664 - val_loss: 0.0462 - val_acc: 0.9834\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04623 to 0.04586, saving model to best.model\n",
      "0s - loss: 0.0947 - acc: 0.9632 - val_loss: 0.0459 - val_acc: 0.9834\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04586 to 0.04430, saving model to best.model\n",
      "0s - loss: 0.0849 - acc: 0.9688 - val_loss: 0.0443 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0917 - acc: 0.9654 - val_loss: 0.0448 - val_acc: 0.9883\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0871 - acc: 0.9676 - val_loss: 0.0448 - val_acc: 0.9854\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04430 to 0.04216, saving model to best.model\n",
      "0s - loss: 0.0933 - acc: 0.9649 - val_loss: 0.0422 - val_acc: 0.9873\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04216 to 0.03849, saving model to best.model\n",
      "0s - loss: 0.0812 - acc: 0.9686 - val_loss: 0.0385 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03849 to 0.03765, saving model to best.model\n",
      "0s - loss: 0.0806 - acc: 0.9705 - val_loss: 0.0377 - val_acc: 0.9873\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.03765 to 0.03602, saving model to best.model\n",
      "0s - loss: 0.0836 - acc: 0.9703 - val_loss: 0.0360 - val_acc: 0.9873\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0812 - acc: 0.9681 - val_loss: 0.0374 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0855 - acc: 0.9676 - val_loss: 0.0384 - val_acc: 0.9883\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.03602 to 0.03401, saving model to best.model\n",
      "0s - loss: 0.0772 - acc: 0.9693 - val_loss: 0.0340 - val_acc: 0.9873\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0737 - acc: 0.9686 - val_loss: 0.0392 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03401 to 0.03359, saving model to best.model\n",
      "0s - loss: 0.0800 - acc: 0.9676 - val_loss: 0.0336 - val_acc: 0.9903\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03359 to 0.03130, saving model to best.model\n",
      "0s - loss: 0.0768 - acc: 0.9710 - val_loss: 0.0313 - val_acc: 0.9903\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0725 - acc: 0.9722 - val_loss: 0.0346 - val_acc: 0.9893\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03130 to 0.03036, saving model to best.model\n",
      "0s - loss: 0.0730 - acc: 0.9759 - val_loss: 0.0304 - val_acc: 0.9903\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0729 - acc: 0.9708 - val_loss: 0.0318 - val_acc: 0.9903\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0690 - acc: 0.9747 - val_loss: 0.0326 - val_acc: 0.9903\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03036 to 0.02714, saving model to best.model\n",
      "0s - loss: 0.0721 - acc: 0.9718 - val_loss: 0.0271 - val_acc: 0.9903\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0719 - acc: 0.9720 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0683 - acc: 0.9720 - val_loss: 0.0285 - val_acc: 0.9903\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.02714 to 0.02679, saving model to best.model\n",
      "0s - loss: 0.0698 - acc: 0.9710 - val_loss: 0.0268 - val_acc: 0.9903\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0658 - acc: 0.9749 - val_loss: 0.0330 - val_acc: 0.9903\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.02679 to 0.02484, saving model to best.model\n",
      "0s - loss: 0.0677 - acc: 0.9759 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0674 - acc: 0.9725 - val_loss: 0.0275 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02484 to 0.02447, saving model to best.model\n",
      "0s - loss: 0.0611 - acc: 0.9766 - val_loss: 0.0245 - val_acc: 0.9922\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0635 - acc: 0.9749 - val_loss: 0.0274 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02447 to 0.02173, saving model to best.model\n",
      "0s - loss: 0.0584 - acc: 0.9774 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02173 to 0.02164, saving model to best.model\n",
      "0s - loss: 0.0587 - acc: 0.9793 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02164 to 0.02055, saving model to best.model\n",
      "0s - loss: 0.0553 - acc: 0.9766 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0611 - acc: 0.9783 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0615 - acc: 0.9766 - val_loss: 0.0263 - val_acc: 0.9903\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0637 - acc: 0.9744 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0587 - acc: 0.9774 - val_loss: 0.0223 - val_acc: 0.9922\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9781 - val_loss: 0.0229 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0536 - acc: 0.9793 - val_loss: 0.0234 - val_acc: 0.9912\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02055 to 0.01793, saving model to best.model\n",
      "0s - loss: 0.0528 - acc: 0.9805 - val_loss: 0.0179 - val_acc: 0.9942\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0551 - acc: 0.9803 - val_loss: 0.0193 - val_acc: 0.9922\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.01793 to 0.01728, saving model to best.model\n",
      "0s - loss: 0.0561 - acc: 0.9791 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0520 - acc: 0.9793 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9800 - val_loss: 0.0222 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0585 - acc: 0.9769 - val_loss: 0.0176 - val_acc: 0.9922\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9810 - val_loss: 0.0174 - val_acc: 0.9922\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0510 - acc: 0.9803 - val_loss: 0.0180 - val_acc: 0.9922\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01728 to 0.01609, saving model to best.model\n",
      "0s - loss: 0.0497 - acc: 0.9805 - val_loss: 0.0161 - val_acc: 0.9922\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9825 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01609 to 0.01588, saving model to best.model\n",
      "0s - loss: 0.0549 - acc: 0.9817 - val_loss: 0.0159 - val_acc: 0.9951\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9817 - val_loss: 0.0195 - val_acc: 0.9912\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.01588 to 0.01505, saving model to best.model\n",
      "0s - loss: 0.0474 - acc: 0.9815 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0505 - acc: 0.9805 - val_loss: 0.0151 - val_acc: 0.9922\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01505 to 0.01455, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9798 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9839 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0460 - acc: 0.9793 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01455 to 0.01249, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9817 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9803 - val_loss: 0.0151 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9844 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9830 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9873 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9815 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01249 to 0.01164, saving model to best.model\n",
      "0s - loss: 0.0399 - acc: 0.9844 - val_loss: 0.0116 - val_acc: 0.9971\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9813 - val_loss: 0.0205 - val_acc: 0.9912\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9820 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9849 - val_loss: 0.0156 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01164 to 0.01155, saving model to best.model\n",
      "0s - loss: 0.0450 - acc: 0.9837 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9815 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01155 to 0.01127, saving model to best.model\n",
      "0s - loss: 0.0381 - acc: 0.9883 - val_loss: 0.0113 - val_acc: 0.9971\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9864 - val_loss: 0.0131 - val_acc: 0.9951\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9834 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01127 to 0.01110, saving model to best.model\n",
      "0s - loss: 0.0437 - acc: 0.9817 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9844 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9847 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01110 to 0.00984, saving model to best.model\n",
      "0s - loss: 0.0404 - acc: 0.9847 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9844 - val_loss: 0.0119 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.00984 to 0.00874, saving model to best.model\n",
      "0s - loss: 0.0355 - acc: 0.9849 - val_loss: 0.0087 - val_acc: 0.9981\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9844 - val_loss: 0.0121 - val_acc: 0.9932\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9866 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9888 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9861 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9881 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0434 - acc: 0.9844 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9854 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9866 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9886 - val_loss: 0.0096 - val_acc: 0.9971\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9851 - val_loss: 0.0095 - val_acc: 0.9961\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9864 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9886 - val_loss: 0.0089 - val_acc: 0.9971\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.00874 to 0.00798, saving model to best.model\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.00798 to 0.00786, saving model to best.model\n",
      "0s - loss: 0.0300 - acc: 0.9881 - val_loss: 0.0079 - val_acc: 0.9971\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.00786 to 0.00783, saving model to best.model\n",
      "0s - loss: 0.0355 - acc: 0.9883 - val_loss: 0.0078 - val_acc: 0.9971\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.00783 to 0.00698, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9886 - val_loss: 0.0070 - val_acc: 0.9990\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9866 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.00698 to 0.00577, saving model to best.model\n",
      "0s - loss: 0.0332 - acc: 0.9859 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9893 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9890 - val_loss: 0.0064 - val_acc: 0.9990\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9866 - val_loss: 0.0078 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9871 - val_loss: 0.0077 - val_acc: 0.9961\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9890 - val_loss: 0.0071 - val_acc: 0.9981\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0255 - acc: 0.9890 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.00577 to 0.00500, saving model to best.model\n",
      "0s - loss: 0.0300 - acc: 0.9895 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9881 - val_loss: 0.0078 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9883 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9861 - val_loss: 0.0072 - val_acc: 0.9981\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9886 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9886 - val_loss: 0.0056 - val_acc: 0.9990\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9881 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00500 to 0.00493, saving model to best.model\n",
      "0s - loss: 0.0257 - acc: 0.9890 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0266 - acc: 0.9900 - val_loss: 0.0057 - val_acc: 0.9990\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0060 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9893 - val_loss: 0.0057 - val_acc: 0.9990\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0240 - acc: 0.9912 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0217 - acc: 0.9912 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00493 to 0.00467, saving model to best.model\n",
      "0s - loss: 0.0273 - acc: 0.9886 - val_loss: 0.0047 - val_acc: 0.9990\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.69123, saving model to best.model\n",
      "0s - loss: 0.8615 - acc: 0.5011 - val_loss: 0.6912 - val_acc: 0.4869\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.69123 to 0.66722, saving model to best.model\n",
      "0s - loss: 0.7901 - acc: 0.5162 - val_loss: 0.6672 - val_acc: 0.5131\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66722 to 0.62702, saving model to best.model\n",
      "0s - loss: 0.7456 - acc: 0.5310 - val_loss: 0.6270 - val_acc: 0.7371\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.62702 to 0.57835, saving model to best.model\n",
      "0s - loss: 0.6868 - acc: 0.5890 - val_loss: 0.5784 - val_acc: 0.7877\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.57835 to 0.51376, saving model to best.model\n",
      "0s - loss: 0.6324 - acc: 0.6460 - val_loss: 0.5138 - val_acc: 0.7945\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.51376 to 0.46152, saving model to best.model\n",
      "0s - loss: 0.5718 - acc: 0.7137 - val_loss: 0.4615 - val_acc: 0.8150\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.46152 to 0.43372, saving model to best.model\n",
      "0s - loss: 0.5309 - acc: 0.7385 - val_loss: 0.4337 - val_acc: 0.8179\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.43372 to 0.38912, saving model to best.model\n",
      "0s - loss: 0.4826 - acc: 0.7787 - val_loss: 0.3891 - val_acc: 0.8510\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.38912 to 0.36778, saving model to best.model\n",
      "0s - loss: 0.4515 - acc: 0.7957 - val_loss: 0.3678 - val_acc: 0.8608\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.36778 to 0.34583, saving model to best.model\n",
      "0s - loss: 0.4271 - acc: 0.8164 - val_loss: 0.3458 - val_acc: 0.8724\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.34583 to 0.32533, saving model to best.model\n",
      "0s - loss: 0.4066 - acc: 0.8320 - val_loss: 0.3253 - val_acc: 0.8763\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.32533 to 0.30441, saving model to best.model\n",
      "0s - loss: 0.3845 - acc: 0.8400 - val_loss: 0.3044 - val_acc: 0.8763\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.30441 to 0.28841, saving model to best.model\n",
      "0s - loss: 0.3700 - acc: 0.8512 - val_loss: 0.2884 - val_acc: 0.8802\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.28841 to 0.27244, saving model to best.model\n",
      "0s - loss: 0.3552 - acc: 0.8568 - val_loss: 0.2724 - val_acc: 0.8841\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27244 to 0.26209, saving model to best.model\n",
      "0s - loss: 0.3348 - acc: 0.8683 - val_loss: 0.2621 - val_acc: 0.8909\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26209 to 0.25315, saving model to best.model\n",
      "0s - loss: 0.3302 - acc: 0.8678 - val_loss: 0.2531 - val_acc: 0.8997\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25315 to 0.24484, saving model to best.model\n",
      "0s - loss: 0.3204 - acc: 0.8734 - val_loss: 0.2448 - val_acc: 0.9085\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24484 to 0.23861, saving model to best.model\n",
      "0s - loss: 0.3130 - acc: 0.8853 - val_loss: 0.2386 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23861 to 0.23549, saving model to best.model\n",
      "0s - loss: 0.3047 - acc: 0.8865 - val_loss: 0.2355 - val_acc: 0.9124\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23549 to 0.23282, saving model to best.model\n",
      "0s - loss: 0.3014 - acc: 0.8831 - val_loss: 0.2328 - val_acc: 0.9163\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23282 to 0.22523, saving model to best.model\n",
      "0s - loss: 0.2918 - acc: 0.8892 - val_loss: 0.2252 - val_acc: 0.9192\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22523 to 0.21957, saving model to best.model\n",
      "0s - loss: 0.2873 - acc: 0.8875 - val_loss: 0.2196 - val_acc: 0.9241\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2916 - acc: 0.8892 - val_loss: 0.2213 - val_acc: 0.9192\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21957 to 0.21399, saving model to best.model\n",
      "0s - loss: 0.2763 - acc: 0.8987 - val_loss: 0.2140 - val_acc: 0.9221\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21399 to 0.20959, saving model to best.model\n",
      "0s - loss: 0.2686 - acc: 0.9011 - val_loss: 0.2096 - val_acc: 0.9231\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20959 to 0.20480, saving model to best.model\n",
      "0s - loss: 0.2679 - acc: 0.8999 - val_loss: 0.2048 - val_acc: 0.9241\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2616 - acc: 0.9009 - val_loss: 0.2059 - val_acc: 0.9231\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20480 to 0.20070, saving model to best.model\n",
      "0s - loss: 0.2550 - acc: 0.9050 - val_loss: 0.2007 - val_acc: 0.9231\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20070 to 0.19560, saving model to best.model\n",
      "0s - loss: 0.2572 - acc: 0.9097 - val_loss: 0.1956 - val_acc: 0.9241\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19560 to 0.19324, saving model to best.model\n",
      "0s - loss: 0.2447 - acc: 0.9111 - val_loss: 0.1932 - val_acc: 0.9270\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2465 - acc: 0.9123 - val_loss: 0.1997 - val_acc: 0.9153\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19324 to 0.18663, saving model to best.model\n",
      "0s - loss: 0.2433 - acc: 0.9082 - val_loss: 0.1866 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18663 to 0.18119, saving model to best.model\n",
      "0s - loss: 0.2307 - acc: 0.9150 - val_loss: 0.1812 - val_acc: 0.9279\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18119 to 0.17798, saving model to best.model\n",
      "0s - loss: 0.2309 - acc: 0.9150 - val_loss: 0.1780 - val_acc: 0.9299\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17798 to 0.17677, saving model to best.model\n",
      "0s - loss: 0.2266 - acc: 0.9133 - val_loss: 0.1768 - val_acc: 0.9221\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17677 to 0.17043, saving model to best.model\n",
      "0s - loss: 0.2201 - acc: 0.9179 - val_loss: 0.1704 - val_acc: 0.9387\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17043 to 0.16726, saving model to best.model\n",
      "0s - loss: 0.2127 - acc: 0.9196 - val_loss: 0.1673 - val_acc: 0.9279\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16726 to 0.16346, saving model to best.model\n",
      "0s - loss: 0.2105 - acc: 0.9184 - val_loss: 0.1635 - val_acc: 0.9279\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16346 to 0.15848, saving model to best.model\n",
      "0s - loss: 0.2138 - acc: 0.9209 - val_loss: 0.1585 - val_acc: 0.9416\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15848 to 0.15489, saving model to best.model\n",
      "0s - loss: 0.2124 - acc: 0.9209 - val_loss: 0.1549 - val_acc: 0.9318\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15489 to 0.15095, saving model to best.model\n",
      "0s - loss: 0.2036 - acc: 0.9216 - val_loss: 0.1509 - val_acc: 0.9396\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15095 to 0.15029, saving model to best.model\n",
      "0s - loss: 0.1991 - acc: 0.9238 - val_loss: 0.1503 - val_acc: 0.9338\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15029 to 0.14633, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9284 - val_loss: 0.1463 - val_acc: 0.9348\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14633 to 0.14385, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9243 - val_loss: 0.1438 - val_acc: 0.9377\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14385 to 0.14123, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9328 - val_loss: 0.1412 - val_acc: 0.9367\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14123 to 0.13551, saving model to best.model\n",
      "0s - loss: 0.1811 - acc: 0.9357 - val_loss: 0.1355 - val_acc: 0.9464\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1825 - acc: 0.9340 - val_loss: 0.1381 - val_acc: 0.9367\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13551 to 0.12798, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9335 - val_loss: 0.1280 - val_acc: 0.9581\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12798 to 0.12518, saving model to best.model\n",
      "0s - loss: 0.1665 - acc: 0.9408 - val_loss: 0.1252 - val_acc: 0.9591\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12518 to 0.12258, saving model to best.model\n",
      "0s - loss: 0.1671 - acc: 0.9399 - val_loss: 0.1226 - val_acc: 0.9601\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.12258 to 0.12128, saving model to best.model\n",
      "0s - loss: 0.1686 - acc: 0.9364 - val_loss: 0.1213 - val_acc: 0.9601\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12128 to 0.11765, saving model to best.model\n",
      "0s - loss: 0.1576 - acc: 0.9423 - val_loss: 0.1177 - val_acc: 0.9640\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11765 to 0.11623, saving model to best.model\n",
      "0s - loss: 0.1663 - acc: 0.9367 - val_loss: 0.1162 - val_acc: 0.9640\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11623 to 0.11095, saving model to best.model\n",
      "0s - loss: 0.1536 - acc: 0.9462 - val_loss: 0.1110 - val_acc: 0.9611\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.11095 to 0.10713, saving model to best.model\n",
      "0s - loss: 0.1508 - acc: 0.9442 - val_loss: 0.1071 - val_acc: 0.9630\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1612 - acc: 0.9423 - val_loss: 0.1079 - val_acc: 0.9640\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10713 to 0.10153, saving model to best.model\n",
      "0s - loss: 0.1543 - acc: 0.9428 - val_loss: 0.1015 - val_acc: 0.9659\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10153 to 0.09931, saving model to best.model\n",
      "0s - loss: 0.1513 - acc: 0.9423 - val_loss: 0.0993 - val_acc: 0.9649\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09931 to 0.09918, saving model to best.model\n",
      "0s - loss: 0.1492 - acc: 0.9479 - val_loss: 0.0992 - val_acc: 0.9698\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09918 to 0.09630, saving model to best.model\n",
      "0s - loss: 0.1409 - acc: 0.9494 - val_loss: 0.0963 - val_acc: 0.9698\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09630 to 0.09491, saving model to best.model\n",
      "0s - loss: 0.1421 - acc: 0.9491 - val_loss: 0.0949 - val_acc: 0.9688\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.09491 to 0.09340, saving model to best.model\n",
      "0s - loss: 0.1349 - acc: 0.9486 - val_loss: 0.0934 - val_acc: 0.9649\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.09340 to 0.09065, saving model to best.model\n",
      "0s - loss: 0.1319 - acc: 0.9501 - val_loss: 0.0907 - val_acc: 0.9718\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.09065 to 0.08768, saving model to best.model\n",
      "0s - loss: 0.1318 - acc: 0.9528 - val_loss: 0.0877 - val_acc: 0.9659\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08768 to 0.08389, saving model to best.model\n",
      "0s - loss: 0.1238 - acc: 0.9550 - val_loss: 0.0839 - val_acc: 0.9708\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08389 to 0.08181, saving model to best.model\n",
      "0s - loss: 0.1263 - acc: 0.9511 - val_loss: 0.0818 - val_acc: 0.9718\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.08181 to 0.07954, saving model to best.model\n",
      "0s - loss: 0.1211 - acc: 0.9540 - val_loss: 0.0795 - val_acc: 0.9737\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07954 to 0.07645, saving model to best.model\n",
      "0s - loss: 0.1203 - acc: 0.9552 - val_loss: 0.0764 - val_acc: 0.9747\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07645 to 0.07396, saving model to best.model\n",
      "0s - loss: 0.1109 - acc: 0.9601 - val_loss: 0.0740 - val_acc: 0.9757\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07396 to 0.07212, saving model to best.model\n",
      "0s - loss: 0.1148 - acc: 0.9591 - val_loss: 0.0721 - val_acc: 0.9766\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.07212 to 0.06941, saving model to best.model\n",
      "0s - loss: 0.1165 - acc: 0.9569 - val_loss: 0.0694 - val_acc: 0.9776\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06941 to 0.06750, saving model to best.model\n",
      "0s - loss: 0.1177 - acc: 0.9589 - val_loss: 0.0675 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06750 to 0.06744, saving model to best.model\n",
      "0s - loss: 0.1126 - acc: 0.9525 - val_loss: 0.0674 - val_acc: 0.9747\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06744 to 0.06284, saving model to best.model\n",
      "0s - loss: 0.1127 - acc: 0.9545 - val_loss: 0.0628 - val_acc: 0.9786\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1080 - acc: 0.9610 - val_loss: 0.0634 - val_acc: 0.9786\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1178 - acc: 0.9569 - val_loss: 0.0677 - val_acc: 0.9737\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06284 to 0.06090, saving model to best.model\n",
      "0s - loss: 0.1175 - acc: 0.9567 - val_loss: 0.0609 - val_acc: 0.9786\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1040 - acc: 0.9593 - val_loss: 0.0616 - val_acc: 0.9796\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06090 to 0.06003, saving model to best.model\n",
      "0s - loss: 0.1030 - acc: 0.9618 - val_loss: 0.0600 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06003 to 0.05565, saving model to best.model\n",
      "0s - loss: 0.0985 - acc: 0.9620 - val_loss: 0.0557 - val_acc: 0.9786\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05565 to 0.05448, saving model to best.model\n",
      "0s - loss: 0.0996 - acc: 0.9618 - val_loss: 0.0545 - val_acc: 0.9786\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0999 - acc: 0.9625 - val_loss: 0.0547 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05448 to 0.05309, saving model to best.model\n",
      "0s - loss: 0.1048 - acc: 0.9598 - val_loss: 0.0531 - val_acc: 0.9834\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05309 to 0.05074, saving model to best.model\n",
      "0s - loss: 0.0962 - acc: 0.9625 - val_loss: 0.0507 - val_acc: 0.9805\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05074 to 0.04814, saving model to best.model\n",
      "0s - loss: 0.0877 - acc: 0.9671 - val_loss: 0.0481 - val_acc: 0.9834\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04814 to 0.04604, saving model to best.model\n",
      "0s - loss: 0.0964 - acc: 0.9666 - val_loss: 0.0460 - val_acc: 0.9825\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04604 to 0.04488, saving model to best.model\n",
      "0s - loss: 0.0878 - acc: 0.9688 - val_loss: 0.0449 - val_acc: 0.9854\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04488 to 0.04425, saving model to best.model\n",
      "0s - loss: 0.0842 - acc: 0.9666 - val_loss: 0.0442 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04425 to 0.04287, saving model to best.model\n",
      "0s - loss: 0.0868 - acc: 0.9683 - val_loss: 0.0429 - val_acc: 0.9844\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04287 to 0.04120, saving model to best.model\n",
      "0s - loss: 0.0892 - acc: 0.9666 - val_loss: 0.0412 - val_acc: 0.9844\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0912 - acc: 0.9669 - val_loss: 0.0416 - val_acc: 0.9844\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04120 to 0.03748, saving model to best.model\n",
      "0s - loss: 0.0793 - acc: 0.9659 - val_loss: 0.0375 - val_acc: 0.9864\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03748 to 0.03634, saving model to best.model\n",
      "0s - loss: 0.0799 - acc: 0.9693 - val_loss: 0.0363 - val_acc: 0.9883\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.03634 to 0.03603, saving model to best.model\n",
      "0s - loss: 0.0767 - acc: 0.9705 - val_loss: 0.0360 - val_acc: 0.9873\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.03603 to 0.03504, saving model to best.model\n",
      "0s - loss: 0.0730 - acc: 0.9715 - val_loss: 0.0350 - val_acc: 0.9864\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.03504 to 0.03489, saving model to best.model\n",
      "0s - loss: 0.0752 - acc: 0.9715 - val_loss: 0.0349 - val_acc: 0.9854\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.03489 to 0.03255, saving model to best.model\n",
      "0s - loss: 0.0730 - acc: 0.9759 - val_loss: 0.0326 - val_acc: 0.9883\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.03255 to 0.03172, saving model to best.model\n",
      "0s - loss: 0.0723 - acc: 0.9715 - val_loss: 0.0317 - val_acc: 0.9864\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03172 to 0.02935, saving model to best.model\n",
      "0s - loss: 0.0777 - acc: 0.9693 - val_loss: 0.0294 - val_acc: 0.9903\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02935 to 0.02848, saving model to best.model\n",
      "0s - loss: 0.0753 - acc: 0.9737 - val_loss: 0.0285 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0768 - acc: 0.9713 - val_loss: 0.0298 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.02848 to 0.02821, saving model to best.model\n",
      "0s - loss: 0.0719 - acc: 0.9730 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0671 - acc: 0.9749 - val_loss: 0.0297 - val_acc: 0.9883\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0802 - acc: 0.9688 - val_loss: 0.0335 - val_acc: 0.9932\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0693 - acc: 0.9725 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.02821 to 0.02771, saving model to best.model\n",
      "0s - loss: 0.0746 - acc: 0.9708 - val_loss: 0.0277 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.02771 to 0.02639, saving model to best.model\n",
      "0s - loss: 0.0706 - acc: 0.9722 - val_loss: 0.0264 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.02639 to 0.02552, saving model to best.model\n",
      "0s - loss: 0.0678 - acc: 0.9761 - val_loss: 0.0255 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02552 to 0.02357, saving model to best.model\n",
      "0s - loss: 0.0635 - acc: 0.9747 - val_loss: 0.0236 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0683 - acc: 0.9727 - val_loss: 0.0240 - val_acc: 0.9893\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02357 to 0.02269, saving model to best.model\n",
      "0s - loss: 0.0572 - acc: 0.9778 - val_loss: 0.0227 - val_acc: 0.9942\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02269 to 0.02007, saving model to best.model\n",
      "0s - loss: 0.0623 - acc: 0.9786 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9774 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0558 - acc: 0.9771 - val_loss: 0.0206 - val_acc: 0.9893\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02007 to 0.01950, saving model to best.model\n",
      "0s - loss: 0.0519 - acc: 0.9815 - val_loss: 0.0195 - val_acc: 0.9903\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0548 - acc: 0.9793 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.01950 to 0.01913, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9761 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.01913 to 0.01772, saving model to best.model\n",
      "0s - loss: 0.0623 - acc: 0.9764 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0675 - acc: 0.9749 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9774 - val_loss: 0.0185 - val_acc: 0.9903\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.01772 to 0.01557, saving model to best.model\n",
      "0s - loss: 0.0556 - acc: 0.9808 - val_loss: 0.0156 - val_acc: 0.9942\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.01557 to 0.01544, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9808 - val_loss: 0.0154 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0512 - acc: 0.9808 - val_loss: 0.0155 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.01544 to 0.01501, saving model to best.model\n",
      "0s - loss: 0.0540 - acc: 0.9798 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.01501 to 0.01391, saving model to best.model\n",
      "0s - loss: 0.0491 - acc: 0.9825 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.01391 to 0.01376, saving model to best.model\n",
      "0s - loss: 0.0466 - acc: 0.9813 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.01376 to 0.01357, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9805 - val_loss: 0.0136 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0520 - acc: 0.9820 - val_loss: 0.0137 - val_acc: 0.9961\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9803 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9803 - val_loss: 0.0145 - val_acc: 0.9971\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01357 to 0.01326, saving model to best.model\n",
      "0s - loss: 0.0513 - acc: 0.9800 - val_loss: 0.0133 - val_acc: 0.9903\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01326 to 0.01266, saving model to best.model\n",
      "0s - loss: 0.0575 - acc: 0.9795 - val_loss: 0.0127 - val_acc: 0.9971\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01266 to 0.01195, saving model to best.model\n",
      "0s - loss: 0.0441 - acc: 0.9830 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.01195 to 0.01135, saving model to best.model\n",
      "0s - loss: 0.0485 - acc: 0.9817 - val_loss: 0.0114 - val_acc: 0.9971\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9786 - val_loss: 0.0124 - val_acc: 0.9922\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9825 - val_loss: 0.0119 - val_acc: 0.9961\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01135 to 0.01119, saving model to best.model\n",
      "0s - loss: 0.0484 - acc: 0.9813 - val_loss: 0.0112 - val_acc: 0.9961\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.01119 to 0.01037, saving model to best.model\n",
      "0s - loss: 0.0435 - acc: 0.9820 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9851 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9800 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9827 - val_loss: 0.0104 - val_acc: 0.9990\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0478 - acc: 0.9817 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01037 to 0.01011, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9817 - val_loss: 0.0101 - val_acc: 0.9990\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01011 to 0.01004, saving model to best.model\n",
      "0s - loss: 0.0429 - acc: 0.9830 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01004 to 0.00951, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9861 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9822 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.00951 to 0.00916, saving model to best.model\n",
      "0s - loss: 0.0486 - acc: 0.9820 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.00916 to 0.00840, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9822 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.00840 to 0.00829, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9815 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.00829 to 0.00792, saving model to best.model\n",
      "0s - loss: 0.0425 - acc: 0.9861 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9827 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0536 - acc: 0.9788 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9839 - val_loss: 0.0101 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0505 - acc: 0.9810 - val_loss: 0.0089 - val_acc: 0.9971\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9847 - val_loss: 0.0081 - val_acc: 0.9971\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0079 - val_acc: 0.9981\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9859 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.00792 to 0.00713, saving model to best.model\n",
      "0s - loss: 0.0414 - acc: 0.9849 - val_loss: 0.0071 - val_acc: 0.9990\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9834 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.00713 to 0.00663, saving model to best.model\n",
      "0s - loss: 0.0366 - acc: 0.9873 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.00663 to 0.00619, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9849 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.00619 to 0.00615, saving model to best.model\n",
      "0s - loss: 0.0410 - acc: 0.9839 - val_loss: 0.0061 - val_acc: 0.9990\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9856 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9856 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9861 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9866 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.00615 to 0.00607, saving model to best.model\n",
      "0s - loss: 0.0366 - acc: 0.9864 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9871 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.00607 to 0.00590, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9859 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.00590 to 0.00526, saving model to best.model\n",
      "0s - loss: 0.0348 - acc: 0.9873 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9883 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.00526 to 0.00514, saving model to best.model\n",
      "0s - loss: 0.0391 - acc: 0.9861 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9866 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.00514 to 0.00465, saving model to best.model\n",
      "0s - loss: 0.0343 - acc: 0.9871 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.00465 to 0.00399, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9837 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.00399 to 0.00395, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9864 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9864 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9849 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0251 - acc: 0.9917 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9871 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9873 - val_loss: 0.0047 - val_acc: 0.9990\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9876 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9893 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9876 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9890 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00395 to 0.00366, saving model to best.model\n",
      "0s - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.00366 to 0.00365, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9900 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00365 to 0.00363, saving model to best.model\n",
      "0s - loss: 0.0267 - acc: 0.9895 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00363 to 0.00299, saving model to best.model\n",
      "0s - loss: 0.0336 - acc: 0.9886 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9881 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.00299 to 0.00289, saving model to best.model\n",
      "0s - loss: 0.0242 - acc: 0.9893 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9903 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00289 to 0.00286, saving model to best.model\n",
      "0s - loss: 0.0301 - acc: 0.9864 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00286 to 0.00281, saving model to best.model\n",
      "0s - loss: 0.0321 - acc: 0.9888 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0249 - acc: 0.9910 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9861 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9881 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9903 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67767, saving model to best.model\n",
      "0s - loss: 0.8321 - acc: 0.4999 - val_loss: 0.6777 - val_acc: 0.4966\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67767 to 0.65910, saving model to best.model\n",
      "0s - loss: 0.7654 - acc: 0.5247 - val_loss: 0.6591 - val_acc: 0.5034\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65910 to 0.61596, saving model to best.model\n",
      "0s - loss: 0.7090 - acc: 0.5605 - val_loss: 0.6160 - val_acc: 0.7916\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61596 to 0.54858, saving model to best.model\n",
      "0s - loss: 0.6658 - acc: 0.6014 - val_loss: 0.5486 - val_acc: 0.7916\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54858 to 0.47337, saving model to best.model\n",
      "0s - loss: 0.5806 - acc: 0.6886 - val_loss: 0.4734 - val_acc: 0.8179\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47337 to 0.40513, saving model to best.model\n",
      "0s - loss: 0.5095 - acc: 0.7619 - val_loss: 0.4051 - val_acc: 0.8384\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40513 to 0.36396, saving model to best.model\n",
      "0s - loss: 0.4540 - acc: 0.7991 - val_loss: 0.3640 - val_acc: 0.8608\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36396 to 0.34369, saving model to best.model\n",
      "0s - loss: 0.4115 - acc: 0.8327 - val_loss: 0.3437 - val_acc: 0.8666\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34369 to 0.31486, saving model to best.model\n",
      "0s - loss: 0.3833 - acc: 0.8459 - val_loss: 0.3149 - val_acc: 0.8822\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31486 to 0.30915, saving model to best.model\n",
      "0s - loss: 0.3727 - acc: 0.8546 - val_loss: 0.3091 - val_acc: 0.8812\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30915 to 0.28946, saving model to best.model\n",
      "0s - loss: 0.3543 - acc: 0.8615 - val_loss: 0.2895 - val_acc: 0.8841\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28946 to 0.27105, saving model to best.model\n",
      "0s - loss: 0.3341 - acc: 0.8714 - val_loss: 0.2711 - val_acc: 0.8919\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27105 to 0.26386, saving model to best.model\n",
      "0s - loss: 0.3201 - acc: 0.8758 - val_loss: 0.2639 - val_acc: 0.8948\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26386 to 0.25960, saving model to best.model\n",
      "0s - loss: 0.3130 - acc: 0.8775 - val_loss: 0.2596 - val_acc: 0.9036\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25960 to 0.24618, saving model to best.model\n",
      "0s - loss: 0.2986 - acc: 0.8899 - val_loss: 0.2462 - val_acc: 0.9075\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.24618 to 0.24339, saving model to best.model\n",
      "0s - loss: 0.2940 - acc: 0.8865 - val_loss: 0.2434 - val_acc: 0.9094\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.2947 - acc: 0.8882 - val_loss: 0.2536 - val_acc: 0.9065\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24339 to 0.23360, saving model to best.model\n",
      "0s - loss: 0.2777 - acc: 0.8980 - val_loss: 0.2336 - val_acc: 0.9124\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23360 to 0.22789, saving model to best.model\n",
      "0s - loss: 0.2756 - acc: 0.8985 - val_loss: 0.2279 - val_acc: 0.9153\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22789 to 0.22723, saving model to best.model\n",
      "0s - loss: 0.2679 - acc: 0.8955 - val_loss: 0.2272 - val_acc: 0.9143\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22723 to 0.21988, saving model to best.model\n",
      "0s - loss: 0.2567 - acc: 0.9075 - val_loss: 0.2199 - val_acc: 0.9143\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2628 - acc: 0.9038 - val_loss: 0.2261 - val_acc: 0.9124\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21988 to 0.21227, saving model to best.model\n",
      "0s - loss: 0.2530 - acc: 0.9106 - val_loss: 0.2123 - val_acc: 0.9221\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2477 - acc: 0.9070 - val_loss: 0.2159 - val_acc: 0.9133\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21227 to 0.20402, saving model to best.model\n",
      "0s - loss: 0.2379 - acc: 0.9128 - val_loss: 0.2040 - val_acc: 0.9241\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2393 - acc: 0.9114 - val_loss: 0.2044 - val_acc: 0.9211\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2281 - acc: 0.9162 - val_loss: 0.2048 - val_acc: 0.9211\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20402 to 0.19579, saving model to best.model\n",
      "0s - loss: 0.2360 - acc: 0.9158 - val_loss: 0.1958 - val_acc: 0.9231\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2337 - acc: 0.9177 - val_loss: 0.1964 - val_acc: 0.9221\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19579 to 0.18884, saving model to best.model\n",
      "0s - loss: 0.2281 - acc: 0.9162 - val_loss: 0.1888 - val_acc: 0.9270\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2251 - acc: 0.9182 - val_loss: 0.1925 - val_acc: 0.9231\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18884 to 0.18661, saving model to best.model\n",
      "0s - loss: 0.2164 - acc: 0.9260 - val_loss: 0.1866 - val_acc: 0.9250\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18661 to 0.18505, saving model to best.model\n",
      "0s - loss: 0.2141 - acc: 0.9167 - val_loss: 0.1851 - val_acc: 0.9221\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18505 to 0.17986, saving model to best.model\n",
      "0s - loss: 0.2114 - acc: 0.9216 - val_loss: 0.1799 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17986 to 0.17801, saving model to best.model\n",
      "0s - loss: 0.2077 - acc: 0.9272 - val_loss: 0.1780 - val_acc: 0.9270\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17801 to 0.17213, saving model to best.model\n",
      "0s - loss: 0.1997 - acc: 0.9262 - val_loss: 0.1721 - val_acc: 0.9309\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.2072 - acc: 0.9243 - val_loss: 0.1753 - val_acc: 0.9231\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17213 to 0.16813, saving model to best.model\n",
      "0s - loss: 0.2033 - acc: 0.9270 - val_loss: 0.1681 - val_acc: 0.9299\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16813 to 0.16314, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9316 - val_loss: 0.1631 - val_acc: 0.9367\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16314 to 0.16155, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9316 - val_loss: 0.1615 - val_acc: 0.9357\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1989 - acc: 0.9265 - val_loss: 0.1780 - val_acc: 0.9221\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.16155 to 0.15909, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9291 - val_loss: 0.1591 - val_acc: 0.9426\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15909 to 0.15863, saving model to best.model\n",
      "0s - loss: 0.2036 - acc: 0.9296 - val_loss: 0.1586 - val_acc: 0.9289\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15863 to 0.15461, saving model to best.model\n",
      "0s - loss: 0.1835 - acc: 0.9350 - val_loss: 0.1546 - val_acc: 0.9357\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15461 to 0.15054, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9364 - val_loss: 0.1505 - val_acc: 0.9435\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1864 - acc: 0.9340 - val_loss: 0.1540 - val_acc: 0.9328\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15054 to 0.14679, saving model to best.model\n",
      "0s - loss: 0.1768 - acc: 0.9316 - val_loss: 0.1468 - val_acc: 0.9426\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14679 to 0.14395, saving model to best.model\n",
      "0s - loss: 0.1707 - acc: 0.9374 - val_loss: 0.1440 - val_acc: 0.9464\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14395 to 0.14189, saving model to best.model\n",
      "0s - loss: 0.1672 - acc: 0.9403 - val_loss: 0.1419 - val_acc: 0.9455\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1683 - acc: 0.9372 - val_loss: 0.1433 - val_acc: 0.9406\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14189 to 0.13757, saving model to best.model\n",
      "0s - loss: 0.1620 - acc: 0.9408 - val_loss: 0.1376 - val_acc: 0.9533\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13757 to 0.13661, saving model to best.model\n",
      "0s - loss: 0.1598 - acc: 0.9433 - val_loss: 0.1366 - val_acc: 0.9523\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1623 - acc: 0.9438 - val_loss: 0.1387 - val_acc: 0.9455\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13661 to 0.13228, saving model to best.model\n",
      "0s - loss: 0.1597 - acc: 0.9411 - val_loss: 0.1323 - val_acc: 0.9552\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1583 - acc: 0.9450 - val_loss: 0.1345 - val_acc: 0.9542\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13228 to 0.12874, saving model to best.model\n",
      "0s - loss: 0.1553 - acc: 0.9447 - val_loss: 0.1287 - val_acc: 0.9572\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12874 to 0.12745, saving model to best.model\n",
      "0s - loss: 0.1523 - acc: 0.9452 - val_loss: 0.1275 - val_acc: 0.9542\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12745 to 0.12355, saving model to best.model\n",
      "0s - loss: 0.1542 - acc: 0.9428 - val_loss: 0.1235 - val_acc: 0.9611\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1498 - acc: 0.9479 - val_loss: 0.1246 - val_acc: 0.9611\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.12355 to 0.12196, saving model to best.model\n",
      "0s - loss: 0.1452 - acc: 0.9484 - val_loss: 0.1220 - val_acc: 0.9620\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.12196 to 0.11972, saving model to best.model\n",
      "0s - loss: 0.1439 - acc: 0.9472 - val_loss: 0.1197 - val_acc: 0.9620\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.11972 to 0.11723, saving model to best.model\n",
      "0s - loss: 0.1420 - acc: 0.9501 - val_loss: 0.1172 - val_acc: 0.9601\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1467 - acc: 0.9518 - val_loss: 0.1197 - val_acc: 0.9620\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.11723 to 0.11336, saving model to best.model\n",
      "0s - loss: 0.1364 - acc: 0.9472 - val_loss: 0.1134 - val_acc: 0.9601\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.11336 to 0.11275, saving model to best.model\n",
      "0s - loss: 0.1380 - acc: 0.9530 - val_loss: 0.1127 - val_acc: 0.9620\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.11275 to 0.11004, saving model to best.model\n",
      "0s - loss: 0.1279 - acc: 0.9562 - val_loss: 0.1100 - val_acc: 0.9649\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.11004 to 0.10819, saving model to best.model\n",
      "0s - loss: 0.1282 - acc: 0.9525 - val_loss: 0.1082 - val_acc: 0.9649\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1381 - acc: 0.9525 - val_loss: 0.1232 - val_acc: 0.9611\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1289 - acc: 0.9547 - val_loss: 0.1087 - val_acc: 0.9669\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.10819 to 0.10303, saving model to best.model\n",
      "0s - loss: 0.1309 - acc: 0.9525 - val_loss: 0.1030 - val_acc: 0.9679\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.10303 to 0.10272, saving model to best.model\n",
      "0s - loss: 0.1202 - acc: 0.9579 - val_loss: 0.1027 - val_acc: 0.9698\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.10272 to 0.10116, saving model to best.model\n",
      "0s - loss: 0.1238 - acc: 0.9550 - val_loss: 0.1012 - val_acc: 0.9698\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.10116 to 0.09692, saving model to best.model\n",
      "0s - loss: 0.1152 - acc: 0.9596 - val_loss: 0.0969 - val_acc: 0.9698\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1198 - acc: 0.9586 - val_loss: 0.0974 - val_acc: 0.9708\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.09692 to 0.09362, saving model to best.model\n",
      "0s - loss: 0.1145 - acc: 0.9569 - val_loss: 0.0936 - val_acc: 0.9718\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.09362 to 0.08963, saving model to best.model\n",
      "0s - loss: 0.1149 - acc: 0.9589 - val_loss: 0.0896 - val_acc: 0.9727\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.08963 to 0.08626, saving model to best.model\n",
      "0s - loss: 0.1187 - acc: 0.9586 - val_loss: 0.0863 - val_acc: 0.9698\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1163 - acc: 0.9562 - val_loss: 0.0953 - val_acc: 0.9679\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.08626 to 0.08624, saving model to best.model\n",
      "0s - loss: 0.1124 - acc: 0.9608 - val_loss: 0.0862 - val_acc: 0.9708\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.08624 to 0.08170, saving model to best.model\n",
      "0s - loss: 0.1094 - acc: 0.9601 - val_loss: 0.0817 - val_acc: 0.9727\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.08170 to 0.08048, saving model to best.model\n",
      "0s - loss: 0.1031 - acc: 0.9620 - val_loss: 0.0805 - val_acc: 0.9737\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1111 - acc: 0.9627 - val_loss: 0.0829 - val_acc: 0.9718\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.08048 to 0.07599, saving model to best.model\n",
      "0s - loss: 0.0999 - acc: 0.9647 - val_loss: 0.0760 - val_acc: 0.9737\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.07599 to 0.07364, saving model to best.model\n",
      "0s - loss: 0.0978 - acc: 0.9618 - val_loss: 0.0736 - val_acc: 0.9727\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.07364 to 0.06992, saving model to best.model\n",
      "0s - loss: 0.0981 - acc: 0.9620 - val_loss: 0.0699 - val_acc: 0.9727\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0979 - acc: 0.9640 - val_loss: 0.0756 - val_acc: 0.9718\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0988 - acc: 0.9649 - val_loss: 0.0740 - val_acc: 0.9718\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.06992 to 0.06393, saving model to best.model\n",
      "0s - loss: 0.0951 - acc: 0.9635 - val_loss: 0.0639 - val_acc: 0.9747\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.06393 to 0.06280, saving model to best.model\n",
      "0s - loss: 0.0968 - acc: 0.9635 - val_loss: 0.0628 - val_acc: 0.9757\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0845 - acc: 0.9664 - val_loss: 0.0656 - val_acc: 0.9747\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.06280 to 0.06166, saving model to best.model\n",
      "0s - loss: 0.0877 - acc: 0.9674 - val_loss: 0.0617 - val_acc: 0.9757\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.06166 to 0.05979, saving model to best.model\n",
      "0s - loss: 0.0908 - acc: 0.9686 - val_loss: 0.0598 - val_acc: 0.9766\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.05979 to 0.05581, saving model to best.model\n",
      "0s - loss: 0.0962 - acc: 0.9637 - val_loss: 0.0558 - val_acc: 0.9796\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0794 - acc: 0.9713 - val_loss: 0.0564 - val_acc: 0.9796\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.05581 to 0.05285, saving model to best.model\n",
      "0s - loss: 0.0768 - acc: 0.9686 - val_loss: 0.0528 - val_acc: 0.9776\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0840 - acc: 0.9669 - val_loss: 0.0580 - val_acc: 0.9815\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.05285 to 0.04922, saving model to best.model\n",
      "0s - loss: 0.0796 - acc: 0.9720 - val_loss: 0.0492 - val_acc: 0.9796\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0779 - acc: 0.9693 - val_loss: 0.0496 - val_acc: 0.9805\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0809 - acc: 0.9696 - val_loss: 0.0519 - val_acc: 0.9825\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04922 to 0.04916, saving model to best.model\n",
      "0s - loss: 0.0718 - acc: 0.9727 - val_loss: 0.0492 - val_acc: 0.9805\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04916 to 0.04543, saving model to best.model\n",
      "0s - loss: 0.0794 - acc: 0.9710 - val_loss: 0.0454 - val_acc: 0.9796\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0749 - acc: 0.9703 - val_loss: 0.0484 - val_acc: 0.9844\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.04543 to 0.04457, saving model to best.model\n",
      "0s - loss: 0.0771 - acc: 0.9715 - val_loss: 0.0446 - val_acc: 0.9834\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.04457 to 0.04370, saving model to best.model\n",
      "0s - loss: 0.0681 - acc: 0.9757 - val_loss: 0.0437 - val_acc: 0.9825\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0770 - acc: 0.9725 - val_loss: 0.0463 - val_acc: 0.9844\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.04370 to 0.04276, saving model to best.model\n",
      "0s - loss: 0.0750 - acc: 0.9701 - val_loss: 0.0428 - val_acc: 0.9844\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.04276 to 0.04020, saving model to best.model\n",
      "0s - loss: 0.0742 - acc: 0.9749 - val_loss: 0.0402 - val_acc: 0.9825\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0731 - acc: 0.9730 - val_loss: 0.0403 - val_acc: 0.9834\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0700 - acc: 0.9727 - val_loss: 0.0416 - val_acc: 0.9844\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.04020 to 0.03981, saving model to best.model\n",
      "0s - loss: 0.0740 - acc: 0.9718 - val_loss: 0.0398 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0744 - acc: 0.9727 - val_loss: 0.0404 - val_acc: 0.9844\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03981 to 0.03746, saving model to best.model\n",
      "0s - loss: 0.0681 - acc: 0.9737 - val_loss: 0.0375 - val_acc: 0.9864\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0660 - acc: 0.9769 - val_loss: 0.0394 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0629 - acc: 0.9749 - val_loss: 0.0380 - val_acc: 0.9834\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9766 - val_loss: 0.0391 - val_acc: 0.9854\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0674 - acc: 0.9757 - val_loss: 0.0410 - val_acc: 0.9844\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.03746 to 0.03332, saving model to best.model\n",
      "0s - loss: 0.0578 - acc: 0.9791 - val_loss: 0.0333 - val_acc: 0.9825\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0602 - acc: 0.9759 - val_loss: 0.0355 - val_acc: 0.9844\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0558 - acc: 0.9786 - val_loss: 0.0348 - val_acc: 0.9864\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0637 - acc: 0.9742 - val_loss: 0.0339 - val_acc: 0.9844\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9774 - val_loss: 0.0377 - val_acc: 0.9864\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0558 - acc: 0.9808 - val_loss: 0.0367 - val_acc: 0.9864\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.03332 to 0.03264, saving model to best.model\n",
      "0s - loss: 0.0592 - acc: 0.9778 - val_loss: 0.0326 - val_acc: 0.9873\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0667 - acc: 0.9739 - val_loss: 0.0371 - val_acc: 0.9864\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03264 to 0.03215, saving model to best.model\n",
      "0s - loss: 0.0627 - acc: 0.9769 - val_loss: 0.0322 - val_acc: 0.9864\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0608 - acc: 0.9761 - val_loss: 0.0326 - val_acc: 0.9864\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0607 - acc: 0.9776 - val_loss: 0.0349 - val_acc: 0.9864\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.03215 to 0.02921, saving model to best.model\n",
      "0s - loss: 0.0514 - acc: 0.9813 - val_loss: 0.0292 - val_acc: 0.9864\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0547 - acc: 0.9771 - val_loss: 0.0323 - val_acc: 0.9864\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0577 - acc: 0.9800 - val_loss: 0.0296 - val_acc: 0.9873\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9815 - val_loss: 0.0293 - val_acc: 0.9873\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9803 - val_loss: 0.0326 - val_acc: 0.9873\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02921 to 0.02702, saving model to best.model\n",
      "0s - loss: 0.0544 - acc: 0.9808 - val_loss: 0.0270 - val_acc: 0.9883\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9873\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9815 - val_loss: 0.0280 - val_acc: 0.9873\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0272 - val_acc: 0.9873\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02702 to 0.02693, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9798 - val_loss: 0.0269 - val_acc: 0.9873\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0554 - acc: 0.9771 - val_loss: 0.0272 - val_acc: 0.9873\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02693 to 0.02434, saving model to best.model\n",
      "0s - loss: 0.0459 - acc: 0.9827 - val_loss: 0.0243 - val_acc: 0.9873\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0507 - acc: 0.9800 - val_loss: 0.0251 - val_acc: 0.9864\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0499 - acc: 0.9803 - val_loss: 0.0266 - val_acc: 0.9864\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9798 - val_loss: 0.0246 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02434 to 0.02285, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9813 - val_loss: 0.0229 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0454 - acc: 0.9815 - val_loss: 0.0323 - val_acc: 0.9864\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.02285 to 0.02258, saving model to best.model\n",
      "0s - loss: 0.0487 - acc: 0.9849 - val_loss: 0.0226 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9842 - val_loss: 0.0271 - val_acc: 0.9864\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.02258 to 0.02122, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9827 - val_loss: 0.0212 - val_acc: 0.9893\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9847 - val_loss: 0.0279 - val_acc: 0.9873\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9847 - val_loss: 0.0227 - val_acc: 0.9883\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.02122 to 0.01958, saving model to best.model\n",
      "0s - loss: 0.0414 - acc: 0.9847 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9805 - val_loss: 0.0229 - val_acc: 0.9873\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.01958 to 0.01802, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9834 - val_loss: 0.0180 - val_acc: 0.9903\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9856 - val_loss: 0.0188 - val_acc: 0.9893\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9837 - val_loss: 0.0219 - val_acc: 0.9873\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.01802 to 0.01694, saving model to best.model\n",
      "0s - loss: 0.0421 - acc: 0.9827 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9803 - val_loss: 0.0258 - val_acc: 0.9873\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0419 - acc: 0.9842 - val_loss: 0.0197 - val_acc: 0.9922\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9861 - val_loss: 0.0237 - val_acc: 0.9873\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9837 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9822 - val_loss: 0.0228 - val_acc: 0.9873\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9854 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9859 - val_loss: 0.0207 - val_acc: 0.9883\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9873 - val_loss: 0.0175 - val_acc: 0.9932\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9859 - val_loss: 0.0192 - val_acc: 0.9893\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9842 - val_loss: 0.0196 - val_acc: 0.9893\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9873 - val_loss: 0.0199 - val_acc: 0.9893\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9844 - val_loss: 0.0176 - val_acc: 0.9903\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9876 - val_loss: 0.0199 - val_acc: 0.9883\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01694 to 0.01518, saving model to best.model\n",
      "0s - loss: 0.0417 - acc: 0.9847 - val_loss: 0.0152 - val_acc: 0.9922\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9859 - val_loss: 0.0215 - val_acc: 0.9873\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0168 - val_acc: 0.9903\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01518 to 0.01343, saving model to best.model\n",
      "0s - loss: 0.0381 - acc: 0.9851 - val_loss: 0.0134 - val_acc: 0.9961\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9864 - val_loss: 0.0210 - val_acc: 0.9873\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9851 - val_loss: 0.0148 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9839 - val_loss: 0.0248 - val_acc: 0.9864\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01343 to 0.01299, saving model to best.model\n",
      "0s - loss: 0.0385 - acc: 0.9871 - val_loss: 0.0130 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9849 - val_loss: 0.0173 - val_acc: 0.9903\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9871 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9871 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9844 - val_loss: 0.0144 - val_acc: 0.9922\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9856 - val_loss: 0.0156 - val_acc: 0.9903\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9849 - val_loss: 0.0172 - val_acc: 0.9903\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9871 - val_loss: 0.0172 - val_acc: 0.9883\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9886 - val_loss: 0.0135 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9881 - val_loss: 0.0150 - val_acc: 0.9922\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.01299 to 0.01232, saving model to best.model\n",
      "0s - loss: 0.0333 - acc: 0.9883 - val_loss: 0.0123 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9871 - val_loss: 0.0134 - val_acc: 0.9942\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01232 to 0.01186, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9890 - val_loss: 0.0119 - val_acc: 0.9961\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.01186 to 0.01165, saving model to best.model\n",
      "0s - loss: 0.0311 - acc: 0.9861 - val_loss: 0.0116 - val_acc: 0.9961\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9878 - val_loss: 0.0176 - val_acc: 0.9873\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.01165 to 0.01070, saving model to best.model\n",
      "0s - loss: 0.0336 - acc: 0.9895 - val_loss: 0.0107 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9883 - val_loss: 0.0158 - val_acc: 0.9922\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9903 - val_loss: 0.0132 - val_acc: 0.9942\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9859 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0252 - acc: 0.9881 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9873 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9903 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9898 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9881 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67045, saving model to best.model\n",
      "0s - loss: 0.8036 - acc: 0.5125 - val_loss: 0.6705 - val_acc: 0.7050\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67045 to 0.63747, saving model to best.model\n",
      "0s - loss: 0.7418 - acc: 0.5327 - val_loss: 0.6375 - val_acc: 0.7089\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63747 to 0.58771, saving model to best.model\n",
      "0s - loss: 0.6896 - acc: 0.5858 - val_loss: 0.5877 - val_acc: 0.7926\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58771 to 0.51508, saving model to best.model\n",
      "0s - loss: 0.6270 - acc: 0.6511 - val_loss: 0.5151 - val_acc: 0.7975\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51508 to 0.46671, saving model to best.model\n",
      "0s - loss: 0.5622 - acc: 0.7129 - val_loss: 0.4667 - val_acc: 0.8121\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.46671 to 0.40149, saving model to best.model\n",
      "0s - loss: 0.5026 - acc: 0.7616 - val_loss: 0.4015 - val_acc: 0.8286\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40149 to 0.37854, saving model to best.model\n",
      "0s - loss: 0.4584 - acc: 0.7972 - val_loss: 0.3785 - val_acc: 0.8413\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37854 to 0.36580, saving model to best.model\n",
      "0s - loss: 0.4252 - acc: 0.8096 - val_loss: 0.3658 - val_acc: 0.8530\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36580 to 0.33004, saving model to best.model\n",
      "0s - loss: 0.3964 - acc: 0.8335 - val_loss: 0.3300 - val_acc: 0.8676\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33004 to 0.31135, saving model to best.model\n",
      "0s - loss: 0.3736 - acc: 0.8495 - val_loss: 0.3113 - val_acc: 0.8724\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31135 to 0.29898, saving model to best.model\n",
      "0s - loss: 0.3614 - acc: 0.8515 - val_loss: 0.2990 - val_acc: 0.8724\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29898 to 0.29474, saving model to best.model\n",
      "0s - loss: 0.3328 - acc: 0.8644 - val_loss: 0.2947 - val_acc: 0.8832\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29474 to 0.27751, saving model to best.model\n",
      "0s - loss: 0.3215 - acc: 0.8736 - val_loss: 0.2775 - val_acc: 0.8861\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27751 to 0.27215, saving model to best.model\n",
      "0s - loss: 0.3023 - acc: 0.8858 - val_loss: 0.2722 - val_acc: 0.8939\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27215 to 0.26677, saving model to best.model\n",
      "0s - loss: 0.2951 - acc: 0.8907 - val_loss: 0.2668 - val_acc: 0.8978\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26677 to 0.25934, saving model to best.model\n",
      "0s - loss: 0.2791 - acc: 0.8997 - val_loss: 0.2593 - val_acc: 0.9017\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25934 to 0.25387, saving model to best.model\n",
      "0s - loss: 0.2852 - acc: 0.8951 - val_loss: 0.2539 - val_acc: 0.9065\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25387 to 0.24791, saving model to best.model\n",
      "0s - loss: 0.2692 - acc: 0.9046 - val_loss: 0.2479 - val_acc: 0.9094\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.2659 - acc: 0.9007 - val_loss: 0.2484 - val_acc: 0.9056\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24791 to 0.24200, saving model to best.model\n",
      "0s - loss: 0.2707 - acc: 0.9024 - val_loss: 0.2420 - val_acc: 0.9104\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2514 - acc: 0.9097 - val_loss: 0.2436 - val_acc: 0.9075\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.24200 to 0.23462, saving model to best.model\n",
      "0s - loss: 0.2475 - acc: 0.9131 - val_loss: 0.2346 - val_acc: 0.9133\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23462 to 0.23187, saving model to best.model\n",
      "0s - loss: 0.2437 - acc: 0.9106 - val_loss: 0.2319 - val_acc: 0.9143\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2455 - acc: 0.9133 - val_loss: 0.2351 - val_acc: 0.9085\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.23187 to 0.22384, saving model to best.model\n",
      "0s - loss: 0.2316 - acc: 0.9206 - val_loss: 0.2238 - val_acc: 0.9133\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.22384 to 0.21996, saving model to best.model\n",
      "0s - loss: 0.2356 - acc: 0.9170 - val_loss: 0.2200 - val_acc: 0.9153\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2253 - acc: 0.9167 - val_loss: 0.2215 - val_acc: 0.9133\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21996 to 0.21226, saving model to best.model\n",
      "0s - loss: 0.2192 - acc: 0.9216 - val_loss: 0.2123 - val_acc: 0.9114\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2232 - acc: 0.9187 - val_loss: 0.2144 - val_acc: 0.9114\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.21226 to 0.20935, saving model to best.model\n",
      "0s - loss: 0.2223 - acc: 0.9182 - val_loss: 0.2094 - val_acc: 0.9094\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20935 to 0.20084, saving model to best.model\n",
      "0s - loss: 0.2232 - acc: 0.9192 - val_loss: 0.2008 - val_acc: 0.9075\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20084 to 0.19722, saving model to best.model\n",
      "0s - loss: 0.2135 - acc: 0.9182 - val_loss: 0.1972 - val_acc: 0.9085\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2111 - acc: 0.9218 - val_loss: 0.2040 - val_acc: 0.9124\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19722 to 0.19289, saving model to best.model\n",
      "0s - loss: 0.2103 - acc: 0.9201 - val_loss: 0.1929 - val_acc: 0.9085\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19289 to 0.18825, saving model to best.model\n",
      "0s - loss: 0.2004 - acc: 0.9233 - val_loss: 0.1882 - val_acc: 0.9104\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2050 - acc: 0.9245 - val_loss: 0.1903 - val_acc: 0.9114\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18825 to 0.18056, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9289 - val_loss: 0.1806 - val_acc: 0.9114\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2009 - acc: 0.9255 - val_loss: 0.1834 - val_acc: 0.9133\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18056 to 0.17480, saving model to best.model\n",
      "0s - loss: 0.1842 - acc: 0.9338 - val_loss: 0.1748 - val_acc: 0.9124\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17480 to 0.17048, saving model to best.model\n",
      "0s - loss: 0.1799 - acc: 0.9350 - val_loss: 0.1705 - val_acc: 0.9153\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1924 - acc: 0.9299 - val_loss: 0.1736 - val_acc: 0.9104\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17048 to 0.16564, saving model to best.model\n",
      "0s - loss: 0.1786 - acc: 0.9347 - val_loss: 0.1656 - val_acc: 0.9153\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.16564 to 0.16020, saving model to best.model\n",
      "0s - loss: 0.1781 - acc: 0.9308 - val_loss: 0.1602 - val_acc: 0.9231\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9330 - val_loss: 0.1673 - val_acc: 0.9124\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16020 to 0.15472, saving model to best.model\n",
      "0s - loss: 0.1719 - acc: 0.9352 - val_loss: 0.1547 - val_acc: 0.9241\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15472 to 0.15366, saving model to best.model\n",
      "0s - loss: 0.1680 - acc: 0.9360 - val_loss: 0.1537 - val_acc: 0.9172\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1627 - acc: 0.9396 - val_loss: 0.1543 - val_acc: 0.9163\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15366 to 0.14810, saving model to best.model\n",
      "0s - loss: 0.1640 - acc: 0.9372 - val_loss: 0.1481 - val_acc: 0.9260\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14810 to 0.14569, saving model to best.model\n",
      "0s - loss: 0.1581 - acc: 0.9364 - val_loss: 0.1457 - val_acc: 0.9221\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14569 to 0.14372, saving model to best.model\n",
      "0s - loss: 0.1585 - acc: 0.9418 - val_loss: 0.1437 - val_acc: 0.9241\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14372 to 0.13506, saving model to best.model\n",
      "0s - loss: 0.1561 - acc: 0.9433 - val_loss: 0.1351 - val_acc: 0.9416\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1527 - acc: 0.9413 - val_loss: 0.1398 - val_acc: 0.9182\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13506 to 0.13075, saving model to best.model\n",
      "0s - loss: 0.1466 - acc: 0.9423 - val_loss: 0.1308 - val_acc: 0.9309\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13075 to 0.12464, saving model to best.model\n",
      "0s - loss: 0.1332 - acc: 0.9486 - val_loss: 0.1246 - val_acc: 0.9377\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1413 - acc: 0.9450 - val_loss: 0.1326 - val_acc: 0.9211\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12464 to 0.11918, saving model to best.model\n",
      "0s - loss: 0.1447 - acc: 0.9406 - val_loss: 0.1192 - val_acc: 0.9357\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.11918 to 0.11807, saving model to best.model\n",
      "0s - loss: 0.1359 - acc: 0.9474 - val_loss: 0.1181 - val_acc: 0.9396\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.11807 to 0.11335, saving model to best.model\n",
      "0s - loss: 0.1293 - acc: 0.9494 - val_loss: 0.1133 - val_acc: 0.9474\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11335 to 0.10881, saving model to best.model\n",
      "0s - loss: 0.1281 - acc: 0.9498 - val_loss: 0.1088 - val_acc: 0.9484\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.10881 to 0.10733, saving model to best.model\n",
      "0s - loss: 0.1320 - acc: 0.9506 - val_loss: 0.1073 - val_acc: 0.9474\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.10733 to 0.09862, saving model to best.model\n",
      "0s - loss: 0.1176 - acc: 0.9528 - val_loss: 0.0986 - val_acc: 0.9552\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.09862 to 0.09531, saving model to best.model\n",
      "0s - loss: 0.1143 - acc: 0.9533 - val_loss: 0.0953 - val_acc: 0.9552\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1227 - acc: 0.9530 - val_loss: 0.0982 - val_acc: 0.9542\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.09531 to 0.08892, saving model to best.model\n",
      "0s - loss: 0.1132 - acc: 0.9564 - val_loss: 0.0889 - val_acc: 0.9581\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1171 - acc: 0.9530 - val_loss: 0.0938 - val_acc: 0.9611\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08892 to 0.08728, saving model to best.model\n",
      "0s - loss: 0.1119 - acc: 0.9567 - val_loss: 0.0873 - val_acc: 0.9581\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.08728 to 0.08576, saving model to best.model\n",
      "0s - loss: 0.1165 - acc: 0.9554 - val_loss: 0.0858 - val_acc: 0.9611\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.08576 to 0.08239, saving model to best.model\n",
      "0s - loss: 0.1037 - acc: 0.9610 - val_loss: 0.0824 - val_acc: 0.9669\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.08239 to 0.07760, saving model to best.model\n",
      "0s - loss: 0.1041 - acc: 0.9571 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07760 to 0.07542, saving model to best.model\n",
      "0s - loss: 0.1040 - acc: 0.9593 - val_loss: 0.0754 - val_acc: 0.9611\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1017 - acc: 0.9623 - val_loss: 0.0789 - val_acc: 0.9708\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07542 to 0.07106, saving model to best.model\n",
      "0s - loss: 0.0934 - acc: 0.9620 - val_loss: 0.0711 - val_acc: 0.9679\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.0954 - acc: 0.9635 - val_loss: 0.0727 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07106 to 0.06624, saving model to best.model\n",
      "0s - loss: 0.0941 - acc: 0.9642 - val_loss: 0.0662 - val_acc: 0.9708\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.0890 - acc: 0.9640 - val_loss: 0.0683 - val_acc: 0.9757\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06624 to 0.06142, saving model to best.model\n",
      "0s - loss: 0.0900 - acc: 0.9625 - val_loss: 0.0614 - val_acc: 0.9708\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.0911 - acc: 0.9647 - val_loss: 0.0659 - val_acc: 0.9757\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0851 - acc: 0.9674 - val_loss: 0.0627 - val_acc: 0.9776\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06142 to 0.05956, saving model to best.model\n",
      "0s - loss: 0.0872 - acc: 0.9649 - val_loss: 0.0596 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05956 to 0.05754, saving model to best.model\n",
      "0s - loss: 0.0918 - acc: 0.9645 - val_loss: 0.0575 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05754 to 0.05709, saving model to best.model\n",
      "0s - loss: 0.0862 - acc: 0.9666 - val_loss: 0.0571 - val_acc: 0.9825\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0840 - acc: 0.9681 - val_loss: 0.0595 - val_acc: 0.9815\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0945 - acc: 0.9647 - val_loss: 0.0592 - val_acc: 0.9834\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05709 to 0.05323, saving model to best.model\n",
      "0s - loss: 0.0925 - acc: 0.9649 - val_loss: 0.0532 - val_acc: 0.9815\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05323 to 0.05042, saving model to best.model\n",
      "0s - loss: 0.0867 - acc: 0.9676 - val_loss: 0.0504 - val_acc: 0.9766\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0818 - acc: 0.9671 - val_loss: 0.0558 - val_acc: 0.9825\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0734 - acc: 0.9713 - val_loss: 0.0507 - val_acc: 0.9844\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05042 to 0.04766, saving model to best.model\n",
      "0s - loss: 0.0648 - acc: 0.9752 - val_loss: 0.0477 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04766 to 0.04678, saving model to best.model\n",
      "0s - loss: 0.0773 - acc: 0.9708 - val_loss: 0.0468 - val_acc: 0.9844\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0788 - acc: 0.9691 - val_loss: 0.0480 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04678 to 0.04242, saving model to best.model\n",
      "0s - loss: 0.0699 - acc: 0.9725 - val_loss: 0.0424 - val_acc: 0.9873\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0769 - acc: 0.9705 - val_loss: 0.0429 - val_acc: 0.9864\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0791 - acc: 0.9688 - val_loss: 0.0565 - val_acc: 0.9815\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04242 to 0.04063, saving model to best.model\n",
      "0s - loss: 0.0821 - acc: 0.9669 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0685 - acc: 0.9727 - val_loss: 0.0502 - val_acc: 0.9825\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0718 - acc: 0.9732 - val_loss: 0.0409 - val_acc: 0.9864\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0595 - acc: 0.9766 - val_loss: 0.0427 - val_acc: 0.9854\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04063 to 0.03661, saving model to best.model\n",
      "0s - loss: 0.0662 - acc: 0.9749 - val_loss: 0.0366 - val_acc: 0.9864\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9739 - val_loss: 0.0400 - val_acc: 0.9873\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0683 - acc: 0.9742 - val_loss: 0.0408 - val_acc: 0.9883\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9752 - val_loss: 0.0413 - val_acc: 0.9864\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0698 - acc: 0.9725 - val_loss: 0.0377 - val_acc: 0.9873\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0558 - acc: 0.9764 - val_loss: 0.0376 - val_acc: 0.9864\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03661 to 0.03476, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9752 - val_loss: 0.0348 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03476 to 0.03445, saving model to best.model\n",
      "0s - loss: 0.0663 - acc: 0.9749 - val_loss: 0.0345 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0549 - acc: 0.9791 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03445 to 0.03192, saving model to best.model\n",
      "0s - loss: 0.0589 - acc: 0.9766 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0589 - acc: 0.9791 - val_loss: 0.0351 - val_acc: 0.9864\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03192 to 0.02932, saving model to best.model\n",
      "0s - loss: 0.0610 - acc: 0.9752 - val_loss: 0.0293 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0601 - acc: 0.9766 - val_loss: 0.0344 - val_acc: 0.9873\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02932 to 0.02672, saving model to best.model\n",
      "0s - loss: 0.0538 - acc: 0.9793 - val_loss: 0.0267 - val_acc: 0.9912\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0537 - acc: 0.9788 - val_loss: 0.0321 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0567 - acc: 0.9805 - val_loss: 0.0290 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0568 - acc: 0.9778 - val_loss: 0.0286 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0579 - acc: 0.9769 - val_loss: 0.0344 - val_acc: 0.9903\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0548 - acc: 0.9786 - val_loss: 0.0283 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9834 - val_loss: 0.0294 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02672 to 0.02548, saving model to best.model\n",
      "0s - loss: 0.0458 - acc: 0.9825 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02548 to 0.02421, saving model to best.model\n",
      "0s - loss: 0.0523 - acc: 0.9800 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9813 - val_loss: 0.0249 - val_acc: 0.9922\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0493 - acc: 0.9825 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0562 - acc: 0.9793 - val_loss: 0.0255 - val_acc: 0.9893\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0504 - acc: 0.9808 - val_loss: 0.0283 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02421 to 0.02296, saving model to best.model\n",
      "0s - loss: 0.0418 - acc: 0.9849 - val_loss: 0.0230 - val_acc: 0.9942\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9822 - val_loss: 0.0252 - val_acc: 0.9893\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02296 to 0.02009, saving model to best.model\n",
      "0s - loss: 0.0441 - acc: 0.9847 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9805 - val_loss: 0.0214 - val_acc: 0.9932\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9800 - val_loss: 0.0225 - val_acc: 0.9922\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9851 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9817 - val_loss: 0.0237 - val_acc: 0.9893\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9822 - val_loss: 0.0219 - val_acc: 0.9893\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9839 - val_loss: 0.0216 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02009 to 0.01798, saving model to best.model\n",
      "0s - loss: 0.0441 - acc: 0.9839 - val_loss: 0.0180 - val_acc: 0.9971\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9803 - val_loss: 0.0232 - val_acc: 0.9912\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9800 - val_loss: 0.0225 - val_acc: 0.9922\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9830 - val_loss: 0.0219 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9854 - val_loss: 0.0191 - val_acc: 0.9942\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01798 to 0.01796, saving model to best.model\n",
      "0s - loss: 0.0472 - acc: 0.9813 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9832 - val_loss: 0.0183 - val_acc: 0.9942\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9864 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01796 to 0.01740, saving model to best.model\n",
      "0s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01740 to 0.01650, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9837 - val_loss: 0.0165 - val_acc: 0.9951\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9847 - val_loss: 0.0223 - val_acc: 0.9903\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9859 - val_loss: 0.0184 - val_acc: 0.9922\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01650 to 0.01516, saving model to best.model\n",
      "0s - loss: 0.0367 - acc: 0.9864 - val_loss: 0.0152 - val_acc: 0.9971\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9832 - val_loss: 0.0170 - val_acc: 0.9942\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9864 - val_loss: 0.0186 - val_acc: 0.9922\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9849 - val_loss: 0.0157 - val_acc: 0.9951\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01516 to 0.01465, saving model to best.model\n",
      "0s - loss: 0.0452 - acc: 0.9837 - val_loss: 0.0147 - val_acc: 0.9961\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9864 - val_loss: 0.0183 - val_acc: 0.9922\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9844 - val_loss: 0.0190 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01465 to 0.01367, saving model to best.model\n",
      "0s - loss: 0.0391 - acc: 0.9849 - val_loss: 0.0137 - val_acc: 0.9971\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9881 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.0140 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01367 to 0.01311, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9893 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9866 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9888 - val_loss: 0.0141 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01311 to 0.01250, saving model to best.model\n",
      "0s - loss: 0.0385 - acc: 0.9861 - val_loss: 0.0125 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0130 - val_acc: 0.9961\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9873 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9861 - val_loss: 0.0158 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9871 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9859 - val_loss: 0.0127 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9864 - val_loss: 0.0153 - val_acc: 0.9951\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01250 to 0.01239, saving model to best.model\n",
      "0s - loss: 0.0311 - acc: 0.9881 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01239 to 0.01194, saving model to best.model\n",
      "0s - loss: 0.0354 - acc: 0.9861 - val_loss: 0.0119 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9851 - val_loss: 0.0124 - val_acc: 0.9961\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9881 - val_loss: 0.0139 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.01194 to 0.01166, saving model to best.model\n",
      "0s - loss: 0.0299 - acc: 0.9886 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9876 - val_loss: 0.0138 - val_acc: 0.9961\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01166 to 0.01061, saving model to best.model\n",
      "0s - loss: 0.0285 - acc: 0.9876 - val_loss: 0.0106 - val_acc: 0.9971\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0254 - acc: 0.9903 - val_loss: 0.0137 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0296 - acc: 0.9893 - val_loss: 0.0127 - val_acc: 0.9961\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9883 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9886 - val_loss: 0.0129 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9903 - val_loss: 0.0128 - val_acc: 0.9961\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9849 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0236 - acc: 0.9934 - val_loss: 0.0115 - val_acc: 0.9971\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9866 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9869 - val_loss: 0.0119 - val_acc: 0.9971\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9898 - val_loss: 0.0122 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9895 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9888 - val_loss: 0.0112 - val_acc: 0.9971\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9881 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9871 - val_loss: 0.0110 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.01061 to 0.01055, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9890 - val_loss: 0.0105 - val_acc: 0.9971\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.01055 to 0.01010, saving model to best.model\n",
      "0s - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01010 to 0.00953, saving model to best.model\n",
      "0s - loss: 0.0286 - acc: 0.9888 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0224 - acc: 0.9912 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00953 to 0.00859, saving model to best.model\n",
      "0s - loss: 0.0261 - acc: 0.9895 - val_loss: 0.0086 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9890 - val_loss: 0.0118 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9900 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0234 - acc: 0.9917 - val_loss: 0.0097 - val_acc: 0.9971\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00859 to 0.00791, saving model to best.model\n",
      "0s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0079 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0257 - acc: 0.9907 - val_loss: 0.0109 - val_acc: 0.9971\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0089 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0237 - acc: 0.9910 - val_loss: 0.0082 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68056, saving model to best.model\n",
      "0s - loss: 0.8310 - acc: 0.5047 - val_loss: 0.6806 - val_acc: 0.5278\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68056 to 0.65483, saving model to best.model\n",
      "0s - loss: 0.7603 - acc: 0.5310 - val_loss: 0.6548 - val_acc: 0.5278\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65483 to 0.61834, saving model to best.model\n",
      "0s - loss: 0.7264 - acc: 0.5588 - val_loss: 0.6183 - val_acc: 0.7877\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61834 to 0.55742, saving model to best.model\n",
      "0s - loss: 0.6762 - acc: 0.5965 - val_loss: 0.5574 - val_acc: 0.8160\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55742 to 0.48178, saving model to best.model\n",
      "0s - loss: 0.5990 - acc: 0.6810 - val_loss: 0.4818 - val_acc: 0.8247\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.48178 to 0.41846, saving model to best.model\n",
      "0s - loss: 0.5317 - acc: 0.7434 - val_loss: 0.4185 - val_acc: 0.8374\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41846 to 0.38127, saving model to best.model\n",
      "0s - loss: 0.4922 - acc: 0.7699 - val_loss: 0.3813 - val_acc: 0.8491\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38127 to 0.35915, saving model to best.model\n",
      "0s - loss: 0.4524 - acc: 0.8050 - val_loss: 0.3591 - val_acc: 0.8559\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35915 to 0.33660, saving model to best.model\n",
      "0s - loss: 0.4273 - acc: 0.8181 - val_loss: 0.3366 - val_acc: 0.8666\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33660 to 0.32661, saving model to best.model\n",
      "0s - loss: 0.4008 - acc: 0.8403 - val_loss: 0.3266 - val_acc: 0.8734\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.32661 to 0.30698, saving model to best.model\n",
      "0s - loss: 0.3796 - acc: 0.8439 - val_loss: 0.3070 - val_acc: 0.8773\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30698 to 0.29735, saving model to best.model\n",
      "0s - loss: 0.3566 - acc: 0.8559 - val_loss: 0.2974 - val_acc: 0.8793\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29735 to 0.29197, saving model to best.model\n",
      "0s - loss: 0.3579 - acc: 0.8605 - val_loss: 0.2920 - val_acc: 0.8812\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.29197 to 0.28096, saving model to best.model\n",
      "0s - loss: 0.3349 - acc: 0.8680 - val_loss: 0.2810 - val_acc: 0.8832\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.28096 to 0.27488, saving model to best.model\n",
      "0s - loss: 0.3343 - acc: 0.8727 - val_loss: 0.2749 - val_acc: 0.8880\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.27488 to 0.27066, saving model to best.model\n",
      "0s - loss: 0.3176 - acc: 0.8741 - val_loss: 0.2707 - val_acc: 0.8939\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.27066 to 0.26394, saving model to best.model\n",
      "0s - loss: 0.3182 - acc: 0.8751 - val_loss: 0.2639 - val_acc: 0.8939\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.26394 to 0.26182, saving model to best.model\n",
      "0s - loss: 0.3123 - acc: 0.8809 - val_loss: 0.2618 - val_acc: 0.8919\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26182 to 0.25445, saving model to best.model\n",
      "0s - loss: 0.3002 - acc: 0.8856 - val_loss: 0.2544 - val_acc: 0.9036\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.25445 to 0.25110, saving model to best.model\n",
      "0s - loss: 0.2884 - acc: 0.8892 - val_loss: 0.2511 - val_acc: 0.9036\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2853 - acc: 0.8926 - val_loss: 0.2571 - val_acc: 0.8958\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25110 to 0.24483, saving model to best.model\n",
      "0s - loss: 0.2822 - acc: 0.8895 - val_loss: 0.2448 - val_acc: 0.9085\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.24483 to 0.24247, saving model to best.model\n",
      "0s - loss: 0.2820 - acc: 0.8970 - val_loss: 0.2425 - val_acc: 0.9114\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24247 to 0.24191, saving model to best.model\n",
      "0s - loss: 0.2792 - acc: 0.8972 - val_loss: 0.2419 - val_acc: 0.9133\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.24191 to 0.23601, saving model to best.model\n",
      "0s - loss: 0.2617 - acc: 0.9014 - val_loss: 0.2360 - val_acc: 0.9104\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23601 to 0.23213, saving model to best.model\n",
      "0s - loss: 0.2631 - acc: 0.9016 - val_loss: 0.2321 - val_acc: 0.9094\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.23213 to 0.22954, saving model to best.model\n",
      "0s - loss: 0.2681 - acc: 0.9033 - val_loss: 0.2295 - val_acc: 0.9124\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.22954 to 0.22527, saving model to best.model\n",
      "0s - loss: 0.2548 - acc: 0.9092 - val_loss: 0.2253 - val_acc: 0.9124\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.22527 to 0.22382, saving model to best.model\n",
      "0s - loss: 0.2518 - acc: 0.9028 - val_loss: 0.2238 - val_acc: 0.9133\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22382 to 0.22162, saving model to best.model\n",
      "0s - loss: 0.2511 - acc: 0.9077 - val_loss: 0.2216 - val_acc: 0.9172\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.22162 to 0.21564, saving model to best.model\n",
      "0s - loss: 0.2481 - acc: 0.9070 - val_loss: 0.2156 - val_acc: 0.9143\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.21564 to 0.21352, saving model to best.model\n",
      "0s - loss: 0.2400 - acc: 0.9089 - val_loss: 0.2135 - val_acc: 0.9143\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.21352 to 0.21062, saving model to best.model\n",
      "0s - loss: 0.2406 - acc: 0.9136 - val_loss: 0.2106 - val_acc: 0.9163\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.2338 - acc: 0.9162 - val_loss: 0.2184 - val_acc: 0.9231\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.21062 to 0.20355, saving model to best.model\n",
      "0s - loss: 0.2298 - acc: 0.9121 - val_loss: 0.2035 - val_acc: 0.9153\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.20355 to 0.20216, saving model to best.model\n",
      "0s - loss: 0.2207 - acc: 0.9201 - val_loss: 0.2022 - val_acc: 0.9163\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.20216 to 0.19965, saving model to best.model\n",
      "0s - loss: 0.2222 - acc: 0.9165 - val_loss: 0.1997 - val_acc: 0.9192\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19965 to 0.19383, saving model to best.model\n",
      "0s - loss: 0.2164 - acc: 0.9182 - val_loss: 0.1938 - val_acc: 0.9172\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.2192 - acc: 0.9116 - val_loss: 0.1939 - val_acc: 0.9250\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19383 to 0.18703, saving model to best.model\n",
      "0s - loss: 0.2138 - acc: 0.9201 - val_loss: 0.1870 - val_acc: 0.9192\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18703 to 0.18658, saving model to best.model\n",
      "0s - loss: 0.2018 - acc: 0.9209 - val_loss: 0.1866 - val_acc: 0.9260\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18658 to 0.18016, saving model to best.model\n",
      "0s - loss: 0.2031 - acc: 0.9184 - val_loss: 0.1802 - val_acc: 0.9163\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.18016 to 0.17678, saving model to best.model\n",
      "0s - loss: 0.1985 - acc: 0.9218 - val_loss: 0.1768 - val_acc: 0.9202\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.17678 to 0.17519, saving model to best.model\n",
      "0s - loss: 0.1981 - acc: 0.9245 - val_loss: 0.1752 - val_acc: 0.9241\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.17519 to 0.17178, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9284 - val_loss: 0.1718 - val_acc: 0.9192\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.17178 to 0.16669, saving model to best.model\n",
      "0s - loss: 0.1893 - acc: 0.9240 - val_loss: 0.1667 - val_acc: 0.9309\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.16669 to 0.16582, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9267 - val_loss: 0.1658 - val_acc: 0.9328\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.16582 to 0.15877, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9316 - val_loss: 0.1588 - val_acc: 0.9241\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15877 to 0.15697, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9301 - val_loss: 0.1570 - val_acc: 0.9357\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.15697 to 0.15209, saving model to best.model\n",
      "0s - loss: 0.1716 - acc: 0.9352 - val_loss: 0.1521 - val_acc: 0.9289\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.15209 to 0.14854, saving model to best.model\n",
      "0s - loss: 0.1685 - acc: 0.9333 - val_loss: 0.1485 - val_acc: 0.9367\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9360 - val_loss: 0.1488 - val_acc: 0.9250\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14854 to 0.14357, saving model to best.model\n",
      "0s - loss: 0.1670 - acc: 0.9347 - val_loss: 0.1436 - val_acc: 0.9348\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.14357 to 0.14205, saving model to best.model\n",
      "0s - loss: 0.1625 - acc: 0.9360 - val_loss: 0.1421 - val_acc: 0.9387\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.14205 to 0.13772, saving model to best.model\n",
      "0s - loss: 0.1471 - acc: 0.9416 - val_loss: 0.1377 - val_acc: 0.9348\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13772 to 0.13478, saving model to best.model\n",
      "0s - loss: 0.1440 - acc: 0.9469 - val_loss: 0.1348 - val_acc: 0.9406\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.13478 to 0.13307, saving model to best.model\n",
      "0s - loss: 0.1459 - acc: 0.9418 - val_loss: 0.1331 - val_acc: 0.9387\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1473 - acc: 0.9416 - val_loss: 0.1359 - val_acc: 0.9445\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.13307 to 0.12380, saving model to best.model\n",
      "0s - loss: 0.1454 - acc: 0.9438 - val_loss: 0.1238 - val_acc: 0.9464\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.12380 to 0.12034, saving model to best.model\n",
      "0s - loss: 0.1387 - acc: 0.9447 - val_loss: 0.1203 - val_acc: 0.9464\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.12034 to 0.11809, saving model to best.model\n",
      "0s - loss: 0.1286 - acc: 0.9525 - val_loss: 0.1181 - val_acc: 0.9503\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.11809 to 0.11539, saving model to best.model\n",
      "0s - loss: 0.1326 - acc: 0.9491 - val_loss: 0.1154 - val_acc: 0.9513\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11539 to 0.11417, saving model to best.model\n",
      "0s - loss: 0.1303 - acc: 0.9479 - val_loss: 0.1142 - val_acc: 0.9542\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.11417 to 0.11091, saving model to best.model\n",
      "0s - loss: 0.1289 - acc: 0.9486 - val_loss: 0.1109 - val_acc: 0.9562\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.11091 to 0.10581, saving model to best.model\n",
      "0s - loss: 0.1253 - acc: 0.9498 - val_loss: 0.1058 - val_acc: 0.9581\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10581 to 0.10209, saving model to best.model\n",
      "0s - loss: 0.1162 - acc: 0.9533 - val_loss: 0.1021 - val_acc: 0.9611\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.10209 to 0.10173, saving model to best.model\n",
      "0s - loss: 0.1221 - acc: 0.9501 - val_loss: 0.1017 - val_acc: 0.9649\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1276 - acc: 0.9498 - val_loss: 0.1060 - val_acc: 0.9620\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.10173 to 0.10046, saving model to best.model\n",
      "0s - loss: 0.1149 - acc: 0.9535 - val_loss: 0.1005 - val_acc: 0.9659\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.10046 to 0.09855, saving model to best.model\n",
      "0s - loss: 0.1184 - acc: 0.9525 - val_loss: 0.0985 - val_acc: 0.9659\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.09855 to 0.09470, saving model to best.model\n",
      "0s - loss: 0.1142 - acc: 0.9564 - val_loss: 0.0947 - val_acc: 0.9757\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1107 - acc: 0.9579 - val_loss: 0.0947 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.09470 to 0.09185, saving model to best.model\n",
      "0s - loss: 0.1061 - acc: 0.9564 - val_loss: 0.0919 - val_acc: 0.9766\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.09185 to 0.08932, saving model to best.model\n",
      "0s - loss: 0.1083 - acc: 0.9593 - val_loss: 0.0893 - val_acc: 0.9718\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08932 to 0.08827, saving model to best.model\n",
      "0s - loss: 0.0981 - acc: 0.9620 - val_loss: 0.0883 - val_acc: 0.9766\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.08827 to 0.08599, saving model to best.model\n",
      "0s - loss: 0.1032 - acc: 0.9615 - val_loss: 0.0860 - val_acc: 0.9786\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.08599 to 0.08289, saving model to best.model\n",
      "0s - loss: 0.1005 - acc: 0.9637 - val_loss: 0.0829 - val_acc: 0.9796\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.08289 to 0.08054, saving model to best.model\n",
      "0s - loss: 0.1011 - acc: 0.9608 - val_loss: 0.0805 - val_acc: 0.9786\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.08054 to 0.07979, saving model to best.model\n",
      "0s - loss: 0.0947 - acc: 0.9640 - val_loss: 0.0798 - val_acc: 0.9805\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07979 to 0.07755, saving model to best.model\n",
      "0s - loss: 0.0963 - acc: 0.9620 - val_loss: 0.0775 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07755 to 0.07706, saving model to best.model\n",
      "0s - loss: 0.1007 - acc: 0.9608 - val_loss: 0.0771 - val_acc: 0.9776\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.07706 to 0.07447, saving model to best.model\n",
      "0s - loss: 0.0893 - acc: 0.9664 - val_loss: 0.0745 - val_acc: 0.9786\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0856 - acc: 0.9671 - val_loss: 0.0756 - val_acc: 0.9805\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.07447 to 0.07064, saving model to best.model\n",
      "0s - loss: 0.0843 - acc: 0.9674 - val_loss: 0.0706 - val_acc: 0.9815\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.07064 to 0.07019, saving model to best.model\n",
      "0s - loss: 0.0891 - acc: 0.9691 - val_loss: 0.0702 - val_acc: 0.9805\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.07019 to 0.06938, saving model to best.model\n",
      "0s - loss: 0.0883 - acc: 0.9691 - val_loss: 0.0694 - val_acc: 0.9805\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06938 to 0.06827, saving model to best.model\n",
      "0s - loss: 0.0826 - acc: 0.9715 - val_loss: 0.0683 - val_acc: 0.9805\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.06827 to 0.06646, saving model to best.model\n",
      "0s - loss: 0.0814 - acc: 0.9703 - val_loss: 0.0665 - val_acc: 0.9815\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0843 - acc: 0.9679 - val_loss: 0.0741 - val_acc: 0.9815\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0809 - acc: 0.9688 - val_loss: 0.0669 - val_acc: 0.9796\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.06646 to 0.06593, saving model to best.model\n",
      "0s - loss: 0.0892 - acc: 0.9688 - val_loss: 0.0659 - val_acc: 0.9825\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.06593 to 0.06438, saving model to best.model\n",
      "0s - loss: 0.0814 - acc: 0.9691 - val_loss: 0.0644 - val_acc: 0.9825\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.06438 to 0.06299, saving model to best.model\n",
      "0s - loss: 0.0763 - acc: 0.9718 - val_loss: 0.0630 - val_acc: 0.9805\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0810 - acc: 0.9710 - val_loss: 0.0655 - val_acc: 0.9805\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.06299 to 0.06009, saving model to best.model\n",
      "0s - loss: 0.0776 - acc: 0.9715 - val_loss: 0.0601 - val_acc: 0.9805\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.06009 to 0.05793, saving model to best.model\n",
      "0s - loss: 0.0757 - acc: 0.9730 - val_loss: 0.0579 - val_acc: 0.9815\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.05793 to 0.05611, saving model to best.model\n",
      "0s - loss: 0.0819 - acc: 0.9708 - val_loss: 0.0561 - val_acc: 0.9825\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0771 - acc: 0.9698 - val_loss: 0.0577 - val_acc: 0.9815\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0711 - acc: 0.9757 - val_loss: 0.0574 - val_acc: 0.9796\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.05611 to 0.05379, saving model to best.model\n",
      "0s - loss: 0.0737 - acc: 0.9720 - val_loss: 0.0538 - val_acc: 0.9815\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.05379 to 0.05290, saving model to best.model\n",
      "0s - loss: 0.0720 - acc: 0.9710 - val_loss: 0.0529 - val_acc: 0.9815\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0669 - acc: 0.9754 - val_loss: 0.0569 - val_acc: 0.9825\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.05290 to 0.05288, saving model to best.model\n",
      "0s - loss: 0.0754 - acc: 0.9737 - val_loss: 0.0529 - val_acc: 0.9834\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.05288 to 0.05243, saving model to best.model\n",
      "0s - loss: 0.0743 - acc: 0.9715 - val_loss: 0.0524 - val_acc: 0.9834\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0662 - acc: 0.9778 - val_loss: 0.0566 - val_acc: 0.9825\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0707 - acc: 0.9749 - val_loss: 0.0565 - val_acc: 0.9834\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.05243 to 0.05029, saving model to best.model\n",
      "0s - loss: 0.0691 - acc: 0.9754 - val_loss: 0.0503 - val_acc: 0.9834\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0664 - acc: 0.9749 - val_loss: 0.0531 - val_acc: 0.9825\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.05029 to 0.04831, saving model to best.model\n",
      "0s - loss: 0.0636 - acc: 0.9761 - val_loss: 0.0483 - val_acc: 0.9825\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9803 - val_loss: 0.0522 - val_acc: 0.9825\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.04831 to 0.04684, saving model to best.model\n",
      "0s - loss: 0.0570 - acc: 0.9798 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0665 - acc: 0.9749 - val_loss: 0.0474 - val_acc: 0.9834\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0607 - acc: 0.9769 - val_loss: 0.0474 - val_acc: 0.9834\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0557 - acc: 0.9781 - val_loss: 0.0473 - val_acc: 0.9834\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0659 - acc: 0.9795 - val_loss: 0.0480 - val_acc: 0.9834\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.04684 to 0.04678, saving model to best.model\n",
      "0s - loss: 0.0583 - acc: 0.9795 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0579 - acc: 0.9813 - val_loss: 0.0516 - val_acc: 0.9825\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.04678 to 0.04421, saving model to best.model\n",
      "0s - loss: 0.0638 - acc: 0.9769 - val_loss: 0.0442 - val_acc: 0.9825\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0539 - acc: 0.9795 - val_loss: 0.0470 - val_acc: 0.9834\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.04421 to 0.04288, saving model to best.model\n",
      "0s - loss: 0.0571 - acc: 0.9808 - val_loss: 0.0429 - val_acc: 0.9834\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9813 - val_loss: 0.0429 - val_acc: 0.9834\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0558 - acc: 0.9800 - val_loss: 0.0443 - val_acc: 0.9834\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9830 - val_loss: 0.0433 - val_acc: 0.9854\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.04288 to 0.04283, saving model to best.model\n",
      "0s - loss: 0.0520 - acc: 0.9817 - val_loss: 0.0428 - val_acc: 0.9834\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9808 - val_loss: 0.0435 - val_acc: 0.9834\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.04283 to 0.03972, saving model to best.model\n",
      "0s - loss: 0.0546 - acc: 0.9815 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0570 - acc: 0.9793 - val_loss: 0.0449 - val_acc: 0.9834\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0579 - acc: 0.9795 - val_loss: 0.0430 - val_acc: 0.9844\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.03972 to 0.03933, saving model to best.model\n",
      "0s - loss: 0.0504 - acc: 0.9817 - val_loss: 0.0393 - val_acc: 0.9844\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9800 - val_loss: 0.0402 - val_acc: 0.9834\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.03933 to 0.03572, saving model to best.model\n",
      "0s - loss: 0.0579 - acc: 0.9791 - val_loss: 0.0357 - val_acc: 0.9854\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0553 - acc: 0.9803 - val_loss: 0.0377 - val_acc: 0.9834\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.03572 to 0.03479, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9842 - val_loss: 0.0348 - val_acc: 0.9873\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0545 - acc: 0.9800 - val_loss: 0.0363 - val_acc: 0.9834\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.03479 to 0.03399, saving model to best.model\n",
      "0s - loss: 0.0505 - acc: 0.9813 - val_loss: 0.0340 - val_acc: 0.9834\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.03399 to 0.03307, saving model to best.model\n",
      "0s - loss: 0.0480 - acc: 0.9832 - val_loss: 0.0331 - val_acc: 0.9854\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0558 - acc: 0.9795 - val_loss: 0.0335 - val_acc: 0.9844\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0512 - acc: 0.9820 - val_loss: 0.0389 - val_acc: 0.9834\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9830 - val_loss: 0.0347 - val_acc: 0.9844\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0478 - acc: 0.9810 - val_loss: 0.0351 - val_acc: 0.9854\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9861 - val_loss: 0.0340 - val_acc: 0.9854\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9847 - val_loss: 0.0358 - val_acc: 0.9834\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9864 - val_loss: 0.0338 - val_acc: 0.9844\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.03307 to 0.03146, saving model to best.model\n",
      "0s - loss: 0.0443 - acc: 0.9859 - val_loss: 0.0315 - val_acc: 0.9864\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.03146 to 0.03003, saving model to best.model\n",
      "0s - loss: 0.0439 - acc: 0.9817 - val_loss: 0.0300 - val_acc: 0.9854\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.03003 to 0.02856, saving model to best.model\n",
      "0s - loss: 0.0480 - acc: 0.9839 - val_loss: 0.0286 - val_acc: 0.9873\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9849 - val_loss: 0.0312 - val_acc: 0.9844\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9825 - val_loss: 0.0310 - val_acc: 0.9854\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0458 - acc: 0.9827 - val_loss: 0.0335 - val_acc: 0.9844\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0458 - acc: 0.9834 - val_loss: 0.0332 - val_acc: 0.9864\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.02856 to 0.02836, saving model to best.model\n",
      "0s - loss: 0.0363 - acc: 0.9861 - val_loss: 0.0284 - val_acc: 0.9854\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9859 - val_loss: 0.0313 - val_acc: 0.9844\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9817 - val_loss: 0.0308 - val_acc: 0.9903\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0458 - acc: 0.9837 - val_loss: 0.0381 - val_acc: 0.9834\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0454 - acc: 0.9842 - val_loss: 0.0293 - val_acc: 0.9883\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9839 - val_loss: 0.0294 - val_acc: 0.9854\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.02836 to 0.02646, saving model to best.model\n",
      "0s - loss: 0.0438 - acc: 0.9834 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9839 - val_loss: 0.0288 - val_acc: 0.9864\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9869 - val_loss: 0.0280 - val_acc: 0.9864\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9859 - val_loss: 0.0289 - val_acc: 0.9864\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.02646 to 0.02619, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9851 - val_loss: 0.0262 - val_acc: 0.9854\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.02619 to 0.02343, saving model to best.model\n",
      "0s - loss: 0.0418 - acc: 0.9866 - val_loss: 0.0234 - val_acc: 0.9912\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9803 - val_loss: 0.0361 - val_acc: 0.9854\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9832 - val_loss: 0.0314 - val_acc: 0.9883\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9849 - val_loss: 0.0325 - val_acc: 0.9844\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0260 - val_acc: 0.9864\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9830 - val_loss: 0.0247 - val_acc: 0.9893\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9854 - val_loss: 0.0279 - val_acc: 0.9844\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9851 - val_loss: 0.0237 - val_acc: 0.9864\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9866 - val_loss: 0.0256 - val_acc: 0.9864\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9873 - val_loss: 0.0250 - val_acc: 0.9864\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9866 - val_loss: 0.0251 - val_acc: 0.9903\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9847 - val_loss: 0.0308 - val_acc: 0.9854\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9859 - val_loss: 0.0257 - val_acc: 0.9883\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.02343 to 0.02342, saving model to best.model\n",
      "0s - loss: 0.0339 - acc: 0.9871 - val_loss: 0.0234 - val_acc: 0.9883\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9871 - val_loss: 0.0249 - val_acc: 0.9864\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9866 - val_loss: 0.0237 - val_acc: 0.9903\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9859 - val_loss: 0.0256 - val_acc: 0.9873\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9864 - val_loss: 0.0242 - val_acc: 0.9912\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9893 - val_loss: 0.0238 - val_acc: 0.9912\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.02342 to 0.02312, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9898 - val_loss: 0.0231 - val_acc: 0.9883\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.02312 to 0.02156, saving model to best.model\n",
      "0s - loss: 0.0358 - acc: 0.9878 - val_loss: 0.0216 - val_acc: 0.9883\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.02156 to 0.02074, saving model to best.model\n",
      "0s - loss: 0.0336 - acc: 0.9873 - val_loss: 0.0207 - val_acc: 0.9883\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9878 - val_loss: 0.0212 - val_acc: 0.9903\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.02074 to 0.01967, saving model to best.model\n",
      "0s - loss: 0.0336 - acc: 0.9871 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9888 - val_loss: 0.0200 - val_acc: 0.9912\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9856 - val_loss: 0.0293 - val_acc: 0.9893\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9876 - val_loss: 0.0247 - val_acc: 0.9912\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9883 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9883 - val_loss: 0.0228 - val_acc: 0.9912\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9888 - val_loss: 0.0243 - val_acc: 0.9864\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9895 - val_loss: 0.0203 - val_acc: 0.9912\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9871 - val_loss: 0.0213 - val_acc: 0.9903\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9888 - val_loss: 0.0230 - val_acc: 0.9883\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.01967 to 0.01963, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9886 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9905 - val_loss: 0.0198 - val_acc: 0.9903\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9890 - val_loss: 0.0217 - val_acc: 0.9883\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.01963 to 0.01927, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9881 - val_loss: 0.0193 - val_acc: 0.9883\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.01927 to 0.01648, saving model to best.model\n",
      "0s - loss: 0.0366 - acc: 0.9876 - val_loss: 0.0165 - val_acc: 0.9912\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.01648 to 0.01616, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9883 - val_loss: 0.0162 - val_acc: 0.9893\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.72585, saving model to best.model\n",
      "0s - loss: 0.9258 - acc: 0.5033 - val_loss: 0.7259 - val_acc: 0.5102\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.72585 to 0.66965, saving model to best.model\n",
      "0s - loss: 0.7801 - acc: 0.5196 - val_loss: 0.6697 - val_acc: 0.5531\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66965 to 0.65109, saving model to best.model\n",
      "0s - loss: 0.7378 - acc: 0.5396 - val_loss: 0.6511 - val_acc: 0.7196\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.65109 to 0.62409, saving model to best.model\n",
      "0s - loss: 0.6964 - acc: 0.5678 - val_loss: 0.6241 - val_acc: 0.7176\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.62409 to 0.57325, saving model to best.model\n",
      "0s - loss: 0.6629 - acc: 0.6116 - val_loss: 0.5733 - val_acc: 0.7614\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.57325 to 0.50042, saving model to best.model\n",
      "0s - loss: 0.5964 - acc: 0.6837 - val_loss: 0.5004 - val_acc: 0.8160\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.50042 to 0.44322, saving model to best.model\n",
      "0s - loss: 0.5422 - acc: 0.7492 - val_loss: 0.4432 - val_acc: 0.8277\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.44322 to 0.40501, saving model to best.model\n",
      "0s - loss: 0.4786 - acc: 0.7865 - val_loss: 0.4050 - val_acc: 0.8462\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.40501 to 0.37383, saving model to best.model\n",
      "0s - loss: 0.4428 - acc: 0.8098 - val_loss: 0.3738 - val_acc: 0.8617\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.37383 to 0.36107, saving model to best.model\n",
      "0s - loss: 0.4088 - acc: 0.8320 - val_loss: 0.3611 - val_acc: 0.8617\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.36107 to 0.34476, saving model to best.model\n",
      "0s - loss: 0.3930 - acc: 0.8388 - val_loss: 0.3448 - val_acc: 0.8695\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.34476 to 0.31872, saving model to best.model\n",
      "0s - loss: 0.3736 - acc: 0.8563 - val_loss: 0.3187 - val_acc: 0.8763\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.3491 - acc: 0.8602 - val_loss: 0.3194 - val_acc: 0.8754\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.31872 to 0.30110, saving model to best.model\n",
      "0s - loss: 0.3349 - acc: 0.8710 - val_loss: 0.3011 - val_acc: 0.8870\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.30110 to 0.28797, saving model to best.model\n",
      "0s - loss: 0.3300 - acc: 0.8751 - val_loss: 0.2880 - val_acc: 0.8890\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.28797 to 0.27981, saving model to best.model\n",
      "0s - loss: 0.3115 - acc: 0.8841 - val_loss: 0.2798 - val_acc: 0.8987\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.27981 to 0.27173, saving model to best.model\n",
      "0s - loss: 0.3113 - acc: 0.8814 - val_loss: 0.2717 - val_acc: 0.9036\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.27173 to 0.26824, saving model to best.model\n",
      "0s - loss: 0.2931 - acc: 0.8921 - val_loss: 0.2682 - val_acc: 0.9085\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26824 to 0.26155, saving model to best.model\n",
      "0s - loss: 0.2984 - acc: 0.8907 - val_loss: 0.2616 - val_acc: 0.9075\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.26155 to 0.25578, saving model to best.model\n",
      "0s - loss: 0.2817 - acc: 0.9011 - val_loss: 0.2558 - val_acc: 0.9056\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2851 - acc: 0.8975 - val_loss: 0.2616 - val_acc: 0.9104\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25578 to 0.24887, saving model to best.model\n",
      "0s - loss: 0.2693 - acc: 0.9050 - val_loss: 0.2489 - val_acc: 0.9085\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2707 - acc: 0.9055 - val_loss: 0.2528 - val_acc: 0.9133\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24887 to 0.24354, saving model to best.model\n",
      "0s - loss: 0.2611 - acc: 0.9058 - val_loss: 0.2435 - val_acc: 0.9114\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.24354 to 0.23966, saving model to best.model\n",
      "0s - loss: 0.2620 - acc: 0.9109 - val_loss: 0.2397 - val_acc: 0.9094\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23966 to 0.23501, saving model to best.model\n",
      "0s - loss: 0.2624 - acc: 0.9102 - val_loss: 0.2350 - val_acc: 0.9133\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2507 - acc: 0.9145 - val_loss: 0.2431 - val_acc: 0.9143\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.23501 to 0.23310, saving model to best.model\n",
      "0s - loss: 0.2543 - acc: 0.9116 - val_loss: 0.2331 - val_acc: 0.9172\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.23310 to 0.22960, saving model to best.model\n",
      "0s - loss: 0.2395 - acc: 0.9201 - val_loss: 0.2296 - val_acc: 0.9133\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2407 - acc: 0.9148 - val_loss: 0.2309 - val_acc: 0.9172\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.22960 to 0.22367, saving model to best.model\n",
      "0s - loss: 0.2371 - acc: 0.9187 - val_loss: 0.2237 - val_acc: 0.9211\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.22367 to 0.21851, saving model to best.model\n",
      "0s - loss: 0.2375 - acc: 0.9179 - val_loss: 0.2185 - val_acc: 0.9221\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.21851 to 0.21845, saving model to best.model\n",
      "0s - loss: 0.2360 - acc: 0.9209 - val_loss: 0.2184 - val_acc: 0.9241\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.21845 to 0.21591, saving model to best.model\n",
      "0s - loss: 0.2347 - acc: 0.9170 - val_loss: 0.2159 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.2277 - acc: 0.9218 - val_loss: 0.2174 - val_acc: 0.9250\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.21591 to 0.20748, saving model to best.model\n",
      "0s - loss: 0.2319 - acc: 0.9216 - val_loss: 0.2075 - val_acc: 0.9202\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.2265 - acc: 0.9218 - val_loss: 0.2101 - val_acc: 0.9260\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2137 - acc: 0.9233 - val_loss: 0.2096 - val_acc: 0.9250\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.20748 to 0.19978, saving model to best.model\n",
      "0s - loss: 0.2231 - acc: 0.9226 - val_loss: 0.1998 - val_acc: 0.9270\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.19978 to 0.19937, saving model to best.model\n",
      "0s - loss: 0.2169 - acc: 0.9235 - val_loss: 0.1994 - val_acc: 0.9279\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.19937 to 0.19687, saving model to best.model\n",
      "0s - loss: 0.2070 - acc: 0.9279 - val_loss: 0.1969 - val_acc: 0.9289\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.19687 to 0.19165, saving model to best.model\n",
      "0s - loss: 0.2115 - acc: 0.9252 - val_loss: 0.1916 - val_acc: 0.9241\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.19165 to 0.18993, saving model to best.model\n",
      "0s - loss: 0.2104 - acc: 0.9282 - val_loss: 0.1899 - val_acc: 0.9289\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.18993 to 0.18478, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9299 - val_loss: 0.1848 - val_acc: 0.9260\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.2036 - acc: 0.9287 - val_loss: 0.1903 - val_acc: 0.9289\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.18478 to 0.18165, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9321 - val_loss: 0.1816 - val_acc: 0.9270\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.18165 to 0.18019, saving model to best.model\n",
      "0s - loss: 0.1941 - acc: 0.9333 - val_loss: 0.1802 - val_acc: 0.9318\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.18019 to 0.17833, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9328 - val_loss: 0.1783 - val_acc: 0.9318\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.17833 to 0.17718, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9340 - val_loss: 0.1772 - val_acc: 0.9318\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.17718 to 0.16817, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9291 - val_loss: 0.1682 - val_acc: 0.9299\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.16817 to 0.16783, saving model to best.model\n",
      "0s - loss: 0.1836 - acc: 0.9330 - val_loss: 0.1678 - val_acc: 0.9357\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.16783 to 0.16506, saving model to best.model\n",
      "0s - loss: 0.1804 - acc: 0.9382 - val_loss: 0.1651 - val_acc: 0.9367\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.16506 to 0.16137, saving model to best.model\n",
      "0s - loss: 0.1729 - acc: 0.9425 - val_loss: 0.1614 - val_acc: 0.9416\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.16137 to 0.15454, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9386 - val_loss: 0.1545 - val_acc: 0.9338\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9399 - val_loss: 0.1571 - val_acc: 0.9426\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.15454 to 0.15398, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9411 - val_loss: 0.1540 - val_acc: 0.9416\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1686 - acc: 0.9421 - val_loss: 0.1562 - val_acc: 0.9406\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.15398 to 0.14800, saving model to best.model\n",
      "0s - loss: 0.1635 - acc: 0.9440 - val_loss: 0.1480 - val_acc: 0.9406\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.14800 to 0.14615, saving model to best.model\n",
      "0s - loss: 0.1627 - acc: 0.9425 - val_loss: 0.1461 - val_acc: 0.9455\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.14615 to 0.14023, saving model to best.model\n",
      "0s - loss: 0.1590 - acc: 0.9428 - val_loss: 0.1402 - val_acc: 0.9503\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.14023 to 0.13631, saving model to best.model\n",
      "0s - loss: 0.1537 - acc: 0.9452 - val_loss: 0.1363 - val_acc: 0.9591\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.13631 to 0.13234, saving model to best.model\n",
      "0s - loss: 0.1523 - acc: 0.9435 - val_loss: 0.1323 - val_acc: 0.9562\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1516 - acc: 0.9452 - val_loss: 0.1474 - val_acc: 0.9416\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.13234 to 0.12737, saving model to best.model\n",
      "0s - loss: 0.1556 - acc: 0.9450 - val_loss: 0.1274 - val_acc: 0.9601\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1444 - acc: 0.9484 - val_loss: 0.1349 - val_acc: 0.9513\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.12737 to 0.12368, saving model to best.model\n",
      "0s - loss: 0.1422 - acc: 0.9498 - val_loss: 0.1237 - val_acc: 0.9630\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.12368 to 0.11754, saving model to best.model\n",
      "0s - loss: 0.1493 - acc: 0.9459 - val_loss: 0.1175 - val_acc: 0.9659\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.11754 to 0.11362, saving model to best.model\n",
      "0s - loss: 0.1410 - acc: 0.9494 - val_loss: 0.1136 - val_acc: 0.9679\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1382 - acc: 0.9520 - val_loss: 0.1205 - val_acc: 0.9630\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1307 - acc: 0.9533 - val_loss: 0.1138 - val_acc: 0.9679\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.11362 to 0.10374, saving model to best.model\n",
      "0s - loss: 0.1354 - acc: 0.9513 - val_loss: 0.1037 - val_acc: 0.9669\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1260 - acc: 0.9557 - val_loss: 0.1089 - val_acc: 0.9630\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.10374 to 0.10135, saving model to best.model\n",
      "0s - loss: 0.1330 - acc: 0.9533 - val_loss: 0.1013 - val_acc: 0.9688\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.10135 to 0.09212, saving model to best.model\n",
      "0s - loss: 0.1224 - acc: 0.9545 - val_loss: 0.0921 - val_acc: 0.9698\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.09212 to 0.09019, saving model to best.model\n",
      "0s - loss: 0.1291 - acc: 0.9559 - val_loss: 0.0902 - val_acc: 0.9669\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.09019 to 0.08871, saving model to best.model\n",
      "0s - loss: 0.1131 - acc: 0.9591 - val_loss: 0.0887 - val_acc: 0.9698\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.08871 to 0.08477, saving model to best.model\n",
      "0s - loss: 0.1156 - acc: 0.9591 - val_loss: 0.0848 - val_acc: 0.9688\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.08477 to 0.08322, saving model to best.model\n",
      "0s - loss: 0.1101 - acc: 0.9618 - val_loss: 0.0832 - val_acc: 0.9718\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.08322 to 0.07339, saving model to best.model\n",
      "0s - loss: 0.1056 - acc: 0.9620 - val_loss: 0.0734 - val_acc: 0.9718\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07339 to 0.07283, saving model to best.model\n",
      "0s - loss: 0.1111 - acc: 0.9596 - val_loss: 0.0728 - val_acc: 0.9718\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1041 - acc: 0.9618 - val_loss: 0.0735 - val_acc: 0.9737\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.07283 to 0.06480, saving model to best.model\n",
      "0s - loss: 0.1052 - acc: 0.9627 - val_loss: 0.0648 - val_acc: 0.9737\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1039 - acc: 0.9627 - val_loss: 0.0677 - val_acc: 0.9747\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06480 to 0.05943, saving model to best.model\n",
      "0s - loss: 0.0937 - acc: 0.9645 - val_loss: 0.0594 - val_acc: 0.9737\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1004 - acc: 0.9640 - val_loss: 0.0604 - val_acc: 0.9766\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0960 - acc: 0.9674 - val_loss: 0.0600 - val_acc: 0.9757\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05943 to 0.05368, saving model to best.model\n",
      "0s - loss: 0.0924 - acc: 0.9652 - val_loss: 0.0537 - val_acc: 0.9757\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05368 to 0.04953, saving model to best.model\n",
      "0s - loss: 0.0871 - acc: 0.9679 - val_loss: 0.0495 - val_acc: 0.9776\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0872 - acc: 0.9686 - val_loss: 0.0690 - val_acc: 0.9747\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04953 to 0.04679, saving model to best.model\n",
      "0s - loss: 0.0857 - acc: 0.9696 - val_loss: 0.0468 - val_acc: 0.9815\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04679 to 0.04660, saving model to best.model\n",
      "0s - loss: 0.0885 - acc: 0.9662 - val_loss: 0.0466 - val_acc: 0.9786\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0891 - acc: 0.9669 - val_loss: 0.0488 - val_acc: 0.9786\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04660 to 0.04439, saving model to best.model\n",
      "0s - loss: 0.0838 - acc: 0.9671 - val_loss: 0.0444 - val_acc: 0.9776\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04439 to 0.04366, saving model to best.model\n",
      "0s - loss: 0.0850 - acc: 0.9683 - val_loss: 0.0437 - val_acc: 0.9766\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04366 to 0.04003, saving model to best.model\n",
      "0s - loss: 0.0728 - acc: 0.9735 - val_loss: 0.0400 - val_acc: 0.9815\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0756 - acc: 0.9713 - val_loss: 0.0402 - val_acc: 0.9815\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04003 to 0.03826, saving model to best.model\n",
      "0s - loss: 0.0705 - acc: 0.9737 - val_loss: 0.0383 - val_acc: 0.9815\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0738 - acc: 0.9718 - val_loss: 0.0427 - val_acc: 0.9805\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0716 - acc: 0.9715 - val_loss: 0.0415 - val_acc: 0.9796\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03826 to 0.03490, saving model to best.model\n",
      "0s - loss: 0.0709 - acc: 0.9720 - val_loss: 0.0349 - val_acc: 0.9844\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0745 - acc: 0.9732 - val_loss: 0.0386 - val_acc: 0.9825\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0763 - acc: 0.9722 - val_loss: 0.0407 - val_acc: 0.9825\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03490 to 0.03361, saving model to best.model\n",
      "0s - loss: 0.0722 - acc: 0.9735 - val_loss: 0.0336 - val_acc: 0.9834\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0684 - acc: 0.9742 - val_loss: 0.0405 - val_acc: 0.9834\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0704 - acc: 0.9766 - val_loss: 0.0349 - val_acc: 0.9825\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03361 to 0.03260, saving model to best.model\n",
      "0s - loss: 0.0613 - acc: 0.9769 - val_loss: 0.0326 - val_acc: 0.9844\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0577 - acc: 0.9795 - val_loss: 0.0410 - val_acc: 0.9825\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03260 to 0.02979, saving model to best.model\n",
      "0s - loss: 0.0618 - acc: 0.9761 - val_loss: 0.0298 - val_acc: 0.9854\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02979 to 0.02821, saving model to best.model\n",
      "0s - loss: 0.0552 - acc: 0.9788 - val_loss: 0.0282 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0816 - acc: 0.9720 - val_loss: 0.0483 - val_acc: 0.9796\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0772 - acc: 0.9713 - val_loss: 0.0352 - val_acc: 0.9854\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02821 to 0.02805, saving model to best.model\n",
      "0s - loss: 0.0662 - acc: 0.9752 - val_loss: 0.0281 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9774 - val_loss: 0.0306 - val_acc: 0.9883\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0563 - acc: 0.9808 - val_loss: 0.0284 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0548 - acc: 0.9781 - val_loss: 0.0283 - val_acc: 0.9893\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0594 - acc: 0.9776 - val_loss: 0.0302 - val_acc: 0.9873\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02805 to 0.02621, saving model to best.model\n",
      "0s - loss: 0.0530 - acc: 0.9817 - val_loss: 0.0262 - val_acc: 0.9912\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02621 to 0.02440, saving model to best.model\n",
      "0s - loss: 0.0619 - acc: 0.9754 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0546 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02440 to 0.02334, saving model to best.model\n",
      "0s - loss: 0.0564 - acc: 0.9776 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0547 - acc: 0.9800 - val_loss: 0.0257 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9805 - val_loss: 0.0257 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02334 to 0.02118, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9808 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0486 - acc: 0.9817 - val_loss: 0.0351 - val_acc: 0.9844\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9793 - val_loss: 0.0244 - val_acc: 0.9932\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9849 - val_loss: 0.0220 - val_acc: 0.9903\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9842 - val_loss: 0.0226 - val_acc: 0.9942\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0499 - acc: 0.9805 - val_loss: 0.0277 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02118 to 0.01914, saving model to best.model\n",
      "0s - loss: 0.0527 - acc: 0.9815 - val_loss: 0.0191 - val_acc: 0.9961\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0527 - acc: 0.9791 - val_loss: 0.0211 - val_acc: 0.9951\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9842 - val_loss: 0.0203 - val_acc: 0.9951\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9871 - val_loss: 0.0192 - val_acc: 0.9961\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01914 to 0.01815, saving model to best.model\n",
      "0s - loss: 0.0472 - acc: 0.9827 - val_loss: 0.0182 - val_acc: 0.9922\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9839 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9786 - val_loss: 0.0195 - val_acc: 0.9922\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9830 - val_loss: 0.0211 - val_acc: 0.9932\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0476 - acc: 0.9820 - val_loss: 0.0185 - val_acc: 0.9961\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9830 - val_loss: 0.0187 - val_acc: 0.9951\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01815 to 0.01729, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9842 - val_loss: 0.0173 - val_acc: 0.9951\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9842 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01729 to 0.01665, saving model to best.model\n",
      "0s - loss: 0.0414 - acc: 0.9839 - val_loss: 0.0166 - val_acc: 0.9932\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9830 - val_loss: 0.0218 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01665 to 0.01619, saving model to best.model\n",
      "0s - loss: 0.0376 - acc: 0.9849 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9856 - val_loss: 0.0165 - val_acc: 0.9961\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9832 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0414 - acc: 0.9844 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.01619 to 0.01539, saving model to best.model\n",
      "0s - loss: 0.0390 - acc: 0.9832 - val_loss: 0.0154 - val_acc: 0.9961\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9839 - val_loss: 0.0155 - val_acc: 0.9961\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0440 - acc: 0.9839 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01539 to 0.01439, saving model to best.model\n",
      "0s - loss: 0.0365 - acc: 0.9847 - val_loss: 0.0144 - val_acc: 0.9971\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9876 - val_loss: 0.0147 - val_acc: 0.9961\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.01439 to 0.01420, saving model to best.model\n",
      "0s - loss: 0.0401 - acc: 0.9851 - val_loss: 0.0142 - val_acc: 0.9971\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9805 - val_loss: 0.0205 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9864 - val_loss: 0.0146 - val_acc: 0.9961\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9844 - val_loss: 0.0147 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9866 - val_loss: 0.0146 - val_acc: 0.9961\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9864 - val_loss: 0.0152 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01420 to 0.01242, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9890 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9859 - val_loss: 0.0142 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9866 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9856 - val_loss: 0.0138 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9871 - val_loss: 0.0133 - val_acc: 0.9932\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9895 - val_loss: 0.0151 - val_acc: 0.9951\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9876 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9861 - val_loss: 0.0129 - val_acc: 0.9961\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9864 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01242 to 0.01185, saving model to best.model\n",
      "0s - loss: 0.0322 - acc: 0.9871 - val_loss: 0.0118 - val_acc: 0.9981\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9861 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9878 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01185 to 0.01180, saving model to best.model\n",
      "0s - loss: 0.0319 - acc: 0.9898 - val_loss: 0.0118 - val_acc: 0.9971\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9893 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01180 to 0.01164, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9869 - val_loss: 0.0116 - val_acc: 0.9981\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9890 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01164 to 0.01116, saving model to best.model\n",
      "0s - loss: 0.0296 - acc: 0.9900 - val_loss: 0.0112 - val_acc: 0.9981\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01116 to 0.01053, saving model to best.model\n",
      "0s - loss: 0.0328 - acc: 0.9873 - val_loss: 0.0105 - val_acc: 0.9981\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01053 to 0.01015, saving model to best.model\n",
      "0s - loss: 0.0290 - acc: 0.9907 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9893 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01015 to 0.00972, saving model to best.model\n",
      "0s - loss: 0.0257 - acc: 0.9895 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9907 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.00972 to 0.00913, saving model to best.model\n",
      "0s - loss: 0.0320 - acc: 0.9873 - val_loss: 0.0091 - val_acc: 0.9981\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9873 - val_loss: 0.0102 - val_acc: 0.9981\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9900 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9881 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0252 - acc: 0.9910 - val_loss: 0.0103 - val_acc: 0.9971\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9905 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9888 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0253 - acc: 0.9895 - val_loss: 0.0100 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9854 - val_loss: 0.0093 - val_acc: 0.9981\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00913 to 0.00811, saving model to best.model\n",
      "0s - loss: 0.0247 - acc: 0.9912 - val_loss: 0.0081 - val_acc: 0.9981\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0212 - acc: 0.9915 - val_loss: 0.0092 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0240 - acc: 0.9910 - val_loss: 0.0087 - val_acc: 0.9981\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9890 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.00811 to 0.00779, saving model to best.model\n",
      "0s - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0078 - val_acc: 0.9990\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9854 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9895 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0250 - acc: 0.9907 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.65662, saving model to best.model\n",
      "0s - loss: 0.8140 - acc: 0.5057 - val_loss: 0.6566 - val_acc: 0.7488\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.65662 to 0.62221, saving model to best.model\n",
      "0s - loss: 0.7306 - acc: 0.5481 - val_loss: 0.6222 - val_acc: 0.7390\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.62221 to 0.56267, saving model to best.model\n",
      "0s - loss: 0.6698 - acc: 0.5944 - val_loss: 0.5627 - val_acc: 0.8082\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.56267 to 0.47885, saving model to best.model\n",
      "0s - loss: 0.5987 - acc: 0.6710 - val_loss: 0.4789 - val_acc: 0.8277\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.47885 to 0.41979, saving model to best.model\n",
      "0s - loss: 0.5154 - acc: 0.7477 - val_loss: 0.4198 - val_acc: 0.8345\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.41979 to 0.39443, saving model to best.model\n",
      "0s - loss: 0.4734 - acc: 0.7784 - val_loss: 0.3944 - val_acc: 0.8423\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39443 to 0.35973, saving model to best.model\n",
      "0s - loss: 0.4295 - acc: 0.8115 - val_loss: 0.3597 - val_acc: 0.8569\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35973 to 0.33952, saving model to best.model\n",
      "0s - loss: 0.4086 - acc: 0.8281 - val_loss: 0.3395 - val_acc: 0.8676\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33952 to 0.32025, saving model to best.model\n",
      "0s - loss: 0.3928 - acc: 0.8420 - val_loss: 0.3202 - val_acc: 0.8666\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32025 to 0.31128, saving model to best.model\n",
      "0s - loss: 0.3714 - acc: 0.8551 - val_loss: 0.3113 - val_acc: 0.8656\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31128 to 0.29545, saving model to best.model\n",
      "0s - loss: 0.3583 - acc: 0.8578 - val_loss: 0.2955 - val_acc: 0.8744\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29545 to 0.28380, saving model to best.model\n",
      "0s - loss: 0.3473 - acc: 0.8668 - val_loss: 0.2838 - val_acc: 0.8754\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28380 to 0.27494, saving model to best.model\n",
      "0s - loss: 0.3307 - acc: 0.8692 - val_loss: 0.2749 - val_acc: 0.8802\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27494 to 0.26354, saving model to best.model\n",
      "0s - loss: 0.3275 - acc: 0.8739 - val_loss: 0.2635 - val_acc: 0.8870\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26354 to 0.26186, saving model to best.model\n",
      "0s - loss: 0.3153 - acc: 0.8783 - val_loss: 0.2619 - val_acc: 0.8909\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26186 to 0.25138, saving model to best.model\n",
      "0s - loss: 0.3202 - acc: 0.8763 - val_loss: 0.2514 - val_acc: 0.8929\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.3025 - acc: 0.8834 - val_loss: 0.2568 - val_acc: 0.8987\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25138 to 0.24062, saving model to best.model\n",
      "0s - loss: 0.2977 - acc: 0.8875 - val_loss: 0.2406 - val_acc: 0.9007\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24062 to 0.23725, saving model to best.model\n",
      "0s - loss: 0.2946 - acc: 0.8926 - val_loss: 0.2373 - val_acc: 0.9026\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23725 to 0.22862, saving model to best.model\n",
      "0s - loss: 0.2878 - acc: 0.8873 - val_loss: 0.2286 - val_acc: 0.9094\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22862 to 0.22321, saving model to best.model\n",
      "0s - loss: 0.2836 - acc: 0.8938 - val_loss: 0.2232 - val_acc: 0.9124\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22321 to 0.22140, saving model to best.model\n",
      "0s - loss: 0.2761 - acc: 0.8975 - val_loss: 0.2214 - val_acc: 0.9133\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22140 to 0.21632, saving model to best.model\n",
      "0s - loss: 0.2768 - acc: 0.8987 - val_loss: 0.2163 - val_acc: 0.9202\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21632 to 0.21390, saving model to best.model\n",
      "0s - loss: 0.2744 - acc: 0.8997 - val_loss: 0.2139 - val_acc: 0.9163\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21390 to 0.21008, saving model to best.model\n",
      "0s - loss: 0.2623 - acc: 0.9050 - val_loss: 0.2101 - val_acc: 0.9182\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21008 to 0.20574, saving model to best.model\n",
      "0s - loss: 0.2622 - acc: 0.9031 - val_loss: 0.2057 - val_acc: 0.9182\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20574 to 0.20520, saving model to best.model\n",
      "0s - loss: 0.2589 - acc: 0.9063 - val_loss: 0.2052 - val_acc: 0.9182\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20520 to 0.20221, saving model to best.model\n",
      "0s - loss: 0.2512 - acc: 0.9063 - val_loss: 0.2022 - val_acc: 0.9250\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20221 to 0.19828, saving model to best.model\n",
      "0s - loss: 0.2613 - acc: 0.8992 - val_loss: 0.1983 - val_acc: 0.9192\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2529 - acc: 0.9048 - val_loss: 0.2014 - val_acc: 0.9172\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19828 to 0.19311, saving model to best.model\n",
      "0s - loss: 0.2462 - acc: 0.9089 - val_loss: 0.1931 - val_acc: 0.9231\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19311 to 0.18823, saving model to best.model\n",
      "0s - loss: 0.2396 - acc: 0.9136 - val_loss: 0.1882 - val_acc: 0.9221\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18823 to 0.18174, saving model to best.model\n",
      "0s - loss: 0.2436 - acc: 0.9140 - val_loss: 0.1817 - val_acc: 0.9279\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18174 to 0.17833, saving model to best.model\n",
      "0s - loss: 0.2333 - acc: 0.9177 - val_loss: 0.1783 - val_acc: 0.9299\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17833 to 0.17770, saving model to best.model\n",
      "0s - loss: 0.2314 - acc: 0.9148 - val_loss: 0.1777 - val_acc: 0.9309\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17770 to 0.17322, saving model to best.model\n",
      "0s - loss: 0.2245 - acc: 0.9167 - val_loss: 0.1732 - val_acc: 0.9289\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17322 to 0.16888, saving model to best.model\n",
      "0s - loss: 0.2267 - acc: 0.9182 - val_loss: 0.1689 - val_acc: 0.9338\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16888 to 0.16522, saving model to best.model\n",
      "0s - loss: 0.2262 - acc: 0.9170 - val_loss: 0.1652 - val_acc: 0.9338\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16522 to 0.16224, saving model to best.model\n",
      "0s - loss: 0.2237 - acc: 0.9175 - val_loss: 0.1622 - val_acc: 0.9348\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16224 to 0.15993, saving model to best.model\n",
      "0s - loss: 0.2162 - acc: 0.9201 - val_loss: 0.1599 - val_acc: 0.9338\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15993 to 0.15780, saving model to best.model\n",
      "0s - loss: 0.2148 - acc: 0.9214 - val_loss: 0.1578 - val_acc: 0.9338\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15780 to 0.15389, saving model to best.model\n",
      "0s - loss: 0.2104 - acc: 0.9184 - val_loss: 0.1539 - val_acc: 0.9367\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15389 to 0.15120, saving model to best.model\n",
      "0s - loss: 0.2093 - acc: 0.9192 - val_loss: 0.1512 - val_acc: 0.9396\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15120 to 0.14632, saving model to best.model\n",
      "0s - loss: 0.2008 - acc: 0.9270 - val_loss: 0.1463 - val_acc: 0.9416\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14632 to 0.14473, saving model to best.model\n",
      "0s - loss: 0.2003 - acc: 0.9262 - val_loss: 0.1447 - val_acc: 0.9387\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14473 to 0.14242, saving model to best.model\n",
      "0s - loss: 0.1996 - acc: 0.9255 - val_loss: 0.1424 - val_acc: 0.9406\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14242 to 0.13774, saving model to best.model\n",
      "0s - loss: 0.1856 - acc: 0.9301 - val_loss: 0.1377 - val_acc: 0.9435\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1984 - acc: 0.9270 - val_loss: 0.1441 - val_acc: 0.9348\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13774 to 0.13191, saving model to best.model\n",
      "0s - loss: 0.1940 - acc: 0.9245 - val_loss: 0.1319 - val_acc: 0.9464\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1836 - acc: 0.9257 - val_loss: 0.1354 - val_acc: 0.9377\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.13191 to 0.12788, saving model to best.model\n",
      "0s - loss: 0.1762 - acc: 0.9326 - val_loss: 0.1279 - val_acc: 0.9455\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1854 - acc: 0.9274 - val_loss: 0.1283 - val_acc: 0.9396\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.12788 to 0.12176, saving model to best.model\n",
      "0s - loss: 0.1776 - acc: 0.9270 - val_loss: 0.1218 - val_acc: 0.9445\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.12176 to 0.11689, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9301 - val_loss: 0.1169 - val_acc: 0.9513\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1699 - acc: 0.9338 - val_loss: 0.1227 - val_acc: 0.9416\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.11689 to 0.11237, saving model to best.model\n",
      "0s - loss: 0.1750 - acc: 0.9304 - val_loss: 0.1124 - val_acc: 0.9503\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.11237 to 0.10876, saving model to best.model\n",
      "0s - loss: 0.1621 - acc: 0.9369 - val_loss: 0.1088 - val_acc: 0.9503\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10876 to 0.10691, saving model to best.model\n",
      "0s - loss: 0.1567 - acc: 0.9367 - val_loss: 0.1069 - val_acc: 0.9494\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.10691 to 0.10292, saving model to best.model\n",
      "0s - loss: 0.1555 - acc: 0.9403 - val_loss: 0.1029 - val_acc: 0.9513\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.10292 to 0.10161, saving model to best.model\n",
      "0s - loss: 0.1516 - acc: 0.9364 - val_loss: 0.1016 - val_acc: 0.9484\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1572 - acc: 0.9396 - val_loss: 0.1040 - val_acc: 0.9484\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10161 to 0.09638, saving model to best.model\n",
      "0s - loss: 0.1459 - acc: 0.9384 - val_loss: 0.0964 - val_acc: 0.9523\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.09638 to 0.09254, saving model to best.model\n",
      "0s - loss: 0.1521 - acc: 0.9389 - val_loss: 0.0925 - val_acc: 0.9591\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1492 - acc: 0.9399 - val_loss: 0.0968 - val_acc: 0.9503\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.09254 to 0.09173, saving model to best.model\n",
      "0s - loss: 0.1436 - acc: 0.9413 - val_loss: 0.0917 - val_acc: 0.9562\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09173 to 0.08494, saving model to best.model\n",
      "0s - loss: 0.1451 - acc: 0.9418 - val_loss: 0.0849 - val_acc: 0.9669\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1388 - acc: 0.9467 - val_loss: 0.0881 - val_acc: 0.9562\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.08494 to 0.08032, saving model to best.model\n",
      "0s - loss: 0.1276 - acc: 0.9491 - val_loss: 0.0803 - val_acc: 0.9688\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1290 - acc: 0.9481 - val_loss: 0.0811 - val_acc: 0.9649\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08032 to 0.07866, saving model to best.model\n",
      "0s - loss: 0.1267 - acc: 0.9430 - val_loss: 0.0787 - val_acc: 0.9688\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.07866 to 0.07753, saving model to best.model\n",
      "0s - loss: 0.1217 - acc: 0.9508 - val_loss: 0.0775 - val_acc: 0.9718\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1254 - acc: 0.9506 - val_loss: 0.0831 - val_acc: 0.9669\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07753 to 0.07088, saving model to best.model\n",
      "0s - loss: 0.1239 - acc: 0.9491 - val_loss: 0.0709 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07088 to 0.06782, saving model to best.model\n",
      "0s - loss: 0.1120 - acc: 0.9530 - val_loss: 0.0678 - val_acc: 0.9757\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1163 - acc: 0.9533 - val_loss: 0.0721 - val_acc: 0.9786\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06782 to 0.06753, saving model to best.model\n",
      "0s - loss: 0.1154 - acc: 0.9535 - val_loss: 0.0675 - val_acc: 0.9747\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06753 to 0.06353, saving model to best.model\n",
      "0s - loss: 0.1080 - acc: 0.9574 - val_loss: 0.0635 - val_acc: 0.9786\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1138 - acc: 0.9537 - val_loss: 0.0722 - val_acc: 0.9776\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06353 to 0.06136, saving model to best.model\n",
      "0s - loss: 0.1057 - acc: 0.9586 - val_loss: 0.0614 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06136 to 0.05849, saving model to best.model\n",
      "0s - loss: 0.1078 - acc: 0.9564 - val_loss: 0.0585 - val_acc: 0.9776\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1010 - acc: 0.9579 - val_loss: 0.0593 - val_acc: 0.9796\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05849 to 0.05587, saving model to best.model\n",
      "0s - loss: 0.1028 - acc: 0.9608 - val_loss: 0.0559 - val_acc: 0.9834\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0935 - acc: 0.9640 - val_loss: 0.0576 - val_acc: 0.9825\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05587 to 0.05228, saving model to best.model\n",
      "0s - loss: 0.0949 - acc: 0.9625 - val_loss: 0.0523 - val_acc: 0.9834\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0978 - acc: 0.9608 - val_loss: 0.0536 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05228 to 0.04891, saving model to best.model\n",
      "0s - loss: 0.0905 - acc: 0.9645 - val_loss: 0.0489 - val_acc: 0.9844\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04891 to 0.04591, saving model to best.model\n",
      "0s - loss: 0.0887 - acc: 0.9679 - val_loss: 0.0459 - val_acc: 0.9844\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04591 to 0.04269, saving model to best.model\n",
      "0s - loss: 0.0817 - acc: 0.9683 - val_loss: 0.0427 - val_acc: 0.9873\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0860 - acc: 0.9652 - val_loss: 0.0494 - val_acc: 0.9844\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0866 - acc: 0.9674 - val_loss: 0.0463 - val_acc: 0.9854\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0858 - acc: 0.9647 - val_loss: 0.0434 - val_acc: 0.9854\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04269 to 0.04176, saving model to best.model\n",
      "0s - loss: 0.0806 - acc: 0.9718 - val_loss: 0.0418 - val_acc: 0.9883\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0845 - acc: 0.9652 - val_loss: 0.0423 - val_acc: 0.9864\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0793 - acc: 0.9713 - val_loss: 0.0464 - val_acc: 0.9854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0730 - acc: 0.9722 - val_loss: 0.0442 - val_acc: 0.9864\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04176 to 0.03653, saving model to best.model\n",
      "0s - loss: 0.0790 - acc: 0.9671 - val_loss: 0.0365 - val_acc: 0.9873\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0806 - acc: 0.9664 - val_loss: 0.0366 - val_acc: 0.9864\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0753 - acc: 0.9715 - val_loss: 0.0437 - val_acc: 0.9864\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03653 to 0.03431, saving model to best.model\n",
      "0s - loss: 0.0739 - acc: 0.9715 - val_loss: 0.0343 - val_acc: 0.9883\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0728 - acc: 0.9744 - val_loss: 0.0388 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0740 - acc: 0.9720 - val_loss: 0.0354 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03431 to 0.03228, saving model to best.model\n",
      "0s - loss: 0.0755 - acc: 0.9688 - val_loss: 0.0323 - val_acc: 0.9893\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0712 - acc: 0.9737 - val_loss: 0.0352 - val_acc: 0.9893\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03228 to 0.03173, saving model to best.model\n",
      "0s - loss: 0.0751 - acc: 0.9696 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03173 to 0.03076, saving model to best.model\n",
      "0s - loss: 0.0653 - acc: 0.9771 - val_loss: 0.0308 - val_acc: 0.9893\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03076 to 0.03054, saving model to best.model\n",
      "0s - loss: 0.0702 - acc: 0.9715 - val_loss: 0.0305 - val_acc: 0.9883\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0768 - acc: 0.9698 - val_loss: 0.0333 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03054 to 0.03018, saving model to best.model\n",
      "0s - loss: 0.0678 - acc: 0.9739 - val_loss: 0.0302 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0656 - acc: 0.9722 - val_loss: 0.0331 - val_acc: 0.9883\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03018 to 0.02919, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9752 - val_loss: 0.0292 - val_acc: 0.9893\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02919 to 0.02813, saving model to best.model\n",
      "0s - loss: 0.0649 - acc: 0.9788 - val_loss: 0.0281 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02813 to 0.02705, saving model to best.model\n",
      "0s - loss: 0.0654 - acc: 0.9761 - val_loss: 0.0271 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9759 - val_loss: 0.0297 - val_acc: 0.9883\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02705 to 0.02446, saving model to best.model\n",
      "0s - loss: 0.0582 - acc: 0.9805 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9749 - val_loss: 0.0304 - val_acc: 0.9893\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0648 - acc: 0.9752 - val_loss: 0.0269 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0626 - acc: 0.9735 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9815 - val_loss: 0.0306 - val_acc: 0.9893\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02446 to 0.02350, saving model to best.model\n",
      "0s - loss: 0.0621 - acc: 0.9766 - val_loss: 0.0235 - val_acc: 0.9903\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9764 - val_loss: 0.0289 - val_acc: 0.9893\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0605 - acc: 0.9757 - val_loss: 0.0248 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0578 - acc: 0.9769 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0545 - acc: 0.9774 - val_loss: 0.0256 - val_acc: 0.9903\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02350 to 0.02284, saving model to best.model\n",
      "0s - loss: 0.0513 - acc: 0.9832 - val_loss: 0.0228 - val_acc: 0.9903\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02284 to 0.02177, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9795 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9805 - val_loss: 0.0262 - val_acc: 0.9903\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0440 - acc: 0.9839 - val_loss: 0.0224 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9810 - val_loss: 0.0229 - val_acc: 0.9912\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9798 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0469 - acc: 0.9825 - val_loss: 0.0220 - val_acc: 0.9912\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02177 to 0.01825, saving model to best.model\n",
      "0s - loss: 0.0493 - acc: 0.9815 - val_loss: 0.0183 - val_acc: 0.9922\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0530 - acc: 0.9820 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0562 - acc: 0.9805 - val_loss: 0.0206 - val_acc: 0.9912\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0510 - acc: 0.9815 - val_loss: 0.0198 - val_acc: 0.9922\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9832 - val_loss: 0.0215 - val_acc: 0.9912\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9851 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9849 - val_loss: 0.0226 - val_acc: 0.9912\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0476 - acc: 0.9825 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0465 - acc: 0.9817 - val_loss: 0.0195 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9832 - val_loss: 0.0200 - val_acc: 0.9912\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9834 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0505 - acc: 0.9837 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9815 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01825 to 0.01651, saving model to best.model\n",
      "0s - loss: 0.0481 - acc: 0.9832 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9825 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9815 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9854 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9815 - val_loss: 0.0169 - val_acc: 0.9942\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9839 - val_loss: 0.0189 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01651 to 0.01543, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9822 - val_loss: 0.0154 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9830 - val_loss: 0.0232 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9861 - val_loss: 0.0158 - val_acc: 0.9942\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9837 - val_loss: 0.0219 - val_acc: 0.9912\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9859 - val_loss: 0.0168 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9859 - val_loss: 0.0186 - val_acc: 0.9922\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01543 to 0.01341, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9861 - val_loss: 0.0134 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9861 - val_loss: 0.0161 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9869 - val_loss: 0.0154 - val_acc: 0.9942\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9859 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9861 - val_loss: 0.0165 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9859 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9878 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9854 - val_loss: 0.0148 - val_acc: 0.9942\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9864 - val_loss: 0.0155 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9837 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9886 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9866 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9871 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9873 - val_loss: 0.0147 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9878 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0300 - acc: 0.9888 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9834 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9883 - val_loss: 0.0149 - val_acc: 0.9932\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.01341 to 0.01080, saving model to best.model\n",
      "0s - loss: 0.0343 - acc: 0.9876 - val_loss: 0.0108 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9866 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9883 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9881 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9881 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01080 to 0.01057, saving model to best.model\n",
      "0s - loss: 0.0268 - acc: 0.9907 - val_loss: 0.0106 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9876 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0144 - val_acc: 0.9932\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9888 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9893 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9910 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9886 - val_loss: 0.0166 - val_acc: 0.9922\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9883 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9907 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0273 - acc: 0.9873 - val_loss: 0.0134 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9888 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.01057 to 0.01006, saving model to best.model\n",
      "0s - loss: 0.0339 - acc: 0.9876 - val_loss: 0.0101 - val_acc: 0.9961\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9866 - val_loss: 0.0131 - val_acc: 0.9951\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9886 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.01006 to 0.00979, saving model to best.model\n",
      "0s - loss: 0.0273 - acc: 0.9903 - val_loss: 0.0098 - val_acc: 0.9961\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9883 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9900 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9910 - val_loss: 0.0152 - val_acc: 0.9942\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9893 - val_loss: 0.0124 - val_acc: 0.9951\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00979 to 0.00860, saving model to best.model\n",
      "0s - loss: 0.0324 - acc: 0.9883 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67408, saving model to best.model\n",
      "0s - loss: 0.7793 - acc: 0.5184 - val_loss: 0.6741 - val_acc: 0.4742\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67408 to 0.63421, saving model to best.model\n",
      "0s - loss: 0.7292 - acc: 0.5291 - val_loss: 0.6342 - val_acc: 0.7731\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63421 to 0.58425, saving model to best.model\n",
      "0s - loss: 0.6782 - acc: 0.5783 - val_loss: 0.5843 - val_acc: 0.7722\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58425 to 0.51086, saving model to best.model\n",
      "0s - loss: 0.6145 - acc: 0.6608 - val_loss: 0.5109 - val_acc: 0.8092\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51086 to 0.44675, saving model to best.model\n",
      "0s - loss: 0.5421 - acc: 0.7409 - val_loss: 0.4468 - val_acc: 0.8247\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44675 to 0.40314, saving model to best.model\n",
      "0s - loss: 0.4847 - acc: 0.7784 - val_loss: 0.4031 - val_acc: 0.8403\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40314 to 0.36868, saving model to best.model\n",
      "0s - loss: 0.4403 - acc: 0.8089 - val_loss: 0.3687 - val_acc: 0.8559\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36868 to 0.34530, saving model to best.model\n",
      "0s - loss: 0.4128 - acc: 0.8259 - val_loss: 0.3453 - val_acc: 0.8627\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34530 to 0.32512, saving model to best.model\n",
      "0s - loss: 0.3855 - acc: 0.8454 - val_loss: 0.3251 - val_acc: 0.8715\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32512 to 0.31047, saving model to best.model\n",
      "0s - loss: 0.3605 - acc: 0.8561 - val_loss: 0.3105 - val_acc: 0.8763\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31047 to 0.29835, saving model to best.model\n",
      "0s - loss: 0.3508 - acc: 0.8656 - val_loss: 0.2984 - val_acc: 0.8802\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29835 to 0.28842, saving model to best.model\n",
      "0s - loss: 0.3514 - acc: 0.8644 - val_loss: 0.2884 - val_acc: 0.8822\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28842 to 0.27991, saving model to best.model\n",
      "0s - loss: 0.3280 - acc: 0.8809 - val_loss: 0.2799 - val_acc: 0.8870\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27991 to 0.27157, saving model to best.model\n",
      "0s - loss: 0.3140 - acc: 0.8826 - val_loss: 0.2716 - val_acc: 0.8948\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27157 to 0.26327, saving model to best.model\n",
      "0s - loss: 0.3087 - acc: 0.8819 - val_loss: 0.2633 - val_acc: 0.8958\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26327 to 0.25654, saving model to best.model\n",
      "0s - loss: 0.2971 - acc: 0.8899 - val_loss: 0.2565 - val_acc: 0.9036\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25654 to 0.25026, saving model to best.model\n",
      "0s - loss: 0.2943 - acc: 0.8912 - val_loss: 0.2503 - val_acc: 0.9104\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25026 to 0.24446, saving model to best.model\n",
      "0s - loss: 0.2815 - acc: 0.9007 - val_loss: 0.2445 - val_acc: 0.9182\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24446 to 0.23937, saving model to best.model\n",
      "0s - loss: 0.2807 - acc: 0.9002 - val_loss: 0.2394 - val_acc: 0.9211\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2755 - acc: 0.9016 - val_loss: 0.2418 - val_acc: 0.9153\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23937 to 0.23351, saving model to best.model\n",
      "0s - loss: 0.2797 - acc: 0.8972 - val_loss: 0.2335 - val_acc: 0.9231\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23351 to 0.23158, saving model to best.model\n",
      "0s - loss: 0.2597 - acc: 0.9072 - val_loss: 0.2316 - val_acc: 0.9211\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23158 to 0.22653, saving model to best.model\n",
      "0s - loss: 0.2632 - acc: 0.9050 - val_loss: 0.2265 - val_acc: 0.9270\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22653 to 0.22224, saving model to best.model\n",
      "0s - loss: 0.2527 - acc: 0.9077 - val_loss: 0.2222 - val_acc: 0.9299\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22224 to 0.22119, saving model to best.model\n",
      "0s - loss: 0.2527 - acc: 0.9123 - val_loss: 0.2212 - val_acc: 0.9241\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.22119 to 0.21471, saving model to best.model\n",
      "0s - loss: 0.2552 - acc: 0.9119 - val_loss: 0.2147 - val_acc: 0.9318\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21471 to 0.21203, saving model to best.model\n",
      "0s - loss: 0.2450 - acc: 0.9114 - val_loss: 0.2120 - val_acc: 0.9338\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21203 to 0.20985, saving model to best.model\n",
      "0s - loss: 0.2458 - acc: 0.9143 - val_loss: 0.2099 - val_acc: 0.9338\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20985 to 0.20843, saving model to best.model\n",
      "0s - loss: 0.2404 - acc: 0.9160 - val_loss: 0.2084 - val_acc: 0.9338\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20843 to 0.20492, saving model to best.model\n",
      "0s - loss: 0.2363 - acc: 0.9140 - val_loss: 0.2049 - val_acc: 0.9279\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20492 to 0.20187, saving model to best.model\n",
      "0s - loss: 0.2350 - acc: 0.9162 - val_loss: 0.2019 - val_acc: 0.9348\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20187 to 0.20133, saving model to best.model\n",
      "0s - loss: 0.2317 - acc: 0.9196 - val_loss: 0.2013 - val_acc: 0.9250\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.20133 to 0.19633, saving model to best.model\n",
      "0s - loss: 0.2298 - acc: 0.9175 - val_loss: 0.1963 - val_acc: 0.9367\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19633 to 0.19077, saving model to best.model\n",
      "0s - loss: 0.2253 - acc: 0.9177 - val_loss: 0.1908 - val_acc: 0.9279\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19077 to 0.18797, saving model to best.model\n",
      "0s - loss: 0.2202 - acc: 0.9209 - val_loss: 0.1880 - val_acc: 0.9299\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18797 to 0.18710, saving model to best.model\n",
      "0s - loss: 0.2187 - acc: 0.9218 - val_loss: 0.1871 - val_acc: 0.9357\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18710 to 0.18201, saving model to best.model\n",
      "0s - loss: 0.2098 - acc: 0.9235 - val_loss: 0.1820 - val_acc: 0.9299\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18201 to 0.17899, saving model to best.model\n",
      "0s - loss: 0.2137 - acc: 0.9214 - val_loss: 0.1790 - val_acc: 0.9309\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17899 to 0.17667, saving model to best.model\n",
      "0s - loss: 0.2140 - acc: 0.9235 - val_loss: 0.1767 - val_acc: 0.9260\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17667 to 0.17282, saving model to best.model\n",
      "0s - loss: 0.2063 - acc: 0.9245 - val_loss: 0.1728 - val_acc: 0.9279\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17282 to 0.16911, saving model to best.model\n",
      "0s - loss: 0.2067 - acc: 0.9252 - val_loss: 0.1691 - val_acc: 0.9279\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1988 - acc: 0.9260 - val_loss: 0.1714 - val_acc: 0.9328\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.16911 to 0.16388, saving model to best.model\n",
      "0s - loss: 0.1959 - acc: 0.9291 - val_loss: 0.1639 - val_acc: 0.9309\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16388 to 0.16216, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9328 - val_loss: 0.1622 - val_acc: 0.9318\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16216 to 0.15752, saving model to best.model\n",
      "0s - loss: 0.1929 - acc: 0.9304 - val_loss: 0.1575 - val_acc: 0.9309\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15752 to 0.15230, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9311 - val_loss: 0.1523 - val_acc: 0.9338\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15230 to 0.15030, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9321 - val_loss: 0.1503 - val_acc: 0.9367\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15030 to 0.14594, saving model to best.model\n",
      "0s - loss: 0.1882 - acc: 0.9313 - val_loss: 0.1459 - val_acc: 0.9367\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14594 to 0.14415, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9355 - val_loss: 0.1442 - val_acc: 0.9328\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14415 to 0.13874, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9367 - val_loss: 0.1387 - val_acc: 0.9396\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.13874 to 0.13530, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9369 - val_loss: 0.1353 - val_acc: 0.9426\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13530 to 0.13377, saving model to best.model\n",
      "0s - loss: 0.1681 - acc: 0.9418 - val_loss: 0.1338 - val_acc: 0.9406\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13377 to 0.13164, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9399 - val_loss: 0.1316 - val_acc: 0.9406\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13164 to 0.12896, saving model to best.model\n",
      "0s - loss: 0.1692 - acc: 0.9418 - val_loss: 0.1290 - val_acc: 0.9513\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.12896 to 0.12433, saving model to best.model\n",
      "0s - loss: 0.1625 - acc: 0.9455 - val_loss: 0.1243 - val_acc: 0.9494\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12433 to 0.12037, saving model to best.model\n",
      "0s - loss: 0.1603 - acc: 0.9430 - val_loss: 0.1204 - val_acc: 0.9523\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12037 to 0.11662, saving model to best.model\n",
      "0s - loss: 0.1668 - acc: 0.9389 - val_loss: 0.1166 - val_acc: 0.9503\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1666 - acc: 0.9406 - val_loss: 0.1187 - val_acc: 0.9513\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11662 to 0.11228, saving model to best.model\n",
      "0s - loss: 0.1608 - acc: 0.9413 - val_loss: 0.1123 - val_acc: 0.9533\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11228 to 0.10865, saving model to best.model\n",
      "0s - loss: 0.1481 - acc: 0.9477 - val_loss: 0.1086 - val_acc: 0.9581\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.10865 to 0.10491, saving model to best.model\n",
      "0s - loss: 0.1505 - acc: 0.9477 - val_loss: 0.1049 - val_acc: 0.9630\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1481 - acc: 0.9498 - val_loss: 0.1085 - val_acc: 0.9562\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10491 to 0.10066, saving model to best.model\n",
      "0s - loss: 0.1435 - acc: 0.9530 - val_loss: 0.1007 - val_acc: 0.9630\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10066 to 0.09700, saving model to best.model\n",
      "0s - loss: 0.1366 - acc: 0.9503 - val_loss: 0.0970 - val_acc: 0.9669\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.09700 to 0.09432, saving model to best.model\n",
      "0s - loss: 0.1363 - acc: 0.9513 - val_loss: 0.0943 - val_acc: 0.9708\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09432 to 0.09361, saving model to best.model\n",
      "0s - loss: 0.1373 - acc: 0.9525 - val_loss: 0.0936 - val_acc: 0.9669\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09361 to 0.08784, saving model to best.model\n",
      "0s - loss: 0.1336 - acc: 0.9501 - val_loss: 0.0878 - val_acc: 0.9766\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.08784 to 0.08451, saving model to best.model\n",
      "0s - loss: 0.1323 - acc: 0.9554 - val_loss: 0.0845 - val_acc: 0.9825\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1240 - acc: 0.9552 - val_loss: 0.0855 - val_acc: 0.9747\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08451 to 0.08222, saving model to best.model\n",
      "0s - loss: 0.1279 - acc: 0.9515 - val_loss: 0.0822 - val_acc: 0.9834\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08222 to 0.08118, saving model to best.model\n",
      "0s - loss: 0.1197 - acc: 0.9591 - val_loss: 0.0812 - val_acc: 0.9786\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08118 to 0.07727, saving model to best.model\n",
      "0s - loss: 0.1246 - acc: 0.9542 - val_loss: 0.0773 - val_acc: 0.9834\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07727 to 0.07551, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9569 - val_loss: 0.0755 - val_acc: 0.9854\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07551 to 0.07389, saving model to best.model\n",
      "0s - loss: 0.1283 - acc: 0.9554 - val_loss: 0.0739 - val_acc: 0.9854\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.07389 to 0.07207, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9596 - val_loss: 0.0721 - val_acc: 0.9864\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07207 to 0.07113, saving model to best.model\n",
      "0s - loss: 0.1172 - acc: 0.9608 - val_loss: 0.0711 - val_acc: 0.9864\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07113 to 0.06900, saving model to best.model\n",
      "0s - loss: 0.1113 - acc: 0.9630 - val_loss: 0.0690 - val_acc: 0.9873\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06900 to 0.06783, saving model to best.model\n",
      "0s - loss: 0.1195 - acc: 0.9557 - val_loss: 0.0678 - val_acc: 0.9873\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06783 to 0.06629, saving model to best.model\n",
      "0s - loss: 0.1064 - acc: 0.9620 - val_loss: 0.0663 - val_acc: 0.9864\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06629 to 0.06605, saving model to best.model\n",
      "0s - loss: 0.1049 - acc: 0.9608 - val_loss: 0.0660 - val_acc: 0.9864\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06605 to 0.06347, saving model to best.model\n",
      "0s - loss: 0.1095 - acc: 0.9654 - val_loss: 0.0635 - val_acc: 0.9893\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1044 - acc: 0.9645 - val_loss: 0.0642 - val_acc: 0.9873\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06347 to 0.06061, saving model to best.model\n",
      "0s - loss: 0.1102 - acc: 0.9627 - val_loss: 0.0606 - val_acc: 0.9883\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06061 to 0.06049, saving model to best.model\n",
      "0s - loss: 0.1101 - acc: 0.9657 - val_loss: 0.0605 - val_acc: 0.9883\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.1014 - acc: 0.9659 - val_loss: 0.0657 - val_acc: 0.9854\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06049 to 0.05916, saving model to best.model\n",
      "0s - loss: 0.1085 - acc: 0.9606 - val_loss: 0.0592 - val_acc: 0.9883\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05916 to 0.05730, saving model to best.model\n",
      "0s - loss: 0.1066 - acc: 0.9640 - val_loss: 0.0573 - val_acc: 0.9893\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05730 to 0.05707, saving model to best.model\n",
      "0s - loss: 0.0909 - acc: 0.9696 - val_loss: 0.0571 - val_acc: 0.9873\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05707 to 0.05636, saving model to best.model\n",
      "0s - loss: 0.0921 - acc: 0.9696 - val_loss: 0.0564 - val_acc: 0.9873\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05636 to 0.05212, saving model to best.model\n",
      "0s - loss: 0.0944 - acc: 0.9652 - val_loss: 0.0521 - val_acc: 0.9893\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0891 - acc: 0.9683 - val_loss: 0.0533 - val_acc: 0.9883\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05212 to 0.05014, saving model to best.model\n",
      "0s - loss: 0.0935 - acc: 0.9669 - val_loss: 0.0501 - val_acc: 0.9893\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0915 - acc: 0.9696 - val_loss: 0.0513 - val_acc: 0.9873\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05014 to 0.04737, saving model to best.model\n",
      "0s - loss: 0.0881 - acc: 0.9683 - val_loss: 0.0474 - val_acc: 0.9883\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04737 to 0.04682, saving model to best.model\n",
      "0s - loss: 0.0925 - acc: 0.9679 - val_loss: 0.0468 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04682 to 0.04454, saving model to best.model\n",
      "0s - loss: 0.0851 - acc: 0.9698 - val_loss: 0.0445 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04454 to 0.04400, saving model to best.model\n",
      "0s - loss: 0.0877 - acc: 0.9693 - val_loss: 0.0440 - val_acc: 0.9893\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04400 to 0.04374, saving model to best.model\n",
      "0s - loss: 0.0841 - acc: 0.9686 - val_loss: 0.0437 - val_acc: 0.9883\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04374 to 0.04159, saving model to best.model\n",
      "0s - loss: 0.0777 - acc: 0.9732 - val_loss: 0.0416 - val_acc: 0.9893\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0827 - acc: 0.9705 - val_loss: 0.0418 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0890 - acc: 0.9713 - val_loss: 0.0448 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04159 to 0.03974, saving model to best.model\n",
      "0s - loss: 0.0872 - acc: 0.9691 - val_loss: 0.0397 - val_acc: 0.9893\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0816 - acc: 0.9744 - val_loss: 0.0407 - val_acc: 0.9893\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03974 to 0.03919, saving model to best.model\n",
      "0s - loss: 0.0783 - acc: 0.9732 - val_loss: 0.0392 - val_acc: 0.9893\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0766 - acc: 0.9720 - val_loss: 0.0419 - val_acc: 0.9883\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03919 to 0.03720, saving model to best.model\n",
      "0s - loss: 0.0775 - acc: 0.9730 - val_loss: 0.0372 - val_acc: 0.9893\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03720 to 0.03671, saving model to best.model\n",
      "0s - loss: 0.0763 - acc: 0.9715 - val_loss: 0.0367 - val_acc: 0.9893\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03671 to 0.03428, saving model to best.model\n",
      "0s - loss: 0.0692 - acc: 0.9776 - val_loss: 0.0343 - val_acc: 0.9893\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0693 - acc: 0.9749 - val_loss: 0.0358 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0683 - acc: 0.9722 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03428 to 0.03268, saving model to best.model\n",
      "0s - loss: 0.0706 - acc: 0.9735 - val_loss: 0.0327 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03268 to 0.03143, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9778 - val_loss: 0.0314 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03143 to 0.03039, saving model to best.model\n",
      "0s - loss: 0.0714 - acc: 0.9744 - val_loss: 0.0304 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0659 - acc: 0.9752 - val_loss: 0.0305 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03039 to 0.02906, saving model to best.model\n",
      "0s - loss: 0.0614 - acc: 0.9800 - val_loss: 0.0291 - val_acc: 0.9912\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02906 to 0.02769, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9754 - val_loss: 0.0277 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0661 - acc: 0.9749 - val_loss: 0.0337 - val_acc: 0.9903\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02769 to 0.02602, saving model to best.model\n",
      "0s - loss: 0.0717 - acc: 0.9739 - val_loss: 0.0260 - val_acc: 0.9903\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0649 - acc: 0.9761 - val_loss: 0.0273 - val_acc: 0.9912\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0640 - acc: 0.9764 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.02602 to 0.02536, saving model to best.model\n",
      "0s - loss: 0.0646 - acc: 0.9769 - val_loss: 0.0254 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0588 - acc: 0.9798 - val_loss: 0.0268 - val_acc: 0.9922\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02536 to 0.02373, saving model to best.model\n",
      "0s - loss: 0.0599 - acc: 0.9786 - val_loss: 0.0237 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02373 to 0.02289, saving model to best.model\n",
      "0s - loss: 0.0577 - acc: 0.9783 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0583 - acc: 0.9803 - val_loss: 0.0240 - val_acc: 0.9922\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0554 - acc: 0.9817 - val_loss: 0.0245 - val_acc: 0.9922\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0548 - acc: 0.9800 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0552 - acc: 0.9820 - val_loss: 0.0232 - val_acc: 0.9932\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0614 - acc: 0.9786 - val_loss: 0.0230 - val_acc: 0.9932\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0533 - acc: 0.9803 - val_loss: 0.0231 - val_acc: 0.9932\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9791 - val_loss: 0.0234 - val_acc: 0.9932\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02289 to 0.02095, saving model to best.model\n",
      "0s - loss: 0.0605 - acc: 0.9783 - val_loss: 0.0210 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0589 - acc: 0.9776 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02095 to 0.01999, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9854 - val_loss: 0.0200 - val_acc: 0.9932\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.01999 to 0.01988, saving model to best.model\n",
      "0s - loss: 0.0486 - acc: 0.9820 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9832 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9808 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9844 - val_loss: 0.0223 - val_acc: 0.9932\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01988 to 0.01869, saving model to best.model\n",
      "0s - loss: 0.0479 - acc: 0.9813 - val_loss: 0.0187 - val_acc: 0.9932\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9864 - val_loss: 0.0226 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01869 to 0.01802, saving model to best.model\n",
      "0s - loss: 0.0501 - acc: 0.9800 - val_loss: 0.0180 - val_acc: 0.9932\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9832 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01802 to 0.01709, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9839 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01709 to 0.01634, saving model to best.model\n",
      "0s - loss: 0.0439 - acc: 0.9839 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9844 - val_loss: 0.0182 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9847 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9830 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9849 - val_loss: 0.0184 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0488 - acc: 0.9815 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9856 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9832 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.01634 to 0.01444, saving model to best.model\n",
      "0s - loss: 0.0484 - acc: 0.9839 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9817 - val_loss: 0.0146 - val_acc: 0.9951\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9861 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9871 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01444 to 0.01440, saving model to best.model\n",
      "0s - loss: 0.0422 - acc: 0.9844 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9847 - val_loss: 0.0157 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9883 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01440 to 0.01387, saving model to best.model\n",
      "0s - loss: 0.0378 - acc: 0.9873 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9866 - val_loss: 0.0161 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0425 - acc: 0.9861 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9851 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9849 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01387 to 0.01320, saving model to best.model\n",
      "0s - loss: 0.0401 - acc: 0.9871 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9847 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9859 - val_loss: 0.0176 - val_acc: 0.9951\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9847 - val_loss: 0.0153 - val_acc: 0.9951\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9854 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9876 - val_loss: 0.0155 - val_acc: 0.9951\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9873 - val_loss: 0.0146 - val_acc: 0.9951\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9893 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9886 - val_loss: 0.0149 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01320 to 0.01245, saving model to best.model\n",
      "0s - loss: 0.0291 - acc: 0.9890 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9866 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01245 to 0.01042, saving model to best.model\n",
      "0s - loss: 0.0410 - acc: 0.9834 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9866 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9856 - val_loss: 0.0123 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9876 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9866 - val_loss: 0.0123 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9854 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9878 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9881 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9898 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9888 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0117 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01042 to 0.00932, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9893 - val_loss: 0.0093 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9890 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9895 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9883 - val_loss: 0.0126 - val_acc: 0.9942\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00932 to 0.00894, saving model to best.model\n",
      "0s - loss: 0.0315 - acc: 0.9886 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9886 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9859 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9903 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9876 - val_loss: 0.0135 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66630, saving model to best.model\n",
      "0s - loss: 0.8148 - acc: 0.5099 - val_loss: 0.6663 - val_acc: 0.6826\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66630 to 0.63388, saving model to best.model\n",
      "0s - loss: 0.7314 - acc: 0.5505 - val_loss: 0.6339 - val_acc: 0.7712\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63388 to 0.58220, saving model to best.model\n",
      "0s - loss: 0.6798 - acc: 0.5961 - val_loss: 0.5822 - val_acc: 0.7819\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58220 to 0.50813, saving model to best.model\n",
      "0s - loss: 0.6026 - acc: 0.6793 - val_loss: 0.5081 - val_acc: 0.7916\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50813 to 0.44784, saving model to best.model\n",
      "0s - loss: 0.5263 - acc: 0.7514 - val_loss: 0.4478 - val_acc: 0.8014\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44784 to 0.41541, saving model to best.model\n",
      "0s - loss: 0.4679 - acc: 0.7943 - val_loss: 0.4154 - val_acc: 0.8218\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41541 to 0.38012, saving model to best.model\n",
      "0s - loss: 0.4327 - acc: 0.8232 - val_loss: 0.3801 - val_acc: 0.8462\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38012 to 0.35690, saving model to best.model\n",
      "0s - loss: 0.4010 - acc: 0.8369 - val_loss: 0.3569 - val_acc: 0.8637\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35690 to 0.33998, saving model to best.model\n",
      "0s - loss: 0.3802 - acc: 0.8495 - val_loss: 0.3400 - val_acc: 0.8695\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33998 to 0.32478, saving model to best.model\n",
      "0s - loss: 0.3576 - acc: 0.8556 - val_loss: 0.3248 - val_acc: 0.8744\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.32478 to 0.31791, saving model to best.model\n",
      "0s - loss: 0.3364 - acc: 0.8685 - val_loss: 0.3179 - val_acc: 0.8783\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31791 to 0.30097, saving model to best.model\n",
      "0s - loss: 0.3368 - acc: 0.8710 - val_loss: 0.3010 - val_acc: 0.8861\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.30097 to 0.29693, saving model to best.model\n",
      "0s - loss: 0.3344 - acc: 0.8668 - val_loss: 0.2969 - val_acc: 0.8851\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.3116 - acc: 0.8758 - val_loss: 0.3038 - val_acc: 0.8841\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.29693 to 0.27590, saving model to best.model\n",
      "0s - loss: 0.3108 - acc: 0.8778 - val_loss: 0.2759 - val_acc: 0.8919\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.27590 to 0.26785, saving model to best.model\n",
      "0s - loss: 0.3034 - acc: 0.8890 - val_loss: 0.2678 - val_acc: 0.8968\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.3003 - acc: 0.8878 - val_loss: 0.2695 - val_acc: 0.8978\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.26785 to 0.25452, saving model to best.model\n",
      "0s - loss: 0.2851 - acc: 0.8929 - val_loss: 0.2545 - val_acc: 0.9017\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.25452 to 0.24990, saving model to best.model\n",
      "0s - loss: 0.2856 - acc: 0.8926 - val_loss: 0.2499 - val_acc: 0.9056\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2696 - acc: 0.8943 - val_loss: 0.2611 - val_acc: 0.9026\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.24990 to 0.24016, saving model to best.model\n",
      "0s - loss: 0.2633 - acc: 0.9014 - val_loss: 0.2402 - val_acc: 0.9114\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.24016 to 0.23477, saving model to best.model\n",
      "0s - loss: 0.2644 - acc: 0.9004 - val_loss: 0.2348 - val_acc: 0.9143\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2577 - acc: 0.9031 - val_loss: 0.2348 - val_acc: 0.9114\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.23477 to 0.22470, saving model to best.model\n",
      "0s - loss: 0.2528 - acc: 0.9036 - val_loss: 0.2247 - val_acc: 0.9192\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22470 to 0.22168, saving model to best.model\n",
      "0s - loss: 0.2471 - acc: 0.9053 - val_loss: 0.2217 - val_acc: 0.9172\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.22168 to 0.21809, saving model to best.model\n",
      "0s - loss: 0.2394 - acc: 0.9099 - val_loss: 0.2181 - val_acc: 0.9172\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21809 to 0.21160, saving model to best.model\n",
      "0s - loss: 0.2431 - acc: 0.9099 - val_loss: 0.2116 - val_acc: 0.9211\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21160 to 0.21021, saving model to best.model\n",
      "0s - loss: 0.2378 - acc: 0.9070 - val_loss: 0.2102 - val_acc: 0.9221\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.21021 to 0.20580, saving model to best.model\n",
      "0s - loss: 0.2350 - acc: 0.9167 - val_loss: 0.2058 - val_acc: 0.9211\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20580 to 0.20106, saving model to best.model\n",
      "0s - loss: 0.2349 - acc: 0.9126 - val_loss: 0.2011 - val_acc: 0.9221\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2315 - acc: 0.9116 - val_loss: 0.2067 - val_acc: 0.9172\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20106 to 0.19464, saving model to best.model\n",
      "0s - loss: 0.2311 - acc: 0.9175 - val_loss: 0.1946 - val_acc: 0.9221\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19464 to 0.18860, saving model to best.model\n",
      "0s - loss: 0.2245 - acc: 0.9162 - val_loss: 0.1886 - val_acc: 0.9250\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.2109 - acc: 0.9199 - val_loss: 0.1890 - val_acc: 0.9221\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18860 to 0.18001, saving model to best.model\n",
      "0s - loss: 0.2125 - acc: 0.9172 - val_loss: 0.1800 - val_acc: 0.9318\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2074 - acc: 0.9221 - val_loss: 0.1828 - val_acc: 0.9221\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18001 to 0.17619, saving model to best.model\n",
      "0s - loss: 0.1998 - acc: 0.9260 - val_loss: 0.1762 - val_acc: 0.9289\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17619 to 0.16892, saving model to best.model\n",
      "0s - loss: 0.2023 - acc: 0.9233 - val_loss: 0.1689 - val_acc: 0.9328\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16892 to 0.16411, saving model to best.model\n",
      "0s - loss: 0.1993 - acc: 0.9245 - val_loss: 0.1641 - val_acc: 0.9367\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16411 to 0.15515, saving model to best.model\n",
      "0s - loss: 0.1883 - acc: 0.9257 - val_loss: 0.1552 - val_acc: 0.9377\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15515 to 0.15172, saving model to best.model\n",
      "0s - loss: 0.1824 - acc: 0.9284 - val_loss: 0.1517 - val_acc: 0.9348\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15172 to 0.14596, saving model to best.model\n",
      "0s - loss: 0.1825 - acc: 0.9296 - val_loss: 0.1460 - val_acc: 0.9396\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.14596 to 0.14468, saving model to best.model\n",
      "0s - loss: 0.1802 - acc: 0.9343 - val_loss: 0.1447 - val_acc: 0.9367\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14468 to 0.13683, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9299 - val_loss: 0.1368 - val_acc: 0.9416\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1716 - acc: 0.9360 - val_loss: 0.1372 - val_acc: 0.9406\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.13683 to 0.12886, saving model to best.model\n",
      "0s - loss: 0.1681 - acc: 0.9372 - val_loss: 0.1289 - val_acc: 0.9503\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.12886 to 0.12412, saving model to best.model\n",
      "0s - loss: 0.1584 - acc: 0.9386 - val_loss: 0.1241 - val_acc: 0.9533\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1601 - acc: 0.9372 - val_loss: 0.1289 - val_acc: 0.9464\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12412 to 0.11723, saving model to best.model\n",
      "0s - loss: 0.1508 - acc: 0.9435 - val_loss: 0.1172 - val_acc: 0.9552\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.11723 to 0.11608, saving model to best.model\n",
      "0s - loss: 0.1605 - acc: 0.9364 - val_loss: 0.1161 - val_acc: 0.9572\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11608 to 0.11266, saving model to best.model\n",
      "0s - loss: 0.1526 - acc: 0.9413 - val_loss: 0.1127 - val_acc: 0.9601\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11266 to 0.11120, saving model to best.model\n",
      "0s - loss: 0.1487 - acc: 0.9428 - val_loss: 0.1112 - val_acc: 0.9601\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11120 to 0.10661, saving model to best.model\n",
      "0s - loss: 0.1467 - acc: 0.9457 - val_loss: 0.1066 - val_acc: 0.9611\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10661 to 0.10144, saving model to best.model\n",
      "0s - loss: 0.1505 - acc: 0.9418 - val_loss: 0.1014 - val_acc: 0.9649\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10144 to 0.09830, saving model to best.model\n",
      "0s - loss: 0.1361 - acc: 0.9498 - val_loss: 0.0983 - val_acc: 0.9659\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.09830 to 0.09601, saving model to best.model\n",
      "0s - loss: 0.1342 - acc: 0.9489 - val_loss: 0.0960 - val_acc: 0.9679\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09601 to 0.09252, saving model to best.model\n",
      "0s - loss: 0.1366 - acc: 0.9467 - val_loss: 0.0925 - val_acc: 0.9688\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09252 to 0.08925, saving model to best.model\n",
      "0s - loss: 0.1331 - acc: 0.9523 - val_loss: 0.0893 - val_acc: 0.9688\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.08925 to 0.08762, saving model to best.model\n",
      "0s - loss: 0.1315 - acc: 0.9535 - val_loss: 0.0876 - val_acc: 0.9698\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1174 - acc: 0.9569 - val_loss: 0.0913 - val_acc: 0.9669\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08762 to 0.08338, saving model to best.model\n",
      "0s - loss: 0.1300 - acc: 0.9550 - val_loss: 0.0834 - val_acc: 0.9747\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08338 to 0.08262, saving model to best.model\n",
      "0s - loss: 0.1351 - acc: 0.9501 - val_loss: 0.0826 - val_acc: 0.9766\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08262 to 0.08042, saving model to best.model\n",
      "0s - loss: 0.1190 - acc: 0.9545 - val_loss: 0.0804 - val_acc: 0.9727\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1162 - acc: 0.9559 - val_loss: 0.0805 - val_acc: 0.9747\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1201 - acc: 0.9571 - val_loss: 0.0864 - val_acc: 0.9679\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08042 to 0.07717, saving model to best.model\n",
      "0s - loss: 0.1177 - acc: 0.9581 - val_loss: 0.0772 - val_acc: 0.9747\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07717 to 0.07530, saving model to best.model\n",
      "0s - loss: 0.1139 - acc: 0.9596 - val_loss: 0.0753 - val_acc: 0.9786\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1095 - acc: 0.9598 - val_loss: 0.0756 - val_acc: 0.9737\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07530 to 0.06941, saving model to best.model\n",
      "0s - loss: 0.1076 - acc: 0.9576 - val_loss: 0.0694 - val_acc: 0.9805\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1103 - acc: 0.9615 - val_loss: 0.0717 - val_acc: 0.9766\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1054 - acc: 0.9610 - val_loss: 0.0705 - val_acc: 0.9815\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06941 to 0.06606, saving model to best.model\n",
      "0s - loss: 0.1020 - acc: 0.9630 - val_loss: 0.0661 - val_acc: 0.9825\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06606 to 0.06416, saving model to best.model\n",
      "0s - loss: 0.1088 - acc: 0.9615 - val_loss: 0.0642 - val_acc: 0.9834\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06416 to 0.06149, saving model to best.model\n",
      "0s - loss: 0.0995 - acc: 0.9623 - val_loss: 0.0615 - val_acc: 0.9844\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06149 to 0.06109, saving model to best.model\n",
      "0s - loss: 0.1065 - acc: 0.9618 - val_loss: 0.0611 - val_acc: 0.9854\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06109 to 0.05726, saving model to best.model\n",
      "0s - loss: 0.0955 - acc: 0.9664 - val_loss: 0.0573 - val_acc: 0.9864\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.0992 - acc: 0.9632 - val_loss: 0.0600 - val_acc: 0.9844\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0933 - acc: 0.9664 - val_loss: 0.0598 - val_acc: 0.9854\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05726 to 0.05645, saving model to best.model\n",
      "0s - loss: 0.0897 - acc: 0.9705 - val_loss: 0.0565 - val_acc: 0.9844\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05645 to 0.05636, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9683 - val_loss: 0.0564 - val_acc: 0.9844\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05636 to 0.05431, saving model to best.model\n",
      "0s - loss: 0.0986 - acc: 0.9637 - val_loss: 0.0543 - val_acc: 0.9864\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0827 - acc: 0.9696 - val_loss: 0.0566 - val_acc: 0.9854\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05431 to 0.05333, saving model to best.model\n",
      "0s - loss: 0.0873 - acc: 0.9679 - val_loss: 0.0533 - val_acc: 0.9854\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05333 to 0.04960, saving model to best.model\n",
      "0s - loss: 0.0794 - acc: 0.9708 - val_loss: 0.0496 - val_acc: 0.9854\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0851 - acc: 0.9686 - val_loss: 0.0565 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04960 to 0.04635, saving model to best.model\n",
      "0s - loss: 0.0781 - acc: 0.9725 - val_loss: 0.0464 - val_acc: 0.9873\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0800 - acc: 0.9705 - val_loss: 0.0471 - val_acc: 0.9864\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04635 to 0.04408, saving model to best.model\n",
      "0s - loss: 0.0815 - acc: 0.9715 - val_loss: 0.0441 - val_acc: 0.9873\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0766 - acc: 0.9737 - val_loss: 0.0458 - val_acc: 0.9864\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04408 to 0.04053, saving model to best.model\n",
      "0s - loss: 0.0813 - acc: 0.9718 - val_loss: 0.0405 - val_acc: 0.9873\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0716 - acc: 0.9759 - val_loss: 0.0414 - val_acc: 0.9873\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0817 - acc: 0.9730 - val_loss: 0.0408 - val_acc: 0.9873\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04053 to 0.04039, saving model to best.model\n",
      "0s - loss: 0.0733 - acc: 0.9752 - val_loss: 0.0404 - val_acc: 0.9864\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0760 - acc: 0.9732 - val_loss: 0.0422 - val_acc: 0.9864\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04039 to 0.03677, saving model to best.model\n",
      "0s - loss: 0.0770 - acc: 0.9725 - val_loss: 0.0368 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0749 - acc: 0.9730 - val_loss: 0.0414 - val_acc: 0.9864\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0741 - acc: 0.9732 - val_loss: 0.0399 - val_acc: 0.9864\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0691 - acc: 0.9737 - val_loss: 0.0397 - val_acc: 0.9864\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0686 - acc: 0.9761 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0678 - acc: 0.9778 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03677 to 0.03631, saving model to best.model\n",
      "0s - loss: 0.0696 - acc: 0.9754 - val_loss: 0.0363 - val_acc: 0.9873\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0661 - acc: 0.9781 - val_loss: 0.0390 - val_acc: 0.9873\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03631 to 0.03607, saving model to best.model\n",
      "0s - loss: 0.0711 - acc: 0.9744 - val_loss: 0.0361 - val_acc: 0.9873\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03607 to 0.03189, saving model to best.model\n",
      "0s - loss: 0.0635 - acc: 0.9774 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0683 - acc: 0.9749 - val_loss: 0.0380 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0714 - acc: 0.9761 - val_loss: 0.0321 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0577 - acc: 0.9781 - val_loss: 0.0337 - val_acc: 0.9873\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0621 - acc: 0.9776 - val_loss: 0.0367 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03189 to 0.03164, saving model to best.model\n",
      "0s - loss: 0.0705 - acc: 0.9747 - val_loss: 0.0316 - val_acc: 0.9873\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03164 to 0.03085, saving model to best.model\n",
      "0s - loss: 0.0608 - acc: 0.9759 - val_loss: 0.0308 - val_acc: 0.9873\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03085 to 0.02990, saving model to best.model\n",
      "0s - loss: 0.0569 - acc: 0.9815 - val_loss: 0.0299 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9759 - val_loss: 0.0303 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02990 to 0.02917, saving model to best.model\n",
      "0s - loss: 0.0550 - acc: 0.9817 - val_loss: 0.0292 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0615 - acc: 0.9774 - val_loss: 0.0315 - val_acc: 0.9873\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0570 - acc: 0.9783 - val_loss: 0.0315 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0541 - acc: 0.9805 - val_loss: 0.0309 - val_acc: 0.9873\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02917 to 0.02748, saving model to best.model\n",
      "0s - loss: 0.0522 - acc: 0.9820 - val_loss: 0.0275 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0530 - acc: 0.9813 - val_loss: 0.0282 - val_acc: 0.9873\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0563 - acc: 0.9769 - val_loss: 0.0295 - val_acc: 0.9873\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02748 to 0.02673, saving model to best.model\n",
      "0s - loss: 0.0567 - acc: 0.9825 - val_loss: 0.0267 - val_acc: 0.9883\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9791 - val_loss: 0.0293 - val_acc: 0.9883\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02673 to 0.02485, saving model to best.model\n",
      "0s - loss: 0.0550 - acc: 0.9798 - val_loss: 0.0249 - val_acc: 0.9883\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02485 to 0.02406, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9793 - val_loss: 0.0241 - val_acc: 0.9883\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02406 to 0.02406, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9791 - val_loss: 0.0241 - val_acc: 0.9883\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9820 - val_loss: 0.0243 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0545 - acc: 0.9805 - val_loss: 0.0251 - val_acc: 0.9883\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02406 to 0.02320, saving model to best.model\n",
      "0s - loss: 0.0401 - acc: 0.9878 - val_loss: 0.0232 - val_acc: 0.9883\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9810 - val_loss: 0.0239 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02320 to 0.02207, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9817 - val_loss: 0.0221 - val_acc: 0.9883\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0471 - acc: 0.9830 - val_loss: 0.0228 - val_acc: 0.9883\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02207 to 0.02124, saving model to best.model\n",
      "0s - loss: 0.0484 - acc: 0.9822 - val_loss: 0.0212 - val_acc: 0.9883\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02124 to 0.02089, saving model to best.model\n",
      "0s - loss: 0.0452 - acc: 0.9820 - val_loss: 0.0209 - val_acc: 0.9893\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02089 to 0.01915, saving model to best.model\n",
      "0s - loss: 0.0490 - acc: 0.9825 - val_loss: 0.0191 - val_acc: 0.9903\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0514 - acc: 0.9825 - val_loss: 0.0192 - val_acc: 0.9903\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9825 - val_loss: 0.0205 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0536 - acc: 0.9781 - val_loss: 0.0213 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01915 to 0.01906, saving model to best.model\n",
      "0s - loss: 0.0446 - acc: 0.9822 - val_loss: 0.0191 - val_acc: 0.9893\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9815 - val_loss: 0.0254 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01906 to 0.01849, saving model to best.model\n",
      "0s - loss: 0.0456 - acc: 0.9817 - val_loss: 0.0185 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9842 - val_loss: 0.0208 - val_acc: 0.9893\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9832 - val_loss: 0.0196 - val_acc: 0.9893\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01849 to 0.01649, saving model to best.model\n",
      "0s - loss: 0.0472 - acc: 0.9810 - val_loss: 0.0165 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9822 - val_loss: 0.0186 - val_acc: 0.9912\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9805 - val_loss: 0.0189 - val_acc: 0.9912\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01649 to 0.01515, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9856 - val_loss: 0.0152 - val_acc: 0.9912\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9837 - val_loss: 0.0212 - val_acc: 0.9893\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9830 - val_loss: 0.0197 - val_acc: 0.9912\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9834 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0465 - acc: 0.9820 - val_loss: 0.0186 - val_acc: 0.9903\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9834 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9844 - val_loss: 0.0159 - val_acc: 0.9922\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9832 - val_loss: 0.0153 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01515 to 0.01446, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9832 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9861 - val_loss: 0.0163 - val_acc: 0.9912\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9844 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01446 to 0.01364, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9849 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9876 - val_loss: 0.0139 - val_acc: 0.9922\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01364 to 0.01275, saving model to best.model\n",
      "0s - loss: 0.0410 - acc: 0.9847 - val_loss: 0.0127 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9869 - val_loss: 0.0141 - val_acc: 0.9932\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9876 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9869 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9888 - val_loss: 0.0141 - val_acc: 0.9932\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9878 - val_loss: 0.0164 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9827 - val_loss: 0.0150 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9851 - val_loss: 0.0167 - val_acc: 0.9903\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9869 - val_loss: 0.0151 - val_acc: 0.9912\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9886 - val_loss: 0.0132 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9890 - val_loss: 0.0137 - val_acc: 0.9932\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9900 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9876 - val_loss: 0.0150 - val_acc: 0.9922\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01275 to 0.01076, saving model to best.model\n",
      "0s - loss: 0.0373 - acc: 0.9871 - val_loss: 0.0108 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9856 - val_loss: 0.0152 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9871 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9898 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9881 - val_loss: 0.0126 - val_acc: 0.9932\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9917 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01076 to 0.01050, saving model to best.model\n",
      "0s - loss: 0.0283 - acc: 0.9883 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9873 - val_loss: 0.0129 - val_acc: 0.9932\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9886 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01050 to 0.00950, saving model to best.model\n",
      "0s - loss: 0.0339 - acc: 0.9888 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9873 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9878 - val_loss: 0.0121 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9876 - val_loss: 0.0133 - val_acc: 0.9932\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9883 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9876 - val_loss: 0.0111 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9907 - val_loss: 0.0097 - val_acc: 0.9942\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9871 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9876 - val_loss: 0.0107 - val_acc: 0.9942\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9869 - val_loss: 0.0109 - val_acc: 0.9942\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00950 to 0.00823, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9844 - val_loss: 0.0082 - val_acc: 0.9961\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9898 - val_loss: 0.0120 - val_acc: 0.9932\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9881 - val_loss: 0.0086 - val_acc: 0.9942\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9883 - val_loss: 0.0102 - val_acc: 0.9942\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9878 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9878 - val_loss: 0.0111 - val_acc: 0.9942\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0274 - acc: 0.9886 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9900 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9861 - val_loss: 0.0115 - val_acc: 0.9942\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9905 - val_loss: 0.0114 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9881 - val_loss: 0.0139 - val_acc: 0.9932\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66366, saving model to best.model\n",
      "0s - loss: 0.7907 - acc: 0.5103 - val_loss: 0.6637 - val_acc: 0.5404\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66366 to 0.63831, saving model to best.model\n",
      "0s - loss: 0.7289 - acc: 0.5474 - val_loss: 0.6383 - val_acc: 0.8092\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63831 to 0.58706, saving model to best.model\n",
      "0s - loss: 0.6799 - acc: 0.5868 - val_loss: 0.5871 - val_acc: 0.8199\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58706 to 0.51090, saving model to best.model\n",
      "0s - loss: 0.6289 - acc: 0.6521 - val_loss: 0.5109 - val_acc: 0.8160\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51090 to 0.43779, saving model to best.model\n",
      "0s - loss: 0.5621 - acc: 0.7129 - val_loss: 0.4378 - val_acc: 0.8335\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.43779 to 0.39337, saving model to best.model\n",
      "0s - loss: 0.5029 - acc: 0.7714 - val_loss: 0.3934 - val_acc: 0.8549\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39337 to 0.35314, saving model to best.model\n",
      "0s - loss: 0.4546 - acc: 0.8057 - val_loss: 0.3531 - val_acc: 0.8754\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35314 to 0.32787, saving model to best.model\n",
      "0s - loss: 0.4252 - acc: 0.8125 - val_loss: 0.3279 - val_acc: 0.8822\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.32787 to 0.31192, saving model to best.model\n",
      "0s - loss: 0.4046 - acc: 0.8335 - val_loss: 0.3119 - val_acc: 0.8919\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31192 to 0.29340, saving model to best.model\n",
      "0s - loss: 0.3837 - acc: 0.8410 - val_loss: 0.2934 - val_acc: 0.8929\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29340 to 0.28021, saving model to best.model\n",
      "0s - loss: 0.3680 - acc: 0.8522 - val_loss: 0.2802 - val_acc: 0.8978\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28021 to 0.26862, saving model to best.model\n",
      "0s - loss: 0.3560 - acc: 0.8600 - val_loss: 0.2686 - val_acc: 0.9046\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.26862 to 0.25866, saving model to best.model\n",
      "0s - loss: 0.3293 - acc: 0.8692 - val_loss: 0.2587 - val_acc: 0.9085\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.25866 to 0.25419, saving model to best.model\n",
      "0s - loss: 0.3278 - acc: 0.8690 - val_loss: 0.2542 - val_acc: 0.9153\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25419 to 0.24268, saving model to best.model\n",
      "0s - loss: 0.3071 - acc: 0.8826 - val_loss: 0.2427 - val_acc: 0.9182\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.3097 - acc: 0.8829 - val_loss: 0.2451 - val_acc: 0.9182\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24268 to 0.23403, saving model to best.model\n",
      "0s - loss: 0.3037 - acc: 0.8865 - val_loss: 0.2340 - val_acc: 0.9250\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.23403 to 0.22836, saving model to best.model\n",
      "0s - loss: 0.2862 - acc: 0.8916 - val_loss: 0.2284 - val_acc: 0.9270\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22836 to 0.22510, saving model to best.model\n",
      "0s - loss: 0.2886 - acc: 0.8931 - val_loss: 0.2251 - val_acc: 0.9289\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22510 to 0.22365, saving model to best.model\n",
      "0s - loss: 0.2922 - acc: 0.8955 - val_loss: 0.2237 - val_acc: 0.9299\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22365 to 0.21686, saving model to best.model\n",
      "0s - loss: 0.2841 - acc: 0.8997 - val_loss: 0.2169 - val_acc: 0.9357\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21686 to 0.21354, saving model to best.model\n",
      "0s - loss: 0.2729 - acc: 0.9021 - val_loss: 0.2135 - val_acc: 0.9338\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21354 to 0.20941, saving model to best.model\n",
      "0s - loss: 0.2649 - acc: 0.9041 - val_loss: 0.2094 - val_acc: 0.9377\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20941 to 0.20781, saving model to best.model\n",
      "0s - loss: 0.2669 - acc: 0.9004 - val_loss: 0.2078 - val_acc: 0.9348\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20781 to 0.20348, saving model to best.model\n",
      "0s - loss: 0.2674 - acc: 0.9067 - val_loss: 0.2035 - val_acc: 0.9387\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20348 to 0.20164, saving model to best.model\n",
      "0s - loss: 0.2519 - acc: 0.9111 - val_loss: 0.2016 - val_acc: 0.9338\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20164 to 0.19690, saving model to best.model\n",
      "0s - loss: 0.2487 - acc: 0.9106 - val_loss: 0.1969 - val_acc: 0.9396\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19690 to 0.19371, saving model to best.model\n",
      "0s - loss: 0.2449 - acc: 0.9150 - val_loss: 0.1937 - val_acc: 0.9377\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19371 to 0.18956, saving model to best.model\n",
      "0s - loss: 0.2414 - acc: 0.9123 - val_loss: 0.1896 - val_acc: 0.9396\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18956 to 0.18910, saving model to best.model\n",
      "0s - loss: 0.2332 - acc: 0.9192 - val_loss: 0.1891 - val_acc: 0.9367\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18910 to 0.18204, saving model to best.model\n",
      "0s - loss: 0.2260 - acc: 0.9189 - val_loss: 0.1820 - val_acc: 0.9396\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18204 to 0.17797, saving model to best.model\n",
      "0s - loss: 0.2291 - acc: 0.9158 - val_loss: 0.1780 - val_acc: 0.9396\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2260 - acc: 0.9140 - val_loss: 0.1792 - val_acc: 0.9377\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17797 to 0.17284, saving model to best.model\n",
      "0s - loss: 0.2220 - acc: 0.9221 - val_loss: 0.1728 - val_acc: 0.9416\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17284 to 0.17027, saving model to best.model\n",
      "0s - loss: 0.2247 - acc: 0.9189 - val_loss: 0.1703 - val_acc: 0.9377\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17027 to 0.16476, saving model to best.model\n",
      "0s - loss: 0.2171 - acc: 0.9211 - val_loss: 0.1648 - val_acc: 0.9416\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16476 to 0.16246, saving model to best.model\n",
      "0s - loss: 0.2106 - acc: 0.9223 - val_loss: 0.1625 - val_acc: 0.9406\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16246 to 0.16134, saving model to best.model\n",
      "0s - loss: 0.2055 - acc: 0.9262 - val_loss: 0.1613 - val_acc: 0.9357\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16134 to 0.15393, saving model to best.model\n",
      "0s - loss: 0.2054 - acc: 0.9250 - val_loss: 0.1539 - val_acc: 0.9445\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15393 to 0.15365, saving model to best.model\n",
      "0s - loss: 0.2021 - acc: 0.9272 - val_loss: 0.1537 - val_acc: 0.9426\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15365 to 0.14776, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9301 - val_loss: 0.1478 - val_acc: 0.9484\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14776 to 0.14400, saving model to best.model\n",
      "0s - loss: 0.1946 - acc: 0.9330 - val_loss: 0.1440 - val_acc: 0.9552\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.2030 - acc: 0.9313 - val_loss: 0.1510 - val_acc: 0.9387\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14400 to 0.13858, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9316 - val_loss: 0.1386 - val_acc: 0.9562\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13858 to 0.13444, saving model to best.model\n",
      "0s - loss: 0.1845 - acc: 0.9326 - val_loss: 0.1344 - val_acc: 0.9581\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.13444 to 0.13148, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9360 - val_loss: 0.1315 - val_acc: 0.9591\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13148 to 0.12792, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9330 - val_loss: 0.1279 - val_acc: 0.9591\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1670 - acc: 0.9433 - val_loss: 0.1292 - val_acc: 0.9523\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12792 to 0.11744, saving model to best.model\n",
      "0s - loss: 0.1677 - acc: 0.9401 - val_loss: 0.1174 - val_acc: 0.9640\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.11744 to 0.11422, saving model to best.model\n",
      "0s - loss: 0.1682 - acc: 0.9357 - val_loss: 0.1142 - val_acc: 0.9649\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11422 to 0.11142, saving model to best.model\n",
      "0s - loss: 0.1591 - acc: 0.9428 - val_loss: 0.1114 - val_acc: 0.9640\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11142 to 0.10877, saving model to best.model\n",
      "0s - loss: 0.1541 - acc: 0.9447 - val_loss: 0.1088 - val_acc: 0.9649\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.10877 to 0.10450, saving model to best.model\n",
      "0s - loss: 0.1515 - acc: 0.9459 - val_loss: 0.1045 - val_acc: 0.9649\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10450 to 0.10389, saving model to best.model\n",
      "0s - loss: 0.1468 - acc: 0.9489 - val_loss: 0.1039 - val_acc: 0.9659\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10389 to 0.09755, saving model to best.model\n",
      "0s - loss: 0.1417 - acc: 0.9457 - val_loss: 0.0976 - val_acc: 0.9649\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1446 - acc: 0.9491 - val_loss: 0.1005 - val_acc: 0.9679\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09755 to 0.09222, saving model to best.model\n",
      "0s - loss: 0.1374 - acc: 0.9515 - val_loss: 0.0922 - val_acc: 0.9737\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09222 to 0.08710, saving model to best.model\n",
      "0s - loss: 0.1362 - acc: 0.9494 - val_loss: 0.0871 - val_acc: 0.9757\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.08710 to 0.08538, saving model to best.model\n",
      "0s - loss: 0.1353 - acc: 0.9533 - val_loss: 0.0854 - val_acc: 0.9747\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.08538 to 0.08470, saving model to best.model\n",
      "0s - loss: 0.1317 - acc: 0.9542 - val_loss: 0.0847 - val_acc: 0.9737\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08470 to 0.08278, saving model to best.model\n",
      "0s - loss: 0.1254 - acc: 0.9567 - val_loss: 0.0828 - val_acc: 0.9757\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08278 to 0.08030, saving model to best.model\n",
      "0s - loss: 0.1298 - acc: 0.9520 - val_loss: 0.0803 - val_acc: 0.9776\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1248 - acc: 0.9530 - val_loss: 0.0855 - val_acc: 0.9747\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08030 to 0.07632, saving model to best.model\n",
      "0s - loss: 0.1260 - acc: 0.9518 - val_loss: 0.0763 - val_acc: 0.9766\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07632 to 0.07518, saving model to best.model\n",
      "0s - loss: 0.1238 - acc: 0.9545 - val_loss: 0.0752 - val_acc: 0.9776\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07518 to 0.07210, saving model to best.model\n",
      "0s - loss: 0.1170 - acc: 0.9598 - val_loss: 0.0721 - val_acc: 0.9796\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1122 - acc: 0.9571 - val_loss: 0.0745 - val_acc: 0.9786\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07210 to 0.06871, saving model to best.model\n",
      "0s - loss: 0.1119 - acc: 0.9640 - val_loss: 0.0687 - val_acc: 0.9796\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.06871 to 0.06820, saving model to best.model\n",
      "0s - loss: 0.1091 - acc: 0.9627 - val_loss: 0.0682 - val_acc: 0.9796\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06820 to 0.06363, saving model to best.model\n",
      "0s - loss: 0.1039 - acc: 0.9613 - val_loss: 0.0636 - val_acc: 0.9796\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06363 to 0.06126, saving model to best.model\n",
      "0s - loss: 0.1057 - acc: 0.9645 - val_loss: 0.0613 - val_acc: 0.9805\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06126 to 0.06119, saving model to best.model\n",
      "0s - loss: 0.1075 - acc: 0.9608 - val_loss: 0.0612 - val_acc: 0.9796\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06119 to 0.05768, saving model to best.model\n",
      "0s - loss: 0.1078 - acc: 0.9581 - val_loss: 0.0577 - val_acc: 0.9796\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.0998 - acc: 0.9642 - val_loss: 0.0643 - val_acc: 0.9796\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.0965 - acc: 0.9642 - val_loss: 0.0583 - val_acc: 0.9815\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.05768 to 0.05391, saving model to best.model\n",
      "0s - loss: 0.1012 - acc: 0.9625 - val_loss: 0.0539 - val_acc: 0.9805\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1043 - acc: 0.9601 - val_loss: 0.0599 - val_acc: 0.9815\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0915 - acc: 0.9664 - val_loss: 0.0553 - val_acc: 0.9815\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05391 to 0.05209, saving model to best.model\n",
      "0s - loss: 0.0974 - acc: 0.9635 - val_loss: 0.0521 - val_acc: 0.9805\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0989 - acc: 0.9625 - val_loss: 0.0536 - val_acc: 0.9815\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0832 - acc: 0.9705 - val_loss: 0.0532 - val_acc: 0.9815\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05209 to 0.04759, saving model to best.model\n",
      "0s - loss: 0.0831 - acc: 0.9688 - val_loss: 0.0476 - val_acc: 0.9825\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0886 - acc: 0.9647 - val_loss: 0.0498 - val_acc: 0.9834\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0894 - acc: 0.9674 - val_loss: 0.0495 - val_acc: 0.9834\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0857 - acc: 0.9713 - val_loss: 0.0521 - val_acc: 0.9834\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0787 - acc: 0.9691 - val_loss: 0.0484 - val_acc: 0.9834\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04759 to 0.04324, saving model to best.model\n",
      "0s - loss: 0.0772 - acc: 0.9710 - val_loss: 0.0432 - val_acc: 0.9834\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0777 - acc: 0.9708 - val_loss: 0.0472 - val_acc: 0.9834\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0815 - acc: 0.9696 - val_loss: 0.0444 - val_acc: 0.9834\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0858 - acc: 0.9701 - val_loss: 0.0450 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04324 to 0.04064, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9739 - val_loss: 0.0406 - val_acc: 0.9834\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0771 - acc: 0.9720 - val_loss: 0.0434 - val_acc: 0.9834\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0679 - acc: 0.9742 - val_loss: 0.0442 - val_acc: 0.9834\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0724 - acc: 0.9742 - val_loss: 0.0409 - val_acc: 0.9834\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0762 - acc: 0.9718 - val_loss: 0.0483 - val_acc: 0.9834\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04064 to 0.03975, saving model to best.model\n",
      "0s - loss: 0.0816 - acc: 0.9715 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0709 - acc: 0.9720 - val_loss: 0.0411 - val_acc: 0.9834\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0750 - acc: 0.9693 - val_loss: 0.0424 - val_acc: 0.9834\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03975 to 0.03924, saving model to best.model\n",
      "0s - loss: 0.0712 - acc: 0.9764 - val_loss: 0.0392 - val_acc: 0.9834\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03924 to 0.03881, saving model to best.model\n",
      "0s - loss: 0.0663 - acc: 0.9742 - val_loss: 0.0388 - val_acc: 0.9844\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03881 to 0.03762, saving model to best.model\n",
      "0s - loss: 0.0673 - acc: 0.9757 - val_loss: 0.0376 - val_acc: 0.9844\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03762 to 0.03742, saving model to best.model\n",
      "0s - loss: 0.0592 - acc: 0.9761 - val_loss: 0.0374 - val_acc: 0.9844\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0664 - acc: 0.9747 - val_loss: 0.0376 - val_acc: 0.9834\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03742 to 0.03459, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9795 - val_loss: 0.0346 - val_acc: 0.9844\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0561 - acc: 0.9795 - val_loss: 0.0393 - val_acc: 0.9834\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03459 to 0.03061, saving model to best.model\n",
      "0s - loss: 0.0611 - acc: 0.9749 - val_loss: 0.0306 - val_acc: 0.9864\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0671 - acc: 0.9754 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0560 - acc: 0.9803 - val_loss: 0.0346 - val_acc: 0.9844\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03061 to 0.03045, saving model to best.model\n",
      "0s - loss: 0.0626 - acc: 0.9764 - val_loss: 0.0304 - val_acc: 0.9873\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0585 - acc: 0.9798 - val_loss: 0.0353 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0612 - acc: 0.9783 - val_loss: 0.0307 - val_acc: 0.9854\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9769 - val_loss: 0.0356 - val_acc: 0.9844\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03045 to 0.02997, saving model to best.model\n",
      "0s - loss: 0.0553 - acc: 0.9810 - val_loss: 0.0300 - val_acc: 0.9854\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9822 - val_loss: 0.0373 - val_acc: 0.9844\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0507 - acc: 0.9800 - val_loss: 0.0332 - val_acc: 0.9844\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9795 - val_loss: 0.0330 - val_acc: 0.9844\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02997 to 0.02784, saving model to best.model\n",
      "0s - loss: 0.0518 - acc: 0.9815 - val_loss: 0.0278 - val_acc: 0.9864\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0538 - acc: 0.9803 - val_loss: 0.0351 - val_acc: 0.9844\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02784 to 0.02436, saving model to best.model\n",
      "0s - loss: 0.0487 - acc: 0.9815 - val_loss: 0.0244 - val_acc: 0.9893\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9783 - val_loss: 0.0314 - val_acc: 0.9854\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0480 - acc: 0.9844 - val_loss: 0.0285 - val_acc: 0.9854\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9813 - val_loss: 0.0270 - val_acc: 0.9854\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0527 - acc: 0.9795 - val_loss: 0.0308 - val_acc: 0.9854\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0485 - acc: 0.9830 - val_loss: 0.0301 - val_acc: 0.9854\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9813 - val_loss: 0.0265 - val_acc: 0.9873\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0514 - acc: 0.9791 - val_loss: 0.0293 - val_acc: 0.9854\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9844 - val_loss: 0.0274 - val_acc: 0.9864\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9817 - val_loss: 0.0253 - val_acc: 0.9903\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0493 - acc: 0.9805 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9844 - val_loss: 0.0266 - val_acc: 0.9883\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02436 to 0.02303, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9800 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9827 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02303 to 0.02107, saving model to best.model\n",
      "0s - loss: 0.0466 - acc: 0.9830 - val_loss: 0.0211 - val_acc: 0.9912\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9813 - val_loss: 0.0390 - val_acc: 0.9844\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0514 - acc: 0.9832 - val_loss: 0.0246 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9827 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0433 - acc: 0.9830 - val_loss: 0.0232 - val_acc: 0.9903\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9810 - val_loss: 0.0217 - val_acc: 0.9903\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9859 - val_loss: 0.0332 - val_acc: 0.9854\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9822 - val_loss: 0.0214 - val_acc: 0.9903\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9820 - val_loss: 0.0239 - val_acc: 0.9903\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02107 to 0.02070, saving model to best.model\n",
      "0s - loss: 0.0398 - acc: 0.9869 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0506 - acc: 0.9798 - val_loss: 0.0322 - val_acc: 0.9854\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.02070 to 0.01964, saving model to best.model\n",
      "0s - loss: 0.0441 - acc: 0.9822 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9859 - val_loss: 0.0252 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0434 - acc: 0.9830 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9847 - val_loss: 0.0244 - val_acc: 0.9893\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9873 - val_loss: 0.0273 - val_acc: 0.9873\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9832 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0448 - acc: 0.9837 - val_loss: 0.0222 - val_acc: 0.9903\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9883 - val_loss: 0.0262 - val_acc: 0.9883\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9851 - val_loss: 0.0205 - val_acc: 0.9903\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9859 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9859 - val_loss: 0.0240 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9849 - val_loss: 0.0224 - val_acc: 0.9893\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0370 - acc: 0.9871 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9883 - val_loss: 0.0213 - val_acc: 0.9903\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9878 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9866 - val_loss: 0.0221 - val_acc: 0.9903\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9866 - val_loss: 0.0250 - val_acc: 0.9903\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01964 to 0.01926, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9837 - val_loss: 0.0193 - val_acc: 0.9903\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9856 - val_loss: 0.0230 - val_acc: 0.9893\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9866 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9888 - val_loss: 0.0229 - val_acc: 0.9893\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01926 to 0.01809, saving model to best.model\n",
      "0s - loss: 0.0355 - acc: 0.9871 - val_loss: 0.0181 - val_acc: 0.9903\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9866 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01809 to 0.01701, saving model to best.model\n",
      "0s - loss: 0.0358 - acc: 0.9851 - val_loss: 0.0170 - val_acc: 0.9912\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9871 - val_loss: 0.0184 - val_acc: 0.9903\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9878 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9878 - val_loss: 0.0236 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01701 to 0.01596, saving model to best.model\n",
      "0s - loss: 0.0323 - acc: 0.9873 - val_loss: 0.0160 - val_acc: 0.9922\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9876 - val_loss: 0.0251 - val_acc: 0.9903\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9834 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9888 - val_loss: 0.0265 - val_acc: 0.9873\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9895 - val_loss: 0.0178 - val_acc: 0.9912\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9871 - val_loss: 0.0249 - val_acc: 0.9883\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9895 - val_loss: 0.0185 - val_acc: 0.9903\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9883 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9866 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9895 - val_loss: 0.0178 - val_acc: 0.9912\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9873 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01596 to 0.01595, saving model to best.model\n",
      "0s - loss: 0.0313 - acc: 0.9881 - val_loss: 0.0159 - val_acc: 0.9912\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9878 - val_loss: 0.0161 - val_acc: 0.9903\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9905 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01595 to 0.01575, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9907 - val_loss: 0.0157 - val_acc: 0.9912\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9895 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.01575 to 0.01522, saving model to best.model\n",
      "0s - loss: 0.0281 - acc: 0.9893 - val_loss: 0.0152 - val_acc: 0.9912\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0240 - acc: 0.9895 - val_loss: 0.0192 - val_acc: 0.9903\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9876 - val_loss: 0.0175 - val_acc: 0.9903\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9922 - val_loss: 0.0190 - val_acc: 0.9903\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0254 - acc: 0.9907 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.01522 to 0.01513, saving model to best.model\n",
      "0s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0151 - val_acc: 0.9912\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9890 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0261 - acc: 0.9912 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9886 - val_loss: 0.0195 - val_acc: 0.9912\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.01513 to 0.01489, saving model to best.model\n",
      "0s - loss: 0.0325 - acc: 0.9873 - val_loss: 0.0149 - val_acc: 0.9912\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0273 - acc: 0.9900 - val_loss: 0.0173 - val_acc: 0.9912\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.01489 to 0.01330, saving model to best.model\n",
      "0s - loss: 0.0264 - acc: 0.9890 - val_loss: 0.0133 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9878 - val_loss: 0.0153 - val_acc: 0.9912\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0251 - acc: 0.9917 - val_loss: 0.0182 - val_acc: 0.9903\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66783, saving model to best.model\n",
      "0s - loss: 0.8043 - acc: 0.5106 - val_loss: 0.6678 - val_acc: 0.7634\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66783 to 0.64069, saving model to best.model\n",
      "0s - loss: 0.7574 - acc: 0.5313 - val_loss: 0.6407 - val_acc: 0.7488\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64069 to 0.59432, saving model to best.model\n",
      "0s - loss: 0.6923 - acc: 0.5827 - val_loss: 0.5943 - val_acc: 0.8160\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59432 to 0.52483, saving model to best.model\n",
      "0s - loss: 0.6364 - acc: 0.6367 - val_loss: 0.5248 - val_acc: 0.8267\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52483 to 0.44944, saving model to best.model\n",
      "0s - loss: 0.5561 - acc: 0.7195 - val_loss: 0.4494 - val_acc: 0.8432\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44944 to 0.40194, saving model to best.model\n",
      "0s - loss: 0.4986 - acc: 0.7733 - val_loss: 0.4019 - val_acc: 0.8530\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40194 to 0.37179, saving model to best.model\n",
      "0s - loss: 0.4543 - acc: 0.8106 - val_loss: 0.3718 - val_acc: 0.8617\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37179 to 0.35096, saving model to best.model\n",
      "0s - loss: 0.4261 - acc: 0.8271 - val_loss: 0.3510 - val_acc: 0.8685\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35096 to 0.33340, saving model to best.model\n",
      "0s - loss: 0.4014 - acc: 0.8395 - val_loss: 0.3334 - val_acc: 0.8773\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33340 to 0.31973, saving model to best.model\n",
      "0s - loss: 0.3797 - acc: 0.8473 - val_loss: 0.3197 - val_acc: 0.8783\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31973 to 0.30752, saving model to best.model\n",
      "0s - loss: 0.3651 - acc: 0.8566 - val_loss: 0.3075 - val_acc: 0.8783\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30752 to 0.30029, saving model to best.model\n",
      "0s - loss: 0.3538 - acc: 0.8563 - val_loss: 0.3003 - val_acc: 0.8822\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.30029 to 0.29190, saving model to best.model\n",
      "0s - loss: 0.3529 - acc: 0.8624 - val_loss: 0.2919 - val_acc: 0.8851\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.29190 to 0.27189, saving model to best.model\n",
      "0s - loss: 0.3143 - acc: 0.8787 - val_loss: 0.2719 - val_acc: 0.8909\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27189 to 0.26102, saving model to best.model\n",
      "0s - loss: 0.3185 - acc: 0.8761 - val_loss: 0.2610 - val_acc: 0.8919\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26102 to 0.25484, saving model to best.model\n",
      "0s - loss: 0.3005 - acc: 0.8812 - val_loss: 0.2548 - val_acc: 0.8968\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.3065 - acc: 0.8785 - val_loss: 0.2576 - val_acc: 0.9026\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25484 to 0.24411, saving model to best.model\n",
      "0s - loss: 0.2881 - acc: 0.8929 - val_loss: 0.2441 - val_acc: 0.9046\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24411 to 0.23666, saving model to best.model\n",
      "0s - loss: 0.2795 - acc: 0.8999 - val_loss: 0.2367 - val_acc: 0.9085\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23666 to 0.23621, saving model to best.model\n",
      "0s - loss: 0.2761 - acc: 0.8999 - val_loss: 0.2362 - val_acc: 0.9114\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23621 to 0.22888, saving model to best.model\n",
      "0s - loss: 0.2786 - acc: 0.8997 - val_loss: 0.2289 - val_acc: 0.9163\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22888 to 0.22568, saving model to best.model\n",
      "0s - loss: 0.2633 - acc: 0.9028 - val_loss: 0.2257 - val_acc: 0.9133\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22568 to 0.22528, saving model to best.model\n",
      "0s - loss: 0.2604 - acc: 0.9055 - val_loss: 0.2253 - val_acc: 0.9133\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22528 to 0.21609, saving model to best.model\n",
      "0s - loss: 0.2521 - acc: 0.9121 - val_loss: 0.2161 - val_acc: 0.9202\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21609 to 0.21131, saving model to best.model\n",
      "0s - loss: 0.2543 - acc: 0.9072 - val_loss: 0.2113 - val_acc: 0.9250\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2406 - acc: 0.9158 - val_loss: 0.2130 - val_acc: 0.9202\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21131 to 0.20417, saving model to best.model\n",
      "0s - loss: 0.2466 - acc: 0.9158 - val_loss: 0.2042 - val_acc: 0.9250\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20417 to 0.20343, saving model to best.model\n",
      "0s - loss: 0.2430 - acc: 0.9133 - val_loss: 0.2034 - val_acc: 0.9231\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20343 to 0.20180, saving model to best.model\n",
      "0s - loss: 0.2393 - acc: 0.9153 - val_loss: 0.2018 - val_acc: 0.9241\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20180 to 0.19564, saving model to best.model\n",
      "0s - loss: 0.2359 - acc: 0.9162 - val_loss: 0.1956 - val_acc: 0.9241\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2297 - acc: 0.9194 - val_loss: 0.1963 - val_acc: 0.9279\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19564 to 0.19002, saving model to best.model\n",
      "0s - loss: 0.2236 - acc: 0.9214 - val_loss: 0.1900 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19002 to 0.18839, saving model to best.model\n",
      "0s - loss: 0.2244 - acc: 0.9192 - val_loss: 0.1884 - val_acc: 0.9279\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18839 to 0.18373, saving model to best.model\n",
      "0s - loss: 0.2182 - acc: 0.9238 - val_loss: 0.1837 - val_acc: 0.9260\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18373 to 0.17838, saving model to best.model\n",
      "0s - loss: 0.2129 - acc: 0.9226 - val_loss: 0.1784 - val_acc: 0.9318\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2183 - acc: 0.9226 - val_loss: 0.1803 - val_acc: 0.9279\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17838 to 0.17246, saving model to best.model\n",
      "0s - loss: 0.2082 - acc: 0.9265 - val_loss: 0.1725 - val_acc: 0.9328\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17246 to 0.17213, saving model to best.model\n",
      "0s - loss: 0.2092 - acc: 0.9250 - val_loss: 0.1721 - val_acc: 0.9309\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17213 to 0.16881, saving model to best.model\n",
      "0s - loss: 0.2029 - acc: 0.9277 - val_loss: 0.1688 - val_acc: 0.9309\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16881 to 0.16212, saving model to best.model\n",
      "0s - loss: 0.1951 - acc: 0.9279 - val_loss: 0.1621 - val_acc: 0.9338\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16212 to 0.15856, saving model to best.model\n",
      "0s - loss: 0.1955 - acc: 0.9311 - val_loss: 0.1586 - val_acc: 0.9357\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.2057 - acc: 0.9291 - val_loss: 0.1605 - val_acc: 0.9357\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15856 to 0.15537, saving model to best.model\n",
      "0s - loss: 0.1999 - acc: 0.9306 - val_loss: 0.1554 - val_acc: 0.9357\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15537 to 0.15198, saving model to best.model\n",
      "0s - loss: 0.1884 - acc: 0.9340 - val_loss: 0.1520 - val_acc: 0.9426\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15198 to 0.14915, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9347 - val_loss: 0.1492 - val_acc: 0.9377\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1918 - acc: 0.9299 - val_loss: 0.1511 - val_acc: 0.9377\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14915 to 0.14328, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9343 - val_loss: 0.1433 - val_acc: 0.9445\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1855 - acc: 0.9340 - val_loss: 0.1459 - val_acc: 0.9396\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14328 to 0.13955, saving model to best.model\n",
      "0s - loss: 0.1794 - acc: 0.9367 - val_loss: 0.1395 - val_acc: 0.9445\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.13955 to 0.13739, saving model to best.model\n",
      "0s - loss: 0.1775 - acc: 0.9335 - val_loss: 0.1374 - val_acc: 0.9455\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1756 - acc: 0.9411 - val_loss: 0.1412 - val_acc: 0.9406\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13739 to 0.13003, saving model to best.model\n",
      "0s - loss: 0.1795 - acc: 0.9357 - val_loss: 0.1300 - val_acc: 0.9581\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1695 - acc: 0.9396 - val_loss: 0.1317 - val_acc: 0.9464\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13003 to 0.12870, saving model to best.model\n",
      "0s - loss: 0.1615 - acc: 0.9418 - val_loss: 0.1287 - val_acc: 0.9474\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.12870 to 0.12183, saving model to best.model\n",
      "0s - loss: 0.1676 - acc: 0.9401 - val_loss: 0.1218 - val_acc: 0.9591\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12183 to 0.12036, saving model to best.model\n",
      "0s - loss: 0.1576 - acc: 0.9447 - val_loss: 0.1204 - val_acc: 0.9601\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1561 - acc: 0.9430 - val_loss: 0.1214 - val_acc: 0.9552\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12036 to 0.11614, saving model to best.model\n",
      "0s - loss: 0.1582 - acc: 0.9428 - val_loss: 0.1161 - val_acc: 0.9649\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11614 to 0.11404, saving model to best.model\n",
      "0s - loss: 0.1579 - acc: 0.9469 - val_loss: 0.1140 - val_acc: 0.9679\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11404 to 0.11172, saving model to best.model\n",
      "0s - loss: 0.1510 - acc: 0.9438 - val_loss: 0.1117 - val_acc: 0.9688\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11172 to 0.10957, saving model to best.model\n",
      "0s - loss: 0.1464 - acc: 0.9508 - val_loss: 0.1096 - val_acc: 0.9669\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10957 to 0.10586, saving model to best.model\n",
      "0s - loss: 0.1470 - acc: 0.9472 - val_loss: 0.1059 - val_acc: 0.9708\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10586 to 0.10550, saving model to best.model\n",
      "0s - loss: 0.1422 - acc: 0.9501 - val_loss: 0.1055 - val_acc: 0.9688\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10550 to 0.10539, saving model to best.model\n",
      "0s - loss: 0.1427 - acc: 0.9462 - val_loss: 0.1054 - val_acc: 0.9669\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10539 to 0.09954, saving model to best.model\n",
      "0s - loss: 0.1492 - acc: 0.9481 - val_loss: 0.0995 - val_acc: 0.9727\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09954 to 0.09831, saving model to best.model\n",
      "0s - loss: 0.1426 - acc: 0.9511 - val_loss: 0.0983 - val_acc: 0.9737\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09831 to 0.09624, saving model to best.model\n",
      "0s - loss: 0.1423 - acc: 0.9479 - val_loss: 0.0962 - val_acc: 0.9718\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09624 to 0.09444, saving model to best.model\n",
      "0s - loss: 0.1382 - acc: 0.9503 - val_loss: 0.0944 - val_acc: 0.9727\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09444 to 0.09306, saving model to best.model\n",
      "0s - loss: 0.1388 - acc: 0.9520 - val_loss: 0.0931 - val_acc: 0.9737\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09306 to 0.09151, saving model to best.model\n",
      "0s - loss: 0.1301 - acc: 0.9550 - val_loss: 0.0915 - val_acc: 0.9747\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.09151 to 0.08869, saving model to best.model\n",
      "0s - loss: 0.1303 - acc: 0.9525 - val_loss: 0.0887 - val_acc: 0.9747\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08869 to 0.08558, saving model to best.model\n",
      "0s - loss: 0.1307 - acc: 0.9540 - val_loss: 0.0856 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08558 to 0.08304, saving model to best.model\n",
      "0s - loss: 0.1286 - acc: 0.9559 - val_loss: 0.0830 - val_acc: 0.9766\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08304 to 0.08092, saving model to best.model\n",
      "0s - loss: 0.1336 - acc: 0.9533 - val_loss: 0.0809 - val_acc: 0.9766\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08092 to 0.07977, saving model to best.model\n",
      "0s - loss: 0.1230 - acc: 0.9562 - val_loss: 0.0798 - val_acc: 0.9757\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07977 to 0.07546, saving model to best.model\n",
      "0s - loss: 0.1217 - acc: 0.9574 - val_loss: 0.0755 - val_acc: 0.9805\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1218 - acc: 0.9559 - val_loss: 0.0759 - val_acc: 0.9766\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07546 to 0.07116, saving model to best.model\n",
      "0s - loss: 0.1147 - acc: 0.9584 - val_loss: 0.0712 - val_acc: 0.9805\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07116 to 0.07039, saving model to best.model\n",
      "0s - loss: 0.1085 - acc: 0.9610 - val_loss: 0.0704 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07039 to 0.06759, saving model to best.model\n",
      "0s - loss: 0.1031 - acc: 0.9635 - val_loss: 0.0676 - val_acc: 0.9796\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06759 to 0.06607, saving model to best.model\n",
      "0s - loss: 0.1088 - acc: 0.9613 - val_loss: 0.0661 - val_acc: 0.9796\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06607 to 0.06457, saving model to best.model\n",
      "0s - loss: 0.1091 - acc: 0.9645 - val_loss: 0.0646 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1085 - acc: 0.9584 - val_loss: 0.0659 - val_acc: 0.9796\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06457 to 0.06316, saving model to best.model\n",
      "0s - loss: 0.1094 - acc: 0.9589 - val_loss: 0.0632 - val_acc: 0.9796\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06316 to 0.06015, saving model to best.model\n",
      "0s - loss: 0.1025 - acc: 0.9596 - val_loss: 0.0602 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06015 to 0.05976, saving model to best.model\n",
      "0s - loss: 0.1089 - acc: 0.9606 - val_loss: 0.0598 - val_acc: 0.9815\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05976 to 0.05700, saving model to best.model\n",
      "0s - loss: 0.1027 - acc: 0.9623 - val_loss: 0.0570 - val_acc: 0.9825\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05700 to 0.05512, saving model to best.model\n",
      "0s - loss: 0.1014 - acc: 0.9630 - val_loss: 0.0551 - val_acc: 0.9825\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05512 to 0.05260, saving model to best.model\n",
      "0s - loss: 0.0968 - acc: 0.9640 - val_loss: 0.0526 - val_acc: 0.9844\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05260 to 0.05087, saving model to best.model\n",
      "0s - loss: 0.0991 - acc: 0.9625 - val_loss: 0.0509 - val_acc: 0.9844\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05087 to 0.04942, saving model to best.model\n",
      "0s - loss: 0.0928 - acc: 0.9654 - val_loss: 0.0494 - val_acc: 0.9844\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04942 to 0.04930, saving model to best.model\n",
      "0s - loss: 0.0903 - acc: 0.9679 - val_loss: 0.0493 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04930 to 0.04728, saving model to best.model\n",
      "0s - loss: 0.0918 - acc: 0.9691 - val_loss: 0.0473 - val_acc: 0.9854\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04728 to 0.04534, saving model to best.model\n",
      "0s - loss: 0.0938 - acc: 0.9659 - val_loss: 0.0453 - val_acc: 0.9854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04534 to 0.04465, saving model to best.model\n",
      "0s - loss: 0.0895 - acc: 0.9693 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04465 to 0.04426, saving model to best.model\n",
      "0s - loss: 0.0990 - acc: 0.9642 - val_loss: 0.0443 - val_acc: 0.9854\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04426 to 0.04242, saving model to best.model\n",
      "0s - loss: 0.0854 - acc: 0.9691 - val_loss: 0.0424 - val_acc: 0.9854\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04242 to 0.04145, saving model to best.model\n",
      "0s - loss: 0.0829 - acc: 0.9713 - val_loss: 0.0415 - val_acc: 0.9854\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04145 to 0.03997, saving model to best.model\n",
      "0s - loss: 0.0770 - acc: 0.9720 - val_loss: 0.0400 - val_acc: 0.9854\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0885 - acc: 0.9674 - val_loss: 0.0440 - val_acc: 0.9903\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03997 to 0.03772, saving model to best.model\n",
      "0s - loss: 0.0902 - acc: 0.9669 - val_loss: 0.0377 - val_acc: 0.9854\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0861 - acc: 0.9676 - val_loss: 0.0377 - val_acc: 0.9864\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0817 - acc: 0.9720 - val_loss: 0.0378 - val_acc: 0.9864\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03772 to 0.03700, saving model to best.model\n",
      "0s - loss: 0.0818 - acc: 0.9722 - val_loss: 0.0370 - val_acc: 0.9854\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03700 to 0.03644, saving model to best.model\n",
      "0s - loss: 0.0801 - acc: 0.9713 - val_loss: 0.0364 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03644 to 0.03469, saving model to best.model\n",
      "0s - loss: 0.0799 - acc: 0.9727 - val_loss: 0.0347 - val_acc: 0.9864\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03469 to 0.03410, saving model to best.model\n",
      "0s - loss: 0.0696 - acc: 0.9771 - val_loss: 0.0341 - val_acc: 0.9903\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03410 to 0.03182, saving model to best.model\n",
      "0s - loss: 0.0752 - acc: 0.9720 - val_loss: 0.0318 - val_acc: 0.9864\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03182 to 0.03132, saving model to best.model\n",
      "0s - loss: 0.0762 - acc: 0.9735 - val_loss: 0.0313 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9778 - val_loss: 0.0318 - val_acc: 0.9903\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03132 to 0.02990, saving model to best.model\n",
      "0s - loss: 0.0766 - acc: 0.9698 - val_loss: 0.0299 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0688 - acc: 0.9747 - val_loss: 0.0305 - val_acc: 0.9912\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02990 to 0.02842, saving model to best.model\n",
      "0s - loss: 0.0663 - acc: 0.9764 - val_loss: 0.0284 - val_acc: 0.9922\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02842 to 0.02768, saving model to best.model\n",
      "0s - loss: 0.0690 - acc: 0.9754 - val_loss: 0.0277 - val_acc: 0.9922\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0698 - acc: 0.9759 - val_loss: 0.0285 - val_acc: 0.9922\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02768 to 0.02707, saving model to best.model\n",
      "0s - loss: 0.0735 - acc: 0.9727 - val_loss: 0.0271 - val_acc: 0.9922\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02707 to 0.02641, saving model to best.model\n",
      "0s - loss: 0.0738 - acc: 0.9737 - val_loss: 0.0264 - val_acc: 0.9932\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02641 to 0.02625, saving model to best.model\n",
      "0s - loss: 0.0676 - acc: 0.9737 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02625 to 0.02561, saving model to best.model\n",
      "0s - loss: 0.0671 - acc: 0.9747 - val_loss: 0.0256 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02561 to 0.02445, saving model to best.model\n",
      "0s - loss: 0.0629 - acc: 0.9776 - val_loss: 0.0244 - val_acc: 0.9932\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0620 - acc: 0.9764 - val_loss: 0.0247 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02445 to 0.02333, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9776 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02333 to 0.02234, saving model to best.model\n",
      "0s - loss: 0.0665 - acc: 0.9766 - val_loss: 0.0223 - val_acc: 0.9932\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0634 - acc: 0.9786 - val_loss: 0.0266 - val_acc: 0.9912\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02234 to 0.02232, saving model to best.model\n",
      "0s - loss: 0.0677 - acc: 0.9744 - val_loss: 0.0223 - val_acc: 0.9922\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0646 - acc: 0.9783 - val_loss: 0.0227 - val_acc: 0.9942\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0713 - acc: 0.9737 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02232 to 0.02133, saving model to best.model\n",
      "0s - loss: 0.0614 - acc: 0.9761 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02133 to 0.01984, saving model to best.model\n",
      "0s - loss: 0.0546 - acc: 0.9830 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.01984 to 0.01890, saving model to best.model\n",
      "0s - loss: 0.0575 - acc: 0.9783 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01890 to 0.01888, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9805 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0551 - acc: 0.9808 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01888 to 0.01811, saving model to best.model\n",
      "0s - loss: 0.0594 - acc: 0.9776 - val_loss: 0.0181 - val_acc: 0.9932\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0573 - acc: 0.9791 - val_loss: 0.0196 - val_acc: 0.9932\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0589 - acc: 0.9808 - val_loss: 0.0181 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0561 - acc: 0.9791 - val_loss: 0.0197 - val_acc: 0.9932\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01811 to 0.01806, saving model to best.model\n",
      "0s - loss: 0.0550 - acc: 0.9808 - val_loss: 0.0181 - val_acc: 0.9932\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0542 - acc: 0.9793 - val_loss: 0.0193 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01806 to 0.01726, saving model to best.model\n",
      "0s - loss: 0.0587 - acc: 0.9793 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01726 to 0.01668, saving model to best.model\n",
      "0s - loss: 0.0513 - acc: 0.9803 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01668 to 0.01620, saving model to best.model\n",
      "0s - loss: 0.0539 - acc: 0.9813 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01620 to 0.01603, saving model to best.model\n",
      "0s - loss: 0.0525 - acc: 0.9798 - val_loss: 0.0160 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01603 to 0.01480, saving model to best.model\n",
      "0s - loss: 0.0444 - acc: 0.9834 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01480 to 0.01422, saving model to best.model\n",
      "0s - loss: 0.0560 - acc: 0.9808 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01422 to 0.01419, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9830 - val_loss: 0.0142 - val_acc: 0.9942\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01419 to 0.01401, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9837 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9827 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01401 to 0.01325, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9837 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01325 to 0.01194, saving model to best.model\n",
      "0s - loss: 0.0504 - acc: 0.9839 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9842 - val_loss: 0.0136 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9830 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9810 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01194 to 0.01157, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9839 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9839 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9834 - val_loss: 0.0152 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01157 to 0.01106, saving model to best.model\n",
      "0s - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0111 - val_acc: 0.9942\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9849 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9864 - val_loss: 0.0111 - val_acc: 0.9942\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9830 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01106 to 0.01020, saving model to best.model\n",
      "0s - loss: 0.0478 - acc: 0.9817 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9832 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9834 - val_loss: 0.0106 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9859 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9842 - val_loss: 0.0121 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9866 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01020 to 0.00966, saving model to best.model\n",
      "0s - loss: 0.0398 - acc: 0.9832 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9822 - val_loss: 0.0108 - val_acc: 0.9942\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.00966 to 0.00945, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9866 - val_loss: 0.0094 - val_acc: 0.9942\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.00945 to 0.00871, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9856 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9827 - val_loss: 0.0090 - val_acc: 0.9961\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.00871 to 0.00868, saving model to best.model\n",
      "0s - loss: 0.0487 - acc: 0.9815 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.00868 to 0.00864, saving model to best.model\n",
      "0s - loss: 0.0414 - acc: 0.9837 - val_loss: 0.0086 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.00864 to 0.00828, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9890 - val_loss: 0.0083 - val_acc: 0.9951\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9871 - val_loss: 0.0084 - val_acc: 0.9961\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9869 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.00828 to 0.00756, saving model to best.model\n",
      "0s - loss: 0.0403 - acc: 0.9864 - val_loss: 0.0076 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9886 - val_loss: 0.0083 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9866 - val_loss: 0.0077 - val_acc: 0.9951\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.00756 to 0.00725, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9851 - val_loss: 0.0073 - val_acc: 0.9961\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9886 - val_loss: 0.0078 - val_acc: 0.9961\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9871 - val_loss: 0.0073 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.00725 to 0.00697, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9861 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.00697 to 0.00679, saving model to best.model\n",
      "0s - loss: 0.0372 - acc: 0.9861 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.00679 to 0.00641, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9847 - val_loss: 0.0064 - val_acc: 0.9971\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00641 to 0.00628, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9883 - val_loss: 0.0063 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9864 - val_loss: 0.0063 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9869 - val_loss: 0.0082 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9849 - val_loss: 0.0077 - val_acc: 0.9961\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9876 - val_loss: 0.0081 - val_acc: 0.9961\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9854 - val_loss: 0.0064 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9881 - val_loss: 0.0068 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00628 to 0.00561, saving model to best.model\n",
      "0s - loss: 0.0337 - acc: 0.9869 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9866 - val_loss: 0.0058 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9890 - val_loss: 0.0057 - val_acc: 0.9971\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00561 to 0.00559, saving model to best.model\n",
      "0s - loss: 0.0267 - acc: 0.9920 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00559 to 0.00488, saving model to best.model\n",
      "0s - loss: 0.0325 - acc: 0.9873 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9861 - val_loss: 0.0062 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9890 - val_loss: 0.0064 - val_acc: 0.9961\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9873 - val_loss: 0.0056 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9847 - val_loss: 0.0053 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67875, saving model to best.model\n",
      "0s - loss: 0.7860 - acc: 0.5021 - val_loss: 0.6787 - val_acc: 0.4606\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67875 to 0.63999, saving model to best.model\n",
      "0s - loss: 0.7446 - acc: 0.5138 - val_loss: 0.6400 - val_acc: 0.8062\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63999 to 0.59216, saving model to best.model\n",
      "0s - loss: 0.6790 - acc: 0.5888 - val_loss: 0.5922 - val_acc: 0.8062\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59216 to 0.51888, saving model to best.model\n",
      "0s - loss: 0.6172 - acc: 0.6596 - val_loss: 0.5189 - val_acc: 0.8179\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51888 to 0.44593, saving model to best.model\n",
      "0s - loss: 0.5411 - acc: 0.7353 - val_loss: 0.4459 - val_acc: 0.8277\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44593 to 0.40106, saving model to best.model\n",
      "0s - loss: 0.4736 - acc: 0.7891 - val_loss: 0.4011 - val_acc: 0.8423\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40106 to 0.37495, saving model to best.model\n",
      "0s - loss: 0.4429 - acc: 0.8062 - val_loss: 0.3749 - val_acc: 0.8530\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37495 to 0.35254, saving model to best.model\n",
      "0s - loss: 0.4071 - acc: 0.8374 - val_loss: 0.3525 - val_acc: 0.8647\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35254 to 0.33273, saving model to best.model\n",
      "0s - loss: 0.3853 - acc: 0.8417 - val_loss: 0.3327 - val_acc: 0.8685\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33273 to 0.31565, saving model to best.model\n",
      "0s - loss: 0.3602 - acc: 0.8576 - val_loss: 0.3157 - val_acc: 0.8744\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31565 to 0.30101, saving model to best.model\n",
      "0s - loss: 0.3506 - acc: 0.8556 - val_loss: 0.3010 - val_acc: 0.8754\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30101 to 0.28966, saving model to best.model\n",
      "0s - loss: 0.3333 - acc: 0.8675 - val_loss: 0.2897 - val_acc: 0.8802\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28966 to 0.27729, saving model to best.model\n",
      "0s - loss: 0.3244 - acc: 0.8731 - val_loss: 0.2773 - val_acc: 0.8841\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27729 to 0.26708, saving model to best.model\n",
      "0s - loss: 0.3163 - acc: 0.8739 - val_loss: 0.2671 - val_acc: 0.8909\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.3066 - acc: 0.8756 - val_loss: 0.2717 - val_acc: 0.8948\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26708 to 0.25606, saving model to best.model\n",
      "0s - loss: 0.3014 - acc: 0.8839 - val_loss: 0.2561 - val_acc: 0.8958\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25606 to 0.24735, saving model to best.model\n",
      "0s - loss: 0.2888 - acc: 0.8887 - val_loss: 0.2474 - val_acc: 0.8968\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2906 - acc: 0.8902 - val_loss: 0.2494 - val_acc: 0.8997\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24735 to 0.23529, saving model to best.model\n",
      "0s - loss: 0.2824 - acc: 0.8941 - val_loss: 0.2353 - val_acc: 0.9017\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23529 to 0.23234, saving model to best.model\n",
      "0s - loss: 0.2717 - acc: 0.8968 - val_loss: 0.2323 - val_acc: 0.9075\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23234 to 0.22350, saving model to best.model\n",
      "0s - loss: 0.2692 - acc: 0.8972 - val_loss: 0.2235 - val_acc: 0.9085\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22350 to 0.21820, saving model to best.model\n",
      "0s - loss: 0.2551 - acc: 0.9050 - val_loss: 0.2182 - val_acc: 0.9075\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21820 to 0.21257, saving model to best.model\n",
      "0s - loss: 0.2525 - acc: 0.9082 - val_loss: 0.2126 - val_acc: 0.9114\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21257 to 0.20862, saving model to best.model\n",
      "0s - loss: 0.2548 - acc: 0.9060 - val_loss: 0.2086 - val_acc: 0.9114\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20862 to 0.20166, saving model to best.model\n",
      "0s - loss: 0.2421 - acc: 0.9121 - val_loss: 0.2017 - val_acc: 0.9143\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2427 - acc: 0.9106 - val_loss: 0.2056 - val_acc: 0.9133\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20166 to 0.19523, saving model to best.model\n",
      "0s - loss: 0.2428 - acc: 0.9067 - val_loss: 0.1952 - val_acc: 0.9192\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19523 to 0.19427, saving model to best.model\n",
      "0s - loss: 0.2334 - acc: 0.9119 - val_loss: 0.1943 - val_acc: 0.9163\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19427 to 0.18879, saving model to best.model\n",
      "0s - loss: 0.2360 - acc: 0.9106 - val_loss: 0.1888 - val_acc: 0.9172\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18879 to 0.18328, saving model to best.model\n",
      "0s - loss: 0.2332 - acc: 0.9148 - val_loss: 0.1833 - val_acc: 0.9250\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2365 - acc: 0.9160 - val_loss: 0.1856 - val_acc: 0.9172\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18328 to 0.17778, saving model to best.model\n",
      "0s - loss: 0.2273 - acc: 0.9138 - val_loss: 0.1778 - val_acc: 0.9231\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17778 to 0.17727, saving model to best.model\n",
      "0s - loss: 0.2186 - acc: 0.9194 - val_loss: 0.1773 - val_acc: 0.9172\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17727 to 0.16931, saving model to best.model\n",
      "0s - loss: 0.2147 - acc: 0.9218 - val_loss: 0.1693 - val_acc: 0.9464\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.2184 - acc: 0.9177 - val_loss: 0.1716 - val_acc: 0.9192\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.16931 to 0.15848, saving model to best.model\n",
      "0s - loss: 0.2119 - acc: 0.9179 - val_loss: 0.1585 - val_acc: 0.9435\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.15848 to 0.15558, saving model to best.model\n",
      "0s - loss: 0.2078 - acc: 0.9223 - val_loss: 0.1556 - val_acc: 0.9338\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.15558 to 0.15536, saving model to best.model\n",
      "0s - loss: 0.2043 - acc: 0.9257 - val_loss: 0.1554 - val_acc: 0.9289\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.15536 to 0.14799, saving model to best.model\n",
      "0s - loss: 0.1955 - acc: 0.9279 - val_loss: 0.1480 - val_acc: 0.9455\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.14799 to 0.14675, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9257 - val_loss: 0.1468 - val_acc: 0.9328\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.14675 to 0.13831, saving model to best.model\n",
      "0s - loss: 0.1938 - acc: 0.9260 - val_loss: 0.1383 - val_acc: 0.9484\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.13831 to 0.13432, saving model to best.model\n",
      "0s - loss: 0.1833 - acc: 0.9277 - val_loss: 0.1343 - val_acc: 0.9455\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.13432 to 0.13313, saving model to best.model\n",
      "0s - loss: 0.1864 - acc: 0.9257 - val_loss: 0.1331 - val_acc: 0.9464\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13313 to 0.12901, saving model to best.model\n",
      "0s - loss: 0.1897 - acc: 0.9296 - val_loss: 0.1290 - val_acc: 0.9494\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.12901 to 0.12388, saving model to best.model\n",
      "0s - loss: 0.1711 - acc: 0.9352 - val_loss: 0.1239 - val_acc: 0.9552\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.12388 to 0.11795, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9377 - val_loss: 0.1179 - val_acc: 0.9552\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.11795 to 0.11430, saving model to best.model\n",
      "0s - loss: 0.1753 - acc: 0.9355 - val_loss: 0.1143 - val_acc: 0.9601\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.11430 to 0.11154, saving model to best.model\n",
      "0s - loss: 0.1672 - acc: 0.9382 - val_loss: 0.1115 - val_acc: 0.9552\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.11154 to 0.11063, saving model to best.model\n",
      "0s - loss: 0.1578 - acc: 0.9413 - val_loss: 0.1106 - val_acc: 0.9533\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.11063 to 0.10672, saving model to best.model\n",
      "0s - loss: 0.1613 - acc: 0.9413 - val_loss: 0.1067 - val_acc: 0.9630\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.10672 to 0.10400, saving model to best.model\n",
      "0s - loss: 0.1612 - acc: 0.9379 - val_loss: 0.1040 - val_acc: 0.9688\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.10400 to 0.10104, saving model to best.model\n",
      "0s - loss: 0.1555 - acc: 0.9423 - val_loss: 0.1010 - val_acc: 0.9659\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.10104 to 0.10043, saving model to best.model\n",
      "0s - loss: 0.1576 - acc: 0.9411 - val_loss: 0.1004 - val_acc: 0.9649\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10043 to 0.09726, saving model to best.model\n",
      "0s - loss: 0.1376 - acc: 0.9496 - val_loss: 0.0973 - val_acc: 0.9659\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1469 - acc: 0.9447 - val_loss: 0.1049 - val_acc: 0.9727\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1739 - acc: 0.9352 - val_loss: 0.1030 - val_acc: 0.9562\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09726 to 0.09290, saving model to best.model\n",
      "0s - loss: 0.1490 - acc: 0.9421 - val_loss: 0.0929 - val_acc: 0.9679\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09290 to 0.08909, saving model to best.model\n",
      "0s - loss: 0.1346 - acc: 0.9508 - val_loss: 0.0891 - val_acc: 0.9708\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.08909 to 0.08553, saving model to best.model\n",
      "0s - loss: 0.1320 - acc: 0.9506 - val_loss: 0.0855 - val_acc: 0.9757\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.08553 to 0.08533, saving model to best.model\n",
      "0s - loss: 0.1376 - acc: 0.9525 - val_loss: 0.0853 - val_acc: 0.9698\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08533 to 0.08508, saving model to best.model\n",
      "0s - loss: 0.1401 - acc: 0.9467 - val_loss: 0.0851 - val_acc: 0.9757\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1310 - acc: 0.9518 - val_loss: 0.0854 - val_acc: 0.9766\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08508 to 0.08083, saving model to best.model\n",
      "0s - loss: 0.1290 - acc: 0.9540 - val_loss: 0.0808 - val_acc: 0.9757\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08083 to 0.07785, saving model to best.model\n",
      "0s - loss: 0.1273 - acc: 0.9506 - val_loss: 0.0778 - val_acc: 0.9757\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1285 - acc: 0.9486 - val_loss: 0.0817 - val_acc: 0.9747\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07785 to 0.07447, saving model to best.model\n",
      "0s - loss: 0.1221 - acc: 0.9554 - val_loss: 0.0745 - val_acc: 0.9757\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07447 to 0.07297, saving model to best.model\n",
      "0s - loss: 0.1192 - acc: 0.9547 - val_loss: 0.0730 - val_acc: 0.9757\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07297 to 0.07246, saving model to best.model\n",
      "0s - loss: 0.1098 - acc: 0.9550 - val_loss: 0.0725 - val_acc: 0.9796\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07246 to 0.07111, saving model to best.model\n",
      "0s - loss: 0.1079 - acc: 0.9625 - val_loss: 0.0711 - val_acc: 0.9796\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07111 to 0.06752, saving model to best.model\n",
      "0s - loss: 0.1107 - acc: 0.9623 - val_loss: 0.0675 - val_acc: 0.9796\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06752 to 0.06676, saving model to best.model\n",
      "0s - loss: 0.1084 - acc: 0.9615 - val_loss: 0.0668 - val_acc: 0.9815\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1096 - acc: 0.9598 - val_loss: 0.0683 - val_acc: 0.9834\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06676 to 0.06399, saving model to best.model\n",
      "0s - loss: 0.1115 - acc: 0.9603 - val_loss: 0.0640 - val_acc: 0.9854\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06399 to 0.06205, saving model to best.model\n",
      "0s - loss: 0.0981 - acc: 0.9645 - val_loss: 0.0621 - val_acc: 0.9815\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06205 to 0.06133, saving model to best.model\n",
      "0s - loss: 0.1027 - acc: 0.9613 - val_loss: 0.0613 - val_acc: 0.9834\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1099 - acc: 0.9567 - val_loss: 0.0615 - val_acc: 0.9864\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06133 to 0.05777, saving model to best.model\n",
      "0s - loss: 0.0914 - acc: 0.9693 - val_loss: 0.0578 - val_acc: 0.9854\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.05777 to 0.05598, saving model to best.model\n",
      "0s - loss: 0.0947 - acc: 0.9669 - val_loss: 0.0560 - val_acc: 0.9864\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1106 - acc: 0.9591 - val_loss: 0.0580 - val_acc: 0.9883\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1045 - acc: 0.9598 - val_loss: 0.0575 - val_acc: 0.9883\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05598 to 0.05473, saving model to best.model\n",
      "0s - loss: 0.0977 - acc: 0.9618 - val_loss: 0.0547 - val_acc: 0.9854\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05473 to 0.05467, saving model to best.model\n",
      "0s - loss: 0.0944 - acc: 0.9652 - val_loss: 0.0547 - val_acc: 0.9893\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05467 to 0.05404, saving model to best.model\n",
      "0s - loss: 0.1012 - acc: 0.9606 - val_loss: 0.0540 - val_acc: 0.9873\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05404 to 0.05398, saving model to best.model\n",
      "0s - loss: 0.0925 - acc: 0.9671 - val_loss: 0.0540 - val_acc: 0.9883\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05398 to 0.05171, saving model to best.model\n",
      "0s - loss: 0.0942 - acc: 0.9637 - val_loss: 0.0517 - val_acc: 0.9844\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05171 to 0.04951, saving model to best.model\n",
      "0s - loss: 0.0903 - acc: 0.9688 - val_loss: 0.0495 - val_acc: 0.9903\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0861 - acc: 0.9686 - val_loss: 0.0511 - val_acc: 0.9893\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04951 to 0.04882, saving model to best.model\n",
      "0s - loss: 0.0805 - acc: 0.9705 - val_loss: 0.0488 - val_acc: 0.9903\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04882 to 0.04770, saving model to best.model\n",
      "0s - loss: 0.0833 - acc: 0.9669 - val_loss: 0.0477 - val_acc: 0.9903\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04770 to 0.04606, saving model to best.model\n",
      "0s - loss: 0.0835 - acc: 0.9698 - val_loss: 0.0461 - val_acc: 0.9903\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04606 to 0.04543, saving model to best.model\n",
      "0s - loss: 0.0925 - acc: 0.9654 - val_loss: 0.0454 - val_acc: 0.9873\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0838 - acc: 0.9679 - val_loss: 0.0542 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04543 to 0.04502, saving model to best.model\n",
      "0s - loss: 0.0791 - acc: 0.9691 - val_loss: 0.0450 - val_acc: 0.9893\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0841 - acc: 0.9683 - val_loss: 0.0453 - val_acc: 0.9903\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0819 - acc: 0.9703 - val_loss: 0.0455 - val_acc: 0.9825\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04502 to 0.04444, saving model to best.model\n",
      "0s - loss: 0.0756 - acc: 0.9701 - val_loss: 0.0444 - val_acc: 0.9903\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04444 to 0.04398, saving model to best.model\n",
      "0s - loss: 0.0753 - acc: 0.9703 - val_loss: 0.0440 - val_acc: 0.9903\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04398 to 0.04059, saving model to best.model\n",
      "0s - loss: 0.0782 - acc: 0.9705 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0698 - acc: 0.9747 - val_loss: 0.0408 - val_acc: 0.9903\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04059 to 0.03820, saving model to best.model\n",
      "0s - loss: 0.0735 - acc: 0.9718 - val_loss: 0.0382 - val_acc: 0.9903\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03820 to 0.03549, saving model to best.model\n",
      "0s - loss: 0.0699 - acc: 0.9732 - val_loss: 0.0355 - val_acc: 0.9903\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0714 - acc: 0.9764 - val_loss: 0.0364 - val_acc: 0.9903\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03549 to 0.03487, saving model to best.model\n",
      "0s - loss: 0.0707 - acc: 0.9732 - val_loss: 0.0349 - val_acc: 0.9903\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03487 to 0.03356, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9698 - val_loss: 0.0336 - val_acc: 0.9903\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0650 - acc: 0.9757 - val_loss: 0.0341 - val_acc: 0.9903\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03356 to 0.03218, saving model to best.model\n",
      "0s - loss: 0.0658 - acc: 0.9764 - val_loss: 0.0322 - val_acc: 0.9893\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9757 - val_loss: 0.0340 - val_acc: 0.9903\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03218 to 0.03217, saving model to best.model\n",
      "0s - loss: 0.0683 - acc: 0.9739 - val_loss: 0.0322 - val_acc: 0.9903\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9759 - val_loss: 0.0324 - val_acc: 0.9903\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03217 to 0.03120, saving model to best.model\n",
      "0s - loss: 0.0677 - acc: 0.9742 - val_loss: 0.0312 - val_acc: 0.9903\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03120 to 0.03022, saving model to best.model\n",
      "0s - loss: 0.0638 - acc: 0.9774 - val_loss: 0.0302 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0614 - acc: 0.9766 - val_loss: 0.0321 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03022 to 0.03021, saving model to best.model\n",
      "0s - loss: 0.0550 - acc: 0.9803 - val_loss: 0.0302 - val_acc: 0.9893\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.03021 to 0.02971, saving model to best.model\n",
      "0s - loss: 0.0678 - acc: 0.9747 - val_loss: 0.0297 - val_acc: 0.9893\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0679 - acc: 0.9730 - val_loss: 0.0306 - val_acc: 0.9912\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02971 to 0.02592, saving model to best.model\n",
      "0s - loss: 0.0597 - acc: 0.9774 - val_loss: 0.0259 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0584 - acc: 0.9783 - val_loss: 0.0276 - val_acc: 0.9903\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9778 - val_loss: 0.0262 - val_acc: 0.9903\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02592 to 0.02583, saving model to best.model\n",
      "0s - loss: 0.0565 - acc: 0.9783 - val_loss: 0.0258 - val_acc: 0.9903\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0621 - acc: 0.9783 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.02583 to 0.02399, saving model to best.model\n",
      "0s - loss: 0.0580 - acc: 0.9793 - val_loss: 0.0240 - val_acc: 0.9903\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9803 - val_loss: 0.0260 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0532 - acc: 0.9803 - val_loss: 0.0256 - val_acc: 0.9903\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02399 to 0.02296, saving model to best.model\n",
      "0s - loss: 0.0584 - acc: 0.9783 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02296 to 0.02191, saving model to best.model\n",
      "0s - loss: 0.0578 - acc: 0.9798 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0529 - acc: 0.9815 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02191 to 0.02044, saving model to best.model\n",
      "0s - loss: 0.0579 - acc: 0.9783 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9783 - val_loss: 0.0242 - val_acc: 0.9912\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0551 - acc: 0.9808 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0523 - acc: 0.9783 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02044 to 0.02037, saving model to best.model\n",
      "0s - loss: 0.0504 - acc: 0.9822 - val_loss: 0.0204 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9825 - val_loss: 0.0236 - val_acc: 0.9912\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02037 to 0.02018, saving model to best.model\n",
      "0s - loss: 0.0555 - acc: 0.9798 - val_loss: 0.0202 - val_acc: 0.9922\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0504 - acc: 0.9830 - val_loss: 0.0207 - val_acc: 0.9922\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9810 - val_loss: 0.0211 - val_acc: 0.9912\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.02018 to 0.01792, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9817 - val_loss: 0.0179 - val_acc: 0.9922\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9844 - val_loss: 0.0192 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.01792 to 0.01653, saving model to best.model\n",
      "0s - loss: 0.0494 - acc: 0.9815 - val_loss: 0.0165 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9815 - val_loss: 0.0187 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9837 - val_loss: 0.0191 - val_acc: 0.9922\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9817 - val_loss: 0.0166 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9786 - val_loss: 0.0192 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9832 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9837 - val_loss: 0.0175 - val_acc: 0.9922\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01653 to 0.01563, saving model to best.model\n",
      "0s - loss: 0.0420 - acc: 0.9856 - val_loss: 0.0156 - val_acc: 0.9922\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9854 - val_loss: 0.0166 - val_acc: 0.9932\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9839 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01563 to 0.01505, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9832 - val_loss: 0.0151 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01505 to 0.01401, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9854 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9808 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9822 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.01401 to 0.01369, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9842 - val_loss: 0.0137 - val_acc: 0.9951\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9837 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01369 to 0.01362, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9864 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9847 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9849 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01362 to 0.01351, saving model to best.model\n",
      "0s - loss: 0.0374 - acc: 0.9856 - val_loss: 0.0135 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01351 to 0.01267, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9851 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01267 to 0.01256, saving model to best.model\n",
      "0s - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0126 - val_acc: 0.9942\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9854 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01256 to 0.01107, saving model to best.model\n",
      "0s - loss: 0.0404 - acc: 0.9859 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0404 - acc: 0.9849 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9822 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9856 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9876 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9834 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01107 to 0.01032, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9851 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9866 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9859 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9869 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9881 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9873 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9869 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9859 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9859 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01032 to 0.00988, saving model to best.model\n",
      "0s - loss: 0.0366 - acc: 0.9854 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9873 - val_loss: 0.0144 - val_acc: 0.9922\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9878 - val_loss: 0.0106 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.00988 to 0.00919, saving model to best.model\n",
      "0s - loss: 0.0344 - acc: 0.9871 - val_loss: 0.0092 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9888 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9864 - val_loss: 0.0094 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9876 - val_loss: 0.0105 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9873 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9878 - val_loss: 0.0139 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9886 - val_loss: 0.0110 - val_acc: 0.9942\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9876 - val_loss: 0.0096 - val_acc: 0.9961\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9915 - val_loss: 0.0114 - val_acc: 0.9942\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9895 - val_loss: 0.0112 - val_acc: 0.9942\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00919 to 0.00788, saving model to best.model\n",
      "0s - loss: 0.0275 - acc: 0.9876 - val_loss: 0.0079 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0219 - acc: 0.9925 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0244 - acc: 0.9925 - val_loss: 0.0096 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0298 - acc: 0.9890 - val_loss: 0.0082 - val_acc: 0.9961\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00788 to 0.00710, saving model to best.model\n",
      "0s - loss: 0.0251 - acc: 0.9900 - val_loss: 0.0071 - val_acc: 0.9971\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9881 - val_loss: 0.0078 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0201 - acc: 0.9917 - val_loss: 0.0079 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.00710 to 0.00629, saving model to best.model\n",
      "0s - loss: 0.0320 - acc: 0.9888 - val_loss: 0.0063 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0261 - acc: 0.9912 - val_loss: 0.0077 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0224 - acc: 0.9895 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9893 - val_loss: 0.0073 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66746, saving model to best.model\n",
      "0s - loss: 0.7799 - acc: 0.5150 - val_loss: 0.6675 - val_acc: 0.5248\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66746 to 0.63229, saving model to best.model\n",
      "0s - loss: 0.7277 - acc: 0.5391 - val_loss: 0.6323 - val_acc: 0.6855\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63229 to 0.56983, saving model to best.model\n",
      "0s - loss: 0.6653 - acc: 0.6036 - val_loss: 0.5698 - val_acc: 0.7936\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.56983 to 0.49542, saving model to best.model\n",
      "0s - loss: 0.6054 - acc: 0.6689 - val_loss: 0.4954 - val_acc: 0.8072\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.49542 to 0.44184, saving model to best.model\n",
      "0s - loss: 0.5249 - acc: 0.7434 - val_loss: 0.4418 - val_acc: 0.8208\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44184 to 0.40172, saving model to best.model\n",
      "0s - loss: 0.4683 - acc: 0.7913 - val_loss: 0.4017 - val_acc: 0.8481\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40172 to 0.37728, saving model to best.model\n",
      "0s - loss: 0.4397 - acc: 0.8135 - val_loss: 0.3773 - val_acc: 0.8588\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37728 to 0.35842, saving model to best.model\n",
      "0s - loss: 0.4141 - acc: 0.8232 - val_loss: 0.3584 - val_acc: 0.8685\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35842 to 0.33831, saving model to best.model\n",
      "0s - loss: 0.3984 - acc: 0.8383 - val_loss: 0.3383 - val_acc: 0.8744\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33831 to 0.32435, saving model to best.model\n",
      "0s - loss: 0.3774 - acc: 0.8459 - val_loss: 0.3244 - val_acc: 0.8773\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.32435 to 0.31080, saving model to best.model\n",
      "0s - loss: 0.3483 - acc: 0.8617 - val_loss: 0.3108 - val_acc: 0.8812\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31080 to 0.29562, saving model to best.model\n",
      "0s - loss: 0.3517 - acc: 0.8598 - val_loss: 0.2956 - val_acc: 0.8802\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29562 to 0.28906, saving model to best.model\n",
      "0s - loss: 0.3288 - acc: 0.8685 - val_loss: 0.2891 - val_acc: 0.8919\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.28906 to 0.27694, saving model to best.model\n",
      "0s - loss: 0.3255 - acc: 0.8785 - val_loss: 0.2769 - val_acc: 0.8900\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27694 to 0.26912, saving model to best.model\n",
      "0s - loss: 0.3015 - acc: 0.8802 - val_loss: 0.2691 - val_acc: 0.8939\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26912 to 0.26044, saving model to best.model\n",
      "0s - loss: 0.3007 - acc: 0.8895 - val_loss: 0.2604 - val_acc: 0.9007\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26044 to 0.25479, saving model to best.model\n",
      "0s - loss: 0.2914 - acc: 0.8897 - val_loss: 0.2548 - val_acc: 0.9036\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25479 to 0.24941, saving model to best.model\n",
      "0s - loss: 0.2856 - acc: 0.8943 - val_loss: 0.2494 - val_acc: 0.9065\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24941 to 0.24722, saving model to best.model\n",
      "0s - loss: 0.2795 - acc: 0.8982 - val_loss: 0.2472 - val_acc: 0.9114\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24722 to 0.24233, saving model to best.model\n",
      "0s - loss: 0.2744 - acc: 0.9014 - val_loss: 0.2423 - val_acc: 0.9114\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.24233 to 0.23556, saving model to best.model\n",
      "0s - loss: 0.2683 - acc: 0.8997 - val_loss: 0.2356 - val_acc: 0.9143\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23556 to 0.23416, saving model to best.model\n",
      "0s - loss: 0.2699 - acc: 0.8999 - val_loss: 0.2342 - val_acc: 0.9143\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23416 to 0.22890, saving model to best.model\n",
      "0s - loss: 0.2628 - acc: 0.9004 - val_loss: 0.2289 - val_acc: 0.9163\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22890 to 0.22530, saving model to best.model\n",
      "0s - loss: 0.2576 - acc: 0.9055 - val_loss: 0.2253 - val_acc: 0.9182\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22530 to 0.21982, saving model to best.model\n",
      "0s - loss: 0.2529 - acc: 0.9092 - val_loss: 0.2198 - val_acc: 0.9163\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21982 to 0.21614, saving model to best.model\n",
      "0s - loss: 0.2503 - acc: 0.9150 - val_loss: 0.2161 - val_acc: 0.9211\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21614 to 0.21444, saving model to best.model\n",
      "0s - loss: 0.2452 - acc: 0.9116 - val_loss: 0.2144 - val_acc: 0.9192\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2422 - acc: 0.9123 - val_loss: 0.2241 - val_acc: 0.9163\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.21444 to 0.21075, saving model to best.model\n",
      "0s - loss: 0.2375 - acc: 0.9150 - val_loss: 0.2108 - val_acc: 0.9260\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.21075 to 0.20607, saving model to best.model\n",
      "0s - loss: 0.2406 - acc: 0.9145 - val_loss: 0.2061 - val_acc: 0.9279\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20607 to 0.20130, saving model to best.model\n",
      "0s - loss: 0.2247 - acc: 0.9194 - val_loss: 0.2013 - val_acc: 0.9279\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20130 to 0.19896, saving model to best.model\n",
      "0s - loss: 0.2265 - acc: 0.9216 - val_loss: 0.1990 - val_acc: 0.9270\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19896 to 0.19653, saving model to best.model\n",
      "0s - loss: 0.2243 - acc: 0.9199 - val_loss: 0.1965 - val_acc: 0.9309\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19653 to 0.19212, saving model to best.model\n",
      "0s - loss: 0.2152 - acc: 0.9252 - val_loss: 0.1921 - val_acc: 0.9279\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19212 to 0.18925, saving model to best.model\n",
      "0s - loss: 0.2177 - acc: 0.9214 - val_loss: 0.1893 - val_acc: 0.9279\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2090 - acc: 0.9223 - val_loss: 0.1893 - val_acc: 0.9231\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18925 to 0.18395, saving model to best.model\n",
      "0s - loss: 0.2101 - acc: 0.9262 - val_loss: 0.1839 - val_acc: 0.9318\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18395 to 0.17998, saving model to best.model\n",
      "0s - loss: 0.2028 - acc: 0.9238 - val_loss: 0.1800 - val_acc: 0.9318\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17998 to 0.17679, saving model to best.model\n",
      "0s - loss: 0.2040 - acc: 0.9255 - val_loss: 0.1768 - val_acc: 0.9338\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17679 to 0.17338, saving model to best.model\n",
      "0s - loss: 0.2021 - acc: 0.9243 - val_loss: 0.1734 - val_acc: 0.9357\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17338 to 0.17095, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9233 - val_loss: 0.1709 - val_acc: 0.9338\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17095 to 0.16937, saving model to best.model\n",
      "0s - loss: 0.1932 - acc: 0.9299 - val_loss: 0.1694 - val_acc: 0.9328\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.16937 to 0.16554, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9260 - val_loss: 0.1655 - val_acc: 0.9435\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16554 to 0.16182, saving model to best.model\n",
      "0s - loss: 0.1869 - acc: 0.9284 - val_loss: 0.1618 - val_acc: 0.9377\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16182 to 0.15889, saving model to best.model\n",
      "0s - loss: 0.1848 - acc: 0.9294 - val_loss: 0.1589 - val_acc: 0.9377\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15889 to 0.15465, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9291 - val_loss: 0.1547 - val_acc: 0.9406\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15465 to 0.15277, saving model to best.model\n",
      "0s - loss: 0.1851 - acc: 0.9330 - val_loss: 0.1528 - val_acc: 0.9435\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15277 to 0.15115, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9328 - val_loss: 0.1512 - val_acc: 0.9445\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15115 to 0.14778, saving model to best.model\n",
      "0s - loss: 0.1668 - acc: 0.9421 - val_loss: 0.1478 - val_acc: 0.9377\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14778 to 0.14488, saving model to best.model\n",
      "0s - loss: 0.1649 - acc: 0.9423 - val_loss: 0.1449 - val_acc: 0.9377\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14488 to 0.14095, saving model to best.model\n",
      "0s - loss: 0.1643 - acc: 0.9340 - val_loss: 0.1409 - val_acc: 0.9474\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.14095 to 0.13538, saving model to best.model\n",
      "0s - loss: 0.1572 - acc: 0.9372 - val_loss: 0.1354 - val_acc: 0.9455\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13538 to 0.13381, saving model to best.model\n",
      "0s - loss: 0.1634 - acc: 0.9362 - val_loss: 0.1338 - val_acc: 0.9542\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1552 - acc: 0.9428 - val_loss: 0.1345 - val_acc: 0.9435\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13381 to 0.12920, saving model to best.model\n",
      "0s - loss: 0.1551 - acc: 0.9401 - val_loss: 0.1292 - val_acc: 0.9523\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12920 to 0.12245, saving model to best.model\n",
      "0s - loss: 0.1530 - acc: 0.9406 - val_loss: 0.1224 - val_acc: 0.9503\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12245 to 0.11706, saving model to best.model\n",
      "0s - loss: 0.1401 - acc: 0.9455 - val_loss: 0.1171 - val_acc: 0.9542\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.11706 to 0.11625, saving model to best.model\n",
      "0s - loss: 0.1420 - acc: 0.9464 - val_loss: 0.1163 - val_acc: 0.9484\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11625 to 0.11054, saving model to best.model\n",
      "0s - loss: 0.1396 - acc: 0.9435 - val_loss: 0.1105 - val_acc: 0.9601\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11054 to 0.10694, saving model to best.model\n",
      "0s - loss: 0.1286 - acc: 0.9525 - val_loss: 0.1069 - val_acc: 0.9630\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.10694 to 0.10357, saving model to best.model\n",
      "0s - loss: 0.1307 - acc: 0.9503 - val_loss: 0.1036 - val_acc: 0.9679\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10357 to 0.10324, saving model to best.model\n",
      "0s - loss: 0.1298 - acc: 0.9498 - val_loss: 0.1032 - val_acc: 0.9591\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10324 to 0.09843, saving model to best.model\n",
      "0s - loss: 0.1325 - acc: 0.9481 - val_loss: 0.0984 - val_acc: 0.9698\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.09843 to 0.09633, saving model to best.model\n",
      "0s - loss: 0.1280 - acc: 0.9484 - val_loss: 0.0963 - val_acc: 0.9718\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.09633 to 0.09446, saving model to best.model\n",
      "0s - loss: 0.1273 - acc: 0.9518 - val_loss: 0.0945 - val_acc: 0.9698\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09446 to 0.09073, saving model to best.model\n",
      "0s - loss: 0.1215 - acc: 0.9542 - val_loss: 0.0907 - val_acc: 0.9737\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09073 to 0.08865, saving model to best.model\n",
      "0s - loss: 0.1180 - acc: 0.9615 - val_loss: 0.0887 - val_acc: 0.9727\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.08865 to 0.08833, saving model to best.model\n",
      "0s - loss: 0.1101 - acc: 0.9598 - val_loss: 0.0883 - val_acc: 0.9698\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.08833 to 0.08743, saving model to best.model\n",
      "0s - loss: 0.1112 - acc: 0.9606 - val_loss: 0.0874 - val_acc: 0.9747\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1197 - acc: 0.9567 - val_loss: 0.0924 - val_acc: 0.9640\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08743 to 0.08286, saving model to best.model\n",
      "0s - loss: 0.1077 - acc: 0.9623 - val_loss: 0.0829 - val_acc: 0.9786\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08286 to 0.07976, saving model to best.model\n",
      "0s - loss: 0.1093 - acc: 0.9581 - val_loss: 0.0798 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07976 to 0.07743, saving model to best.model\n",
      "0s - loss: 0.1045 - acc: 0.9601 - val_loss: 0.0774 - val_acc: 0.9796\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1072 - acc: 0.9542 - val_loss: 0.0826 - val_acc: 0.9688\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1050 - acc: 0.9591 - val_loss: 0.0793 - val_acc: 0.9776\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07743 to 0.07566, saving model to best.model\n",
      "0s - loss: 0.1093 - acc: 0.9601 - val_loss: 0.0757 - val_acc: 0.9757\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1040 - acc: 0.9589 - val_loss: 0.0799 - val_acc: 0.9776\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07566 to 0.07446, saving model to best.model\n",
      "0s - loss: 0.1026 - acc: 0.9627 - val_loss: 0.0745 - val_acc: 0.9825\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07446 to 0.07052, saving model to best.model\n",
      "0s - loss: 0.0929 - acc: 0.9652 - val_loss: 0.0705 - val_acc: 0.9766\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07052 to 0.06986, saving model to best.model\n",
      "0s - loss: 0.0949 - acc: 0.9640 - val_loss: 0.0699 - val_acc: 0.9747\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06986 to 0.06876, saving model to best.model\n",
      "0s - loss: 0.0928 - acc: 0.9640 - val_loss: 0.0688 - val_acc: 0.9737\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06876 to 0.06605, saving model to best.model\n",
      "0s - loss: 0.1004 - acc: 0.9608 - val_loss: 0.0660 - val_acc: 0.9766\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0913 - acc: 0.9681 - val_loss: 0.0747 - val_acc: 0.9805\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0874 - acc: 0.9657 - val_loss: 0.0678 - val_acc: 0.9776\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06605 to 0.06499, saving model to best.model\n",
      "0s - loss: 0.0873 - acc: 0.9705 - val_loss: 0.0650 - val_acc: 0.9815\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06499 to 0.06149, saving model to best.model\n",
      "0s - loss: 0.0918 - acc: 0.9645 - val_loss: 0.0615 - val_acc: 0.9834\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0881 - acc: 0.9671 - val_loss: 0.0628 - val_acc: 0.9786\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0863 - acc: 0.9647 - val_loss: 0.0659 - val_acc: 0.9834\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0852 - acc: 0.9701 - val_loss: 0.0633 - val_acc: 0.9776\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.06149 to 0.05948, saving model to best.model\n",
      "0s - loss: 0.0865 - acc: 0.9696 - val_loss: 0.0595 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05948 to 0.05754, saving model to best.model\n",
      "0s - loss: 0.0812 - acc: 0.9705 - val_loss: 0.0575 - val_acc: 0.9834\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05754 to 0.05697, saving model to best.model\n",
      "0s - loss: 0.0761 - acc: 0.9725 - val_loss: 0.0570 - val_acc: 0.9834\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.05697 to 0.05636, saving model to best.model\n",
      "0s - loss: 0.0801 - acc: 0.9718 - val_loss: 0.0564 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05636 to 0.05464, saving model to best.model\n",
      "0s - loss: 0.0748 - acc: 0.9720 - val_loss: 0.0546 - val_acc: 0.9834\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.05464 to 0.05361, saving model to best.model\n",
      "0s - loss: 0.0772 - acc: 0.9715 - val_loss: 0.0536 - val_acc: 0.9844\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.05361 to 0.05104, saving model to best.model\n",
      "0s - loss: 0.0698 - acc: 0.9725 - val_loss: 0.0510 - val_acc: 0.9834\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.05104 to 0.05087, saving model to best.model\n",
      "0s - loss: 0.0813 - acc: 0.9693 - val_loss: 0.0509 - val_acc: 0.9854\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.05087 to 0.04987, saving model to best.model\n",
      "0s - loss: 0.0705 - acc: 0.9732 - val_loss: 0.0499 - val_acc: 0.9844\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04987 to 0.04961, saving model to best.model\n",
      "0s - loss: 0.0714 - acc: 0.9757 - val_loss: 0.0496 - val_acc: 0.9844\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0751 - acc: 0.9744 - val_loss: 0.0497 - val_acc: 0.9844\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04961 to 0.04765, saving model to best.model\n",
      "0s - loss: 0.0701 - acc: 0.9732 - val_loss: 0.0476 - val_acc: 0.9854\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0652 - acc: 0.9761 - val_loss: 0.0482 - val_acc: 0.9844\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.04765 to 0.04733, saving model to best.model\n",
      "0s - loss: 0.0646 - acc: 0.9774 - val_loss: 0.0473 - val_acc: 0.9854\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.04733 to 0.04642, saving model to best.model\n",
      "0s - loss: 0.0696 - acc: 0.9761 - val_loss: 0.0464 - val_acc: 0.9864\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.04642 to 0.04538, saving model to best.model\n",
      "0s - loss: 0.0691 - acc: 0.9752 - val_loss: 0.0454 - val_acc: 0.9864\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0715 - acc: 0.9732 - val_loss: 0.0514 - val_acc: 0.9834\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0670 - acc: 0.9757 - val_loss: 0.0461 - val_acc: 0.9893\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.04538 to 0.04383, saving model to best.model\n",
      "0s - loss: 0.0635 - acc: 0.9754 - val_loss: 0.0438 - val_acc: 0.9854\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.04383 to 0.04212, saving model to best.model\n",
      "0s - loss: 0.0602 - acc: 0.9776 - val_loss: 0.0421 - val_acc: 0.9854\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0677 - acc: 0.9759 - val_loss: 0.0431 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.04212 to 0.04110, saving model to best.model\n",
      "0s - loss: 0.0647 - acc: 0.9766 - val_loss: 0.0411 - val_acc: 0.9883\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.04110 to 0.04034, saving model to best.model\n",
      "0s - loss: 0.0622 - acc: 0.9776 - val_loss: 0.0403 - val_acc: 0.9854\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.04034 to 0.03778, saving model to best.model\n",
      "0s - loss: 0.0645 - acc: 0.9778 - val_loss: 0.0378 - val_acc: 0.9883\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0660 - acc: 0.9766 - val_loss: 0.0397 - val_acc: 0.9864\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0589 - acc: 0.9764 - val_loss: 0.0391 - val_acc: 0.9864\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0588 - acc: 0.9793 - val_loss: 0.0382 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.03778 to 0.03728, saving model to best.model\n",
      "0s - loss: 0.0597 - acc: 0.9798 - val_loss: 0.0373 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.03728 to 0.03683, saving model to best.model\n",
      "0s - loss: 0.0613 - acc: 0.9759 - val_loss: 0.0368 - val_acc: 0.9883\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.03683 to 0.03566, saving model to best.model\n",
      "0s - loss: 0.0613 - acc: 0.9761 - val_loss: 0.0357 - val_acc: 0.9883\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9783 - val_loss: 0.0373 - val_acc: 0.9864\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.03566 to 0.03513, saving model to best.model\n",
      "0s - loss: 0.0516 - acc: 0.9808 - val_loss: 0.0351 - val_acc: 0.9883\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.03513 to 0.03480, saving model to best.model\n",
      "0s - loss: 0.0548 - acc: 0.9808 - val_loss: 0.0348 - val_acc: 0.9883\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9827 - val_loss: 0.0356 - val_acc: 0.9873\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.03480 to 0.03474, saving model to best.model\n",
      "0s - loss: 0.0587 - acc: 0.9757 - val_loss: 0.0347 - val_acc: 0.9873\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03474 to 0.03418, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9803 - val_loss: 0.0342 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.03418 to 0.03313, saving model to best.model\n",
      "0s - loss: 0.0512 - acc: 0.9822 - val_loss: 0.0331 - val_acc: 0.9883\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0504 - acc: 0.9813 - val_loss: 0.0333 - val_acc: 0.9873\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.03313 to 0.03188, saving model to best.model\n",
      "0s - loss: 0.0513 - acc: 0.9798 - val_loss: 0.0319 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9808 - val_loss: 0.0329 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.03188 to 0.03011, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9825 - val_loss: 0.0301 - val_acc: 0.9883\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9798 - val_loss: 0.0311 - val_acc: 0.9873\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0530 - acc: 0.9813 - val_loss: 0.0312 - val_acc: 0.9893\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0501 - acc: 0.9815 - val_loss: 0.0332 - val_acc: 0.9883\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0532 - acc: 0.9830 - val_loss: 0.0326 - val_acc: 0.9883\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.03011 to 0.03005, saving model to best.model\n",
      "0s - loss: 0.0457 - acc: 0.9832 - val_loss: 0.0300 - val_acc: 0.9883\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9813 - val_loss: 0.0307 - val_acc: 0.9883\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.03005 to 0.02967, saving model to best.model\n",
      "0s - loss: 0.0447 - acc: 0.9847 - val_loss: 0.0297 - val_acc: 0.9883\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02967 to 0.02922, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9851 - val_loss: 0.0292 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02922 to 0.02819, saving model to best.model\n",
      "0s - loss: 0.0478 - acc: 0.9815 - val_loss: 0.0282 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0524 - acc: 0.9798 - val_loss: 0.0289 - val_acc: 0.9873\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02819 to 0.02761, saving model to best.model\n",
      "0s - loss: 0.0469 - acc: 0.9832 - val_loss: 0.0276 - val_acc: 0.9903\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02761 to 0.02635, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9842 - val_loss: 0.0264 - val_acc: 0.9893\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9847 - val_loss: 0.0268 - val_acc: 0.9883\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9842 - val_loss: 0.0273 - val_acc: 0.9903\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9859 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02635 to 0.02319, saving model to best.model\n",
      "0s - loss: 0.0406 - acc: 0.9851 - val_loss: 0.0232 - val_acc: 0.9883\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.02319 to 0.02311, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9825 - val_loss: 0.0231 - val_acc: 0.9883\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02311 to 0.02188, saving model to best.model\n",
      "0s - loss: 0.0445 - acc: 0.9844 - val_loss: 0.0219 - val_acc: 0.9893\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.02188 to 0.02167, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9871 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9866 - val_loss: 0.0250 - val_acc: 0.9883\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9827 - val_loss: 0.0228 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9859 - val_loss: 0.0251 - val_acc: 0.9883\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0404 - acc: 0.9866 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02167 to 0.02073, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9866 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9866 - val_loss: 0.0215 - val_acc: 0.9883\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.02073 to 0.02015, saving model to best.model\n",
      "0s - loss: 0.0491 - acc: 0.9810 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9861 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02015 to 0.01907, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9873 - val_loss: 0.0191 - val_acc: 0.9893\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9864 - val_loss: 0.0201 - val_acc: 0.9893\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9883 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01907 to 0.01787, saving model to best.model\n",
      "0s - loss: 0.0408 - acc: 0.9847 - val_loss: 0.0179 - val_acc: 0.9912\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9847 - val_loss: 0.0183 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9851 - val_loss: 0.0200 - val_acc: 0.9883\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01787 to 0.01787, saving model to best.model\n",
      "0s - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01787 to 0.01718, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9861 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9864 - val_loss: 0.0206 - val_acc: 0.9903\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9871 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9876 - val_loss: 0.0212 - val_acc: 0.9903\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0182 - val_acc: 0.9893\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9873 - val_loss: 0.0181 - val_acc: 0.9932\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9876 - val_loss: 0.0178 - val_acc: 0.9883\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01718 to 0.01496, saving model to best.model\n",
      "0s - loss: 0.0303 - acc: 0.9881 - val_loss: 0.0150 - val_acc: 0.9912\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01496 to 0.01466, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9888 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9869 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0181 - val_acc: 0.9883\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0367 - acc: 0.9851 - val_loss: 0.0202 - val_acc: 0.9912\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9861 - val_loss: 0.0185 - val_acc: 0.9883\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9883 - val_loss: 0.0174 - val_acc: 0.9932\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9900 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.01466 to 0.01433, saving model to best.model\n",
      "0s - loss: 0.0355 - acc: 0.9873 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01433 to 0.01396, saving model to best.model\n",
      "0s - loss: 0.0368 - acc: 0.9871 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01396 to 0.01267, saving model to best.model\n",
      "0s - loss: 0.0312 - acc: 0.9878 - val_loss: 0.0127 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9856 - val_loss: 0.0137 - val_acc: 0.9932\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9895 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9866 - val_loss: 0.0149 - val_acc: 0.9932\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9869 - val_loss: 0.0132 - val_acc: 0.9932\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9883 - val_loss: 0.0149 - val_acc: 0.9912\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.01267 to 0.01266, saving model to best.model\n",
      "0s - loss: 0.0302 - acc: 0.9895 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01266 to 0.01265, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0127 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9903 - val_loss: 0.0128 - val_acc: 0.9932\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9905 - val_loss: 0.0145 - val_acc: 0.9922\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9883 - val_loss: 0.0160 - val_acc: 0.9903\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9910 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9876 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.01265 to 0.01222, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9900 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.01222 to 0.01133, saving model to best.model\n",
      "0s - loss: 0.0275 - acc: 0.9903 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9912 - val_loss: 0.0123 - val_acc: 0.9932\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9898 - val_loss: 0.0123 - val_acc: 0.9942\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0243 - acc: 0.9912 - val_loss: 0.0122 - val_acc: 0.9932\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.01133 to 0.01077, saving model to best.model\n",
      "0s - loss: 0.0279 - acc: 0.9888 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67447, saving model to best.model\n",
      "0s - loss: 0.7802 - acc: 0.5060 - val_loss: 0.6745 - val_acc: 0.5131\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67447 to 0.64729, saving model to best.model\n",
      "0s - loss: 0.7350 - acc: 0.5213 - val_loss: 0.6473 - val_acc: 0.6845\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64729 to 0.59760, saving model to best.model\n",
      "0s - loss: 0.6802 - acc: 0.5802 - val_loss: 0.5976 - val_acc: 0.7936\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59760 to 0.52034, saving model to best.model\n",
      "0s - loss: 0.6200 - acc: 0.6652 - val_loss: 0.5203 - val_acc: 0.8179\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52034 to 0.44360, saving model to best.model\n",
      "0s - loss: 0.5489 - acc: 0.7295 - val_loss: 0.4436 - val_acc: 0.8364\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44360 to 0.39199, saving model to best.model\n",
      "0s - loss: 0.4845 - acc: 0.7833 - val_loss: 0.3920 - val_acc: 0.8491\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39199 to 0.36154, saving model to best.model\n",
      "0s - loss: 0.4383 - acc: 0.8179 - val_loss: 0.3615 - val_acc: 0.8617\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36154 to 0.34312, saving model to best.model\n",
      "0s - loss: 0.4089 - acc: 0.8337 - val_loss: 0.3431 - val_acc: 0.8676\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34312 to 0.32599, saving model to best.model\n",
      "0s - loss: 0.3900 - acc: 0.8439 - val_loss: 0.3260 - val_acc: 0.8705\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32599 to 0.31683, saving model to best.model\n",
      "0s - loss: 0.3565 - acc: 0.8610 - val_loss: 0.3168 - val_acc: 0.8783\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31683 to 0.29941, saving model to best.model\n",
      "0s - loss: 0.3498 - acc: 0.8636 - val_loss: 0.2994 - val_acc: 0.8783\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29941 to 0.29171, saving model to best.model\n",
      "0s - loss: 0.3377 - acc: 0.8666 - val_loss: 0.2917 - val_acc: 0.8793\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29171 to 0.28477, saving model to best.model\n",
      "0s - loss: 0.3307 - acc: 0.8724 - val_loss: 0.2848 - val_acc: 0.8841\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.28477 to 0.27702, saving model to best.model\n",
      "0s - loss: 0.3163 - acc: 0.8814 - val_loss: 0.2770 - val_acc: 0.8861\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27702 to 0.27225, saving model to best.model\n",
      "0s - loss: 0.3041 - acc: 0.8822 - val_loss: 0.2722 - val_acc: 0.8939\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.27225 to 0.26759, saving model to best.model\n",
      "0s - loss: 0.3010 - acc: 0.8890 - val_loss: 0.2676 - val_acc: 0.8997\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26759 to 0.26250, saving model to best.model\n",
      "0s - loss: 0.2981 - acc: 0.8863 - val_loss: 0.2625 - val_acc: 0.9026\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.26250 to 0.25879, saving model to best.model\n",
      "0s - loss: 0.2861 - acc: 0.8919 - val_loss: 0.2588 - val_acc: 0.9036\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.25879 to 0.25543, saving model to best.model\n",
      "0s - loss: 0.2798 - acc: 0.8919 - val_loss: 0.2554 - val_acc: 0.9056\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.25543 to 0.25188, saving model to best.model\n",
      "0s - loss: 0.2768 - acc: 0.8987 - val_loss: 0.2519 - val_acc: 0.9085\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.25188 to 0.25053, saving model to best.model\n",
      "0s - loss: 0.2668 - acc: 0.8977 - val_loss: 0.2505 - val_acc: 0.9085\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25053 to 0.24591, saving model to best.model\n",
      "0s - loss: 0.2724 - acc: 0.8951 - val_loss: 0.2459 - val_acc: 0.9094\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.24591 to 0.24272, saving model to best.model\n",
      "0s - loss: 0.2675 - acc: 0.9026 - val_loss: 0.2427 - val_acc: 0.9104\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24272 to 0.24198, saving model to best.model\n",
      "0s - loss: 0.2629 - acc: 0.9002 - val_loss: 0.2420 - val_acc: 0.9085\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.24198 to 0.23694, saving model to best.model\n",
      "0s - loss: 0.2566 - acc: 0.9028 - val_loss: 0.2369 - val_acc: 0.9124\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.23694 to 0.23499, saving model to best.model\n",
      "0s - loss: 0.2607 - acc: 0.9011 - val_loss: 0.2350 - val_acc: 0.9124\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.23499 to 0.22774, saving model to best.model\n",
      "0s - loss: 0.2537 - acc: 0.9026 - val_loss: 0.2277 - val_acc: 0.9153\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2444 - acc: 0.9048 - val_loss: 0.2279 - val_acc: 0.9133\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.22774 to 0.22256, saving model to best.model\n",
      "0s - loss: 0.2426 - acc: 0.9060 - val_loss: 0.2226 - val_acc: 0.9163\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22256 to 0.22070, saving model to best.model\n",
      "0s - loss: 0.2296 - acc: 0.9126 - val_loss: 0.2207 - val_acc: 0.9143\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.22070 to 0.21783, saving model to best.model\n",
      "0s - loss: 0.2250 - acc: 0.9106 - val_loss: 0.2178 - val_acc: 0.9114\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.21783 to 0.21201, saving model to best.model\n",
      "0s - loss: 0.2368 - acc: 0.9094 - val_loss: 0.2120 - val_acc: 0.9163\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2302 - acc: 0.9143 - val_loss: 0.2125 - val_acc: 0.9133\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.21201 to 0.20782, saving model to best.model\n",
      "0s - loss: 0.2345 - acc: 0.9089 - val_loss: 0.2078 - val_acc: 0.9172\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.20782 to 0.20507, saving model to best.model\n",
      "0s - loss: 0.2188 - acc: 0.9155 - val_loss: 0.2051 - val_acc: 0.9192\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.20507 to 0.20197, saving model to best.model\n",
      "0s - loss: 0.2133 - acc: 0.9158 - val_loss: 0.2020 - val_acc: 0.9163\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.20197 to 0.19927, saving model to best.model\n",
      "0s - loss: 0.2130 - acc: 0.9179 - val_loss: 0.1993 - val_acc: 0.9153\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19927 to 0.19041, saving model to best.model\n",
      "0s - loss: 0.2195 - acc: 0.9131 - val_loss: 0.1904 - val_acc: 0.9163\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.19041 to 0.18866, saving model to best.model\n",
      "0s - loss: 0.2149 - acc: 0.9119 - val_loss: 0.1887 - val_acc: 0.9172\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18866 to 0.18302, saving model to best.model\n",
      "0s - loss: 0.2023 - acc: 0.9189 - val_loss: 0.1830 - val_acc: 0.9211\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18302 to 0.18032, saving model to best.model\n",
      "0s - loss: 0.2045 - acc: 0.9199 - val_loss: 0.1803 - val_acc: 0.9202\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.18032 to 0.17403, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9165 - val_loss: 0.1740 - val_acc: 0.9192\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17403 to 0.17181, saving model to best.model\n",
      "0s - loss: 0.2022 - acc: 0.9196 - val_loss: 0.1718 - val_acc: 0.9202\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.17181 to 0.16567, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9199 - val_loss: 0.1657 - val_acc: 0.9211\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16567 to 0.16143, saving model to best.model\n",
      "0s - loss: 0.1950 - acc: 0.9194 - val_loss: 0.1614 - val_acc: 0.9221\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.16143 to 0.15747, saving model to best.model\n",
      "0s - loss: 0.1806 - acc: 0.9274 - val_loss: 0.1575 - val_acc: 0.9250\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15747 to 0.15291, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9245 - val_loss: 0.1529 - val_acc: 0.9250\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15291 to 0.15230, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9262 - val_loss: 0.1523 - val_acc: 0.9338\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15230 to 0.14550, saving model to best.model\n",
      "0s - loss: 0.1701 - acc: 0.9243 - val_loss: 0.1455 - val_acc: 0.9348\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14550 to 0.14257, saving model to best.model\n",
      "0s - loss: 0.1708 - acc: 0.9282 - val_loss: 0.1426 - val_acc: 0.9348\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14257 to 0.13933, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9299 - val_loss: 0.1393 - val_acc: 0.9357\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13933 to 0.13756, saving model to best.model\n",
      "0s - loss: 0.1713 - acc: 0.9330 - val_loss: 0.1376 - val_acc: 0.9309\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1649 - acc: 0.9296 - val_loss: 0.1383 - val_acc: 0.9435\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13756 to 0.13355, saving model to best.model\n",
      "0s - loss: 0.1593 - acc: 0.9333 - val_loss: 0.1336 - val_acc: 0.9396\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13355 to 0.12974, saving model to best.model\n",
      "0s - loss: 0.1595 - acc: 0.9304 - val_loss: 0.1297 - val_acc: 0.9406\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12974 to 0.12605, saving model to best.model\n",
      "0s - loss: 0.1572 - acc: 0.9340 - val_loss: 0.1261 - val_acc: 0.9406\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12605 to 0.12402, saving model to best.model\n",
      "0s - loss: 0.1509 - acc: 0.9401 - val_loss: 0.1240 - val_acc: 0.9455\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12402 to 0.12126, saving model to best.model\n",
      "0s - loss: 0.1545 - acc: 0.9396 - val_loss: 0.1213 - val_acc: 0.9445\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.12126 to 0.11640, saving model to best.model\n",
      "0s - loss: 0.1492 - acc: 0.9403 - val_loss: 0.1164 - val_acc: 0.9455\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11640 to 0.11355, saving model to best.model\n",
      "0s - loss: 0.1377 - acc: 0.9435 - val_loss: 0.1136 - val_acc: 0.9494\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11355 to 0.11132, saving model to best.model\n",
      "0s - loss: 0.1359 - acc: 0.9440 - val_loss: 0.1113 - val_acc: 0.9494\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1420 - acc: 0.9438 - val_loss: 0.1114 - val_acc: 0.9611\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11132 to 0.10769, saving model to best.model\n",
      "0s - loss: 0.1393 - acc: 0.9421 - val_loss: 0.1077 - val_acc: 0.9542\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10769 to 0.10300, saving model to best.model\n",
      "0s - loss: 0.1419 - acc: 0.9435 - val_loss: 0.1030 - val_acc: 0.9542\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10300 to 0.10050, saving model to best.model\n",
      "0s - loss: 0.1307 - acc: 0.9469 - val_loss: 0.1005 - val_acc: 0.9620\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10050 to 0.09514, saving model to best.model\n",
      "0s - loss: 0.1306 - acc: 0.9503 - val_loss: 0.0951 - val_acc: 0.9649\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09514 to 0.09417, saving model to best.model\n",
      "0s - loss: 0.1351 - acc: 0.9452 - val_loss: 0.0942 - val_acc: 0.9630\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09417 to 0.09236, saving model to best.model\n",
      "0s - loss: 0.1232 - acc: 0.9503 - val_loss: 0.0924 - val_acc: 0.9669\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09236 to 0.09054, saving model to best.model\n",
      "0s - loss: 0.1256 - acc: 0.9511 - val_loss: 0.0905 - val_acc: 0.9659\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09054 to 0.08797, saving model to best.model\n",
      "0s - loss: 0.1201 - acc: 0.9491 - val_loss: 0.0880 - val_acc: 0.9630\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08797 to 0.08560, saving model to best.model\n",
      "0s - loss: 0.1250 - acc: 0.9472 - val_loss: 0.0856 - val_acc: 0.9698\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1097 - acc: 0.9569 - val_loss: 0.0856 - val_acc: 0.9737\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08560 to 0.08254, saving model to best.model\n",
      "0s - loss: 0.1160 - acc: 0.9554 - val_loss: 0.0825 - val_acc: 0.9747\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08254 to 0.07743, saving model to best.model\n",
      "0s - loss: 0.1130 - acc: 0.9581 - val_loss: 0.0774 - val_acc: 0.9757\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.07743 to 0.07735, saving model to best.model\n",
      "0s - loss: 0.1172 - acc: 0.9535 - val_loss: 0.0773 - val_acc: 0.9757\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07735 to 0.07371, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9481 - val_loss: 0.0737 - val_acc: 0.9776\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07371 to 0.07192, saving model to best.model\n",
      "0s - loss: 0.1063 - acc: 0.9598 - val_loss: 0.0719 - val_acc: 0.9766\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07192 to 0.06977, saving model to best.model\n",
      "0s - loss: 0.1076 - acc: 0.9574 - val_loss: 0.0698 - val_acc: 0.9776\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06977 to 0.06852, saving model to best.model\n",
      "0s - loss: 0.1033 - acc: 0.9579 - val_loss: 0.0685 - val_acc: 0.9815\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06852 to 0.06800, saving model to best.model\n",
      "0s - loss: 0.0999 - acc: 0.9610 - val_loss: 0.0680 - val_acc: 0.9776\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06800 to 0.06496, saving model to best.model\n",
      "0s - loss: 0.0946 - acc: 0.9657 - val_loss: 0.0650 - val_acc: 0.9815\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06496 to 0.06304, saving model to best.model\n",
      "0s - loss: 0.0911 - acc: 0.9632 - val_loss: 0.0630 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06304 to 0.06038, saving model to best.model\n",
      "0s - loss: 0.0920 - acc: 0.9645 - val_loss: 0.0604 - val_acc: 0.9796\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06038 to 0.06011, saving model to best.model\n",
      "0s - loss: 0.0932 - acc: 0.9664 - val_loss: 0.0601 - val_acc: 0.9815\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06011 to 0.05888, saving model to best.model\n",
      "0s - loss: 0.0957 - acc: 0.9618 - val_loss: 0.0589 - val_acc: 0.9776\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05888 to 0.05756, saving model to best.model\n",
      "0s - loss: 0.0892 - acc: 0.9647 - val_loss: 0.0576 - val_acc: 0.9796\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05756 to 0.05449, saving model to best.model\n",
      "0s - loss: 0.0926 - acc: 0.9637 - val_loss: 0.0545 - val_acc: 0.9796\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0941 - acc: 0.9645 - val_loss: 0.0553 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0994 - acc: 0.9598 - val_loss: 0.0607 - val_acc: 0.9805\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0977 - acc: 0.9598 - val_loss: 0.0546 - val_acc: 0.9815\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05449 to 0.05105, saving model to best.model\n",
      "0s - loss: 0.0819 - acc: 0.9681 - val_loss: 0.0511 - val_acc: 0.9834\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05105 to 0.04999, saving model to best.model\n",
      "0s - loss: 0.0820 - acc: 0.9718 - val_loss: 0.0500 - val_acc: 0.9815\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04999 to 0.04851, saving model to best.model\n",
      "0s - loss: 0.0764 - acc: 0.9698 - val_loss: 0.0485 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04851 to 0.04657, saving model to best.model\n",
      "0s - loss: 0.0799 - acc: 0.9710 - val_loss: 0.0466 - val_acc: 0.9805\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04657 to 0.04504, saving model to best.model\n",
      "0s - loss: 0.0742 - acc: 0.9735 - val_loss: 0.0450 - val_acc: 0.9844\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0709 - acc: 0.9710 - val_loss: 0.0460 - val_acc: 0.9864\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04504 to 0.04259, saving model to best.model\n",
      "0s - loss: 0.0869 - acc: 0.9662 - val_loss: 0.0426 - val_acc: 0.9883\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04259 to 0.04054, saving model to best.model\n",
      "0s - loss: 0.0718 - acc: 0.9705 - val_loss: 0.0405 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04054 to 0.04032, saving model to best.model\n",
      "0s - loss: 0.0759 - acc: 0.9710 - val_loss: 0.0403 - val_acc: 0.9844\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0718 - acc: 0.9739 - val_loss: 0.0411 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04032 to 0.03855, saving model to best.model\n",
      "0s - loss: 0.0722 - acc: 0.9713 - val_loss: 0.0385 - val_acc: 0.9873\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03855 to 0.03594, saving model to best.model\n",
      "0s - loss: 0.0736 - acc: 0.9730 - val_loss: 0.0359 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0735 - acc: 0.9693 - val_loss: 0.0362 - val_acc: 0.9873\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0738 - acc: 0.9691 - val_loss: 0.0415 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0752 - acc: 0.9713 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0745 - acc: 0.9735 - val_loss: 0.0381 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.03594 to 0.03564, saving model to best.model\n",
      "0s - loss: 0.0751 - acc: 0.9718 - val_loss: 0.0356 - val_acc: 0.9854\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03564 to 0.03536, saving model to best.model\n",
      "0s - loss: 0.0653 - acc: 0.9752 - val_loss: 0.0354 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0672 - acc: 0.9754 - val_loss: 0.0387 - val_acc: 0.9873\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03536 to 0.03181, saving model to best.model\n",
      "0s - loss: 0.0622 - acc: 0.9766 - val_loss: 0.0318 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0596 - acc: 0.9776 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0607 - acc: 0.9759 - val_loss: 0.0351 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03181 to 0.03072, saving model to best.model\n",
      "0s - loss: 0.0614 - acc: 0.9766 - val_loss: 0.0307 - val_acc: 0.9864\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0552 - acc: 0.9786 - val_loss: 0.0320 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03072 to 0.02936, saving model to best.model\n",
      "0s - loss: 0.0566 - acc: 0.9791 - val_loss: 0.0294 - val_acc: 0.9893\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02936 to 0.02781, saving model to best.model\n",
      "0s - loss: 0.0576 - acc: 0.9783 - val_loss: 0.0278 - val_acc: 0.9893\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02781 to 0.02754, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9822 - val_loss: 0.0275 - val_acc: 0.9893\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02754 to 0.02722, saving model to best.model\n",
      "0s - loss: 0.0561 - acc: 0.9783 - val_loss: 0.0272 - val_acc: 0.9893\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02722 to 0.02606, saving model to best.model\n",
      "0s - loss: 0.0521 - acc: 0.9798 - val_loss: 0.0261 - val_acc: 0.9912\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9757 - val_loss: 0.0268 - val_acc: 0.9893\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0514 - acc: 0.9810 - val_loss: 0.0284 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0602 - acc: 0.9754 - val_loss: 0.0296 - val_acc: 0.9873\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02606 to 0.02477, saving model to best.model\n",
      "0s - loss: 0.0599 - acc: 0.9730 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0581 - acc: 0.9781 - val_loss: 0.0282 - val_acc: 0.9873\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9830 - val_loss: 0.0254 - val_acc: 0.9893\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02477 to 0.02420, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9798 - val_loss: 0.0242 - val_acc: 0.9912\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0594 - acc: 0.9783 - val_loss: 0.0260 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9783 - val_loss: 0.0252 - val_acc: 0.9893\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02420 to 0.02410, saving model to best.model\n",
      "0s - loss: 0.0527 - acc: 0.9793 - val_loss: 0.0241 - val_acc: 0.9893\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02410 to 0.02262, saving model to best.model\n",
      "0s - loss: 0.0433 - acc: 0.9825 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0507 - acc: 0.9803 - val_loss: 0.0229 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0527 - acc: 0.9791 - val_loss: 0.0227 - val_acc: 0.9903\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9820 - val_loss: 0.0254 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0531 - acc: 0.9800 - val_loss: 0.0245 - val_acc: 0.9893\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9820 - val_loss: 0.0254 - val_acc: 0.9883\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0456 - acc: 0.9830 - val_loss: 0.0257 - val_acc: 0.9873\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02262 to 0.02078, saving model to best.model\n",
      "0s - loss: 0.0454 - acc: 0.9820 - val_loss: 0.0208 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0441 - acc: 0.9837 - val_loss: 0.0257 - val_acc: 0.9873\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9822 - val_loss: 0.0209 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9825 - val_loss: 0.0211 - val_acc: 0.9922\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9851 - val_loss: 0.0216 - val_acc: 0.9903\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.02078 to 0.02024, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9825 - val_loss: 0.0202 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9859 - val_loss: 0.0215 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.02024 to 0.01893, saving model to best.model\n",
      "0s - loss: 0.0432 - acc: 0.9825 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9834 - val_loss: 0.0233 - val_acc: 0.9903\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01893 to 0.01889, saving model to best.model\n",
      "0s - loss: 0.0407 - acc: 0.9834 - val_loss: 0.0189 - val_acc: 0.9922\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0201 - val_acc: 0.9922\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9844 - val_loss: 0.0209 - val_acc: 0.9903\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9839 - val_loss: 0.0195 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01889 to 0.01711, saving model to best.model\n",
      "0s - loss: 0.0398 - acc: 0.9815 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01711 to 0.01612, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9847 - val_loss: 0.0161 - val_acc: 0.9942\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9827 - val_loss: 0.0256 - val_acc: 0.9893\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0456 - acc: 0.9839 - val_loss: 0.0178 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9873 - val_loss: 0.0221 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.01612 to 0.01561, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9844 - val_loss: 0.0156 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9856 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9873 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9866 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9864 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01561 to 0.01541, saving model to best.model\n",
      "0s - loss: 0.0344 - acc: 0.9876 - val_loss: 0.0154 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01541 to 0.01449, saving model to best.model\n",
      "0s - loss: 0.0340 - acc: 0.9873 - val_loss: 0.0145 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9830 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01449 to 0.01391, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0139 - val_acc: 0.9961\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9888 - val_loss: 0.0147 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0307 - acc: 0.9888 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9871 - val_loss: 0.0188 - val_acc: 0.9922\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01391 to 0.01380, saving model to best.model\n",
      "0s - loss: 0.0523 - acc: 0.9817 - val_loss: 0.0138 - val_acc: 0.9971\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9864 - val_loss: 0.0166 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9871 - val_loss: 0.0166 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9856 - val_loss: 0.0169 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9844 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0421 - acc: 0.9830 - val_loss: 0.0188 - val_acc: 0.9903\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9881 - val_loss: 0.0163 - val_acc: 0.9922\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9849 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9871 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9898 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9876 - val_loss: 0.0156 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01380 to 0.01184, saving model to best.model\n",
      "0s - loss: 0.0293 - acc: 0.9893 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9888 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01184 to 0.01156, saving model to best.model\n",
      "0s - loss: 0.0344 - acc: 0.9886 - val_loss: 0.0116 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9888 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9871 - val_loss: 0.0152 - val_acc: 0.9942\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9881 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9888 - val_loss: 0.0138 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9871 - val_loss: 0.0166 - val_acc: 0.9932\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.01156 to 0.01101, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9871 - val_loss: 0.0110 - val_acc: 0.9961\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9878 - val_loss: 0.0124 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0245 - acc: 0.9905 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9900 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9864 - val_loss: 0.0175 - val_acc: 0.9903\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9844 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9883 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9893 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0249 - acc: 0.9895 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0259 - acc: 0.9883 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9871 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9869 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0136 - val_acc: 0.9942\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66774, saving model to best.model\n",
      "0s - loss: 0.7906 - acc: 0.5096 - val_loss: 0.6677 - val_acc: 0.5287\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66774 to 0.63727, saving model to best.model\n",
      "0s - loss: 0.7311 - acc: 0.5352 - val_loss: 0.6373 - val_acc: 0.7390\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63727 to 0.58584, saving model to best.model\n",
      "0s - loss: 0.6738 - acc: 0.5958 - val_loss: 0.5858 - val_acc: 0.7361\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58584 to 0.50596, saving model to best.model\n",
      "0s - loss: 0.5978 - acc: 0.6840 - val_loss: 0.5060 - val_acc: 0.7838\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50596 to 0.45079, saving model to best.model\n",
      "0s - loss: 0.5196 - acc: 0.7495 - val_loss: 0.4508 - val_acc: 0.8218\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.45079 to 0.42047, saving model to best.model\n",
      "0s - loss: 0.4586 - acc: 0.8045 - val_loss: 0.4205 - val_acc: 0.8325\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.42047 to 0.40041, saving model to best.model\n",
      "0s - loss: 0.4156 - acc: 0.8237 - val_loss: 0.4004 - val_acc: 0.8393\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.40041 to 0.37996, saving model to best.model\n",
      "0s - loss: 0.4009 - acc: 0.8410 - val_loss: 0.3800 - val_acc: 0.8432\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.37996 to 0.36377, saving model to best.model\n",
      "0s - loss: 0.3619 - acc: 0.8561 - val_loss: 0.3638 - val_acc: 0.8569\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.36377 to 0.34944, saving model to best.model\n",
      "0s - loss: 0.3508 - acc: 0.8632 - val_loss: 0.3494 - val_acc: 0.8598\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.34944 to 0.33244, saving model to best.model\n",
      "0s - loss: 0.3300 - acc: 0.8671 - val_loss: 0.3324 - val_acc: 0.8685\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.33244 to 0.31467, saving model to best.model\n",
      "0s - loss: 0.3269 - acc: 0.8710 - val_loss: 0.3147 - val_acc: 0.8608\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.31467 to 0.30411, saving model to best.model\n",
      "0s - loss: 0.3060 - acc: 0.8802 - val_loss: 0.3041 - val_acc: 0.8695\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.30411 to 0.29102, saving model to best.model\n",
      "0s - loss: 0.2923 - acc: 0.8890 - val_loss: 0.2910 - val_acc: 0.8783\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.29102 to 0.28252, saving model to best.model\n",
      "0s - loss: 0.2887 - acc: 0.8878 - val_loss: 0.2825 - val_acc: 0.8822\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.28252 to 0.27454, saving model to best.model\n",
      "0s - loss: 0.2751 - acc: 0.8999 - val_loss: 0.2745 - val_acc: 0.8929\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.27454 to 0.27082, saving model to best.model\n",
      "0s - loss: 0.2758 - acc: 0.8992 - val_loss: 0.2708 - val_acc: 0.8958\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.27082 to 0.26097, saving model to best.model\n",
      "0s - loss: 0.2615 - acc: 0.9065 - val_loss: 0.2610 - val_acc: 0.9017\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26097 to 0.25394, saving model to best.model\n",
      "0s - loss: 0.2579 - acc: 0.9053 - val_loss: 0.2539 - val_acc: 0.9046\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.25394 to 0.25082, saving model to best.model\n",
      "0s - loss: 0.2543 - acc: 0.9082 - val_loss: 0.2508 - val_acc: 0.9036\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.25082 to 0.24121, saving model to best.model\n",
      "0s - loss: 0.2469 - acc: 0.9063 - val_loss: 0.2412 - val_acc: 0.9036\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.24121 to 0.23907, saving model to best.model\n",
      "0s - loss: 0.2478 - acc: 0.9092 - val_loss: 0.2391 - val_acc: 0.9085\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23907 to 0.23724, saving model to best.model\n",
      "0s - loss: 0.2439 - acc: 0.9133 - val_loss: 0.2372 - val_acc: 0.9085\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.23724 to 0.23187, saving model to best.model\n",
      "0s - loss: 0.2366 - acc: 0.9138 - val_loss: 0.2319 - val_acc: 0.9085\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.23187 to 0.22888, saving model to best.model\n",
      "0s - loss: 0.2297 - acc: 0.9189 - val_loss: 0.2289 - val_acc: 0.9085\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.22888 to 0.22178, saving model to best.model\n",
      "0s - loss: 0.2281 - acc: 0.9153 - val_loss: 0.2218 - val_acc: 0.9094\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.22178 to 0.21710, saving model to best.model\n",
      "0s - loss: 0.2250 - acc: 0.9206 - val_loss: 0.2171 - val_acc: 0.9094\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21710 to 0.21345, saving model to best.model\n",
      "0s - loss: 0.2183 - acc: 0.9172 - val_loss: 0.2134 - val_acc: 0.9094\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.21345 to 0.21035, saving model to best.model\n",
      "0s - loss: 0.2196 - acc: 0.9216 - val_loss: 0.2103 - val_acc: 0.9104\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.21035 to 0.20544, saving model to best.model\n",
      "0s - loss: 0.2050 - acc: 0.9267 - val_loss: 0.2054 - val_acc: 0.9172\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20544 to 0.20413, saving model to best.model\n",
      "0s - loss: 0.2150 - acc: 0.9206 - val_loss: 0.2041 - val_acc: 0.9143\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20413 to 0.20149, saving model to best.model\n",
      "0s - loss: 0.2112 - acc: 0.9240 - val_loss: 0.2015 - val_acc: 0.9124\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.20149 to 0.19372, saving model to best.model\n",
      "0s - loss: 0.2045 - acc: 0.9279 - val_loss: 0.1937 - val_acc: 0.9221\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19372 to 0.19008, saving model to best.model\n",
      "0s - loss: 0.1911 - acc: 0.9311 - val_loss: 0.1901 - val_acc: 0.9279\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19008 to 0.18877, saving model to best.model\n",
      "0s - loss: 0.1915 - acc: 0.9291 - val_loss: 0.1888 - val_acc: 0.9250\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18877 to 0.18175, saving model to best.model\n",
      "0s - loss: 0.1940 - acc: 0.9308 - val_loss: 0.1817 - val_acc: 0.9289\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18175 to 0.17872, saving model to best.model\n",
      "0s - loss: 0.2005 - acc: 0.9311 - val_loss: 0.1787 - val_acc: 0.9289\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17872 to 0.17430, saving model to best.model\n",
      "0s - loss: 0.1923 - acc: 0.9306 - val_loss: 0.1743 - val_acc: 0.9328\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17430 to 0.17198, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9343 - val_loss: 0.1720 - val_acc: 0.9318\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9367 - val_loss: 0.1730 - val_acc: 0.9299\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17198 to 0.16462, saving model to best.model\n",
      "0s - loss: 0.1725 - acc: 0.9408 - val_loss: 0.1646 - val_acc: 0.9377\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1758 - acc: 0.9396 - val_loss: 0.1649 - val_acc: 0.9318\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.16462 to 0.15682, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9401 - val_loss: 0.1568 - val_acc: 0.9406\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15682 to 0.15391, saving model to best.model\n",
      "0s - loss: 0.1730 - acc: 0.9384 - val_loss: 0.1539 - val_acc: 0.9367\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.1781 - acc: 0.9382 - val_loss: 0.1612 - val_acc: 0.9250\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15391 to 0.15093, saving model to best.model\n",
      "0s - loss: 0.1611 - acc: 0.9457 - val_loss: 0.1509 - val_acc: 0.9367\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15093 to 0.14792, saving model to best.model\n",
      "0s - loss: 0.1728 - acc: 0.9350 - val_loss: 0.1479 - val_acc: 0.9426\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14792 to 0.14638, saving model to best.model\n",
      "0s - loss: 0.1665 - acc: 0.9403 - val_loss: 0.1464 - val_acc: 0.9435\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1591 - acc: 0.9394 - val_loss: 0.1466 - val_acc: 0.9377\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14638 to 0.14012, saving model to best.model\n",
      "0s - loss: 0.1608 - acc: 0.9396 - val_loss: 0.1401 - val_acc: 0.9455\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14012 to 0.13859, saving model to best.model\n",
      "0s - loss: 0.1586 - acc: 0.9421 - val_loss: 0.1386 - val_acc: 0.9435\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13859 to 0.13387, saving model to best.model\n",
      "0s - loss: 0.1510 - acc: 0.9474 - val_loss: 0.1339 - val_acc: 0.9435\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13387 to 0.12993, saving model to best.model\n",
      "0s - loss: 0.1453 - acc: 0.9491 - val_loss: 0.1299 - val_acc: 0.9464\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.12993 to 0.12851, saving model to best.model\n",
      "0s - loss: 0.1495 - acc: 0.9489 - val_loss: 0.1285 - val_acc: 0.9484\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.12851 to 0.12383, saving model to best.model\n",
      "0s - loss: 0.1459 - acc: 0.9469 - val_loss: 0.1238 - val_acc: 0.9591\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12383 to 0.12332, saving model to best.model\n",
      "0s - loss: 0.1422 - acc: 0.9462 - val_loss: 0.1233 - val_acc: 0.9513\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12332 to 0.12332, saving model to best.model\n",
      "0s - loss: 0.1470 - acc: 0.9491 - val_loss: 0.1233 - val_acc: 0.9513\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12332 to 0.11983, saving model to best.model\n",
      "0s - loss: 0.1373 - acc: 0.9525 - val_loss: 0.1198 - val_acc: 0.9523\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11983 to 0.11524, saving model to best.model\n",
      "0s - loss: 0.1386 - acc: 0.9501 - val_loss: 0.1152 - val_acc: 0.9562\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11524 to 0.11294, saving model to best.model\n",
      "0s - loss: 0.1305 - acc: 0.9535 - val_loss: 0.1129 - val_acc: 0.9581\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11294 to 0.10771, saving model to best.model\n",
      "0s - loss: 0.1226 - acc: 0.9540 - val_loss: 0.1077 - val_acc: 0.9591\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10771 to 0.10491, saving model to best.model\n",
      "0s - loss: 0.1271 - acc: 0.9552 - val_loss: 0.1049 - val_acc: 0.9601\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1347 - acc: 0.9511 - val_loss: 0.1145 - val_acc: 0.9513\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1304 - acc: 0.9528 - val_loss: 0.1054 - val_acc: 0.9572\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10491 to 0.10211, saving model to best.model\n",
      "0s - loss: 0.1237 - acc: 0.9547 - val_loss: 0.1021 - val_acc: 0.9640\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10211 to 0.09795, saving model to best.model\n",
      "0s - loss: 0.1233 - acc: 0.9511 - val_loss: 0.0979 - val_acc: 0.9611\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09795 to 0.09711, saving model to best.model\n",
      "0s - loss: 0.1141 - acc: 0.9576 - val_loss: 0.0971 - val_acc: 0.9640\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09711 to 0.09483, saving model to best.model\n",
      "0s - loss: 0.1119 - acc: 0.9586 - val_loss: 0.0948 - val_acc: 0.9679\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.1107 - acc: 0.9564 - val_loss: 0.0969 - val_acc: 0.9630\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09483 to 0.09005, saving model to best.model\n",
      "0s - loss: 0.1102 - acc: 0.9545 - val_loss: 0.0900 - val_acc: 0.9640\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.09005 to 0.08815, saving model to best.model\n",
      "0s - loss: 0.1144 - acc: 0.9586 - val_loss: 0.0881 - val_acc: 0.9659\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08815 to 0.08558, saving model to best.model\n",
      "0s - loss: 0.1085 - acc: 0.9586 - val_loss: 0.0856 - val_acc: 0.9688\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08558 to 0.08375, saving model to best.model\n",
      "0s - loss: 0.1030 - acc: 0.9640 - val_loss: 0.0838 - val_acc: 0.9688\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08375 to 0.08037, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9645 - val_loss: 0.0804 - val_acc: 0.9669\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08037 to 0.08012, saving model to best.model\n",
      "0s - loss: 0.0963 - acc: 0.9637 - val_loss: 0.0801 - val_acc: 0.9688\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.08012 to 0.07879, saving model to best.model\n",
      "0s - loss: 0.1000 - acc: 0.9608 - val_loss: 0.0788 - val_acc: 0.9727\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07879 to 0.07359, saving model to best.model\n",
      "0s - loss: 0.1005 - acc: 0.9627 - val_loss: 0.0736 - val_acc: 0.9698\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07359 to 0.07228, saving model to best.model\n",
      "0s - loss: 0.0930 - acc: 0.9647 - val_loss: 0.0723 - val_acc: 0.9659\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1051 - acc: 0.9608 - val_loss: 0.0804 - val_acc: 0.9796\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07228 to 0.07014, saving model to best.model\n",
      "0s - loss: 0.0871 - acc: 0.9671 - val_loss: 0.0701 - val_acc: 0.9727\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07014 to 0.06746, saving model to best.model\n",
      "0s - loss: 0.0864 - acc: 0.9637 - val_loss: 0.0675 - val_acc: 0.9708\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0918 - acc: 0.9681 - val_loss: 0.0791 - val_acc: 0.9786\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06746 to 0.06728, saving model to best.model\n",
      "0s - loss: 0.0875 - acc: 0.9654 - val_loss: 0.0673 - val_acc: 0.9776\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06728 to 0.06452, saving model to best.model\n",
      "0s - loss: 0.0783 - acc: 0.9696 - val_loss: 0.0645 - val_acc: 0.9737\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0785 - acc: 0.9720 - val_loss: 0.0664 - val_acc: 0.9786\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06452 to 0.06143, saving model to best.model\n",
      "0s - loss: 0.0760 - acc: 0.9737 - val_loss: 0.0614 - val_acc: 0.9796\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06143 to 0.05651, saving model to best.model\n",
      "0s - loss: 0.0799 - acc: 0.9732 - val_loss: 0.0565 - val_acc: 0.9805\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0757 - acc: 0.9718 - val_loss: 0.0578 - val_acc: 0.9737\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0778 - acc: 0.9701 - val_loss: 0.0596 - val_acc: 0.9805\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0851 - acc: 0.9657 - val_loss: 0.0612 - val_acc: 0.9815\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05651 to 0.05359, saving model to best.model\n",
      "0s - loss: 0.0728 - acc: 0.9710 - val_loss: 0.0536 - val_acc: 0.9815\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0773 - acc: 0.9693 - val_loss: 0.0550 - val_acc: 0.9805\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0786 - acc: 0.9718 - val_loss: 0.0632 - val_acc: 0.9796\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0708 - acc: 0.9747 - val_loss: 0.0556 - val_acc: 0.9796\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.05359 to 0.04821, saving model to best.model\n",
      "0s - loss: 0.0758 - acc: 0.9718 - val_loss: 0.0482 - val_acc: 0.9825\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0711 - acc: 0.9754 - val_loss: 0.0632 - val_acc: 0.9815\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0722 - acc: 0.9725 - val_loss: 0.0494 - val_acc: 0.9834\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04821 to 0.04798, saving model to best.model\n",
      "0s - loss: 0.0739 - acc: 0.9725 - val_loss: 0.0480 - val_acc: 0.9825\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04798 to 0.04360, saving model to best.model\n",
      "0s - loss: 0.0673 - acc: 0.9727 - val_loss: 0.0436 - val_acc: 0.9854\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04360 to 0.04351, saving model to best.model\n",
      "0s - loss: 0.0610 - acc: 0.9781 - val_loss: 0.0435 - val_acc: 0.9854\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0650 - acc: 0.9783 - val_loss: 0.0474 - val_acc: 0.9834\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0626 - acc: 0.9771 - val_loss: 0.0438 - val_acc: 0.9864\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.04351 to 0.04006, saving model to best.model\n",
      "0s - loss: 0.0616 - acc: 0.9791 - val_loss: 0.0401 - val_acc: 0.9844\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0594 - acc: 0.9774 - val_loss: 0.0432 - val_acc: 0.9834\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.04006 to 0.03879, saving model to best.model\n",
      "0s - loss: 0.0551 - acc: 0.9783 - val_loss: 0.0388 - val_acc: 0.9854\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0668 - acc: 0.9754 - val_loss: 0.0389 - val_acc: 0.9864\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0639 - acc: 0.9759 - val_loss: 0.0408 - val_acc: 0.9864\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0518 - acc: 0.9795 - val_loss: 0.0399 - val_acc: 0.9864\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0555 - acc: 0.9822 - val_loss: 0.0389 - val_acc: 0.9864\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03879 to 0.03829, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9795 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03829 to 0.03613, saving model to best.model\n",
      "0s - loss: 0.0592 - acc: 0.9795 - val_loss: 0.0361 - val_acc: 0.9864\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0571 - acc: 0.9805 - val_loss: 0.0382 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03613 to 0.03415, saving model to best.model\n",
      "0s - loss: 0.0510 - acc: 0.9805 - val_loss: 0.0341 - val_acc: 0.9864\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0529 - acc: 0.9808 - val_loss: 0.0345 - val_acc: 0.9864\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03415 to 0.03363, saving model to best.model\n",
      "0s - loss: 0.0516 - acc: 0.9813 - val_loss: 0.0336 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.03363 to 0.03238, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9788 - val_loss: 0.0324 - val_acc: 0.9873\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0471 - acc: 0.9820 - val_loss: 0.0345 - val_acc: 0.9864\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0496 - acc: 0.9820 - val_loss: 0.0364 - val_acc: 0.9864\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0548 - acc: 0.9803 - val_loss: 0.0328 - val_acc: 0.9873\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9795 - val_loss: 0.0345 - val_acc: 0.9864\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9810 - val_loss: 0.0339 - val_acc: 0.9873\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9808 - val_loss: 0.0326 - val_acc: 0.9864\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0591 - acc: 0.9810 - val_loss: 0.0331 - val_acc: 0.9873\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.03238 to 0.02872, saving model to best.model\n",
      "0s - loss: 0.0473 - acc: 0.9827 - val_loss: 0.0287 - val_acc: 0.9903\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9822 - val_loss: 0.0366 - val_acc: 0.9864\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02872 to 0.02807, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9822 - val_loss: 0.0281 - val_acc: 0.9873\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9808 - val_loss: 0.0344 - val_acc: 0.9873\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02807 to 0.02646, saving model to best.model\n",
      "0s - loss: 0.0407 - acc: 0.9837 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9825 - val_loss: 0.0340 - val_acc: 0.9873\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0265 - val_acc: 0.9903\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9851 - val_loss: 0.0273 - val_acc: 0.9893\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9842 - val_loss: 0.0266 - val_acc: 0.9893\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9851 - val_loss: 0.0274 - val_acc: 0.9883\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9839 - val_loss: 0.0292 - val_acc: 0.9883\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.02646 to 0.02536, saving model to best.model\n",
      "0s - loss: 0.0420 - acc: 0.9839 - val_loss: 0.0254 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9813 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02536 to 0.02504, saving model to best.model\n",
      "0s - loss: 0.0439 - acc: 0.9837 - val_loss: 0.0250 - val_acc: 0.9903\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02504 to 0.02491, saving model to best.model\n",
      "0s - loss: 0.0406 - acc: 0.9869 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9869 - val_loss: 0.0254 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.02491 to 0.02466, saving model to best.model\n",
      "0s - loss: 0.0364 - acc: 0.9881 - val_loss: 0.0247 - val_acc: 0.9893\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02466 to 0.02205, saving model to best.model\n",
      "0s - loss: 0.0434 - acc: 0.9851 - val_loss: 0.0221 - val_acc: 0.9903\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9869 - val_loss: 0.0285 - val_acc: 0.9883\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02205 to 0.02128, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9866 - val_loss: 0.0213 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9866 - val_loss: 0.0228 - val_acc: 0.9903\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9854 - val_loss: 0.0354 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9837 - val_loss: 0.0219 - val_acc: 0.9883\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9859 - val_loss: 0.0327 - val_acc: 0.9873\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02128 to 0.02064, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9878 - val_loss: 0.0206 - val_acc: 0.9912\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9878 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9869 - val_loss: 0.0221 - val_acc: 0.9912\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9873 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9876 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.02064 to 0.01941, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9883 - val_loss: 0.0194 - val_acc: 0.9903\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0391 - acc: 0.9869 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.01941 to 0.01804, saving model to best.model\n",
      "0s - loss: 0.0347 - acc: 0.9883 - val_loss: 0.0180 - val_acc: 0.9912\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9856 - val_loss: 0.0278 - val_acc: 0.9883\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9859 - val_loss: 0.0196 - val_acc: 0.9903\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9878 - val_loss: 0.0223 - val_acc: 0.9903\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9854 - val_loss: 0.0206 - val_acc: 0.9903\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9895 - val_loss: 0.0192 - val_acc: 0.9903\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9876 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01804 to 0.01776, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9888 - val_loss: 0.0178 - val_acc: 0.9903\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9861 - val_loss: 0.0222 - val_acc: 0.9903\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01776 to 0.01666, saving model to best.model\n",
      "0s - loss: 0.0365 - acc: 0.9871 - val_loss: 0.0167 - val_acc: 0.9912\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9878 - val_loss: 0.0246 - val_acc: 0.9903\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01666 to 0.01609, saving model to best.model\n",
      "0s - loss: 0.0312 - acc: 0.9869 - val_loss: 0.0161 - val_acc: 0.9912\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9876 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9900 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01609 to 0.01582, saving model to best.model\n",
      "0s - loss: 0.0323 - acc: 0.9878 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.01582 to 0.01477, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9881 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9878 - val_loss: 0.0179 - val_acc: 0.9912\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01477 to 0.01442, saving model to best.model\n",
      "0s - loss: 0.0300 - acc: 0.9915 - val_loss: 0.0144 - val_acc: 0.9932\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9854 - val_loss: 0.0170 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9871 - val_loss: 0.0173 - val_acc: 0.9922\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9888 - val_loss: 0.0182 - val_acc: 0.9922\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9900 - val_loss: 0.0152 - val_acc: 0.9922\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9890 - val_loss: 0.0169 - val_acc: 0.9903\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01442 to 0.01251, saving model to best.model\n",
      "0s - loss: 0.0311 - acc: 0.9871 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9871 - val_loss: 0.0175 - val_acc: 0.9893\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9903 - val_loss: 0.0138 - val_acc: 0.9942\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9886 - val_loss: 0.0179 - val_acc: 0.9903\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9866 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9871 - val_loss: 0.0144 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9888 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9895 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9903 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0250 - acc: 0.9910 - val_loss: 0.0135 - val_acc: 0.9932\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0244 - acc: 0.9907 - val_loss: 0.0165 - val_acc: 0.9922\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.01251 to 0.01171, saving model to best.model\n",
      "0s - loss: 0.0242 - acc: 0.9907 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0244 - acc: 0.9912 - val_loss: 0.0151 - val_acc: 0.9932\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9903 - val_loss: 0.0153 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0215 - acc: 0.9920 - val_loss: 0.0121 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9886 - val_loss: 0.0123 - val_acc: 0.9932\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9905 - val_loss: 0.0126 - val_acc: 0.9932\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9893 - val_loss: 0.0126 - val_acc: 0.9932\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9905 - val_loss: 0.0127 - val_acc: 0.9932\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.01171 to 0.00931, saving model to best.model\n",
      "0s - loss: 0.0233 - acc: 0.9922 - val_loss: 0.0093 - val_acc: 0.9951\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0250 - acc: 0.9917 - val_loss: 0.0116 - val_acc: 0.9932\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0255 - acc: 0.9915 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67994, saving model to best.model\n",
      "0s - loss: 0.8843 - acc: 0.4884 - val_loss: 0.6799 - val_acc: 0.5170\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67994 to 0.66809, saving model to best.model\n",
      "0s - loss: 0.7735 - acc: 0.5206 - val_loss: 0.6681 - val_acc: 0.5170\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66809 to 0.63852, saving model to best.model\n",
      "0s - loss: 0.7410 - acc: 0.5340 - val_loss: 0.6385 - val_acc: 0.7556\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.63852 to 0.59582, saving model to best.model\n",
      "0s - loss: 0.7019 - acc: 0.5739 - val_loss: 0.5958 - val_acc: 0.8014\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.59582 to 0.53929, saving model to best.model\n",
      "0s - loss: 0.6445 - acc: 0.6289 - val_loss: 0.5393 - val_acc: 0.7994\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.53929 to 0.46947, saving model to best.model\n",
      "0s - loss: 0.5959 - acc: 0.6798 - val_loss: 0.4695 - val_acc: 0.8257\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.46947 to 0.41265, saving model to best.model\n",
      "0s - loss: 0.5342 - acc: 0.7392 - val_loss: 0.4126 - val_acc: 0.8491\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.41265 to 0.37005, saving model to best.model\n",
      "0s - loss: 0.4790 - acc: 0.7882 - val_loss: 0.3700 - val_acc: 0.8617\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.37005 to 0.34286, saving model to best.model\n",
      "0s - loss: 0.4607 - acc: 0.7974 - val_loss: 0.3429 - val_acc: 0.8715\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34286 to 0.31644, saving model to best.model\n",
      "0s - loss: 0.4235 - acc: 0.8203 - val_loss: 0.3164 - val_acc: 0.8812\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31644 to 0.29243, saving model to best.model\n",
      "0s - loss: 0.3906 - acc: 0.8376 - val_loss: 0.2924 - val_acc: 0.8909\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29243 to 0.27374, saving model to best.model\n",
      "0s - loss: 0.3671 - acc: 0.8537 - val_loss: 0.2737 - val_acc: 0.8948\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27374 to 0.25905, saving model to best.model\n",
      "0s - loss: 0.3558 - acc: 0.8549 - val_loss: 0.2590 - val_acc: 0.9036\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.25905 to 0.24591, saving model to best.model\n",
      "0s - loss: 0.3390 - acc: 0.8663 - val_loss: 0.2459 - val_acc: 0.9065\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.24591 to 0.23587, saving model to best.model\n",
      "0s - loss: 0.3277 - acc: 0.8734 - val_loss: 0.2359 - val_acc: 0.9036\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.23587 to 0.23083, saving model to best.model\n",
      "0s - loss: 0.3176 - acc: 0.8736 - val_loss: 0.2308 - val_acc: 0.9211\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.23083 to 0.22097, saving model to best.model\n",
      "0s - loss: 0.3143 - acc: 0.8787 - val_loss: 0.2210 - val_acc: 0.9192\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.22097 to 0.21273, saving model to best.model\n",
      "0s - loss: 0.2976 - acc: 0.8909 - val_loss: 0.2127 - val_acc: 0.9221\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.21273 to 0.20830, saving model to best.model\n",
      "0s - loss: 0.2915 - acc: 0.8919 - val_loss: 0.2083 - val_acc: 0.9260\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.20830 to 0.20281, saving model to best.model\n",
      "0s - loss: 0.2844 - acc: 0.8980 - val_loss: 0.2028 - val_acc: 0.9318\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.20281 to 0.19952, saving model to best.model\n",
      "0s - loss: 0.2844 - acc: 0.8968 - val_loss: 0.1995 - val_acc: 0.9338\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.19952 to 0.19326, saving model to best.model\n",
      "0s - loss: 0.2742 - acc: 0.9019 - val_loss: 0.1933 - val_acc: 0.9367\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19326 to 0.18918, saving model to best.model\n",
      "0s - loss: 0.2690 - acc: 0.8990 - val_loss: 0.1892 - val_acc: 0.9348\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.18918 to 0.18777, saving model to best.model\n",
      "0s - loss: 0.2632 - acc: 0.9036 - val_loss: 0.1878 - val_acc: 0.9348\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18777 to 0.18331, saving model to best.model\n",
      "0s - loss: 0.2656 - acc: 0.9058 - val_loss: 0.1833 - val_acc: 0.9357\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2651 - acc: 0.9028 - val_loss: 0.1899 - val_acc: 0.9445\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18331 to 0.18321, saving model to best.model\n",
      "0s - loss: 0.2609 - acc: 0.9077 - val_loss: 0.1832 - val_acc: 0.9377\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.18321 to 0.17798, saving model to best.model\n",
      "0s - loss: 0.2552 - acc: 0.9104 - val_loss: 0.1780 - val_acc: 0.9406\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.17798 to 0.17431, saving model to best.model\n",
      "0s - loss: 0.2509 - acc: 0.9099 - val_loss: 0.1743 - val_acc: 0.9416\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.17431 to 0.17401, saving model to best.model\n",
      "0s - loss: 0.2467 - acc: 0.9121 - val_loss: 0.1740 - val_acc: 0.9455\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.17401 to 0.16971, saving model to best.model\n",
      "0s - loss: 0.2388 - acc: 0.9148 - val_loss: 0.1697 - val_acc: 0.9396\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.16971 to 0.16421, saving model to best.model\n",
      "0s - loss: 0.2329 - acc: 0.9145 - val_loss: 0.1642 - val_acc: 0.9445\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.16421 to 0.16283, saving model to best.model\n",
      "0s - loss: 0.2338 - acc: 0.9136 - val_loss: 0.1628 - val_acc: 0.9484\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.16283 to 0.16196, saving model to best.model\n",
      "0s - loss: 0.2328 - acc: 0.9182 - val_loss: 0.1620 - val_acc: 0.9445\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.16196 to 0.15819, saving model to best.model\n",
      "0s - loss: 0.2234 - acc: 0.9189 - val_loss: 0.1582 - val_acc: 0.9474\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.15819 to 0.15396, saving model to best.model\n",
      "0s - loss: 0.2255 - acc: 0.9199 - val_loss: 0.1540 - val_acc: 0.9455\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.15396 to 0.15153, saving model to best.model\n",
      "0s - loss: 0.2184 - acc: 0.9194 - val_loss: 0.1515 - val_acc: 0.9464\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.15153 to 0.14948, saving model to best.model\n",
      "0s - loss: 0.2171 - acc: 0.9189 - val_loss: 0.1495 - val_acc: 0.9445\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.14948 to 0.14567, saving model to best.model\n",
      "0s - loss: 0.2182 - acc: 0.9177 - val_loss: 0.1457 - val_acc: 0.9484\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.14567 to 0.14209, saving model to best.model\n",
      "0s - loss: 0.2015 - acc: 0.9255 - val_loss: 0.1421 - val_acc: 0.9474\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.14209 to 0.14034, saving model to best.model\n",
      "0s - loss: 0.2030 - acc: 0.9270 - val_loss: 0.1403 - val_acc: 0.9464\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14034 to 0.13638, saving model to best.model\n",
      "0s - loss: 0.2001 - acc: 0.9223 - val_loss: 0.1364 - val_acc: 0.9523\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.13638 to 0.13383, saving model to best.model\n",
      "0s - loss: 0.2037 - acc: 0.9233 - val_loss: 0.1338 - val_acc: 0.9533\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13383 to 0.13133, saving model to best.model\n",
      "0s - loss: 0.1953 - acc: 0.9301 - val_loss: 0.1313 - val_acc: 0.9484\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13133 to 0.12867, saving model to best.model\n",
      "0s - loss: 0.1837 - acc: 0.9321 - val_loss: 0.1287 - val_acc: 0.9552\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.12867 to 0.12580, saving model to best.model\n",
      "0s - loss: 0.1965 - acc: 0.9277 - val_loss: 0.1258 - val_acc: 0.9513\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.12580 to 0.12212, saving model to best.model\n",
      "0s - loss: 0.1863 - acc: 0.9301 - val_loss: 0.1221 - val_acc: 0.9542\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.12212 to 0.11998, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9299 - val_loss: 0.1200 - val_acc: 0.9562\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.11998 to 0.11455, saving model to best.model\n",
      "0s - loss: 0.1787 - acc: 0.9267 - val_loss: 0.1146 - val_acc: 0.9572\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.11455 to 0.11208, saving model to best.model\n",
      "0s - loss: 0.1792 - acc: 0.9330 - val_loss: 0.1121 - val_acc: 0.9552\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11208 to 0.11045, saving model to best.model\n",
      "0s - loss: 0.1793 - acc: 0.9326 - val_loss: 0.1105 - val_acc: 0.9562\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1783 - acc: 0.9330 - val_loss: 0.1115 - val_acc: 0.9611\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11045 to 0.10506, saving model to best.model\n",
      "0s - loss: 0.1647 - acc: 0.9372 - val_loss: 0.1051 - val_acc: 0.9581\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10506 to 0.10194, saving model to best.model\n",
      "0s - loss: 0.1668 - acc: 0.9413 - val_loss: 0.1019 - val_acc: 0.9572\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10194 to 0.09733, saving model to best.model\n",
      "0s - loss: 0.1542 - acc: 0.9374 - val_loss: 0.0973 - val_acc: 0.9552\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.09733 to 0.09408, saving model to best.model\n",
      "0s - loss: 0.1607 - acc: 0.9389 - val_loss: 0.0941 - val_acc: 0.9572\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09408 to 0.09254, saving model to best.model\n",
      "0s - loss: 0.1511 - acc: 0.9428 - val_loss: 0.0925 - val_acc: 0.9630\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09254 to 0.08640, saving model to best.model\n",
      "0s - loss: 0.1511 - acc: 0.9421 - val_loss: 0.0864 - val_acc: 0.9630\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1561 - acc: 0.9403 - val_loss: 0.0874 - val_acc: 0.9620\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1569 - acc: 0.9401 - val_loss: 0.0878 - val_acc: 0.9640\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08640 to 0.08163, saving model to best.model\n",
      "0s - loss: 0.1445 - acc: 0.9450 - val_loss: 0.0816 - val_acc: 0.9659\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08163 to 0.07684, saving model to best.model\n",
      "0s - loss: 0.1397 - acc: 0.9462 - val_loss: 0.0768 - val_acc: 0.9679\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.07684 to 0.07400, saving model to best.model\n",
      "0s - loss: 0.1382 - acc: 0.9506 - val_loss: 0.0740 - val_acc: 0.9708\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.07400 to 0.07299, saving model to best.model\n",
      "0s - loss: 0.1372 - acc: 0.9506 - val_loss: 0.0730 - val_acc: 0.9718\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07299 to 0.06921, saving model to best.model\n",
      "0s - loss: 0.1298 - acc: 0.9506 - val_loss: 0.0692 - val_acc: 0.9737\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.06921 to 0.06654, saving model to best.model\n",
      "0s - loss: 0.1332 - acc: 0.9498 - val_loss: 0.0665 - val_acc: 0.9747\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.06654 to 0.06556, saving model to best.model\n",
      "0s - loss: 0.1307 - acc: 0.9520 - val_loss: 0.0656 - val_acc: 0.9786\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.06556 to 0.06363, saving model to best.model\n",
      "0s - loss: 0.1266 - acc: 0.9501 - val_loss: 0.0636 - val_acc: 0.9796\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.06363 to 0.05978, saving model to best.model\n",
      "0s - loss: 0.1185 - acc: 0.9564 - val_loss: 0.0598 - val_acc: 0.9815\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.05978 to 0.05751, saving model to best.model\n",
      "0s - loss: 0.1205 - acc: 0.9530 - val_loss: 0.0575 - val_acc: 0.9834\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.05751 to 0.05640, saving model to best.model\n",
      "0s - loss: 0.1068 - acc: 0.9569 - val_loss: 0.0564 - val_acc: 0.9815\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.05640 to 0.05336, saving model to best.model\n",
      "0s - loss: 0.1161 - acc: 0.9564 - val_loss: 0.0534 - val_acc: 0.9834\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.05336 to 0.05120, saving model to best.model\n",
      "0s - loss: 0.1163 - acc: 0.9552 - val_loss: 0.0512 - val_acc: 0.9864\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.05120 to 0.04936, saving model to best.model\n",
      "0s - loss: 0.1030 - acc: 0.9657 - val_loss: 0.0494 - val_acc: 0.9873\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.04936 to 0.04745, saving model to best.model\n",
      "0s - loss: 0.1030 - acc: 0.9627 - val_loss: 0.0475 - val_acc: 0.9873\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.04745 to 0.04599, saving model to best.model\n",
      "0s - loss: 0.0980 - acc: 0.9645 - val_loss: 0.0460 - val_acc: 0.9864\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.04599 to 0.04496, saving model to best.model\n",
      "0s - loss: 0.1023 - acc: 0.9642 - val_loss: 0.0450 - val_acc: 0.9883\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.04496 to 0.04333, saving model to best.model\n",
      "0s - loss: 0.1106 - acc: 0.9630 - val_loss: 0.0433 - val_acc: 0.9883\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.04333 to 0.04215, saving model to best.model\n",
      "0s - loss: 0.0994 - acc: 0.9623 - val_loss: 0.0422 - val_acc: 0.9893\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.04215 to 0.04081, saving model to best.model\n",
      "0s - loss: 0.0987 - acc: 0.9608 - val_loss: 0.0408 - val_acc: 0.9873\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.04081 to 0.03930, saving model to best.model\n",
      "0s - loss: 0.0995 - acc: 0.9632 - val_loss: 0.0393 - val_acc: 0.9893\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.03930 to 0.03802, saving model to best.model\n",
      "0s - loss: 0.0967 - acc: 0.9664 - val_loss: 0.0380 - val_acc: 0.9903\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.03802 to 0.03691, saving model to best.model\n",
      "0s - loss: 0.0898 - acc: 0.9686 - val_loss: 0.0369 - val_acc: 0.9893\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.03691 to 0.03571, saving model to best.model\n",
      "0s - loss: 0.0934 - acc: 0.9647 - val_loss: 0.0357 - val_acc: 0.9893\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.03571 to 0.03537, saving model to best.model\n",
      "0s - loss: 0.0884 - acc: 0.9693 - val_loss: 0.0354 - val_acc: 0.9903\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.03537 to 0.03288, saving model to best.model\n",
      "0s - loss: 0.0878 - acc: 0.9681 - val_loss: 0.0329 - val_acc: 0.9912\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.03288 to 0.03228, saving model to best.model\n",
      "0s - loss: 0.0903 - acc: 0.9676 - val_loss: 0.0323 - val_acc: 0.9912\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.03228 to 0.03180, saving model to best.model\n",
      "0s - loss: 0.0840 - acc: 0.9669 - val_loss: 0.0318 - val_acc: 0.9903\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.03180 to 0.03159, saving model to best.model\n",
      "0s - loss: 0.0813 - acc: 0.9691 - val_loss: 0.0316 - val_acc: 0.9922\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03159 to 0.02963, saving model to best.model\n",
      "0s - loss: 0.0848 - acc: 0.9703 - val_loss: 0.0296 - val_acc: 0.9903\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0837 - acc: 0.9701 - val_loss: 0.0322 - val_acc: 0.9893\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.02963 to 0.02827, saving model to best.model\n",
      "0s - loss: 0.0747 - acc: 0.9718 - val_loss: 0.0283 - val_acc: 0.9912\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.02827 to 0.02722, saving model to best.model\n",
      "0s - loss: 0.0778 - acc: 0.9737 - val_loss: 0.0272 - val_acc: 0.9922\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.02722 to 0.02593, saving model to best.model\n",
      "0s - loss: 0.0748 - acc: 0.9710 - val_loss: 0.0259 - val_acc: 0.9932\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.02593 to 0.02456, saving model to best.model\n",
      "0s - loss: 0.0706 - acc: 0.9761 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.02456 to 0.02392, saving model to best.model\n",
      "0s - loss: 0.0807 - acc: 0.9701 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0785 - acc: 0.9715 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0701 - acc: 0.9739 - val_loss: 0.0242 - val_acc: 0.9932\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.02392 to 0.02288, saving model to best.model\n",
      "0s - loss: 0.0768 - acc: 0.9725 - val_loss: 0.0229 - val_acc: 0.9942\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02288 to 0.02222, saving model to best.model\n",
      "0s - loss: 0.0724 - acc: 0.9718 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.02222 to 0.02149, saving model to best.model\n",
      "0s - loss: 0.0754 - acc: 0.9727 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0693 - acc: 0.9730 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.02149 to 0.02062, saving model to best.model\n",
      "0s - loss: 0.0685 - acc: 0.9742 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0696 - acc: 0.9725 - val_loss: 0.0207 - val_acc: 0.9932\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.02062 to 0.01987, saving model to best.model\n",
      "0s - loss: 0.0707 - acc: 0.9732 - val_loss: 0.0199 - val_acc: 0.9951\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.01987 to 0.01903, saving model to best.model\n",
      "0s - loss: 0.0636 - acc: 0.9781 - val_loss: 0.0190 - val_acc: 0.9951\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.01903 to 0.01788, saving model to best.model\n",
      "0s - loss: 0.0657 - acc: 0.9759 - val_loss: 0.0179 - val_acc: 0.9951\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0700 - acc: 0.9744 - val_loss: 0.0187 - val_acc: 0.9951\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0632 - acc: 0.9764 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0621 - acc: 0.9764 - val_loss: 0.0187 - val_acc: 0.9951\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.01788 to 0.01785, saving model to best.model\n",
      "0s - loss: 0.0630 - acc: 0.9776 - val_loss: 0.0178 - val_acc: 0.9932\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.01785 to 0.01729, saving model to best.model\n",
      "0s - loss: 0.0601 - acc: 0.9774 - val_loss: 0.0173 - val_acc: 0.9951\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0584 - acc: 0.9793 - val_loss: 0.0179 - val_acc: 0.9942\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.01729 to 0.01656, saving model to best.model\n",
      "0s - loss: 0.0666 - acc: 0.9769 - val_loss: 0.0166 - val_acc: 0.9961\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0616 - acc: 0.9754 - val_loss: 0.0173 - val_acc: 0.9961\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.01656 to 0.01622, saving model to best.model\n",
      "0s - loss: 0.0595 - acc: 0.9749 - val_loss: 0.0162 - val_acc: 0.9951\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.01622 to 0.01508, saving model to best.model\n",
      "0s - loss: 0.0583 - acc: 0.9781 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9820 - val_loss: 0.0152 - val_acc: 0.9961\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.01508 to 0.01360, saving model to best.model\n",
      "0s - loss: 0.0553 - acc: 0.9800 - val_loss: 0.0136 - val_acc: 0.9961\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.01360 to 0.01334, saving model to best.model\n",
      "0s - loss: 0.0521 - acc: 0.9827 - val_loss: 0.0133 - val_acc: 0.9951\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.01334 to 0.01300, saving model to best.model\n",
      "0s - loss: 0.0548 - acc: 0.9786 - val_loss: 0.0130 - val_acc: 0.9961\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.01300 to 0.01290, saving model to best.model\n",
      "0s - loss: 0.0497 - acc: 0.9803 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0488 - acc: 0.9834 - val_loss: 0.0150 - val_acc: 0.9951\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.01290 to 0.01268, saving model to best.model\n",
      "0s - loss: 0.0583 - acc: 0.9776 - val_loss: 0.0127 - val_acc: 0.9961\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0637 - acc: 0.9776 - val_loss: 0.0161 - val_acc: 0.9951\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9820 - val_loss: 0.0154 - val_acc: 0.9951\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0510 - acc: 0.9844 - val_loss: 0.0141 - val_acc: 0.9951\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0627 - acc: 0.9774 - val_loss: 0.0134 - val_acc: 0.9961\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0487 - acc: 0.9847 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.01268 to 0.01217, saving model to best.model\n",
      "0s - loss: 0.0520 - acc: 0.9822 - val_loss: 0.0122 - val_acc: 0.9971\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01217 to 0.01201, saving model to best.model\n",
      "0s - loss: 0.0499 - acc: 0.9813 - val_loss: 0.0120 - val_acc: 0.9961\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01201 to 0.01108, saving model to best.model\n",
      "0s - loss: 0.0442 - acc: 0.9856 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01108 to 0.01066, saving model to best.model\n",
      "0s - loss: 0.0582 - acc: 0.9813 - val_loss: 0.0107 - val_acc: 0.9971\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9803 - val_loss: 0.0112 - val_acc: 0.9961\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.01066 to 0.01047, saving model to best.model\n",
      "0s - loss: 0.0439 - acc: 0.9839 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9849 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9754 - val_loss: 0.0164 - val_acc: 0.9942\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0551 - acc: 0.9800 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01047 to 0.01038, saving model to best.model\n",
      "0s - loss: 0.0453 - acc: 0.9827 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9815 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01038 to 0.00987, saving model to best.model\n",
      "0s - loss: 0.0486 - acc: 0.9817 - val_loss: 0.0099 - val_acc: 0.9961\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.00987 to 0.00979, saving model to best.model\n",
      "0s - loss: 0.0425 - acc: 0.9856 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0448 - acc: 0.9851 - val_loss: 0.0098 - val_acc: 0.9961\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.00979 to 0.00880, saving model to best.model\n",
      "0s - loss: 0.0389 - acc: 0.9876 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9859 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0391 - acc: 0.9873 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.00880 to 0.00874, saving model to best.model\n",
      "0s - loss: 0.0423 - acc: 0.9847 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.00874 to 0.00840, saving model to best.model\n",
      "0s - loss: 0.0419 - acc: 0.9834 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9842 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0409 - acc: 0.9854 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.00840 to 0.00789, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9817 - val_loss: 0.0079 - val_acc: 0.9971\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9861 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9864 - val_loss: 0.0082 - val_acc: 0.9971\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0080 - val_acc: 0.9961\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9851 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.00789 to 0.00729, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9822 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9847 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9869 - val_loss: 0.0076 - val_acc: 0.9971\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9873 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9866 - val_loss: 0.0073 - val_acc: 0.9971\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.00729 to 0.00699, saving model to best.model\n",
      "0s - loss: 0.0350 - acc: 0.9895 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.00699 to 0.00688, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9869 - val_loss: 0.0069 - val_acc: 0.9971\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.00688 to 0.00661, saving model to best.model\n",
      "0s - loss: 0.0363 - acc: 0.9876 - val_loss: 0.0066 - val_acc: 0.9981\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.00661 to 0.00637, saving model to best.model\n",
      "0s - loss: 0.0380 - acc: 0.9849 - val_loss: 0.0064 - val_acc: 0.9981\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.00637 to 0.00600, saving model to best.model\n",
      "0s - loss: 0.0356 - acc: 0.9893 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9856 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9864 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9842 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9842 - val_loss: 0.0063 - val_acc: 0.9971\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0071 - val_acc: 0.9971\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9881 - val_loss: 0.0073 - val_acc: 0.9961\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9856 - val_loss: 0.0060 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9869 - val_loss: 0.0061 - val_acc: 0.9971\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.00600 to 0.00558, saving model to best.model\n",
      "0s - loss: 0.0324 - acc: 0.9881 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.00558 to 0.00552, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9871 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9900 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9881 - val_loss: 0.0059 - val_acc: 0.9971\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9888 - val_loss: 0.0070 - val_acc: 0.9961\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9847 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9873 - val_loss: 0.0081 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9861 - val_loss: 0.0069 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9883 - val_loss: 0.0063 - val_acc: 0.9981\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9861 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00552 to 0.00524, saving model to best.model\n",
      "0s - loss: 0.0302 - acc: 0.9883 - val_loss: 0.0052 - val_acc: 0.9981\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9878 - val_loss: 0.0064 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0396 - acc: 0.9830 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9881 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9856 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0296 - acc: 0.9893 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00524 to 0.00512, saving model to best.model\n",
      "0s - loss: 0.0281 - acc: 0.9890 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00512 to 0.00481, saving model to best.model\n",
      "0s - loss: 0.0318 - acc: 0.9881 - val_loss: 0.0048 - val_acc: 0.9981\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9903 - val_loss: 0.0052 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9912 - val_loss: 0.0049 - val_acc: 0.9981\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00481 to 0.00433, saving model to best.model\n",
      "0s - loss: 0.0322 - acc: 0.9876 - val_loss: 0.0043 - val_acc: 0.9981\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9883 - val_loss: 0.0047 - val_acc: 0.9981\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9895 - val_loss: 0.0050 - val_acc: 0.9981\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9898 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9893 - val_loss: 0.0050 - val_acc: 0.9981\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00433 to 0.00420, saving model to best.model\n",
      "0s - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0042 - val_acc: 0.9981\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66595, saving model to best.model\n",
      "0s - loss: 0.7974 - acc: 0.5096 - val_loss: 0.6659 - val_acc: 0.5764\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66595 to 0.61953, saving model to best.model\n",
      "0s - loss: 0.7430 - acc: 0.5405 - val_loss: 0.6195 - val_acc: 0.8043\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.61953 to 0.55617, saving model to best.model\n",
      "0s - loss: 0.6931 - acc: 0.5810 - val_loss: 0.5562 - val_acc: 0.8267\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.55617 to 0.47676, saving model to best.model\n",
      "0s - loss: 0.6156 - acc: 0.6659 - val_loss: 0.4768 - val_acc: 0.8374\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.47676 to 0.41445, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7378 - val_loss: 0.4144 - val_acc: 0.8423\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.41445 to 0.36892, saving model to best.model\n",
      "0s - loss: 0.4901 - acc: 0.7731 - val_loss: 0.3689 - val_acc: 0.8500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.36892 to 0.34309, saving model to best.model\n",
      "0s - loss: 0.4581 - acc: 0.7972 - val_loss: 0.3431 - val_acc: 0.8734\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.34309 to 0.31895, saving model to best.model\n",
      "0s - loss: 0.4216 - acc: 0.8227 - val_loss: 0.3189 - val_acc: 0.8832\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.31895 to 0.29998, saving model to best.model\n",
      "0s - loss: 0.4023 - acc: 0.8378 - val_loss: 0.3000 - val_acc: 0.8870\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.29998 to 0.28501, saving model to best.model\n",
      "0s - loss: 0.3846 - acc: 0.8430 - val_loss: 0.2850 - val_acc: 0.8948\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.28501 to 0.27503, saving model to best.model\n",
      "0s - loss: 0.3716 - acc: 0.8498 - val_loss: 0.2750 - val_acc: 0.8987\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.27503 to 0.26884, saving model to best.model\n",
      "0s - loss: 0.3568 - acc: 0.8607 - val_loss: 0.2688 - val_acc: 0.8978\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.26884 to 0.25523, saving model to best.model\n",
      "0s - loss: 0.3522 - acc: 0.8559 - val_loss: 0.2552 - val_acc: 0.9114\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.25523 to 0.24925, saving model to best.model\n",
      "0s - loss: 0.3358 - acc: 0.8727 - val_loss: 0.2493 - val_acc: 0.9056\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.24925 to 0.23968, saving model to best.model\n",
      "0s - loss: 0.3283 - acc: 0.8753 - val_loss: 0.2397 - val_acc: 0.9202\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.23968 to 0.23150, saving model to best.model\n",
      "0s - loss: 0.3178 - acc: 0.8790 - val_loss: 0.2315 - val_acc: 0.9260\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.23150 to 0.22552, saving model to best.model\n",
      "0s - loss: 0.2987 - acc: 0.8895 - val_loss: 0.2255 - val_acc: 0.9260\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.22552 to 0.22059, saving model to best.model\n",
      "0s - loss: 0.3002 - acc: 0.8909 - val_loss: 0.2206 - val_acc: 0.9231\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22059 to 0.21862, saving model to best.model\n",
      "0s - loss: 0.2934 - acc: 0.8919 - val_loss: 0.2186 - val_acc: 0.9270\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.21862 to 0.21351, saving model to best.model\n",
      "0s - loss: 0.2926 - acc: 0.8934 - val_loss: 0.2135 - val_acc: 0.9279\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2858 - acc: 0.8965 - val_loss: 0.2138 - val_acc: 0.9309\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21351 to 0.20706, saving model to best.model\n",
      "0s - loss: 0.2836 - acc: 0.8972 - val_loss: 0.2071 - val_acc: 0.9318\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20706 to 0.20278, saving model to best.model\n",
      "0s - loss: 0.2804 - acc: 0.8999 - val_loss: 0.2028 - val_acc: 0.9357\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2704 - acc: 0.8980 - val_loss: 0.2038 - val_acc: 0.9328\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20278 to 0.19614, saving model to best.model\n",
      "0s - loss: 0.2675 - acc: 0.9058 - val_loss: 0.1961 - val_acc: 0.9328\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19614 to 0.19517, saving model to best.model\n",
      "0s - loss: 0.2653 - acc: 0.9063 - val_loss: 0.1952 - val_acc: 0.9309\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19517 to 0.19362, saving model to best.model\n",
      "0s - loss: 0.2692 - acc: 0.9041 - val_loss: 0.1936 - val_acc: 0.9338\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19362 to 0.18746, saving model to best.model\n",
      "0s - loss: 0.2601 - acc: 0.9033 - val_loss: 0.1875 - val_acc: 0.9309\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18746 to 0.18400, saving model to best.model\n",
      "0s - loss: 0.2544 - acc: 0.9084 - val_loss: 0.1840 - val_acc: 0.9318\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18400 to 0.18124, saving model to best.model\n",
      "0s - loss: 0.2463 - acc: 0.9133 - val_loss: 0.1812 - val_acc: 0.9348\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18124 to 0.17740, saving model to best.model\n",
      "0s - loss: 0.2447 - acc: 0.9153 - val_loss: 0.1774 - val_acc: 0.9338\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.17740 to 0.17629, saving model to best.model\n",
      "0s - loss: 0.2467 - acc: 0.9104 - val_loss: 0.1763 - val_acc: 0.9367\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17629 to 0.17433, saving model to best.model\n",
      "0s - loss: 0.2367 - acc: 0.9128 - val_loss: 0.1743 - val_acc: 0.9367\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17433 to 0.17075, saving model to best.model\n",
      "0s - loss: 0.2289 - acc: 0.9158 - val_loss: 0.1708 - val_acc: 0.9348\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17075 to 0.16825, saving model to best.model\n",
      "0s - loss: 0.2311 - acc: 0.9170 - val_loss: 0.1682 - val_acc: 0.9357\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.16825 to 0.16475, saving model to best.model\n",
      "0s - loss: 0.2233 - acc: 0.9177 - val_loss: 0.1648 - val_acc: 0.9348\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16475 to 0.16396, saving model to best.model\n",
      "0s - loss: 0.2210 - acc: 0.9172 - val_loss: 0.1640 - val_acc: 0.9455\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16396 to 0.15888, saving model to best.model\n",
      "0s - loss: 0.2173 - acc: 0.9189 - val_loss: 0.1589 - val_acc: 0.9455\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.15888 to 0.15535, saving model to best.model\n",
      "0s - loss: 0.2151 - acc: 0.9221 - val_loss: 0.1554 - val_acc: 0.9426\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15535 to 0.15189, saving model to best.model\n",
      "0s - loss: 0.2112 - acc: 0.9206 - val_loss: 0.1519 - val_acc: 0.9416\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15189 to 0.14921, saving model to best.model\n",
      "0s - loss: 0.2051 - acc: 0.9231 - val_loss: 0.1492 - val_acc: 0.9464\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14921 to 0.14574, saving model to best.model\n",
      "0s - loss: 0.2094 - acc: 0.9265 - val_loss: 0.1457 - val_acc: 0.9503\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.14574 to 0.14424, saving model to best.model\n",
      "0s - loss: 0.2139 - acc: 0.9187 - val_loss: 0.1442 - val_acc: 0.9445\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14424 to 0.14381, saving model to best.model\n",
      "0s - loss: 0.2022 - acc: 0.9272 - val_loss: 0.1438 - val_acc: 0.9435\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14381 to 0.14139, saving model to best.model\n",
      "0s - loss: 0.2027 - acc: 0.9257 - val_loss: 0.1414 - val_acc: 0.9445\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14139 to 0.13755, saving model to best.model\n",
      "0s - loss: 0.1924 - acc: 0.9291 - val_loss: 0.1376 - val_acc: 0.9494\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13755 to 0.13442, saving model to best.model\n",
      "0s - loss: 0.1877 - acc: 0.9338 - val_loss: 0.1344 - val_acc: 0.9494\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13442 to 0.13186, saving model to best.model\n",
      "0s - loss: 0.1904 - acc: 0.9316 - val_loss: 0.1319 - val_acc: 0.9494\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13186 to 0.12939, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9306 - val_loss: 0.1294 - val_acc: 0.9523\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1768 - acc: 0.9328 - val_loss: 0.1303 - val_acc: 0.9552\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.12939 to 0.12582, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9284 - val_loss: 0.1258 - val_acc: 0.9552\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12582 to 0.12504, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9360 - val_loss: 0.1250 - val_acc: 0.9611\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.12504 to 0.11958, saving model to best.model\n",
      "0s - loss: 0.1801 - acc: 0.9360 - val_loss: 0.1196 - val_acc: 0.9533\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11958 to 0.11727, saving model to best.model\n",
      "0s - loss: 0.1783 - acc: 0.9294 - val_loss: 0.1173 - val_acc: 0.9620\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.11727 to 0.11385, saving model to best.model\n",
      "0s - loss: 0.1697 - acc: 0.9382 - val_loss: 0.1139 - val_acc: 0.9611\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.11385 to 0.11180, saving model to best.model\n",
      "0s - loss: 0.1625 - acc: 0.9401 - val_loss: 0.1118 - val_acc: 0.9572\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.11180 to 0.10811, saving model to best.model\n",
      "0s - loss: 0.1578 - acc: 0.9425 - val_loss: 0.1081 - val_acc: 0.9620\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10811 to 0.10624, saving model to best.model\n",
      "0s - loss: 0.1626 - acc: 0.9401 - val_loss: 0.1062 - val_acc: 0.9640\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.10624 to 0.10443, saving model to best.model\n",
      "0s - loss: 0.1557 - acc: 0.9459 - val_loss: 0.1044 - val_acc: 0.9649\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1566 - acc: 0.9425 - val_loss: 0.1057 - val_acc: 0.9659\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.10443 to 0.10078, saving model to best.model\n",
      "0s - loss: 0.1535 - acc: 0.9440 - val_loss: 0.1008 - val_acc: 0.9659\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10078 to 0.09627, saving model to best.model\n",
      "0s - loss: 0.1418 - acc: 0.9472 - val_loss: 0.0963 - val_acc: 0.9669\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.09627 to 0.09289, saving model to best.model\n",
      "0s - loss: 0.1402 - acc: 0.9457 - val_loss: 0.0929 - val_acc: 0.9669\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.09289 to 0.08976, saving model to best.model\n",
      "0s - loss: 0.1448 - acc: 0.9469 - val_loss: 0.0898 - val_acc: 0.9679\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08976 to 0.08653, saving model to best.model\n",
      "0s - loss: 0.1373 - acc: 0.9425 - val_loss: 0.0865 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08653 to 0.08418, saving model to best.model\n",
      "0s - loss: 0.1346 - acc: 0.9481 - val_loss: 0.0842 - val_acc: 0.9708\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.08418 to 0.08305, saving model to best.model\n",
      "0s - loss: 0.1373 - acc: 0.9459 - val_loss: 0.0831 - val_acc: 0.9688\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.08305 to 0.07950, saving model to best.model\n",
      "0s - loss: 0.1292 - acc: 0.9486 - val_loss: 0.0795 - val_acc: 0.9727\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07950 to 0.07689, saving model to best.model\n",
      "0s - loss: 0.1272 - acc: 0.9472 - val_loss: 0.0769 - val_acc: 0.9747\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1275 - acc: 0.9484 - val_loss: 0.0799 - val_acc: 0.9737\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.07689 to 0.07572, saving model to best.model\n",
      "0s - loss: 0.1278 - acc: 0.9472 - val_loss: 0.0757 - val_acc: 0.9708\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07572 to 0.07197, saving model to best.model\n",
      "0s - loss: 0.1257 - acc: 0.9503 - val_loss: 0.0720 - val_acc: 0.9776\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07197 to 0.07051, saving model to best.model\n",
      "0s - loss: 0.1222 - acc: 0.9520 - val_loss: 0.0705 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07051 to 0.06708, saving model to best.model\n",
      "0s - loss: 0.1167 - acc: 0.9523 - val_loss: 0.0671 - val_acc: 0.9776\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06708 to 0.06399, saving model to best.model\n",
      "0s - loss: 0.1123 - acc: 0.9547 - val_loss: 0.0640 - val_acc: 0.9796\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06399 to 0.06295, saving model to best.model\n",
      "0s - loss: 0.1128 - acc: 0.9559 - val_loss: 0.0630 - val_acc: 0.9805\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06295 to 0.06200, saving model to best.model\n",
      "0s - loss: 0.1138 - acc: 0.9576 - val_loss: 0.0620 - val_acc: 0.9786\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06200 to 0.05896, saving model to best.model\n",
      "0s - loss: 0.1085 - acc: 0.9584 - val_loss: 0.0590 - val_acc: 0.9796\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1064 - acc: 0.9571 - val_loss: 0.0590 - val_acc: 0.9796\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1180 - acc: 0.9550 - val_loss: 0.0599 - val_acc: 0.9805\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05896 to 0.05445, saving model to best.model\n",
      "0s - loss: 0.1067 - acc: 0.9571 - val_loss: 0.0545 - val_acc: 0.9796\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0936 - acc: 0.9645 - val_loss: 0.0545 - val_acc: 0.9786\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05445 to 0.05152, saving model to best.model\n",
      "0s - loss: 0.0988 - acc: 0.9615 - val_loss: 0.0515 - val_acc: 0.9805\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0997 - acc: 0.9603 - val_loss: 0.0527 - val_acc: 0.9854\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05152 to 0.04890, saving model to best.model\n",
      "0s - loss: 0.0905 - acc: 0.9608 - val_loss: 0.0489 - val_acc: 0.9815\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04890 to 0.04866, saving model to best.model\n",
      "0s - loss: 0.0857 - acc: 0.9664 - val_loss: 0.0487 - val_acc: 0.9854\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04866 to 0.04451, saving model to best.model\n",
      "0s - loss: 0.0972 - acc: 0.9625 - val_loss: 0.0445 - val_acc: 0.9854\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0852 - acc: 0.9691 - val_loss: 0.0464 - val_acc: 0.9854\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04451 to 0.04364, saving model to best.model\n",
      "0s - loss: 0.0909 - acc: 0.9632 - val_loss: 0.0436 - val_acc: 0.9864\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04364 to 0.04293, saving model to best.model\n",
      "0s - loss: 0.0878 - acc: 0.9654 - val_loss: 0.0429 - val_acc: 0.9854\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0880 - acc: 0.9589 - val_loss: 0.0455 - val_acc: 0.9864\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0859 - acc: 0.9686 - val_loss: 0.0448 - val_acc: 0.9805\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04293 to 0.04098, saving model to best.model\n",
      "0s - loss: 0.0869 - acc: 0.9664 - val_loss: 0.0410 - val_acc: 0.9873\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04098 to 0.04073, saving model to best.model\n",
      "0s - loss: 0.0852 - acc: 0.9642 - val_loss: 0.0407 - val_acc: 0.9873\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04073 to 0.04040, saving model to best.model\n",
      "0s - loss: 0.0835 - acc: 0.9671 - val_loss: 0.0404 - val_acc: 0.9864\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04040 to 0.03933, saving model to best.model\n",
      "0s - loss: 0.0852 - acc: 0.9652 - val_loss: 0.0393 - val_acc: 0.9864\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.03933 to 0.03793, saving model to best.model\n",
      "0s - loss: 0.0782 - acc: 0.9676 - val_loss: 0.0379 - val_acc: 0.9873\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0905 - acc: 0.9618 - val_loss: 0.0415 - val_acc: 0.9864\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03793 to 0.03659, saving model to best.model\n",
      "0s - loss: 0.0745 - acc: 0.9710 - val_loss: 0.0366 - val_acc: 0.9873\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0798 - acc: 0.9705 - val_loss: 0.0369 - val_acc: 0.9864\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03659 to 0.03560, saving model to best.model\n",
      "0s - loss: 0.0762 - acc: 0.9691 - val_loss: 0.0356 - val_acc: 0.9873\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03560 to 0.03413, saving model to best.model\n",
      "0s - loss: 0.0732 - acc: 0.9715 - val_loss: 0.0341 - val_acc: 0.9873\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0760 - acc: 0.9671 - val_loss: 0.0345 - val_acc: 0.9873\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03413 to 0.03306, saving model to best.model\n",
      "0s - loss: 0.0763 - acc: 0.9686 - val_loss: 0.0331 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03306 to 0.03236, saving model to best.model\n",
      "0s - loss: 0.0757 - acc: 0.9705 - val_loss: 0.0324 - val_acc: 0.9883\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0676 - acc: 0.9720 - val_loss: 0.0325 - val_acc: 0.9883\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0777 - acc: 0.9701 - val_loss: 0.0348 - val_acc: 0.9873\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03236 to 0.03182, saving model to best.model\n",
      "0s - loss: 0.0768 - acc: 0.9698 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0689 - acc: 0.9735 - val_loss: 0.0332 - val_acc: 0.9883\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03182 to 0.02966, saving model to best.model\n",
      "0s - loss: 0.0699 - acc: 0.9715 - val_loss: 0.0297 - val_acc: 0.9873\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0661 - acc: 0.9747 - val_loss: 0.0305 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02966 to 0.02759, saving model to best.model\n",
      "0s - loss: 0.0630 - acc: 0.9737 - val_loss: 0.0276 - val_acc: 0.9883\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9776 - val_loss: 0.0277 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0602 - acc: 0.9754 - val_loss: 0.0277 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02759 to 0.02594, saving model to best.model\n",
      "0s - loss: 0.0673 - acc: 0.9730 - val_loss: 0.0259 - val_acc: 0.9893\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02594 to 0.02575, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9754 - val_loss: 0.0258 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02575 to 0.02548, saving model to best.model\n",
      "0s - loss: 0.0641 - acc: 0.9725 - val_loss: 0.0255 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02548 to 0.02417, saving model to best.model\n",
      "0s - loss: 0.0655 - acc: 0.9759 - val_loss: 0.0242 - val_acc: 0.9883\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0638 - acc: 0.9739 - val_loss: 0.0245 - val_acc: 0.9883\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02417 to 0.02370, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9747 - val_loss: 0.0237 - val_acc: 0.9893\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9800 - val_loss: 0.0238 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02370 to 0.02266, saving model to best.model\n",
      "0s - loss: 0.0522 - acc: 0.9808 - val_loss: 0.0227 - val_acc: 0.9893\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0579 - acc: 0.9783 - val_loss: 0.0232 - val_acc: 0.9903\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02266 to 0.02143, saving model to best.model\n",
      "0s - loss: 0.0526 - acc: 0.9788 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0578 - acc: 0.9776 - val_loss: 0.0241 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02143 to 0.02085, saving model to best.model\n",
      "0s - loss: 0.0588 - acc: 0.9754 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9798 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0538 - acc: 0.9795 - val_loss: 0.0217 - val_acc: 0.9912\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9795 - val_loss: 0.0210 - val_acc: 0.9903\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02085 to 0.02012, saving model to best.model\n",
      "0s - loss: 0.0534 - acc: 0.9766 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02012 to 0.01950, saving model to best.model\n",
      "0s - loss: 0.0496 - acc: 0.9788 - val_loss: 0.0195 - val_acc: 0.9922\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0515 - acc: 0.9810 - val_loss: 0.0253 - val_acc: 0.9903\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0561 - acc: 0.9769 - val_loss: 0.0200 - val_acc: 0.9961\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0584 - acc: 0.9788 - val_loss: 0.0211 - val_acc: 0.9903\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0541 - acc: 0.9781 - val_loss: 0.0230 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9791 - val_loss: 0.0199 - val_acc: 0.9912\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01950 to 0.01883, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9815 - val_loss: 0.0188 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9820 - val_loss: 0.0190 - val_acc: 0.9903\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0493 - acc: 0.9830 - val_loss: 0.0190 - val_acc: 0.9912\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01883 to 0.01736, saving model to best.model\n",
      "0s - loss: 0.0412 - acc: 0.9847 - val_loss: 0.0174 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9813 - val_loss: 0.0176 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0433 - acc: 0.9815 - val_loss: 0.0182 - val_acc: 0.9912\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01736 to 0.01555, saving model to best.model\n",
      "0s - loss: 0.0461 - acc: 0.9825 - val_loss: 0.0156 - val_acc: 0.9942\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0219 - val_acc: 0.9893\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9791 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9803 - val_loss: 0.0159 - val_acc: 0.9951\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0547 - acc: 0.9781 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9844 - val_loss: 0.0194 - val_acc: 0.9912\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01555 to 0.01489, saving model to best.model\n",
      "0s - loss: 0.0397 - acc: 0.9856 - val_loss: 0.0149 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9822 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9820 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9832 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0421 - acc: 0.9837 - val_loss: 0.0159 - val_acc: 0.9961\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9810 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9813 - val_loss: 0.0152 - val_acc: 0.9942\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9849 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01489 to 0.01425, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9847 - val_loss: 0.0143 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01425 to 0.01402, saving model to best.model\n",
      "0s - loss: 0.0412 - acc: 0.9854 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9881 - val_loss: 0.0154 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9820 - val_loss: 0.0141 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9854 - val_loss: 0.0141 - val_acc: 0.9951\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9820 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01402 to 0.01301, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9854 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9832 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9832 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9815 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9837 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9866 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9842 - val_loss: 0.0138 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01301 to 0.01258, saving model to best.model\n",
      "0s - loss: 0.0398 - acc: 0.9839 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01258 to 0.01239, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9859 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01239 to 0.01202, saving model to best.model\n",
      "0s - loss: 0.0376 - acc: 0.9859 - val_loss: 0.0120 - val_acc: 0.9981\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9881 - val_loss: 0.0133 - val_acc: 0.9961\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9847 - val_loss: 0.0125 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9881 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01202 to 0.01151, saving model to best.model\n",
      "0s - loss: 0.0365 - acc: 0.9869 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01151 to 0.01094, saving model to best.model\n",
      "0s - loss: 0.0317 - acc: 0.9876 - val_loss: 0.0109 - val_acc: 0.9971\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9869 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01094 to 0.01065, saving model to best.model\n",
      "0s - loss: 0.0375 - acc: 0.9842 - val_loss: 0.0106 - val_acc: 0.9981\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9898 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9854 - val_loss: 0.0114 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9869 - val_loss: 0.0108 - val_acc: 0.9981\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01065 to 0.01038, saving model to best.model\n",
      "0s - loss: 0.0283 - acc: 0.9900 - val_loss: 0.0104 - val_acc: 0.9990\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9873 - val_loss: 0.0111 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9893 - val_loss: 0.0107 - val_acc: 0.9981\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.01038 to 0.00982, saving model to best.model\n",
      "0s - loss: 0.0291 - acc: 0.9871 - val_loss: 0.0098 - val_acc: 0.9990\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.00982 to 0.00950, saving model to best.model\n",
      "0s - loss: 0.0397 - acc: 0.9842 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00950 to 0.00907, saving model to best.model\n",
      "0s - loss: 0.0298 - acc: 0.9895 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9869 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9886 - val_loss: 0.0094 - val_acc: 0.9981\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9895 - val_loss: 0.0099 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9888 - val_loss: 0.0094 - val_acc: 0.9990\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9866 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9893 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9890 - val_loss: 0.0102 - val_acc: 0.9990\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9881 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9873 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9890 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67920, saving model to best.model\n",
      "0s - loss: 0.8776 - acc: 0.5067 - val_loss: 0.6792 - val_acc: 0.4995\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67920 to 0.65340, saving model to best.model\n",
      "0s - loss: 0.7752 - acc: 0.5174 - val_loss: 0.6534 - val_acc: 0.5336\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65340 to 0.61118, saving model to best.model\n",
      "0s - loss: 0.7350 - acc: 0.5439 - val_loss: 0.6112 - val_acc: 0.8160\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61118 to 0.54219, saving model to best.model\n",
      "0s - loss: 0.6772 - acc: 0.6017 - val_loss: 0.5422 - val_acc: 0.8033\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54219 to 0.46293, saving model to best.model\n",
      "0s - loss: 0.5967 - acc: 0.6861 - val_loss: 0.4629 - val_acc: 0.8296\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.46293 to 0.40146, saving model to best.model\n",
      "0s - loss: 0.5179 - acc: 0.7551 - val_loss: 0.4015 - val_acc: 0.8403\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40146 to 0.36213, saving model to best.model\n",
      "0s - loss: 0.4597 - acc: 0.8008 - val_loss: 0.3621 - val_acc: 0.8530\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36213 to 0.34092, saving model to best.model\n",
      "0s - loss: 0.4229 - acc: 0.8223 - val_loss: 0.3409 - val_acc: 0.8647\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34092 to 0.31808, saving model to best.model\n",
      "0s - loss: 0.3930 - acc: 0.8337 - val_loss: 0.3181 - val_acc: 0.8705\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31808 to 0.30428, saving model to best.model\n",
      "0s - loss: 0.3746 - acc: 0.8476 - val_loss: 0.3043 - val_acc: 0.8763\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30428 to 0.28731, saving model to best.model\n",
      "0s - loss: 0.3541 - acc: 0.8607 - val_loss: 0.2873 - val_acc: 0.8890\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28731 to 0.27613, saving model to best.model\n",
      "0s - loss: 0.3388 - acc: 0.8658 - val_loss: 0.2761 - val_acc: 0.8909\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27613 to 0.26715, saving model to best.model\n",
      "0s - loss: 0.3145 - acc: 0.8804 - val_loss: 0.2672 - val_acc: 0.8909\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26715 to 0.26103, saving model to best.model\n",
      "0s - loss: 0.3251 - acc: 0.8780 - val_loss: 0.2610 - val_acc: 0.8939\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26103 to 0.25488, saving model to best.model\n",
      "0s - loss: 0.3050 - acc: 0.8853 - val_loss: 0.2549 - val_acc: 0.9007\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25488 to 0.25047, saving model to best.model\n",
      "0s - loss: 0.2929 - acc: 0.8887 - val_loss: 0.2505 - val_acc: 0.9094\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25047 to 0.24596, saving model to best.model\n",
      "0s - loss: 0.2901 - acc: 0.8895 - val_loss: 0.2460 - val_acc: 0.9153\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24596 to 0.24129, saving model to best.model\n",
      "0s - loss: 0.2842 - acc: 0.8916 - val_loss: 0.2413 - val_acc: 0.9153\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24129 to 0.23875, saving model to best.model\n",
      "0s - loss: 0.2726 - acc: 0.8997 - val_loss: 0.2387 - val_acc: 0.9163\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23875 to 0.23508, saving model to best.model\n",
      "0s - loss: 0.2596 - acc: 0.9053 - val_loss: 0.2351 - val_acc: 0.9182\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2558 - acc: 0.9109 - val_loss: 0.2378 - val_acc: 0.9182\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23508 to 0.23023, saving model to best.model\n",
      "0s - loss: 0.2627 - acc: 0.9058 - val_loss: 0.2302 - val_acc: 0.9192\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23023 to 0.22560, saving model to best.model\n",
      "0s - loss: 0.2477 - acc: 0.9126 - val_loss: 0.2256 - val_acc: 0.9211\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22560 to 0.22498, saving model to best.model\n",
      "0s - loss: 0.2425 - acc: 0.9128 - val_loss: 0.2250 - val_acc: 0.9172\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22498 to 0.22029, saving model to best.model\n",
      "0s - loss: 0.2362 - acc: 0.9170 - val_loss: 0.2203 - val_acc: 0.9211\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.22029 to 0.21906, saving model to best.model\n",
      "0s - loss: 0.2454 - acc: 0.9138 - val_loss: 0.2191 - val_acc: 0.9250\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21906 to 0.21593, saving model to best.model\n",
      "0s - loss: 0.2385 - acc: 0.9177 - val_loss: 0.2159 - val_acc: 0.9241\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21593 to 0.21505, saving model to best.model\n",
      "0s - loss: 0.2329 - acc: 0.9194 - val_loss: 0.2151 - val_acc: 0.9211\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.21505 to 0.21122, saving model to best.model\n",
      "0s - loss: 0.2303 - acc: 0.9196 - val_loss: 0.2112 - val_acc: 0.9231\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.21122 to 0.20801, saving model to best.model\n",
      "0s - loss: 0.2236 - acc: 0.9214 - val_loss: 0.2080 - val_acc: 0.9221\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20801 to 0.20248, saving model to best.model\n",
      "0s - loss: 0.2226 - acc: 0.9204 - val_loss: 0.2025 - val_acc: 0.9241\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.20248 to 0.20031, saving model to best.model\n",
      "0s - loss: 0.2136 - acc: 0.9231 - val_loss: 0.2003 - val_acc: 0.9241\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.20031 to 0.19798, saving model to best.model\n",
      "0s - loss: 0.2163 - acc: 0.9221 - val_loss: 0.1980 - val_acc: 0.9250\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19798 to 0.19520, saving model to best.model\n",
      "0s - loss: 0.2155 - acc: 0.9226 - val_loss: 0.1952 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19520 to 0.19235, saving model to best.model\n",
      "0s - loss: 0.2138 - acc: 0.9252 - val_loss: 0.1923 - val_acc: 0.9289\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19235 to 0.19147, saving model to best.model\n",
      "0s - loss: 0.2040 - acc: 0.9255 - val_loss: 0.1915 - val_acc: 0.9367\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.2009 - acc: 0.9287 - val_loss: 0.1916 - val_acc: 0.9202\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19147 to 0.18611, saving model to best.model\n",
      "0s - loss: 0.1973 - acc: 0.9313 - val_loss: 0.1861 - val_acc: 0.9377\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18611 to 0.18106, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9311 - val_loss: 0.1811 - val_acc: 0.9348\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.1980 - acc: 0.9267 - val_loss: 0.1818 - val_acc: 0.9231\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.18106 to 0.17584, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9265 - val_loss: 0.1758 - val_acc: 0.9348\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17584 to 0.17201, saving model to best.model\n",
      "0s - loss: 0.1903 - acc: 0.9316 - val_loss: 0.1720 - val_acc: 0.9338\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17201 to 0.16902, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9294 - val_loss: 0.1690 - val_acc: 0.9357\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16902 to 0.16573, saving model to best.model\n",
      "0s - loss: 0.1906 - acc: 0.9333 - val_loss: 0.1657 - val_acc: 0.9357\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16573 to 0.16506, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9333 - val_loss: 0.1651 - val_acc: 0.9445\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.16506 to 0.15921, saving model to best.model\n",
      "0s - loss: 0.1739 - acc: 0.9355 - val_loss: 0.1592 - val_acc: 0.9406\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15921 to 0.15756, saving model to best.model\n",
      "0s - loss: 0.1660 - acc: 0.9386 - val_loss: 0.1576 - val_acc: 0.9377\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.1722 - acc: 0.9372 - val_loss: 0.1635 - val_acc: 0.9464\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15756 to 0.15304, saving model to best.model\n",
      "0s - loss: 0.1717 - acc: 0.9350 - val_loss: 0.1530 - val_acc: 0.9357\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.15304 to 0.14586, saving model to best.model\n",
      "0s - loss: 0.1661 - acc: 0.9355 - val_loss: 0.1459 - val_acc: 0.9426\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1642 - acc: 0.9391 - val_loss: 0.1459 - val_acc: 0.9484\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.14586 to 0.13973, saving model to best.model\n",
      "0s - loss: 0.1561 - acc: 0.9401 - val_loss: 0.1397 - val_acc: 0.9435\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13973 to 0.13743, saving model to best.model\n",
      "0s - loss: 0.1541 - acc: 0.9450 - val_loss: 0.1374 - val_acc: 0.9484\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13743 to 0.13341, saving model to best.model\n",
      "0s - loss: 0.1469 - acc: 0.9469 - val_loss: 0.1334 - val_acc: 0.9484\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13341 to 0.12953, saving model to best.model\n",
      "0s - loss: 0.1444 - acc: 0.9486 - val_loss: 0.1295 - val_acc: 0.9494\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12953 to 0.12698, saving model to best.model\n",
      "0s - loss: 0.1396 - acc: 0.9494 - val_loss: 0.1270 - val_acc: 0.9494\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12698 to 0.12272, saving model to best.model\n",
      "0s - loss: 0.1488 - acc: 0.9433 - val_loss: 0.1227 - val_acc: 0.9523\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12272 to 0.12118, saving model to best.model\n",
      "0s - loss: 0.1401 - acc: 0.9484 - val_loss: 0.1212 - val_acc: 0.9494\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.12118 to 0.11816, saving model to best.model\n",
      "0s - loss: 0.1372 - acc: 0.9489 - val_loss: 0.1182 - val_acc: 0.9523\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11816 to 0.11607, saving model to best.model\n",
      "0s - loss: 0.1299 - acc: 0.9503 - val_loss: 0.1161 - val_acc: 0.9552\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11607 to 0.11291, saving model to best.model\n",
      "0s - loss: 0.1376 - acc: 0.9469 - val_loss: 0.1129 - val_acc: 0.9533\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.11291 to 0.11129, saving model to best.model\n",
      "0s - loss: 0.1269 - acc: 0.9535 - val_loss: 0.1113 - val_acc: 0.9581\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11129 to 0.10671, saving model to best.model\n",
      "0s - loss: 0.1273 - acc: 0.9506 - val_loss: 0.1067 - val_acc: 0.9562\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10671 to 0.10577, saving model to best.model\n",
      "0s - loss: 0.1236 - acc: 0.9508 - val_loss: 0.1058 - val_acc: 0.9562\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10577 to 0.10160, saving model to best.model\n",
      "0s - loss: 0.1232 - acc: 0.9515 - val_loss: 0.1016 - val_acc: 0.9591\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10160 to 0.09939, saving model to best.model\n",
      "0s - loss: 0.1229 - acc: 0.9554 - val_loss: 0.0994 - val_acc: 0.9572\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09939 to 0.09867, saving model to best.model\n",
      "0s - loss: 0.1117 - acc: 0.9598 - val_loss: 0.0987 - val_acc: 0.9640\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09867 to 0.09378, saving model to best.model\n",
      "0s - loss: 0.1074 - acc: 0.9596 - val_loss: 0.0938 - val_acc: 0.9591\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09378 to 0.09144, saving model to best.model\n",
      "0s - loss: 0.1114 - acc: 0.9586 - val_loss: 0.0914 - val_acc: 0.9611\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09144 to 0.08993, saving model to best.model\n",
      "0s - loss: 0.1067 - acc: 0.9610 - val_loss: 0.0899 - val_acc: 0.9630\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08993 to 0.08554, saving model to best.model\n",
      "0s - loss: 0.1054 - acc: 0.9576 - val_loss: 0.0855 - val_acc: 0.9630\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08554 to 0.08221, saving model to best.model\n",
      "0s - loss: 0.1029 - acc: 0.9589 - val_loss: 0.0822 - val_acc: 0.9659\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08221 to 0.07869, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9654 - val_loss: 0.0787 - val_acc: 0.9698\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07869 to 0.07731, saving model to best.model\n",
      "0s - loss: 0.1019 - acc: 0.9589 - val_loss: 0.0773 - val_acc: 0.9698\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1009 - acc: 0.9586 - val_loss: 0.0778 - val_acc: 0.9718\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07731 to 0.07535, saving model to best.model\n",
      "0s - loss: 0.1001 - acc: 0.9620 - val_loss: 0.0754 - val_acc: 0.9708\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07535 to 0.07264, saving model to best.model\n",
      "0s - loss: 0.0995 - acc: 0.9610 - val_loss: 0.0726 - val_acc: 0.9737\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07264 to 0.07262, saving model to best.model\n",
      "0s - loss: 0.0936 - acc: 0.9637 - val_loss: 0.0726 - val_acc: 0.9766\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0998 - acc: 0.9640 - val_loss: 0.0740 - val_acc: 0.9708\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07262 to 0.06841, saving model to best.model\n",
      "0s - loss: 0.0895 - acc: 0.9662 - val_loss: 0.0684 - val_acc: 0.9718\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.06841 to 0.06657, saving model to best.model\n",
      "0s - loss: 0.0873 - acc: 0.9691 - val_loss: 0.0666 - val_acc: 0.9737\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06657 to 0.06427, saving model to best.model\n",
      "0s - loss: 0.0897 - acc: 0.9676 - val_loss: 0.0643 - val_acc: 0.9737\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06427 to 0.06411, saving model to best.model\n",
      "0s - loss: 0.0820 - acc: 0.9696 - val_loss: 0.0641 - val_acc: 0.9766\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06411 to 0.06329, saving model to best.model\n",
      "0s - loss: 0.0848 - acc: 0.9674 - val_loss: 0.0633 - val_acc: 0.9718\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0804 - acc: 0.9703 - val_loss: 0.0662 - val_acc: 0.9776\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06329 to 0.05887, saving model to best.model\n",
      "0s - loss: 0.0864 - acc: 0.9647 - val_loss: 0.0589 - val_acc: 0.9786\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0809 - acc: 0.9676 - val_loss: 0.0600 - val_acc: 0.9776\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05887 to 0.05650, saving model to best.model\n",
      "0s - loss: 0.0836 - acc: 0.9676 - val_loss: 0.0565 - val_acc: 0.9786\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05650 to 0.05512, saving model to best.model\n",
      "0s - loss: 0.0840 - acc: 0.9686 - val_loss: 0.0551 - val_acc: 0.9766\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05512 to 0.05281, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9769 - val_loss: 0.0528 - val_acc: 0.9815\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05281 to 0.05057, saving model to best.model\n",
      "0s - loss: 0.0740 - acc: 0.9713 - val_loss: 0.0506 - val_acc: 0.9825\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0775 - acc: 0.9718 - val_loss: 0.0543 - val_acc: 0.9834\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0660 - acc: 0.9737 - val_loss: 0.0509 - val_acc: 0.9815\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05057 to 0.04825, saving model to best.model\n",
      "0s - loss: 0.0689 - acc: 0.9761 - val_loss: 0.0482 - val_acc: 0.9815\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0743 - acc: 0.9722 - val_loss: 0.0495 - val_acc: 0.9834\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04825 to 0.04713, saving model to best.model\n",
      "0s - loss: 0.0697 - acc: 0.9742 - val_loss: 0.0471 - val_acc: 0.9825\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0730 - acc: 0.9747 - val_loss: 0.0487 - val_acc: 0.9796\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9783 - val_loss: 0.0478 - val_acc: 0.9796\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04713 to 0.04295, saving model to best.model\n",
      "0s - loss: 0.0651 - acc: 0.9737 - val_loss: 0.0429 - val_acc: 0.9844\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04295 to 0.04082, saving model to best.model\n",
      "0s - loss: 0.0700 - acc: 0.9732 - val_loss: 0.0408 - val_acc: 0.9825\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0628 - acc: 0.9759 - val_loss: 0.0426 - val_acc: 0.9834\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9754 - val_loss: 0.0454 - val_acc: 0.9796\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.04082 to 0.04001, saving model to best.model\n",
      "0s - loss: 0.0671 - acc: 0.9757 - val_loss: 0.0400 - val_acc: 0.9844\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.04001 to 0.03790, saving model to best.model\n",
      "0s - loss: 0.0617 - acc: 0.9742 - val_loss: 0.0379 - val_acc: 0.9854\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0605 - acc: 0.9749 - val_loss: 0.0380 - val_acc: 0.9844\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03790 to 0.03611, saving model to best.model\n",
      "0s - loss: 0.0608 - acc: 0.9769 - val_loss: 0.0361 - val_acc: 0.9834\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0600 - acc: 0.9754 - val_loss: 0.0362 - val_acc: 0.9834\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0623 - acc: 0.9764 - val_loss: 0.0364 - val_acc: 0.9854\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03611 to 0.03606, saving model to best.model\n",
      "0s - loss: 0.0600 - acc: 0.9754 - val_loss: 0.0361 - val_acc: 0.9854\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9769 - val_loss: 0.0385 - val_acc: 0.9825\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03606 to 0.03300, saving model to best.model\n",
      "0s - loss: 0.0563 - acc: 0.9761 - val_loss: 0.0330 - val_acc: 0.9873\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9781 - val_loss: 0.0340 - val_acc: 0.9844\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.03300 to 0.03189, saving model to best.model\n",
      "0s - loss: 0.0586 - acc: 0.9783 - val_loss: 0.0319 - val_acc: 0.9893\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0525 - acc: 0.9776 - val_loss: 0.0330 - val_acc: 0.9854\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03189 to 0.03043, saving model to best.model\n",
      "0s - loss: 0.0513 - acc: 0.9817 - val_loss: 0.0304 - val_acc: 0.9864\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9808 - val_loss: 0.0339 - val_acc: 0.9844\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.03043 to 0.02785, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9788 - val_loss: 0.0279 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02785 to 0.02767, saving model to best.model\n",
      "0s - loss: 0.0548 - acc: 0.9793 - val_loss: 0.0277 - val_acc: 0.9873\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02767 to 0.02554, saving model to best.model\n",
      "0s - loss: 0.0492 - acc: 0.9815 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0485 - acc: 0.9832 - val_loss: 0.0282 - val_acc: 0.9873\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9834 - val_loss: 0.0266 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9810 - val_loss: 0.0316 - val_acc: 0.9854\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0527 - acc: 0.9788 - val_loss: 0.0272 - val_acc: 0.9873\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02554 to 0.02493, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9834 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9795 - val_loss: 0.0277 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0472 - acc: 0.9808 - val_loss: 0.0260 - val_acc: 0.9903\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0465 - acc: 0.9832 - val_loss: 0.0252 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9839 - val_loss: 0.0265 - val_acc: 0.9893\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.02493 to 0.02248, saving model to best.model\n",
      "0s - loss: 0.0430 - acc: 0.9844 - val_loss: 0.0225 - val_acc: 0.9912\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0527 - acc: 0.9800 - val_loss: 0.0255 - val_acc: 0.9893\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9834 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02248 to 0.02220, saving model to best.model\n",
      "0s - loss: 0.0416 - acc: 0.9827 - val_loss: 0.0222 - val_acc: 0.9912\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9876 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02220 to 0.02165, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9793 - val_loss: 0.0216 - val_acc: 0.9912\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9842 - val_loss: 0.0254 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9834 - val_loss: 0.0221 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02165 to 0.01990, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9810 - val_loss: 0.0199 - val_acc: 0.9912\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9832 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01990 to 0.01975, saving model to best.model\n",
      "0s - loss: 0.0392 - acc: 0.9861 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01975 to 0.01969, saving model to best.model\n",
      "0s - loss: 0.0384 - acc: 0.9851 - val_loss: 0.0197 - val_acc: 0.9942\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01969 to 0.01815, saving model to best.model\n",
      "0s - loss: 0.0399 - acc: 0.9834 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9827 - val_loss: 0.0208 - val_acc: 0.9942\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01815 to 0.01728, saving model to best.model\n",
      "0s - loss: 0.0415 - acc: 0.9851 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9883 - val_loss: 0.0222 - val_acc: 0.9903\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9834 - val_loss: 0.0197 - val_acc: 0.9922\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9837 - val_loss: 0.0235 - val_acc: 0.9883\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9854 - val_loss: 0.0174 - val_acc: 0.9932\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0196 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9859 - val_loss: 0.0184 - val_acc: 0.9942\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01728 to 0.01627, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9861 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01627 to 0.01559, saving model to best.model\n",
      "0s - loss: 0.0374 - acc: 0.9844 - val_loss: 0.0156 - val_acc: 0.9951\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9861 - val_loss: 0.0170 - val_acc: 0.9942\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9866 - val_loss: 0.0168 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9869 - val_loss: 0.0164 - val_acc: 0.9942\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9883 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9883 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01559 to 0.01479, saving model to best.model\n",
      "0s - loss: 0.0304 - acc: 0.9861 - val_loss: 0.0148 - val_acc: 0.9942\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9883 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01479 to 0.01240, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9886 - val_loss: 0.0124 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9869 - val_loss: 0.0148 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9844 - val_loss: 0.0166 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01240 to 0.01212, saving model to best.model\n",
      "0s - loss: 0.0335 - acc: 0.9893 - val_loss: 0.0121 - val_acc: 0.9971\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9890 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01212 to 0.01201, saving model to best.model\n",
      "0s - loss: 0.0252 - acc: 0.9910 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9886 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9854 - val_loss: 0.0234 - val_acc: 0.9864\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9871 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9856 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9854 - val_loss: 0.0133 - val_acc: 0.9951\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9869 - val_loss: 0.0178 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9851 - val_loss: 0.0150 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9883 - val_loss: 0.0147 - val_acc: 0.9951\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0288 - acc: 0.9888 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9883 - val_loss: 0.0144 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9910 - val_loss: 0.0156 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9890 - val_loss: 0.0125 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9893 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9881 - val_loss: 0.0133 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9869 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01201 to 0.01112, saving model to best.model\n",
      "0s - loss: 0.0237 - acc: 0.9903 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9888 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9866 - val_loss: 0.0112 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0258 - acc: 0.9898 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9881 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9898 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9893 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.01112 to 0.01009, saving model to best.model\n",
      "0s - loss: 0.0293 - acc: 0.9886 - val_loss: 0.0101 - val_acc: 0.9961\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.01009 to 0.00908, saving model to best.model\n",
      "0s - loss: 0.0280 - acc: 0.9900 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9883 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9890 - val_loss: 0.0101 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0200 - acc: 0.9917 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0226 - acc: 0.9920 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9893 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00908 to 0.00901, saving model to best.model\n",
      "0s - loss: 0.0221 - acc: 0.9917 - val_loss: 0.0090 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0253 - acc: 0.9893 - val_loss: 0.0091 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0242 - acc: 0.9898 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0218 - acc: 0.9922 - val_loss: 0.0104 - val_acc: 0.9961\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0248 - acc: 0.9912 - val_loss: 0.0096 - val_acc: 0.9961\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9900 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67680, saving model to best.model\n",
      "0s - loss: 0.7992 - acc: 0.5033 - val_loss: 0.6768 - val_acc: 0.5229\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67680 to 0.66242, saving model to best.model\n",
      "0s - loss: 0.7380 - acc: 0.5320 - val_loss: 0.6624 - val_acc: 0.5229\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66242 to 0.61699, saving model to best.model\n",
      "0s - loss: 0.6951 - acc: 0.5698 - val_loss: 0.6170 - val_acc: 0.8014\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61699 to 0.55432, saving model to best.model\n",
      "0s - loss: 0.6519 - acc: 0.6189 - val_loss: 0.5543 - val_acc: 0.7936\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55432 to 0.47633, saving model to best.model\n",
      "0s - loss: 0.5815 - acc: 0.7054 - val_loss: 0.4763 - val_acc: 0.8169\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47633 to 0.41443, saving model to best.model\n",
      "0s - loss: 0.5088 - acc: 0.7714 - val_loss: 0.4144 - val_acc: 0.8413\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41443 to 0.37735, saving model to best.model\n",
      "0s - loss: 0.4659 - acc: 0.7999 - val_loss: 0.3773 - val_acc: 0.8530\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37735 to 0.35756, saving model to best.model\n",
      "0s - loss: 0.4225 - acc: 0.8227 - val_loss: 0.3576 - val_acc: 0.8588\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35756 to 0.33585, saving model to best.model\n",
      "0s - loss: 0.4056 - acc: 0.8315 - val_loss: 0.3359 - val_acc: 0.8724\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33585 to 0.31006, saving model to best.model\n",
      "0s - loss: 0.3853 - acc: 0.8444 - val_loss: 0.3101 - val_acc: 0.8802\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31006 to 0.29189, saving model to best.model\n",
      "0s - loss: 0.3668 - acc: 0.8576 - val_loss: 0.2919 - val_acc: 0.8822\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29189 to 0.28095, saving model to best.model\n",
      "0s - loss: 0.3477 - acc: 0.8675 - val_loss: 0.2809 - val_acc: 0.8919\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28095 to 0.26702, saving model to best.model\n",
      "0s - loss: 0.3340 - acc: 0.8731 - val_loss: 0.2670 - val_acc: 0.8919\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26702 to 0.25706, saving model to best.model\n",
      "0s - loss: 0.3233 - acc: 0.8770 - val_loss: 0.2571 - val_acc: 0.8939\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25706 to 0.24805, saving model to best.model\n",
      "0s - loss: 0.3169 - acc: 0.8812 - val_loss: 0.2480 - val_acc: 0.8968\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.3033 - acc: 0.8858 - val_loss: 0.2744 - val_acc: 0.9056\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24805 to 0.23662, saving model to best.model\n",
      "0s - loss: 0.2898 - acc: 0.8897 - val_loss: 0.2366 - val_acc: 0.9085\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.23662 to 0.23200, saving model to best.model\n",
      "0s - loss: 0.2812 - acc: 0.8985 - val_loss: 0.2320 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.2706 - acc: 0.8994 - val_loss: 0.2325 - val_acc: 0.9153\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23200 to 0.21820, saving model to best.model\n",
      "0s - loss: 0.2713 - acc: 0.9060 - val_loss: 0.2182 - val_acc: 0.9211\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2670 - acc: 0.9043 - val_loss: 0.2351 - val_acc: 0.9133\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21820 to 0.20864, saving model to best.model\n",
      "0s - loss: 0.2692 - acc: 0.9031 - val_loss: 0.2086 - val_acc: 0.9221\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.20864 to 0.20311, saving model to best.model\n",
      "0s - loss: 0.2604 - acc: 0.9114 - val_loss: 0.2031 - val_acc: 0.9241\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2473 - acc: 0.9109 - val_loss: 0.2159 - val_acc: 0.9202\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20311 to 0.19819, saving model to best.model\n",
      "0s - loss: 0.2490 - acc: 0.9055 - val_loss: 0.1982 - val_acc: 0.9250\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.2478 - acc: 0.9131 - val_loss: 0.2043 - val_acc: 0.9241\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19819 to 0.19178, saving model to best.model\n",
      "0s - loss: 0.2418 - acc: 0.9148 - val_loss: 0.1918 - val_acc: 0.9241\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19178 to 0.18845, saving model to best.model\n",
      "0s - loss: 0.2439 - acc: 0.9160 - val_loss: 0.1885 - val_acc: 0.9241\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2358 - acc: 0.9165 - val_loss: 0.1911 - val_acc: 0.9250\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18845 to 0.18631, saving model to best.model\n",
      "0s - loss: 0.2287 - acc: 0.9194 - val_loss: 0.1863 - val_acc: 0.9270\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18631 to 0.18368, saving model to best.model\n",
      "0s - loss: 0.2264 - acc: 0.9206 - val_loss: 0.1837 - val_acc: 0.9270\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18368 to 0.17669, saving model to best.model\n",
      "0s - loss: 0.2214 - acc: 0.9233 - val_loss: 0.1767 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17669 to 0.17444, saving model to best.model\n",
      "0s - loss: 0.2262 - acc: 0.9228 - val_loss: 0.1744 - val_acc: 0.9279\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.2180 - acc: 0.9243 - val_loss: 0.1795 - val_acc: 0.9279\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17444 to 0.16751, saving model to best.model\n",
      "0s - loss: 0.2181 - acc: 0.9199 - val_loss: 0.1675 - val_acc: 0.9299\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2137 - acc: 0.9235 - val_loss: 0.1684 - val_acc: 0.9289\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16751 to 0.16317, saving model to best.model\n",
      "0s - loss: 0.2044 - acc: 0.9291 - val_loss: 0.1632 - val_acc: 0.9279\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16317 to 0.15672, saving model to best.model\n",
      "0s - loss: 0.1989 - acc: 0.9231 - val_loss: 0.1567 - val_acc: 0.9328\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.2020 - acc: 0.9257 - val_loss: 0.1908 - val_acc: 0.9250\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15672 to 0.15123, saving model to best.model\n",
      "0s - loss: 0.2119 - acc: 0.9228 - val_loss: 0.1512 - val_acc: 0.9445\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9272 - val_loss: 0.1570 - val_acc: 0.9299\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9301 - val_loss: 0.1524 - val_acc: 0.9309\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15123 to 0.14396, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9296 - val_loss: 0.1440 - val_acc: 0.9357\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14396 to 0.14128, saving model to best.model\n",
      "0s - loss: 0.1822 - acc: 0.9326 - val_loss: 0.1413 - val_acc: 0.9357\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14128 to 0.14111, saving model to best.model\n",
      "0s - loss: 0.1767 - acc: 0.9318 - val_loss: 0.1411 - val_acc: 0.9318\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14111 to 0.13861, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9316 - val_loss: 0.1386 - val_acc: 0.9309\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13861 to 0.13265, saving model to best.model\n",
      "0s - loss: 0.1756 - acc: 0.9333 - val_loss: 0.1326 - val_acc: 0.9396\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13265 to 0.12956, saving model to best.model\n",
      "0s - loss: 0.1691 - acc: 0.9357 - val_loss: 0.1296 - val_acc: 0.9387\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12956 to 0.12331, saving model to best.model\n",
      "0s - loss: 0.1709 - acc: 0.9340 - val_loss: 0.1233 - val_acc: 0.9455\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12331 to 0.12166, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9333 - val_loss: 0.1217 - val_acc: 0.9455\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1718 - acc: 0.9318 - val_loss: 0.1218 - val_acc: 0.9445\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12166 to 0.12147, saving model to best.model\n",
      "0s - loss: 0.1569 - acc: 0.9425 - val_loss: 0.1215 - val_acc: 0.9445\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.12147 to 0.11267, saving model to best.model\n",
      "0s - loss: 0.1523 - acc: 0.9440 - val_loss: 0.1127 - val_acc: 0.9552\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11267 to 0.11080, saving model to best.model\n",
      "0s - loss: 0.1515 - acc: 0.9425 - val_loss: 0.1108 - val_acc: 0.9562\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.11080 to 0.10848, saving model to best.model\n",
      "0s - loss: 0.1484 - acc: 0.9479 - val_loss: 0.1085 - val_acc: 0.9591\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1521 - acc: 0.9421 - val_loss: 0.1093 - val_acc: 0.9562\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1449 - acc: 0.9484 - val_loss: 0.1129 - val_acc: 0.9494\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10848 to 0.09921, saving model to best.model\n",
      "0s - loss: 0.1481 - acc: 0.9442 - val_loss: 0.0992 - val_acc: 0.9698\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1479 - acc: 0.9425 - val_loss: 0.1099 - val_acc: 0.9552\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1484 - acc: 0.9430 - val_loss: 0.1097 - val_acc: 0.9474\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09921 to 0.09718, saving model to best.model\n",
      "0s - loss: 0.1422 - acc: 0.9445 - val_loss: 0.0972 - val_acc: 0.9649\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1378 - acc: 0.9462 - val_loss: 0.0983 - val_acc: 0.9620\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1238 - acc: 0.9525 - val_loss: 0.1010 - val_acc: 0.9581\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.09718 to 0.09186, saving model to best.model\n",
      "0s - loss: 0.1339 - acc: 0.9496 - val_loss: 0.0919 - val_acc: 0.9679\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1254 - acc: 0.9528 - val_loss: 0.0925 - val_acc: 0.9679\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1210 - acc: 0.9528 - val_loss: 0.0924 - val_acc: 0.9659\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09186 to 0.08635, saving model to best.model\n",
      "0s - loss: 0.1173 - acc: 0.9567 - val_loss: 0.0864 - val_acc: 0.9727\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1218 - acc: 0.9547 - val_loss: 0.0891 - val_acc: 0.9698\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.08635 to 0.08420, saving model to best.model\n",
      "0s - loss: 0.1190 - acc: 0.9540 - val_loss: 0.0842 - val_acc: 0.9747\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08420 to 0.07947, saving model to best.model\n",
      "0s - loss: 0.1212 - acc: 0.9518 - val_loss: 0.0795 - val_acc: 0.9737\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1164 - acc: 0.9547 - val_loss: 0.0822 - val_acc: 0.9786\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07947 to 0.07624, saving model to best.model\n",
      "0s - loss: 0.1092 - acc: 0.9584 - val_loss: 0.0762 - val_acc: 0.9747\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1173 - acc: 0.9567 - val_loss: 0.0801 - val_acc: 0.9786\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1065 - acc: 0.9606 - val_loss: 0.0769 - val_acc: 0.9776\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.0996 - acc: 0.9601 - val_loss: 0.0835 - val_acc: 0.9766\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07624 to 0.07407, saving model to best.model\n",
      "0s - loss: 0.1076 - acc: 0.9586 - val_loss: 0.0741 - val_acc: 0.9796\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07407 to 0.07030, saving model to best.model\n",
      "0s - loss: 0.1026 - acc: 0.9613 - val_loss: 0.0703 - val_acc: 0.9757\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1080 - acc: 0.9593 - val_loss: 0.0858 - val_acc: 0.9727\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07030 to 0.06821, saving model to best.model\n",
      "0s - loss: 0.0996 - acc: 0.9623 - val_loss: 0.0682 - val_acc: 0.9766\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1041 - acc: 0.9615 - val_loss: 0.0708 - val_acc: 0.9796\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0988 - acc: 0.9601 - val_loss: 0.0714 - val_acc: 0.9796\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06821 to 0.06735, saving model to best.model\n",
      "0s - loss: 0.1000 - acc: 0.9642 - val_loss: 0.0674 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0996 - acc: 0.9645 - val_loss: 0.0674 - val_acc: 0.9796\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06735 to 0.06424, saving model to best.model\n",
      "0s - loss: 0.1041 - acc: 0.9615 - val_loss: 0.0642 - val_acc: 0.9796\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06424 to 0.06165, saving model to best.model\n",
      "0s - loss: 0.0907 - acc: 0.9681 - val_loss: 0.0617 - val_acc: 0.9796\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0889 - acc: 0.9679 - val_loss: 0.0645 - val_acc: 0.9796\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.06165 to 0.05890, saving model to best.model\n",
      "0s - loss: 0.0871 - acc: 0.9659 - val_loss: 0.0589 - val_acc: 0.9805\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0924 - acc: 0.9669 - val_loss: 0.0653 - val_acc: 0.9796\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05890 to 0.05807, saving model to best.model\n",
      "0s - loss: 0.0880 - acc: 0.9657 - val_loss: 0.0581 - val_acc: 0.9805\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05807 to 0.05764, saving model to best.model\n",
      "0s - loss: 0.0847 - acc: 0.9693 - val_loss: 0.0576 - val_acc: 0.9805\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05764 to 0.05705, saving model to best.model\n",
      "0s - loss: 0.0885 - acc: 0.9688 - val_loss: 0.0571 - val_acc: 0.9805\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05705 to 0.05391, saving model to best.model\n",
      "0s - loss: 0.0800 - acc: 0.9688 - val_loss: 0.0539 - val_acc: 0.9825\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0893 - acc: 0.9645 - val_loss: 0.0654 - val_acc: 0.9815\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0811 - acc: 0.9722 - val_loss: 0.0650 - val_acc: 0.9805\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.05391 to 0.05068, saving model to best.model\n",
      "0s - loss: 0.0863 - acc: 0.9674 - val_loss: 0.0507 - val_acc: 0.9815\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0723 - acc: 0.9732 - val_loss: 0.0569 - val_acc: 0.9834\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.05068 to 0.04916, saving model to best.model\n",
      "0s - loss: 0.0787 - acc: 0.9718 - val_loss: 0.0492 - val_acc: 0.9834\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0785 - acc: 0.9722 - val_loss: 0.0495 - val_acc: 0.9844\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0748 - acc: 0.9718 - val_loss: 0.0502 - val_acc: 0.9844\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0696 - acc: 0.9766 - val_loss: 0.0497 - val_acc: 0.9834\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0807 - acc: 0.9708 - val_loss: 0.0585 - val_acc: 0.9815\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04916 to 0.04820, saving model to best.model\n",
      "0s - loss: 0.0763 - acc: 0.9698 - val_loss: 0.0482 - val_acc: 0.9825\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0702 - acc: 0.9742 - val_loss: 0.0549 - val_acc: 0.9815\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.04820 to 0.04551, saving model to best.model\n",
      "0s - loss: 0.0768 - acc: 0.9744 - val_loss: 0.0455 - val_acc: 0.9834\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9769 - val_loss: 0.0474 - val_acc: 0.9844\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.04551 to 0.04548, saving model to best.model\n",
      "0s - loss: 0.0692 - acc: 0.9749 - val_loss: 0.0455 - val_acc: 0.9844\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0677 - acc: 0.9769 - val_loss: 0.0474 - val_acc: 0.9844\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.04548 to 0.04388, saving model to best.model\n",
      "0s - loss: 0.0655 - acc: 0.9766 - val_loss: 0.0439 - val_acc: 0.9834\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9788 - val_loss: 0.0482 - val_acc: 0.9844\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.04388 to 0.04352, saving model to best.model\n",
      "0s - loss: 0.0702 - acc: 0.9752 - val_loss: 0.0435 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0670 - acc: 0.9757 - val_loss: 0.0472 - val_acc: 0.9834\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.04352 to 0.04340, saving model to best.model\n",
      "0s - loss: 0.0614 - acc: 0.9786 - val_loss: 0.0434 - val_acc: 0.9834\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.04340 to 0.04257, saving model to best.model\n",
      "0s - loss: 0.0641 - acc: 0.9769 - val_loss: 0.0426 - val_acc: 0.9844\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.04257 to 0.04251, saving model to best.model\n",
      "0s - loss: 0.0648 - acc: 0.9744 - val_loss: 0.0425 - val_acc: 0.9844\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9752 - val_loss: 0.0484 - val_acc: 0.9844\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.04251 to 0.04016, saving model to best.model\n",
      "0s - loss: 0.0634 - acc: 0.9776 - val_loss: 0.0402 - val_acc: 0.9834\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0697 - acc: 0.9754 - val_loss: 0.0426 - val_acc: 0.9844\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0563 - acc: 0.9793 - val_loss: 0.0416 - val_acc: 0.9844\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.04016 to 0.03998, saving model to best.model\n",
      "0s - loss: 0.0583 - acc: 0.9795 - val_loss: 0.0400 - val_acc: 0.9854\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0626 - acc: 0.9766 - val_loss: 0.0432 - val_acc: 0.9854\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9786 - val_loss: 0.0426 - val_acc: 0.9844\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.03998 to 0.03864, saving model to best.model\n",
      "0s - loss: 0.0562 - acc: 0.9820 - val_loss: 0.0386 - val_acc: 0.9854\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.03864 to 0.03652, saving model to best.model\n",
      "0s - loss: 0.0524 - acc: 0.9810 - val_loss: 0.0365 - val_acc: 0.9844\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0600 - acc: 0.9778 - val_loss: 0.0460 - val_acc: 0.9844\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03652 to 0.03551, saving model to best.model\n",
      "0s - loss: 0.0607 - acc: 0.9788 - val_loss: 0.0355 - val_acc: 0.9854\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.03551 to 0.03477, saving model to best.model\n",
      "0s - loss: 0.0530 - acc: 0.9778 - val_loss: 0.0348 - val_acc: 0.9844\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0636 - acc: 0.9749 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.03477 to 0.03346, saving model to best.model\n",
      "0s - loss: 0.0520 - acc: 0.9810 - val_loss: 0.0335 - val_acc: 0.9844\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0542 - acc: 0.9805 - val_loss: 0.0406 - val_acc: 0.9844\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0535 - acc: 0.9800 - val_loss: 0.0358 - val_acc: 0.9854\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9817 - val_loss: 0.0349 - val_acc: 0.9854\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0563 - acc: 0.9793 - val_loss: 0.0398 - val_acc: 0.9844\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0510 - acc: 0.9800 - val_loss: 0.0383 - val_acc: 0.9844\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.03346 to 0.03196, saving model to best.model\n",
      "0s - loss: 0.0548 - acc: 0.9825 - val_loss: 0.0320 - val_acc: 0.9844\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0529 - acc: 0.9810 - val_loss: 0.0360 - val_acc: 0.9854\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9842 - val_loss: 0.0335 - val_acc: 0.9854\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9808 - val_loss: 0.0382 - val_acc: 0.9854\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9844 - val_loss: 0.0343 - val_acc: 0.9854\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9813 - val_loss: 0.0352 - val_acc: 0.9854\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0456 - acc: 0.9844 - val_loss: 0.0330 - val_acc: 0.9854\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0450 - acc: 0.9832 - val_loss: 0.0334 - val_acc: 0.9854\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9825 - val_loss: 0.0338 - val_acc: 0.9854\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0492 - acc: 0.9837 - val_loss: 0.0334 - val_acc: 0.9854\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9834 - val_loss: 0.0325 - val_acc: 0.9854\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.03196 to 0.03145, saving model to best.model\n",
      "0s - loss: 0.0462 - acc: 0.9834 - val_loss: 0.0315 - val_acc: 0.9844\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.03145 to 0.03127, saving model to best.model\n",
      "0s - loss: 0.0422 - acc: 0.9825 - val_loss: 0.0313 - val_acc: 0.9854\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0433 - acc: 0.9805 - val_loss: 0.0333 - val_acc: 0.9854\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.03127 to 0.02998, saving model to best.model\n",
      "0s - loss: 0.0458 - acc: 0.9813 - val_loss: 0.0300 - val_acc: 0.9854\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9822 - val_loss: 0.0331 - val_acc: 0.9854\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.02998 to 0.02972, saving model to best.model\n",
      "0s - loss: 0.0409 - acc: 0.9844 - val_loss: 0.0297 - val_acc: 0.9873\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9834 - val_loss: 0.0331 - val_acc: 0.9854\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9851 - val_loss: 0.0307 - val_acc: 0.9854\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0419 - acc: 0.9849 - val_loss: 0.0307 - val_acc: 0.9854\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02972 to 0.02930, saving model to best.model\n",
      "0s - loss: 0.0408 - acc: 0.9866 - val_loss: 0.0293 - val_acc: 0.9873\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9820 - val_loss: 0.0320 - val_acc: 0.9854\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.02930 to 0.02840, saving model to best.model\n",
      "0s - loss: 0.0393 - acc: 0.9849 - val_loss: 0.0284 - val_acc: 0.9854\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9864 - val_loss: 0.0288 - val_acc: 0.9854\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02840 to 0.02737, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9832 - val_loss: 0.0274 - val_acc: 0.9873\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9856 - val_loss: 0.0306 - val_acc: 0.9854\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.02737 to 0.02691, saving model to best.model\n",
      "0s - loss: 0.0375 - acc: 0.9859 - val_loss: 0.0269 - val_acc: 0.9873\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9864 - val_loss: 0.0274 - val_acc: 0.9873\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.02691 to 0.02575, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9866 - val_loss: 0.0258 - val_acc: 0.9873\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9871 - val_loss: 0.0278 - val_acc: 0.9854\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9825 - val_loss: 0.0288 - val_acc: 0.9864\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.02575 to 0.02419, saving model to best.model\n",
      "0s - loss: 0.0391 - acc: 0.9844 - val_loss: 0.0242 - val_acc: 0.9873\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9851 - val_loss: 0.0290 - val_acc: 0.9854\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9864 - val_loss: 0.0282 - val_acc: 0.9854\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0262 - val_acc: 0.9873\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9866 - val_loss: 0.0283 - val_acc: 0.9864\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.02419 to 0.02260, saving model to best.model\n",
      "0s - loss: 0.0296 - acc: 0.9890 - val_loss: 0.0226 - val_acc: 0.9873\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9869 - val_loss: 0.0269 - val_acc: 0.9854\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9861 - val_loss: 0.0249 - val_acc: 0.9873\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9893 - val_loss: 0.0242 - val_acc: 0.9864\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9893 - val_loss: 0.0275 - val_acc: 0.9864\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.02260 to 0.02152, saving model to best.model\n",
      "0s - loss: 0.0324 - acc: 0.9878 - val_loss: 0.0215 - val_acc: 0.9883\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9878 - val_loss: 0.0276 - val_acc: 0.9864\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0278 - acc: 0.9898 - val_loss: 0.0238 - val_acc: 0.9873\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9890 - val_loss: 0.0237 - val_acc: 0.9883\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9886 - val_loss: 0.0232 - val_acc: 0.9883\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9854 - val_loss: 0.0227 - val_acc: 0.9883\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9873 - val_loss: 0.0229 - val_acc: 0.9883\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9893 - val_loss: 0.0230 - val_acc: 0.9883\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.02152 to 0.01949, saving model to best.model\n",
      "0s - loss: 0.0321 - acc: 0.9878 - val_loss: 0.0195 - val_acc: 0.9883\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0278 - acc: 0.9895 - val_loss: 0.0218 - val_acc: 0.9883\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9876 - val_loss: 0.0217 - val_acc: 0.9883\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9883 - val_loss: 0.0200 - val_acc: 0.9883\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0367 - acc: 0.9859 - val_loss: 0.0218 - val_acc: 0.9883\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.01949 to 0.01806, saving model to best.model\n",
      "0s - loss: 0.0359 - acc: 0.9859 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9883 - val_loss: 0.0210 - val_acc: 0.9883\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9890 - val_loss: 0.0202 - val_acc: 0.9883\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9900 - val_loss: 0.0194 - val_acc: 0.9883\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9898 - val_loss: 0.0224 - val_acc: 0.9883\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9890 - val_loss: 0.0182 - val_acc: 0.9932\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9898 - val_loss: 0.0210 - val_acc: 0.9883\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9883 - val_loss: 0.0209 - val_acc: 0.9883\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9878 - val_loss: 0.0196 - val_acc: 0.9883\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9866 - val_loss: 0.0188 - val_acc: 0.9883\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9900 - val_loss: 0.0188 - val_acc: 0.9883\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9886 - val_loss: 0.0186 - val_acc: 0.9883\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9900 - val_loss: 0.0228 - val_acc: 0.9883\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66438, saving model to best.model\n",
      "0s - loss: 0.7675 - acc: 0.5228 - val_loss: 0.6644 - val_acc: 0.7128\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.66438 to 0.63506, saving model to best.model\n",
      "0s - loss: 0.7114 - acc: 0.5476 - val_loss: 0.6351 - val_acc: 0.7196\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63506 to 0.57771, saving model to best.model\n",
      "0s - loss: 0.6665 - acc: 0.5980 - val_loss: 0.5777 - val_acc: 0.7760\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.57771 to 0.50798, saving model to best.model\n",
      "0s - loss: 0.5941 - acc: 0.6881 - val_loss: 0.5080 - val_acc: 0.7877\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50798 to 0.45154, saving model to best.model\n",
      "0s - loss: 0.5199 - acc: 0.7519 - val_loss: 0.4515 - val_acc: 0.8111\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.45154 to 0.41058, saving model to best.model\n",
      "0s - loss: 0.4663 - acc: 0.7891 - val_loss: 0.4106 - val_acc: 0.8277\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41058 to 0.38285, saving model to best.model\n",
      "0s - loss: 0.4263 - acc: 0.8188 - val_loss: 0.3828 - val_acc: 0.8530\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38285 to 0.36312, saving model to best.model\n",
      "0s - loss: 0.3920 - acc: 0.8439 - val_loss: 0.3631 - val_acc: 0.8588\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36312 to 0.34488, saving model to best.model\n",
      "0s - loss: 0.3797 - acc: 0.8473 - val_loss: 0.3449 - val_acc: 0.8647\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34488 to 0.33360, saving model to best.model\n",
      "0s - loss: 0.3541 - acc: 0.8598 - val_loss: 0.3336 - val_acc: 0.8685\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33360 to 0.32239, saving model to best.model\n",
      "0s - loss: 0.3420 - acc: 0.8697 - val_loss: 0.3224 - val_acc: 0.8763\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.32239 to 0.32085, saving model to best.model\n",
      "0s - loss: 0.3318 - acc: 0.8675 - val_loss: 0.3209 - val_acc: 0.8773\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.32085 to 0.30029, saving model to best.model\n",
      "0s - loss: 0.3187 - acc: 0.8736 - val_loss: 0.3003 - val_acc: 0.8832\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.30029 to 0.28729, saving model to best.model\n",
      "0s - loss: 0.3118 - acc: 0.8800 - val_loss: 0.2873 - val_acc: 0.8870\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.3015 - acc: 0.8839 - val_loss: 0.2944 - val_acc: 0.8919\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.28729 to 0.28506, saving model to best.model\n",
      "0s - loss: 0.2956 - acc: 0.8875 - val_loss: 0.2851 - val_acc: 0.8958\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.28506 to 0.27010, saving model to best.model\n",
      "0s - loss: 0.2879 - acc: 0.8941 - val_loss: 0.2701 - val_acc: 0.9017\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.27010 to 0.26653, saving model to best.model\n",
      "0s - loss: 0.2745 - acc: 0.9002 - val_loss: 0.2665 - val_acc: 0.9017\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.26653 to 0.25918, saving model to best.model\n",
      "0s - loss: 0.2669 - acc: 0.9031 - val_loss: 0.2592 - val_acc: 0.9065\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2630 - acc: 0.9026 - val_loss: 0.2602 - val_acc: 0.9026\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2472 - acc: 0.9153 - val_loss: 0.2600 - val_acc: 0.9017\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.25918 to 0.24809, saving model to best.model\n",
      "0s - loss: 0.2526 - acc: 0.9109 - val_loss: 0.2481 - val_acc: 0.9094\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.24809 to 0.24155, saving model to best.model\n",
      "0s - loss: 0.2490 - acc: 0.9097 - val_loss: 0.2416 - val_acc: 0.9094\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.24155 to 0.24082, saving model to best.model\n",
      "0s - loss: 0.2363 - acc: 0.9226 - val_loss: 0.2408 - val_acc: 0.9104\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2390 - acc: 0.9194 - val_loss: 0.2417 - val_acc: 0.9104\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.24082 to 0.23671, saving model to best.model\n",
      "0s - loss: 0.2300 - acc: 0.9196 - val_loss: 0.2367 - val_acc: 0.9094\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.23671 to 0.22729, saving model to best.model\n",
      "0s - loss: 0.2297 - acc: 0.9221 - val_loss: 0.2273 - val_acc: 0.9124\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2202 - acc: 0.9223 - val_loss: 0.2284 - val_acc: 0.9094\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2255 - acc: 0.9194 - val_loss: 0.2298 - val_acc: 0.9124\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.22729 to 0.22039, saving model to best.model\n",
      "0s - loss: 0.2122 - acc: 0.9240 - val_loss: 0.2204 - val_acc: 0.9124\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.22039 to 0.21784, saving model to best.model\n",
      "0s - loss: 0.2101 - acc: 0.9284 - val_loss: 0.2178 - val_acc: 0.9133\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.21784 to 0.20821, saving model to best.model\n",
      "0s - loss: 0.2107 - acc: 0.9228 - val_loss: 0.2082 - val_acc: 0.9153\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2101 - acc: 0.9252 - val_loss: 0.2136 - val_acc: 0.9163\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.20821 to 0.20732, saving model to best.model\n",
      "0s - loss: 0.2027 - acc: 0.9284 - val_loss: 0.2073 - val_acc: 0.9153\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.20732 to 0.19607, saving model to best.model\n",
      "0s - loss: 0.2045 - acc: 0.9255 - val_loss: 0.1961 - val_acc: 0.9153\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.19607 to 0.19186, saving model to best.model\n",
      "0s - loss: 0.2018 - acc: 0.9262 - val_loss: 0.1919 - val_acc: 0.9163\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.1968 - acc: 0.9313 - val_loss: 0.1974 - val_acc: 0.9172\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.19186 to 0.18381, saving model to best.model\n",
      "0s - loss: 0.1908 - acc: 0.9357 - val_loss: 0.1838 - val_acc: 0.9221\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.1832 - acc: 0.9377 - val_loss: 0.1869 - val_acc: 0.9172\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.18381 to 0.17977, saving model to best.model\n",
      "0s - loss: 0.1847 - acc: 0.9347 - val_loss: 0.1798 - val_acc: 0.9202\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17977 to 0.17253, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9372 - val_loss: 0.1725 - val_acc: 0.9289\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1917 - acc: 0.9333 - val_loss: 0.1797 - val_acc: 0.9192\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17253 to 0.17145, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9330 - val_loss: 0.1714 - val_acc: 0.9241\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.17145 to 0.16507, saving model to best.model\n",
      "0s - loss: 0.1757 - acc: 0.9425 - val_loss: 0.1651 - val_acc: 0.9289\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16507 to 0.15929, saving model to best.model\n",
      "0s - loss: 0.1686 - acc: 0.9425 - val_loss: 0.1593 - val_acc: 0.9357\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1740 - acc: 0.9425 - val_loss: 0.1631 - val_acc: 0.9260\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15929 to 0.15446, saving model to best.model\n",
      "0s - loss: 0.1622 - acc: 0.9445 - val_loss: 0.1545 - val_acc: 0.9348\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15446 to 0.15322, saving model to best.model\n",
      "0s - loss: 0.1686 - acc: 0.9423 - val_loss: 0.1532 - val_acc: 0.9357\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.15322 to 0.14565, saving model to best.model\n",
      "0s - loss: 0.1655 - acc: 0.9428 - val_loss: 0.1456 - val_acc: 0.9435\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1602 - acc: 0.9455 - val_loss: 0.1477 - val_acc: 0.9367\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1586 - acc: 0.9484 - val_loss: 0.1469 - val_acc: 0.9367\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.14565 to 0.13942, saving model to best.model\n",
      "0s - loss: 0.1492 - acc: 0.9469 - val_loss: 0.1394 - val_acc: 0.9474\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1562 - acc: 0.9462 - val_loss: 0.1505 - val_acc: 0.9338\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13942 to 0.13394, saving model to best.model\n",
      "0s - loss: 0.1462 - acc: 0.9513 - val_loss: 0.1339 - val_acc: 0.9455\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13394 to 0.13184, saving model to best.model\n",
      "0s - loss: 0.1428 - acc: 0.9447 - val_loss: 0.1318 - val_acc: 0.9464\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13184 to 0.12265, saving model to best.model\n",
      "0s - loss: 0.1393 - acc: 0.9530 - val_loss: 0.1226 - val_acc: 0.9513\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1357 - acc: 0.9525 - val_loss: 0.1397 - val_acc: 0.9426\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12265 to 0.11895, saving model to best.model\n",
      "0s - loss: 0.1352 - acc: 0.9513 - val_loss: 0.1190 - val_acc: 0.9523\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1298 - acc: 0.9530 - val_loss: 0.1221 - val_acc: 0.9503\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1272 - acc: 0.9547 - val_loss: 0.1277 - val_acc: 0.9503\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11895 to 0.11188, saving model to best.model\n",
      "0s - loss: 0.1249 - acc: 0.9542 - val_loss: 0.1119 - val_acc: 0.9542\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1268 - acc: 0.9535 - val_loss: 0.1122 - val_acc: 0.9542\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11188 to 0.10741, saving model to best.model\n",
      "0s - loss: 0.1196 - acc: 0.9562 - val_loss: 0.1074 - val_acc: 0.9581\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10741 to 0.10529, saving model to best.model\n",
      "0s - loss: 0.1206 - acc: 0.9545 - val_loss: 0.1053 - val_acc: 0.9601\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10529 to 0.10196, saving model to best.model\n",
      "0s - loss: 0.1213 - acc: 0.9579 - val_loss: 0.1020 - val_acc: 0.9591\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1194 - acc: 0.9554 - val_loss: 0.1063 - val_acc: 0.9630\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.10196 to 0.09848, saving model to best.model\n",
      "0s - loss: 0.1138 - acc: 0.9574 - val_loss: 0.0985 - val_acc: 0.9611\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1110 - acc: 0.9598 - val_loss: 0.1018 - val_acc: 0.9669\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09848 to 0.09202, saving model to best.model\n",
      "0s - loss: 0.1108 - acc: 0.9584 - val_loss: 0.0920 - val_acc: 0.9611\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1120 - acc: 0.9589 - val_loss: 0.0948 - val_acc: 0.9688\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1107 - acc: 0.9608 - val_loss: 0.0930 - val_acc: 0.9688\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.09202 to 0.08731, saving model to best.model\n",
      "0s - loss: 0.1122 - acc: 0.9562 - val_loss: 0.0873 - val_acc: 0.9669\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1031 - acc: 0.9608 - val_loss: 0.0968 - val_acc: 0.9669\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08731 to 0.08503, saving model to best.model\n",
      "0s - loss: 0.0990 - acc: 0.9652 - val_loss: 0.0850 - val_acc: 0.9640\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08503 to 0.08108, saving model to best.model\n",
      "0s - loss: 0.1063 - acc: 0.9596 - val_loss: 0.0811 - val_acc: 0.9640\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1038 - acc: 0.9618 - val_loss: 0.0861 - val_acc: 0.9698\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.0999 - acc: 0.9640 - val_loss: 0.0847 - val_acc: 0.9688\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.08108 to 0.07695, saving model to best.model\n",
      "0s - loss: 0.0954 - acc: 0.9662 - val_loss: 0.0770 - val_acc: 0.9620\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.0934 - acc: 0.9654 - val_loss: 0.0820 - val_acc: 0.9727\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0983 - acc: 0.9645 - val_loss: 0.0840 - val_acc: 0.9737\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07695 to 0.07333, saving model to best.model\n",
      "0s - loss: 0.0896 - acc: 0.9657 - val_loss: 0.0733 - val_acc: 0.9727\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0879 - acc: 0.9664 - val_loss: 0.0764 - val_acc: 0.9718\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0895 - acc: 0.9657 - val_loss: 0.0902 - val_acc: 0.9727\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.07333 to 0.07329, saving model to best.model\n",
      "0s - loss: 0.0837 - acc: 0.9703 - val_loss: 0.0733 - val_acc: 0.9659\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.07329 to 0.07301, saving model to best.model\n",
      "0s - loss: 0.0796 - acc: 0.9718 - val_loss: 0.0730 - val_acc: 0.9718\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0856 - acc: 0.9701 - val_loss: 0.0788 - val_acc: 0.9747\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.07301 to 0.07027, saving model to best.model\n",
      "0s - loss: 0.0830 - acc: 0.9720 - val_loss: 0.0703 - val_acc: 0.9747\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.07027 to 0.06005, saving model to best.model\n",
      "0s - loss: 0.0755 - acc: 0.9710 - val_loss: 0.0600 - val_acc: 0.9727\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0841 - acc: 0.9691 - val_loss: 0.0629 - val_acc: 0.9757\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.06005 to 0.06002, saving model to best.model\n",
      "0s - loss: 0.0725 - acc: 0.9727 - val_loss: 0.0600 - val_acc: 0.9727\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0817 - acc: 0.9701 - val_loss: 0.0691 - val_acc: 0.9757\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.06002 to 0.05872, saving model to best.model\n",
      "0s - loss: 0.0751 - acc: 0.9715 - val_loss: 0.0587 - val_acc: 0.9747\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0818 - acc: 0.9696 - val_loss: 0.0628 - val_acc: 0.9766\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05872 to 0.05705, saving model to best.model\n",
      "0s - loss: 0.0834 - acc: 0.9710 - val_loss: 0.0571 - val_acc: 0.9747\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0815 - acc: 0.9713 - val_loss: 0.0746 - val_acc: 0.9727\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.05705 to 0.05595, saving model to best.model\n",
      "0s - loss: 0.0731 - acc: 0.9722 - val_loss: 0.0559 - val_acc: 0.9737\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0653 - acc: 0.9766 - val_loss: 0.0570 - val_acc: 0.9776\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0732 - acc: 0.9739 - val_loss: 0.0584 - val_acc: 0.9766\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.05595 to 0.05374, saving model to best.model\n",
      "0s - loss: 0.0641 - acc: 0.9761 - val_loss: 0.0537 - val_acc: 0.9766\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.05374 to 0.04751, saving model to best.model\n",
      "0s - loss: 0.0642 - acc: 0.9776 - val_loss: 0.0475 - val_acc: 0.9776\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0707 - acc: 0.9727 - val_loss: 0.0602 - val_acc: 0.9766\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0693 - acc: 0.9754 - val_loss: 0.0565 - val_acc: 0.9776\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0641 - acc: 0.9771 - val_loss: 0.0555 - val_acc: 0.9766\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0723 - acc: 0.9718 - val_loss: 0.0494 - val_acc: 0.9776\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0608 - acc: 0.9786 - val_loss: 0.0484 - val_acc: 0.9786\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0627 - acc: 0.9766 - val_loss: 0.0557 - val_acc: 0.9766\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.04751 to 0.04560, saving model to best.model\n",
      "0s - loss: 0.0681 - acc: 0.9778 - val_loss: 0.0456 - val_acc: 0.9786\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0634 - acc: 0.9798 - val_loss: 0.0459 - val_acc: 0.9776\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.04560 to 0.04520, saving model to best.model\n",
      "0s - loss: 0.0613 - acc: 0.9761 - val_loss: 0.0452 - val_acc: 0.9776\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.04520 to 0.04234, saving model to best.model\n",
      "0s - loss: 0.0648 - acc: 0.9776 - val_loss: 0.0423 - val_acc: 0.9805\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0652 - acc: 0.9744 - val_loss: 0.0483 - val_acc: 0.9786\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0621 - acc: 0.9778 - val_loss: 0.0431 - val_acc: 0.9786\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.04234 to 0.04062, saving model to best.model\n",
      "0s - loss: 0.0645 - acc: 0.9737 - val_loss: 0.0406 - val_acc: 0.9796\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0561 - acc: 0.9798 - val_loss: 0.0526 - val_acc: 0.9776\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0646 - acc: 0.9776 - val_loss: 0.0442 - val_acc: 0.9796\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0599 - acc: 0.9764 - val_loss: 0.0502 - val_acc: 0.9786\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0570 - acc: 0.9786 - val_loss: 0.0441 - val_acc: 0.9786\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0591 - acc: 0.9764 - val_loss: 0.0425 - val_acc: 0.9786\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.04062 to 0.03995, saving model to best.model\n",
      "0s - loss: 0.0596 - acc: 0.9791 - val_loss: 0.0400 - val_acc: 0.9786\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.03995 to 0.03922, saving model to best.model\n",
      "0s - loss: 0.0554 - acc: 0.9800 - val_loss: 0.0392 - val_acc: 0.9796\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.03922 to 0.03844, saving model to best.model\n",
      "0s - loss: 0.0507 - acc: 0.9800 - val_loss: 0.0384 - val_acc: 0.9796\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.03844 to 0.03583, saving model to best.model\n",
      "0s - loss: 0.0530 - acc: 0.9805 - val_loss: 0.0358 - val_acc: 0.9815\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.03583 to 0.03332, saving model to best.model\n",
      "0s - loss: 0.0517 - acc: 0.9793 - val_loss: 0.0333 - val_acc: 0.9815\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0586 - acc: 0.9800 - val_loss: 0.0445 - val_acc: 0.9786\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0710 - acc: 0.9749 - val_loss: 0.0392 - val_acc: 0.9825\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0575 - acc: 0.9778 - val_loss: 0.0467 - val_acc: 0.9776\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0542 - acc: 0.9793 - val_loss: 0.0365 - val_acc: 0.9825\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0490 - acc: 0.9822 - val_loss: 0.0383 - val_acc: 0.9796\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0498 - acc: 0.9822 - val_loss: 0.0371 - val_acc: 0.9796\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0498 - acc: 0.9834 - val_loss: 0.0365 - val_acc: 0.9815\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9808 - val_loss: 0.0378 - val_acc: 0.9786\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0549 - acc: 0.9800 - val_loss: 0.0342 - val_acc: 0.9805\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9822 - val_loss: 0.0359 - val_acc: 0.9796\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.03332 to 0.03271, saving model to best.model\n",
      "0s - loss: 0.0481 - acc: 0.9825 - val_loss: 0.0327 - val_acc: 0.9805\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.03271 to 0.03171, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9832 - val_loss: 0.0317 - val_acc: 0.9825\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9810 - val_loss: 0.0365 - val_acc: 0.9825\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.03171 to 0.02992, saving model to best.model\n",
      "0s - loss: 0.0515 - acc: 0.9822 - val_loss: 0.0299 - val_acc: 0.9815\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02992 to 0.02873, saving model to best.model\n",
      "0s - loss: 0.0433 - acc: 0.9842 - val_loss: 0.0287 - val_acc: 0.9844\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9837 - val_loss: 0.0305 - val_acc: 0.9815\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9795 - val_loss: 0.0317 - val_acc: 0.9815\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02873 to 0.02606, saving model to best.model\n",
      "0s - loss: 0.0435 - acc: 0.9834 - val_loss: 0.0261 - val_acc: 0.9864\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0476 - acc: 0.9817 - val_loss: 0.0294 - val_acc: 0.9844\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02606 to 0.02378, saving model to best.model\n",
      "0s - loss: 0.0499 - acc: 0.9837 - val_loss: 0.0238 - val_acc: 0.9873\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9820 - val_loss: 0.0267 - val_acc: 0.9854\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0419 - acc: 0.9851 - val_loss: 0.0243 - val_acc: 0.9834\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0442 - acc: 0.9832 - val_loss: 0.0257 - val_acc: 0.9844\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9830 - val_loss: 0.0254 - val_acc: 0.9854\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02378 to 0.02203, saving model to best.model\n",
      "0s - loss: 0.0440 - acc: 0.9817 - val_loss: 0.0220 - val_acc: 0.9883\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.02203 to 0.02070, saving model to best.model\n",
      "0s - loss: 0.0435 - acc: 0.9849 - val_loss: 0.0207 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9834 - val_loss: 0.0214 - val_acc: 0.9883\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9847 - val_loss: 0.0247 - val_acc: 0.9844\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9856 - val_loss: 0.0215 - val_acc: 0.9883\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9864 - val_loss: 0.0225 - val_acc: 0.9844\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0440 - acc: 0.9837 - val_loss: 0.0215 - val_acc: 0.9873\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.02070 to 0.01850, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9864 - val_loss: 0.0185 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9832 - val_loss: 0.0212 - val_acc: 0.9864\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9873 - val_loss: 0.0217 - val_acc: 0.9873\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9861 - val_loss: 0.0243 - val_acc: 0.9854\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9883 - val_loss: 0.0212 - val_acc: 0.9873\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9851 - val_loss: 0.0192 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01850 to 0.01849, saving model to best.model\n",
      "0s - loss: 0.0438 - acc: 0.9822 - val_loss: 0.0185 - val_acc: 0.9912\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9847 - val_loss: 0.0188 - val_acc: 0.9903\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9834 - val_loss: 0.0204 - val_acc: 0.9883\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01849 to 0.01766, saving model to best.model\n",
      "0s - loss: 0.0379 - acc: 0.9859 - val_loss: 0.0177 - val_acc: 0.9912\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9886 - val_loss: 0.0186 - val_acc: 0.9912\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9837 - val_loss: 0.0191 - val_acc: 0.9903\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9866 - val_loss: 0.0204 - val_acc: 0.9883\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01766 to 0.01567, saving model to best.model\n",
      "0s - loss: 0.0387 - acc: 0.9861 - val_loss: 0.0157 - val_acc: 0.9932\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9876 - val_loss: 0.0221 - val_acc: 0.9864\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0207 - val_acc: 0.9854\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0419 - acc: 0.9847 - val_loss: 0.0188 - val_acc: 0.9922\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9856 - val_loss: 0.0184 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9861 - val_loss: 0.0201 - val_acc: 0.9883\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9900 - val_loss: 0.0185 - val_acc: 0.9912\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.01567 to 0.01533, saving model to best.model\n",
      "0s - loss: 0.0325 - acc: 0.9893 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.01533 to 0.01472, saving model to best.model\n",
      "0s - loss: 0.0306 - acc: 0.9893 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9866 - val_loss: 0.0159 - val_acc: 0.9932\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9878 - val_loss: 0.0178 - val_acc: 0.9883\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01472 to 0.01259, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9873 - val_loss: 0.0126 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9876 - val_loss: 0.0143 - val_acc: 0.9932\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9893 - val_loss: 0.0135 - val_acc: 0.9932\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01259 to 0.01231, saving model to best.model\n",
      "0s - loss: 0.0343 - acc: 0.9854 - val_loss: 0.0123 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9878 - val_loss: 0.0157 - val_acc: 0.9932\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9871 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0379 - acc: 0.9861 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9876 - val_loss: 0.0125 - val_acc: 0.9932\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9876 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9883 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9851 - val_loss: 0.0136 - val_acc: 0.9932\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9883 - val_loss: 0.0138 - val_acc: 0.9932\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9895 - val_loss: 0.0184 - val_acc: 0.9883\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9886 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.01231 to 0.01152, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9903 - val_loss: 0.0115 - val_acc: 0.9942\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9873 - val_loss: 0.0119 - val_acc: 0.9942\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9888 - val_loss: 0.0130 - val_acc: 0.9932\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9893 - val_loss: 0.0171 - val_acc: 0.9903\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9883 - val_loss: 0.0123 - val_acc: 0.9942\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9876 - val_loss: 0.0153 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9886 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.01152 to 0.01087, saving model to best.model\n",
      "0s - loss: 0.0287 - acc: 0.9883 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67459, saving model to best.model\n",
      "0s - loss: 0.7963 - acc: 0.5140 - val_loss: 0.6746 - val_acc: 0.5764\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67459 to 0.64911, saving model to best.model\n",
      "0s - loss: 0.7389 - acc: 0.5354 - val_loss: 0.6491 - val_acc: 0.7098\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64911 to 0.61477, saving model to best.model\n",
      "0s - loss: 0.6939 - acc: 0.5807 - val_loss: 0.6148 - val_acc: 0.7420\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61477 to 0.55499, saving model to best.model\n",
      "0s - loss: 0.6421 - acc: 0.6294 - val_loss: 0.5550 - val_acc: 0.7760\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55499 to 0.49086, saving model to best.model\n",
      "0s - loss: 0.5829 - acc: 0.7042 - val_loss: 0.4909 - val_acc: 0.7916\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.49086 to 0.44242, saving model to best.model\n",
      "0s - loss: 0.5202 - acc: 0.7568 - val_loss: 0.4424 - val_acc: 0.8208\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.44242 to 0.40759, saving model to best.model\n",
      "0s - loss: 0.4760 - acc: 0.7843 - val_loss: 0.4076 - val_acc: 0.8345\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.40759 to 0.37564, saving model to best.model\n",
      "0s - loss: 0.4450 - acc: 0.8081 - val_loss: 0.3756 - val_acc: 0.8442\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.37564 to 0.35187, saving model to best.model\n",
      "0s - loss: 0.4209 - acc: 0.8223 - val_loss: 0.3519 - val_acc: 0.8578\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.35187 to 0.33631, saving model to best.model\n",
      "0s - loss: 0.3963 - acc: 0.8352 - val_loss: 0.3363 - val_acc: 0.8588\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33631 to 0.31289, saving model to best.model\n",
      "0s - loss: 0.3724 - acc: 0.8544 - val_loss: 0.3129 - val_acc: 0.8695\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31289 to 0.29569, saving model to best.model\n",
      "0s - loss: 0.3439 - acc: 0.8602 - val_loss: 0.2957 - val_acc: 0.8744\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29569 to 0.28123, saving model to best.model\n",
      "0s - loss: 0.3426 - acc: 0.8629 - val_loss: 0.2812 - val_acc: 0.8763\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.28123 to 0.26842, saving model to best.model\n",
      "0s - loss: 0.3278 - acc: 0.8695 - val_loss: 0.2684 - val_acc: 0.8861\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26842 to 0.25863, saving model to best.model\n",
      "0s - loss: 0.3110 - acc: 0.8802 - val_loss: 0.2586 - val_acc: 0.8870\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25863 to 0.25378, saving model to best.model\n",
      "0s - loss: 0.3046 - acc: 0.8831 - val_loss: 0.2538 - val_acc: 0.8958\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25378 to 0.24853, saving model to best.model\n",
      "0s - loss: 0.2923 - acc: 0.8880 - val_loss: 0.2485 - val_acc: 0.9007\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24853 to 0.24575, saving model to best.model\n",
      "0s - loss: 0.2891 - acc: 0.8868 - val_loss: 0.2458 - val_acc: 0.8987\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24575 to 0.22603, saving model to best.model\n",
      "0s - loss: 0.2770 - acc: 0.8946 - val_loss: 0.2260 - val_acc: 0.9143\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22603 to 0.22357, saving model to best.model\n",
      "0s - loss: 0.2624 - acc: 0.8972 - val_loss: 0.2236 - val_acc: 0.9163\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22357 to 0.22326, saving model to best.model\n",
      "0s - loss: 0.2676 - acc: 0.9036 - val_loss: 0.2233 - val_acc: 0.9085\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22326 to 0.21195, saving model to best.model\n",
      "0s - loss: 0.2532 - acc: 0.9077 - val_loss: 0.2120 - val_acc: 0.9202\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21195 to 0.20675, saving model to best.model\n",
      "0s - loss: 0.2513 - acc: 0.9072 - val_loss: 0.2068 - val_acc: 0.9241\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20675 to 0.20512, saving model to best.model\n",
      "0s - loss: 0.2473 - acc: 0.9145 - val_loss: 0.2051 - val_acc: 0.9231\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20512 to 0.19863, saving model to best.model\n",
      "0s - loss: 0.2414 - acc: 0.9092 - val_loss: 0.1986 - val_acc: 0.9299\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19863 to 0.19777, saving model to best.model\n",
      "0s - loss: 0.2442 - acc: 0.9116 - val_loss: 0.1978 - val_acc: 0.9231\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19777 to 0.19152, saving model to best.model\n",
      "0s - loss: 0.2305 - acc: 0.9196 - val_loss: 0.1915 - val_acc: 0.9299\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.2245 - acc: 0.9216 - val_loss: 0.1917 - val_acc: 0.9270\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19152 to 0.18425, saving model to best.model\n",
      "0s - loss: 0.2277 - acc: 0.9179 - val_loss: 0.1843 - val_acc: 0.9406\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18425 to 0.18090, saving model to best.model\n",
      "0s - loss: 0.2153 - acc: 0.9243 - val_loss: 0.1809 - val_acc: 0.9377\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18090 to 0.17950, saving model to best.model\n",
      "0s - loss: 0.2135 - acc: 0.9260 - val_loss: 0.1795 - val_acc: 0.9377\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.2189 - acc: 0.9235 - val_loss: 0.1824 - val_acc: 0.9328\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17950 to 0.17738, saving model to best.model\n",
      "0s - loss: 0.2076 - acc: 0.9274 - val_loss: 0.1774 - val_acc: 0.9318\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.2101 - acc: 0.9250 - val_loss: 0.1791 - val_acc: 0.9503\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17738 to 0.17008, saving model to best.model\n",
      "0s - loss: 0.2088 - acc: 0.9248 - val_loss: 0.1701 - val_acc: 0.9406\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17008 to 0.16910, saving model to best.model\n",
      "0s - loss: 0.2008 - acc: 0.9284 - val_loss: 0.1691 - val_acc: 0.9396\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16910 to 0.16381, saving model to best.model\n",
      "0s - loss: 0.1949 - acc: 0.9338 - val_loss: 0.1638 - val_acc: 0.9455\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16381 to 0.16120, saving model to best.model\n",
      "0s - loss: 0.2016 - acc: 0.9287 - val_loss: 0.1612 - val_acc: 0.9464\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16120 to 0.16025, saving model to best.model\n",
      "0s - loss: 0.2009 - acc: 0.9330 - val_loss: 0.1603 - val_acc: 0.9455\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16025 to 0.16019, saving model to best.model\n",
      "0s - loss: 0.1887 - acc: 0.9338 - val_loss: 0.1602 - val_acc: 0.9406\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16019 to 0.15350, saving model to best.model\n",
      "0s - loss: 0.1896 - acc: 0.9357 - val_loss: 0.1535 - val_acc: 0.9542\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15350 to 0.15045, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9369 - val_loss: 0.1504 - val_acc: 0.9523\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15045 to 0.14790, saving model to best.model\n",
      "0s - loss: 0.1755 - acc: 0.9382 - val_loss: 0.1479 - val_acc: 0.9523\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1803 - acc: 0.9389 - val_loss: 0.1530 - val_acc: 0.9426\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14790 to 0.14328, saving model to best.model\n",
      "0s - loss: 0.1732 - acc: 0.9411 - val_loss: 0.1433 - val_acc: 0.9552\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14328 to 0.14181, saving model to best.model\n",
      "0s - loss: 0.1649 - acc: 0.9459 - val_loss: 0.1418 - val_acc: 0.9562\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14181 to 0.14026, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9396 - val_loss: 0.1403 - val_acc: 0.9533\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14026 to 0.13574, saving model to best.model\n",
      "0s - loss: 0.1592 - acc: 0.9472 - val_loss: 0.1357 - val_acc: 0.9562\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13574 to 0.13287, saving model to best.model\n",
      "0s - loss: 0.1492 - acc: 0.9518 - val_loss: 0.1329 - val_acc: 0.9581\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.13287 to 0.13185, saving model to best.model\n",
      "0s - loss: 0.1594 - acc: 0.9445 - val_loss: 0.1319 - val_acc: 0.9572\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.13185 to 0.12955, saving model to best.model\n",
      "0s - loss: 0.1593 - acc: 0.9469 - val_loss: 0.1295 - val_acc: 0.9572\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12955 to 0.12645, saving model to best.model\n",
      "0s - loss: 0.1504 - acc: 0.9484 - val_loss: 0.1265 - val_acc: 0.9581\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1471 - acc: 0.9489 - val_loss: 0.1294 - val_acc: 0.9581\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.12645 to 0.12260, saving model to best.model\n",
      "0s - loss: 0.1471 - acc: 0.9506 - val_loss: 0.1226 - val_acc: 0.9601\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.12260 to 0.11916, saving model to best.model\n",
      "0s - loss: 0.1402 - acc: 0.9501 - val_loss: 0.1192 - val_acc: 0.9611\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1408 - acc: 0.9518 - val_loss: 0.1193 - val_acc: 0.9611\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.11916 to 0.11434, saving model to best.model\n",
      "0s - loss: 0.1396 - acc: 0.9554 - val_loss: 0.1143 - val_acc: 0.9611\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.11434 to 0.11395, saving model to best.model\n",
      "0s - loss: 0.1389 - acc: 0.9554 - val_loss: 0.1139 - val_acc: 0.9620\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11395 to 0.10901, saving model to best.model\n",
      "0s - loss: 0.1403 - acc: 0.9518 - val_loss: 0.1090 - val_acc: 0.9620\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.10901 to 0.10664, saving model to best.model\n",
      "0s - loss: 0.1325 - acc: 0.9557 - val_loss: 0.1066 - val_acc: 0.9630\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.10664 to 0.10545, saving model to best.model\n",
      "0s - loss: 0.1305 - acc: 0.9552 - val_loss: 0.1055 - val_acc: 0.9649\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10545 to 0.10213, saving model to best.model\n",
      "0s - loss: 0.1248 - acc: 0.9579 - val_loss: 0.1021 - val_acc: 0.9630\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.1313 - acc: 0.9564 - val_loss: 0.1025 - val_acc: 0.9649\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10213 to 0.10187, saving model to best.model\n",
      "0s - loss: 0.1279 - acc: 0.9584 - val_loss: 0.1019 - val_acc: 0.9659\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10187 to 0.09812, saving model to best.model\n",
      "0s - loss: 0.1210 - acc: 0.9601 - val_loss: 0.0981 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1313 - acc: 0.9545 - val_loss: 0.1016 - val_acc: 0.9679\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1257 - acc: 0.9557 - val_loss: 0.1002 - val_acc: 0.9669\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09812 to 0.09260, saving model to best.model\n",
      "0s - loss: 0.1192 - acc: 0.9593 - val_loss: 0.0926 - val_acc: 0.9698\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09260 to 0.09050, saving model to best.model\n",
      "0s - loss: 0.1246 - acc: 0.9596 - val_loss: 0.0905 - val_acc: 0.9727\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1105 - acc: 0.9637 - val_loss: 0.0915 - val_acc: 0.9708\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.09050 to 0.08791, saving model to best.model\n",
      "0s - loss: 0.1084 - acc: 0.9618 - val_loss: 0.0879 - val_acc: 0.9727\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08791 to 0.08587, saving model to best.model\n",
      "0s - loss: 0.1176 - acc: 0.9615 - val_loss: 0.0859 - val_acc: 0.9747\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1088 - acc: 0.9632 - val_loss: 0.0883 - val_acc: 0.9737\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08587 to 0.08190, saving model to best.model\n",
      "0s - loss: 0.1092 - acc: 0.9659 - val_loss: 0.0819 - val_acc: 0.9757\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08190 to 0.08147, saving model to best.model\n",
      "0s - loss: 0.1015 - acc: 0.9679 - val_loss: 0.0815 - val_acc: 0.9766\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.08147 to 0.08027, saving model to best.model\n",
      "0s - loss: 0.1033 - acc: 0.9688 - val_loss: 0.0803 - val_acc: 0.9776\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.0998 - acc: 0.9669 - val_loss: 0.0803 - val_acc: 0.9776\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1031 - acc: 0.9686 - val_loss: 0.0805 - val_acc: 0.9766\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.08027 to 0.07508, saving model to best.model\n",
      "0s - loss: 0.0986 - acc: 0.9662 - val_loss: 0.0751 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07508 to 0.07384, saving model to best.model\n",
      "0s - loss: 0.0930 - acc: 0.9703 - val_loss: 0.0738 - val_acc: 0.9815\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07384 to 0.07307, saving model to best.model\n",
      "0s - loss: 0.0995 - acc: 0.9693 - val_loss: 0.0731 - val_acc: 0.9805\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.07307 to 0.07177, saving model to best.model\n",
      "0s - loss: 0.0929 - acc: 0.9730 - val_loss: 0.0718 - val_acc: 0.9815\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.07177 to 0.07074, saving model to best.model\n",
      "0s - loss: 0.0961 - acc: 0.9691 - val_loss: 0.0707 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0878 - acc: 0.9730 - val_loss: 0.0743 - val_acc: 0.9796\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0940 - acc: 0.9705 - val_loss: 0.0710 - val_acc: 0.9776\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.0981 - acc: 0.9679 - val_loss: 0.0723 - val_acc: 0.9805\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0947 - acc: 0.9657 - val_loss: 0.0709 - val_acc: 0.9796\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.07074 to 0.06506, saving model to best.model\n",
      "0s - loss: 0.0863 - acc: 0.9725 - val_loss: 0.0651 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.06506 to 0.06473, saving model to best.model\n",
      "0s - loss: 0.0883 - acc: 0.9701 - val_loss: 0.0647 - val_acc: 0.9825\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0822 - acc: 0.9730 - val_loss: 0.0649 - val_acc: 0.9815\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.06473 to 0.06369, saving model to best.model\n",
      "0s - loss: 0.0870 - acc: 0.9722 - val_loss: 0.0637 - val_acc: 0.9834\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.06369 to 0.06283, saving model to best.model\n",
      "0s - loss: 0.0842 - acc: 0.9725 - val_loss: 0.0628 - val_acc: 0.9825\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.06283 to 0.06219, saving model to best.model\n",
      "0s - loss: 0.0801 - acc: 0.9737 - val_loss: 0.0622 - val_acc: 0.9834\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0861 - acc: 0.9720 - val_loss: 0.0631 - val_acc: 0.9825\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0843 - acc: 0.9713 - val_loss: 0.0633 - val_acc: 0.9796\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0825 - acc: 0.9744 - val_loss: 0.0640 - val_acc: 0.9786\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.06219 to 0.05959, saving model to best.model\n",
      "0s - loss: 0.0806 - acc: 0.9722 - val_loss: 0.0596 - val_acc: 0.9825\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0828 - acc: 0.9749 - val_loss: 0.0610 - val_acc: 0.9815\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.05959 to 0.05869, saving model to best.model\n",
      "0s - loss: 0.0841 - acc: 0.9720 - val_loss: 0.0587 - val_acc: 0.9825\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.05869 to 0.05728, saving model to best.model\n",
      "0s - loss: 0.0779 - acc: 0.9747 - val_loss: 0.0573 - val_acc: 0.9844\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0744 - acc: 0.9737 - val_loss: 0.0576 - val_acc: 0.9825\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.05728 to 0.05549, saving model to best.model\n",
      "0s - loss: 0.0775 - acc: 0.9735 - val_loss: 0.0555 - val_acc: 0.9854\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.05549 to 0.05406, saving model to best.model\n",
      "0s - loss: 0.0715 - acc: 0.9769 - val_loss: 0.0541 - val_acc: 0.9834\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.05406 to 0.05314, saving model to best.model\n",
      "0s - loss: 0.0803 - acc: 0.9747 - val_loss: 0.0531 - val_acc: 0.9834\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.05314 to 0.05309, saving model to best.model\n",
      "0s - loss: 0.0748 - acc: 0.9783 - val_loss: 0.0531 - val_acc: 0.9844\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.05309 to 0.05253, saving model to best.model\n",
      "0s - loss: 0.0740 - acc: 0.9769 - val_loss: 0.0525 - val_acc: 0.9854\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0660 - acc: 0.9795 - val_loss: 0.0527 - val_acc: 0.9854\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0695 - acc: 0.9798 - val_loss: 0.0530 - val_acc: 0.9834\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.05253 to 0.05123, saving model to best.model\n",
      "0s - loss: 0.0708 - acc: 0.9778 - val_loss: 0.0512 - val_acc: 0.9844\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0709 - acc: 0.9778 - val_loss: 0.0520 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.05123 to 0.04994, saving model to best.model\n",
      "0s - loss: 0.0704 - acc: 0.9776 - val_loss: 0.0499 - val_acc: 0.9834\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0723 - acc: 0.9781 - val_loss: 0.0505 - val_acc: 0.9834\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.04994 to 0.04927, saving model to best.model\n",
      "0s - loss: 0.0679 - acc: 0.9774 - val_loss: 0.0493 - val_acc: 0.9834\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.04927 to 0.04808, saving model to best.model\n",
      "0s - loss: 0.0684 - acc: 0.9759 - val_loss: 0.0481 - val_acc: 0.9834\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0677 - acc: 0.9752 - val_loss: 0.0512 - val_acc: 0.9825\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.04808 to 0.04762, saving model to best.model\n",
      "0s - loss: 0.0669 - acc: 0.9798 - val_loss: 0.0476 - val_acc: 0.9825\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.04762 to 0.04541, saving model to best.model\n",
      "0s - loss: 0.0613 - acc: 0.9825 - val_loss: 0.0454 - val_acc: 0.9834\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.04541 to 0.04410, saving model to best.model\n",
      "0s - loss: 0.0676 - acc: 0.9778 - val_loss: 0.0441 - val_acc: 0.9854\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0604 - acc: 0.9786 - val_loss: 0.0442 - val_acc: 0.9834\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0660 - acc: 0.9776 - val_loss: 0.0449 - val_acc: 0.9854\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.04410 to 0.04299, saving model to best.model\n",
      "0s - loss: 0.0605 - acc: 0.9795 - val_loss: 0.0430 - val_acc: 0.9854\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.04299 to 0.04255, saving model to best.model\n",
      "0s - loss: 0.0584 - acc: 0.9781 - val_loss: 0.0426 - val_acc: 0.9854\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.04255 to 0.04176, saving model to best.model\n",
      "0s - loss: 0.0662 - acc: 0.9783 - val_loss: 0.0418 - val_acc: 0.9825\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.04176 to 0.04040, saving model to best.model\n",
      "0s - loss: 0.0540 - acc: 0.9805 - val_loss: 0.0404 - val_acc: 0.9854\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.04040 to 0.03891, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9822 - val_loss: 0.0389 - val_acc: 0.9873\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9827 - val_loss: 0.0413 - val_acc: 0.9825\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0584 - acc: 0.9817 - val_loss: 0.0421 - val_acc: 0.9834\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.03891 to 0.03876, saving model to best.model\n",
      "0s - loss: 0.0567 - acc: 0.9832 - val_loss: 0.0388 - val_acc: 0.9844\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.03876 to 0.03724, saving model to best.model\n",
      "0s - loss: 0.0619 - acc: 0.9793 - val_loss: 0.0372 - val_acc: 0.9825\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.03724 to 0.03714, saving model to best.model\n",
      "0s - loss: 0.0510 - acc: 0.9822 - val_loss: 0.0371 - val_acc: 0.9854\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.03714 to 0.03582, saving model to best.model\n",
      "0s - loss: 0.0532 - acc: 0.9817 - val_loss: 0.0358 - val_acc: 0.9844\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.03582 to 0.03360, saving model to best.model\n",
      "0s - loss: 0.0579 - acc: 0.9793 - val_loss: 0.0336 - val_acc: 0.9844\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9832 - val_loss: 0.0369 - val_acc: 0.9854\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0546 - acc: 0.9800 - val_loss: 0.0339 - val_acc: 0.9864\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9822 - val_loss: 0.0339 - val_acc: 0.9854\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.03360 to 0.03219, saving model to best.model\n",
      "0s - loss: 0.0580 - acc: 0.9769 - val_loss: 0.0322 - val_acc: 0.9854\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0492 - acc: 0.9817 - val_loss: 0.0339 - val_acc: 0.9854\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.03219 to 0.03053, saving model to best.model\n",
      "0s - loss: 0.0534 - acc: 0.9820 - val_loss: 0.0305 - val_acc: 0.9844\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.03053 to 0.02966, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9854 - val_loss: 0.0297 - val_acc: 0.9854\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.02966 to 0.02821, saving model to best.model\n",
      "0s - loss: 0.0500 - acc: 0.9834 - val_loss: 0.0282 - val_acc: 0.9854\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9842 - val_loss: 0.0300 - val_acc: 0.9854\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0460 - acc: 0.9830 - val_loss: 0.0284 - val_acc: 0.9864\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02821 to 0.02703, saving model to best.model\n",
      "0s - loss: 0.0469 - acc: 0.9847 - val_loss: 0.0270 - val_acc: 0.9864\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.02703 to 0.02693, saving model to best.model\n",
      "0s - loss: 0.0430 - acc: 0.9839 - val_loss: 0.0269 - val_acc: 0.9854\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.02693 to 0.02621, saving model to best.model\n",
      "0s - loss: 0.0402 - acc: 0.9856 - val_loss: 0.0262 - val_acc: 0.9864\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02621 to 0.02544, saving model to best.model\n",
      "0s - loss: 0.0474 - acc: 0.9842 - val_loss: 0.0254 - val_acc: 0.9864\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9839 - val_loss: 0.0260 - val_acc: 0.9864\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02544 to 0.02424, saving model to best.model\n",
      "0s - loss: 0.0453 - acc: 0.9837 - val_loss: 0.0242 - val_acc: 0.9873\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.02424 to 0.02315, saving model to best.model\n",
      "0s - loss: 0.0419 - acc: 0.9844 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.02315 to 0.02293, saving model to best.model\n",
      "0s - loss: 0.0417 - acc: 0.9864 - val_loss: 0.0229 - val_acc: 0.9903\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9847 - val_loss: 0.0234 - val_acc: 0.9883\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9861 - val_loss: 0.0249 - val_acc: 0.9873\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9854 - val_loss: 0.0231 - val_acc: 0.9883\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9827 - val_loss: 0.0246 - val_acc: 0.9883\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.02293 to 0.02182, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9876 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9844 - val_loss: 0.0236 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9859 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02182 to 0.02066, saving model to best.model\n",
      "0s - loss: 0.0370 - acc: 0.9878 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9864 - val_loss: 0.0219 - val_acc: 0.9912\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.02066 to 0.02025, saving model to best.model\n",
      "0s - loss: 0.0358 - acc: 0.9876 - val_loss: 0.0202 - val_acc: 0.9903\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9849 - val_loss: 0.0208 - val_acc: 0.9903\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.02025 to 0.01947, saving model to best.model\n",
      "0s - loss: 0.0373 - acc: 0.9844 - val_loss: 0.0195 - val_acc: 0.9903\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01947 to 0.01864, saving model to best.model\n",
      "0s - loss: 0.0351 - acc: 0.9873 - val_loss: 0.0186 - val_acc: 0.9893\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01864 to 0.01757, saving model to best.model\n",
      "0s - loss: 0.0358 - acc: 0.9866 - val_loss: 0.0176 - val_acc: 0.9903\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9881 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9893 - val_loss: 0.0198 - val_acc: 0.9912\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9888 - val_loss: 0.0184 - val_acc: 0.9903\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01757 to 0.01739, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9888 - val_loss: 0.0174 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9886 - val_loss: 0.0183 - val_acc: 0.9912\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9878 - val_loss: 0.0180 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9888 - val_loss: 0.0178 - val_acc: 0.9912\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01739 to 0.01653, saving model to best.model\n",
      "0s - loss: 0.0340 - acc: 0.9871 - val_loss: 0.0165 - val_acc: 0.9903\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01653 to 0.01511, saving model to best.model\n",
      "0s - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0151 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01511 to 0.01502, saving model to best.model\n",
      "0s - loss: 0.0306 - acc: 0.9888 - val_loss: 0.0150 - val_acc: 0.9922\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9873 - val_loss: 0.0164 - val_acc: 0.9912\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0159 - val_acc: 0.9903\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9905 - val_loss: 0.0162 - val_acc: 0.9912\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9898 - val_loss: 0.0171 - val_acc: 0.9912\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9871 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9866 - val_loss: 0.0157 - val_acc: 0.9912\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9898 - val_loss: 0.0175 - val_acc: 0.9922\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01502 to 0.01461, saving model to best.model\n",
      "0s - loss: 0.0310 - acc: 0.9883 - val_loss: 0.0146 - val_acc: 0.9912\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9856 - val_loss: 0.0150 - val_acc: 0.9912\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9890 - val_loss: 0.0156 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9876 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.01461 to 0.01447, saving model to best.model\n",
      "0s - loss: 0.0336 - acc: 0.9878 - val_loss: 0.0145 - val_acc: 0.9903\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.01447 to 0.01338, saving model to best.model\n",
      "0s - loss: 0.0271 - acc: 0.9903 - val_loss: 0.0134 - val_acc: 0.9912\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9888 - val_loss: 0.0141 - val_acc: 0.9912\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9866 - val_loss: 0.0176 - val_acc: 0.9912\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9851 - val_loss: 0.0184 - val_acc: 0.9912\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9920 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.01338 to 0.01325, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9893 - val_loss: 0.0133 - val_acc: 0.9912\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0287 - acc: 0.9905 - val_loss: 0.0144 - val_acc: 0.9912\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0139 - val_acc: 0.9922\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9883 - val_loss: 0.0147 - val_acc: 0.9922\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.01325 to 0.01272, saving model to best.model\n",
      "0s - loss: 0.0319 - acc: 0.9873 - val_loss: 0.0127 - val_acc: 0.9922\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.01272 to 0.01149, saving model to best.model\n",
      "0s - loss: 0.0283 - acc: 0.9903 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9912 - val_loss: 0.0133 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9910 - val_loss: 0.0135 - val_acc: 0.9932\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0236 - acc: 0.9905 - val_loss: 0.0126 - val_acc: 0.9922\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67012, saving model to best.model\n",
      "0s - loss: 0.7802 - acc: 0.5074 - val_loss: 0.6701 - val_acc: 0.6241\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67012 to 0.64845, saving model to best.model\n",
      "0s - loss: 0.7359 - acc: 0.5303 - val_loss: 0.6484 - val_acc: 0.6563\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64845 to 0.58740, saving model to best.model\n",
      "0s - loss: 0.6782 - acc: 0.5875 - val_loss: 0.5874 - val_acc: 0.8014\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58740 to 0.50517, saving model to best.model\n",
      "0s - loss: 0.6277 - acc: 0.6530 - val_loss: 0.5052 - val_acc: 0.8179\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50517 to 0.43815, saving model to best.model\n",
      "0s - loss: 0.5506 - acc: 0.7297 - val_loss: 0.4382 - val_acc: 0.8218\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.43815 to 0.40009, saving model to best.model\n",
      "0s - loss: 0.4939 - acc: 0.7709 - val_loss: 0.4001 - val_acc: 0.8345\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40009 to 0.36478, saving model to best.model\n",
      "0s - loss: 0.4689 - acc: 0.8035 - val_loss: 0.3648 - val_acc: 0.8608\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36478 to 0.34107, saving model to best.model\n",
      "0s - loss: 0.4278 - acc: 0.8259 - val_loss: 0.3411 - val_acc: 0.8666\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34107 to 0.32918, saving model to best.model\n",
      "0s - loss: 0.4042 - acc: 0.8352 - val_loss: 0.3292 - val_acc: 0.8724\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32918 to 0.30973, saving model to best.model\n",
      "0s - loss: 0.3871 - acc: 0.8417 - val_loss: 0.3097 - val_acc: 0.8793\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30973 to 0.29269, saving model to best.model\n",
      "0s - loss: 0.3712 - acc: 0.8573 - val_loss: 0.2927 - val_acc: 0.8890\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29269 to 0.28067, saving model to best.model\n",
      "0s - loss: 0.3563 - acc: 0.8605 - val_loss: 0.2807 - val_acc: 0.8919\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28067 to 0.27026, saving model to best.model\n",
      "0s - loss: 0.3365 - acc: 0.8617 - val_loss: 0.2703 - val_acc: 0.8948\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27026 to 0.25865, saving model to best.model\n",
      "0s - loss: 0.3291 - acc: 0.8697 - val_loss: 0.2586 - val_acc: 0.8939\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25865 to 0.25083, saving model to best.model\n",
      "0s - loss: 0.3238 - acc: 0.8731 - val_loss: 0.2508 - val_acc: 0.8968\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25083 to 0.24257, saving model to best.model\n",
      "0s - loss: 0.3083 - acc: 0.8804 - val_loss: 0.2426 - val_acc: 0.9017\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24257 to 0.23555, saving model to best.model\n",
      "0s - loss: 0.3063 - acc: 0.8807 - val_loss: 0.2355 - val_acc: 0.9065\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.23555 to 0.22969, saving model to best.model\n",
      "0s - loss: 0.2885 - acc: 0.8907 - val_loss: 0.2297 - val_acc: 0.9114\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22969 to 0.22485, saving model to best.model\n",
      "0s - loss: 0.2857 - acc: 0.8953 - val_loss: 0.2248 - val_acc: 0.9182\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22485 to 0.21992, saving model to best.model\n",
      "0s - loss: 0.2759 - acc: 0.8972 - val_loss: 0.2199 - val_acc: 0.9182\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.21992 to 0.21616, saving model to best.model\n",
      "0s - loss: 0.2736 - acc: 0.8999 - val_loss: 0.2162 - val_acc: 0.9202\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21616 to 0.21106, saving model to best.model\n",
      "0s - loss: 0.2729 - acc: 0.9014 - val_loss: 0.2111 - val_acc: 0.9192\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21106 to 0.21070, saving model to best.model\n",
      "0s - loss: 0.2677 - acc: 0.9063 - val_loss: 0.2107 - val_acc: 0.9221\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21070 to 0.20619, saving model to best.model\n",
      "0s - loss: 0.2668 - acc: 0.9041 - val_loss: 0.2062 - val_acc: 0.9211\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20619 to 0.20489, saving model to best.model\n",
      "0s - loss: 0.2574 - acc: 0.9043 - val_loss: 0.2049 - val_acc: 0.9202\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20489 to 0.19890, saving model to best.model\n",
      "0s - loss: 0.2496 - acc: 0.9092 - val_loss: 0.1989 - val_acc: 0.9221\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19890 to 0.19483, saving model to best.model\n",
      "0s - loss: 0.2455 - acc: 0.9114 - val_loss: 0.1948 - val_acc: 0.9250\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19483 to 0.19135, saving model to best.model\n",
      "0s - loss: 0.2463 - acc: 0.9143 - val_loss: 0.1913 - val_acc: 0.9270\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19135 to 0.19013, saving model to best.model\n",
      "0s - loss: 0.2438 - acc: 0.9128 - val_loss: 0.1901 - val_acc: 0.9221\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19013 to 0.18442, saving model to best.model\n",
      "0s - loss: 0.2357 - acc: 0.9150 - val_loss: 0.1844 - val_acc: 0.9279\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18442 to 0.18121, saving model to best.model\n",
      "0s - loss: 0.2376 - acc: 0.9140 - val_loss: 0.1812 - val_acc: 0.9260\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18121 to 0.17663, saving model to best.model\n",
      "0s - loss: 0.2321 - acc: 0.9158 - val_loss: 0.1766 - val_acc: 0.9270\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17663 to 0.17310, saving model to best.model\n",
      "0s - loss: 0.2286 - acc: 0.9136 - val_loss: 0.1731 - val_acc: 0.9270\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17310 to 0.17190, saving model to best.model\n",
      "0s - loss: 0.2272 - acc: 0.9126 - val_loss: 0.1719 - val_acc: 0.9250\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17190 to 0.16682, saving model to best.model\n",
      "0s - loss: 0.2126 - acc: 0.9216 - val_loss: 0.1668 - val_acc: 0.9318\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.16682 to 0.16220, saving model to best.model\n",
      "0s - loss: 0.2090 - acc: 0.9211 - val_loss: 0.1622 - val_acc: 0.9309\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16220 to 0.16091, saving model to best.model\n",
      "0s - loss: 0.2099 - acc: 0.9238 - val_loss: 0.1609 - val_acc: 0.9270\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2050 - acc: 0.9240 - val_loss: 0.1636 - val_acc: 0.9435\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16091 to 0.15244, saving model to best.model\n",
      "0s - loss: 0.2053 - acc: 0.9238 - val_loss: 0.1524 - val_acc: 0.9318\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15244 to 0.14921, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9284 - val_loss: 0.1492 - val_acc: 0.9367\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.14921 to 0.14526, saving model to best.model\n",
      "0s - loss: 0.1978 - acc: 0.9252 - val_loss: 0.1453 - val_acc: 0.9367\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14526 to 0.14223, saving model to best.model\n",
      "0s - loss: 0.1966 - acc: 0.9243 - val_loss: 0.1422 - val_acc: 0.9357\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.14223 to 0.13965, saving model to best.model\n",
      "0s - loss: 0.1928 - acc: 0.9274 - val_loss: 0.1397 - val_acc: 0.9338\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13965 to 0.13700, saving model to best.model\n",
      "0s - loss: 0.1912 - acc: 0.9282 - val_loss: 0.1370 - val_acc: 0.9426\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13700 to 0.13574, saving model to best.model\n",
      "0s - loss: 0.1875 - acc: 0.9296 - val_loss: 0.1357 - val_acc: 0.9435\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.13574 to 0.13087, saving model to best.model\n",
      "0s - loss: 0.1819 - acc: 0.9330 - val_loss: 0.1309 - val_acc: 0.9416\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13087 to 0.13058, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9345 - val_loss: 0.1306 - val_acc: 0.9328\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13058 to 0.12398, saving model to best.model\n",
      "0s - loss: 0.1696 - acc: 0.9357 - val_loss: 0.1240 - val_acc: 0.9406\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12398 to 0.12125, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9372 - val_loss: 0.1212 - val_acc: 0.9426\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12125 to 0.11802, saving model to best.model\n",
      "0s - loss: 0.1659 - acc: 0.9362 - val_loss: 0.1180 - val_acc: 0.9533\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11802 to 0.11754, saving model to best.model\n",
      "0s - loss: 0.1630 - acc: 0.9411 - val_loss: 0.1175 - val_acc: 0.9406\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11754 to 0.11197, saving model to best.model\n",
      "0s - loss: 0.1554 - acc: 0.9399 - val_loss: 0.1120 - val_acc: 0.9484\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11197 to 0.10879, saving model to best.model\n",
      "0s - loss: 0.1537 - acc: 0.9403 - val_loss: 0.1088 - val_acc: 0.9503\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10879 to 0.10598, saving model to best.model\n",
      "0s - loss: 0.1580 - acc: 0.9396 - val_loss: 0.1060 - val_acc: 0.9464\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10598 to 0.10221, saving model to best.model\n",
      "0s - loss: 0.1457 - acc: 0.9425 - val_loss: 0.1022 - val_acc: 0.9591\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.10221 to 0.09880, saving model to best.model\n",
      "0s - loss: 0.1429 - acc: 0.9425 - val_loss: 0.0988 - val_acc: 0.9552\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09880 to 0.09595, saving model to best.model\n",
      "0s - loss: 0.1378 - acc: 0.9503 - val_loss: 0.0960 - val_acc: 0.9620\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09595 to 0.09459, saving model to best.model\n",
      "0s - loss: 0.1442 - acc: 0.9494 - val_loss: 0.0946 - val_acc: 0.9640\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09459 to 0.09122, saving model to best.model\n",
      "0s - loss: 0.1417 - acc: 0.9503 - val_loss: 0.0912 - val_acc: 0.9659\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09122 to 0.08830, saving model to best.model\n",
      "0s - loss: 0.1326 - acc: 0.9462 - val_loss: 0.0883 - val_acc: 0.9649\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08830 to 0.08650, saving model to best.model\n",
      "0s - loss: 0.1263 - acc: 0.9535 - val_loss: 0.0865 - val_acc: 0.9669\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08650 to 0.08344, saving model to best.model\n",
      "0s - loss: 0.1366 - acc: 0.9515 - val_loss: 0.0834 - val_acc: 0.9708\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08344 to 0.07935, saving model to best.model\n",
      "0s - loss: 0.1255 - acc: 0.9518 - val_loss: 0.0793 - val_acc: 0.9688\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.07935 to 0.07743, saving model to best.model\n",
      "0s - loss: 0.1216 - acc: 0.9564 - val_loss: 0.0774 - val_acc: 0.9698\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07743 to 0.07510, saving model to best.model\n",
      "0s - loss: 0.1169 - acc: 0.9542 - val_loss: 0.0751 - val_acc: 0.9718\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.07510 to 0.07377, saving model to best.model\n",
      "0s - loss: 0.1169 - acc: 0.9547 - val_loss: 0.0738 - val_acc: 0.9747\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07377 to 0.07008, saving model to best.model\n",
      "0s - loss: 0.1173 - acc: 0.9542 - val_loss: 0.0701 - val_acc: 0.9737\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07008 to 0.06995, saving model to best.model\n",
      "0s - loss: 0.1113 - acc: 0.9593 - val_loss: 0.0699 - val_acc: 0.9757\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.06995 to 0.06769, saving model to best.model\n",
      "0s - loss: 0.1081 - acc: 0.9569 - val_loss: 0.0677 - val_acc: 0.9766\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06769 to 0.06531, saving model to best.model\n",
      "0s - loss: 0.1099 - acc: 0.9589 - val_loss: 0.0653 - val_acc: 0.9727\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06531 to 0.06293, saving model to best.model\n",
      "0s - loss: 0.1093 - acc: 0.9589 - val_loss: 0.0629 - val_acc: 0.9805\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06293 to 0.06273, saving model to best.model\n",
      "0s - loss: 0.1079 - acc: 0.9576 - val_loss: 0.0627 - val_acc: 0.9805\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06273 to 0.06188, saving model to best.model\n",
      "0s - loss: 0.1018 - acc: 0.9606 - val_loss: 0.0619 - val_acc: 0.9815\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06188 to 0.05842, saving model to best.model\n",
      "0s - loss: 0.0972 - acc: 0.9647 - val_loss: 0.0584 - val_acc: 0.9766\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.05842 to 0.05655, saving model to best.model\n",
      "0s - loss: 0.0977 - acc: 0.9603 - val_loss: 0.0566 - val_acc: 0.9854\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.05655 to 0.05450, saving model to best.model\n",
      "0s - loss: 0.0956 - acc: 0.9618 - val_loss: 0.0545 - val_acc: 0.9854\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05450 to 0.05261, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9623 - val_loss: 0.0526 - val_acc: 0.9854\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0982 - acc: 0.9606 - val_loss: 0.0530 - val_acc: 0.9864\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05261 to 0.05144, saving model to best.model\n",
      "0s - loss: 0.0949 - acc: 0.9652 - val_loss: 0.0514 - val_acc: 0.9873\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0901 - acc: 0.9674 - val_loss: 0.0576 - val_acc: 0.9825\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1174 - acc: 0.9569 - val_loss: 0.0666 - val_acc: 0.9727\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05144 to 0.05020, saving model to best.model\n",
      "0s - loss: 0.1023 - acc: 0.9606 - val_loss: 0.0502 - val_acc: 0.9854\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05020 to 0.04801, saving model to best.model\n",
      "0s - loss: 0.0878 - acc: 0.9686 - val_loss: 0.0480 - val_acc: 0.9873\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.04801 to 0.04734, saving model to best.model\n",
      "0s - loss: 0.0944 - acc: 0.9642 - val_loss: 0.0473 - val_acc: 0.9873\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04734 to 0.04672, saving model to best.model\n",
      "0s - loss: 0.0857 - acc: 0.9662 - val_loss: 0.0467 - val_acc: 0.9864\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04672 to 0.04580, saving model to best.model\n",
      "0s - loss: 0.0844 - acc: 0.9654 - val_loss: 0.0458 - val_acc: 0.9854\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04580 to 0.04197, saving model to best.model\n",
      "0s - loss: 0.0815 - acc: 0.9703 - val_loss: 0.0420 - val_acc: 0.9873\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04197 to 0.04089, saving model to best.model\n",
      "0s - loss: 0.0799 - acc: 0.9718 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04089 to 0.04048, saving model to best.model\n",
      "0s - loss: 0.0755 - acc: 0.9710 - val_loss: 0.0405 - val_acc: 0.9873\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04048 to 0.03743, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9718 - val_loss: 0.0374 - val_acc: 0.9883\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.03743 to 0.03714, saving model to best.model\n",
      "0s - loss: 0.0786 - acc: 0.9710 - val_loss: 0.0371 - val_acc: 0.9883\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0734 - acc: 0.9742 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03714 to 0.03660, saving model to best.model\n",
      "0s - loss: 0.0773 - acc: 0.9713 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0744 - acc: 0.9705 - val_loss: 0.0407 - val_acc: 0.9854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.03660 to 0.03404, saving model to best.model\n",
      "0s - loss: 0.0795 - acc: 0.9708 - val_loss: 0.0340 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.03404 to 0.03230, saving model to best.model\n",
      "0s - loss: 0.0730 - acc: 0.9742 - val_loss: 0.0323 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9737 - val_loss: 0.0324 - val_acc: 0.9883\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.03230 to 0.02994, saving model to best.model\n",
      "0s - loss: 0.0690 - acc: 0.9752 - val_loss: 0.0299 - val_acc: 0.9883\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.02994 to 0.02911, saving model to best.model\n",
      "0s - loss: 0.0616 - acc: 0.9757 - val_loss: 0.0291 - val_acc: 0.9883\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02911 to 0.02836, saving model to best.model\n",
      "0s - loss: 0.0653 - acc: 0.9761 - val_loss: 0.0284 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.02836 to 0.02639, saving model to best.model\n",
      "0s - loss: 0.0627 - acc: 0.9761 - val_loss: 0.0264 - val_acc: 0.9893\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.02639 to 0.02522, saving model to best.model\n",
      "0s - loss: 0.0622 - acc: 0.9747 - val_loss: 0.0252 - val_acc: 0.9893\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0631 - acc: 0.9761 - val_loss: 0.0261 - val_acc: 0.9883\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0612 - acc: 0.9783 - val_loss: 0.0261 - val_acc: 0.9883\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.02522 to 0.02497, saving model to best.model\n",
      "0s - loss: 0.0589 - acc: 0.9783 - val_loss: 0.0250 - val_acc: 0.9893\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9764 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0574 - acc: 0.9783 - val_loss: 0.0256 - val_acc: 0.9912\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0703 - acc: 0.9720 - val_loss: 0.0315 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02497 to 0.02426, saving model to best.model\n",
      "0s - loss: 0.0582 - acc: 0.9774 - val_loss: 0.0243 - val_acc: 0.9912\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.02426 to 0.02397, saving model to best.model\n",
      "0s - loss: 0.0626 - acc: 0.9732 - val_loss: 0.0240 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0578 - acc: 0.9776 - val_loss: 0.0240 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02397 to 0.02073, saving model to best.model\n",
      "0s - loss: 0.0575 - acc: 0.9781 - val_loss: 0.0207 - val_acc: 0.9942\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9791 - val_loss: 0.0214 - val_acc: 0.9912\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02073 to 0.02004, saving model to best.model\n",
      "0s - loss: 0.0585 - acc: 0.9778 - val_loss: 0.0200 - val_acc: 0.9942\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0514 - acc: 0.9820 - val_loss: 0.0239 - val_acc: 0.9893\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02004 to 0.01905, saving model to best.model\n",
      "0s - loss: 0.0566 - acc: 0.9788 - val_loss: 0.0190 - val_acc: 0.9912\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.01905 to 0.01903, saving model to best.model\n",
      "0s - loss: 0.0525 - acc: 0.9803 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9815 - val_loss: 0.0198 - val_acc: 0.9922\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.01903 to 0.01775, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9805 - val_loss: 0.0177 - val_acc: 0.9951\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0498 - acc: 0.9803 - val_loss: 0.0198 - val_acc: 0.9903\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.01775 to 0.01652, saving model to best.model\n",
      "0s - loss: 0.0515 - acc: 0.9793 - val_loss: 0.0165 - val_acc: 0.9961\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9820 - val_loss: 0.0192 - val_acc: 0.9912\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0528 - acc: 0.9805 - val_loss: 0.0169 - val_acc: 0.9942\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.01652 to 0.01528, saving model to best.model\n",
      "0s - loss: 0.0491 - acc: 0.9798 - val_loss: 0.0153 - val_acc: 0.9971\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9810 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0439 - acc: 0.9854 - val_loss: 0.0156 - val_acc: 0.9951\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9803 - val_loss: 0.0221 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.01528 to 0.01522, saving model to best.model\n",
      "0s - loss: 0.0467 - acc: 0.9822 - val_loss: 0.0152 - val_acc: 0.9961\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.01522 to 0.01476, saving model to best.model\n",
      "0s - loss: 0.0511 - acc: 0.9783 - val_loss: 0.0148 - val_acc: 0.9961\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0438 - acc: 0.9844 - val_loss: 0.0168 - val_acc: 0.9922\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01476 to 0.01355, saving model to best.model\n",
      "0s - loss: 0.0445 - acc: 0.9832 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9830 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01355 to 0.01309, saving model to best.model\n",
      "0s - loss: 0.0413 - acc: 0.9832 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0473 - acc: 0.9810 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9849 - val_loss: 0.0155 - val_acc: 0.9922\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.01309 to 0.01204, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9834 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9817 - val_loss: 0.0180 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0440 - acc: 0.9815 - val_loss: 0.0128 - val_acc: 0.9961\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9844 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9820 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9876 - val_loss: 0.0134 - val_acc: 0.9951\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9854 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9854 - val_loss: 0.0124 - val_acc: 0.9961\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9876 - val_loss: 0.0125 - val_acc: 0.9961\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9856 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01204 to 0.01059, saving model to best.model\n",
      "0s - loss: 0.0327 - acc: 0.9866 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0404 - acc: 0.9827 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01059 to 0.00992, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9849 - val_loss: 0.0099 - val_acc: 0.9971\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.00992 to 0.00964, saving model to best.model\n",
      "0s - loss: 0.0408 - acc: 0.9830 - val_loss: 0.0096 - val_acc: 0.9971\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9832 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9861 - val_loss: 0.0114 - val_acc: 0.9971\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9849 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9849 - val_loss: 0.0120 - val_acc: 0.9951\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0428 - acc: 0.9849 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9866 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9866 - val_loss: 0.0119 - val_acc: 0.9951\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.00964 to 0.00952, saving model to best.model\n",
      "0s - loss: 0.0307 - acc: 0.9898 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.00952 to 0.00859, saving model to best.model\n",
      "0s - loss: 0.0377 - acc: 0.9869 - val_loss: 0.0086 - val_acc: 0.9971\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0412 - acc: 0.9842 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9883 - val_loss: 0.0089 - val_acc: 0.9971\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.00859 to 0.00838, saving model to best.model\n",
      "0s - loss: 0.0354 - acc: 0.9876 - val_loss: 0.0084 - val_acc: 0.9971\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9854 - val_loss: 0.0102 - val_acc: 0.9961\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9876 - val_loss: 0.0110 - val_acc: 0.9961\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.00838 to 0.00826, saving model to best.model\n",
      "0s - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9854 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.00826 to 0.00811, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9871 - val_loss: 0.0081 - val_acc: 0.9971\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.00811 to 0.00752, saving model to best.model\n",
      "0s - loss: 0.0318 - acc: 0.9859 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0389 - acc: 0.9871 - val_loss: 0.0081 - val_acc: 0.9971\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9915 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0359 - acc: 0.9871 - val_loss: 0.0091 - val_acc: 0.9961\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9869 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0327 - acc: 0.9866 - val_loss: 0.0077 - val_acc: 0.9971\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9876 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.00752 to 0.00678, saving model to best.model\n",
      "0s - loss: 0.0311 - acc: 0.9876 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9881 - val_loss: 0.0081 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9893 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.00678 to 0.00610, saving model to best.model\n",
      "0s - loss: 0.0243 - acc: 0.9883 - val_loss: 0.0061 - val_acc: 0.9971\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9856 - val_loss: 0.0082 - val_acc: 0.9961\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9888 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.00610 to 0.00606, saving model to best.model\n",
      "0s - loss: 0.0357 - acc: 0.9851 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.00606 to 0.00583, saving model to best.model\n",
      "0s - loss: 0.0304 - acc: 0.9898 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0238 - acc: 0.9912 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0260 - acc: 0.9888 - val_loss: 0.0072 - val_acc: 0.9971\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0269 - acc: 0.9883 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00583 to 0.00545, saving model to best.model\n",
      "0s - loss: 0.0266 - acc: 0.9905 - val_loss: 0.0054 - val_acc: 0.9981\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0240 - acc: 0.9910 - val_loss: 0.0067 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0232 - acc: 0.9920 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.00545 to 0.00479, saving model to best.model\n",
      "0s - loss: 0.0282 - acc: 0.9893 - val_loss: 0.0048 - val_acc: 0.9981\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9895 - val_loss: 0.0062 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0273 - acc: 0.9878 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0258 - acc: 0.9920 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0235 - acc: 0.9917 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9883 - val_loss: 0.0054 - val_acc: 0.9981\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0242 - acc: 0.9910 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0220 - acc: 0.9920 - val_loss: 0.0054 - val_acc: 0.9981\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0204 - acc: 0.9922 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0058 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0206 - acc: 0.9907 - val_loss: 0.0052 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0223 - acc: 0.9915 - val_loss: 0.0052 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67713, saving model to best.model\n",
      "0s - loss: 0.7846 - acc: 0.5118 - val_loss: 0.6771 - val_acc: 0.4742\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67713 to 0.64749, saving model to best.model\n",
      "0s - loss: 0.7431 - acc: 0.5325 - val_loss: 0.6475 - val_acc: 0.7498\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64749 to 0.59969, saving model to best.model\n",
      "0s - loss: 0.6933 - acc: 0.5620 - val_loss: 0.5997 - val_acc: 0.7838\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59969 to 0.52329, saving model to best.model\n",
      "0s - loss: 0.6273 - acc: 0.6430 - val_loss: 0.5233 - val_acc: 0.8053\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52329 to 0.45571, saving model to best.model\n",
      "0s - loss: 0.5456 - acc: 0.7339 - val_loss: 0.4557 - val_acc: 0.8150\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.45571 to 0.41212, saving model to best.model\n",
      "0s - loss: 0.4864 - acc: 0.7775 - val_loss: 0.4121 - val_acc: 0.8364\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41212 to 0.38438, saving model to best.model\n",
      "0s - loss: 0.4419 - acc: 0.8169 - val_loss: 0.3844 - val_acc: 0.8481\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38438 to 0.35689, saving model to best.model\n",
      "0s - loss: 0.4150 - acc: 0.8315 - val_loss: 0.3569 - val_acc: 0.8539\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.35689 to 0.33854, saving model to best.model\n",
      "0s - loss: 0.3937 - acc: 0.8427 - val_loss: 0.3385 - val_acc: 0.8608\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33854 to 0.32434, saving model to best.model\n",
      "0s - loss: 0.3752 - acc: 0.8454 - val_loss: 0.3243 - val_acc: 0.8627\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.32434 to 0.31269, saving model to best.model\n",
      "0s - loss: 0.3611 - acc: 0.8549 - val_loss: 0.3127 - val_acc: 0.8676\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31269 to 0.29726, saving model to best.model\n",
      "0s - loss: 0.3441 - acc: 0.8629 - val_loss: 0.2973 - val_acc: 0.8793\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29726 to 0.28881, saving model to best.model\n",
      "0s - loss: 0.3294 - acc: 0.8685 - val_loss: 0.2888 - val_acc: 0.8861\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.28881 to 0.27580, saving model to best.model\n",
      "0s - loss: 0.3279 - acc: 0.8714 - val_loss: 0.2758 - val_acc: 0.8870\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27580 to 0.26849, saving model to best.model\n",
      "0s - loss: 0.3151 - acc: 0.8734 - val_loss: 0.2685 - val_acc: 0.8929\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26849 to 0.26120, saving model to best.model\n",
      "0s - loss: 0.3043 - acc: 0.8783 - val_loss: 0.2612 - val_acc: 0.8958\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26120 to 0.25363, saving model to best.model\n",
      "0s - loss: 0.2982 - acc: 0.8834 - val_loss: 0.2536 - val_acc: 0.9017\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25363 to 0.24476, saving model to best.model\n",
      "0s - loss: 0.2935 - acc: 0.8826 - val_loss: 0.2448 - val_acc: 0.9075\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24476 to 0.23937, saving model to best.model\n",
      "0s - loss: 0.2869 - acc: 0.8892 - val_loss: 0.2394 - val_acc: 0.9094\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23937 to 0.23533, saving model to best.model\n",
      "0s - loss: 0.2838 - acc: 0.8921 - val_loss: 0.2353 - val_acc: 0.9104\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23533 to 0.22822, saving model to best.model\n",
      "0s - loss: 0.2740 - acc: 0.8951 - val_loss: 0.2282 - val_acc: 0.9114\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22822 to 0.22389, saving model to best.model\n",
      "0s - loss: 0.2727 - acc: 0.8955 - val_loss: 0.2239 - val_acc: 0.9124\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22389 to 0.21978, saving model to best.model\n",
      "0s - loss: 0.2677 - acc: 0.8997 - val_loss: 0.2198 - val_acc: 0.9124\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21978 to 0.21453, saving model to best.model\n",
      "0s - loss: 0.2653 - acc: 0.8955 - val_loss: 0.2145 - val_acc: 0.9260\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21453 to 0.21390, saving model to best.model\n",
      "0s - loss: 0.2575 - acc: 0.9014 - val_loss: 0.2139 - val_acc: 0.9153\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21390 to 0.21068, saving model to best.model\n",
      "0s - loss: 0.2537 - acc: 0.9063 - val_loss: 0.2107 - val_acc: 0.9250\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21068 to 0.20697, saving model to best.model\n",
      "0s - loss: 0.2609 - acc: 0.9011 - val_loss: 0.2070 - val_acc: 0.9231\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20697 to 0.20340, saving model to best.model\n",
      "0s - loss: 0.2513 - acc: 0.9058 - val_loss: 0.2034 - val_acc: 0.9241\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20340 to 0.20038, saving model to best.model\n",
      "0s - loss: 0.2489 - acc: 0.9055 - val_loss: 0.2004 - val_acc: 0.9338\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20038 to 0.19589, saving model to best.model\n",
      "0s - loss: 0.2449 - acc: 0.9092 - val_loss: 0.1959 - val_acc: 0.9309\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19589 to 0.19328, saving model to best.model\n",
      "0s - loss: 0.2383 - acc: 0.9119 - val_loss: 0.1933 - val_acc: 0.9309\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19328 to 0.18963, saving model to best.model\n",
      "0s - loss: 0.2335 - acc: 0.9102 - val_loss: 0.1896 - val_acc: 0.9357\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18963 to 0.18746, saving model to best.model\n",
      "0s - loss: 0.2305 - acc: 0.9143 - val_loss: 0.1875 - val_acc: 0.9377\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18746 to 0.18630, saving model to best.model\n",
      "0s - loss: 0.2264 - acc: 0.9184 - val_loss: 0.1863 - val_acc: 0.9426\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18630 to 0.17899, saving model to best.model\n",
      "0s - loss: 0.2235 - acc: 0.9160 - val_loss: 0.1790 - val_acc: 0.9396\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17899 to 0.17639, saving model to best.model\n",
      "0s - loss: 0.2223 - acc: 0.9155 - val_loss: 0.1764 - val_acc: 0.9396\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.2174 - acc: 0.9226 - val_loss: 0.1779 - val_acc: 0.9328\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17639 to 0.17057, saving model to best.model\n",
      "0s - loss: 0.2159 - acc: 0.9211 - val_loss: 0.1706 - val_acc: 0.9426\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17057 to 0.16833, saving model to best.model\n",
      "0s - loss: 0.2085 - acc: 0.9252 - val_loss: 0.1683 - val_acc: 0.9416\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16833 to 0.16626, saving model to best.model\n",
      "0s - loss: 0.2130 - acc: 0.9238 - val_loss: 0.1663 - val_acc: 0.9396\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16626 to 0.16321, saving model to best.model\n",
      "0s - loss: 0.2101 - acc: 0.9250 - val_loss: 0.1632 - val_acc: 0.9426\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.16321 to 0.16107, saving model to best.model\n",
      "0s - loss: 0.2074 - acc: 0.9211 - val_loss: 0.1611 - val_acc: 0.9494\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.16107 to 0.15800, saving model to best.model\n",
      "0s - loss: 0.1985 - acc: 0.9335 - val_loss: 0.1580 - val_acc: 0.9396\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15800 to 0.15414, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9343 - val_loss: 0.1541 - val_acc: 0.9484\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15414 to 0.15211, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9299 - val_loss: 0.1521 - val_acc: 0.9416\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15211 to 0.14948, saving model to best.model\n",
      "0s - loss: 0.1987 - acc: 0.9304 - val_loss: 0.1495 - val_acc: 0.9513\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14948 to 0.14703, saving model to best.model\n",
      "0s - loss: 0.1905 - acc: 0.9311 - val_loss: 0.1470 - val_acc: 0.9494\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14703 to 0.14579, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9289 - val_loss: 0.1458 - val_acc: 0.9533\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14579 to 0.14517, saving model to best.model\n",
      "0s - loss: 0.1862 - acc: 0.9330 - val_loss: 0.1452 - val_acc: 0.9503\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.14517 to 0.14158, saving model to best.model\n",
      "0s - loss: 0.1865 - acc: 0.9333 - val_loss: 0.1416 - val_acc: 0.9494\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1806 - acc: 0.9386 - val_loss: 0.1424 - val_acc: 0.9416\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.14158 to 0.13689, saving model to best.model\n",
      "0s - loss: 0.1800 - acc: 0.9306 - val_loss: 0.1369 - val_acc: 0.9601\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13689 to 0.13250, saving model to best.model\n",
      "0s - loss: 0.1766 - acc: 0.9355 - val_loss: 0.1325 - val_acc: 0.9601\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13250 to 0.13217, saving model to best.model\n",
      "0s - loss: 0.1815 - acc: 0.9360 - val_loss: 0.1322 - val_acc: 0.9523\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13217 to 0.12754, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9403 - val_loss: 0.1275 - val_acc: 0.9591\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12754 to 0.12468, saving model to best.model\n",
      "0s - loss: 0.1720 - acc: 0.9418 - val_loss: 0.1247 - val_acc: 0.9601\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12468 to 0.12072, saving model to best.model\n",
      "0s - loss: 0.1677 - acc: 0.9401 - val_loss: 0.1207 - val_acc: 0.9630\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12072 to 0.11724, saving model to best.model\n",
      "0s - loss: 0.1616 - acc: 0.9428 - val_loss: 0.1172 - val_acc: 0.9630\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11724 to 0.11450, saving model to best.model\n",
      "0s - loss: 0.1584 - acc: 0.9452 - val_loss: 0.1145 - val_acc: 0.9630\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11450 to 0.11196, saving model to best.model\n",
      "0s - loss: 0.1592 - acc: 0.9421 - val_loss: 0.1120 - val_acc: 0.9630\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11196 to 0.10927, saving model to best.model\n",
      "0s - loss: 0.1592 - acc: 0.9435 - val_loss: 0.1093 - val_acc: 0.9620\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10927 to 0.10626, saving model to best.model\n",
      "0s - loss: 0.1546 - acc: 0.9445 - val_loss: 0.1063 - val_acc: 0.9640\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10626 to 0.10272, saving model to best.model\n",
      "0s - loss: 0.1480 - acc: 0.9474 - val_loss: 0.1027 - val_acc: 0.9640\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10272 to 0.09972, saving model to best.model\n",
      "0s - loss: 0.1407 - acc: 0.9513 - val_loss: 0.0997 - val_acc: 0.9659\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.09972 to 0.09744, saving model to best.model\n",
      "0s - loss: 0.1387 - acc: 0.9533 - val_loss: 0.0974 - val_acc: 0.9659\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09744 to 0.09537, saving model to best.model\n",
      "0s - loss: 0.1417 - acc: 0.9494 - val_loss: 0.0954 - val_acc: 0.9659\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09537 to 0.09273, saving model to best.model\n",
      "0s - loss: 0.1450 - acc: 0.9477 - val_loss: 0.0927 - val_acc: 0.9679\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09273 to 0.09109, saving model to best.model\n",
      "0s - loss: 0.1421 - acc: 0.9472 - val_loss: 0.0911 - val_acc: 0.9669\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09109 to 0.08886, saving model to best.model\n",
      "0s - loss: 0.1287 - acc: 0.9542 - val_loss: 0.0889 - val_acc: 0.9679\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08886 to 0.08560, saving model to best.model\n",
      "0s - loss: 0.1303 - acc: 0.9518 - val_loss: 0.0856 - val_acc: 0.9718\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08560 to 0.08305, saving model to best.model\n",
      "0s - loss: 0.1287 - acc: 0.9528 - val_loss: 0.0831 - val_acc: 0.9718\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08305 to 0.08157, saving model to best.model\n",
      "0s - loss: 0.1320 - acc: 0.9496 - val_loss: 0.0816 - val_acc: 0.9718\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08157 to 0.08030, saving model to best.model\n",
      "0s - loss: 0.1282 - acc: 0.9542 - val_loss: 0.0803 - val_acc: 0.9757\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08030 to 0.08006, saving model to best.model\n",
      "0s - loss: 0.1233 - acc: 0.9564 - val_loss: 0.0801 - val_acc: 0.9718\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08006 to 0.07702, saving model to best.model\n",
      "0s - loss: 0.1282 - acc: 0.9528 - val_loss: 0.0770 - val_acc: 0.9718\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07702 to 0.07491, saving model to best.model\n",
      "0s - loss: 0.1211 - acc: 0.9579 - val_loss: 0.0749 - val_acc: 0.9688\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07491 to 0.07297, saving model to best.model\n",
      "0s - loss: 0.1160 - acc: 0.9574 - val_loss: 0.0730 - val_acc: 0.9766\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07297 to 0.07171, saving model to best.model\n",
      "0s - loss: 0.1147 - acc: 0.9586 - val_loss: 0.0717 - val_acc: 0.9698\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.07171 to 0.06905, saving model to best.model\n",
      "0s - loss: 0.1124 - acc: 0.9574 - val_loss: 0.0691 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06905 to 0.06675, saving model to best.model\n",
      "0s - loss: 0.1114 - acc: 0.9589 - val_loss: 0.0667 - val_acc: 0.9766\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1141 - acc: 0.9610 - val_loss: 0.0687 - val_acc: 0.9825\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.1123 - acc: 0.9586 - val_loss: 0.0670 - val_acc: 0.9786\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1098 - acc: 0.9584 - val_loss: 0.0712 - val_acc: 0.9698\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06675 to 0.06532, saving model to best.model\n",
      "0s - loss: 0.1075 - acc: 0.9620 - val_loss: 0.0653 - val_acc: 0.9786\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06532 to 0.06022, saving model to best.model\n",
      "0s - loss: 0.1040 - acc: 0.9618 - val_loss: 0.0602 - val_acc: 0.9805\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06022 to 0.05812, saving model to best.model\n",
      "0s - loss: 0.0997 - acc: 0.9642 - val_loss: 0.0581 - val_acc: 0.9796\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05812 to 0.05785, saving model to best.model\n",
      "0s - loss: 0.1041 - acc: 0.9635 - val_loss: 0.0578 - val_acc: 0.9805\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05785 to 0.05657, saving model to best.model\n",
      "0s - loss: 0.0956 - acc: 0.9647 - val_loss: 0.0566 - val_acc: 0.9796\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05657 to 0.05585, saving model to best.model\n",
      "0s - loss: 0.0928 - acc: 0.9654 - val_loss: 0.0559 - val_acc: 0.9747\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05585 to 0.05206, saving model to best.model\n",
      "0s - loss: 0.0995 - acc: 0.9632 - val_loss: 0.0521 - val_acc: 0.9805\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05206 to 0.05099, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9683 - val_loss: 0.0510 - val_acc: 0.9825\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05099 to 0.04843, saving model to best.model\n",
      "0s - loss: 0.0973 - acc: 0.9630 - val_loss: 0.0484 - val_acc: 0.9834\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04843 to 0.04695, saving model to best.model\n",
      "0s - loss: 0.0862 - acc: 0.9703 - val_loss: 0.0469 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04695 to 0.04626, saving model to best.model\n",
      "0s - loss: 0.0893 - acc: 0.9676 - val_loss: 0.0463 - val_acc: 0.9844\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04626 to 0.04602, saving model to best.model\n",
      "0s - loss: 0.0938 - acc: 0.9645 - val_loss: 0.0460 - val_acc: 0.9834\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0802 - acc: 0.9705 - val_loss: 0.0460 - val_acc: 0.9844\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04602 to 0.04450, saving model to best.model\n",
      "0s - loss: 0.0898 - acc: 0.9647 - val_loss: 0.0445 - val_acc: 0.9844\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04450 to 0.04369, saving model to best.model\n",
      "0s - loss: 0.0819 - acc: 0.9698 - val_loss: 0.0437 - val_acc: 0.9844\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04369 to 0.04233, saving model to best.model\n",
      "0s - loss: 0.0924 - acc: 0.9630 - val_loss: 0.0423 - val_acc: 0.9854\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0803 - acc: 0.9686 - val_loss: 0.0424 - val_acc: 0.9844\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.04233 to 0.04095, saving model to best.model\n",
      "0s - loss: 0.0788 - acc: 0.9722 - val_loss: 0.0409 - val_acc: 0.9854\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04095 to 0.03950, saving model to best.model\n",
      "0s - loss: 0.0748 - acc: 0.9725 - val_loss: 0.0395 - val_acc: 0.9864\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03950 to 0.03697, saving model to best.model\n",
      "0s - loss: 0.0734 - acc: 0.9720 - val_loss: 0.0370 - val_acc: 0.9873\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03697 to 0.03616, saving model to best.model\n",
      "0s - loss: 0.0797 - acc: 0.9701 - val_loss: 0.0362 - val_acc: 0.9864\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03616 to 0.03594, saving model to best.model\n",
      "0s - loss: 0.0766 - acc: 0.9715 - val_loss: 0.0359 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03594 to 0.03505, saving model to best.model\n",
      "0s - loss: 0.0725 - acc: 0.9705 - val_loss: 0.0351 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0770 - acc: 0.9730 - val_loss: 0.0359 - val_acc: 0.9903\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03505 to 0.03282, saving model to best.model\n",
      "0s - loss: 0.0650 - acc: 0.9781 - val_loss: 0.0328 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03282 to 0.03185, saving model to best.model\n",
      "0s - loss: 0.0718 - acc: 0.9737 - val_loss: 0.0319 - val_acc: 0.9883\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03185 to 0.03174, saving model to best.model\n",
      "0s - loss: 0.0718 - acc: 0.9727 - val_loss: 0.0317 - val_acc: 0.9903\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03174 to 0.03075, saving model to best.model\n",
      "0s - loss: 0.0682 - acc: 0.9752 - val_loss: 0.0307 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03075 to 0.02956, saving model to best.model\n",
      "0s - loss: 0.0606 - acc: 0.9786 - val_loss: 0.0296 - val_acc: 0.9873\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02956 to 0.02903, saving model to best.model\n",
      "0s - loss: 0.0655 - acc: 0.9749 - val_loss: 0.0290 - val_acc: 0.9893\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0678 - acc: 0.9769 - val_loss: 0.0290 - val_acc: 0.9893\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02903 to 0.02763, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9771 - val_loss: 0.0276 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02763 to 0.02737, saving model to best.model\n",
      "0s - loss: 0.0706 - acc: 0.9737 - val_loss: 0.0274 - val_acc: 0.9912\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02737 to 0.02583, saving model to best.model\n",
      "0s - loss: 0.0597 - acc: 0.9766 - val_loss: 0.0258 - val_acc: 0.9912\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02583 to 0.02487, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9778 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0624 - acc: 0.9761 - val_loss: 0.0265 - val_acc: 0.9912\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02487 to 0.02417, saving model to best.model\n",
      "0s - loss: 0.0602 - acc: 0.9778 - val_loss: 0.0242 - val_acc: 0.9903\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9776 - val_loss: 0.0251 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0652 - acc: 0.9764 - val_loss: 0.0248 - val_acc: 0.9912\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0612 - acc: 0.9769 - val_loss: 0.0254 - val_acc: 0.9903\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0689 - acc: 0.9744 - val_loss: 0.0323 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0607 - acc: 0.9769 - val_loss: 0.0277 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0627 - acc: 0.9778 - val_loss: 0.0254 - val_acc: 0.9912\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0533 - acc: 0.9783 - val_loss: 0.0253 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02417 to 0.02247, saving model to best.model\n",
      "0s - loss: 0.0599 - acc: 0.9764 - val_loss: 0.0225 - val_acc: 0.9912\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0518 - acc: 0.9803 - val_loss: 0.0233 - val_acc: 0.9912\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9788 - val_loss: 0.0231 - val_acc: 0.9912\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.02247 to 0.02180, saving model to best.model\n",
      "0s - loss: 0.0517 - acc: 0.9810 - val_loss: 0.0218 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0522 - acc: 0.9813 - val_loss: 0.0220 - val_acc: 0.9912\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02180 to 0.02109, saving model to best.model\n",
      "0s - loss: 0.0541 - acc: 0.9798 - val_loss: 0.0211 - val_acc: 0.9912\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02109 to 0.02094, saving model to best.model\n",
      "0s - loss: 0.0528 - acc: 0.9815 - val_loss: 0.0209 - val_acc: 0.9912\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.02094 to 0.01909, saving model to best.model\n",
      "0s - loss: 0.0519 - acc: 0.9793 - val_loss: 0.0191 - val_acc: 0.9922\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0525 - acc: 0.9788 - val_loss: 0.0235 - val_acc: 0.9903\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0597 - acc: 0.9781 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9810 - val_loss: 0.0195 - val_acc: 0.9912\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01909 to 0.01841, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9813 - val_loss: 0.0184 - val_acc: 0.9912\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9820 - val_loss: 0.0191 - val_acc: 0.9912\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01841 to 0.01687, saving model to best.model\n",
      "0s - loss: 0.0512 - acc: 0.9803 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9815 - val_loss: 0.0176 - val_acc: 0.9912\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01687 to 0.01681, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9825 - val_loss: 0.0168 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01681 to 0.01668, saving model to best.model\n",
      "0s - loss: 0.0519 - acc: 0.9817 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01668 to 0.01592, saving model to best.model\n",
      "0s - loss: 0.0457 - acc: 0.9822 - val_loss: 0.0159 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0464 - acc: 0.9839 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.01592 to 0.01545, saving model to best.model\n",
      "0s - loss: 0.0459 - acc: 0.9844 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0476 - acc: 0.9813 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01545 to 0.01434, saving model to best.model\n",
      "0s - loss: 0.0437 - acc: 0.9813 - val_loss: 0.0143 - val_acc: 0.9922\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0477 - acc: 0.9817 - val_loss: 0.0161 - val_acc: 0.9942\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9832 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0460 - acc: 0.9834 - val_loss: 0.0144 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9847 - val_loss: 0.0152 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01434 to 0.01375, saving model to best.model\n",
      "0s - loss: 0.0426 - acc: 0.9842 - val_loss: 0.0138 - val_acc: 0.9942\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9837 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9849 - val_loss: 0.0140 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01375 to 0.01304, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9849 - val_loss: 0.0130 - val_acc: 0.9932\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9866 - val_loss: 0.0131 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01304 to 0.01242, saving model to best.model\n",
      "0s - loss: 0.0400 - acc: 0.9832 - val_loss: 0.0124 - val_acc: 0.9932\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9854 - val_loss: 0.0129 - val_acc: 0.9932\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9844 - val_loss: 0.0129 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01242 to 0.01199, saving model to best.model\n",
      "0s - loss: 0.0394 - acc: 0.9849 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0361 - acc: 0.9859 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9842 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9861 - val_loss: 0.0134 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01199 to 0.01124, saving model to best.model\n",
      "0s - loss: 0.0397 - acc: 0.9849 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9866 - val_loss: 0.0164 - val_acc: 0.9922\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01124 to 0.01010, saving model to best.model\n",
      "0s - loss: 0.0370 - acc: 0.9864 - val_loss: 0.0101 - val_acc: 0.9951\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9866 - val_loss: 0.0115 - val_acc: 0.9942\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9873 - val_loss: 0.0109 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9847 - val_loss: 0.0132 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0344 - acc: 0.9881 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9876 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9837 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9876 - val_loss: 0.0115 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9873 - val_loss: 0.0106 - val_acc: 0.9951\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9856 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9859 - val_loss: 0.0113 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0393 - acc: 0.9822 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9851 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.01010 to 0.00946, saving model to best.model\n",
      "0s - loss: 0.0310 - acc: 0.9886 - val_loss: 0.0095 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9869 - val_loss: 0.0109 - val_acc: 0.9942\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9876 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9898 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9861 - val_loss: 0.0110 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0334 - acc: 0.9854 - val_loss: 0.0101 - val_acc: 0.9942\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.00946 to 0.00870, saving model to best.model\n",
      "0s - loss: 0.0300 - acc: 0.9893 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9873 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0345 - acc: 0.9854 - val_loss: 0.0092 - val_acc: 0.9961\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00870 to 0.00827, saving model to best.model\n",
      "0s - loss: 0.0287 - acc: 0.9890 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00827 to 0.00760, saving model to best.model\n",
      "0s - loss: 0.0334 - acc: 0.9869 - val_loss: 0.0076 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9893 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9881 - val_loss: 0.0076 - val_acc: 0.9961\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00760 to 0.00722, saving model to best.model\n",
      "0s - loss: 0.0312 - acc: 0.9878 - val_loss: 0.0072 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00722 to 0.00693, saving model to best.model\n",
      "0s - loss: 0.0310 - acc: 0.9878 - val_loss: 0.0069 - val_acc: 0.9961\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00693 to 0.00675, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9890 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9895 - val_loss: 0.0085 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9881 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.00675 to 0.00629, saving model to best.model\n",
      "0s - loss: 0.0266 - acc: 0.9900 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0312 - acc: 0.9893 - val_loss: 0.0069 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67225, saving model to best.model\n",
      "0s - loss: 0.8008 - acc: 0.5103 - val_loss: 0.6723 - val_acc: 0.5278\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67225 to 0.65420, saving model to best.model\n",
      "0s - loss: 0.7383 - acc: 0.5386 - val_loss: 0.6542 - val_acc: 0.6904\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65420 to 0.61317, saving model to best.model\n",
      "0s - loss: 0.6881 - acc: 0.5776 - val_loss: 0.6132 - val_acc: 0.7585\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61317 to 0.54469, saving model to best.model\n",
      "0s - loss: 0.6323 - acc: 0.6484 - val_loss: 0.5447 - val_acc: 0.7809\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54469 to 0.47306, saving model to best.model\n",
      "0s - loss: 0.5594 - acc: 0.7202 - val_loss: 0.4731 - val_acc: 0.8023\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47306 to 0.43231, saving model to best.model\n",
      "0s - loss: 0.5037 - acc: 0.7719 - val_loss: 0.4323 - val_acc: 0.8160\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.43231 to 0.39287, saving model to best.model\n",
      "0s - loss: 0.4576 - acc: 0.8079 - val_loss: 0.3929 - val_acc: 0.8403\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.39287 to 0.36640, saving model to best.model\n",
      "0s - loss: 0.4148 - acc: 0.8322 - val_loss: 0.3664 - val_acc: 0.8471\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36640 to 0.34934, saving model to best.model\n",
      "0s - loss: 0.3918 - acc: 0.8391 - val_loss: 0.3493 - val_acc: 0.8510\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34934 to 0.33268, saving model to best.model\n",
      "0s - loss: 0.3682 - acc: 0.8527 - val_loss: 0.3327 - val_acc: 0.8530\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.33268 to 0.31702, saving model to best.model\n",
      "0s - loss: 0.3582 - acc: 0.8578 - val_loss: 0.3170 - val_acc: 0.8598\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.31702 to 0.29840, saving model to best.model\n",
      "0s - loss: 0.3309 - acc: 0.8678 - val_loss: 0.2984 - val_acc: 0.8685\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29840 to 0.28440, saving model to best.model\n",
      "0s - loss: 0.3248 - acc: 0.8773 - val_loss: 0.2844 - val_acc: 0.8822\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.28440 to 0.27982, saving model to best.model\n",
      "0s - loss: 0.3122 - acc: 0.8763 - val_loss: 0.2798 - val_acc: 0.8812\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27982 to 0.26665, saving model to best.model\n",
      "0s - loss: 0.3070 - acc: 0.8858 - val_loss: 0.2667 - val_acc: 0.8919\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26665 to 0.26027, saving model to best.model\n",
      "0s - loss: 0.2990 - acc: 0.8831 - val_loss: 0.2603 - val_acc: 0.8948\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.2970 - acc: 0.8826 - val_loss: 0.2609 - val_acc: 0.9007\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.26027 to 0.25010, saving model to best.model\n",
      "0s - loss: 0.2937 - acc: 0.8865 - val_loss: 0.2501 - val_acc: 0.8978\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.25010 to 0.24490, saving model to best.model\n",
      "0s - loss: 0.2728 - acc: 0.8972 - val_loss: 0.2449 - val_acc: 0.9065\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24490 to 0.23534, saving model to best.model\n",
      "0s - loss: 0.2723 - acc: 0.8980 - val_loss: 0.2353 - val_acc: 0.9065\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23534 to 0.23021, saving model to best.model\n",
      "0s - loss: 0.2653 - acc: 0.8992 - val_loss: 0.2302 - val_acc: 0.9085\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.23021 to 0.22319, saving model to best.model\n",
      "0s - loss: 0.2527 - acc: 0.9028 - val_loss: 0.2232 - val_acc: 0.9143\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22319 to 0.21867, saving model to best.model\n",
      "0s - loss: 0.2548 - acc: 0.9048 - val_loss: 0.2187 - val_acc: 0.9163\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21867 to 0.21526, saving model to best.model\n",
      "0s - loss: 0.2538 - acc: 0.9043 - val_loss: 0.2153 - val_acc: 0.9163\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21526 to 0.21279, saving model to best.model\n",
      "0s - loss: 0.2442 - acc: 0.9080 - val_loss: 0.2128 - val_acc: 0.9124\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21279 to 0.20715, saving model to best.model\n",
      "0s - loss: 0.2437 - acc: 0.9145 - val_loss: 0.2072 - val_acc: 0.9192\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20715 to 0.20224, saving model to best.model\n",
      "0s - loss: 0.2387 - acc: 0.9126 - val_loss: 0.2022 - val_acc: 0.9221\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20224 to 0.19935, saving model to best.model\n",
      "0s - loss: 0.2308 - acc: 0.9131 - val_loss: 0.1994 - val_acc: 0.9279\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2319 - acc: 0.9136 - val_loss: 0.2014 - val_acc: 0.9094\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19935 to 0.19498, saving model to best.model\n",
      "0s - loss: 0.2286 - acc: 0.9158 - val_loss: 0.1950 - val_acc: 0.9182\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19498 to 0.18684, saving model to best.model\n",
      "0s - loss: 0.2236 - acc: 0.9165 - val_loss: 0.1868 - val_acc: 0.9289\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.2198 - acc: 0.9182 - val_loss: 0.1878 - val_acc: 0.9192\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18684 to 0.17901, saving model to best.model\n",
      "0s - loss: 0.2142 - acc: 0.9150 - val_loss: 0.1790 - val_acc: 0.9299\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17901 to 0.17516, saving model to best.model\n",
      "0s - loss: 0.2084 - acc: 0.9228 - val_loss: 0.1752 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17516 to 0.17090, saving model to best.model\n",
      "0s - loss: 0.2084 - acc: 0.9231 - val_loss: 0.1709 - val_acc: 0.9318\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17090 to 0.16676, saving model to best.model\n",
      "0s - loss: 0.1974 - acc: 0.9284 - val_loss: 0.1668 - val_acc: 0.9464\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16676 to 0.16322, saving model to best.model\n",
      "0s - loss: 0.1975 - acc: 0.9243 - val_loss: 0.1632 - val_acc: 0.9396\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.1932 - acc: 0.9282 - val_loss: 0.1640 - val_acc: 0.9309\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16322 to 0.15744, saving model to best.model\n",
      "0s - loss: 0.1936 - acc: 0.9284 - val_loss: 0.1574 - val_acc: 0.9464\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15744 to 0.15384, saving model to best.model\n",
      "0s - loss: 0.1860 - acc: 0.9282 - val_loss: 0.1538 - val_acc: 0.9562\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15384 to 0.14783, saving model to best.model\n",
      "0s - loss: 0.1831 - acc: 0.9301 - val_loss: 0.1478 - val_acc: 0.9513\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14783 to 0.14518, saving model to best.model\n",
      "0s - loss: 0.1846 - acc: 0.9296 - val_loss: 0.1452 - val_acc: 0.9533\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1775 - acc: 0.9364 - val_loss: 0.1457 - val_acc: 0.9416\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14518 to 0.13994, saving model to best.model\n",
      "0s - loss: 0.1748 - acc: 0.9360 - val_loss: 0.1399 - val_acc: 0.9601\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13994 to 0.13671, saving model to best.model\n",
      "0s - loss: 0.1737 - acc: 0.9367 - val_loss: 0.1367 - val_acc: 0.9611\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.13671 to 0.13351, saving model to best.model\n",
      "0s - loss: 0.1686 - acc: 0.9362 - val_loss: 0.1335 - val_acc: 0.9542\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13351 to 0.13224, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9367 - val_loss: 0.1322 - val_acc: 0.9513\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13224 to 0.12969, saving model to best.model\n",
      "0s - loss: 0.1648 - acc: 0.9440 - val_loss: 0.1297 - val_acc: 0.9513\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12969 to 0.12480, saving model to best.model\n",
      "0s - loss: 0.1571 - acc: 0.9433 - val_loss: 0.1248 - val_acc: 0.9649\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12480 to 0.12254, saving model to best.model\n",
      "0s - loss: 0.1582 - acc: 0.9408 - val_loss: 0.1225 - val_acc: 0.9679\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1473 - acc: 0.9430 - val_loss: 0.1249 - val_acc: 0.9455\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12254 to 0.11368, saving model to best.model\n",
      "0s - loss: 0.1499 - acc: 0.9440 - val_loss: 0.1137 - val_acc: 0.9708\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.11368 to 0.10894, saving model to best.model\n",
      "0s - loss: 0.1459 - acc: 0.9469 - val_loss: 0.1089 - val_acc: 0.9659\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10894 to 0.10891, saving model to best.model\n",
      "0s - loss: 0.1470 - acc: 0.9467 - val_loss: 0.1089 - val_acc: 0.9552\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10891 to 0.10145, saving model to best.model\n",
      "0s - loss: 0.1405 - acc: 0.9486 - val_loss: 0.1015 - val_acc: 0.9669\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.1376 - acc: 0.9467 - val_loss: 0.1019 - val_acc: 0.9649\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10145 to 0.09966, saving model to best.model\n",
      "0s - loss: 0.1360 - acc: 0.9523 - val_loss: 0.0997 - val_acc: 0.9669\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09966 to 0.09565, saving model to best.model\n",
      "0s - loss: 0.1348 - acc: 0.9494 - val_loss: 0.0957 - val_acc: 0.9727\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09565 to 0.09142, saving model to best.model\n",
      "0s - loss: 0.1318 - acc: 0.9525 - val_loss: 0.0914 - val_acc: 0.9727\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09142 to 0.08883, saving model to best.model\n",
      "0s - loss: 0.1420 - acc: 0.9469 - val_loss: 0.0888 - val_acc: 0.9727\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08883 to 0.08569, saving model to best.model\n",
      "0s - loss: 0.1255 - acc: 0.9545 - val_loss: 0.0857 - val_acc: 0.9737\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.08569 to 0.08272, saving model to best.model\n",
      "0s - loss: 0.1299 - acc: 0.9506 - val_loss: 0.0827 - val_acc: 0.9747\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08272 to 0.08021, saving model to best.model\n",
      "0s - loss: 0.1160 - acc: 0.9571 - val_loss: 0.0802 - val_acc: 0.9747\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08021 to 0.07817, saving model to best.model\n",
      "0s - loss: 0.1109 - acc: 0.9615 - val_loss: 0.0782 - val_acc: 0.9737\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.07817 to 0.07583, saving model to best.model\n",
      "0s - loss: 0.1082 - acc: 0.9598 - val_loss: 0.0758 - val_acc: 0.9757\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.1197 - acc: 0.9576 - val_loss: 0.0770 - val_acc: 0.9776\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07583 to 0.07106, saving model to best.model\n",
      "0s - loss: 0.1145 - acc: 0.9586 - val_loss: 0.0711 - val_acc: 0.9805\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07106 to 0.06950, saving model to best.model\n",
      "0s - loss: 0.1061 - acc: 0.9598 - val_loss: 0.0695 - val_acc: 0.9805\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.06950 to 0.06650, saving model to best.model\n",
      "0s - loss: 0.1099 - acc: 0.9632 - val_loss: 0.0665 - val_acc: 0.9805\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.06650 to 0.06394, saving model to best.model\n",
      "0s - loss: 0.1012 - acc: 0.9589 - val_loss: 0.0639 - val_acc: 0.9834\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06394 to 0.06336, saving model to best.model\n",
      "0s - loss: 0.1062 - acc: 0.9593 - val_loss: 0.0634 - val_acc: 0.9796\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06336 to 0.06086, saving model to best.model\n",
      "0s - loss: 0.0980 - acc: 0.9647 - val_loss: 0.0609 - val_acc: 0.9834\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.06086 to 0.05961, saving model to best.model\n",
      "0s - loss: 0.0977 - acc: 0.9659 - val_loss: 0.0596 - val_acc: 0.9844\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.05961 to 0.05914, saving model to best.model\n",
      "0s - loss: 0.0958 - acc: 0.9618 - val_loss: 0.0591 - val_acc: 0.9844\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.05914 to 0.05548, saving model to best.model\n",
      "0s - loss: 0.0907 - acc: 0.9632 - val_loss: 0.0555 - val_acc: 0.9844\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.0913 - acc: 0.9657 - val_loss: 0.0606 - val_acc: 0.9757\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1009 - acc: 0.9610 - val_loss: 0.0571 - val_acc: 0.9864\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.0980 - acc: 0.9630 - val_loss: 0.0566 - val_acc: 0.9883\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05548 to 0.05440, saving model to best.model\n",
      "0s - loss: 0.0917 - acc: 0.9674 - val_loss: 0.0544 - val_acc: 0.9873\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05440 to 0.05389, saving model to best.model\n",
      "0s - loss: 0.0886 - acc: 0.9662 - val_loss: 0.0539 - val_acc: 0.9844\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05389 to 0.05092, saving model to best.model\n",
      "0s - loss: 0.0842 - acc: 0.9705 - val_loss: 0.0509 - val_acc: 0.9873\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05092 to 0.04862, saving model to best.model\n",
      "0s - loss: 0.0905 - acc: 0.9669 - val_loss: 0.0486 - val_acc: 0.9883\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04862 to 0.04737, saving model to best.model\n",
      "0s - loss: 0.0868 - acc: 0.9676 - val_loss: 0.0474 - val_acc: 0.9883\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.04737 to 0.04715, saving model to best.model\n",
      "0s - loss: 0.0821 - acc: 0.9683 - val_loss: 0.0472 - val_acc: 0.9854\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04715 to 0.04698, saving model to best.model\n",
      "0s - loss: 0.0780 - acc: 0.9715 - val_loss: 0.0470 - val_acc: 0.9873\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04698 to 0.04472, saving model to best.model\n",
      "0s - loss: 0.0797 - acc: 0.9701 - val_loss: 0.0447 - val_acc: 0.9883\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04472 to 0.04361, saving model to best.model\n",
      "0s - loss: 0.0812 - acc: 0.9669 - val_loss: 0.0436 - val_acc: 0.9903\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04361 to 0.04220, saving model to best.model\n",
      "0s - loss: 0.0828 - acc: 0.9701 - val_loss: 0.0422 - val_acc: 0.9903\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.04220 to 0.04170, saving model to best.model\n",
      "0s - loss: 0.0735 - acc: 0.9713 - val_loss: 0.0417 - val_acc: 0.9912\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0786 - acc: 0.9705 - val_loss: 0.0444 - val_acc: 0.9854\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04170 to 0.03911, saving model to best.model\n",
      "0s - loss: 0.0792 - acc: 0.9696 - val_loss: 0.0391 - val_acc: 0.9893\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.03911 to 0.03906, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9759 - val_loss: 0.0391 - val_acc: 0.9912\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03906 to 0.03763, saving model to best.model\n",
      "0s - loss: 0.0710 - acc: 0.9742 - val_loss: 0.0376 - val_acc: 0.9912\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0688 - acc: 0.9749 - val_loss: 0.0385 - val_acc: 0.9893\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.03763 to 0.03440, saving model to best.model\n",
      "0s - loss: 0.0663 - acc: 0.9766 - val_loss: 0.0344 - val_acc: 0.9903\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.03440 to 0.03296, saving model to best.model\n",
      "0s - loss: 0.0607 - acc: 0.9783 - val_loss: 0.0330 - val_acc: 0.9932\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0641 - acc: 0.9791 - val_loss: 0.0348 - val_acc: 0.9903\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.03296 to 0.03196, saving model to best.model\n",
      "0s - loss: 0.0732 - acc: 0.9722 - val_loss: 0.0320 - val_acc: 0.9922\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0719 - acc: 0.9742 - val_loss: 0.0327 - val_acc: 0.9903\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0644 - acc: 0.9744 - val_loss: 0.0344 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9747 - val_loss: 0.0322 - val_acc: 0.9912\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03196 to 0.03047, saving model to best.model\n",
      "0s - loss: 0.0572 - acc: 0.9786 - val_loss: 0.0305 - val_acc: 0.9932\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0575 - acc: 0.9791 - val_loss: 0.0321 - val_acc: 0.9912\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0640 - acc: 0.9776 - val_loss: 0.0317 - val_acc: 0.9912\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0639 - acc: 0.9744 - val_loss: 0.0309 - val_acc: 0.9912\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03047 to 0.02966, saving model to best.model\n",
      "0s - loss: 0.0647 - acc: 0.9774 - val_loss: 0.0297 - val_acc: 0.9912\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0540 - acc: 0.9795 - val_loss: 0.0307 - val_acc: 0.9903\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0639 - acc: 0.9771 - val_loss: 0.0300 - val_acc: 0.9903\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02966 to 0.02841, saving model to best.model\n",
      "0s - loss: 0.0570 - acc: 0.9795 - val_loss: 0.0284 - val_acc: 0.9912\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0583 - acc: 0.9793 - val_loss: 0.0317 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02841 to 0.02765, saving model to best.model\n",
      "0s - loss: 0.0686 - acc: 0.9722 - val_loss: 0.0276 - val_acc: 0.9922\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02765 to 0.02737, saving model to best.model\n",
      "0s - loss: 0.0531 - acc: 0.9805 - val_loss: 0.0274 - val_acc: 0.9912\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02737 to 0.02706, saving model to best.model\n",
      "0s - loss: 0.0545 - acc: 0.9793 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02706 to 0.02626, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9783 - val_loss: 0.0263 - val_acc: 0.9932\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02626 to 0.02561, saving model to best.model\n",
      "0s - loss: 0.0490 - acc: 0.9830 - val_loss: 0.0256 - val_acc: 0.9912\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02561 to 0.02422, saving model to best.model\n",
      "0s - loss: 0.0579 - acc: 0.9761 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02422 to 0.02310, saving model to best.model\n",
      "0s - loss: 0.0499 - acc: 0.9822 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9856 - val_loss: 0.0237 - val_acc: 0.9932\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0585 - acc: 0.9783 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.02310 to 0.02307, saving model to best.model\n",
      "0s - loss: 0.0509 - acc: 0.9815 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0479 - acc: 0.9832 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9827 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02307 to 0.02189, saving model to best.model\n",
      "0s - loss: 0.0525 - acc: 0.9842 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02189 to 0.02086, saving model to best.model\n",
      "0s - loss: 0.0466 - acc: 0.9817 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9817 - val_loss: 0.0276 - val_acc: 0.9922\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9815 - val_loss: 0.0210 - val_acc: 0.9932\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0424 - acc: 0.9825 - val_loss: 0.0219 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9847 - val_loss: 0.0215 - val_acc: 0.9922\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9844 - val_loss: 0.0217 - val_acc: 0.9912\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02086 to 0.02003, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9844 - val_loss: 0.0200 - val_acc: 0.9942\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9876 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02003 to 0.01887, saving model to best.model\n",
      "0s - loss: 0.0429 - acc: 0.9847 - val_loss: 0.0189 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0414 - acc: 0.9861 - val_loss: 0.0204 - val_acc: 0.9922\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9822 - val_loss: 0.0241 - val_acc: 0.9922\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9856 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9851 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0396 - acc: 0.9856 - val_loss: 0.0196 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.01887 to 0.01779, saving model to best.model\n",
      "0s - loss: 0.0438 - acc: 0.9856 - val_loss: 0.0178 - val_acc: 0.9932\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01779 to 0.01732, saving model to best.model\n",
      "0s - loss: 0.0421 - acc: 0.9851 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9869 - val_loss: 0.0180 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9859 - val_loss: 0.0197 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9844 - val_loss: 0.0190 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9869 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0416 - acc: 0.9832 - val_loss: 0.0174 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01732 to 0.01630, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9873 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01630 to 0.01542, saving model to best.model\n",
      "0s - loss: 0.0338 - acc: 0.9876 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.01542 to 0.01362, saving model to best.model\n",
      "0s - loss: 0.0387 - acc: 0.9849 - val_loss: 0.0136 - val_acc: 0.9961\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0400 - acc: 0.9856 - val_loss: 0.0140 - val_acc: 0.9971\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9854 - val_loss: 0.0149 - val_acc: 0.9932\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9883 - val_loss: 0.0167 - val_acc: 0.9922\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9888 - val_loss: 0.0163 - val_acc: 0.9922\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9839 - val_loss: 0.0156 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9871 - val_loss: 0.0145 - val_acc: 0.9951\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9866 - val_loss: 0.0155 - val_acc: 0.9951\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9893 - val_loss: 0.0143 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01362 to 0.01310, saving model to best.model\n",
      "0s - loss: 0.0351 - acc: 0.9873 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01310 to 0.01297, saving model to best.model\n",
      "0s - loss: 0.0368 - acc: 0.9871 - val_loss: 0.0130 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9859 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9871 - val_loss: 0.0142 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0340 - acc: 0.9873 - val_loss: 0.0153 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9827 - val_loss: 0.0155 - val_acc: 0.9951\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0367 - acc: 0.9876 - val_loss: 0.0147 - val_acc: 0.9951\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9886 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9878 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9876 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.01297 to 0.01259, saving model to best.model\n",
      "0s - loss: 0.0344 - acc: 0.9878 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9878 - val_loss: 0.0136 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9825 - val_loss: 0.0149 - val_acc: 0.9951\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0141 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.01259 to 0.01221, saving model to best.model\n",
      "0s - loss: 0.0354 - acc: 0.9864 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01221 to 0.01196, saving model to best.model\n",
      "0s - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0120 - val_acc: 0.9961\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01196 to 0.01174, saving model to best.model\n",
      "0s - loss: 0.0325 - acc: 0.9878 - val_loss: 0.0117 - val_acc: 0.9961\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0238 - acc: 0.9912 - val_loss: 0.0123 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01174 to 0.01142, saving model to best.model\n",
      "0s - loss: 0.0268 - acc: 0.9903 - val_loss: 0.0114 - val_acc: 0.9961\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.01142 to 0.01139, saving model to best.model\n",
      "0s - loss: 0.0254 - acc: 0.9903 - val_loss: 0.0114 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9907 - val_loss: 0.0114 - val_acc: 0.9971\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01139 to 0.01112, saving model to best.model\n",
      "0s - loss: 0.0292 - acc: 0.9886 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9900 - val_loss: 0.0116 - val_acc: 0.9971\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01112 to 0.01097, saving model to best.model\n",
      "0s - loss: 0.0283 - acc: 0.9893 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9881 - val_loss: 0.0113 - val_acc: 0.9971\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9888 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01097 to 0.01011, saving model to best.model\n",
      "0s - loss: 0.0252 - acc: 0.9898 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01011 to 0.00978, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9905 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9873 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0106 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9886 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9895 - val_loss: 0.0110 - val_acc: 0.9971\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9886 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0266 - acc: 0.9898 - val_loss: 0.0100 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00978 to 0.00937, saving model to best.model\n",
      "0s - loss: 0.0222 - acc: 0.9907 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00937 to 0.00907, saving model to best.model\n",
      "0s - loss: 0.0260 - acc: 0.9900 - val_loss: 0.0091 - val_acc: 0.9981\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9898 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0220 - acc: 0.9934 - val_loss: 0.0111 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9898 - val_loss: 0.0101 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9886 - val_loss: 0.0110 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9895 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9900 - val_loss: 0.0115 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9903 - val_loss: 0.0097 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0242 - acc: 0.9907 - val_loss: 0.0099 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0103 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67722, saving model to best.model\n",
      "0s - loss: 0.8165 - acc: 0.5009 - val_loss: 0.6772 - val_acc: 0.5054\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67722 to 0.65550, saving model to best.model\n",
      "0s - loss: 0.7562 - acc: 0.5211 - val_loss: 0.6555 - val_acc: 0.7089\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65550 to 0.61465, saving model to best.model\n",
      "0s - loss: 0.7102 - acc: 0.5673 - val_loss: 0.6147 - val_acc: 0.7439\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61465 to 0.54937, saving model to best.model\n",
      "0s - loss: 0.6503 - acc: 0.6138 - val_loss: 0.5494 - val_acc: 0.7955\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54937 to 0.47058, saving model to best.model\n",
      "0s - loss: 0.5837 - acc: 0.6988 - val_loss: 0.4706 - val_acc: 0.8218\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47058 to 0.40231, saving model to best.model\n",
      "0s - loss: 0.5163 - acc: 0.7565 - val_loss: 0.4023 - val_acc: 0.8393\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40231 to 0.37353, saving model to best.model\n",
      "0s - loss: 0.4711 - acc: 0.7921 - val_loss: 0.3735 - val_acc: 0.8442\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37353 to 0.33506, saving model to best.model\n",
      "0s - loss: 0.4221 - acc: 0.8237 - val_loss: 0.3351 - val_acc: 0.8773\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33506 to 0.31083, saving model to best.model\n",
      "0s - loss: 0.4016 - acc: 0.8352 - val_loss: 0.3108 - val_acc: 0.8841\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31083 to 0.29975, saving model to best.model\n",
      "0s - loss: 0.3751 - acc: 0.8488 - val_loss: 0.2998 - val_acc: 0.8890\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29975 to 0.28698, saving model to best.model\n",
      "0s - loss: 0.3530 - acc: 0.8590 - val_loss: 0.2870 - val_acc: 0.8919\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28698 to 0.27223, saving model to best.model\n",
      "0s - loss: 0.3515 - acc: 0.8634 - val_loss: 0.2722 - val_acc: 0.8939\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27223 to 0.26311, saving model to best.model\n",
      "0s - loss: 0.3361 - acc: 0.8736 - val_loss: 0.2631 - val_acc: 0.8948\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26311 to 0.25657, saving model to best.model\n",
      "0s - loss: 0.3205 - acc: 0.8766 - val_loss: 0.2566 - val_acc: 0.9046\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25657 to 0.25065, saving model to best.model\n",
      "0s - loss: 0.3156 - acc: 0.8880 - val_loss: 0.2507 - val_acc: 0.9104\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25065 to 0.25024, saving model to best.model\n",
      "0s - loss: 0.3080 - acc: 0.8831 - val_loss: 0.2502 - val_acc: 0.9075\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25024 to 0.24799, saving model to best.model\n",
      "0s - loss: 0.3072 - acc: 0.8873 - val_loss: 0.2480 - val_acc: 0.9085\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24799 to 0.23782, saving model to best.model\n",
      "0s - loss: 0.2951 - acc: 0.8931 - val_loss: 0.2378 - val_acc: 0.9172\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23782 to 0.23636, saving model to best.model\n",
      "0s - loss: 0.2984 - acc: 0.8887 - val_loss: 0.2364 - val_acc: 0.9153\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23636 to 0.23036, saving model to best.model\n",
      "0s - loss: 0.2814 - acc: 0.8955 - val_loss: 0.2304 - val_acc: 0.9182\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23036 to 0.22690, saving model to best.model\n",
      "0s - loss: 0.2846 - acc: 0.8980 - val_loss: 0.2269 - val_acc: 0.9221\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2764 - acc: 0.9021 - val_loss: 0.2299 - val_acc: 0.9202\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22690 to 0.22353, saving model to best.model\n",
      "0s - loss: 0.2737 - acc: 0.9043 - val_loss: 0.2235 - val_acc: 0.9202\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22353 to 0.21826, saving model to best.model\n",
      "0s - loss: 0.2754 - acc: 0.9038 - val_loss: 0.2183 - val_acc: 0.9250\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21826 to 0.21795, saving model to best.model\n",
      "0s - loss: 0.2581 - acc: 0.9084 - val_loss: 0.2179 - val_acc: 0.9250\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21795 to 0.21194, saving model to best.model\n",
      "0s - loss: 0.2570 - acc: 0.9063 - val_loss: 0.2119 - val_acc: 0.9241\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21194 to 0.21011, saving model to best.model\n",
      "0s - loss: 0.2583 - acc: 0.9082 - val_loss: 0.2101 - val_acc: 0.9270\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21011 to 0.20875, saving model to best.model\n",
      "0s - loss: 0.2502 - acc: 0.9094 - val_loss: 0.2087 - val_acc: 0.9279\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20875 to 0.20538, saving model to best.model\n",
      "0s - loss: 0.2544 - acc: 0.9065 - val_loss: 0.2054 - val_acc: 0.9270\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2586 - acc: 0.9092 - val_loss: 0.2088 - val_acc: 0.9260\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20538 to 0.19923, saving model to best.model\n",
      "0s - loss: 0.2472 - acc: 0.9119 - val_loss: 0.1992 - val_acc: 0.9250\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19923 to 0.19803, saving model to best.model\n",
      "0s - loss: 0.2447 - acc: 0.9133 - val_loss: 0.1980 - val_acc: 0.9270\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2440 - acc: 0.9104 - val_loss: 0.2014 - val_acc: 0.9260\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19803 to 0.19233, saving model to best.model\n",
      "0s - loss: 0.2370 - acc: 0.9114 - val_loss: 0.1923 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.19233 to 0.18904, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9167 - val_loss: 0.1890 - val_acc: 0.9279\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.2348 - acc: 0.9162 - val_loss: 0.1952 - val_acc: 0.9299\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18904 to 0.18587, saving model to best.model\n",
      "0s - loss: 0.2275 - acc: 0.9165 - val_loss: 0.1859 - val_acc: 0.9309\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.18587 to 0.18040, saving model to best.model\n",
      "0s - loss: 0.2207 - acc: 0.9179 - val_loss: 0.1804 - val_acc: 0.9279\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.18040 to 0.17799, saving model to best.model\n",
      "0s - loss: 0.2213 - acc: 0.9226 - val_loss: 0.1780 - val_acc: 0.9299\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17799 to 0.17792, saving model to best.model\n",
      "0s - loss: 0.2130 - acc: 0.9182 - val_loss: 0.1779 - val_acc: 0.9289\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17792 to 0.17263, saving model to best.model\n",
      "0s - loss: 0.2129 - acc: 0.9240 - val_loss: 0.1726 - val_acc: 0.9309\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.17263 to 0.17108, saving model to best.model\n",
      "0s - loss: 0.2201 - acc: 0.9199 - val_loss: 0.1711 - val_acc: 0.9309\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.17108 to 0.16651, saving model to best.model\n",
      "0s - loss: 0.2069 - acc: 0.9182 - val_loss: 0.1665 - val_acc: 0.9348\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16651 to 0.16319, saving model to best.model\n",
      "0s - loss: 0.2067 - acc: 0.9240 - val_loss: 0.1632 - val_acc: 0.9338\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.16319 to 0.15894, saving model to best.model\n",
      "0s - loss: 0.2048 - acc: 0.9211 - val_loss: 0.1589 - val_acc: 0.9357\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.2018 - acc: 0.9243 - val_loss: 0.1602 - val_acc: 0.9299\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.15894 to 0.15341, saving model to best.model\n",
      "0s - loss: 0.1987 - acc: 0.9226 - val_loss: 0.1534 - val_acc: 0.9367\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15341 to 0.15052, saving model to best.model\n",
      "0s - loss: 0.1931 - acc: 0.9248 - val_loss: 0.1505 - val_acc: 0.9367\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1969 - acc: 0.9238 - val_loss: 0.1507 - val_acc: 0.9338\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.15052 to 0.14625, saving model to best.model\n",
      "0s - loss: 0.1947 - acc: 0.9231 - val_loss: 0.1462 - val_acc: 0.9357\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.14625 to 0.14384, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9279 - val_loss: 0.1438 - val_acc: 0.9357\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1849 - acc: 0.9279 - val_loss: 0.1466 - val_acc: 0.9377\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14384 to 0.13943, saving model to best.model\n",
      "0s - loss: 0.1867 - acc: 0.9270 - val_loss: 0.1394 - val_acc: 0.9367\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.13943 to 0.13704, saving model to best.model\n",
      "0s - loss: 0.1785 - acc: 0.9291 - val_loss: 0.1370 - val_acc: 0.9377\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13704 to 0.13503, saving model to best.model\n",
      "0s - loss: 0.1784 - acc: 0.9240 - val_loss: 0.1350 - val_acc: 0.9377\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13503 to 0.12966, saving model to best.model\n",
      "0s - loss: 0.1749 - acc: 0.9289 - val_loss: 0.1297 - val_acc: 0.9426\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12966 to 0.12758, saving model to best.model\n",
      "0s - loss: 0.1694 - acc: 0.9340 - val_loss: 0.1276 - val_acc: 0.9445\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12758 to 0.12566, saving model to best.model\n",
      "0s - loss: 0.1685 - acc: 0.9316 - val_loss: 0.1257 - val_acc: 0.9455\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1677 - acc: 0.9318 - val_loss: 0.1286 - val_acc: 0.9396\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.12566 to 0.11992, saving model to best.model\n",
      "0s - loss: 0.1589 - acc: 0.9355 - val_loss: 0.1199 - val_acc: 0.9533\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1514 - acc: 0.9377 - val_loss: 0.1232 - val_acc: 0.9416\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.11992 to 0.11451, saving model to best.model\n",
      "0s - loss: 0.1587 - acc: 0.9299 - val_loss: 0.1145 - val_acc: 0.9533\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.11451 to 0.11239, saving model to best.model\n",
      "0s - loss: 0.1535 - acc: 0.9362 - val_loss: 0.1124 - val_acc: 0.9503\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.11239 to 0.11002, saving model to best.model\n",
      "0s - loss: 0.1471 - acc: 0.9406 - val_loss: 0.1100 - val_acc: 0.9503\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.11002 to 0.10652, saving model to best.model\n",
      "0s - loss: 0.1500 - acc: 0.9386 - val_loss: 0.1065 - val_acc: 0.9494\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10652 to 0.10314, saving model to best.model\n",
      "0s - loss: 0.1406 - acc: 0.9423 - val_loss: 0.1031 - val_acc: 0.9513\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.10314 to 0.09907, saving model to best.model\n",
      "0s - loss: 0.1367 - acc: 0.9433 - val_loss: 0.0991 - val_acc: 0.9581\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09907 to 0.09895, saving model to best.model\n",
      "0s - loss: 0.1398 - acc: 0.9440 - val_loss: 0.0990 - val_acc: 0.9533\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09895 to 0.09508, saving model to best.model\n",
      "0s - loss: 0.1336 - acc: 0.9435 - val_loss: 0.0951 - val_acc: 0.9649\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09508 to 0.09231, saving model to best.model\n",
      "0s - loss: 0.1405 - acc: 0.9433 - val_loss: 0.0923 - val_acc: 0.9669\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.09231 to 0.08947, saving model to best.model\n",
      "0s - loss: 0.1252 - acc: 0.9511 - val_loss: 0.0895 - val_acc: 0.9679\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08947 to 0.08663, saving model to best.model\n",
      "0s - loss: 0.1298 - acc: 0.9469 - val_loss: 0.0866 - val_acc: 0.9708\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08663 to 0.08604, saving model to best.model\n",
      "0s - loss: 0.1318 - acc: 0.9428 - val_loss: 0.0860 - val_acc: 0.9766\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1268 - acc: 0.9484 - val_loss: 0.0876 - val_acc: 0.9620\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08604 to 0.07965, saving model to best.model\n",
      "0s - loss: 0.1205 - acc: 0.9518 - val_loss: 0.0797 - val_acc: 0.9786\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07965 to 0.07947, saving model to best.model\n",
      "0s - loss: 0.1262 - acc: 0.9472 - val_loss: 0.0795 - val_acc: 0.9766\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07947 to 0.07898, saving model to best.model\n",
      "0s - loss: 0.1143 - acc: 0.9547 - val_loss: 0.0790 - val_acc: 0.9757\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07898 to 0.07349, saving model to best.model\n",
      "0s - loss: 0.1116 - acc: 0.9552 - val_loss: 0.0735 - val_acc: 0.9834\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.1125 - acc: 0.9564 - val_loss: 0.0763 - val_acc: 0.9776\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.07349 to 0.07084, saving model to best.model\n",
      "0s - loss: 0.1109 - acc: 0.9559 - val_loss: 0.0708 - val_acc: 0.9825\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07084 to 0.07026, saving model to best.model\n",
      "0s - loss: 0.1038 - acc: 0.9589 - val_loss: 0.0703 - val_acc: 0.9825\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.07026 to 0.06907, saving model to best.model\n",
      "0s - loss: 0.1105 - acc: 0.9584 - val_loss: 0.0691 - val_acc: 0.9805\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.1123 - acc: 0.9533 - val_loss: 0.0711 - val_acc: 0.9776\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06907 to 0.06428, saving model to best.model\n",
      "0s - loss: 0.1070 - acc: 0.9589 - val_loss: 0.0643 - val_acc: 0.9844\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0992 - acc: 0.9606 - val_loss: 0.0648 - val_acc: 0.9844\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06428 to 0.05968, saving model to best.model\n",
      "0s - loss: 0.1011 - acc: 0.9613 - val_loss: 0.0597 - val_acc: 0.9844\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0879 - acc: 0.9676 - val_loss: 0.0610 - val_acc: 0.9844\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05968 to 0.05844, saving model to best.model\n",
      "0s - loss: 0.0969 - acc: 0.9586 - val_loss: 0.0584 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0892 - acc: 0.9657 - val_loss: 0.0642 - val_acc: 0.9825\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05844 to 0.05277, saving model to best.model\n",
      "0s - loss: 0.0976 - acc: 0.9630 - val_loss: 0.0528 - val_acc: 0.9854\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0979 - acc: 0.9620 - val_loss: 0.0563 - val_acc: 0.9844\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05277 to 0.05131, saving model to best.model\n",
      "0s - loss: 0.0897 - acc: 0.9618 - val_loss: 0.0513 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0912 - acc: 0.9632 - val_loss: 0.0631 - val_acc: 0.9825\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0868 - acc: 0.9652 - val_loss: 0.0538 - val_acc: 0.9844\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.05131 to 0.05095, saving model to best.model\n",
      "0s - loss: 0.0899 - acc: 0.9666 - val_loss: 0.0509 - val_acc: 0.9854\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0904 - acc: 0.9676 - val_loss: 0.0576 - val_acc: 0.9854\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0868 - acc: 0.9657 - val_loss: 0.0517 - val_acc: 0.9854\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.05095 to 0.04994, saving model to best.model\n",
      "0s - loss: 0.0896 - acc: 0.9669 - val_loss: 0.0499 - val_acc: 0.9854\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0728 - acc: 0.9701 - val_loss: 0.0568 - val_acc: 0.9864\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.04994 to 0.04458, saving model to best.model\n",
      "0s - loss: 0.0794 - acc: 0.9679 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0719 - acc: 0.9701 - val_loss: 0.0473 - val_acc: 0.9864\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0725 - acc: 0.9715 - val_loss: 0.0525 - val_acc: 0.9864\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0801 - acc: 0.9674 - val_loss: 0.0482 - val_acc: 0.9864\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0739 - acc: 0.9701 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0739 - acc: 0.9710 - val_loss: 0.0506 - val_acc: 0.9864\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.04458 to 0.04378, saving model to best.model\n",
      "0s - loss: 0.0791 - acc: 0.9713 - val_loss: 0.0438 - val_acc: 0.9864\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.04378 to 0.04338, saving model to best.model\n",
      "0s - loss: 0.0712 - acc: 0.9710 - val_loss: 0.0434 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0675 - acc: 0.9739 - val_loss: 0.0464 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0671 - acc: 0.9754 - val_loss: 0.0463 - val_acc: 0.9864\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0640 - acc: 0.9739 - val_loss: 0.0443 - val_acc: 0.9864\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.04338 to 0.03854, saving model to best.model\n",
      "0s - loss: 0.0639 - acc: 0.9757 - val_loss: 0.0385 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0665 - acc: 0.9730 - val_loss: 0.0436 - val_acc: 0.9893\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0721 - acc: 0.9720 - val_loss: 0.0423 - val_acc: 0.9893\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0734 - acc: 0.9739 - val_loss: 0.0431 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03854 to 0.03785, saving model to best.model\n",
      "0s - loss: 0.0671 - acc: 0.9744 - val_loss: 0.0378 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0637 - acc: 0.9759 - val_loss: 0.0416 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0684 - acc: 0.9761 - val_loss: 0.0416 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0621 - acc: 0.9754 - val_loss: 0.0380 - val_acc: 0.9883\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0630 - acc: 0.9769 - val_loss: 0.0443 - val_acc: 0.9883\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.03785 to 0.03548, saving model to best.model\n",
      "0s - loss: 0.0622 - acc: 0.9757 - val_loss: 0.0355 - val_acc: 0.9883\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9786 - val_loss: 0.0397 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0633 - acc: 0.9749 - val_loss: 0.0369 - val_acc: 0.9893\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0614 - acc: 0.9793 - val_loss: 0.0396 - val_acc: 0.9883\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0646 - acc: 0.9749 - val_loss: 0.0379 - val_acc: 0.9903\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0565 - acc: 0.9810 - val_loss: 0.0383 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0577 - acc: 0.9810 - val_loss: 0.0364 - val_acc: 0.9903\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0570 - acc: 0.9769 - val_loss: 0.0386 - val_acc: 0.9903\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0550 - acc: 0.9803 - val_loss: 0.0373 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0557 - acc: 0.9791 - val_loss: 0.0363 - val_acc: 0.9893\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.03548 to 0.03464, saving model to best.model\n",
      "0s - loss: 0.0611 - acc: 0.9783 - val_loss: 0.0346 - val_acc: 0.9893\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9805 - val_loss: 0.0381 - val_acc: 0.9912\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0574 - acc: 0.9791 - val_loss: 0.0371 - val_acc: 0.9903\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.03464 to 0.03274, saving model to best.model\n",
      "0s - loss: 0.0551 - acc: 0.9803 - val_loss: 0.0327 - val_acc: 0.9903\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9793 - val_loss: 0.0393 - val_acc: 0.9883\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.03274 to 0.03273, saving model to best.model\n",
      "0s - loss: 0.0500 - acc: 0.9825 - val_loss: 0.0327 - val_acc: 0.9912\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0541 - acc: 0.9791 - val_loss: 0.0369 - val_acc: 0.9893\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9805 - val_loss: 0.0375 - val_acc: 0.9883\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9825 - val_loss: 0.0342 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.03273 to 0.03163, saving model to best.model\n",
      "0s - loss: 0.0505 - acc: 0.9800 - val_loss: 0.0316 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.03163 to 0.03012, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9795 - val_loss: 0.0301 - val_acc: 0.9903\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9793 - val_loss: 0.0358 - val_acc: 0.9903\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0556 - acc: 0.9803 - val_loss: 0.0315 - val_acc: 0.9903\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.03012 to 0.02940, saving model to best.model\n",
      "0s - loss: 0.0476 - acc: 0.9830 - val_loss: 0.0294 - val_acc: 0.9912\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0505 - acc: 0.9791 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0448 - acc: 0.9832 - val_loss: 0.0297 - val_acc: 0.9912\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0522 - acc: 0.9810 - val_loss: 0.0352 - val_acc: 0.9912\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9839 - val_loss: 0.0311 - val_acc: 0.9912\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9827 - val_loss: 0.0304 - val_acc: 0.9912\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9854 - val_loss: 0.0335 - val_acc: 0.9912\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0462 - acc: 0.9832 - val_loss: 0.0321 - val_acc: 0.9912\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0489 - acc: 0.9817 - val_loss: 0.0348 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9813 - val_loss: 0.0314 - val_acc: 0.9912\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0513 - acc: 0.9825 - val_loss: 0.0315 - val_acc: 0.9912\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.02940 to 0.02923, saving model to best.model\n",
      "0s - loss: 0.0464 - acc: 0.9837 - val_loss: 0.0292 - val_acc: 0.9912\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0502 - acc: 0.9805 - val_loss: 0.0330 - val_acc: 0.9912\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9842 - val_loss: 0.0320 - val_acc: 0.9912\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0441 - acc: 0.9847 - val_loss: 0.0293 - val_acc: 0.9912\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.02923 to 0.02800, saving model to best.model\n",
      "0s - loss: 0.0440 - acc: 0.9827 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.02800 to 0.02750, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9830 - val_loss: 0.0275 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9830 - val_loss: 0.0302 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9825 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0387 - acc: 0.9871 - val_loss: 0.0313 - val_acc: 0.9912\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.02750 to 0.02554, saving model to best.model\n",
      "0s - loss: 0.0417 - acc: 0.9842 - val_loss: 0.0255 - val_acc: 0.9912\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9851 - val_loss: 0.0308 - val_acc: 0.9912\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0401 - acc: 0.9854 - val_loss: 0.0286 - val_acc: 0.9922\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9878 - val_loss: 0.0300 - val_acc: 0.9922\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9864 - val_loss: 0.0257 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.02554 to 0.02535, saving model to best.model\n",
      "0s - loss: 0.0432 - acc: 0.9834 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9849 - val_loss: 0.0289 - val_acc: 0.9912\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9864 - val_loss: 0.0283 - val_acc: 0.9912\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9861 - val_loss: 0.0267 - val_acc: 0.9932\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9876 - val_loss: 0.0277 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9883 - val_loss: 0.0286 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.02535 to 0.02396, saving model to best.model\n",
      "0s - loss: 0.0369 - acc: 0.9851 - val_loss: 0.0240 - val_acc: 0.9951\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9900 - val_loss: 0.0293 - val_acc: 0.9912\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.02396 to 0.02367, saving model to best.model\n",
      "0s - loss: 0.0341 - acc: 0.9873 - val_loss: 0.0237 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9883 - val_loss: 0.0293 - val_acc: 0.9912\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9876 - val_loss: 0.0241 - val_acc: 0.9961\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9888 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9854 - val_loss: 0.0263 - val_acc: 0.9942\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9873 - val_loss: 0.0297 - val_acc: 0.9912\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9886 - val_loss: 0.0271 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9888 - val_loss: 0.0256 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9869 - val_loss: 0.0268 - val_acc: 0.9932\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.02367 to 0.02127, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9856 - val_loss: 0.0213 - val_acc: 0.9961\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9842 - val_loss: 0.0271 - val_acc: 0.9942\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9873 - val_loss: 0.0234 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.0233 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9844 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.02127 to 0.02125, saving model to best.model\n",
      "0s - loss: 0.0356 - acc: 0.9871 - val_loss: 0.0212 - val_acc: 0.9951\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9873 - val_loss: 0.0237 - val_acc: 0.9932\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9871 - val_loss: 0.0280 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9866 - val_loss: 0.0249 - val_acc: 0.9951\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9876 - val_loss: 0.0218 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.02125 to 0.02020, saving model to best.model\n",
      "0s - loss: 0.0296 - acc: 0.9900 - val_loss: 0.0202 - val_acc: 0.9961\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9878 - val_loss: 0.0233 - val_acc: 0.9932\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0332 - acc: 0.9893 - val_loss: 0.0211 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9903 - val_loss: 0.0230 - val_acc: 0.9951\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9869 - val_loss: 0.0208 - val_acc: 0.9961\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9922 - val_loss: 0.0218 - val_acc: 0.9961\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67338, saving model to best.model\n",
      "0s - loss: 0.8070 - acc: 0.5023 - val_loss: 0.6734 - val_acc: 0.5112\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67338 to 0.63896, saving model to best.model\n",
      "0s - loss: 0.7330 - acc: 0.5383 - val_loss: 0.6390 - val_acc: 0.7770\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63896 to 0.58527, saving model to best.model\n",
      "0s - loss: 0.6898 - acc: 0.5749 - val_loss: 0.5853 - val_acc: 0.8199\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58527 to 0.51745, saving model to best.model\n",
      "0s - loss: 0.6253 - acc: 0.6511 - val_loss: 0.5174 - val_acc: 0.8072\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51745 to 0.44940, saving model to best.model\n",
      "0s - loss: 0.5450 - acc: 0.7356 - val_loss: 0.4494 - val_acc: 0.8179\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44940 to 0.38450, saving model to best.model\n",
      "0s - loss: 0.4893 - acc: 0.7818 - val_loss: 0.3845 - val_acc: 0.8559\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.38450 to 0.35002, saving model to best.model\n",
      "0s - loss: 0.4436 - acc: 0.8137 - val_loss: 0.3500 - val_acc: 0.8685\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35002 to 0.33072, saving model to best.model\n",
      "0s - loss: 0.4141 - acc: 0.8322 - val_loss: 0.3307 - val_acc: 0.8744\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33072 to 0.31332, saving model to best.model\n",
      "0s - loss: 0.3928 - acc: 0.8451 - val_loss: 0.3133 - val_acc: 0.8763\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31332 to 0.29944, saving model to best.model\n",
      "0s - loss: 0.3729 - acc: 0.8503 - val_loss: 0.2994 - val_acc: 0.8832\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.29944 to 0.28291, saving model to best.model\n",
      "0s - loss: 0.3561 - acc: 0.8624 - val_loss: 0.2829 - val_acc: 0.8880\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.3363 - acc: 0.8712 - val_loss: 0.2836 - val_acc: 0.8880\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28291 to 0.26757, saving model to best.model\n",
      "0s - loss: 0.3280 - acc: 0.8758 - val_loss: 0.2676 - val_acc: 0.8890\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.26757 to 0.25913, saving model to best.model\n",
      "0s - loss: 0.3190 - acc: 0.8841 - val_loss: 0.2591 - val_acc: 0.8909\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25913 to 0.25183, saving model to best.model\n",
      "0s - loss: 0.3081 - acc: 0.8773 - val_loss: 0.2518 - val_acc: 0.8968\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.25183 to 0.24803, saving model to best.model\n",
      "0s - loss: 0.2906 - acc: 0.8914 - val_loss: 0.2480 - val_acc: 0.8968\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.24803 to 0.24430, saving model to best.model\n",
      "0s - loss: 0.2853 - acc: 0.8946 - val_loss: 0.2443 - val_acc: 0.9017\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24430 to 0.23873, saving model to best.model\n",
      "0s - loss: 0.2783 - acc: 0.8965 - val_loss: 0.2387 - val_acc: 0.9056\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23873 to 0.23507, saving model to best.model\n",
      "0s - loss: 0.2716 - acc: 0.8987 - val_loss: 0.2351 - val_acc: 0.9104\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23507 to 0.23283, saving model to best.model\n",
      "0s - loss: 0.2695 - acc: 0.9031 - val_loss: 0.2328 - val_acc: 0.9046\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23283 to 0.22831, saving model to best.model\n",
      "0s - loss: 0.2590 - acc: 0.8997 - val_loss: 0.2283 - val_acc: 0.9094\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22831 to 0.22830, saving model to best.model\n",
      "0s - loss: 0.2608 - acc: 0.9050 - val_loss: 0.2283 - val_acc: 0.9065\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.22830 to 0.22279, saving model to best.model\n",
      "0s - loss: 0.2497 - acc: 0.9102 - val_loss: 0.2228 - val_acc: 0.9104\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.2428 - acc: 0.9109 - val_loss: 0.2241 - val_acc: 0.9056\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.22279 to 0.21372, saving model to best.model\n",
      "0s - loss: 0.2433 - acc: 0.9070 - val_loss: 0.2137 - val_acc: 0.9163\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21372 to 0.21121, saving model to best.model\n",
      "0s - loss: 0.2427 - acc: 0.9133 - val_loss: 0.2112 - val_acc: 0.9143\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.21121 to 0.21021, saving model to best.model\n",
      "0s - loss: 0.2235 - acc: 0.9179 - val_loss: 0.2102 - val_acc: 0.9143\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21021 to 0.20565, saving model to best.model\n",
      "0s - loss: 0.2270 - acc: 0.9196 - val_loss: 0.2057 - val_acc: 0.9192\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2226 - acc: 0.9231 - val_loss: 0.2074 - val_acc: 0.9163\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.20565 to 0.19937, saving model to best.model\n",
      "0s - loss: 0.2212 - acc: 0.9175 - val_loss: 0.1994 - val_acc: 0.9241\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19937 to 0.19690, saving model to best.model\n",
      "0s - loss: 0.2225 - acc: 0.9177 - val_loss: 0.1969 - val_acc: 0.9211\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19690 to 0.19425, saving model to best.model\n",
      "0s - loss: 0.2120 - acc: 0.9282 - val_loss: 0.1943 - val_acc: 0.9241\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.19425 to 0.19273, saving model to best.model\n",
      "0s - loss: 0.2118 - acc: 0.9243 - val_loss: 0.1927 - val_acc: 0.9231\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19273 to 0.18821, saving model to best.model\n",
      "0s - loss: 0.2066 - acc: 0.9243 - val_loss: 0.1882 - val_acc: 0.9241\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18821 to 0.18428, saving model to best.model\n",
      "0s - loss: 0.2005 - acc: 0.9316 - val_loss: 0.1843 - val_acc: 0.9270\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18428 to 0.18165, saving model to best.model\n",
      "0s - loss: 0.1930 - acc: 0.9323 - val_loss: 0.1817 - val_acc: 0.9260\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.18165 to 0.17713, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9245 - val_loss: 0.1771 - val_acc: 0.9289\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17713 to 0.17565, saving model to best.model\n",
      "0s - loss: 0.1850 - acc: 0.9330 - val_loss: 0.1756 - val_acc: 0.9270\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17565 to 0.17124, saving model to best.model\n",
      "0s - loss: 0.1821 - acc: 0.9338 - val_loss: 0.1712 - val_acc: 0.9318\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17124 to 0.16918, saving model to best.model\n",
      "0s - loss: 0.1843 - acc: 0.9330 - val_loss: 0.1692 - val_acc: 0.9289\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.16918 to 0.16803, saving model to best.model\n",
      "0s - loss: 0.1763 - acc: 0.9374 - val_loss: 0.1680 - val_acc: 0.9270\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.16803 to 0.15935, saving model to best.model\n",
      "0s - loss: 0.1861 - acc: 0.9330 - val_loss: 0.1593 - val_acc: 0.9348\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15935 to 0.15787, saving model to best.model\n",
      "0s - loss: 0.1740 - acc: 0.9357 - val_loss: 0.1579 - val_acc: 0.9328\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.15787 to 0.15368, saving model to best.model\n",
      "0s - loss: 0.1641 - acc: 0.9411 - val_loss: 0.1537 - val_acc: 0.9377\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15368 to 0.15254, saving model to best.model\n",
      "0s - loss: 0.1603 - acc: 0.9423 - val_loss: 0.1525 - val_acc: 0.9338\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.15254 to 0.14947, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9394 - val_loss: 0.1495 - val_acc: 0.9357\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14947 to 0.14504, saving model to best.model\n",
      "0s - loss: 0.1542 - acc: 0.9452 - val_loss: 0.1450 - val_acc: 0.9357\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14504 to 0.14057, saving model to best.model\n",
      "0s - loss: 0.1545 - acc: 0.9452 - val_loss: 0.1406 - val_acc: 0.9552\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.14057 to 0.13670, saving model to best.model\n",
      "0s - loss: 0.1631 - acc: 0.9430 - val_loss: 0.1367 - val_acc: 0.9484\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.13670 to 0.13450, saving model to best.model\n",
      "0s - loss: 0.1511 - acc: 0.9523 - val_loss: 0.1345 - val_acc: 0.9523\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1569 - acc: 0.9455 - val_loss: 0.1360 - val_acc: 0.9426\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.1511 - acc: 0.9469 - val_loss: 0.1364 - val_acc: 0.9406\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13450 to 0.12893, saving model to best.model\n",
      "0s - loss: 0.1428 - acc: 0.9481 - val_loss: 0.1289 - val_acc: 0.9581\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.12893 to 0.12832, saving model to best.model\n",
      "0s - loss: 0.1364 - acc: 0.9537 - val_loss: 0.1283 - val_acc: 0.9523\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.12832 to 0.12519, saving model to best.model\n",
      "0s - loss: 0.1374 - acc: 0.9515 - val_loss: 0.1252 - val_acc: 0.9533\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12519 to 0.12049, saving model to best.model\n",
      "0s - loss: 0.1400 - acc: 0.9467 - val_loss: 0.1205 - val_acc: 0.9542\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12049 to 0.11740, saving model to best.model\n",
      "0s - loss: 0.1334 - acc: 0.9530 - val_loss: 0.1174 - val_acc: 0.9572\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1350 - acc: 0.9511 - val_loss: 0.1178 - val_acc: 0.9552\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11740 to 0.11378, saving model to best.model\n",
      "0s - loss: 0.1265 - acc: 0.9579 - val_loss: 0.1138 - val_acc: 0.9581\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1363 - acc: 0.9518 - val_loss: 0.1154 - val_acc: 0.9513\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11378 to 0.10690, saving model to best.model\n",
      "0s - loss: 0.1333 - acc: 0.9511 - val_loss: 0.1069 - val_acc: 0.9591\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.10690 to 0.10626, saving model to best.model\n",
      "0s - loss: 0.1210 - acc: 0.9593 - val_loss: 0.1063 - val_acc: 0.9581\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10626 to 0.10270, saving model to best.model\n",
      "0s - loss: 0.1233 - acc: 0.9552 - val_loss: 0.1027 - val_acc: 0.9620\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1215 - acc: 0.9567 - val_loss: 0.1046 - val_acc: 0.9562\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10270 to 0.09799, saving model to best.model\n",
      "0s - loss: 0.1144 - acc: 0.9571 - val_loss: 0.0980 - val_acc: 0.9620\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.09799 to 0.09503, saving model to best.model\n",
      "0s - loss: 0.1120 - acc: 0.9627 - val_loss: 0.0950 - val_acc: 0.9630\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1168 - acc: 0.9569 - val_loss: 0.0971 - val_acc: 0.9581\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09503 to 0.09230, saving model to best.model\n",
      "0s - loss: 0.1111 - acc: 0.9603 - val_loss: 0.0923 - val_acc: 0.9601\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09230 to 0.08943, saving model to best.model\n",
      "0s - loss: 0.1131 - acc: 0.9567 - val_loss: 0.0894 - val_acc: 0.9611\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08943 to 0.08783, saving model to best.model\n",
      "0s - loss: 0.1115 - acc: 0.9596 - val_loss: 0.0878 - val_acc: 0.9620\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.08783 to 0.08754, saving model to best.model\n",
      "0s - loss: 0.1043 - acc: 0.9623 - val_loss: 0.0875 - val_acc: 0.9620\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.08754 to 0.08163, saving model to best.model\n",
      "0s - loss: 0.1100 - acc: 0.9603 - val_loss: 0.0816 - val_acc: 0.9649\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08163 to 0.07918, saving model to best.model\n",
      "0s - loss: 0.1023 - acc: 0.9618 - val_loss: 0.0792 - val_acc: 0.9649\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.07918 to 0.07586, saving model to best.model\n",
      "0s - loss: 0.0972 - acc: 0.9662 - val_loss: 0.0759 - val_acc: 0.9630\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.0951 - acc: 0.9671 - val_loss: 0.0781 - val_acc: 0.9659\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.07586 to 0.07291, saving model to best.model\n",
      "0s - loss: 0.1046 - acc: 0.9603 - val_loss: 0.0729 - val_acc: 0.9649\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.07291 to 0.07130, saving model to best.model\n",
      "0s - loss: 0.0934 - acc: 0.9691 - val_loss: 0.0713 - val_acc: 0.9688\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.07130 to 0.06824, saving model to best.model\n",
      "0s - loss: 0.1050 - acc: 0.9601 - val_loss: 0.0682 - val_acc: 0.9688\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06824 to 0.06619, saving model to best.model\n",
      "0s - loss: 0.0895 - acc: 0.9693 - val_loss: 0.0662 - val_acc: 0.9688\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06619 to 0.06482, saving model to best.model\n",
      "0s - loss: 0.0925 - acc: 0.9649 - val_loss: 0.0648 - val_acc: 0.9688\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.0909 - acc: 0.9647 - val_loss: 0.0657 - val_acc: 0.9708\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.06482 to 0.06214, saving model to best.model\n",
      "0s - loss: 0.0869 - acc: 0.9642 - val_loss: 0.0621 - val_acc: 0.9737\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.06214 to 0.06210, saving model to best.model\n",
      "0s - loss: 0.0824 - acc: 0.9703 - val_loss: 0.0621 - val_acc: 0.9747\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.06210 to 0.05935, saving model to best.model\n",
      "0s - loss: 0.0904 - acc: 0.9664 - val_loss: 0.0594 - val_acc: 0.9727\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05935 to 0.05881, saving model to best.model\n",
      "0s - loss: 0.0883 - acc: 0.9693 - val_loss: 0.0588 - val_acc: 0.9737\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05881 to 0.05624, saving model to best.model\n",
      "0s - loss: 0.0896 - acc: 0.9657 - val_loss: 0.0562 - val_acc: 0.9747\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0723 - acc: 0.9701 - val_loss: 0.0579 - val_acc: 0.9844\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.05624 to 0.05574, saving model to best.model\n",
      "0s - loss: 0.0849 - acc: 0.9679 - val_loss: 0.0557 - val_acc: 0.9864\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.05574 to 0.05132, saving model to best.model\n",
      "0s - loss: 0.0852 - acc: 0.9662 - val_loss: 0.0513 - val_acc: 0.9834\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.05132 to 0.05034, saving model to best.model\n",
      "0s - loss: 0.0774 - acc: 0.9701 - val_loss: 0.0503 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.05034 to 0.04896, saving model to best.model\n",
      "0s - loss: 0.0758 - acc: 0.9713 - val_loss: 0.0490 - val_acc: 0.9854\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04896 to 0.04795, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9739 - val_loss: 0.0480 - val_acc: 0.9844\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04795 to 0.04687, saving model to best.model\n",
      "0s - loss: 0.0732 - acc: 0.9730 - val_loss: 0.0469 - val_acc: 0.9844\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.04687 to 0.04589, saving model to best.model\n",
      "0s - loss: 0.0766 - acc: 0.9732 - val_loss: 0.0459 - val_acc: 0.9864\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04589 to 0.04420, saving model to best.model\n",
      "0s - loss: 0.0756 - acc: 0.9744 - val_loss: 0.0442 - val_acc: 0.9864\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0716 - acc: 0.9737 - val_loss: 0.0442 - val_acc: 0.9864\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04420 to 0.04173, saving model to best.model\n",
      "0s - loss: 0.0683 - acc: 0.9761 - val_loss: 0.0417 - val_acc: 0.9854\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04173 to 0.03890, saving model to best.model\n",
      "0s - loss: 0.0630 - acc: 0.9786 - val_loss: 0.0389 - val_acc: 0.9854\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0693 - acc: 0.9752 - val_loss: 0.0393 - val_acc: 0.9873\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03890 to 0.03593, saving model to best.model\n",
      "0s - loss: 0.0611 - acc: 0.9757 - val_loss: 0.0359 - val_acc: 0.9864\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03593 to 0.03472, saving model to best.model\n",
      "0s - loss: 0.0684 - acc: 0.9754 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03472 to 0.03460, saving model to best.model\n",
      "0s - loss: 0.0635 - acc: 0.9776 - val_loss: 0.0346 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0575 - acc: 0.9791 - val_loss: 0.0392 - val_acc: 0.9873\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.03460 to 0.03203, saving model to best.model\n",
      "0s - loss: 0.0606 - acc: 0.9778 - val_loss: 0.0320 - val_acc: 0.9873\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.03203 to 0.03157, saving model to best.model\n",
      "0s - loss: 0.0608 - acc: 0.9791 - val_loss: 0.0316 - val_acc: 0.9883\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.03157 to 0.02983, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9778 - val_loss: 0.0298 - val_acc: 0.9883\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.02983 to 0.02963, saving model to best.model\n",
      "0s - loss: 0.0506 - acc: 0.9798 - val_loss: 0.0296 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0578 - acc: 0.9778 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02963 to 0.02747, saving model to best.model\n",
      "0s - loss: 0.0598 - acc: 0.9776 - val_loss: 0.0275 - val_acc: 0.9883\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.02747 to 0.02744, saving model to best.model\n",
      "0s - loss: 0.0601 - acc: 0.9764 - val_loss: 0.0274 - val_acc: 0.9883\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02744 to 0.02593, saving model to best.model\n",
      "0s - loss: 0.0553 - acc: 0.9808 - val_loss: 0.0259 - val_acc: 0.9883\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02593 to 0.02377, saving model to best.model\n",
      "0s - loss: 0.0537 - acc: 0.9815 - val_loss: 0.0238 - val_acc: 0.9912\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0552 - acc: 0.9795 - val_loss: 0.0238 - val_acc: 0.9893\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0585 - acc: 0.9791 - val_loss: 0.0273 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9825 - val_loss: 0.0247 - val_acc: 0.9883\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0528 - acc: 0.9795 - val_loss: 0.0268 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9788 - val_loss: 0.0297 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.02377 to 0.02289, saving model to best.model\n",
      "0s - loss: 0.0574 - acc: 0.9805 - val_loss: 0.0229 - val_acc: 0.9912\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0505 - acc: 0.9813 - val_loss: 0.0244 - val_acc: 0.9883\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9805 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.02289 to 0.02238, saving model to best.model\n",
      "0s - loss: 0.0546 - acc: 0.9805 - val_loss: 0.0224 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9786 - val_loss: 0.0241 - val_acc: 0.9883\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02238 to 0.02096, saving model to best.model\n",
      "0s - loss: 0.0456 - acc: 0.9830 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9803 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0500 - acc: 0.9815 - val_loss: 0.0212 - val_acc: 0.9883\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0469 - acc: 0.9830 - val_loss: 0.0222 - val_acc: 0.9883\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02096 to 0.01704, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9830 - val_loss: 0.0170 - val_acc: 0.9961\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9834 - val_loss: 0.0238 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0494 - acc: 0.9813 - val_loss: 0.0193 - val_acc: 0.9893\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0530 - acc: 0.9810 - val_loss: 0.0332 - val_acc: 0.9873\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9871 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.0427 - acc: 0.9851 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01704 to 0.01668, saving model to best.model\n",
      "0s - loss: 0.0412 - acc: 0.9834 - val_loss: 0.0167 - val_acc: 0.9922\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.01668 to 0.01621, saving model to best.model\n",
      "0s - loss: 0.0378 - acc: 0.9849 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0489 - acc: 0.9837 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.01621 to 0.01527, saving model to best.model\n",
      "0s - loss: 0.0388 - acc: 0.9851 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01527 to 0.01390, saving model to best.model\n",
      "0s - loss: 0.0391 - acc: 0.9866 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0436 - acc: 0.9839 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9869 - val_loss: 0.0150 - val_acc: 0.9951\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0399 - acc: 0.9856 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9859 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01390 to 0.01318, saving model to best.model\n",
      "0s - loss: 0.0352 - acc: 0.9869 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01318 to 0.01288, saving model to best.model\n",
      "0s - loss: 0.0413 - acc: 0.9856 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0343 - acc: 0.9881 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0408 - acc: 0.9856 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01288 to 0.01129, saving model to best.model\n",
      "0s - loss: 0.0330 - acc: 0.9869 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9859 - val_loss: 0.0134 - val_acc: 0.9942\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01129 to 0.01107, saving model to best.model\n",
      "0s - loss: 0.0430 - acc: 0.9822 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9856 - val_loss: 0.0135 - val_acc: 0.9932\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9900 - val_loss: 0.0139 - val_acc: 0.9932\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01107 to 0.01106, saving model to best.model\n",
      "0s - loss: 0.0335 - acc: 0.9883 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0493 - acc: 0.9832 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9888 - val_loss: 0.0133 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9886 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9890 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0357 - acc: 0.9869 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9888 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01106 to 0.00977, saving model to best.model\n",
      "0s - loss: 0.0347 - acc: 0.9878 - val_loss: 0.0098 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.00977 to 0.00872, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9888 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0392 - acc: 0.9864 - val_loss: 0.0102 - val_acc: 0.9961\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9907 - val_loss: 0.0100 - val_acc: 0.9961\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9900 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9878 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0309 - acc: 0.9883 - val_loss: 0.0127 - val_acc: 0.9942\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0266 - acc: 0.9900 - val_loss: 0.0091 - val_acc: 0.9961\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9878 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9893 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9888 - val_loss: 0.0112 - val_acc: 0.9961\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0261 - acc: 0.9893 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0270 - acc: 0.9907 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.00872 to 0.00823, saving model to best.model\n",
      "0s - loss: 0.0340 - acc: 0.9869 - val_loss: 0.0082 - val_acc: 0.9971\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.00823 to 0.00771, saving model to best.model\n",
      "0s - loss: 0.0310 - acc: 0.9893 - val_loss: 0.0077 - val_acc: 0.9990\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9873 - val_loss: 0.0165 - val_acc: 0.9903\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9883 - val_loss: 0.0088 - val_acc: 0.9961\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9881 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0331 - acc: 0.9871 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.00771 to 0.00770, saving model to best.model\n",
      "0s - loss: 0.0339 - acc: 0.9881 - val_loss: 0.0077 - val_acc: 0.9961\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0293 - acc: 0.9886 - val_loss: 0.0091 - val_acc: 0.9961\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.00770 to 0.00749, saving model to best.model\n",
      "0s - loss: 0.0288 - acc: 0.9903 - val_loss: 0.0075 - val_acc: 0.9961\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0221 - acc: 0.9917 - val_loss: 0.0096 - val_acc: 0.9961\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.00749 to 0.00740, saving model to best.model\n",
      "0s - loss: 0.0287 - acc: 0.9900 - val_loss: 0.0074 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0194 - acc: 0.9927 - val_loss: 0.0085 - val_acc: 0.9961\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.00740 to 0.00701, saving model to best.model\n",
      "0s - loss: 0.0317 - acc: 0.9883 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0240 - acc: 0.9907 - val_loss: 0.0090 - val_acc: 0.9961\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.00701 to 0.00615, saving model to best.model\n",
      "0s - loss: 0.0296 - acc: 0.9886 - val_loss: 0.0062 - val_acc: 0.9981\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.00615 to 0.00572, saving model to best.model\n",
      "0s - loss: 0.0265 - acc: 0.9905 - val_loss: 0.0057 - val_acc: 0.9990\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9907 - val_loss: 0.0057 - val_acc: 0.9990\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0259 - acc: 0.9903 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.00572 to 0.00522, saving model to best.model\n",
      "0s - loss: 0.0250 - acc: 0.9905 - val_loss: 0.0052 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0056 - val_acc: 0.9990\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0261 - acc: 0.9890 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9861 - val_loss: 0.0054 - val_acc: 0.9990\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0210 - acc: 0.9920 - val_loss: 0.0054 - val_acc: 0.9990\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0206 - acc: 0.9910 - val_loss: 0.0073 - val_acc: 0.9961\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0285 - acc: 0.9888 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0226 - acc: 0.9912 - val_loss: 0.0063 - val_acc: 0.9981\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67894, saving model to best.model\n",
      "0s - loss: 0.8471 - acc: 0.5023 - val_loss: 0.6789 - val_acc: 0.5628\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67894 to 0.67606, saving model to best.model\n",
      "0s - loss: 0.7526 - acc: 0.5320 - val_loss: 0.6761 - val_acc: 0.5034\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.67606 to 0.61699, saving model to best.model\n",
      "0s - loss: 0.7010 - acc: 0.5763 - val_loss: 0.6170 - val_acc: 0.8062\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61699 to 0.55010, saving model to best.model\n",
      "0s - loss: 0.6641 - acc: 0.6109 - val_loss: 0.5501 - val_acc: 0.8121\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55010 to 0.47355, saving model to best.model\n",
      "0s - loss: 0.5888 - acc: 0.7003 - val_loss: 0.4736 - val_acc: 0.8062\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.47355 to 0.41318, saving model to best.model\n",
      "0s - loss: 0.5010 - acc: 0.7728 - val_loss: 0.4132 - val_acc: 0.8423\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.41318 to 0.36633, saving model to best.model\n",
      "0s - loss: 0.4539 - acc: 0.7994 - val_loss: 0.3663 - val_acc: 0.8676\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36633 to 0.33885, saving model to best.model\n",
      "0s - loss: 0.4238 - acc: 0.8230 - val_loss: 0.3389 - val_acc: 0.8744\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33885 to 0.33230, saving model to best.model\n",
      "0s - loss: 0.3915 - acc: 0.8400 - val_loss: 0.3323 - val_acc: 0.8763\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33230 to 0.30399, saving model to best.model\n",
      "0s - loss: 0.3760 - acc: 0.8461 - val_loss: 0.3040 - val_acc: 0.8851\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30399 to 0.29372, saving model to best.model\n",
      "0s - loss: 0.3502 - acc: 0.8632 - val_loss: 0.2937 - val_acc: 0.8870\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29372 to 0.28519, saving model to best.model\n",
      "0s - loss: 0.3352 - acc: 0.8661 - val_loss: 0.2852 - val_acc: 0.8890\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28519 to 0.27151, saving model to best.model\n",
      "0s - loss: 0.3214 - acc: 0.8683 - val_loss: 0.2715 - val_acc: 0.8880\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27151 to 0.26229, saving model to best.model\n",
      "0s - loss: 0.3095 - acc: 0.8761 - val_loss: 0.2623 - val_acc: 0.8900\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26229 to 0.26097, saving model to best.model\n",
      "0s - loss: 0.3077 - acc: 0.8831 - val_loss: 0.2610 - val_acc: 0.8997\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.2954 - acc: 0.8890 - val_loss: 0.2623 - val_acc: 0.8987\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.26097 to 0.24482, saving model to best.model\n",
      "0s - loss: 0.2855 - acc: 0.8921 - val_loss: 0.2448 - val_acc: 0.9094\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.2824 - acc: 0.8916 - val_loss: 0.2513 - val_acc: 0.8978\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24482 to 0.23334, saving model to best.model\n",
      "0s - loss: 0.2651 - acc: 0.8977 - val_loss: 0.2333 - val_acc: 0.9153\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23334 to 0.22876, saving model to best.model\n",
      "0s - loss: 0.2621 - acc: 0.9021 - val_loss: 0.2288 - val_acc: 0.9172\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2579 - acc: 0.9053 - val_loss: 0.2308 - val_acc: 0.9104\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22876 to 0.21564, saving model to best.model\n",
      "0s - loss: 0.2530 - acc: 0.9053 - val_loss: 0.2156 - val_acc: 0.9309\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.2525 - acc: 0.9102 - val_loss: 0.2190 - val_acc: 0.9192\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21564 to 0.21444, saving model to best.model\n",
      "0s - loss: 0.2524 - acc: 0.9046 - val_loss: 0.2144 - val_acc: 0.9202\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.21444 to 0.21015, saving model to best.model\n",
      "0s - loss: 0.2448 - acc: 0.9131 - val_loss: 0.2102 - val_acc: 0.9221\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21015 to 0.20992, saving model to best.model\n",
      "0s - loss: 0.2396 - acc: 0.9133 - val_loss: 0.2099 - val_acc: 0.9182\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20992 to 0.20816, saving model to best.model\n",
      "0s - loss: 0.2403 - acc: 0.9150 - val_loss: 0.2082 - val_acc: 0.9211\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20816 to 0.19713, saving model to best.model\n",
      "0s - loss: 0.2294 - acc: 0.9184 - val_loss: 0.1971 - val_acc: 0.9348\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.2308 - acc: 0.9170 - val_loss: 0.1990 - val_acc: 0.9309\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19713 to 0.19469, saving model to best.model\n",
      "0s - loss: 0.2160 - acc: 0.9238 - val_loss: 0.1947 - val_acc: 0.9328\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.19469 to 0.18820, saving model to best.model\n",
      "0s - loss: 0.2326 - acc: 0.9165 - val_loss: 0.1882 - val_acc: 0.9387\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.2266 - acc: 0.9206 - val_loss: 0.1957 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2162 - acc: 0.9243 - val_loss: 0.1962 - val_acc: 0.9260\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.18820 to 0.18010, saving model to best.model\n",
      "0s - loss: 0.2217 - acc: 0.9150 - val_loss: 0.1801 - val_acc: 0.9406\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.2122 - acc: 0.9243 - val_loss: 0.1834 - val_acc: 0.9328\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18010 to 0.17628, saving model to best.model\n",
      "0s - loss: 0.2101 - acc: 0.9267 - val_loss: 0.1763 - val_acc: 0.9406\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17628 to 0.17599, saving model to best.model\n",
      "0s - loss: 0.2041 - acc: 0.9274 - val_loss: 0.1760 - val_acc: 0.9387\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.2095 - acc: 0.9238 - val_loss: 0.1820 - val_acc: 0.9348\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17599 to 0.17582, saving model to best.model\n",
      "0s - loss: 0.1969 - acc: 0.9340 - val_loss: 0.1758 - val_acc: 0.9367\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.17582 to 0.17079, saving model to best.model\n",
      "0s - loss: 0.1968 - acc: 0.9294 - val_loss: 0.1708 - val_acc: 0.9396\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.17079 to 0.16494, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9294 - val_loss: 0.1649 - val_acc: 0.9445\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1899 - acc: 0.9323 - val_loss: 0.1655 - val_acc: 0.9396\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.1915 - acc: 0.9326 - val_loss: 0.1663 - val_acc: 0.9396\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.16494 to 0.15915, saving model to best.model\n",
      "0s - loss: 0.1885 - acc: 0.9347 - val_loss: 0.1592 - val_acc: 0.9445\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15915 to 0.15504, saving model to best.model\n",
      "0s - loss: 0.1810 - acc: 0.9357 - val_loss: 0.1550 - val_acc: 0.9464\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1788 - acc: 0.9406 - val_loss: 0.1607 - val_acc: 0.9396\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.1882 - acc: 0.9330 - val_loss: 0.1697 - val_acc: 0.9377\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.15504 to 0.15007, saving model to best.model\n",
      "0s - loss: 0.1773 - acc: 0.9408 - val_loss: 0.1501 - val_acc: 0.9523\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1773 - acc: 0.9411 - val_loss: 0.1556 - val_acc: 0.9435\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.15007 to 0.14649, saving model to best.model\n",
      "0s - loss: 0.1718 - acc: 0.9408 - val_loss: 0.1465 - val_acc: 0.9523\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1700 - acc: 0.9430 - val_loss: 0.1485 - val_acc: 0.9435\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.14649 to 0.14591, saving model to best.model\n",
      "0s - loss: 0.1751 - acc: 0.9399 - val_loss: 0.1459 - val_acc: 0.9445\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.14591 to 0.13875, saving model to best.model\n",
      "0s - loss: 0.1635 - acc: 0.9433 - val_loss: 0.1387 - val_acc: 0.9562\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1608 - acc: 0.9442 - val_loss: 0.1452 - val_acc: 0.9455\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.13875 to 0.13875, saving model to best.model\n",
      "0s - loss: 0.1669 - acc: 0.9440 - val_loss: 0.1387 - val_acc: 0.9503\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.13875 to 0.13601, saving model to best.model\n",
      "0s - loss: 0.1597 - acc: 0.9438 - val_loss: 0.1360 - val_acc: 0.9503\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.13601 to 0.12953, saving model to best.model\n",
      "0s - loss: 0.1585 - acc: 0.9428 - val_loss: 0.1295 - val_acc: 0.9591\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.1587 - acc: 0.9467 - val_loss: 0.1313 - val_acc: 0.9562\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.12953 to 0.12673, saving model to best.model\n",
      "0s - loss: 0.1519 - acc: 0.9469 - val_loss: 0.1267 - val_acc: 0.9581\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1530 - acc: 0.9464 - val_loss: 0.1288 - val_acc: 0.9542\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.12673 to 0.12380, saving model to best.model\n",
      "0s - loss: 0.1402 - acc: 0.9523 - val_loss: 0.1238 - val_acc: 0.9562\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1443 - acc: 0.9503 - val_loss: 0.1251 - val_acc: 0.9572\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.12380 to 0.11647, saving model to best.model\n",
      "0s - loss: 0.1427 - acc: 0.9496 - val_loss: 0.1165 - val_acc: 0.9601\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.11647 to 0.10964, saving model to best.model\n",
      "0s - loss: 0.1413 - acc: 0.9523 - val_loss: 0.1096 - val_acc: 0.9630\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1376 - acc: 0.9496 - val_loss: 0.1186 - val_acc: 0.9581\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10964 to 0.10659, saving model to best.model\n",
      "0s - loss: 0.1326 - acc: 0.9513 - val_loss: 0.1066 - val_acc: 0.9620\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.10659 to 0.10015, saving model to best.model\n",
      "0s - loss: 0.1228 - acc: 0.9559 - val_loss: 0.1001 - val_acc: 0.9640\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1350 - acc: 0.9515 - val_loss: 0.1241 - val_acc: 0.9513\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.10015 to 0.09907, saving model to best.model\n",
      "0s - loss: 0.1354 - acc: 0.9513 - val_loss: 0.0991 - val_acc: 0.9640\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09907 to 0.09383, saving model to best.model\n",
      "0s - loss: 0.1240 - acc: 0.9567 - val_loss: 0.0938 - val_acc: 0.9669\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.1176 - acc: 0.9571 - val_loss: 0.1001 - val_acc: 0.9679\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1207 - acc: 0.9559 - val_loss: 0.0963 - val_acc: 0.9718\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.09383 to 0.08669, saving model to best.model\n",
      "0s - loss: 0.1149 - acc: 0.9610 - val_loss: 0.0867 - val_acc: 0.9727\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.08669 to 0.08281, saving model to best.model\n",
      "0s - loss: 0.1156 - acc: 0.9589 - val_loss: 0.0828 - val_acc: 0.9727\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.1161 - acc: 0.9601 - val_loss: 0.0998 - val_acc: 0.9669\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.08281 to 0.08023, saving model to best.model\n",
      "0s - loss: 0.1145 - acc: 0.9593 - val_loss: 0.0802 - val_acc: 0.9727\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.1106 - acc: 0.9618 - val_loss: 0.0831 - val_acc: 0.9786\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.1088 - acc: 0.9610 - val_loss: 0.0819 - val_acc: 0.9766\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.08023 to 0.07535, saving model to best.model\n",
      "0s - loss: 0.1079 - acc: 0.9620 - val_loss: 0.0753 - val_acc: 0.9747\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1002 - acc: 0.9640 - val_loss: 0.0782 - val_acc: 0.9786\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1037 - acc: 0.9642 - val_loss: 0.0772 - val_acc: 0.9786\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.0964 - acc: 0.9618 - val_loss: 0.0793 - val_acc: 0.9766\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.07535 to 0.06618, saving model to best.model\n",
      "0s - loss: 0.0972 - acc: 0.9662 - val_loss: 0.0662 - val_acc: 0.9737\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0917 - acc: 0.9662 - val_loss: 0.0769 - val_acc: 0.9766\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.06618 to 0.06615, saving model to best.model\n",
      "0s - loss: 0.0916 - acc: 0.9686 - val_loss: 0.0661 - val_acc: 0.9786\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.06615 to 0.06601, saving model to best.model\n",
      "0s - loss: 0.0890 - acc: 0.9657 - val_loss: 0.0660 - val_acc: 0.9786\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0917 - acc: 0.9691 - val_loss: 0.0691 - val_acc: 0.9786\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0862 - acc: 0.9679 - val_loss: 0.0684 - val_acc: 0.9796\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0829 - acc: 0.9705 - val_loss: 0.0668 - val_acc: 0.9796\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.06601 to 0.05733, saving model to best.model\n",
      "0s - loss: 0.0831 - acc: 0.9701 - val_loss: 0.0573 - val_acc: 0.9805\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0860 - acc: 0.9705 - val_loss: 0.0609 - val_acc: 0.9796\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.05733 to 0.05656, saving model to best.model\n",
      "0s - loss: 0.0756 - acc: 0.9744 - val_loss: 0.0566 - val_acc: 0.9805\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.05656 to 0.05441, saving model to best.model\n",
      "0s - loss: 0.0844 - acc: 0.9683 - val_loss: 0.0544 - val_acc: 0.9815\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.05441 to 0.05361, saving model to best.model\n",
      "0s - loss: 0.0792 - acc: 0.9701 - val_loss: 0.0536 - val_acc: 0.9815\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.0727 - acc: 0.9727 - val_loss: 0.0542 - val_acc: 0.9815\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.05361 to 0.04824, saving model to best.model\n",
      "0s - loss: 0.0791 - acc: 0.9725 - val_loss: 0.0482 - val_acc: 0.9825\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0791 - acc: 0.9722 - val_loss: 0.0508 - val_acc: 0.9825\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0779 - acc: 0.9747 - val_loss: 0.0516 - val_acc: 0.9815\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.04824 to 0.04577, saving model to best.model\n",
      "0s - loss: 0.0732 - acc: 0.9730 - val_loss: 0.0458 - val_acc: 0.9825\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0679 - acc: 0.9766 - val_loss: 0.0475 - val_acc: 0.9825\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0699 - acc: 0.9761 - val_loss: 0.0519 - val_acc: 0.9815\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.04577 to 0.04179, saving model to best.model\n",
      "0s - loss: 0.0664 - acc: 0.9766 - val_loss: 0.0418 - val_acc: 0.9844\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0676 - acc: 0.9757 - val_loss: 0.0484 - val_acc: 0.9825\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0692 - acc: 0.9764 - val_loss: 0.0430 - val_acc: 0.9854\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0683 - acc: 0.9749 - val_loss: 0.0540 - val_acc: 0.9815\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0655 - acc: 0.9786 - val_loss: 0.0431 - val_acc: 0.9825\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0674 - acc: 0.9752 - val_loss: 0.0460 - val_acc: 0.9825\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0607 - acc: 0.9791 - val_loss: 0.0474 - val_acc: 0.9815\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.04179 to 0.03632, saving model to best.model\n",
      "0s - loss: 0.0600 - acc: 0.9783 - val_loss: 0.0363 - val_acc: 0.9854\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0587 - acc: 0.9800 - val_loss: 0.0498 - val_acc: 0.9815\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0575 - acc: 0.9808 - val_loss: 0.0381 - val_acc: 0.9844\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03632 to 0.03563, saving model to best.model\n",
      "0s - loss: 0.0595 - acc: 0.9791 - val_loss: 0.0356 - val_acc: 0.9854\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0633 - acc: 0.9774 - val_loss: 0.0504 - val_acc: 0.9815\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0658 - acc: 0.9795 - val_loss: 0.0432 - val_acc: 0.9825\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0573 - acc: 0.9813 - val_loss: 0.0417 - val_acc: 0.9844\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0601 - acc: 0.9788 - val_loss: 0.0443 - val_acc: 0.9815\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9813 - val_loss: 0.0386 - val_acc: 0.9825\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0568 - acc: 0.9791 - val_loss: 0.0357 - val_acc: 0.9825\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0517 - acc: 0.9805 - val_loss: 0.0470 - val_acc: 0.9844\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.03563 to 0.03143, saving model to best.model\n",
      "0s - loss: 0.0602 - acc: 0.9808 - val_loss: 0.0314 - val_acc: 0.9864\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0572 - acc: 0.9822 - val_loss: 0.0374 - val_acc: 0.9844\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0468 - acc: 0.9844 - val_loss: 0.0345 - val_acc: 0.9854\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9847 - val_loss: 0.0348 - val_acc: 0.9854\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9805 - val_loss: 0.0345 - val_acc: 0.9844\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03143 to 0.03016, saving model to best.model\n",
      "0s - loss: 0.0525 - acc: 0.9813 - val_loss: 0.0302 - val_acc: 0.9854\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.03016 to 0.02663, saving model to best.model\n",
      "0s - loss: 0.0426 - acc: 0.9851 - val_loss: 0.0266 - val_acc: 0.9864\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.0484 - acc: 0.9820 - val_loss: 0.0309 - val_acc: 0.9854\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02663 to 0.02518, saving model to best.model\n",
      "0s - loss: 0.0478 - acc: 0.9820 - val_loss: 0.0252 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0499 - acc: 0.9844 - val_loss: 0.0290 - val_acc: 0.9854\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9820 - val_loss: 0.0311 - val_acc: 0.9854\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0454 - acc: 0.9832 - val_loss: 0.0264 - val_acc: 0.9873\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02518 to 0.02358, saving model to best.model\n",
      "0s - loss: 0.0466 - acc: 0.9817 - val_loss: 0.0236 - val_acc: 0.9873\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0491 - acc: 0.9827 - val_loss: 0.0281 - val_acc: 0.9864\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9851 - val_loss: 0.0264 - val_acc: 0.9864\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.02358 to 0.02197, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9844 - val_loss: 0.0220 - val_acc: 0.9893\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0461 - acc: 0.9834 - val_loss: 0.0238 - val_acc: 0.9883\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0519 - acc: 0.9805 - val_loss: 0.0282 - val_acc: 0.9854\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0414 - acc: 0.9849 - val_loss: 0.0236 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9844 - val_loss: 0.0309 - val_acc: 0.9864\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0455 - acc: 0.9839 - val_loss: 0.0259 - val_acc: 0.9873\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9866 - val_loss: 0.0291 - val_acc: 0.9873\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0369 - acc: 0.9869 - val_loss: 0.0242 - val_acc: 0.9873\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.02197 to 0.01987, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9851 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0495 - acc: 0.9808 - val_loss: 0.0343 - val_acc: 0.9825\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0456 - acc: 0.9844 - val_loss: 0.0216 - val_acc: 0.9883\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0238 - val_acc: 0.9883\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9883 - val_loss: 0.0234 - val_acc: 0.9873\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0405 - acc: 0.9842 - val_loss: 0.0264 - val_acc: 0.9854\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9839 - val_loss: 0.0275 - val_acc: 0.9864\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01987 to 0.01922, saving model to best.model\n",
      "0s - loss: 0.0422 - acc: 0.9849 - val_loss: 0.0192 - val_acc: 0.9903\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0370 - acc: 0.9878 - val_loss: 0.0245 - val_acc: 0.9864\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9859 - val_loss: 0.0197 - val_acc: 0.9912\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9869 - val_loss: 0.0255 - val_acc: 0.9864\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0418 - acc: 0.9849 - val_loss: 0.0197 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0383 - acc: 0.9873 - val_loss: 0.0246 - val_acc: 0.9873\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9856 - val_loss: 0.0234 - val_acc: 0.9873\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9844 - val_loss: 0.0223 - val_acc: 0.9883\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01922 to 0.01877, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9869 - val_loss: 0.0188 - val_acc: 0.9912\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9869 - val_loss: 0.0228 - val_acc: 0.9864\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01877 to 0.01628, saving model to best.model\n",
      "0s - loss: 0.0369 - acc: 0.9851 - val_loss: 0.0163 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9864 - val_loss: 0.0233 - val_acc: 0.9883\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9886 - val_loss: 0.0199 - val_acc: 0.9903\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0353 - acc: 0.9869 - val_loss: 0.0214 - val_acc: 0.9903\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0163 - val_acc: 0.9912\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0226 - val_acc: 0.9873\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9876 - val_loss: 0.0208 - val_acc: 0.9893\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9844 - val_loss: 0.0169 - val_acc: 0.9912\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0371 - acc: 0.9866 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0354 - acc: 0.9873 - val_loss: 0.0199 - val_acc: 0.9893\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0321 - acc: 0.9881 - val_loss: 0.0173 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01628 to 0.01549, saving model to best.model\n",
      "0s - loss: 0.0292 - acc: 0.9903 - val_loss: 0.0155 - val_acc: 0.9912\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0341 - acc: 0.9861 - val_loss: 0.0167 - val_acc: 0.9912\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.01549 to 0.01539, saving model to best.model\n",
      "0s - loss: 0.0331 - acc: 0.9890 - val_loss: 0.0154 - val_acc: 0.9912\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01539 to 0.01380, saving model to best.model\n",
      "0s - loss: 0.0268 - acc: 0.9890 - val_loss: 0.0138 - val_acc: 0.9912\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9886 - val_loss: 0.0168 - val_acc: 0.9912\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9886 - val_loss: 0.0158 - val_acc: 0.9903\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0153 - val_acc: 0.9903\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.01380 to 0.01344, saving model to best.model\n",
      "0s - loss: 0.0270 - acc: 0.9895 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.01344 to 0.01336, saving model to best.model\n",
      "0s - loss: 0.0250 - acc: 0.9907 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9866 - val_loss: 0.0135 - val_acc: 0.9922\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0267 - acc: 0.9886 - val_loss: 0.0145 - val_acc: 0.9912\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01336 to 0.01250, saving model to best.model\n",
      "0s - loss: 0.0332 - acc: 0.9888 - val_loss: 0.0125 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9905 - val_loss: 0.0146 - val_acc: 0.9912\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9910 - val_loss: 0.0142 - val_acc: 0.9912\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0292 - acc: 0.9893 - val_loss: 0.0161 - val_acc: 0.9912\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0259 - acc: 0.9900 - val_loss: 0.0147 - val_acc: 0.9912\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9903 - val_loss: 0.0129 - val_acc: 0.9922\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0250 - acc: 0.9905 - val_loss: 0.0152 - val_acc: 0.9912\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9876 - val_loss: 0.0130 - val_acc: 0.9912\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9888 - val_loss: 0.0148 - val_acc: 0.9912\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.01250 to 0.01118, saving model to best.model\n",
      "0s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0112 - val_acc: 0.9922\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0244 - acc: 0.9903 - val_loss: 0.0123 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0286 - acc: 0.9883 - val_loss: 0.0125 - val_acc: 0.9922\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0314 - acc: 0.9905 - val_loss: 0.0139 - val_acc: 0.9912\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0276 - acc: 0.9895 - val_loss: 0.0113 - val_acc: 0.9932\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0210 - acc: 0.9922 - val_loss: 0.0137 - val_acc: 0.9912\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9900 - val_loss: 0.0123 - val_acc: 0.9932\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9895 - val_loss: 0.0125 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.01118 to 0.01042, saving model to best.model\n",
      "0s - loss: 0.0262 - acc: 0.9893 - val_loss: 0.0104 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0230 - acc: 0.9920 - val_loss: 0.0148 - val_acc: 0.9912\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67131, saving model to best.model\n",
      "0s - loss: 0.8208 - acc: 0.5004 - val_loss: 0.6713 - val_acc: 0.5278\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67131 to 0.64557, saving model to best.model\n",
      "0s - loss: 0.7439 - acc: 0.5393 - val_loss: 0.6456 - val_acc: 0.7478\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64557 to 0.60147, saving model to best.model\n",
      "0s - loss: 0.6932 - acc: 0.5768 - val_loss: 0.6015 - val_acc: 0.7644\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.60147 to 0.52603, saving model to best.model\n",
      "0s - loss: 0.6447 - acc: 0.6277 - val_loss: 0.5260 - val_acc: 0.8101\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52603 to 0.44521, saving model to best.model\n",
      "0s - loss: 0.5560 - acc: 0.7207 - val_loss: 0.4452 - val_acc: 0.8277\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44521 to 0.39464, saving model to best.model\n",
      "0s - loss: 0.4973 - acc: 0.7765 - val_loss: 0.3946 - val_acc: 0.8374\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39464 to 0.36407, saving model to best.model\n",
      "0s - loss: 0.4465 - acc: 0.8037 - val_loss: 0.3641 - val_acc: 0.8530\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.36407 to 0.33809, saving model to best.model\n",
      "0s - loss: 0.4087 - acc: 0.8232 - val_loss: 0.3381 - val_acc: 0.8627\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33809 to 0.32046, saving model to best.model\n",
      "0s - loss: 0.3927 - acc: 0.8410 - val_loss: 0.3205 - val_acc: 0.8666\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32046 to 0.31064, saving model to best.model\n",
      "0s - loss: 0.3783 - acc: 0.8442 - val_loss: 0.3106 - val_acc: 0.8695\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31064 to 0.29709, saving model to best.model\n",
      "0s - loss: 0.3612 - acc: 0.8563 - val_loss: 0.2971 - val_acc: 0.8783\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29709 to 0.29150, saving model to best.model\n",
      "0s - loss: 0.3463 - acc: 0.8607 - val_loss: 0.2915 - val_acc: 0.8890\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.29150 to 0.27504, saving model to best.model\n",
      "0s - loss: 0.3353 - acc: 0.8739 - val_loss: 0.2750 - val_acc: 0.8861\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27504 to 0.26670, saving model to best.model\n",
      "0s - loss: 0.3147 - acc: 0.8770 - val_loss: 0.2667 - val_acc: 0.8958\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26670 to 0.26055, saving model to best.model\n",
      "0s - loss: 0.3144 - acc: 0.8770 - val_loss: 0.2605 - val_acc: 0.9007\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26055 to 0.25256, saving model to best.model\n",
      "0s - loss: 0.2947 - acc: 0.8839 - val_loss: 0.2526 - val_acc: 0.9017\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25256 to 0.24545, saving model to best.model\n",
      "0s - loss: 0.3047 - acc: 0.8873 - val_loss: 0.2454 - val_acc: 0.9065\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24545 to 0.23817, saving model to best.model\n",
      "0s - loss: 0.2886 - acc: 0.8938 - val_loss: 0.2382 - val_acc: 0.9075\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23817 to 0.23352, saving model to best.model\n",
      "0s - loss: 0.2841 - acc: 0.8887 - val_loss: 0.2335 - val_acc: 0.9104\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.23352 to 0.22796, saving model to best.model\n",
      "0s - loss: 0.2714 - acc: 0.8982 - val_loss: 0.2280 - val_acc: 0.9124\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.22796 to 0.22233, saving model to best.model\n",
      "0s - loss: 0.2699 - acc: 0.8999 - val_loss: 0.2223 - val_acc: 0.9133\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.22233 to 0.21854, saving model to best.model\n",
      "0s - loss: 0.2713 - acc: 0.9016 - val_loss: 0.2185 - val_acc: 0.9133\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21854 to 0.21377, saving model to best.model\n",
      "0s - loss: 0.2609 - acc: 0.9048 - val_loss: 0.2138 - val_acc: 0.9211\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21377 to 0.20888, saving model to best.model\n",
      "0s - loss: 0.2558 - acc: 0.9077 - val_loss: 0.2089 - val_acc: 0.9182\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20888 to 0.20619, saving model to best.model\n",
      "0s - loss: 0.2517 - acc: 0.9106 - val_loss: 0.2062 - val_acc: 0.9202\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.20619 to 0.20459, saving model to best.model\n",
      "0s - loss: 0.2503 - acc: 0.9109 - val_loss: 0.2046 - val_acc: 0.9211\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20459 to 0.20412, saving model to best.model\n",
      "0s - loss: 0.2400 - acc: 0.9116 - val_loss: 0.2041 - val_acc: 0.9192\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.20412 to 0.19580, saving model to best.model\n",
      "0s - loss: 0.2417 - acc: 0.9104 - val_loss: 0.1958 - val_acc: 0.9221\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19580 to 0.19225, saving model to best.model\n",
      "0s - loss: 0.2357 - acc: 0.9165 - val_loss: 0.1922 - val_acc: 0.9221\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19225 to 0.18929, saving model to best.model\n",
      "0s - loss: 0.2352 - acc: 0.9123 - val_loss: 0.1893 - val_acc: 0.9231\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18929 to 0.18614, saving model to best.model\n",
      "0s - loss: 0.2282 - acc: 0.9150 - val_loss: 0.1861 - val_acc: 0.9241\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18614 to 0.18136, saving model to best.model\n",
      "0s - loss: 0.2274 - acc: 0.9196 - val_loss: 0.1814 - val_acc: 0.9270\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.18136 to 0.17722, saving model to best.model\n",
      "0s - loss: 0.2252 - acc: 0.9211 - val_loss: 0.1772 - val_acc: 0.9289\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17722 to 0.17156, saving model to best.model\n",
      "0s - loss: 0.2160 - acc: 0.9196 - val_loss: 0.1716 - val_acc: 0.9289\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17156 to 0.16832, saving model to best.model\n",
      "0s - loss: 0.2132 - acc: 0.9255 - val_loss: 0.1683 - val_acc: 0.9289\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.16832 to 0.16689, saving model to best.model\n",
      "0s - loss: 0.2052 - acc: 0.9238 - val_loss: 0.1669 - val_acc: 0.9260\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16689 to 0.16232, saving model to best.model\n",
      "0s - loss: 0.2038 - acc: 0.9248 - val_loss: 0.1623 - val_acc: 0.9377\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16232 to 0.15882, saving model to best.model\n",
      "0s - loss: 0.2071 - acc: 0.9231 - val_loss: 0.1588 - val_acc: 0.9309\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.15882 to 0.15391, saving model to best.model\n",
      "0s - loss: 0.1942 - acc: 0.9299 - val_loss: 0.1539 - val_acc: 0.9318\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15391 to 0.15042, saving model to best.model\n",
      "0s - loss: 0.2003 - acc: 0.9284 - val_loss: 0.1504 - val_acc: 0.9299\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15042 to 0.14523, saving model to best.model\n",
      "0s - loss: 0.1899 - acc: 0.9289 - val_loss: 0.1452 - val_acc: 0.9377\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14523 to 0.14095, saving model to best.model\n",
      "0s - loss: 0.1964 - acc: 0.9279 - val_loss: 0.1409 - val_acc: 0.9387\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.14095 to 0.13948, saving model to best.model\n",
      "0s - loss: 0.1902 - acc: 0.9311 - val_loss: 0.1395 - val_acc: 0.9445\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13948 to 0.13582, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9340 - val_loss: 0.1358 - val_acc: 0.9416\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13582 to 0.13467, saving model to best.model\n",
      "0s - loss: 0.1853 - acc: 0.9328 - val_loss: 0.1347 - val_acc: 0.9484\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.13467 to 0.12974, saving model to best.model\n",
      "0s - loss: 0.1747 - acc: 0.9364 - val_loss: 0.1297 - val_acc: 0.9406\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.12974 to 0.12612, saving model to best.model\n",
      "0s - loss: 0.1675 - acc: 0.9379 - val_loss: 0.1261 - val_acc: 0.9474\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.12612 to 0.12249, saving model to best.model\n",
      "0s - loss: 0.1650 - acc: 0.9386 - val_loss: 0.1225 - val_acc: 0.9542\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.12249 to 0.12183, saving model to best.model\n",
      "0s - loss: 0.1632 - acc: 0.9423 - val_loss: 0.1218 - val_acc: 0.9494\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12183 to 0.11415, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9364 - val_loss: 0.1142 - val_acc: 0.9484\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.1544 - acc: 0.9423 - val_loss: 0.1146 - val_acc: 0.9581\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11415 to 0.10840, saving model to best.model\n",
      "0s - loss: 0.1517 - acc: 0.9455 - val_loss: 0.1084 - val_acc: 0.9581\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.10840 to 0.10591, saving model to best.model\n",
      "0s - loss: 0.1508 - acc: 0.9442 - val_loss: 0.1059 - val_acc: 0.9591\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10591 to 0.10212, saving model to best.model\n",
      "0s - loss: 0.1452 - acc: 0.9481 - val_loss: 0.1021 - val_acc: 0.9659\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10212 to 0.10098, saving model to best.model\n",
      "0s - loss: 0.1371 - acc: 0.9496 - val_loss: 0.1010 - val_acc: 0.9630\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.10098 to 0.09889, saving model to best.model\n",
      "0s - loss: 0.1424 - acc: 0.9481 - val_loss: 0.0989 - val_acc: 0.9659\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.09889 to 0.09750, saving model to best.model\n",
      "0s - loss: 0.1405 - acc: 0.9484 - val_loss: 0.0975 - val_acc: 0.9649\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09750 to 0.09376, saving model to best.model\n",
      "0s - loss: 0.1394 - acc: 0.9479 - val_loss: 0.0938 - val_acc: 0.9640\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.09376 to 0.08908, saving model to best.model\n",
      "0s - loss: 0.1334 - acc: 0.9506 - val_loss: 0.0891 - val_acc: 0.9698\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.08908 to 0.08850, saving model to best.model\n",
      "0s - loss: 0.1324 - acc: 0.9477 - val_loss: 0.0885 - val_acc: 0.9698\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.08850 to 0.08518, saving model to best.model\n",
      "0s - loss: 0.1322 - acc: 0.9513 - val_loss: 0.0852 - val_acc: 0.9766\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1250 - acc: 0.9508 - val_loss: 0.0862 - val_acc: 0.9659\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08518 to 0.08018, saving model to best.model\n",
      "0s - loss: 0.1308 - acc: 0.9486 - val_loss: 0.0802 - val_acc: 0.9757\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.1269 - acc: 0.9542 - val_loss: 0.0821 - val_acc: 0.9718\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.1199 - acc: 0.9535 - val_loss: 0.0815 - val_acc: 0.9727\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08018 to 0.07774, saving model to best.model\n",
      "0s - loss: 0.1250 - acc: 0.9567 - val_loss: 0.0777 - val_acc: 0.9708\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.07774 to 0.07350, saving model to best.model\n",
      "0s - loss: 0.1117 - acc: 0.9637 - val_loss: 0.0735 - val_acc: 0.9796\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.07350 to 0.07253, saving model to best.model\n",
      "0s - loss: 0.1073 - acc: 0.9593 - val_loss: 0.0725 - val_acc: 0.9805\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07253 to 0.07045, saving model to best.model\n",
      "0s - loss: 0.1135 - acc: 0.9579 - val_loss: 0.0705 - val_acc: 0.9815\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.07045 to 0.06567, saving model to best.model\n",
      "0s - loss: 0.1134 - acc: 0.9567 - val_loss: 0.0657 - val_acc: 0.9805\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.06567 to 0.06285, saving model to best.model\n",
      "0s - loss: 0.1059 - acc: 0.9596 - val_loss: 0.0629 - val_acc: 0.9805\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.06285 to 0.06178, saving model to best.model\n",
      "0s - loss: 0.1096 - acc: 0.9657 - val_loss: 0.0618 - val_acc: 0.9825\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.1126 - acc: 0.9542 - val_loss: 0.0684 - val_acc: 0.9737\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.06178 to 0.05968, saving model to best.model\n",
      "0s - loss: 0.1134 - acc: 0.9559 - val_loss: 0.0597 - val_acc: 0.9825\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.05968 to 0.05744, saving model to best.model\n",
      "0s - loss: 0.0993 - acc: 0.9659 - val_loss: 0.0574 - val_acc: 0.9834\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.05744 to 0.05695, saving model to best.model\n",
      "0s - loss: 0.0951 - acc: 0.9649 - val_loss: 0.0569 - val_acc: 0.9834\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.05695 to 0.05536, saving model to best.model\n",
      "0s - loss: 0.0969 - acc: 0.9662 - val_loss: 0.0554 - val_acc: 0.9815\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.05536 to 0.05509, saving model to best.model\n",
      "0s - loss: 0.0972 - acc: 0.9630 - val_loss: 0.0551 - val_acc: 0.9834\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05509 to 0.05162, saving model to best.model\n",
      "0s - loss: 0.0900 - acc: 0.9669 - val_loss: 0.0516 - val_acc: 0.9844\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.05162 to 0.05107, saving model to best.model\n",
      "0s - loss: 0.0982 - acc: 0.9637 - val_loss: 0.0511 - val_acc: 0.9834\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.1042 - acc: 0.9593 - val_loss: 0.0517 - val_acc: 0.9815\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05107 to 0.04997, saving model to best.model\n",
      "0s - loss: 0.0910 - acc: 0.9647 - val_loss: 0.0500 - val_acc: 0.9844\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.04997 to 0.04699, saving model to best.model\n",
      "0s - loss: 0.0832 - acc: 0.9652 - val_loss: 0.0470 - val_acc: 0.9854\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.04699 to 0.04494, saving model to best.model\n",
      "0s - loss: 0.0863 - acc: 0.9640 - val_loss: 0.0449 - val_acc: 0.9844\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.04494 to 0.04289, saving model to best.model\n",
      "0s - loss: 0.0778 - acc: 0.9701 - val_loss: 0.0429 - val_acc: 0.9844\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.04289 to 0.04058, saving model to best.model\n",
      "0s - loss: 0.0744 - acc: 0.9708 - val_loss: 0.0406 - val_acc: 0.9844\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04058 to 0.03904, saving model to best.model\n",
      "0s - loss: 0.0835 - acc: 0.9693 - val_loss: 0.0390 - val_acc: 0.9854\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.03904 to 0.03838, saving model to best.model\n",
      "0s - loss: 0.0865 - acc: 0.9693 - val_loss: 0.0384 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.03838 to 0.03833, saving model to best.model\n",
      "0s - loss: 0.0766 - acc: 0.9703 - val_loss: 0.0383 - val_acc: 0.9854\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03833 to 0.03778, saving model to best.model\n",
      "0s - loss: 0.0773 - acc: 0.9708 - val_loss: 0.0378 - val_acc: 0.9854\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.03778 to 0.03604, saving model to best.model\n",
      "0s - loss: 0.0690 - acc: 0.9737 - val_loss: 0.0360 - val_acc: 0.9854\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.03604 to 0.03367, saving model to best.model\n",
      "0s - loss: 0.0787 - acc: 0.9705 - val_loss: 0.0337 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0674 - acc: 0.9759 - val_loss: 0.0345 - val_acc: 0.9854\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.03367 to 0.03309, saving model to best.model\n",
      "0s - loss: 0.0690 - acc: 0.9759 - val_loss: 0.0331 - val_acc: 0.9854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.03309 to 0.03177, saving model to best.model\n",
      "0s - loss: 0.0755 - acc: 0.9691 - val_loss: 0.0318 - val_acc: 0.9854\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0723 - acc: 0.9732 - val_loss: 0.0318 - val_acc: 0.9873\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.03177 to 0.03059, saving model to best.model\n",
      "0s - loss: 0.0737 - acc: 0.9732 - val_loss: 0.0306 - val_acc: 0.9903\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.03059 to 0.02948, saving model to best.model\n",
      "0s - loss: 0.0701 - acc: 0.9737 - val_loss: 0.0295 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0641 - acc: 0.9749 - val_loss: 0.0296 - val_acc: 0.9854\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02948 to 0.02799, saving model to best.model\n",
      "0s - loss: 0.0716 - acc: 0.9752 - val_loss: 0.0280 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.02799 to 0.02703, saving model to best.model\n",
      "0s - loss: 0.0654 - acc: 0.9757 - val_loss: 0.0270 - val_acc: 0.9854\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0806 - acc: 0.9708 - val_loss: 0.0324 - val_acc: 0.9864\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0619 - acc: 0.9781 - val_loss: 0.0291 - val_acc: 0.9951\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.02703 to 0.02615, saving model to best.model\n",
      "0s - loss: 0.0654 - acc: 0.9761 - val_loss: 0.0262 - val_acc: 0.9903\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.02615 to 0.02475, saving model to best.model\n",
      "0s - loss: 0.0661 - acc: 0.9749 - val_loss: 0.0248 - val_acc: 0.9903\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.02475 to 0.02419, saving model to best.model\n",
      "0s - loss: 0.0619 - acc: 0.9783 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0671 - acc: 0.9761 - val_loss: 0.0258 - val_acc: 0.9912\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.02419 to 0.02302, saving model to best.model\n",
      "0s - loss: 0.0631 - acc: 0.9757 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02302 to 0.02194, saving model to best.model\n",
      "0s - loss: 0.0569 - acc: 0.9800 - val_loss: 0.0219 - val_acc: 0.9922\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0618 - acc: 0.9786 - val_loss: 0.0241 - val_acc: 0.9854\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.0651 - acc: 0.9766 - val_loss: 0.0221 - val_acc: 0.9922\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02194 to 0.02187, saving model to best.model\n",
      "0s - loss: 0.0566 - acc: 0.9783 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0545 - acc: 0.9800 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0644 - acc: 0.9771 - val_loss: 0.0231 - val_acc: 0.9951\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.0630 - acc: 0.9774 - val_loss: 0.0220 - val_acc: 0.9922\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.02187 to 0.02104, saving model to best.model\n",
      "0s - loss: 0.0588 - acc: 0.9783 - val_loss: 0.0210 - val_acc: 0.9951\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.02104 to 0.01956, saving model to best.model\n",
      "0s - loss: 0.0519 - acc: 0.9795 - val_loss: 0.0196 - val_acc: 0.9922\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.01956 to 0.01935, saving model to best.model\n",
      "0s - loss: 0.0568 - acc: 0.9791 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.01935 to 0.01843, saving model to best.model\n",
      "0s - loss: 0.0524 - acc: 0.9815 - val_loss: 0.0184 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.01843 to 0.01800, saving model to best.model\n",
      "0s - loss: 0.0563 - acc: 0.9791 - val_loss: 0.0180 - val_acc: 0.9932\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.01800 to 0.01762, saving model to best.model\n",
      "0s - loss: 0.0498 - acc: 0.9805 - val_loss: 0.0176 - val_acc: 0.9932\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.01762 to 0.01735, saving model to best.model\n",
      "0s - loss: 0.0511 - acc: 0.9795 - val_loss: 0.0173 - val_acc: 0.9922\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9817 - val_loss: 0.0176 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.01735 to 0.01728, saving model to best.model\n",
      "0s - loss: 0.0514 - acc: 0.9805 - val_loss: 0.0173 - val_acc: 0.9932\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.01728 to 0.01720, saving model to best.model\n",
      "0s - loss: 0.0471 - acc: 0.9808 - val_loss: 0.0172 - val_acc: 0.9932\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.01720 to 0.01659, saving model to best.model\n",
      "0s - loss: 0.0553 - acc: 0.9795 - val_loss: 0.0166 - val_acc: 0.9922\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.01659 to 0.01647, saving model to best.model\n",
      "0s - loss: 0.0519 - acc: 0.9791 - val_loss: 0.0165 - val_acc: 0.9951\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.01647 to 0.01578, saving model to best.model\n",
      "0s - loss: 0.0470 - acc: 0.9822 - val_loss: 0.0158 - val_acc: 0.9932\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.01578 to 0.01532, saving model to best.model\n",
      "0s - loss: 0.0451 - acc: 0.9813 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.01532 to 0.01525, saving model to best.model\n",
      "0s - loss: 0.0459 - acc: 0.9827 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.01525 to 0.01510, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9815 - val_loss: 0.0151 - val_acc: 0.9951\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01510 to 0.01450, saving model to best.model\n",
      "0s - loss: 0.0429 - acc: 0.9834 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01450 to 0.01392, saving model to best.model\n",
      "0s - loss: 0.0491 - acc: 0.9810 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9837 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.01392 to 0.01352, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9820 - val_loss: 0.0135 - val_acc: 0.9951\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.01352 to 0.01311, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9825 - val_loss: 0.0131 - val_acc: 0.9961\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0431 - acc: 0.9856 - val_loss: 0.0132 - val_acc: 0.9951\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.01311 to 0.01290, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9832 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01290 to 0.01258, saving model to best.model\n",
      "0s - loss: 0.0406 - acc: 0.9849 - val_loss: 0.0126 - val_acc: 0.9942\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.01258 to 0.01245, saving model to best.model\n",
      "0s - loss: 0.0468 - acc: 0.9795 - val_loss: 0.0125 - val_acc: 0.9942\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.01245 to 0.01232, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0123 - val_acc: 0.9961\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.01232 to 0.01177, saving model to best.model\n",
      "0s - loss: 0.0455 - acc: 0.9842 - val_loss: 0.0118 - val_acc: 0.9961\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.01177 to 0.01160, saving model to best.model\n",
      "0s - loss: 0.0387 - acc: 0.9859 - val_loss: 0.0116 - val_acc: 0.9961\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.01160 to 0.01127, saving model to best.model\n",
      "0s - loss: 0.0403 - acc: 0.9827 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01127 to 0.01090, saving model to best.model\n",
      "0s - loss: 0.0405 - acc: 0.9842 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01090 to 0.01067, saving model to best.model\n",
      "0s - loss: 0.0360 - acc: 0.9873 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0410 - acc: 0.9859 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9871 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9839 - val_loss: 0.0116 - val_acc: 0.9942\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9854 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9869 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9890 - val_loss: 0.0111 - val_acc: 0.9961\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01067 to 0.01061, saving model to best.model\n",
      "0s - loss: 0.0365 - acc: 0.9861 - val_loss: 0.0106 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01061 to 0.01029, saving model to best.model\n",
      "0s - loss: 0.0316 - acc: 0.9888 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.01029 to 0.00994, saving model to best.model\n",
      "0s - loss: 0.0362 - acc: 0.9869 - val_loss: 0.0099 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.00994 to 0.00990, saving model to best.model\n",
      "0s - loss: 0.0397 - acc: 0.9839 - val_loss: 0.0099 - val_acc: 0.9951\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0381 - acc: 0.9873 - val_loss: 0.0103 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.00990 to 0.00973, saving model to best.model\n",
      "0s - loss: 0.0312 - acc: 0.9866 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9876 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9866 - val_loss: 0.0102 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0422 - acc: 0.9839 - val_loss: 0.0104 - val_acc: 0.9961\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9871 - val_loss: 0.0100 - val_acc: 0.9951\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.00973 to 0.00954, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9883 - val_loss: 0.0095 - val_acc: 0.9961\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.00954 to 0.00915, saving model to best.model\n",
      "0s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.00915 to 0.00907, saving model to best.model\n",
      "0s - loss: 0.0332 - acc: 0.9886 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9861 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0310 - acc: 0.9888 - val_loss: 0.0092 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.00907 to 0.00883, saving model to best.model\n",
      "0s - loss: 0.0365 - acc: 0.9878 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.00883 to 0.00866, saving model to best.model\n",
      "0s - loss: 0.0321 - acc: 0.9876 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.00866 to 0.00848, saving model to best.model\n",
      "0s - loss: 0.0315 - acc: 0.9878 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.00848 to 0.00832, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9917 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.00832 to 0.00799, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9903 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9871 - val_loss: 0.0082 - val_acc: 0.9951\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0282 - acc: 0.9905 - val_loss: 0.0124 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0316 - acc: 0.9895 - val_loss: 0.0104 - val_acc: 0.9951\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0303 - acc: 0.9888 - val_loss: 0.0096 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9895 - val_loss: 0.0089 - val_acc: 0.9971\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0322 - acc: 0.9886 - val_loss: 0.0120 - val_acc: 0.9961\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0432 - acc: 0.9834 - val_loss: 0.0105 - val_acc: 0.9942\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9864 - val_loss: 0.0096 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9893 - val_loss: 0.0090 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0289 - acc: 0.9878 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9903 - val_loss: 0.0081 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.00799 to 0.00773, saving model to best.model\n",
      "0s - loss: 0.0291 - acc: 0.9903 - val_loss: 0.0077 - val_acc: 0.9961\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.00773 to 0.00733, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9895 - val_loss: 0.0073 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.00733 to 0.00725, saving model to best.model\n",
      "0s - loss: 0.0275 - acc: 0.9893 - val_loss: 0.0073 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0313 - acc: 0.9869 - val_loss: 0.0077 - val_acc: 0.9971\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0277 - acc: 0.9903 - val_loss: 0.0073 - val_acc: 0.9971\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.00725 to 0.00683, saving model to best.model\n",
      "0s - loss: 0.0259 - acc: 0.9912 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00683 to 0.00662, saving model to best.model\n",
      "0s - loss: 0.0280 - acc: 0.9890 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00662 to 0.00660, saving model to best.model\n",
      "0s - loss: 0.0288 - acc: 0.9900 - val_loss: 0.0066 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9890 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0290 - acc: 0.9890 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0265 - acc: 0.9895 - val_loss: 0.0067 - val_acc: 0.9971\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.00660 to 0.00655, saving model to best.model\n",
      "0s - loss: 0.0278 - acc: 0.9898 - val_loss: 0.0065 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00655 to 0.00632, saving model to best.model\n",
      "0s - loss: 0.0238 - acc: 0.9910 - val_loss: 0.0063 - val_acc: 0.9971\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.00632 to 0.00592, saving model to best.model\n",
      "0s - loss: 0.0263 - acc: 0.9898 - val_loss: 0.0059 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.00592 to 0.00576, saving model to best.model\n",
      "0s - loss: 0.0264 - acc: 0.9907 - val_loss: 0.0058 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.00576 to 0.00572, saving model to best.model\n",
      "0s - loss: 0.0211 - acc: 0.9920 - val_loss: 0.0057 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00572 to 0.00564, saving model to best.model\n",
      "0s - loss: 0.0239 - acc: 0.9907 - val_loss: 0.0056 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67254, saving model to best.model\n",
      "0s - loss: 0.8102 - acc: 0.5113 - val_loss: 0.6725 - val_acc: 0.4927\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67254 to 0.63718, saving model to best.model\n",
      "0s - loss: 0.7428 - acc: 0.5449 - val_loss: 0.6372 - val_acc: 0.7556\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63718 to 0.58558, saving model to best.model\n",
      "0s - loss: 0.6873 - acc: 0.5849 - val_loss: 0.5856 - val_acc: 0.7877\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58558 to 0.50341, saving model to best.model\n",
      "0s - loss: 0.6185 - acc: 0.6557 - val_loss: 0.5034 - val_acc: 0.8092\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.50341 to 0.43336, saving model to best.model\n",
      "0s - loss: 0.5451 - acc: 0.7317 - val_loss: 0.4334 - val_acc: 0.8208\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.43336 to 0.40392, saving model to best.model\n",
      "0s - loss: 0.4859 - acc: 0.7784 - val_loss: 0.4039 - val_acc: 0.8315\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.40392 to 0.35467, saving model to best.model\n",
      "0s - loss: 0.4483 - acc: 0.8035 - val_loss: 0.3547 - val_acc: 0.8491\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.35467 to 0.33187, saving model to best.model\n",
      "0s - loss: 0.4242 - acc: 0.8269 - val_loss: 0.3319 - val_acc: 0.8656\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.33187 to 0.31509, saving model to best.model\n",
      "0s - loss: 0.3863 - acc: 0.8405 - val_loss: 0.3151 - val_acc: 0.8705\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.31509 to 0.30981, saving model to best.model\n",
      "0s - loss: 0.3773 - acc: 0.8471 - val_loss: 0.3098 - val_acc: 0.8715\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30981 to 0.28356, saving model to best.model\n",
      "0s - loss: 0.3616 - acc: 0.8566 - val_loss: 0.2836 - val_acc: 0.8802\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28356 to 0.27320, saving model to best.model\n",
      "0s - loss: 0.3434 - acc: 0.8644 - val_loss: 0.2732 - val_acc: 0.8841\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.3462 - acc: 0.8563 - val_loss: 0.2736 - val_acc: 0.8870\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27320 to 0.26910, saving model to best.model\n",
      "0s - loss: 0.3213 - acc: 0.8734 - val_loss: 0.2691 - val_acc: 0.8890\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.26910 to 0.25528, saving model to best.model\n",
      "0s - loss: 0.3177 - acc: 0.8787 - val_loss: 0.2553 - val_acc: 0.8948\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.3025 - acc: 0.8812 - val_loss: 0.2579 - val_acc: 0.8968\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.25528 to 0.24254, saving model to best.model\n",
      "0s - loss: 0.3038 - acc: 0.8848 - val_loss: 0.2425 - val_acc: 0.9075\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.24254 to 0.23693, saving model to best.model\n",
      "0s - loss: 0.2910 - acc: 0.8902 - val_loss: 0.2369 - val_acc: 0.9104\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.23693 to 0.23252, saving model to best.model\n",
      "0s - loss: 0.2892 - acc: 0.8892 - val_loss: 0.2325 - val_acc: 0.9133\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.2815 - acc: 0.8946 - val_loss: 0.2389 - val_acc: 0.9065\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.23252 to 0.21936, saving model to best.model\n",
      "0s - loss: 0.2829 - acc: 0.8929 - val_loss: 0.2194 - val_acc: 0.9143\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2710 - acc: 0.8953 - val_loss: 0.2202 - val_acc: 0.9133\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21936 to 0.21331, saving model to best.model\n",
      "0s - loss: 0.2687 - acc: 0.9004 - val_loss: 0.2133 - val_acc: 0.9202\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.21331 to 0.21174, saving model to best.model\n",
      "0s - loss: 0.2665 - acc: 0.9033 - val_loss: 0.2117 - val_acc: 0.9163\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2651 - acc: 0.9011 - val_loss: 0.2153 - val_acc: 0.9143\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21174 to 0.20550, saving model to best.model\n",
      "0s - loss: 0.2504 - acc: 0.9082 - val_loss: 0.2055 - val_acc: 0.9153\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.20550 to 0.19885, saving model to best.model\n",
      "0s - loss: 0.2490 - acc: 0.9036 - val_loss: 0.1989 - val_acc: 0.9202\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19885 to 0.19790, saving model to best.model\n",
      "0s - loss: 0.2509 - acc: 0.9089 - val_loss: 0.1979 - val_acc: 0.9182\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.19790 to 0.19413, saving model to best.model\n",
      "0s - loss: 0.2439 - acc: 0.9094 - val_loss: 0.1941 - val_acc: 0.9192\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.19413 to 0.18495, saving model to best.model\n",
      "0s - loss: 0.2342 - acc: 0.9089 - val_loss: 0.1849 - val_acc: 0.9241\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.2285 - acc: 0.9094 - val_loss: 0.1852 - val_acc: 0.9250\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.18495 to 0.17806, saving model to best.model\n",
      "0s - loss: 0.2306 - acc: 0.9128 - val_loss: 0.1781 - val_acc: 0.9289\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17806 to 0.17562, saving model to best.model\n",
      "0s - loss: 0.2250 - acc: 0.9092 - val_loss: 0.1756 - val_acc: 0.9260\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17562 to 0.17264, saving model to best.model\n",
      "0s - loss: 0.2288 - acc: 0.9109 - val_loss: 0.1726 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.2186 - acc: 0.9187 - val_loss: 0.1747 - val_acc: 0.9260\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.17264 to 0.16661, saving model to best.model\n",
      "0s - loss: 0.2179 - acc: 0.9175 - val_loss: 0.1666 - val_acc: 0.9289\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16661 to 0.16072, saving model to best.model\n",
      "0s - loss: 0.2115 - acc: 0.9177 - val_loss: 0.1607 - val_acc: 0.9309\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16072 to 0.15837, saving model to best.model\n",
      "0s - loss: 0.2085 - acc: 0.9182 - val_loss: 0.1584 - val_acc: 0.9299\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.2073 - acc: 0.9206 - val_loss: 0.1614 - val_acc: 0.9299\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15837 to 0.14877, saving model to best.model\n",
      "0s - loss: 0.1982 - acc: 0.9223 - val_loss: 0.1488 - val_acc: 0.9328\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.1987 - acc: 0.9214 - val_loss: 0.1546 - val_acc: 0.9299\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.14877 to 0.13927, saving model to best.model\n",
      "0s - loss: 0.1939 - acc: 0.9233 - val_loss: 0.1393 - val_acc: 0.9348\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.13927 to 0.13424, saving model to best.model\n",
      "0s - loss: 0.1874 - acc: 0.9257 - val_loss: 0.1342 - val_acc: 0.9435\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.13424 to 0.13149, saving model to best.model\n",
      "0s - loss: 0.1743 - acc: 0.9311 - val_loss: 0.1315 - val_acc: 0.9416\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.13149 to 0.13001, saving model to best.model\n",
      "0s - loss: 0.1803 - acc: 0.9323 - val_loss: 0.1300 - val_acc: 0.9455\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.1754 - acc: 0.9308 - val_loss: 0.1326 - val_acc: 0.9387\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13001 to 0.12066, saving model to best.model\n",
      "0s - loss: 0.1765 - acc: 0.9318 - val_loss: 0.1207 - val_acc: 0.9572\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.12066 to 0.11946, saving model to best.model\n",
      "0s - loss: 0.1726 - acc: 0.9343 - val_loss: 0.1195 - val_acc: 0.9533\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.11946 to 0.11671, saving model to best.model\n",
      "0s - loss: 0.1672 - acc: 0.9362 - val_loss: 0.1167 - val_acc: 0.9542\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.11671 to 0.11469, saving model to best.model\n",
      "0s - loss: 0.1631 - acc: 0.9377 - val_loss: 0.1147 - val_acc: 0.9523\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.11469 to 0.11185, saving model to best.model\n",
      "0s - loss: 0.1570 - acc: 0.9377 - val_loss: 0.1119 - val_acc: 0.9542\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.11185 to 0.10704, saving model to best.model\n",
      "0s - loss: 0.1510 - acc: 0.9411 - val_loss: 0.1070 - val_acc: 0.9591\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.1629 - acc: 0.9347 - val_loss: 0.1085 - val_acc: 0.9591\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.10704 to 0.10199, saving model to best.model\n",
      "0s - loss: 0.1486 - acc: 0.9418 - val_loss: 0.1020 - val_acc: 0.9620\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.10199 to 0.09881, saving model to best.model\n",
      "0s - loss: 0.1524 - acc: 0.9406 - val_loss: 0.0988 - val_acc: 0.9669\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.09881 to 0.09772, saving model to best.model\n",
      "0s - loss: 0.1589 - acc: 0.9425 - val_loss: 0.0977 - val_acc: 0.9659\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.1443 - acc: 0.9440 - val_loss: 0.1000 - val_acc: 0.9659\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.09772 to 0.09245, saving model to best.model\n",
      "0s - loss: 0.1410 - acc: 0.9462 - val_loss: 0.0924 - val_acc: 0.9679\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.1424 - acc: 0.9494 - val_loss: 0.1069 - val_acc: 0.9533\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09245 to 0.08975, saving model to best.model\n",
      "0s - loss: 0.1439 - acc: 0.9479 - val_loss: 0.0898 - val_acc: 0.9679\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.1339 - acc: 0.9486 - val_loss: 0.0900 - val_acc: 0.9708\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1361 - acc: 0.9484 - val_loss: 0.0911 - val_acc: 0.9688\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.08975 to 0.08486, saving model to best.model\n",
      "0s - loss: 0.1346 - acc: 0.9481 - val_loss: 0.0849 - val_acc: 0.9737\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08486 to 0.08070, saving model to best.model\n",
      "0s - loss: 0.1260 - acc: 0.9498 - val_loss: 0.0807 - val_acc: 0.9737\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08070 to 0.08036, saving model to best.model\n",
      "0s - loss: 0.1280 - acc: 0.9537 - val_loss: 0.0804 - val_acc: 0.9747\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08036 to 0.07677, saving model to best.model\n",
      "0s - loss: 0.1265 - acc: 0.9494 - val_loss: 0.0768 - val_acc: 0.9718\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1260 - acc: 0.9498 - val_loss: 0.0814 - val_acc: 0.9747\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1208 - acc: 0.9542 - val_loss: 0.0803 - val_acc: 0.9757\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.07677 to 0.07176, saving model to best.model\n",
      "0s - loss: 0.1219 - acc: 0.9550 - val_loss: 0.0718 - val_acc: 0.9757\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.1190 - acc: 0.9557 - val_loss: 0.0754 - val_acc: 0.9766\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.07176 to 0.07008, saving model to best.model\n",
      "0s - loss: 0.1252 - acc: 0.9571 - val_loss: 0.0701 - val_acc: 0.9776\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.1125 - acc: 0.9552 - val_loss: 0.0706 - val_acc: 0.9766\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07008 to 0.06745, saving model to best.model\n",
      "0s - loss: 0.1103 - acc: 0.9554 - val_loss: 0.0675 - val_acc: 0.9766\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1086 - acc: 0.9581 - val_loss: 0.0726 - val_acc: 0.9766\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.06745 to 0.06552, saving model to best.model\n",
      "0s - loss: 0.1090 - acc: 0.9579 - val_loss: 0.0655 - val_acc: 0.9786\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.1032 - acc: 0.9625 - val_loss: 0.0679 - val_acc: 0.9776\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06552 to 0.06106, saving model to best.model\n",
      "0s - loss: 0.1054 - acc: 0.9613 - val_loss: 0.0611 - val_acc: 0.9776\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06106 to 0.05781, saving model to best.model\n",
      "0s - loss: 0.1025 - acc: 0.9630 - val_loss: 0.0578 - val_acc: 0.9786\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.05781 to 0.05764, saving model to best.model\n",
      "0s - loss: 0.1063 - acc: 0.9586 - val_loss: 0.0576 - val_acc: 0.9796\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.1000 - acc: 0.9627 - val_loss: 0.0588 - val_acc: 0.9786\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05764 to 0.05738, saving model to best.model\n",
      "0s - loss: 0.1003 - acc: 0.9625 - val_loss: 0.0574 - val_acc: 0.9796\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05738 to 0.05433, saving model to best.model\n",
      "0s - loss: 0.1024 - acc: 0.9625 - val_loss: 0.0543 - val_acc: 0.9796\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0998 - acc: 0.9627 - val_loss: 0.0556 - val_acc: 0.9834\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.05433 to 0.05166, saving model to best.model\n",
      "0s - loss: 0.0988 - acc: 0.9615 - val_loss: 0.0517 - val_acc: 0.9825\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05166 to 0.05110, saving model to best.model\n",
      "0s - loss: 0.0883 - acc: 0.9674 - val_loss: 0.0511 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05110 to 0.04958, saving model to best.model\n",
      "0s - loss: 0.0893 - acc: 0.9647 - val_loss: 0.0496 - val_acc: 0.9815\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.04958 to 0.04850, saving model to best.model\n",
      "0s - loss: 0.0928 - acc: 0.9630 - val_loss: 0.0485 - val_acc: 0.9805\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.0953 - acc: 0.9637 - val_loss: 0.0488 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0926 - acc: 0.9635 - val_loss: 0.0493 - val_acc: 0.9844\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.04850 to 0.04519, saving model to best.model\n",
      "0s - loss: 0.0897 - acc: 0.9664 - val_loss: 0.0452 - val_acc: 0.9864\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0887 - acc: 0.9647 - val_loss: 0.0467 - val_acc: 0.9844\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.0844 - acc: 0.9669 - val_loss: 0.0473 - val_acc: 0.9834\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.04519 to 0.04229, saving model to best.model\n",
      "0s - loss: 0.0861 - acc: 0.9674 - val_loss: 0.0423 - val_acc: 0.9864\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0762 - acc: 0.9715 - val_loss: 0.0467 - val_acc: 0.9854\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04229 to 0.04122, saving model to best.model\n",
      "0s - loss: 0.0915 - acc: 0.9662 - val_loss: 0.0412 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0851 - acc: 0.9679 - val_loss: 0.0442 - val_acc: 0.9873\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.04122 to 0.03947, saving model to best.model\n",
      "0s - loss: 0.0792 - acc: 0.9688 - val_loss: 0.0395 - val_acc: 0.9864\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.0758 - acc: 0.9698 - val_loss: 0.0423 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03947 to 0.03694, saving model to best.model\n",
      "0s - loss: 0.0731 - acc: 0.9749 - val_loss: 0.0369 - val_acc: 0.9873\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0672 - acc: 0.9739 - val_loss: 0.0411 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03694 to 0.03457, saving model to best.model\n",
      "0s - loss: 0.0686 - acc: 0.9735 - val_loss: 0.0346 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.0726 - acc: 0.9727 - val_loss: 0.0352 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.03457 to 0.03297, saving model to best.model\n",
      "0s - loss: 0.0672 - acc: 0.9759 - val_loss: 0.0330 - val_acc: 0.9893\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0758 - acc: 0.9703 - val_loss: 0.0458 - val_acc: 0.9864\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0708 - acc: 0.9752 - val_loss: 0.0349 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0740 - acc: 0.9713 - val_loss: 0.0337 - val_acc: 0.9873\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0697 - acc: 0.9764 - val_loss: 0.0356 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.0688 - acc: 0.9749 - val_loss: 0.0339 - val_acc: 0.9873\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03297 to 0.03111, saving model to best.model\n",
      "0s - loss: 0.0697 - acc: 0.9752 - val_loss: 0.0311 - val_acc: 0.9893\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0673 - acc: 0.9754 - val_loss: 0.0345 - val_acc: 0.9883\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03111 to 0.03039, saving model to best.model\n",
      "0s - loss: 0.0712 - acc: 0.9732 - val_loss: 0.0304 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.0627 - acc: 0.9774 - val_loss: 0.0309 - val_acc: 0.9903\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0639 - acc: 0.9778 - val_loss: 0.0308 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0605 - acc: 0.9776 - val_loss: 0.0308 - val_acc: 0.9883\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.03039 to 0.03022, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9764 - val_loss: 0.0302 - val_acc: 0.9873\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0724 - acc: 0.9713 - val_loss: 0.0303 - val_acc: 0.9873\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.03022 to 0.02753, saving model to best.model\n",
      "0s - loss: 0.0635 - acc: 0.9764 - val_loss: 0.0275 - val_acc: 0.9873\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9774 - val_loss: 0.0312 - val_acc: 0.9873\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.02753 to 0.02641, saving model to best.model\n",
      "0s - loss: 0.0663 - acc: 0.9732 - val_loss: 0.0264 - val_acc: 0.9893\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0606 - acc: 0.9774 - val_loss: 0.0331 - val_acc: 0.9873\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0511 - acc: 0.9820 - val_loss: 0.0286 - val_acc: 0.9873\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0554 - acc: 0.9781 - val_loss: 0.0267 - val_acc: 0.9873\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02641 to 0.02485, saving model to best.model\n",
      "0s - loss: 0.0527 - acc: 0.9798 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02485 to 0.02416, saving model to best.model\n",
      "0s - loss: 0.0581 - acc: 0.9764 - val_loss: 0.0242 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9793 - val_loss: 0.0246 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0588 - acc: 0.9776 - val_loss: 0.0283 - val_acc: 0.9883\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02416 to 0.02363, saving model to best.model\n",
      "0s - loss: 0.0557 - acc: 0.9803 - val_loss: 0.0236 - val_acc: 0.9903\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9798 - val_loss: 0.0249 - val_acc: 0.9883\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0516 - acc: 0.9769 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0543 - acc: 0.9798 - val_loss: 0.0254 - val_acc: 0.9903\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0521 - acc: 0.9793 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.02363 to 0.02327, saving model to best.model\n",
      "0s - loss: 0.0564 - acc: 0.9791 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0526 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.02327 to 0.01997, saving model to best.model\n",
      "0s - loss: 0.0448 - acc: 0.9834 - val_loss: 0.0200 - val_acc: 0.9922\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9832 - val_loss: 0.0239 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9786 - val_loss: 0.0244 - val_acc: 0.9883\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01997 to 0.01836, saving model to best.model\n",
      "0s - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0184 - val_acc: 0.9932\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9822 - val_loss: 0.0241 - val_acc: 0.9883\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9808 - val_loss: 0.0206 - val_acc: 0.9922\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0497 - acc: 0.9815 - val_loss: 0.0219 - val_acc: 0.9903\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0437 - acc: 0.9832 - val_loss: 0.0190 - val_acc: 0.9922\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0421 - acc: 0.9837 - val_loss: 0.0211 - val_acc: 0.9903\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9861 - val_loss: 0.0188 - val_acc: 0.9922\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9866 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9839 - val_loss: 0.0191 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0445 - acc: 0.9834 - val_loss: 0.0189 - val_acc: 0.9922\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.01836 to 0.01707, saving model to best.model\n",
      "0s - loss: 0.0518 - acc: 0.9813 - val_loss: 0.0171 - val_acc: 0.9932\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0465 - acc: 0.9813 - val_loss: 0.0204 - val_acc: 0.9912\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01707 to 0.01696, saving model to best.model\n",
      "0s - loss: 0.0448 - acc: 0.9817 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01696 to 0.01671, saving model to best.model\n",
      "0s - loss: 0.0395 - acc: 0.9851 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9839 - val_loss: 0.0178 - val_acc: 0.9912\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0362 - acc: 0.9871 - val_loss: 0.0178 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9847 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.01671 to 0.01639, saving model to best.model\n",
      "0s - loss: 0.0447 - acc: 0.9827 - val_loss: 0.0164 - val_acc: 0.9942\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0540 - acc: 0.9793 - val_loss: 0.0169 - val_acc: 0.9932\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.01639 to 0.01628, saving model to best.model\n",
      "0s - loss: 0.0388 - acc: 0.9837 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9854 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0423 - acc: 0.9839 - val_loss: 0.0190 - val_acc: 0.9922\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0373 - acc: 0.9864 - val_loss: 0.0170 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.01628 to 0.01404, saving model to best.model\n",
      "0s - loss: 0.0354 - acc: 0.9859 - val_loss: 0.0140 - val_acc: 0.9942\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9866 - val_loss: 0.0145 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0355 - acc: 0.9839 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9871 - val_loss: 0.0196 - val_acc: 0.9893\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9854 - val_loss: 0.0146 - val_acc: 0.9942\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0386 - acc: 0.9847 - val_loss: 0.0163 - val_acc: 0.9932\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0374 - acc: 0.9839 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.0376 - acc: 0.9861 - val_loss: 0.0150 - val_acc: 0.9932\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01404 to 0.01302, saving model to best.model\n",
      "0s - loss: 0.0371 - acc: 0.9837 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0447 - acc: 0.9839 - val_loss: 0.0148 - val_acc: 0.9932\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9856 - val_loss: 0.0141 - val_acc: 0.9932\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9869 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01302 to 0.01301, saving model to best.model\n",
      "0s - loss: 0.0389 - acc: 0.9847 - val_loss: 0.0130 - val_acc: 0.9951\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0304 - acc: 0.9871 - val_loss: 0.0162 - val_acc: 0.9932\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.01301 to 0.01114, saving model to best.model\n",
      "0s - loss: 0.0370 - acc: 0.9866 - val_loss: 0.0111 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9861 - val_loss: 0.0194 - val_acc: 0.9912\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9856 - val_loss: 0.0120 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0145 - val_acc: 0.9932\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9883 - val_loss: 0.0123 - val_acc: 0.9951\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0349 - acc: 0.9890 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0145 - val_acc: 0.9951\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9881 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.01114 to 0.01111, saving model to best.model\n",
      "0s - loss: 0.0311 - acc: 0.9900 - val_loss: 0.0111 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.01111 to 0.01059, saving model to best.model\n",
      "0s - loss: 0.0335 - acc: 0.9861 - val_loss: 0.0106 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0266 - acc: 0.9888 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01059 to 0.00885, saving model to best.model\n",
      "0s - loss: 0.0284 - acc: 0.9893 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0317 - acc: 0.9886 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9895 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9907 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.00885 to 0.00853, saving model to best.model\n",
      "0s - loss: 0.0282 - acc: 0.9886 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9917 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.00853 to 0.00799, saving model to best.model\n",
      "0s - loss: 0.0320 - acc: 0.9873 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0339 - acc: 0.9866 - val_loss: 0.0128 - val_acc: 0.9932\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9876 - val_loss: 0.0093 - val_acc: 0.9951\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0284 - acc: 0.9886 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0351 - acc: 0.9854 - val_loss: 0.0124 - val_acc: 0.9932\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0329 - acc: 0.9866 - val_loss: 0.0098 - val_acc: 0.9961\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0268 - acc: 0.9900 - val_loss: 0.0112 - val_acc: 0.9951\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0366 - acc: 0.9876 - val_loss: 0.0096 - val_acc: 0.9961\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0279 - acc: 0.9871 - val_loss: 0.0089 - val_acc: 0.9961\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.00799 to 0.00760, saving model to best.model\n",
      "0s - loss: 0.0264 - acc: 0.9903 - val_loss: 0.0076 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67987, saving model to best.model\n",
      "0s - loss: 0.8175 - acc: 0.5047 - val_loss: 0.6799 - val_acc: 0.5599\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67987 to 0.65477, saving model to best.model\n",
      "0s - loss: 0.7521 - acc: 0.5233 - val_loss: 0.6548 - val_acc: 0.7936\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65477 to 0.61972, saving model to best.model\n",
      "0s - loss: 0.7165 - acc: 0.5457 - val_loss: 0.6197 - val_acc: 0.7595\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61972 to 0.56249, saving model to best.model\n",
      "0s - loss: 0.6610 - acc: 0.6041 - val_loss: 0.5625 - val_acc: 0.7965\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.56249 to 0.49197, saving model to best.model\n",
      "0s - loss: 0.5851 - acc: 0.6978 - val_loss: 0.4920 - val_acc: 0.7965\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.49197 to 0.43810, saving model to best.model\n",
      "0s - loss: 0.5136 - acc: 0.7568 - val_loss: 0.4381 - val_acc: 0.8247\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.43810 to 0.39484, saving model to best.model\n",
      "0s - loss: 0.4752 - acc: 0.7906 - val_loss: 0.3948 - val_acc: 0.8325\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.39484 to 0.36479, saving model to best.model\n",
      "0s - loss: 0.4418 - acc: 0.8057 - val_loss: 0.3648 - val_acc: 0.8510\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.36479 to 0.34016, saving model to best.model\n",
      "0s - loss: 0.4170 - acc: 0.8342 - val_loss: 0.3402 - val_acc: 0.8656\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.34016 to 0.31872, saving model to best.model\n",
      "0s - loss: 0.3845 - acc: 0.8425 - val_loss: 0.3187 - val_acc: 0.8705\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31872 to 0.30133, saving model to best.model\n",
      "0s - loss: 0.3680 - acc: 0.8605 - val_loss: 0.3013 - val_acc: 0.8783\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.30133 to 0.28410, saving model to best.model\n",
      "0s - loss: 0.3451 - acc: 0.8644 - val_loss: 0.2841 - val_acc: 0.8822\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28410 to 0.27400, saving model to best.model\n",
      "0s - loss: 0.3268 - acc: 0.8761 - val_loss: 0.2740 - val_acc: 0.8841\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.27400 to 0.25758, saving model to best.model\n",
      "0s - loss: 0.3202 - acc: 0.8836 - val_loss: 0.2576 - val_acc: 0.8987\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.25758 to 0.24879, saving model to best.model\n",
      "0s - loss: 0.3079 - acc: 0.8873 - val_loss: 0.2488 - val_acc: 0.9094\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.24879 to 0.23985, saving model to best.model\n",
      "0s - loss: 0.2931 - acc: 0.8892 - val_loss: 0.2399 - val_acc: 0.9124\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.23985 to 0.23104, saving model to best.model\n",
      "0s - loss: 0.2829 - acc: 0.8963 - val_loss: 0.2310 - val_acc: 0.9163\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.23104 to 0.22462, saving model to best.model\n",
      "0s - loss: 0.2816 - acc: 0.8982 - val_loss: 0.2246 - val_acc: 0.9221\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.22462 to 0.22160, saving model to best.model\n",
      "0s - loss: 0.2745 - acc: 0.9038 - val_loss: 0.2216 - val_acc: 0.9211\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.22160 to 0.21814, saving model to best.model\n",
      "0s - loss: 0.2684 - acc: 0.9041 - val_loss: 0.2181 - val_acc: 0.9221\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.2642 - acc: 0.9058 - val_loss: 0.2230 - val_acc: 0.9133\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.21814 to 0.21240, saving model to best.model\n",
      "0s - loss: 0.2641 - acc: 0.9043 - val_loss: 0.2124 - val_acc: 0.9241\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.21240 to 0.20896, saving model to best.model\n",
      "0s - loss: 0.2581 - acc: 0.9094 - val_loss: 0.2090 - val_acc: 0.9250\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.20896 to 0.20311, saving model to best.model\n",
      "0s - loss: 0.2520 - acc: 0.9089 - val_loss: 0.2031 - val_acc: 0.9338\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.20311 to 0.19985, saving model to best.model\n",
      "0s - loss: 0.2449 - acc: 0.9131 - val_loss: 0.1998 - val_acc: 0.9328\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.19985 to 0.19502, saving model to best.model\n",
      "0s - loss: 0.2319 - acc: 0.9136 - val_loss: 0.1950 - val_acc: 0.9406\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.19502 to 0.19230, saving model to best.model\n",
      "0s - loss: 0.2272 - acc: 0.9167 - val_loss: 0.1923 - val_acc: 0.9357\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.19230 to 0.18774, saving model to best.model\n",
      "0s - loss: 0.2211 - acc: 0.9211 - val_loss: 0.1877 - val_acc: 0.9455\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.18774 to 0.18710, saving model to best.model\n",
      "0s - loss: 0.2144 - acc: 0.9231 - val_loss: 0.1871 - val_acc: 0.9348\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.18710 to 0.18105, saving model to best.model\n",
      "0s - loss: 0.2205 - acc: 0.9189 - val_loss: 0.1811 - val_acc: 0.9455\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.18105 to 0.17856, saving model to best.model\n",
      "0s - loss: 0.2094 - acc: 0.9240 - val_loss: 0.1786 - val_acc: 0.9435\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.17856 to 0.17436, saving model to best.model\n",
      "0s - loss: 0.2101 - acc: 0.9274 - val_loss: 0.1744 - val_acc: 0.9494\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.17436 to 0.17235, saving model to best.model\n",
      "0s - loss: 0.2060 - acc: 0.9294 - val_loss: 0.1724 - val_acc: 0.9503\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.17235 to 0.17072, saving model to best.model\n",
      "0s - loss: 0.2079 - acc: 0.9274 - val_loss: 0.1707 - val_acc: 0.9445\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.17072 to 0.16724, saving model to best.model\n",
      "0s - loss: 0.2026 - acc: 0.9311 - val_loss: 0.1672 - val_acc: 0.9484\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.16724 to 0.16721, saving model to best.model\n",
      "0s - loss: 0.1876 - acc: 0.9345 - val_loss: 0.1672 - val_acc: 0.9455\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.16721 to 0.16235, saving model to best.model\n",
      "0s - loss: 0.1922 - acc: 0.9316 - val_loss: 0.1624 - val_acc: 0.9523\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.16235 to 0.16141, saving model to best.model\n",
      "0s - loss: 0.1808 - acc: 0.9367 - val_loss: 0.1614 - val_acc: 0.9591\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.16141 to 0.15856, saving model to best.model\n",
      "0s - loss: 0.1798 - acc: 0.9401 - val_loss: 0.1586 - val_acc: 0.9611\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.15856 to 0.15460, saving model to best.model\n",
      "0s - loss: 0.1769 - acc: 0.9389 - val_loss: 0.1546 - val_acc: 0.9523\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15460 to 0.15348, saving model to best.model\n",
      "0s - loss: 0.1734 - acc: 0.9413 - val_loss: 0.1535 - val_acc: 0.9581\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.1760 - acc: 0.9403 - val_loss: 0.1544 - val_acc: 0.9494\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15348 to 0.14929, saving model to best.model\n",
      "0s - loss: 0.1703 - acc: 0.9425 - val_loss: 0.1493 - val_acc: 0.9572\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.14929 to 0.14783, saving model to best.model\n",
      "0s - loss: 0.1761 - acc: 0.9396 - val_loss: 0.1478 - val_acc: 0.9552\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.14783 to 0.14480, saving model to best.model\n",
      "0s - loss: 0.1616 - acc: 0.9423 - val_loss: 0.1448 - val_acc: 0.9611\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14480 to 0.14296, saving model to best.model\n",
      "0s - loss: 0.1606 - acc: 0.9447 - val_loss: 0.1430 - val_acc: 0.9620\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.14296 to 0.14045, saving model to best.model\n",
      "0s - loss: 0.1629 - acc: 0.9445 - val_loss: 0.1404 - val_acc: 0.9611\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.14045 to 0.13751, saving model to best.model\n",
      "0s - loss: 0.1563 - acc: 0.9457 - val_loss: 0.1375 - val_acc: 0.9630\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.13751 to 0.13578, saving model to best.model\n",
      "0s - loss: 0.1542 - acc: 0.9481 - val_loss: 0.1358 - val_acc: 0.9649\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.1642 - acc: 0.9430 - val_loss: 0.1416 - val_acc: 0.9572\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.13578 to 0.13152, saving model to best.model\n",
      "0s - loss: 0.1540 - acc: 0.9481 - val_loss: 0.1315 - val_acc: 0.9620\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.13152 to 0.13013, saving model to best.model\n",
      "0s - loss: 0.1542 - acc: 0.9462 - val_loss: 0.1301 - val_acc: 0.9640\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.13013 to 0.12669, saving model to best.model\n",
      "0s - loss: 0.1469 - acc: 0.9503 - val_loss: 0.1267 - val_acc: 0.9640\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.12669 to 0.12435, saving model to best.model\n",
      "0s - loss: 0.1393 - acc: 0.9540 - val_loss: 0.1243 - val_acc: 0.9630\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.12435 to 0.12324, saving model to best.model\n",
      "0s - loss: 0.1392 - acc: 0.9533 - val_loss: 0.1232 - val_acc: 0.9640\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.12324 to 0.12226, saving model to best.model\n",
      "0s - loss: 0.1368 - acc: 0.9535 - val_loss: 0.1223 - val_acc: 0.9630\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.12226 to 0.12001, saving model to best.model\n",
      "0s - loss: 0.1390 - acc: 0.9552 - val_loss: 0.1200 - val_acc: 0.9659\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.12001 to 0.11756, saving model to best.model\n",
      "0s - loss: 0.1463 - acc: 0.9484 - val_loss: 0.1176 - val_acc: 0.9659\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.11756 to 0.11401, saving model to best.model\n",
      "0s - loss: 0.1367 - acc: 0.9537 - val_loss: 0.1140 - val_acc: 0.9640\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.11401 to 0.11168, saving model to best.model\n",
      "0s - loss: 0.1240 - acc: 0.9603 - val_loss: 0.1117 - val_acc: 0.9649\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.11168 to 0.10951, saving model to best.model\n",
      "0s - loss: 0.1231 - acc: 0.9596 - val_loss: 0.1095 - val_acc: 0.9659\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.1265 - acc: 0.9596 - val_loss: 0.1096 - val_acc: 0.9698\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.10951 to 0.10524, saving model to best.model\n",
      "0s - loss: 0.1234 - acc: 0.9623 - val_loss: 0.1052 - val_acc: 0.9679\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.10524 to 0.10351, saving model to best.model\n",
      "0s - loss: 0.1278 - acc: 0.9567 - val_loss: 0.1035 - val_acc: 0.9688\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.10351 to 0.10163, saving model to best.model\n",
      "0s - loss: 0.1159 - acc: 0.9608 - val_loss: 0.1016 - val_acc: 0.9688\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.10163 to 0.09945, saving model to best.model\n",
      "0s - loss: 0.1212 - acc: 0.9603 - val_loss: 0.0994 - val_acc: 0.9698\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.09945 to 0.09865, saving model to best.model\n",
      "0s - loss: 0.1175 - acc: 0.9606 - val_loss: 0.0987 - val_acc: 0.9708\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.09865 to 0.09584, saving model to best.model\n",
      "0s - loss: 0.1221 - acc: 0.9603 - val_loss: 0.0958 - val_acc: 0.9698\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.09584 to 0.09424, saving model to best.model\n",
      "0s - loss: 0.1061 - acc: 0.9647 - val_loss: 0.0942 - val_acc: 0.9698\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.09424 to 0.09221, saving model to best.model\n",
      "0s - loss: 0.1164 - acc: 0.9610 - val_loss: 0.0922 - val_acc: 0.9698\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.09221 to 0.09054, saving model to best.model\n",
      "0s - loss: 0.1098 - acc: 0.9640 - val_loss: 0.0905 - val_acc: 0.9727\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.09054 to 0.08773, saving model to best.model\n",
      "0s - loss: 0.1126 - acc: 0.9620 - val_loss: 0.0877 - val_acc: 0.9747\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.08773 to 0.08652, saving model to best.model\n",
      "0s - loss: 0.1107 - acc: 0.9620 - val_loss: 0.0865 - val_acc: 0.9766\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1061 - acc: 0.9608 - val_loss: 0.0873 - val_acc: 0.9737\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.08652 to 0.08596, saving model to best.model\n",
      "0s - loss: 0.1081 - acc: 0.9640 - val_loss: 0.0860 - val_acc: 0.9747\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.08596 to 0.08246, saving model to best.model\n",
      "0s - loss: 0.1038 - acc: 0.9654 - val_loss: 0.0825 - val_acc: 0.9757\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.08246 to 0.08231, saving model to best.model\n",
      "0s - loss: 0.1032 - acc: 0.9645 - val_loss: 0.0823 - val_acc: 0.9776\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.08231 to 0.08194, saving model to best.model\n",
      "0s - loss: 0.1048 - acc: 0.9632 - val_loss: 0.0819 - val_acc: 0.9786\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.08194 to 0.08099, saving model to best.model\n",
      "0s - loss: 0.0994 - acc: 0.9681 - val_loss: 0.0810 - val_acc: 0.9786\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.08099 to 0.07846, saving model to best.model\n",
      "0s - loss: 0.1053 - acc: 0.9649 - val_loss: 0.0785 - val_acc: 0.9796\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.07846 to 0.07626, saving model to best.model\n",
      "0s - loss: 0.0994 - acc: 0.9691 - val_loss: 0.0763 - val_acc: 0.9815\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.07626 to 0.07422, saving model to best.model\n",
      "0s - loss: 0.0974 - acc: 0.9686 - val_loss: 0.0742 - val_acc: 0.9825\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.07422 to 0.07329, saving model to best.model\n",
      "0s - loss: 0.0916 - acc: 0.9701 - val_loss: 0.0733 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.07329 to 0.07308, saving model to best.model\n",
      "0s - loss: 0.0911 - acc: 0.9722 - val_loss: 0.0731 - val_acc: 0.9825\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.07308 to 0.07282, saving model to best.model\n",
      "0s - loss: 0.0933 - acc: 0.9679 - val_loss: 0.0728 - val_acc: 0.9825\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.07282 to 0.07175, saving model to best.model\n",
      "0s - loss: 0.0944 - acc: 0.9681 - val_loss: 0.0717 - val_acc: 0.9805\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.07175 to 0.07130, saving model to best.model\n",
      "0s - loss: 0.0956 - acc: 0.9701 - val_loss: 0.0713 - val_acc: 0.9834\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.07130 to 0.06897, saving model to best.model\n",
      "0s - loss: 0.1012 - acc: 0.9652 - val_loss: 0.0690 - val_acc: 0.9815\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0942 - acc: 0.9725 - val_loss: 0.0691 - val_acc: 0.9825\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.06897 to 0.06841, saving model to best.model\n",
      "0s - loss: 0.0896 - acc: 0.9713 - val_loss: 0.0684 - val_acc: 0.9825\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0844 - acc: 0.9718 - val_loss: 0.0684 - val_acc: 0.9825\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.06841 to 0.06659, saving model to best.model\n",
      "0s - loss: 0.0896 - acc: 0.9715 - val_loss: 0.0666 - val_acc: 0.9825\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.06659 to 0.06582, saving model to best.model\n",
      "0s - loss: 0.0865 - acc: 0.9705 - val_loss: 0.0658 - val_acc: 0.9825\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.06582 to 0.06555, saving model to best.model\n",
      "0s - loss: 0.0887 - acc: 0.9725 - val_loss: 0.0655 - val_acc: 0.9805\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.06555 to 0.06349, saving model to best.model\n",
      "0s - loss: 0.0854 - acc: 0.9715 - val_loss: 0.0635 - val_acc: 0.9825\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.06349 to 0.06249, saving model to best.model\n",
      "0s - loss: 0.0829 - acc: 0.9722 - val_loss: 0.0625 - val_acc: 0.9825\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.06249 to 0.06227, saving model to best.model\n",
      "0s - loss: 0.0801 - acc: 0.9732 - val_loss: 0.0623 - val_acc: 0.9825\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.06227 to 0.06100, saving model to best.model\n",
      "0s - loss: 0.0814 - acc: 0.9722 - val_loss: 0.0610 - val_acc: 0.9825\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.06100 to 0.06040, saving model to best.model\n",
      "0s - loss: 0.0783 - acc: 0.9752 - val_loss: 0.0604 - val_acc: 0.9825\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.06040 to 0.05944, saving model to best.model\n",
      "0s - loss: 0.0824 - acc: 0.9744 - val_loss: 0.0594 - val_acc: 0.9825\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.05944 to 0.05916, saving model to best.model\n",
      "0s - loss: 0.0724 - acc: 0.9788 - val_loss: 0.0592 - val_acc: 0.9825\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.05916 to 0.05791, saving model to best.model\n",
      "0s - loss: 0.0796 - acc: 0.9722 - val_loss: 0.0579 - val_acc: 0.9825\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.05791 to 0.05696, saving model to best.model\n",
      "0s - loss: 0.0733 - acc: 0.9761 - val_loss: 0.0570 - val_acc: 0.9825\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.05696 to 0.05589, saving model to best.model\n",
      "0s - loss: 0.0761 - acc: 0.9769 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.05589 to 0.05374, saving model to best.model\n",
      "0s - loss: 0.0883 - acc: 0.9703 - val_loss: 0.0537 - val_acc: 0.9815\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0783 - acc: 0.9752 - val_loss: 0.0538 - val_acc: 0.9815\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0766 - acc: 0.9739 - val_loss: 0.0545 - val_acc: 0.9825\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.05374 to 0.05110, saving model to best.model\n",
      "0s - loss: 0.0749 - acc: 0.9725 - val_loss: 0.0511 - val_acc: 0.9825\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.0701 - acc: 0.9774 - val_loss: 0.0530 - val_acc: 0.9834\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.05110 to 0.05107, saving model to best.model\n",
      "0s - loss: 0.0801 - acc: 0.9725 - val_loss: 0.0511 - val_acc: 0.9815\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.05107 to 0.04938, saving model to best.model\n",
      "0s - loss: 0.0726 - acc: 0.9769 - val_loss: 0.0494 - val_acc: 0.9825\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.04938 to 0.04837, saving model to best.model\n",
      "0s - loss: 0.0765 - acc: 0.9761 - val_loss: 0.0484 - val_acc: 0.9825\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.04837 to 0.04675, saving model to best.model\n",
      "0s - loss: 0.0643 - acc: 0.9786 - val_loss: 0.0467 - val_acc: 0.9825\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.04675 to 0.04545, saving model to best.model\n",
      "0s - loss: 0.0668 - acc: 0.9778 - val_loss: 0.0455 - val_acc: 0.9825\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.04545 to 0.04538, saving model to best.model\n",
      "0s - loss: 0.0669 - acc: 0.9769 - val_loss: 0.0454 - val_acc: 0.9825\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.04538 to 0.04409, saving model to best.model\n",
      "0s - loss: 0.0666 - acc: 0.9754 - val_loss: 0.0441 - val_acc: 0.9825\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.04409 to 0.04360, saving model to best.model\n",
      "0s - loss: 0.0671 - acc: 0.9761 - val_loss: 0.0436 - val_acc: 0.9825\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0644 - acc: 0.9795 - val_loss: 0.0456 - val_acc: 0.9834\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.04360 to 0.04344, saving model to best.model\n",
      "0s - loss: 0.0677 - acc: 0.9783 - val_loss: 0.0434 - val_acc: 0.9825\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.04344 to 0.04113, saving model to best.model\n",
      "0s - loss: 0.0653 - acc: 0.9781 - val_loss: 0.0411 - val_acc: 0.9834\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.04113 to 0.03929, saving model to best.model\n",
      "0s - loss: 0.0640 - acc: 0.9795 - val_loss: 0.0393 - val_acc: 0.9825\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.0654 - acc: 0.9786 - val_loss: 0.0400 - val_acc: 0.9825\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.03929 to 0.03922, saving model to best.model\n",
      "0s - loss: 0.0622 - acc: 0.9793 - val_loss: 0.0392 - val_acc: 0.9825\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.03922 to 0.03832, saving model to best.model\n",
      "0s - loss: 0.0596 - acc: 0.9783 - val_loss: 0.0383 - val_acc: 0.9825\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.03832 to 0.03636, saving model to best.model\n",
      "0s - loss: 0.0546 - acc: 0.9817 - val_loss: 0.0364 - val_acc: 0.9825\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.03636 to 0.03533, saving model to best.model\n",
      "0s - loss: 0.0533 - acc: 0.9808 - val_loss: 0.0353 - val_acc: 0.9825\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.03533 to 0.03120, saving model to best.model\n",
      "0s - loss: 0.0622 - acc: 0.9766 - val_loss: 0.0312 - val_acc: 0.9844\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0591 - acc: 0.9808 - val_loss: 0.0324 - val_acc: 0.9834\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0603 - acc: 0.9786 - val_loss: 0.0330 - val_acc: 0.9834\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0626 - acc: 0.9798 - val_loss: 0.0312 - val_acc: 0.9834\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.03120 to 0.03054, saving model to best.model\n",
      "0s - loss: 0.0618 - acc: 0.9791 - val_loss: 0.0305 - val_acc: 0.9834\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.03054 to 0.02923, saving model to best.model\n",
      "0s - loss: 0.0598 - acc: 0.9788 - val_loss: 0.0292 - val_acc: 0.9854\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.02923 to 0.02811, saving model to best.model\n",
      "0s - loss: 0.0598 - acc: 0.9798 - val_loss: 0.0281 - val_acc: 0.9873\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0576 - acc: 0.9815 - val_loss: 0.0290 - val_acc: 0.9873\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0604 - acc: 0.9786 - val_loss: 0.0293 - val_acc: 0.9844\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.02811 to 0.02795, saving model to best.model\n",
      "0s - loss: 0.0529 - acc: 0.9834 - val_loss: 0.0279 - val_acc: 0.9864\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.02795 to 0.02615, saving model to best.model\n",
      "0s - loss: 0.0495 - acc: 0.9827 - val_loss: 0.0261 - val_acc: 0.9873\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.02615 to 0.02529, saving model to best.model\n",
      "0s - loss: 0.0541 - acc: 0.9815 - val_loss: 0.0253 - val_acc: 0.9873\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.02529 to 0.02426, saving model to best.model\n",
      "0s - loss: 0.0488 - acc: 0.9822 - val_loss: 0.0243 - val_acc: 0.9903\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.02426 to 0.02314, saving model to best.model\n",
      "0s - loss: 0.0467 - acc: 0.9832 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.02314 to 0.02200, saving model to best.model\n",
      "0s - loss: 0.0530 - acc: 0.9813 - val_loss: 0.0220 - val_acc: 0.9903\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0503 - acc: 0.9820 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0557 - acc: 0.9803 - val_loss: 0.0246 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0559 - acc: 0.9808 - val_loss: 0.0268 - val_acc: 0.9893\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0542 - acc: 0.9817 - val_loss: 0.0265 - val_acc: 0.9903\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.02200 to 0.02171, saving model to best.model\n",
      "0s - loss: 0.0516 - acc: 0.9815 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.02171 to 0.02016, saving model to best.model\n",
      "0s - loss: 0.0494 - acc: 0.9830 - val_loss: 0.0202 - val_acc: 0.9903\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.02016 to 0.01987, saving model to best.model\n",
      "0s - loss: 0.0494 - acc: 0.9822 - val_loss: 0.0199 - val_acc: 0.9912\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0467 - acc: 0.9837 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01987 to 0.01981, saving model to best.model\n",
      "0s - loss: 0.0478 - acc: 0.9810 - val_loss: 0.0198 - val_acc: 0.9912\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01981 to 0.01946, saving model to best.model\n",
      "0s - loss: 0.0436 - acc: 0.9839 - val_loss: 0.0195 - val_acc: 0.9942\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0482 - acc: 0.9822 - val_loss: 0.0205 - val_acc: 0.9903\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01946 to 0.01614, saving model to best.model\n",
      "0s - loss: 0.0509 - acc: 0.9798 - val_loss: 0.0161 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0466 - acc: 0.9830 - val_loss: 0.0177 - val_acc: 0.9912\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0483 - acc: 0.9827 - val_loss: 0.0191 - val_acc: 0.9903\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0474 - acc: 0.9847 - val_loss: 0.0181 - val_acc: 0.9922\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0434 - acc: 0.9839 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01614 to 0.01523, saving model to best.model\n",
      "0s - loss: 0.0465 - acc: 0.9839 - val_loss: 0.0152 - val_acc: 0.9932\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0426 - acc: 0.9820 - val_loss: 0.0153 - val_acc: 0.9932\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9856 - val_loss: 0.0162 - val_acc: 0.9912\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01523 to 0.01519, saving model to best.model\n",
      "0s - loss: 0.0402 - acc: 0.9849 - val_loss: 0.0152 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.01519 to 0.01461, saving model to best.model\n",
      "0s - loss: 0.0424 - acc: 0.9844 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9878 - val_loss: 0.0152 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.01461 to 0.01438, saving model to best.model\n",
      "0s - loss: 0.0454 - acc: 0.9842 - val_loss: 0.0144 - val_acc: 0.9932\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0430 - acc: 0.9851 - val_loss: 0.0151 - val_acc: 0.9942\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9859 - val_loss: 0.0145 - val_acc: 0.9922\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01438 to 0.01359, saving model to best.model\n",
      "0s - loss: 0.0454 - acc: 0.9832 - val_loss: 0.0136 - val_acc: 0.9951\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.01359 to 0.01305, saving model to best.model\n",
      "0s - loss: 0.0404 - acc: 0.9851 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0397 - acc: 0.9869 - val_loss: 0.0134 - val_acc: 0.9932\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.01305 to 0.01301, saving model to best.model\n",
      "0s - loss: 0.0393 - acc: 0.9859 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.01301 to 0.01268, saving model to best.model\n",
      "0s - loss: 0.0407 - acc: 0.9851 - val_loss: 0.0127 - val_acc: 0.9932\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0365 - acc: 0.9869 - val_loss: 0.0128 - val_acc: 0.9942\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9856 - val_loss: 0.0149 - val_acc: 0.9942\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0352 - acc: 0.9864 - val_loss: 0.0139 - val_acc: 0.9942\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0308 - acc: 0.9888 - val_loss: 0.0135 - val_acc: 0.9942\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.01268 to 0.01220, saving model to best.model\n",
      "0s - loss: 0.0406 - acc: 0.9861 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0141 - val_acc: 0.9922\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0377 - acc: 0.9864 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0350 - acc: 0.9861 - val_loss: 0.0132 - val_acc: 0.9932\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9837 - val_loss: 0.0138 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0372 - acc: 0.9878 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0406 - acc: 0.9859 - val_loss: 0.0135 - val_acc: 0.9942\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.01220 to 0.01127, saving model to best.model\n",
      "0s - loss: 0.0354 - acc: 0.9893 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.01127 to 0.01078, saving model to best.model\n",
      "0s - loss: 0.0341 - acc: 0.9869 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0330 - acc: 0.9881 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0315 - acc: 0.9886 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.01078 to 0.01052, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9895 - val_loss: 0.0105 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9866 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9895 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0326 - acc: 0.9878 - val_loss: 0.0109 - val_acc: 0.9951\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0311 - acc: 0.9869 - val_loss: 0.0122 - val_acc: 0.9942\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0306 - acc: 0.9893 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0295 - acc: 0.9890 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9849 - val_loss: 0.0107 - val_acc: 0.9951\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9900 - val_loss: 0.0114 - val_acc: 0.9951\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0283 - acc: 0.9886 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0333 - acc: 0.9898 - val_loss: 0.0108 - val_acc: 0.9981\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0420 - acc: 0.9854 - val_loss: 0.0109 - val_acc: 0.9942\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.01052 to 0.01028, saving model to best.model\n",
      "0s - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0103 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68835, saving model to best.model\n",
      "0s - loss: 0.8273 - acc: 0.4994 - val_loss: 0.6883 - val_acc: 0.4888\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68835 to 0.65576, saving model to best.model\n",
      "0s - loss: 0.7615 - acc: 0.5167 - val_loss: 0.6558 - val_acc: 0.7955\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65576 to 0.62566, saving model to best.model\n",
      "0s - loss: 0.7137 - acc: 0.5569 - val_loss: 0.6257 - val_acc: 0.7118\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.62566 to 0.57049, saving model to best.model\n",
      "0s - loss: 0.6590 - acc: 0.6121 - val_loss: 0.5705 - val_acc: 0.7537\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.57049 to 0.48224, saving model to best.model\n",
      "0s - loss: 0.6046 - acc: 0.6808 - val_loss: 0.4822 - val_acc: 0.8179\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.48224 to 0.43645, saving model to best.model\n",
      "0s - loss: 0.5190 - acc: 0.7475 - val_loss: 0.4364 - val_acc: 0.8179\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.43645 to 0.38370, saving model to best.model\n",
      "0s - loss: 0.4739 - acc: 0.7916 - val_loss: 0.3837 - val_acc: 0.8520\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.38370 to 0.34671, saving model to best.model\n",
      "0s - loss: 0.4405 - acc: 0.8147 - val_loss: 0.3467 - val_acc: 0.8637\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34671 to 0.33164, saving model to best.model\n",
      "0s - loss: 0.4015 - acc: 0.8386 - val_loss: 0.3316 - val_acc: 0.8685\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.33164 to 0.31463, saving model to best.model\n",
      "0s - loss: 0.3826 - acc: 0.8468 - val_loss: 0.3146 - val_acc: 0.8793\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.31463 to 0.29578, saving model to best.model\n",
      "0s - loss: 0.3695 - acc: 0.8563 - val_loss: 0.2958 - val_acc: 0.8851\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.29578 to 0.28656, saving model to best.model\n",
      "0s - loss: 0.3520 - acc: 0.8580 - val_loss: 0.2866 - val_acc: 0.8870\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.28656 to 0.27437, saving model to best.model\n",
      "0s - loss: 0.3328 - acc: 0.8639 - val_loss: 0.2744 - val_acc: 0.8880\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.3237 - acc: 0.8741 - val_loss: 0.2868 - val_acc: 0.8929\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.27437 to 0.26055, saving model to best.model\n",
      "0s - loss: 0.3161 - acc: 0.8802 - val_loss: 0.2605 - val_acc: 0.8939\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.26055 to 0.25477, saving model to best.model\n",
      "0s - loss: 0.3119 - acc: 0.8853 - val_loss: 0.2548 - val_acc: 0.8987\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.3080 - acc: 0.8824 - val_loss: 0.2630 - val_acc: 0.9007\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.25477 to 0.24479, saving model to best.model\n",
      "0s - loss: 0.2943 - acc: 0.8858 - val_loss: 0.2448 - val_acc: 0.9036\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.24479 to 0.24385, saving model to best.model\n",
      "0s - loss: 0.2990 - acc: 0.8834 - val_loss: 0.2438 - val_acc: 0.9104\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.24385 to 0.24114, saving model to best.model\n",
      "0s - loss: 0.2788 - acc: 0.8963 - val_loss: 0.2411 - val_acc: 0.9114\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.24114 to 0.23412, saving model to best.model\n",
      "0s - loss: 0.2750 - acc: 0.8960 - val_loss: 0.2341 - val_acc: 0.9114\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.2735 - acc: 0.8963 - val_loss: 0.2347 - val_acc: 0.9104\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.23412 to 0.22292, saving model to best.model\n",
      "0s - loss: 0.2673 - acc: 0.9028 - val_loss: 0.2229 - val_acc: 0.9163\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.22292 to 0.21942, saving model to best.model\n",
      "0s - loss: 0.2622 - acc: 0.9021 - val_loss: 0.2194 - val_acc: 0.9192\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.2569 - acc: 0.9067 - val_loss: 0.2252 - val_acc: 0.9202\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.21942 to 0.21381, saving model to best.model\n",
      "0s - loss: 0.2543 - acc: 0.9036 - val_loss: 0.2138 - val_acc: 0.9250\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.2507 - acc: 0.9094 - val_loss: 0.2159 - val_acc: 0.9202\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.21381 to 0.20838, saving model to best.model\n",
      "0s - loss: 0.2481 - acc: 0.9092 - val_loss: 0.2084 - val_acc: 0.9250\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.20838 to 0.20238, saving model to best.model\n",
      "0s - loss: 0.2470 - acc: 0.9123 - val_loss: 0.2024 - val_acc: 0.9241\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.2435 - acc: 0.9116 - val_loss: 0.2068 - val_acc: 0.9260\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.20238 to 0.19708, saving model to best.model\n",
      "0s - loss: 0.2388 - acc: 0.9084 - val_loss: 0.1971 - val_acc: 0.9231\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.19708 to 0.19231, saving model to best.model\n",
      "0s - loss: 0.2361 - acc: 0.9087 - val_loss: 0.1923 - val_acc: 0.9231\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.2352 - acc: 0.9140 - val_loss: 0.1927 - val_acc: 0.9260\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.19231 to 0.18457, saving model to best.model\n",
      "0s - loss: 0.2263 - acc: 0.9102 - val_loss: 0.1846 - val_acc: 0.9270\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.18457 to 0.18153, saving model to best.model\n",
      "0s - loss: 0.2225 - acc: 0.9165 - val_loss: 0.1815 - val_acc: 0.9270\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.18153 to 0.17577, saving model to best.model\n",
      "0s - loss: 0.2183 - acc: 0.9170 - val_loss: 0.1758 - val_acc: 0.9250\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.17577 to 0.17395, saving model to best.model\n",
      "0s - loss: 0.2194 - acc: 0.9158 - val_loss: 0.1740 - val_acc: 0.9250\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.17395 to 0.17357, saving model to best.model\n",
      "0s - loss: 0.2129 - acc: 0.9214 - val_loss: 0.1736 - val_acc: 0.9260\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.17357 to 0.16355, saving model to best.model\n",
      "0s - loss: 0.2047 - acc: 0.9240 - val_loss: 0.1635 - val_acc: 0.9289\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.16355 to 0.15943, saving model to best.model\n",
      "0s - loss: 0.2067 - acc: 0.9228 - val_loss: 0.1594 - val_acc: 0.9309\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.15943 to 0.15678, saving model to best.model\n",
      "0s - loss: 0.2020 - acc: 0.9177 - val_loss: 0.1568 - val_acc: 0.9260\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.15678 to 0.15414, saving model to best.model\n",
      "0s - loss: 0.2061 - acc: 0.9204 - val_loss: 0.1541 - val_acc: 0.9279\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.15414 to 0.15060, saving model to best.model\n",
      "0s - loss: 0.1936 - acc: 0.9233 - val_loss: 0.1506 - val_acc: 0.9279\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.1866 - acc: 0.9343 - val_loss: 0.1552 - val_acc: 0.9279\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.15060 to 0.14229, saving model to best.model\n",
      "0s - loss: 0.1957 - acc: 0.9235 - val_loss: 0.1423 - val_acc: 0.9406\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.14229 to 0.13855, saving model to best.model\n",
      "0s - loss: 0.1780 - acc: 0.9333 - val_loss: 0.1386 - val_acc: 0.9309\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.13855 to 0.13276, saving model to best.model\n",
      "0s - loss: 0.1760 - acc: 0.9279 - val_loss: 0.1328 - val_acc: 0.9396\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.13276 to 0.12858, saving model to best.model\n",
      "0s - loss: 0.1710 - acc: 0.9347 - val_loss: 0.1286 - val_acc: 0.9494\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.1710 - acc: 0.9367 - val_loss: 0.1314 - val_acc: 0.9328\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.12858 to 0.12442, saving model to best.model\n",
      "0s - loss: 0.1745 - acc: 0.9308 - val_loss: 0.1244 - val_acc: 0.9426\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.12442 to 0.12349, saving model to best.model\n",
      "0s - loss: 0.1730 - acc: 0.9313 - val_loss: 0.1235 - val_acc: 0.9572\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.12349 to 0.12257, saving model to best.model\n",
      "0s - loss: 0.1595 - acc: 0.9413 - val_loss: 0.1226 - val_acc: 0.9455\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.12257 to 0.11568, saving model to best.model\n",
      "0s - loss: 0.1654 - acc: 0.9326 - val_loss: 0.1157 - val_acc: 0.9601\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.11568 to 0.11105, saving model to best.model\n",
      "0s - loss: 0.1564 - acc: 0.9396 - val_loss: 0.1110 - val_acc: 0.9581\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.1621 - acc: 0.9377 - val_loss: 0.1118 - val_acc: 0.9523\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.11105 to 0.10715, saving model to best.model\n",
      "0s - loss: 0.1516 - acc: 0.9445 - val_loss: 0.1072 - val_acc: 0.9669\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.10715 to 0.10311, saving model to best.model\n",
      "0s - loss: 0.1522 - acc: 0.9421 - val_loss: 0.1031 - val_acc: 0.9611\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.10311 to 0.10070, saving model to best.model\n",
      "0s - loss: 0.1468 - acc: 0.9433 - val_loss: 0.1007 - val_acc: 0.9601\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.10070 to 0.09818, saving model to best.model\n",
      "0s - loss: 0.1393 - acc: 0.9474 - val_loss: 0.0982 - val_acc: 0.9630\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.09818 to 0.09588, saving model to best.model\n",
      "0s - loss: 0.1405 - acc: 0.9501 - val_loss: 0.0959 - val_acc: 0.9649\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.09588 to 0.09376, saving model to best.model\n",
      "0s - loss: 0.1401 - acc: 0.9464 - val_loss: 0.0938 - val_acc: 0.9640\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.09376 to 0.09208, saving model to best.model\n",
      "0s - loss: 0.1300 - acc: 0.9494 - val_loss: 0.0921 - val_acc: 0.9649\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.09208 to 0.08863, saving model to best.model\n",
      "0s - loss: 0.1360 - acc: 0.9452 - val_loss: 0.0886 - val_acc: 0.9698\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.08863 to 0.08726, saving model to best.model\n",
      "0s - loss: 0.1365 - acc: 0.9484 - val_loss: 0.0873 - val_acc: 0.9688\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.08726 to 0.08489, saving model to best.model\n",
      "0s - loss: 0.1270 - acc: 0.9528 - val_loss: 0.0849 - val_acc: 0.9718\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.08489 to 0.08177, saving model to best.model\n",
      "0s - loss: 0.1188 - acc: 0.9569 - val_loss: 0.0818 - val_acc: 0.9727\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.08177 to 0.08076, saving model to best.model\n",
      "0s - loss: 0.1274 - acc: 0.9508 - val_loss: 0.0808 - val_acc: 0.9718\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.1285 - acc: 0.9513 - val_loss: 0.0813 - val_acc: 0.9737\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.08076 to 0.08011, saving model to best.model\n",
      "0s - loss: 0.1264 - acc: 0.9511 - val_loss: 0.0801 - val_acc: 0.9766\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.08011 to 0.07816, saving model to best.model\n",
      "0s - loss: 0.1234 - acc: 0.9547 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.07816 to 0.07391, saving model to best.model\n",
      "0s - loss: 0.1190 - acc: 0.9540 - val_loss: 0.0739 - val_acc: 0.9786\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.07391 to 0.07302, saving model to best.model\n",
      "0s - loss: 0.1187 - acc: 0.9554 - val_loss: 0.0730 - val_acc: 0.9776\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.07302 to 0.07152, saving model to best.model\n",
      "0s - loss: 0.1141 - acc: 0.9567 - val_loss: 0.0715 - val_acc: 0.9776\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.1199 - acc: 0.9559 - val_loss: 0.0734 - val_acc: 0.9776\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.07152 to 0.06982, saving model to best.model\n",
      "0s - loss: 0.1076 - acc: 0.9627 - val_loss: 0.0698 - val_acc: 0.9786\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.06982 to 0.06570, saving model to best.model\n",
      "0s - loss: 0.1033 - acc: 0.9620 - val_loss: 0.0657 - val_acc: 0.9805\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.06570 to 0.06424, saving model to best.model\n",
      "0s - loss: 0.1118 - acc: 0.9557 - val_loss: 0.0642 - val_acc: 0.9815\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.06424 to 0.06203, saving model to best.model\n",
      "0s - loss: 0.1064 - acc: 0.9647 - val_loss: 0.0620 - val_acc: 0.9825\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.06203 to 0.06055, saving model to best.model\n",
      "0s - loss: 0.1083 - acc: 0.9589 - val_loss: 0.0606 - val_acc: 0.9815\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.06055 to 0.05963, saving model to best.model\n",
      "0s - loss: 0.1056 - acc: 0.9581 - val_loss: 0.0596 - val_acc: 0.9815\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.05963 to 0.05719, saving model to best.model\n",
      "0s - loss: 0.1014 - acc: 0.9608 - val_loss: 0.0572 - val_acc: 0.9815\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.05719 to 0.05618, saving model to best.model\n",
      "0s - loss: 0.0987 - acc: 0.9642 - val_loss: 0.0562 - val_acc: 0.9825\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.05618 to 0.05488, saving model to best.model\n",
      "0s - loss: 0.0966 - acc: 0.9630 - val_loss: 0.0549 - val_acc: 0.9815\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.0964 - acc: 0.9657 - val_loss: 0.0555 - val_acc: 0.9825\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.05488 to 0.05477, saving model to best.model\n",
      "0s - loss: 0.0942 - acc: 0.9637 - val_loss: 0.0548 - val_acc: 0.9796\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.05477 to 0.05170, saving model to best.model\n",
      "0s - loss: 0.0911 - acc: 0.9630 - val_loss: 0.0517 - val_acc: 0.9844\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.05170 to 0.04983, saving model to best.model\n",
      "0s - loss: 0.0936 - acc: 0.9654 - val_loss: 0.0498 - val_acc: 0.9834\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.04983 to 0.04955, saving model to best.model\n",
      "0s - loss: 0.0931 - acc: 0.9654 - val_loss: 0.0495 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0899 - acc: 0.9662 - val_loss: 0.0518 - val_acc: 0.9825\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0963 - acc: 0.9637 - val_loss: 0.0496 - val_acc: 0.9844\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.04955 to 0.04598, saving model to best.model\n",
      "0s - loss: 0.0858 - acc: 0.9664 - val_loss: 0.0460 - val_acc: 0.9854\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.04598 to 0.04473, saving model to best.model\n",
      "0s - loss: 0.0810 - acc: 0.9696 - val_loss: 0.0447 - val_acc: 0.9854\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.0843 - acc: 0.9686 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0834 - acc: 0.9701 - val_loss: 0.0452 - val_acc: 0.9834\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.04473 to 0.04184, saving model to best.model\n",
      "0s - loss: 0.0841 - acc: 0.9681 - val_loss: 0.0418 - val_acc: 0.9873\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.04184 to 0.04126, saving model to best.model\n",
      "0s - loss: 0.0918 - acc: 0.9640 - val_loss: 0.0413 - val_acc: 0.9864\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.0797 - acc: 0.9710 - val_loss: 0.0422 - val_acc: 0.9864\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.04126 to 0.03919, saving model to best.model\n",
      "0s - loss: 0.0845 - acc: 0.9691 - val_loss: 0.0392 - val_acc: 0.9883\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.03919 to 0.03758, saving model to best.model\n",
      "0s - loss: 0.0789 - acc: 0.9703 - val_loss: 0.0376 - val_acc: 0.9883\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.03758 to 0.03741, saving model to best.model\n",
      "0s - loss: 0.0779 - acc: 0.9730 - val_loss: 0.0374 - val_acc: 0.9873\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.03741 to 0.03531, saving model to best.model\n",
      "0s - loss: 0.0765 - acc: 0.9727 - val_loss: 0.0353 - val_acc: 0.9903\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.03531 to 0.03467, saving model to best.model\n",
      "0s - loss: 0.0821 - acc: 0.9657 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0819 - acc: 0.9705 - val_loss: 0.0360 - val_acc: 0.9864\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.0736 - acc: 0.9739 - val_loss: 0.0368 - val_acc: 0.9854\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0786 - acc: 0.9703 - val_loss: 0.0350 - val_acc: 0.9873\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.0801 - acc: 0.9718 - val_loss: 0.0377 - val_acc: 0.9893\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0811 - acc: 0.9715 - val_loss: 0.0350 - val_acc: 0.9883\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.03467 to 0.03466, saving model to best.model\n",
      "0s - loss: 0.0738 - acc: 0.9696 - val_loss: 0.0347 - val_acc: 0.9864\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.03466 to 0.03324, saving model to best.model\n",
      "0s - loss: 0.0758 - acc: 0.9735 - val_loss: 0.0332 - val_acc: 0.9883\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.03324 to 0.03201, saving model to best.model\n",
      "0s - loss: 0.0692 - acc: 0.9754 - val_loss: 0.0320 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.03201 to 0.03110, saving model to best.model\n",
      "0s - loss: 0.0723 - acc: 0.9735 - val_loss: 0.0311 - val_acc: 0.9893\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.03110 to 0.02953, saving model to best.model\n",
      "0s - loss: 0.0644 - acc: 0.9754 - val_loss: 0.0295 - val_acc: 0.9912\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.02953 to 0.02828, saving model to best.model\n",
      "0s - loss: 0.0700 - acc: 0.9759 - val_loss: 0.0283 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.02828 to 0.02685, saving model to best.model\n",
      "0s - loss: 0.0625 - acc: 0.9771 - val_loss: 0.0268 - val_acc: 0.9903\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02685 to 0.02627, saving model to best.model\n",
      "0s - loss: 0.0619 - acc: 0.9778 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0657 - acc: 0.9761 - val_loss: 0.0265 - val_acc: 0.9903\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.0618 - acc: 0.9774 - val_loss: 0.0267 - val_acc: 0.9903\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0645 - acc: 0.9764 - val_loss: 0.0265 - val_acc: 0.9903\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.0569 - acc: 0.9793 - val_loss: 0.0276 - val_acc: 0.9903\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0700 - acc: 0.9737 - val_loss: 0.0312 - val_acc: 0.9893\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0679 - acc: 0.9744 - val_loss: 0.0278 - val_acc: 0.9893\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.02627 to 0.02542, saving model to best.model\n",
      "0s - loss: 0.0681 - acc: 0.9759 - val_loss: 0.0254 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.02542 to 0.02449, saving model to best.model\n",
      "0s - loss: 0.0651 - acc: 0.9761 - val_loss: 0.0245 - val_acc: 0.9903\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.02449 to 0.02409, saving model to best.model\n",
      "0s - loss: 0.0563 - acc: 0.9781 - val_loss: 0.0241 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.02409 to 0.02263, saving model to best.model\n",
      "0s - loss: 0.0580 - acc: 0.9803 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.02263 to 0.02130, saving model to best.model\n",
      "0s - loss: 0.0556 - acc: 0.9815 - val_loss: 0.0213 - val_acc: 0.9912\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.02130 to 0.02081, saving model to best.model\n",
      "0s - loss: 0.0649 - acc: 0.9798 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.02081 to 0.02024, saving model to best.model\n",
      "0s - loss: 0.0575 - acc: 0.9798 - val_loss: 0.0202 - val_acc: 0.9912\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0525 - acc: 0.9786 - val_loss: 0.0204 - val_acc: 0.9903\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.02024 to 0.01896, saving model to best.model\n",
      "0s - loss: 0.0508 - acc: 0.9822 - val_loss: 0.0190 - val_acc: 0.9912\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0509 - acc: 0.9822 - val_loss: 0.0193 - val_acc: 0.9922\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01896 to 0.01857, saving model to best.model\n",
      "0s - loss: 0.0565 - acc: 0.9795 - val_loss: 0.0186 - val_acc: 0.9932\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.01857 to 0.01818, saving model to best.model\n",
      "0s - loss: 0.0600 - acc: 0.9788 - val_loss: 0.0182 - val_acc: 0.9942\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.01818 to 0.01745, saving model to best.model\n",
      "0s - loss: 0.0547 - acc: 0.9803 - val_loss: 0.0174 - val_acc: 0.9942\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0508 - acc: 0.9825 - val_loss: 0.0177 - val_acc: 0.9922\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0545 - acc: 0.9793 - val_loss: 0.0178 - val_acc: 0.9942\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.01745 to 0.01679, saving model to best.model\n",
      "0s - loss: 0.0460 - acc: 0.9844 - val_loss: 0.0168 - val_acc: 0.9951\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.01679 to 0.01529, saving model to best.model\n",
      "0s - loss: 0.0520 - acc: 0.9771 - val_loss: 0.0153 - val_acc: 0.9961\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01529 to 0.01525, saving model to best.model\n",
      "0s - loss: 0.0506 - acc: 0.9803 - val_loss: 0.0153 - val_acc: 0.9951\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0564 - acc: 0.9803 - val_loss: 0.0157 - val_acc: 0.9951\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0518 - acc: 0.9810 - val_loss: 0.0158 - val_acc: 0.9951\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0463 - acc: 0.9859 - val_loss: 0.0167 - val_acc: 0.9942\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0489 - acc: 0.9813 - val_loss: 0.0161 - val_acc: 0.9932\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9830 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.01525 to 0.01408, saving model to best.model\n",
      "0s - loss: 0.0511 - acc: 0.9822 - val_loss: 0.0141 - val_acc: 0.9961\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9830 - val_loss: 0.0143 - val_acc: 0.9961\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0454 - acc: 0.9834 - val_loss: 0.0145 - val_acc: 0.9951\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.01408 to 0.01338, saving model to best.model\n",
      "0s - loss: 0.0437 - acc: 0.9847 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.01338 to 0.01332, saving model to best.model\n",
      "0s - loss: 0.0418 - acc: 0.9847 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.01332 to 0.01323, saving model to best.model\n",
      "0s - loss: 0.0518 - acc: 0.9815 - val_loss: 0.0132 - val_acc: 0.9961\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.0453 - acc: 0.9844 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0470 - acc: 0.9847 - val_loss: 0.0144 - val_acc: 0.9951\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.01323 to 0.01253, saving model to best.model\n",
      "0s - loss: 0.0487 - acc: 0.9827 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0363 - acc: 0.9847 - val_loss: 0.0129 - val_acc: 0.9961\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.01253 to 0.01223, saving model to best.model\n",
      "0s - loss: 0.0433 - acc: 0.9842 - val_loss: 0.0122 - val_acc: 0.9971\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0125 - val_acc: 0.9961\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.01223 to 0.01123, saving model to best.model\n",
      "0s - loss: 0.0372 - acc: 0.9869 - val_loss: 0.0112 - val_acc: 0.9971\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.01123 to 0.01116, saving model to best.model\n",
      "0s - loss: 0.0461 - acc: 0.9830 - val_loss: 0.0112 - val_acc: 0.9971\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0459 - acc: 0.9832 - val_loss: 0.0113 - val_acc: 0.9971\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.01116 to 0.01060, saving model to best.model\n",
      "0s - loss: 0.0427 - acc: 0.9817 - val_loss: 0.0106 - val_acc: 0.9971\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0481 - acc: 0.9832 - val_loss: 0.0124 - val_acc: 0.9951\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01060 to 0.01046, saving model to best.model\n",
      "0s - loss: 0.0427 - acc: 0.9866 - val_loss: 0.0105 - val_acc: 0.9971\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9837 - val_loss: 0.0133 - val_acc: 0.9951\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.01046 to 0.01040, saving model to best.model\n",
      "0s - loss: 0.0408 - acc: 0.9851 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0415 - acc: 0.9869 - val_loss: 0.0114 - val_acc: 0.9971\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.01040 to 0.01015, saving model to best.model\n",
      "0s - loss: 0.0396 - acc: 0.9869 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9851 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.01015 to 0.01010, saving model to best.model\n",
      "0s - loss: 0.0352 - acc: 0.9849 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.01010 to 0.00929, saving model to best.model\n",
      "0s - loss: 0.0386 - acc: 0.9856 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.00929 to 0.00860, saving model to best.model\n",
      "0s - loss: 0.0382 - acc: 0.9866 - val_loss: 0.0086 - val_acc: 0.9971\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0435 - acc: 0.9854 - val_loss: 0.0097 - val_acc: 0.9971\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.0402 - acc: 0.9844 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0385 - acc: 0.9847 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.00860 to 0.00850, saving model to best.model\n",
      "0s - loss: 0.0400 - acc: 0.9849 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.0325 - acc: 0.9878 - val_loss: 0.0098 - val_acc: 0.9971\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0407 - acc: 0.9844 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.00850 to 0.00793, saving model to best.model\n",
      "0s - loss: 0.0343 - acc: 0.9878 - val_loss: 0.0079 - val_acc: 0.9971\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0382 - acc: 0.9864 - val_loss: 0.0082 - val_acc: 0.9971\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0384 - acc: 0.9871 - val_loss: 0.0084 - val_acc: 0.9981\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.00793 to 0.00763, saving model to best.model\n",
      "0s - loss: 0.0314 - acc: 0.9886 - val_loss: 0.0076 - val_acc: 0.9971\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9886 - val_loss: 0.0085 - val_acc: 0.9971\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.00763 to 0.00722, saving model to best.model\n",
      "0s - loss: 0.0305 - acc: 0.9893 - val_loss: 0.0072 - val_acc: 0.9971\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0320 - acc: 0.9883 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0360 - acc: 0.9847 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0335 - acc: 0.9866 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0375 - acc: 0.9876 - val_loss: 0.0073 - val_acc: 0.9971\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0404 - acc: 0.9837 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0078 - val_acc: 0.9971\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.00722 to 0.00721, saving model to best.model\n",
      "0s - loss: 0.0370 - acc: 0.9864 - val_loss: 0.0072 - val_acc: 0.9971\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0338 - acc: 0.9871 - val_loss: 0.0076 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0411 - acc: 0.9859 - val_loss: 0.0091 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0358 - acc: 0.9873 - val_loss: 0.0079 - val_acc: 0.9981\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.00721 to 0.00703, saving model to best.model\n",
      "0s - loss: 0.0329 - acc: 0.9881 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0364 - acc: 0.9859 - val_loss: 0.0082 - val_acc: 0.9971\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00703 to 0.00603, saving model to best.model\n",
      "0s - loss: 0.0357 - acc: 0.9873 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0348 - acc: 0.9873 - val_loss: 0.0064 - val_acc: 0.9981\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9876 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.00603 to 0.00565, saving model to best.model\n",
      "0s - loss: 0.0309 - acc: 0.9890 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0296 - acc: 0.9905 - val_loss: 0.0078 - val_acc: 0.9971\n",
      "Train on 4107 samples, validate on 1027 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67191, saving model to best.model\n",
      "0s - loss: 0.7945 - acc: 0.5035 - val_loss: 0.6719 - val_acc: 0.6962\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.67191 to 0.64044, saving model to best.model\n",
      "0s - loss: 0.7348 - acc: 0.5442 - val_loss: 0.6404 - val_acc: 0.7994\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64044 to 0.59096, saving model to best.model\n",
      "0s - loss: 0.6906 - acc: 0.5717 - val_loss: 0.5910 - val_acc: 0.7400\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59096 to 0.51895, saving model to best.model\n",
      "0s - loss: 0.6234 - acc: 0.6496 - val_loss: 0.5189 - val_acc: 0.8092\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51895 to 0.44619, saving model to best.model\n",
      "0s - loss: 0.5424 - acc: 0.7412 - val_loss: 0.4462 - val_acc: 0.8354\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.44619 to 0.39639, saving model to best.model\n",
      "0s - loss: 0.4816 - acc: 0.7869 - val_loss: 0.3964 - val_acc: 0.8569\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.39639 to 0.37612, saving model to best.model\n",
      "0s - loss: 0.4249 - acc: 0.8223 - val_loss: 0.3761 - val_acc: 0.8598\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.37612 to 0.34044, saving model to best.model\n",
      "0s - loss: 0.4071 - acc: 0.8344 - val_loss: 0.3404 - val_acc: 0.8754\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.34044 to 0.32085, saving model to best.model\n",
      "0s - loss: 0.3863 - acc: 0.8437 - val_loss: 0.3209 - val_acc: 0.8822\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.32085 to 0.30282, saving model to best.model\n",
      "0s - loss: 0.3643 - acc: 0.8551 - val_loss: 0.3028 - val_acc: 0.8832\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.30282 to 0.28558, saving model to best.model\n",
      "0s - loss: 0.3444 - acc: 0.8685 - val_loss: 0.2856 - val_acc: 0.8880\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.28558 to 0.27096, saving model to best.model\n",
      "0s - loss: 0.3437 - acc: 0.8707 - val_loss: 0.2710 - val_acc: 0.8939\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.27096 to 0.25761, saving model to best.model\n",
      "0s - loss: 0.3189 - acc: 0.8775 - val_loss: 0.2576 - val_acc: 0.8968\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.25761 to 0.24807, saving model to best.model\n",
      "0s - loss: 0.3277 - acc: 0.8785 - val_loss: 0.2481 - val_acc: 0.8978\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.24807 to 0.24009, saving model to best.model\n",
      "0s - loss: 0.3126 - acc: 0.8802 - val_loss: 0.2401 - val_acc: 0.9007\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.24009 to 0.23202, saving model to best.model\n",
      "0s - loss: 0.2936 - acc: 0.8907 - val_loss: 0.2320 - val_acc: 0.9065\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.23202 to 0.22788, saving model to best.model\n",
      "0s - loss: 0.2950 - acc: 0.8875 - val_loss: 0.2279 - val_acc: 0.9133\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.22788 to 0.21595, saving model to best.model\n",
      "0s - loss: 0.2841 - acc: 0.8936 - val_loss: 0.2159 - val_acc: 0.9163\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.21595 to 0.20986, saving model to best.model\n",
      "0s - loss: 0.2807 - acc: 0.8965 - val_loss: 0.2099 - val_acc: 0.9260\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.20986 to 0.20575, saving model to best.model\n",
      "0s - loss: 0.2721 - acc: 0.8975 - val_loss: 0.2057 - val_acc: 0.9241\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.20575 to 0.20139, saving model to best.model\n",
      "0s - loss: 0.2709 - acc: 0.9011 - val_loss: 0.2014 - val_acc: 0.9241\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.20139 to 0.19528, saving model to best.model\n",
      "0s - loss: 0.2594 - acc: 0.9011 - val_loss: 0.1953 - val_acc: 0.9338\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.19528 to 0.19037, saving model to best.model\n",
      "0s - loss: 0.2572 - acc: 0.9075 - val_loss: 0.1904 - val_acc: 0.9328\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.19037 to 0.18750, saving model to best.model\n",
      "0s - loss: 0.2587 - acc: 0.9031 - val_loss: 0.1875 - val_acc: 0.9318\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.18750 to 0.18387, saving model to best.model\n",
      "0s - loss: 0.2524 - acc: 0.9053 - val_loss: 0.1839 - val_acc: 0.9328\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.18387 to 0.18088, saving model to best.model\n",
      "0s - loss: 0.2533 - acc: 0.9055 - val_loss: 0.1809 - val_acc: 0.9309\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.18088 to 0.17587, saving model to best.model\n",
      "0s - loss: 0.2437 - acc: 0.9109 - val_loss: 0.1759 - val_acc: 0.9377\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.17587 to 0.17034, saving model to best.model\n",
      "0s - loss: 0.2358 - acc: 0.9092 - val_loss: 0.1703 - val_acc: 0.9387\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.17034 to 0.16657, saving model to best.model\n",
      "0s - loss: 0.2358 - acc: 0.9126 - val_loss: 0.1666 - val_acc: 0.9387\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.16657 to 0.16312, saving model to best.model\n",
      "0s - loss: 0.2257 - acc: 0.9162 - val_loss: 0.1631 - val_acc: 0.9396\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.16312 to 0.16028, saving model to best.model\n",
      "0s - loss: 0.2256 - acc: 0.9150 - val_loss: 0.1603 - val_acc: 0.9406\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.16028 to 0.15514, saving model to best.model\n",
      "0s - loss: 0.2171 - acc: 0.9201 - val_loss: 0.1551 - val_acc: 0.9387\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.15514 to 0.15095, saving model to best.model\n",
      "0s - loss: 0.2109 - acc: 0.9204 - val_loss: 0.1510 - val_acc: 0.9406\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.15095 to 0.15060, saving model to best.model\n",
      "0s - loss: 0.2174 - acc: 0.9196 - val_loss: 0.1506 - val_acc: 0.9396\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.15060 to 0.14360, saving model to best.model\n",
      "0s - loss: 0.2071 - acc: 0.9206 - val_loss: 0.1436 - val_acc: 0.9455\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.14360 to 0.13996, saving model to best.model\n",
      "0s - loss: 0.1983 - acc: 0.9243 - val_loss: 0.1400 - val_acc: 0.9484\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.13996 to 0.13714, saving model to best.model\n",
      "0s - loss: 0.2034 - acc: 0.9228 - val_loss: 0.1371 - val_acc: 0.9474\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.13714 to 0.13287, saving model to best.model\n",
      "0s - loss: 0.1933 - acc: 0.9296 - val_loss: 0.1329 - val_acc: 0.9484\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.13287 to 0.12941, saving model to best.model\n",
      "0s - loss: 0.1935 - acc: 0.9231 - val_loss: 0.1294 - val_acc: 0.9464\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.12941 to 0.12469, saving model to best.model\n",
      "0s - loss: 0.1868 - acc: 0.9299 - val_loss: 0.1247 - val_acc: 0.9503\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.12469 to 0.12340, saving model to best.model\n",
      "0s - loss: 0.1890 - acc: 0.9274 - val_loss: 0.1234 - val_acc: 0.9552\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.12340 to 0.11875, saving model to best.model\n",
      "0s - loss: 0.1812 - acc: 0.9296 - val_loss: 0.1188 - val_acc: 0.9533\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.11875 to 0.11674, saving model to best.model\n",
      "0s - loss: 0.1828 - acc: 0.9306 - val_loss: 0.1167 - val_acc: 0.9494\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.11674 to 0.11235, saving model to best.model\n",
      "0s - loss: 0.1698 - acc: 0.9403 - val_loss: 0.1124 - val_acc: 0.9552\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.11235 to 0.11140, saving model to best.model\n",
      "0s - loss: 0.1736 - acc: 0.9299 - val_loss: 0.1114 - val_acc: 0.9562\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.11140 to 0.10671, saving model to best.model\n",
      "0s - loss: 0.1735 - acc: 0.9318 - val_loss: 0.1067 - val_acc: 0.9572\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.10671 to 0.10310, saving model to best.model\n",
      "0s - loss: 0.1604 - acc: 0.9374 - val_loss: 0.1031 - val_acc: 0.9572\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.10310 to 0.10121, saving model to best.model\n",
      "0s - loss: 0.1647 - acc: 0.9362 - val_loss: 0.1012 - val_acc: 0.9601\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.10121 to 0.09878, saving model to best.model\n",
      "0s - loss: 0.1562 - acc: 0.9384 - val_loss: 0.0988 - val_acc: 0.9572\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.09878 to 0.09477, saving model to best.model\n",
      "0s - loss: 0.1515 - acc: 0.9401 - val_loss: 0.0948 - val_acc: 0.9591\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.09477 to 0.09155, saving model to best.model\n",
      "0s - loss: 0.1458 - acc: 0.9435 - val_loss: 0.0916 - val_acc: 0.9611\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.09155 to 0.08722, saving model to best.model\n",
      "0s - loss: 0.1496 - acc: 0.9401 - val_loss: 0.0872 - val_acc: 0.9640\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.08722 to 0.08588, saving model to best.model\n",
      "0s - loss: 0.1381 - acc: 0.9464 - val_loss: 0.0859 - val_acc: 0.9669\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.1431 - acc: 0.9459 - val_loss: 0.0924 - val_acc: 0.9611\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.08588 to 0.08028, saving model to best.model\n",
      "0s - loss: 0.1376 - acc: 0.9481 - val_loss: 0.0803 - val_acc: 0.9688\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.08028 to 0.07816, saving model to best.model\n",
      "0s - loss: 0.1363 - acc: 0.9455 - val_loss: 0.0782 - val_acc: 0.9688\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.07816 to 0.07630, saving model to best.model\n",
      "0s - loss: 0.1352 - acc: 0.9457 - val_loss: 0.0763 - val_acc: 0.9708\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.07630 to 0.07498, saving model to best.model\n",
      "0s - loss: 0.1301 - acc: 0.9520 - val_loss: 0.0750 - val_acc: 0.9698\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.07498 to 0.07303, saving model to best.model\n",
      "0s - loss: 0.1249 - acc: 0.9523 - val_loss: 0.0730 - val_acc: 0.9718\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.1358 - acc: 0.9486 - val_loss: 0.0737 - val_acc: 0.9718\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.07303 to 0.06904, saving model to best.model\n",
      "0s - loss: 0.1204 - acc: 0.9559 - val_loss: 0.0690 - val_acc: 0.9757\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.06904 to 0.06600, saving model to best.model\n",
      "0s - loss: 0.1154 - acc: 0.9535 - val_loss: 0.0660 - val_acc: 0.9776\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.06600 to 0.06464, saving model to best.model\n",
      "0s - loss: 0.1133 - acc: 0.9552 - val_loss: 0.0646 - val_acc: 0.9776\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.06464 to 0.06148, saving model to best.model\n",
      "0s - loss: 0.1179 - acc: 0.9571 - val_loss: 0.0615 - val_acc: 0.9786\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.06148 to 0.06039, saving model to best.model\n",
      "0s - loss: 0.1049 - acc: 0.9635 - val_loss: 0.0604 - val_acc: 0.9796\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.06039 to 0.05812, saving model to best.model\n",
      "0s - loss: 0.1027 - acc: 0.9637 - val_loss: 0.0581 - val_acc: 0.9796\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.1108 - acc: 0.9593 - val_loss: 0.0585 - val_acc: 0.9825\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.05812 to 0.05487, saving model to best.model\n",
      "0s - loss: 0.1033 - acc: 0.9610 - val_loss: 0.0549 - val_acc: 0.9825\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.05487 to 0.05372, saving model to best.model\n",
      "0s - loss: 0.1085 - acc: 0.9598 - val_loss: 0.0537 - val_acc: 0.9825\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.05372 to 0.05326, saving model to best.model\n",
      "0s - loss: 0.0945 - acc: 0.9642 - val_loss: 0.0533 - val_acc: 0.9864\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.05326 to 0.05086, saving model to best.model\n",
      "0s - loss: 0.1005 - acc: 0.9652 - val_loss: 0.0509 - val_acc: 0.9873\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.05086 to 0.04939, saving model to best.model\n",
      "0s - loss: 0.0957 - acc: 0.9647 - val_loss: 0.0494 - val_acc: 0.9873\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.04939 to 0.04683, saving model to best.model\n",
      "0s - loss: 0.0940 - acc: 0.9642 - val_loss: 0.0468 - val_acc: 0.9844\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.04683 to 0.04611, saving model to best.model\n",
      "0s - loss: 0.0950 - acc: 0.9642 - val_loss: 0.0461 - val_acc: 0.9883\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.04611 to 0.04473, saving model to best.model\n",
      "0s - loss: 0.0937 - acc: 0.9645 - val_loss: 0.0447 - val_acc: 0.9883\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.04473 to 0.04312, saving model to best.model\n",
      "0s - loss: 0.0912 - acc: 0.9691 - val_loss: 0.0431 - val_acc: 0.9883\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.0911 - acc: 0.9666 - val_loss: 0.0433 - val_acc: 0.9883\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.04312 to 0.04253, saving model to best.model\n",
      "0s - loss: 0.0887 - acc: 0.9691 - val_loss: 0.0425 - val_acc: 0.9883\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.04253 to 0.04129, saving model to best.model\n",
      "0s - loss: 0.0881 - acc: 0.9681 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.04129 to 0.04000, saving model to best.model\n",
      "0s - loss: 0.0752 - acc: 0.9703 - val_loss: 0.0400 - val_acc: 0.9883\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.04000 to 0.03872, saving model to best.model\n",
      "0s - loss: 0.0796 - acc: 0.9698 - val_loss: 0.0387 - val_acc: 0.9883\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.03872 to 0.03749, saving model to best.model\n",
      "0s - loss: 0.0786 - acc: 0.9708 - val_loss: 0.0375 - val_acc: 0.9903\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.0794 - acc: 0.9713 - val_loss: 0.0389 - val_acc: 0.9883\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.03749 to 0.03426, saving model to best.model\n",
      "0s - loss: 0.0765 - acc: 0.9715 - val_loss: 0.0343 - val_acc: 0.9883\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.0786 - acc: 0.9725 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.03426 to 0.03352, saving model to best.model\n",
      "0s - loss: 0.0787 - acc: 0.9725 - val_loss: 0.0335 - val_acc: 0.9883\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.0745 - acc: 0.9730 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.03352 to 0.03273, saving model to best.model\n",
      "0s - loss: 0.0759 - acc: 0.9725 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.0666 - acc: 0.9764 - val_loss: 0.0422 - val_acc: 0.9864\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.03273 to 0.03224, saving model to best.model\n",
      "0s - loss: 0.0755 - acc: 0.9749 - val_loss: 0.0322 - val_acc: 0.9883\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.0759 - acc: 0.9732 - val_loss: 0.0328 - val_acc: 0.9883\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.03224 to 0.03205, saving model to best.model\n",
      "0s - loss: 0.0658 - acc: 0.9749 - val_loss: 0.0320 - val_acc: 0.9893\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.03205 to 0.03092, saving model to best.model\n",
      "0s - loss: 0.0667 - acc: 0.9749 - val_loss: 0.0309 - val_acc: 0.9893\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.0682 - acc: 0.9735 - val_loss: 0.0341 - val_acc: 0.9893\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.03092 to 0.02919, saving model to best.model\n",
      "0s - loss: 0.0639 - acc: 0.9795 - val_loss: 0.0292 - val_acc: 0.9893\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.0612 - acc: 0.9771 - val_loss: 0.0300 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.02919 to 0.02754, saving model to best.model\n",
      "0s - loss: 0.0648 - acc: 0.9757 - val_loss: 0.0275 - val_acc: 0.9893\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.02754 to 0.02744, saving model to best.model\n",
      "0s - loss: 0.0687 - acc: 0.9754 - val_loss: 0.0274 - val_acc: 0.9893\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.0616 - acc: 0.9798 - val_loss: 0.0289 - val_acc: 0.9893\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.02744 to 0.02574, saving model to best.model\n",
      "0s - loss: 0.0587 - acc: 0.9798 - val_loss: 0.0257 - val_acc: 0.9893\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.0613 - acc: 0.9791 - val_loss: 0.0275 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.02574 to 0.02377, saving model to best.model\n",
      "0s - loss: 0.0535 - acc: 0.9832 - val_loss: 0.0238 - val_acc: 0.9903\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.0566 - acc: 0.9813 - val_loss: 0.0277 - val_acc: 0.9903\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.02377 to 0.02331, saving model to best.model\n",
      "0s - loss: 0.0620 - acc: 0.9803 - val_loss: 0.0233 - val_acc: 0.9893\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.0637 - acc: 0.9769 - val_loss: 0.0269 - val_acc: 0.9893\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.02331 to 0.02233, saving model to best.model\n",
      "0s - loss: 0.0570 - acc: 0.9781 - val_loss: 0.0223 - val_acc: 0.9912\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.0663 - acc: 0.9791 - val_loss: 0.0254 - val_acc: 0.9893\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.02233 to 0.02129, saving model to best.model\n",
      "0s - loss: 0.0588 - acc: 0.9778 - val_loss: 0.0213 - val_acc: 0.9912\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.02129 to 0.02095, saving model to best.model\n",
      "0s - loss: 0.0539 - acc: 0.9825 - val_loss: 0.0210 - val_acc: 0.9912\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0592 - acc: 0.9788 - val_loss: 0.0215 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.02095 to 0.02028, saving model to best.model\n",
      "0s - loss: 0.0523 - acc: 0.9822 - val_loss: 0.0203 - val_acc: 0.9922\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.02028 to 0.02018, saving model to best.model\n",
      "0s - loss: 0.0562 - acc: 0.9798 - val_loss: 0.0202 - val_acc: 0.9922\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.0544 - acc: 0.9791 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.0580 - acc: 0.9776 - val_loss: 0.0205 - val_acc: 0.9912\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.02018 to 0.01966, saving model to best.model\n",
      "0s - loss: 0.0461 - acc: 0.9847 - val_loss: 0.0197 - val_acc: 0.9922\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.0534 - acc: 0.9813 - val_loss: 0.0214 - val_acc: 0.9893\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.01966 to 0.01832, saving model to best.model\n",
      "0s - loss: 0.0489 - acc: 0.9817 - val_loss: 0.0183 - val_acc: 0.9932\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.0452 - acc: 0.9851 - val_loss: 0.0197 - val_acc: 0.9903\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.01832 to 0.01746, saving model to best.model\n",
      "0s - loss: 0.0535 - acc: 0.9808 - val_loss: 0.0175 - val_acc: 0.9922\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0595 - acc: 0.9781 - val_loss: 0.0206 - val_acc: 0.9903\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9837 - val_loss: 0.0185 - val_acc: 0.9912\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.01746 to 0.01610, saving model to best.model\n",
      "0s - loss: 0.0475 - acc: 0.9832 - val_loss: 0.0161 - val_acc: 0.9932\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.0429 - acc: 0.9849 - val_loss: 0.0162 - val_acc: 0.9922\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.0443 - acc: 0.9842 - val_loss: 0.0171 - val_acc: 0.9922\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.0425 - acc: 0.9856 - val_loss: 0.0183 - val_acc: 0.9922\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.0488 - acc: 0.9832 - val_loss: 0.0172 - val_acc: 0.9922\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.01610 to 0.01543, saving model to best.model\n",
      "0s - loss: 0.0448 - acc: 0.9825 - val_loss: 0.0154 - val_acc: 0.9922\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9851 - val_loss: 0.0171 - val_acc: 0.9922\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.0435 - acc: 0.9832 - val_loss: 0.0168 - val_acc: 0.9922\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.01543 to 0.01468, saving model to best.model\n",
      "0s - loss: 0.0463 - acc: 0.9847 - val_loss: 0.0147 - val_acc: 0.9932\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.0444 - acc: 0.9815 - val_loss: 0.0178 - val_acc: 0.9922\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.01468 to 0.01411, saving model to best.model\n",
      "0s - loss: 0.0411 - acc: 0.9869 - val_loss: 0.0141 - val_acc: 0.9942\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.0451 - acc: 0.9834 - val_loss: 0.0163 - val_acc: 0.9922\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.0390 - acc: 0.9871 - val_loss: 0.0151 - val_acc: 0.9922\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.0449 - acc: 0.9849 - val_loss: 0.0153 - val_acc: 0.9922\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9851 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.0403 - acc: 0.9849 - val_loss: 0.0148 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.01411 to 0.01322, saving model to best.model\n",
      "0s - loss: 0.0349 - acc: 0.9866 - val_loss: 0.0132 - val_acc: 0.9932\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.01322 to 0.01287, saving model to best.model\n",
      "0s - loss: 0.0428 - acc: 0.9847 - val_loss: 0.0129 - val_acc: 0.9942\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0396 - acc: 0.9851 - val_loss: 0.0133 - val_acc: 0.9942\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.0414 - acc: 0.9827 - val_loss: 0.0136 - val_acc: 0.9942\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.0413 - acc: 0.9856 - val_loss: 0.0146 - val_acc: 0.9932\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9844 - val_loss: 0.0131 - val_acc: 0.9942\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0133 - val_acc: 0.9932\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.0368 - acc: 0.9866 - val_loss: 0.0131 - val_acc: 0.9932\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.01287 to 0.01179, saving model to best.model\n",
      "0s - loss: 0.0339 - acc: 0.9869 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.0398 - acc: 0.9871 - val_loss: 0.0154 - val_acc: 0.9932\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.0388 - acc: 0.9871 - val_loss: 0.0126 - val_acc: 0.9961\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.0302 - acc: 0.9895 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9888 - val_loss: 0.0131 - val_acc: 0.9951\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.01179 to 0.01103, saving model to best.model\n",
      "0s - loss: 0.0383 - acc: 0.9856 - val_loss: 0.0110 - val_acc: 0.9951\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.0394 - acc: 0.9854 - val_loss: 0.0125 - val_acc: 0.9932\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.0404 - acc: 0.9851 - val_loss: 0.0118 - val_acc: 0.9942\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.0475 - acc: 0.9820 - val_loss: 0.0221 - val_acc: 0.9903\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.0454 - acc: 0.9839 - val_loss: 0.0110 - val_acc: 0.9961\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.0337 - acc: 0.9876 - val_loss: 0.0126 - val_acc: 0.9951\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.01103 to 0.01063, saving model to best.model\n",
      "0s - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.0346 - acc: 0.9878 - val_loss: 0.0110 - val_acc: 0.9942\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.0347 - acc: 0.9886 - val_loss: 0.0116 - val_acc: 0.9951\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0318 - acc: 0.9883 - val_loss: 0.0113 - val_acc: 0.9951\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.0319 - acc: 0.9883 - val_loss: 0.0117 - val_acc: 0.9942\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.0299 - acc: 0.9893 - val_loss: 0.0114 - val_acc: 0.9932\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.01063 to 0.00983, saving model to best.model\n",
      "0s - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0098 - val_acc: 0.9961\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.0446 - acc: 0.9851 - val_loss: 0.0130 - val_acc: 0.9942\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.0395 - acc: 0.9859 - val_loss: 0.0109 - val_acc: 0.9961\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.0323 - acc: 0.9876 - val_loss: 0.0107 - val_acc: 0.9961\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.00983 to 0.00956, saving model to best.model\n",
      "0s - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0096 - val_acc: 0.9971\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.00956 to 0.00944, saving model to best.model\n",
      "0s - loss: 0.0273 - acc: 0.9888 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.0301 - acc: 0.9888 - val_loss: 0.0101 - val_acc: 0.9951\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0275 - acc: 0.9883 - val_loss: 0.0096 - val_acc: 0.9951\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.0336 - acc: 0.9893 - val_loss: 0.0100 - val_acc: 0.9951\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.0356 - acc: 0.9881 - val_loss: 0.0097 - val_acc: 0.9942\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.00944 to 0.00867, saving model to best.model\n",
      "0s - loss: 0.0277 - acc: 0.9900 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.0294 - acc: 0.9893 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.0256 - acc: 0.9920 - val_loss: 0.0088 - val_acc: 0.9961\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.00867 to 0.00848, saving model to best.model\n",
      "0s - loss: 0.0308 - acc: 0.9895 - val_loss: 0.0085 - val_acc: 0.9961\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.0271 - acc: 0.9893 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.0297 - acc: 0.9893 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.0255 - acc: 0.9905 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.00848 to 0.00833, saving model to best.model\n",
      "0s - loss: 0.0242 - acc: 0.9900 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.0305 - acc: 0.9890 - val_loss: 0.0090 - val_acc: 0.9951\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.00833 to 0.00733, saving model to best.model\n",
      "0s - loss: 0.0245 - acc: 0.9903 - val_loss: 0.0073 - val_acc: 0.9961\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9886 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.0239 - acc: 0.9907 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.0324 - acc: 0.9869 - val_loss: 0.0101 - val_acc: 0.9942\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.0247 - acc: 0.9905 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0087 - val_acc: 0.9951\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.0328 - acc: 0.9876 - val_loss: 0.0097 - val_acc: 0.9951\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.0263 - acc: 0.9895 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0262 - acc: 0.9922 - val_loss: 0.0083 - val_acc: 0.9961\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.0245 - acc: 0.9925 - val_loss: 0.0088 - val_acc: 0.9971\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.0280 - acc: 0.9895 - val_loss: 0.0082 - val_acc: 0.9971\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.0221 - acc: 0.9912 - val_loss: 0.0083 - val_acc: 0.9971\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.0219 - acc: 0.9927 - val_loss: 0.0088 - val_acc: 0.9961\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.0228 - acc: 0.9927 - val_loss: 0.0088 - val_acc: 0.9951\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.00733 to 0.00681, saving model to best.model\n",
      "0s - loss: 0.0269 - acc: 0.9907 - val_loss: 0.0068 - val_acc: 0.9971\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.0260 - acc: 0.9907 - val_loss: 0.0080 - val_acc: 0.9971\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0074 - val_acc: 0.9971\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.0245 - acc: 0.9903 - val_loss: 0.0075 - val_acc: 0.9971\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0291 - acc: 0.9905 - val_loss: 0.0068 - val_acc: 0.9971\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(50):\n",
    "    y_pred=train_nn_simple(train,X_val,y_val)\n",
    "    result.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       ..., \n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new=np.array(result)\n",
    "result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_new1=result_new.sum(axis=0)\n",
    "result_new1\n",
    "re=result_new1.tolist()\n",
    "re\n",
    "y_pred=[]\n",
    "for each in re:\n",
    "    if each>=25:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    0]\n",
      " [   3  956]]\n",
      "99.8522895126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1072\n",
      "          1       1.00      1.00      1.00       959\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(y_val, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_val, y_pred) * 100) \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 50,  0, ...,  0, 50, 50])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
