{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_list=[\"Status of account\",'Duration','Credit history','Purpose','Credit amount',\n",
    "           'Savings account','Present employment','Installment rate','Personal status and sex','Other debtors',\n",
    "           'Present residence','Property','Age','Other installment plans','Housing',\n",
    "           'Number of existing credits','Job','Number of people','Telephone','Foreign worker',\n",
    "           'y'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\",delimiter=r\"\\s+\",names=name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status of account</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Savings account</th>\n",
       "      <th>Present employment</th>\n",
       "      <th>Installment rate</th>\n",
       "      <th>Personal status and sex</th>\n",
       "      <th>Other debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>Property</th>\n",
       "      <th>Age</th>\n",
       "      <th>Other installment plans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Number of existing credits</th>\n",
       "      <th>Job</th>\n",
       "      <th>Number of people</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign worker</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Status of account  Duration Credit history Purpose  Credit amount  \\\n",
       "0               A11         6            A34     A43           1169   \n",
       "1               A12        48            A32     A43           5951   \n",
       "2               A14        12            A34     A46           2096   \n",
       "3               A11        42            A32     A42           7882   \n",
       "4               A11        24            A33     A40           4870   \n",
       "\n",
       "  Savings account Present employment  Installment rate  \\\n",
       "0             A65                A75                 4   \n",
       "1             A61                A73                 2   \n",
       "2             A61                A74                 2   \n",
       "3             A61                A74                 2   \n",
       "4             A61                A73                 3   \n",
       "\n",
       "  Personal status and sex Other debtors ...  Property Age  \\\n",
       "0                     A93          A101 ...      A121  67   \n",
       "1                     A92          A101 ...      A121  22   \n",
       "2                     A93          A101 ...      A121  49   \n",
       "3                     A93          A103 ...      A122  45   \n",
       "4                     A93          A101 ...      A124  53   \n",
       "\n",
       "   Other installment plans Housing Number of existing credits   Job  \\\n",
       "0                     A143    A152                          2  A173   \n",
       "1                     A143    A152                          1  A173   \n",
       "2                     A143    A152                          1  A172   \n",
       "3                     A143    A153                          1  A173   \n",
       "4                     A143    A153                          2  A173   \n",
       "\n",
       "  Number of people  Telephone Foreign worker  y  \n",
       "0                1       A192           A201  1  \n",
       "1                1       A191           A201  2  \n",
       "2                2       A191           A201  1  \n",
       "3                2       A191           A201  1  \n",
       "4                2       A191           A201  2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAHfCAYAAAB9MP2sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XlAU1e+B/BvSAgoyyBT9PWNxYKCSy2jlXEZFJdaUSt1\nKaJg0RbbUerUYl1YZNHBqlRLXUZErc44cUEeUGs702kVtbSIvJbRKlTqSJWKUos7QUwCnPeHz4zI\nDjckge/nL3KT3PxOOCf3l5N7f0cmhBAgIiIiIklYGDsAIiIiovaEyRURERGRhJhcEREREUmIyRUR\nERGRhJhcEREREUmIyRURERGRhJhcmSCdTofhw4dj7ty5xg6FqFFVVVX4y1/+gmnTpmHy5MmYOHEi\n1q1bB61W2+p9Dxw4EMXFxTh79iwWLlwIADhz5gxiYmJave+2EhwcjJs3bxo7DDJjxcXF6Nu3LyZP\nnozJkyfD19cX06ZNw8GDByV9nUf76htvvIELFy5Iuv+ORGHsAKi2w4cPo3fv3sjPz0dhYSF69uxp\n7JCI6rVixQrcuXMHu3fvhp2dHe7du4clS5Zg+fLlWLdunSSv8eyzz2LTpk0AgAsXLuDatWuS7Lct\nZGVlGTsEagesra3x8ccf629fuXIFr776Kjp16gQfHx9JXuPRvrpjxw5J9tlRMbkyQfv378fEiRPR\no0cP7N69G3/6058AANu3b0dqaipsbGzg6emJjIwMHD16FFqtFuvXr8c333yDqqoq9OvXD1FRUbC1\ntTVyS6i9u3z5Mj755BN8/fXX+v7WuXNnrFy5EqdOnQIAhIeH4/bt27h8+TJGjRqFt99+u97++u23\n3yIuLg4ymQzPPvssqqurAQA5OTmIi4vDjh07sGnTJpSVlSEiIgJr1qypEc+xY8ewbds2aLVa3Lx5\nE1OmTEFoaChycnKQkJCArl274t///jc6deqEt956CyqVChcvXsS4ceMQGRkJADhw4ABUKhUsLCzw\nxBNPIDo6Gi4uLggPD4ebm5t+RvnR22PGjMHUqVORnZ2NkpISTJgwAcuWLUNERAQAYM6cOdi+fTue\nfPLJNvm/UPv3m9/8BgsXLsTOnTtx7NixBvumh4cHfvjhB7zzzjtQKBR1jpHH++qsWbOwceNGPPvs\nsw2OCVtbW/zwww/4+eef4erqioSEBNjY2BjzrTEJ/FnQxFy4cAGnT5/GhAkTMGXKFHz88ce4desW\nvvrqK6SnpyM1NRXp6ekoLy/XP2f79u2Qy+VIT0/HoUOH0LVrV6xfv96IraCO4vvvv0evXr1qJfJO\nTk4YN26c/vb9+/fx97//HUuXLq23v2q1Wrz99tsIDw/HwYMHMWTIENy/f7/Gfp988kksXLgQnp6e\ntRIrIQR27dqFtWvXIj09HQcOHMD27dv1P3OcPXsWISEh+Oc//4lf//rX2L59O7Zt24b09HTs27cP\n165dQ3Z2Nj788EP87W9/w6FDhzBp0iQsWLAATVnI4t69e9i3bx+Sk5OxZ88eXL58WR/j7t27mViR\n5Pr06YPz5883+jg3Nzd89tlnGDt2bL1jpL6+2tiYyMvLw86dO/GPf/wDv/zyC/75z38aprFmhjNX\nJmb//v0YNWoUHBwc4ODggO7du+PAgQO4fv06xo8fD3t7ewDArFmzcPLkSQDA8ePHUVZWhhMnTgB4\ncM7Wr3/9a6O1gToOCwsL/exSQwYNGqT/u77+ev78eSgUCgwbNgwAMGnSpGadWyWTyZCUlITjx4/j\n008/RWFhIYQQqKioAAB0794d/fr1AwA4OzvDzs4OSqUSjo6OsLGxwZ07d/DVV19h4sSJcHR0BABM\nmzYN7777LoqLixt9/eeffx4A0K1bN/z617/GnTt38NRTTzU5fqLmkslksLa2bvRxnp6e+sc3NEbq\n0tiYGDFiBJRKJQDA3d0dd+7caW2z2gUmVybk3r17OHjwIKysrDBmzBgAgFqtxt69e/Hiiy/W+PYs\nl8v1f1dXVyMyMhIjR44EAJSXl0Oj0bRt8NQheXh44Mcff4Rara4xe3Xt2jVER0frz5Pq3Lmz/r76\n+mtJSUmtGSKFoukfUffu3cPUqVMxduxYeHp64uWXX8aRI0f0+3x4AGho33XNUAkhUFlZCZlMVuN+\nnU5X43FWVlb6vx9/LJEhnD17Fu7u7o32zYfjr7ExUpeGxgSAGskd+/1/8GdBE/LJJ5+gS5cu+Oqr\nr3D06FEcPXoUR44cwb1799CvXz988cUXKCsrAwCkpqbqnzd8+HDs3bsXWq0W1dXViI6ORkJCgrGa\nQR1It27d4Ovri8jISKjVagAPvhCsWLECDg4OdX6rrq+/uru7QwiBL7/8EgCQkZFR57dguVyu/2B/\nVFFREdRqNUJDQzFmzBj87//+r/41mmr48OH4xz/+of8pMS0tDQ4ODujRowe6dOmCvLw8AMDNmzfx\n7bffNmmf9cVL1BoXL15EYmIigoODm9w3GxsjdfXVhsYE1Y8zVyZk//79eO2112rMStnb2yMoKAi7\nd++Gv78/ZsyYAWtra7i5uaFTp04AgDfffBPx8fGYOnUqqqqq0LdvX4SHhxurGdTBxMbGIjExETNn\nzoRcLodWq8XYsWPx1ltv1fn4+vqrpaUltmzZghUrViAhIQF9+/at8+ftgQMHYsOGDViwYAG2bNmi\n3967d2+MGjUKEyZMgL29PZydndGrVy8UFRXVmrWqj5eXF1599VXMmTMH1dXVcHR0xLZt22BhYYGg\noCAsWbIEPj4+6N69OwYPHtykfb7wwgsIDAxEYmIi3N3dm/Qcosfdv38fkydPBvDg53grKyu88847\nGDVqFHr37t2kvtnQGHF2dq7RVx9qaExQ/WSCc3hm4ezZszh16hRmz54NAPjLX/6C7777Dhs2bDBy\nZERERPQoJldmQq1WIzIyEj/++CNkMhmefPJJxMXFoVu3bsYOjYiIiB7B5IqIiIhIQvzRlIiIiEhC\nTK6IiIiIJMTkioiIiEhCRi3FUFpa1qTHdenSGbdu3TNwNIbHdhiPk5OdsUNosbrGian+D0w1LoCx\nNYW5jpOmHkuMxVT+v40xhziNHWNTx4hZzFwpFPLGH2QG2A6Siqn+D0w1LoCxkfGYy//XHOI0hxgB\nM0muiIiIiMwFkysiIiIiCTG5IiIiIpIQkysiIiIiCbW7hZuD1x5t0fN2hY+ROBIiw2N/JzItHJME\ncOaKiIiISFINzlzpdDpERkbiypUr0Gq1CAkJwZNPPol58+bh6aefBgAEBARg4sSJSElJQXJyMhQK\nBUJCQjB69Oi2iJ+IiIjIpDSYXB06dAgODg5Yt24dbt++jSlTpmDBggV47bXXEBwcrH9caWkpVCoV\n0tLSoNFoEBgYCC8vLyiVSoM3gIiIiMiUNJhcjR8/Hj4+PgAAIQTkcjny8vJw8eJFZGRkoEePHoiM\njMSZM2cwcOBAKJVKKJVKODs7o6CgAB4eHm3SCCIiIiJT0WByZWNjAwBQq9VYuHAhQkNDodVqMX36\ndPTv3x9bt27Fli1b0KdPH9jZ2dV4nlqtbvTFu3Tp3ORqq4ZelqGtln0w1+UlHtde2kFERCS1Rq8W\nLCkpwYIFCxAYGAhfX1/cvXsX9vb2AIAXXngBcXFx8PT0RHl5uf455eXlNZKt+jR1fSAnJzuDrx3V\nFmtTtUU72oI5toPJIBERtZUGrxa8fv06goODsXTpUvj5+QEA5s6dizNnzgAAsrOz8cwzz8DDwwO5\nubnQaDQoKytDYWEh3N3dDR89ERERkYlpcOYqKSkJd+/eRWJiIhITEwEA4eHhWL16NSwtLfHEE08g\nLi4Otra2CAoKQmBgIIQQWLRoEaysrNqkAUSm4saNG5g2bRp27doFhUKB8PBwyGQyuLm5ITY2FhYW\nFryqloioA2gwuYqKikJUVFSt7cnJybW2+fv7w9/fX7rIiMyITqdDTEwMrK2tAQBr1qxBaGgohgwZ\ngpiYGGRkZGDAgAG8qpY6rKqqKkRFReHixYuQyWRYuXIlrKys+CWE2qV2V6GdyBji4+Mxc+ZMbN++\nHQCQn5+PwYMHAwC8vb2RlZUFCwsLXlVLHdaxY8cAPPhynpOTgw8++ABCCH4JoXaJyRVRK6Wnp8PR\n0REjRozQJ1dCCMhkMgAPrp4tKyuDWq2W9Kra1pykb8gT/E354gHGZjxjx47FqFGjAABXr16Fvb09\nTpw4wS8h1C4xuSJqpbS0NMhkMmRnZ+PcuXMICwvDzZs39feXl5fD3t4etra2kl1V29orNg11tacp\nX0nK2JoWhyEpFAqEhYXh8OHD2LRpE7KysiT5EtKcsj6mylSSa1OJoyHmECOTK6JW2rt3r/7voKAg\nrFixAuvWrUNOTg6GDBmCzMxMDB06FB4eHtiwYQM0Gg20Wi2vqqUOKT4+HkuWLIG/vz80Go1+e2u+\nhDS1rI8pM5Xk2hTiaIixY2xqYseFm4kMICwsDJs3b8aMGTOg0+ng4+MDJycn/VW1c+bM4VW11KEc\nPHgQ27ZtAwB06tQJMpkM/fv3R05ODgAgMzMTnp6eLO1D7QJnrogkpFKp9H/v2bOn1v28qpY6qnHj\nxiEiIgKzZs1CZWUlIiMj0bNnT0RHRyMhIQGurq7w8fGBXC5naR8ye0yuiIjI4Dp37oyNGzfW2s4v\nIdQe8WdBIiIiIgkxuSIiIiKSEJMrIiIiIgkxuSIiIiKSEJMrIiIiIgkxuSIiIiKSEJMrIiIiIgk1\nWOdKp9MhMjISV65cgVarRUhICHr16oXw8HDIZDK4ubkhNjYWFhYWSElJQXJyMhQKBUJCQjB69Oi2\nagMRERGRyWgwuTp06BAcHBywbt063L59G1OmTEGfPn0QGhqKIUOGICYmBhkZGRgwYABUKhXS0tKg\n0WgQGBgILy8vKJXKtmoHERGRZILXHjV2CGTGGkyuxo8fDx8fHwCAEAJyuRz5+fkYPHgwAMDb2xtZ\nWVmwsLDAwIEDoVQqoVQq4ezsjIKCAnh4eBi+BUREREQmpMHkysbGBgCgVquxcOFChIaGIj4+HjKZ\nTH9/WVkZ1Gp1jVXLbWxsoFarG33xLl06Q6GQNynQpq5E3VKG3n9bv46htZd2EBERSa3RtQVLSkqw\nYMECBAYGwtfXF+vWrdPfV15eDnt7e9ja2qK8vLzG9keTrfrcunWvSUE6OdmhtLSsSY9tKUPvH2ib\ndrQFc2wHk0EiImorDV4teP36dQQHB2Pp0qXw8/MDAPTr1w85OTkAgMzMTHh6esLDwwO5ubnQaDQo\nKytDYWEh3N3dDR89ERERkYlpcOYqKSkJd+/eRWJiIhITEwEAy5cvx6pVq5CQkABXV1f4+PhALpcj\nKCgIgYGBEEJg0aJFsLKyapMGEBEREZmSBpOrqKgoREVF1dq+Z8+eWtv8/f3h7+8vXWREREREZohF\nRImIiIgkxOSKiIiISEKNXi1IRA2rqqpCVFQULl68CJlMhpUrV8LKyoorGRARdVBMroha6dixYwCA\n5ORk5OTk4IMPPoAQgisZEBF1UEyuiFpp7NixGDVqFADg6tWrsLe3x4kTJ7iSARFRB8Xk6v+1dB2p\nXeFjJI6EzJFCoUBYWBgOHz6MTZs2ISsry+ArGbSmMKohi6qacsFWxkZEbYHJFZFE4uPjsWTJEvj7\n+0Oj0ei3G2Ilg9ZWyTdUhX1Trt7P2JoWBxG1HpMrolY6ePAgrl27hnnz5qFTp06QyWTo378/cnJy\nMGTIEGRmZmLo0KHw8PDAhg0boNFooNVqjbqSAWdqiYgMh8kVUSuNGzcOERERmDVrFiorKxEZGYme\nPXsiOjqaKxkQEXVATK6IWqlz587YuHFjre1cyYCIqGNiEVEiIiIiCXHmioiIDEqn0yEyMhJXrlyB\nVqtFSEgIevXqxUK71G4xuSIiIoM6dOgQHBwcsG7dOty+fRtTpkxBnz59WGiX2i0mV0REZFDjx4+H\nj48PAEAIAblcjvz8fBbapXarScnVd999h/Xr10OlUuH777/HvHnz8PTTTwMAAgICMHHiRE7lEhFR\nnWxsbAAAarUaCxcuRGhoKOLj4w1eaNecmEqNMVOJoyHmEGOjydWOHTtw6NAhdOrUCQCQn5+P1157\nDcHBwfrHlJaWdtipXNYLIiJqXElJCRYsWIDAwED4+vpi3bp1+vsMUWjX3JhKEVlTiKMhxo6xqYld\no1cLOjs7Y/PmzfrbeXl5OH78OGbNmoXIyEio1WqcOXNGP5VrZ2enn8olIiK6fv06goODsXTpUvj5\n+QEA+vXrh5ycHABAZmYmPD094eHhgdzcXGg0GpSVlRm10C5RazQ6c+Xj44Pi4mL9bQ8PD0yfPh39\n+/fH1q1bsWXLFvTp00fyqVzfxR83JX6zZQ7Tmg0x9/iJqO0kJSXh7t27SExMRGJiIgBg+fLlWLVq\nFQvtUrvU7BPaX3jhBdjb2+v/jouLg6enZ4edym0pU596bYixp2VbgskgkfFERUUhKiqq1nYW2qX2\nqtlFROfOnYszZ84AALKzs/HMM89wKpeIiIjo/zV75mrFihWIi4uDpaUlnnjiCcTFxcHW1pZTuURE\nRERoYnLVvXt3pKSkAACeeeYZJCcn13oMp3KJiIiIuLYgERERkaSYXBERERFJiMvfEBFRu9XSQs9E\nrcGZKyIiIiIJMbkiIiIikhCTKyIiIiIJ8ZwrolbS6XSIjIzElStXoNVqERISgl69eiE8PBwymQxu\nbm6IjY2FhYUFUlJSkJycDIVCgZCQEIwePdrY4RMRkcSYXBG10qFDh+Dg4IB169bh9u3bmDJlCvr0\n6YPQ0FAMGTIEMTExyMjIwIABA6BSqZCWlgaNRoPAwEB4eXlBqVQauwlERCQhJldErTR+/Hj4+PgA\nAIQQkMvlyM/Px+DBgwEA3t7eyMrKgoWFBQYOHAilUgmlUglnZ2cUFBTAw8PDmOETEZHEmFwRtZKN\njQ0AQK1WY+HChQgNDUV8fDxkMpn+/rKyMqjV6hoLmtvY2ECtVje6/y5dOkOhkNfabozFqJvymqa8\nSDZjI6K2wOSKSAIlJSVYsGABAgMD4evri3Xr1unvKy8vh729PWxtbVFeXl5j+6PJVn1u3bpXa5uT\nkx1KS8ukCb4ZGntNY8XVFIytaXEQUevxakGiVrp+/TqCg4OxdOlS+Pn5AQD69euHnJwcAEBmZiY8\nPT3h4eGB3NxcaDQalJWVobCwEO7u7sYMnYiIDIAzV0StlJSUhLt37yIxMRGJiYkAgOXLl2PVqlVI\nSEiAq6srfHx8IJfLERQUhMDAQAghsGjRIlhZWRk5eiIikhqTK6JWioqKQlRUVK3te/bsqbXN398f\n/v7+bREWEREZSZN+Fvzuu+8QFBQEACgqKkJAQAACAwMRGxuL6upqAEBKSgqmTZsGf39/HDt2zHAR\nExEREZmwRpOrHTt2ICoqChqNBgCwZs0ahIaGYt++fRBCICMjA6WlpVCpVEhOTsbOnTuRkJAArVZr\n8OCJiIiITE2jyZWzszM2b96sv/14/Z4TJ07gzJkz+vo9dnZ2+vo9RERERB1No+dc+fj4oLi4WH9b\nCGHw+j0dgblf8mzu8RMRERlKs09ot7D4z2SXIer3dBSmUNOmpUylJk9zMBkkIqK20uw6V6zfQ0RE\nRFS/Zs9chYWFITo6mvV7iIiIiOrQpOSqe/fuSElJAQC4uLiwfg8RERFRPVhE1EiC1x5t8XN3hY+R\nMBIiIiKSEtcWJCKiNsGC1NRRMLkiIiKDY0Fq6kiYXBERkcGxIDV1JEyuiIjI4Hx8fKBQ/Oc0XykL\nUhOZGp7QTkREbU7KgtTtYbUPUyl0bCpxNMQcYmRyRUREbe5hQeohQ4YgMzMTQ4cOhYeHBzZs2ACN\nRgOtVtvkgtTtYbUPU1j1whxW3zB2jE1N7JhcmaGWlnFgCQciMhUsSE3tGZMrIiJqEyxITR0Fkysi\nIiIzxYLUpolXCxJJhAUSiYgIYHJFJAkWSCQiooeYXBFJgAUSiYjoIZ5zRSQBHx8fFBcX629LWSCx\nvho+xqj10pTXNOUaNIyNiNpCi5OrqVOnwtbWFsCDK0Dmz5+P8PBwyGQyuLm5ITY2tkaROKKORMoC\niXXV8DFWrRffxR+36HmmcOKssevjNMRUYmOCRySNFmU/Go0GQgioVCqoVCqsWbOmznNMiDqqhwUS\nASAzMxOenp7w8PBAbm4uNBoNysrKmlwgkYiIzEuLkquCggJUVFQgODgYs2fPxunTp+s8x4SoowoL\nC8PmzZsxY8YM6HQ6+Pj4wMnJSV8gcc6cOSyQSETUTrXoZ0Fra2vMnTsX06dPx6VLl/DGG2/UeY5J\nY9rDelDmRMopf/58UBsLJBIREdDC5MrFxQU9evSATCaDi4sLHBwckJ+fr7//4TkmjWkP60GZE6nO\n6TCV80Oag8mgcXHJJiLqSFqUXKWmpuL8+fNYsWIFrl27BrVaDS8vr1qLcBIREVHjWlNpnUxPi5Ir\nPz8/REREICAgADKZDKtXr0aXLl1qLcJJpoWzB0RE1Fo8ljSuRcmVUqnE+++/X2t7XeeYEBEREXUk\nLERFREREJCEmV0REREQSYnJFREREJCEmV0REREQSYnJFREREJKEWL9xMHQcvuyUiImo6zlwRERER\nSYgzV2QwnPGi1mIfIiJzxJkrIiIiIgkxuSIiIiKSEJMrIiIiIgnxnCsiIqIOqKXnNFLjmFwRUbvD\nE+GJ2g9zHM+SJlfV1dVYsWIFfvjhByiVSqxatQo9evSQ8iWIzBrHiGkzxw/x9ojjhMydpMnVkSNH\noNVqceDAAZw+fRpr167F1q1bpXwJ6gDa8wGOY4SocRwnZO4kTa5yc3MxYsQIAMCAAQOQl5cn5e6J\nzB7HSPvU1ueumMMXidbgOCFzJ2lypVarYWtrq78tl8tRWVkJhYKndhEBHCMkjdYkc+aQmHGctE9t\n/SXEmL+CSNpTbW1tUV5err9dXV3d4GBwcrKr975P3p8sZWhEJqG5YwSof5w4OdlxnFC7xGMJmTtJ\n61w999xzyMzMBACcPn0a7u7uUu6eyOxxjBA1juOEzJ1MCCGk2tnDKzzOnz8PIQRWr16Nnj17SrV7\nIrPHMULUOI4TMneSJldEREREHR2XvyEiIiKSEJMrIiIiIgkxuSIiIiKSkEkVDdHpdIiMjMSVK1eg\n1WoREhKCXr16ITw8HDKZDG5uboiNjYWFhXnkhDdu3MC0adOwa9cuKBQKs23Htm3bcPToUeh0OgQE\nBGDw4MFm2xZzZuwlQaZOnaqvPdS9e3fMnz+/zn6QkpKC5ORkKBQKhISEYPTo0bh//z6WLl2KGzdu\nwMbGBvHx8XB0dGxVPN999x3Wr18PlUqFoqKiVsdy+vRpvPvuu5DL5Rg+fDj++Mc/ShLb999/j3nz\n5uHpp58GAAQEBGDixIlGi40My5yOY+ZwjDLb448wIampqWLVqlVCCCFu3bolRo4cKebNmydOnjwp\nhBAiOjpafPHFF8YMscm0Wq148803xbhx48SFCxfMth0nT54U8+bNE1VVVUKtVotNmzaZbVvM3eef\nfy7CwsKEEEKcOnVKzJ8/v81e+/79+2Ly5Mk1ttXVD3755RcxadIkodFoxN27d/V/79q1S2zatEkI\nIcSnn34q4uLiWhXP9u3bxaRJk8T06dMli+Wll14SRUVForq6Wrz++usiPz9fkthSUlLEzp07azzG\nWLGR4ZnLccwcjlHmfPwxqXRv/PjxePvttwEAQgjI5XLk5+dj8ODBAABvb2+cOHHCmCE2WXx8PGbO\nnImuXbsCgNm24+uvv4a7uzsWLFiA+fPnY9SoUWbbFnNnzCVBCgoKUFFRgeDgYMyePRunT5+usx+c\nOXMGAwcOhFKphJ2dHZydnVFQUFAjdm9vb2RnZ7cqHmdnZ2zevFl/u7WxqNVqaLVaODs7QyaTYfjw\n4S3u14/HlpeXh+PHj2PWrFmIjIyEWq02WmxkeOZyHDOHY5Q5H39MKrmysbGBra0t1Go1Fi5ciNDQ\nUAghIJPJ9PeXlZUZOcrGpaenw9HRUf8hCcAs2wEAt27dQl5eHjZu3IiVK1diyZIlZtsWc1ffkiBt\nwdraGnPnzsXOnTsb7AdqtRp2dv+plm1jYwO1Wl1juxR9xsfHp0bF7tbG8vh725oYH4/Nw8MDy5Yt\nw969e/HUU09hy5YtRouNDM8cjmPmcowy5+OPSSVXAFBSUoLZs2dj8uTJ8PX1rfFbanl5Oezt7Y0Y\nXdOkpaXhxIkTCAoKwrlz5xAWFoabN2/q7zeXdgCAg4MDhg8fDqVSCVdXV1hZWdXozObUFnPXkqVz\npOLi4oKXXnoJMpkMLi4ucHBwwI0bN/T3P+wHj8dYXl4OOzu7GtsN0Wfq+pxoTix1PVaqGF944QX0\n799f//f3339vMrGRYZj6ccxcjlHmfPwxqeTq+vXrCA4OxtKlS+Hn5wcA6NevH3JycgAAmZmZ8PT0\nNGaITbJ3717s2bMHKpUKffv2RXx8PLy9vc2uHQAwaNAgfPXVVxBC4Nq1a6ioqMCwYcPMsi3mzphL\ngqSmpmLt2rUAgGvXrkGtVsPLy6tWP/Dw8EBubi40Gg3KyspQWFgId3d3PPfcc/jyyy/1jx00aJCk\n8dX1OdGcWGxtbWFpaYmffvoJQgh8/fXXkvXruXPn4syZMwCA7OxsPPPMMyYTG0nPHI5j5nKMMufj\nj0lVaF+1ahU+++wzuLq66rctX74cq1atgk6ng6urK1atWgW5XG7EKJsnKCgIK1asgIWFBaKjo82y\nHe+99x5ycnIghMCiRYvQvXt3s22LOTPmkiBarRYRERG4evUqZDIZlixZgi5dutTZD1JSUnDgwAEI\nITBv3jz4+PigoqICYWFhKC0thaWlJd5//304OTm1Kqbi4mK88847SElJwcWLF1sdy+nTp7F69WpU\nVVVh+PDhWLRokSSx5efnIy4uDpaWlnjiiScQFxcHW1tbo8VGhmVuxzFTP0aZ6/HHpJIrIiIiInNn\nUj8LEhEREZk7JldEREREEmJyRURERCQhJldEREREEmJyRURERCQhJldEREREEmJyRURERCQhJld1\nGDNmDM6NIqYcAAAgAElEQVSePdui55aVlWH27NmNPi49PR3z5s0D8KCI2z//+c8WvV5zHD9+HBs3\nbmzVPpraPmo7xcXF6N27N/7nf/6nxvadO3ciPDxcstdpzbhoLrVajZkzZ+LFF1/E559/3ur9TZ48\nGXfv3q33/sf7dWOPN6abN2+id+/eAICMjAysWrUKgDTjm5qHY88wiouLMXDgQKO8tlTaZmGyDuTO\nnTttNgia6+zZs7hz506r9mHK7evILCwsEB8fD09PT7i4uBg7nFY7d+4cbty4gcOHD0uyv48//rjB\n+x/v14093lQ8//zzeP755wFIM76p+Tj2qC5Mrhrx7LPP4g9/+AOysrLwyy+/YPbs2Xj11VdRWlqK\nsLAw3Lp1CwAwcuRIhIaGIiIiAvfv38fkyZORnp6Ojz76CAcOHIBOp8OdO3fwxhtvIDAwsM7XKi4u\nxpw5czB06FCcPn0alZWVWLZsGQ4cOIAff/wR/fv3R0JCAiwsLPCvf/0L69evR0VFBWQyGd566y2M\nHj0a6enpOHz4MCwsLFBUVARLS0vEx8ejoqICycnJqKqqgp2dXa3lM/r374/nn38eBQUFWL9+PX74\n4Yc64368fZcuXcK7776L27dvo6qqCkFBQfr1tKjtWFtb47XXXsPixYuRnJwMpVJZ4/7w8HC4ublh\n7ty5tW6PGTMGkyZNwvHjx3H79m289dZb+Ne//oX8/HwoFAps3boV3bp1AwDs27cPBQUF0Gq1eO21\n1/T/66NHj2Lr1q3Q6XSwtrZGWFgYBg4ciM2bN+P06dP45Zdf0Lt3b6xfv75GXEeOHMGf//xnVFVV\nwdbWFhEREbC1tUVkZCSuXbuGyZMn48CBA7C2ttY/p6ysDO+++y7Onz8PnU6HYcOGYdmyZSgqKsKM\nGTOwZ88e9OnTB8uWLYNcLseaNWvQu3dvZGdno6qqqknjtl+/fsjOzsbx48frHE/u7u4oKipCZGQk\n7ty5AycnJwgh8NJLL2HatGk12lhaWorY2Fj8+OOPsLCwwMyZMzF79mwEBQXhV7/6FX788UcEBARg\nypQpdbZLoVDgiy++wAcffIBOnTrpF4EGHsyAf/7553jzzTdrjO9XXnmlznaS9DrS2AsKCkLPnj2R\nl5eHW7duYfLkyVi4cCEA1HtMAoAtW7bg73//O+RyOVxcXBAdHQ0nJ6cG9/eorVu34osvvkB1dTV+\n85vfIDY2Vv++mCxBtYwePVqcOXNGCCGEu7u7UKlUQgghzp49K/r37y/u378v/vznP4vo6GghhBDl\n5eUiNDRU3L17V1y+fFkMGDBACCGEWq0W/v7+4ubNm0IIIU6dOqW/Ly0tTfzhD38QQgjxyiuviM8+\n+0xcvnxZuLu7iyNHjgghhIiJiRGjR48WZWVl4v79+8LLy0vk5uaK27dvi3HjxonLly8LIYT4+eef\nhbe3t7hy5YpIS0sTgwYNEiUlJUIIIf70pz+JZcuWCSGE2LRpk1i5cmWdbXZ3dxcfffRRo3E/2j6d\nTicmTpwo8vLyhBBC3L17V0yYMEGcOnWqlf8Bao6H/5OqqioRGBgo1q5dK4QQ4sMPPxRhYWFCCCHC\nwsLEhx9+qH/Oo7dHjx4tVq9eLYQQ4u9//7vo06ePOHfunBBCiDfffFNs3bpV/7jY2FghxIM+N3To\nUHH+/Hlx8eJFMWnSJH1/OX/+vPDy8hLl5eVi06ZNwsfHR+h0ulpxX7hwQfz+978XP/30kxBCiBMn\nTggvLy9RVlYmTp48KV588cU62xseHi7+9re/CSGEqKysFEuWLBHbt28XQghx4MAB4evrK1JSUoSv\nr6+oqKgQQjzo3zdu3GjSuH308Q2NJ39/f7F37159W37729+KtLS0WvEuWLBAxMfHCyEejJEXX3xR\nXLp0SbzyyisiIiKi0XaVlpaKQYMGiX//+99CCCGSkpKEu7u7EKLm58ij47u+dpK0OtrYe+WVV8Qb\nb7whtFqtuHPnjvDx8RFHjx5t8JiUmpoqZsyYIcrLy4UQD/ppcHBwg/t7dDx+9NFHIjQ0VN+O5ORk\n8frrrzfvH2UEnLlqgofT7s888wy0Wi3u3buHESNG4A9/+ANKSkrw+9//HosXL4adnV2NaXkbGxsk\nJSXhyy+/xKVLl1BQUIB79+41+FqWlpYYM2YMAMDZ2RkDBw6Era0tAKBr1664c+cOTp8+jdLSUixY\nsED/PJlMhh9++EEf53/9138BeLAae1Ondx+uLt7UuC9duoSffvoJkZGR+m3379/H999/jwEDBjTp\nNUk6FhYWWLduHaZOnYrhw4c367njxo0DADz11FN44okn0KdPHwAP+uCjfXrmzJkAgG7dumH48OHI\nzs6GXC7HL7/8gldffVX/OJlMhp9++gkAMGDAACgUtT9qTp48iaFDh+Kpp54CAAwbNgyOjo7Iy8uD\nTCarN9bjx4/j7NmzSE1NBfCgzz3k7++Pr776CqtWrcLHH39c41s3gCaN28fVNZ7u3LmDM2fOYM+e\nPQCAnj17YujQoXU+/8SJE1i6dCkAwM7ODp9++qn+vodjrqF25ebmwt3dHb169QIAzJgxAwkJCfXG\n21A7yTA6ytgDHvQ/S0tLWFpaYvz48fj6669hYWFR7zEpMzMT06ZNQ+fOnQEAs2fPRlJSErRabb37\nc3Nz0+/n2LFjOHv2LF5++WUADxawr6ioaMI7a1xMrprAysoKAPSdTggBDw8PZGRkIDs7GydPnsT0\n6dOxZcsWdO3aVf+8n3/+GTNmzIC/vz8GDRqE8ePH49ixYw2+lqWlZY3ObWlpWesxVVVV6NmzZ42T\nKK9duwZHR0d88sknNQ4oMpkMoolrcz/s/E2Nu6qqCvb29jXOT7l+/To/xI3ov//7v7FixQqEhYVh\nypQp+u2P9wOdTlfjeY/+lFFXn3vIwuI/18AIIaBQKFBVVYVhw4Zhw4YN+vtKSkrQtWtXHD58WN+v\nHldXvxRCoLKyssEYqqursXHjRvTs2RMAcPfuXf2Y0Wq1+Omnn2BnZ4eCggI8/fTTNZ7blHH7uLrG\nk1wur9WGh9sep1Aoaozpy5cvo0uXLgBQ472pr13Z2dk1Xqeug+Xj6mvnc8891+hzqWU6wtgDavY/\nIQQsLCwaPCZ99NFHNZ5fXV2NysrKBvf3+ONff/11/ek0Wq3WLM4t5NWCLbR+/XokJiZi7NixWL58\nOXr16oVLly7pO7wQAnl5eXB0dMSbb76JESNG6BOUqqqqVr32gAEDUFRUhG+++QbAgxMQfXx88Msv\nvzT4PLlcXqNT16ehuB9tn4uLC6ysrPTJVUlJCSZNmoS8vLxWtY9aZ8KECfD29sbu3bv127p06aL/\nv9y8eRPffvtti/b98IPy6tWrOHHiBIYNG4ahQ4ciKysLhYWFAIAvv/wSL730EjQaTYP7evi8y5cv\nAwCys7NRUlKC3/72tw0+b/jw4fjrX/8KIQS0Wi1CQkL0M0jvvfce3NzcsHPnTsTFxeHKlSs1ntuU\ncdsUtra2eO6555Ceng7gQcKUnZ1d57f+YcOGIS0tDcCD88XmzJmDS5cuNbldnp6euHDhAgoKCgBA\n/5qPe3R819dOMqz2PvYA4NChQ6iursadO3fw2WefYcyYMQ0ek4YPH4709HT9rx8qlQq/+93v9Ell\nXft71PDhw5Gamgq1Wg0A2LhxI5YtW9bUt81oOHPVQnPmzEF4eDgmTZoEpVKJ3r17Y9KkSZDL5ejX\nrx8mTJiA3bt3o1u3bhg/fjw6deoEDw8PODo6oqioqFWv7ejoiE2bNuG9996DRqOBEALvvfcefvOb\n3zT4vGHDhuGtt96CpaUloqOj632cl5cXUlNT64y7R48e+vbt378fiYmJePfdd/Hhhx+isrISb7/9\nNgYNGtSq9lHrRUVFITc3V387KCgIS5YsgY+PD7p3747Bgwe3aL8ajQZTp06FTqdDVFSU/uqoP/3p\nT3jnnXf036i3bt1a77fmh3r16oXY2Fj88Y9/RFVVFaytrZGUlNTozOfy5cvx7rvvwtfXFzqdDr//\n/e/x+uuv49ixYzhy5AgOHToEe3t7zJkzB4sXL9YnXkDTxu3+/fub9F7Ex8dj+fLl2LdvH7p164bu\n3bvX+hkSAGJiYrBixQr4+vpCCIF58+bVOCm9sXZZWlpi/fr1WLJkCSwtLfG73/2uzngeHd/z58+v\ns51keO157AEPfq728/NDeXk5AgMDMWzYMACo95jk5+eHkpISTJ8+HdXV1ejRo0eNk+vr2l9xcbH+\n/unTp+PatWvw9/eHTCbDk08+ibVr17bkLWxTMtHUr2pERKS3detWjBs3Dj179kRZWRleeukl7Nix\nQ39uFFF7ExQUhFmzZmH8+PEmuT9TwpkrIqIWePrpp7Fo0SL9OSdvvPEGEysiAsCZKyIiIiJJNWnm\naurUqfpyAN27d9f/ni+TyeDm5obY2FhYWFggJSUFycnJUCgUCAkJ0RcQIyIiIuooGk2uHp6cplKp\n9Nvmz5+P0NBQDBkyBDExMcjIyMCAAQOgUqmQlpYGjUaDwMBAeHl51apWS0RERNSeNZpcFRQUoKKi\nAsHBwaisrMQ777yD/Px8/RUP3t7eyMrKgoWFBQYOHAilUgmlUglnZ2cUFBTAw8PD4I0gIiIiMhWN\nJlfW1taYO3cupk+fjkuXLuGNN96AEEJfz8XGxgZlZWVQq9U1LuO0sbHR16WoT2VlFRSKugvvEdED\npaVl9d7XpUtn3LrVcNV/U8XYjaOh2J2czLMAsLmMEVOKBTCteMwllqaOkUaTKxcXF/To0QMymQwu\nLi5wcHBAfn6+/v7y8nLY29vD1tYW5eXlNbY3VjOjoTfSycmuwQFjyhi7cTQUu7keNBpjzl9OGLtx\nmHPsLWFK7TWlWADTiqe9xdJohfbU1FR9wa5r165BrVbDy8sLOTk5AIDMzEx4enrCw8MDubm50Gg0\nKCsrQ2FhIdzd3VsdIBEREZE5aXTmys/PDxEREQgICIBMJsPq1avRpUsXREdHIyEhAa6urvDx8YFc\nLkdQUBACAwMhhMCiRYv0a/IRERERdRSNJldKpRLvv/9+re2PLinxkL+/P/z9/aWJjIiIiMgMceFm\nIiIiIglx+RsyOcFrj7boeZ+8P1niSEyf7+KPW/S8XeFjGn8QUTvAMULGwJkrIiIiIglx5opIAtu2\nbcPRo0eh0+kQEBCAwYMHc4koIqIOiskVUSvl5OTg1KlT2L9/PyoqKrBr1y6sWbOGS0QRPUKn0yE8\nPBxXrlyBhYUF4uLioFAo+CWE2iUmV0St9PXXX8Pd3R0LFiyAWq3GsmXLkJKSwiWiiB7x5ZdforKy\nEsnJycjKysKGDRug0+n4JYTaJSZXRK1069YtXL16FUlJSSguLkZISIhkS0QRtRcuLi6oqqpCdXU1\n1Go1FAoFTp8+zS8h1C4xuSJqJQcHB7i6ukKpVMLV1RVWVlb4+eef9fe3Zoko4ME6V1IvDWEqywGZ\nShwtwdibp3Pnzrhy5QomTJiAW7duISkpCd98840kX0LMaYyYWr8xpXjaUyxMrohaadCgQfjb3/6G\n1157Db/88gsqKiowbNgw5OTkYMiQIcjMzMTQoUPh4eGBDRs2QKPRQKvVNnmJKEMsZmoK60e213Us\nTZ2x1uD861//iuHDh2Px4sUoKSnBnDlzoNPp9Pcbap3aljLE/9fU+o0pxWMusUi2cDMRNWz06NH4\n5ptv4OfnByEEYmJi0L17dy4RRfQIe3t7WFpaAgB+9atfobKyEv369ZPsSwiRKWFyRSSBZcuW1drG\nJaKI/uPVV19FZGQkAgMDodPpsGjRIvTv359fQqhdYnJFREQGZ2Njg40bN9bazi8h1B6xQjsRERGR\nhJhcEREREUmIyRURERGRhJhcEREREUmoScnVjRs3MHLkSBQWFqKoqAgBAQEIDAxEbGwsqqurAQAp\nKSmYNm0a/P39cezYMYMGTURERGSqGk2udDodYmJiYG1tDQD6BWn37dsHIQQyMjJQWloKlUqF5ORk\n7Ny5EwkJCdBqtQYPnoiIiMjUNJpcxcfHY+bMmejatSsAID8/v8ZaUCdOnMCZM2f0a0HZ2dnp14Ii\nIiIi6mgarHOVnp4OR0dHjBgxAtu3bwcASRekbWw9KFNaZ6i5GLtxmHPsRETUPjSYXKWlpUEmkyE7\nOxvnzp1DWFgYbt68qb+/tQvSNrQelCmtM9RcjN14jLFmGhER0aMa/Flw79692LNnD1QqFfr27Yv4\n+Hh4e3sjJycHAJCZmQlPT094eHggNzcXGo0GZWVlXAuKiIiIOqxmL38TFhbGtaCIiIiI6tHk5Eql\nUun/5lpQRERERHVjEVEiIiIiCTG5IiIiIpIQkysiIiIiCTG5IiIiIpIQkysiIiIiCTG5IiIiIpIQ\nkysiIiIiCTW7iCgREVFLbNu2DUePHoVOp0NAQAAGDx6M8PBwyGQyuLm5ITY2FhYWFkhJSUFycjIU\nCgVCQkIwevRoY4dO1CycuSIiIoPLycnBqVOnsH//fqhUKvz8889Ys2YNQkNDsW/fPgghkJGRgdLS\nUqhUKiQnJ2Pnzp1ISEiAVqs1dvhEzcLkioiIDO7rr7+Gu7s7FixYgPnz52PUqFHIz8/H4MGDAQDe\n3t44ceIEzpw5g4EDB0KpVMLOzg7Ozs4oKCgwcvREzcOfBYmIyOBu3bqFq1evIikpCcXFxQgJCYEQ\nAjKZDABgY2ODsrIyqNVq2NnZ6Z9nY2MDtVrd4L67dOkMhUIuabxOTnaNP8iE9ttSphRPe4qFyRUR\nERmcg4MDXF1doVQq4erqCisrK/z888/6+8vLy2Fvbw9bW1uUl5fX2P5oslWXW7fuSR5vaWmZ5Pt0\ncrIzyH5bypTiMZdYmpp08WdBIiIyuEGDBuGrr76CEALXrl1DRUUFhg0bhpycHABAZmYmPD094eHh\ngdzcXGg0GpSVlaGwsBDu7u5Gjp6oeThzRUREBjd69Gh888038PPzgxACMTEx6N69O6Kjo5GQkABX\nV1f4+PhALpcjKCgIgYGBEEJg0aJFsLKyMnb4RM3C5IqIiNrEsmXLam3bs2dPrW3+/v7w9/dvi5CI\nDII/CxIRERFJqNGZq6qqKkRFReHixYuQyWRYuXIlrKysWPiN6DE3btzAtGnTsGvXLigUCo4RIqIO\nqtHk6tixYwCA5ORk5OTk4IMPPoAQAqGhoRgyZAhiYmKQkZGBAQMGQKVSIS0tDRqNBoGBgfDy8oJS\nqTR4I4iMTafTISYmBtbW1gCgL47IMUJE1PE0+rPg2LFjERcXBwC4evUq7O3tWfiN6DHx8fGYOXMm\nunbtCgAcI0REHViTTmhXKBQICwvD4cOHsWnTJmRlZbVJ4TdTKijWXIzdOIwRe3p6OhwdHTFixAhs\n374dACQrjgiYV4HE5jKVOFqCsRNRfZp8tWB8fDyWLFkCf39/aDQa/XZDFX4zpYJizcXYjae1hd9a\nIi0tDTKZDNnZ2Th37hzCwsJw8+ZN/f2tGSOA+RRIbC5z7mvtNXYmXUTSaPRnwYMHD2Lbtm0AgE6d\nOkEmk6F///4s/Eb0//bu3Ys9e/ZApVKhb9++iI+Ph7e3N8cIEVEH1ejM1bhx4xAREYFZs2ahsrIS\nkZGR6NmzJwu/ETUgLCyMY4SIqINqNLnq3LkzNm7cWGs7C78R1aZSqfR/c4wQEXVMLCJKREREJCEm\nV0REREQSYnJFREREJCEmV0REREQSYnJFREREJCEmV0REREQSYnJFREREJKEmL39DRNRSwWuPtuh5\nu8LHSBwJEZHhceaKiIiISEJMroiIiIgkxOSKiIjaxI0bNzBy5EgUFhaiqKgIAQEBCAwMRGxsLKqr\nqwEAKSkpmDZtGvz9/XHs2DEjR0zUMkyuiIjI4HQ6HWJiYmBtbQ0AWLNmDUJDQ7Fv3z4IIZCRkYHS\n0lKoVCokJydj586dSEhIgFarNXLkRM3HE9pbiSfqEhE1Lj4+HjNnzsT27dsBAPn5+Rg8eDAAwNvb\nG1lZWbCwsMDAgQOhVCqhVCrh7OyMgoICeHh4GDN0omZjckVERAaVnp4OR0dHjBgxQp9cCSEgk8kA\nADY2NigrK4NarYadnZ3+eTY2NlCr1Y3uv0uXzlAo5JLG7ORk1/iDTGi/LWVK8bSnWJhcERGRQaWl\npUEmkyE7Oxvnzp1DWFgYbt68qb+/vLwc9vb2sLW1RXl5eY3tjyZb9bl1657kMZeWlkm+TycnO4Ps\nt6VMKR5ziaWpSRfPuSIiIoPau3cv9uzZA5VKhb59+yI+Ph7e3t7IyckBAGRmZsLT0xMeHh7Izc2F\nRqNBWVkZCgsL4e7ubuToiZqvwZkrnU6HyMhIXLlyBVqtFiEhIejVqxfCw8Mhk8ng5uaG2NhYWFhY\nICUlBcnJyVAoFAgJCcHo0aPbqg1ERGRmwsLCEB0djYSEBLi6usLHxwdyuRxBQUEIDAyEEAKLFi2C\nlZWVsUMlarYGk6tDhw7BwcEB69atw+3btzFlyhT06dMHoaGhGDJkCGJiYpCRkYEBAwZApVIhLS0N\nGo0GgYGB8PLyglKpbKt2EBGRGVCpVPq/9+zZU+t+f39/+Pv7t2VIRJJrMLkaP348fHx8ADw4+VAu\nl/MKDyIiIqIGNJhc2djYAADUajUWLlyI0NBQxMfHt9kVHqZ05YDUTLltphxbY8w5diIiah8avVqw\npKQECxYsQGBgIHx9fbFu3Tr9fYa8wsOUrhwwBFNtm7m/7629woOIiKi1Grxa8Pr16wgODsbSpUvh\n5+cHAOjXrx+v8CAiIiKqR4MzV0lJSbh79y4SExORmJgIAFi+fDlWrVrFKzyIiIiI6tBgchUVFYWo\nqKha23mFBxEREVHdWESUiIiISEJMroiIiIgkxOSKiIiISEJMroiIiIgk1GidKyJqGNfgJCKiRzG5\nImolrsFJRESPYnLVgQSvPdqi5+0KHyNxJO0L1+AkIqJHMbkiaiVjr8HZEuayHJApx2nKsTXGnGMn\nMgdMrogkYKw1OFvKXNaPNNU4zXkNzoZiZ9JFJA1eLUjUSlyDk4iIHsWZK6JW4hqcRET0KJNNrnwX\nf9yi5/Hka2prXIOTiIgexZ8FiYiIiCRksjNXRETUPrDQLnU0TK6IiMigWGiXOhomV0REZFAstEsd\nTZPOufruu+8QFBQEACgqKkJAQAACAwMRGxuL6upqAEBKSgqmTZsGf39/HDt2zHARExGRWbGxsYGt\nrW2NQrtCCMkK7RKZmkZnrnbs2IFDhw6hU6dOAIA1a9ZwKpeIiJrFkIV2zWkVA1Mr1GpK8bSnWBpN\nrpydnbF582YsW7YMADiVS0REzfKw0G5MTAyGDRsG4D+FdocMGYLMzEwMHToUHh4e2LBhAzQaDbRa\nbZML7ZrLKgamVtnflOIxl1iamnQ1mlz5+PiguLhYf5tTuURE1BwstEsdTbNPaLew+M9pWh1pKldq\n5hInwFiJqHVYaJc6mmYnVx1xKtcQzCVOoH3EyqSLiIjaSrOTq7CwMERHR3Mql4iIiKgOTUquunfv\njpSUFACAi4sLp3KJiIjIpAWvPdqi533y/uRWvzbXFiQiIiKSEJMrIiIiIgkxuSIiIiKSEJMrIiIi\nIgkxuSIiIiKSEJMrIiIiIgkxuSIiIiKSEJMrIiIiIgkxuSIiIiKSEJMrIiIiIgkxuSIiIiKSEJMr\nIiIiIgkxuSIiIiKSEJMrIiIiIgkxuSIiIiKSkMLYARARmYrgtUdb9Lxd4WMkjoSIzBlnroiIiIgk\nJOnMVXV1NVasWIEffvgBSqUSq1atQo8ePaR8CSKzxjFC1DiOEzJ3ks5cHTlyBFqtFgcOHMDixYux\ndu1aKXdPZPY4Rogax3FC5k7Smavc3FyMGDECADBgwADk5eVJuXsis8cxQlJo6blhAPDJ+5MljMQw\nOE7I3EmaXKnVatja2upvy+VyVFZWQqGo+2WcnOzq3Zc5fAAA5hMnYD6xtibOhvqUKWjuGAE4TtpS\nR4mzvY0Tcxojpvbem1I8UsdizGOJpD8L2traory8XH+7urq6wYMGUUfDMULUOI4TMneSJlfPPfcc\nMjMzAQCnT5+Gu7u7lLsnMnscI0SN4zghcycTQgipdvbwCo/z589DCIHVq1ejZ8+eUu2eyOxxjBA1\njuOEzJ2kyRURERFRR8ciokREREQSYnJFREREJCGTTK6+++47BAUFGTuMZtPpdFi6dCkCAwPh5+eH\njIwMY4fUZFVVVYiIiMDMmTMREBCA8+fPGzukZrlx4wZGjhyJwsJCY4fSZsxxnHCMGFd7HCf1jYOj\nR4/i5ZdfxowZM5CSkgLgwblcMTExmDFjBoKCglBUVNRm8Xz66aeYPn06Zs6ciZiYGFRXVwMApk6d\niqCgIAQFBSEiIqJNYvnrX/+KF198Uf+6P/74o8Hfm7piKS0t1ccQFBQET09P7N+/H4Dh3pfGPoMk\n6zfCxGzfvl1MmjRJTJ8+3dihNFtqaqpYtWqVEEKIW7duiZEjRxo3oGY4fPiwCA8PF0IIcfLkSTF/\n/nwjR9R0Wq1WvPnmm2LcuHHiwoULxg6nTZjrOOEYMZ72OE7qGwdarVaMHTtW3L59W2g0GjFt2jRR\nWloqPv/8cxEWFiaEEOLUqVOS/w/ri6eiokI8//zz4t69e0IIIRYtWiSOHDki7t+/LyZPnixpDI3F\nIoQQixcvFmfPnq2xzZDvTVM+r/71r3+JoKAgUVlZadD3paHPICn7jcnNXDk7O2Pz5s3GDqNFxo8f\nj7fffhsAIISAXC43ckRNN3bsWMTFxQEArl69Cnt7eyNH1HTx8fGYOXMmunbtauxQ2oy5jhOOEeNp\nj+OkvnFQWFgIZ2dn/OpXv4JSqcSgQYPwzTffGLzye33xKJVKJCcno1OnTgCAyspKWFlZoaCgABUV\nFQgODsbs2bNx+vRpg8cCAPn5+di+fTsCAgKwbds2AIatit/Y55UQAnFxcVixYgXkcrlB35eGPoOk\n7PW69zUAAB1xSURBVDcml1z5+PiYbbE4Gxsb2NraQq1WY+HChQgNDTV2SM2iUCgQFhaGuLg4+Pr6\nGjucJklPT4ejo6O+43cU5jpOOEaMo72Ok/rGgVqthp3dfyps29jYQK1W11v53dDxWFhY4IknngAA\nqFQq3Lt3D15eXrC2tsbcuXOxc+dOrFy5EkuWLJEsnoY+I1588UWsWLECu3fvRm5uLo4dO2bQ96ax\nz6ujR4/Czc0Nrq6uAGDQ96WhzyAp+43JJVfmrqSkBLNnz8bkyZPN6sP3ofj4eHz++eeIjo7GvXv3\njB1Oo9LS0nDixAkEBQXh3LlzCAsLQ2lpqbHDogZwjLS9jjZOHq/wXl5eDjs7O6NWfq+urkZ8fDyy\nsrKwefNmyGQyuLi44KWXXtL/7eDgYPD/ixACc+bMgaOjI5RKJUaOHInvv//eqO/NoUOH4O/vr79t\n6Pelvs8gKfsNkysJXb9+HcHBwVi6dCn8/PyMHU6zHDx4UD893KlTJ8hkMlhYmH732Lt3L/bs2QOV\nSoW+ffsiPj4eTk5Oxg6L6sExYhwdbZz07NkTRUVFuH37NrRaLb799lsMHDjQqJXfY2JioNFokJiY\nqP95MDU1FWvXrgUAXLt2DWq12uD/F7VajUmTJqG8vBxCCOTk5KB///5GfW/y8vLw3HPP6W8b8n1p\n6DNIyn5jfr8rmLCkpCTcvXsXiYmJSExMBADs2LED1tbWRo6scePGjUNERARmzZqFyspKREZGmkXc\nZF44RsiQPvnkE9y7dw8zZsxAeHg45s6dCyEEXn75ZXTr1g0vvPACsrKyMHPmTH3l97aIp3///khN\nTYWnpyfmzJkDAJg9ezb8/PwQERGBgIAAyGQyrF692mCzRY++N4sWLcLs2bOhVCoxbNgwjBw5EtXV\n1W323vxfe/cfFHWd+HH8tcAsKospZU2XR98wSRqPMM2u8EdYiU2ZZYi4tjpDNRfZeXiJoPHDTs8g\njX7YkdnUXAMmR2Jl3dxYoZ2GHmPaT3/UHXfnVf7C3ywQv/b9/aO5vUwBf3yWXeD5mGmG/Sz73tfn\nw362l5/P7vvz4yxHjx6Vw+GQzWbz3u/L7XKm96ApU6aooaHB0tcNM7QDAABYqGsc0wYAAOgiKFcA\nAAAWolwBAABYiHIFAABgIcoVAACAhShXAAAAFqJcAQAAWKjHlatvv/1WMTExmjRpkve/u+++W2vW\nrPF3NKWmpuro0aM+Gfvxxx/Xli1bTlv+xRdfaNy4cT55TgAAeqIeOUN7r1699Pbbb3tvHzx4UHfd\ndZeGDh2qIUOG+C1XZWWlz8b+/e9/77OxAQDA//TIcvVTl112ma688kr9+9//1q5du7RmzRo1NDTI\n4XCouLhYb7zxhlavXi2Px6N+/fopJydHgwYN0scff6z8/Hx5PB5J0q9+9SslJiaqqalJy5Yt07Zt\n29Ta2qprr71W2dnZcjgcGjdunO69915t3bpV+/fv1x133KF58+Zp/vz5kqSZM2dq5cqVuvzyy735\nli9frk8//VSHDh3SNddco2XLlunFF1/Ue++9J4/HoyuuuEJ5eXm67LLL9N577+nFF1+UzWZTcHCw\n5s2bpxtuuEEul0vTp0/XhAkT9Prrr+u1116Tw+E47RpJbY3rcrkUFxenHTt2aP/+/Ro+fLgKCgoU\nFBSkjRs36tlnn5XH41GfPn30xBNPaMiQIdqxY4eWLVumhoYG2Ww2/frXv1ZCQkLn/WHRo2RnZysi\nIkK//e1vJf1wMdj169frD3/4g5+TAehxTA/zzTffmLi4uFOW7dixw9xwww1m3759pry83Nxwww2m\ntrbWGGNMVVWVcTqdpr6+3hhjzObNm80dd9xhjDFmxowZ5t133zXGGLN7926zcOFCY4wxy5cvN/n5\n+cbj8RhjjHn66adNXl6eMcaYhIQEk5+fb4wx5sCBA+YXv/iF+c9//mOMMSY6OtocOXLktMzPP/+8\nSUxMNM3NzcYYY958802Tnp7uvV1aWmoefPBBY4wxt956q/nkk0+8WZcvX26MMeb+++83f/nLX8yu\nXbvMTTfdZA4dOmSMMSYnJ8ckJCR0OO79999vZs+ebVpbW01tba0ZNWqU2bp1q6mpqTHDhw83u3bt\nMsYYs379evPAAw+Y48ePm/Hjx5tvvvnGu65jxowx33333Tn8tYCzt2vXLhMfH+99/TqdTrNp0yY/\npwLQE/XII1fff/+9Jk2aJElqbW1V//79tXTpUu/RomuuuUYOh0OS9OGHH2rv3r1KSUnxPv7EiRM6\nfvy47rjjDv3ud7/Thg0bdPPNN3v/xfzhhx+qtrbW+xmn5uZmXXzxxd7H33rrrZJ+OGJ28cUX68SJ\nE/r5z3/ebua4uDjvhSs3btyoL774Qvfdd58kyePxqKGhQZJ055136tFHH9XYsWMVHx+vhx566JRx\ntm7dqvj4eO8VxqdOnaqPPvqow3ElKSEhQUFBQXI4HLryyit14sQJ7dixQ4MHD1ZMTIykHy5uO378\neP31r39VTU2NZs2a5X28zWbTV199pZ/97GftritwPmJiYjRw4EB9+OGHuuqqq3To0CGNGjXK37EA\n9EA9slz99DNXP9WnTx/vzx6PR5MmTVJGRob39qFDh3TRRRcpJSVFCQkJqqys1ObNm/XCCy9o3bp1\n8ng8WrBggcaOHStJqqurU2Njo3fM0NBQ7882m03mLK6d/dNMDz74oJxOpySpqalJJ06ckCTNmTNH\nSUlJ+uijj7R27VqtXLlSa9eubfP5goODz2rc/263n44TEhJyytXMjTH66quv1NraqkGDBumNN97w\n3nfw4EFFRER0uK7A+Zo+fbrKy8v1f//3f0pOTj7ltQkAnaXHfVvwXMXHx+vPf/6zDh06JElavXq1\nZs6cKUlKSUnR7t27NXnyZC1atEgnT57UiRMnNGrUKK1atUpNTU3yeDzKyclRYWFhh88VHByslpaW\nDn9v1KhRWrNmjdxutyTpueee07x589TS0qJx48apvr5e06ZNU15enqqrq08Z8+abb1ZlZaUOHDgg\nSXrzzTc7HLc91113naqrq/X3v/9dklRRUaGMjAzFxcVp79692rZtmyRp9+7dSkxM9G5HwBcSExO1\ne/duvffee94jsADQ2XrkkatzMXr0aD300ENKTU2VzWaTw+HQCy+8IJvNprlz52rJkiV69tlnFRQU\npEcffVQDBw7UI488ooKCAt17771qbW1VTEyMsrKyOnyu22+/XU6nU0VFRad90PzHpkyZooMHD3r/\nZX755ZcrPz9fISEhWrBggebOnes9orRkyRLZ7XbvY6+55hplZGRo5syZCgsLU2xsbIfjtueSSy7R\nsmXLlJmZqdbWVjkcDj3zzDOKiIjQ888/r6eeekqNjY0yxuipp57SFVdccRZbHTg/drtdiYmJOnz4\nMEdJAfiNzZzNOSkA6ALq6+s1ffp0LVy4UNddd52/4wDooTgtCKBb2Lx5s2655Rb98pe/pFgB8CuO\nXAEAAFiII1cAAAAWolwBAABYiHIFAABgIb9OxVBTU9vmff3799GxY/WdmMY6ZPeP9rIPGBDeyWms\n01X2E7KcWSBlkbrvfgIEkoA9chUSEtzxLwUosvtHV85+vgJpnclyZoGURQq8PEB3FLDlCgAAoCui\nXAEAAFiIcgUAAGAhyhUAAICFzurbgkeOHNHkyZP16quvKiQkRFlZWbLZbBo8eLDy8vIUFBSksrIy\nlZaWKiQkRGlpaUpISPB1dnRTqfkbzutx7zw9yeIkgW/iY2+f1+NezRpncRIAwH91eOSqublZubm5\n6tWrlyTpySefVHp6ul5//XUZY1RRUaGamhoVFxertLRUr7zyigoLC9XU1OTz8AAAAIGmw3JVUFCg\nlJQUXXrppZKknTt3auTIkZKkMWPGaMuWLfr88881bNgw2e12hYeHKzIyUnv27PFtcgAAgADU7mnB\ntWvXKiIiQqNHj9bKlSslScYY2Ww2SVJYWJhqa2vldrsVHv6/yefCwsLkdrs7fPL+/fu0O+dKV57Q\njuz+0ZWzAwC6h3bLVXl5uWw2m7Zu3ardu3crMzNTR48e9d5fV1envn37yuFwqK6u7pTlPy5bbWlv\n1uIBA8LbnZk6kJHdf9rKTukCAHSWdk8Lrlq1SiUlJSouLlZMTIwKCgo0ZswYVVVVSZI2bdqkESNG\nKDY2Vtu3b1djY6Nqa2tVXV2t6OjoTlkBAACAQHLO1xbMzMxUTk6OCgsLFRUVpcTERAUHB8vlcsnp\ndMoYozlz5ig0NNQXeQEAAALaWZer4uJi788lJSWn3Z+cnKzk5GRrUgEAAHRRTCIKAABgIcoVAACA\nhShXAAAAFqJcAQAAWIhyBQAAYKFznooBwOleeuklbdiwQc3NzZo2bZpGjhzJBc4BoIfiyBVwgaqq\nqvTJJ59o9erVKi4u1oEDB7jAOQD0YJQr4AJ99NFHio6O1qxZs/Twww/rlltu4QLnANCDcVoQuEDH\njh3Tvn37tGLFCn377bdKS0vr1Aucnw9fXWsxkK7hSJa2BVoeoLuhXAEXqF+/foqKipLdbldUVJRC\nQ0N14MAB7/2+vMD5+fLFxbkD6aLfZGlbe3koXYA1OC0IXKDhw4dr8+bNMsbo4MGDamho0E033cQF\nzgGgh+LIFXCBEhIStG3bNiUlJckYo9zcXA0cOJALnANAD0W5Aiwwb96805ZxgXMA6Jk4LQgAAGAh\nyhUAAICFKFcAAAAWolwBAABYiHIFAABgIcoVAACAhShXAAAAFupwnqvW1lZlZ2frX//6l2w2m554\n4gmFhoYqKytLNptNgwcPVl5enoKCglRWVqbS0lKFhIQoLS1NCQkJnbEOAAAAAaPDcrVx40ZJUmlp\nqaqqqvTMM8/IGKP09HTdeOONys3NVUVFheLi4lRcXKzy8nI1NjbK6XQqPj5edrvd5yvhT6n5G87r\nca9mjbM4CQAACAQdlqvbbrtNt9xyiyRp37596tu3r7Zs2aKRI0dKksaMGaPKykoFBQVp2LBhstvt\nstvtioyM1J49exQbG+vTFQAAAAgkZ3X5m5CQEGVmZur999/X888/r8rKStlsNklSWFiYamtr5Xa7\nFR7+vyuqh4WFye12tztu//59FBIS3Ob93fkK7YG8boGcrSNdOTsAoHs462sLFhQUaO7cuUpOTlZj\nY6N3eV1dnfr27SuHw6G6urpTlv+4bJ3JsWP1bd43YEC4ampqzzZelxOo69bVt3tb2SldAIDO0uG3\nBd966y299NJLkqTevXvLZrNp6NChqqqqkiRt2rRJI0aMUGxsrLZv367GxkbV1taqurpa0dHRvk0P\nAAAQYDo8cjV+/HjNnz9f06dPV0tLixYsWKBBgwYpJydHhYWFioqKUmJiooKDg+VyueR0OmWM0Zw5\ncxQaGtoZ6wAAABAwOixXffr00XPPPXfa8pKSktOWJScnKzk52ZpkAAAAXRCTiAIAAFiIcgUAAGAh\nyhUAAICFKFcAAAAWolwBAABYiHIFAABgIcoVAACAhShXAAAAFqJcAQAAWIhyBQAAYCHKFWCRI0eO\naOzYsaqurtbevXs1bdo0OZ1O5eXlyePxSJLKyso0efJkJScna+PGjX5ODADwBcoVYIHm5mbl5uaq\nV69ekqQnn3xS6enpev3112WMUUVFhWpqalRcXKzS0lK98sorKiwsVFNTk5+TAwCsRrkCLFBQUKCU\nlBRdeumlkqSdO3dq5MiRkqQxY8Zoy5Yt+vzzzzVs2DDZ7XaFh4crMjJSe/bs8WdsAIAPhPg7ANDV\nrV27VhERERo9erRWrlwpSTLGyGazSZLCwsJUW1srt9ut8PBw7+PCwsLkdrs7HL9//z4KCQm2NPOA\nAeEd/1IAjXs+yNK2QMsDdDeUK+AClZeXy2azaevWrdq9e7cyMzN19OhR7/11dXXq27evHA6H6urq\nTln+47LVlmPH6i3PXFNTa/mYAwaE+2Tc80GWtrWXh9IFWIPTgsAFWrVqlUpKSlRcXKyYmBgVFBRo\nzJgxqqqqkiRt2rRJI0aMUGxsrLZv367GxkbV1taqurpa0dHRfk4PALAaR64AH8jMzFROTo4KCwsV\nFRWlxMREBQcHy+Vyyel0yhijOXPmKDQ01N9RAQAWo1wBFiouLvb+XFJSctr9ycnJSk5O7sxIAIBO\nxmlBAAAAC1GuAAAALNTuacHm5mYtWLBA3333nZqampSWlqarr75aWVlZstlsGjx4sPLy8hQUFKSy\nsjKVlpYqJCREaWlpSkhI6Kx1AAAACBjtlqt169apX79+Wrp0qY4fP6577rlHQ4YMUXp6um688Ubl\n5uaqoqJCcXFxKi4uVnl5uRobG+V0OhUfHy+73d5Z6wEAABAQ2i1XEyZMUGJioqQfJkUMDg4+bebp\nyspKBQUFeWeettvt3pmnY2Njfb8GAAAAAaTdchUWFiZJcrvdmj17ttLT01VQUNBpM0935wntAnnd\nAjlbR7pydgBA99DhVAz79+/XrFmz5HQ6NXHiRC1dutR7ny9nng60WY2tFqjr1tW3OzNPAwD8rd1v\nCx4+fFipqanKyMhQUlKSJOnaa69l5mkAAIA2tHvkasWKFTp58qSKiopUVFQkSXr88ce1ePFiZp4G\nAAA4g3bLVXZ2trKzs09bzszTAAAAZ8YkogAAABbi2oIA0MWk5m8478e+8/QkC5MAOBOOXAEAAFiI\ncgUAAGAhyhUAAICFKFcAAAAWolwBAABYiHIFAABgIcoVAACAhZjnqgc537lxXs0aZ3ESAAC6L45c\nAQAAWIhyBQAAYCHKFQAAgIUoVwAAABaiXAEAAFgoYL8tOPGxt8/rcXyzDZ2tublZCxYs0Hfffaem\npialpaXp6quvVlZWlmw2mwYPHqy8vDwFBQWprKxMpaWlCgkJUVpamhISEvwdHwBgsYAtV0BXsW7d\nOvXr109Lly7V8ePHdc8992jIkCFKT0/XjTfeqNzcXFVUVCguLk7FxcUqLy9XY2OjnE6n4uPjZbfb\n/b0KAAALUa6ACzRhwgQlJiZKkowxCg4O1s6dOzVy5EhJ0pgxY1RZWamgoCANGzZMdrtddrtdkZGR\n2rNnj2JjY/0ZHwBgMcoVcIHCwsIkSW63W7Nnz1Z6eroKCgpks9m899fW1srtdis8PPyUx7nd7g7H\n79+/j0JCgi3NPGBAeMe/FEDjng+ytC3Q8gDdDeUKsMD+/fs1a9YsOZ1OTZw4UUuXLvXeV1dXp759\n+8rhcKiuru6U5T8uW205dqze8rw1NbWWjzlgQLhPxj0fZGlfW3koXYA1zurbgp999plcLpckae/e\nvZo2bZqcTqfy8vLk8XgkSWVlZZo8ebKSk5O1ceNG3yUGAszhw4eVmpqqjIwMJSUlSZKuvfZaVVVV\nSZI2bdqkESNGKDY2Vtu3b1djY6Nqa2tVXV2t6Ohof0YHAPhAh0euXn75Za1bt069e/eWJD355JN8\nUBf4kRUrVujkyZMqKipSUVGRJOnxxx/X4sWLVVhYqKioKCUmJio4OFgul0tOp1PGGM2ZM0ehoaF+\nTg8AsFqH5SoyMlLLly/XvHnzJIkP6gI/kZ2drezs7NOWl5SUnLYsOTlZycnJnRELAOAnHZarxMRE\nffvtt97bxpge+UFdq3WVnBJZAQA4F+f8gfagoP99TKunfFDXF7pKTql7ZKV0AQA6yzlf/oYP6gIA\nALTtnI9cZWZmKicnhw/qAgAAnMFZlauBAweqrKxMknTVVVfxQV0AAIA2nPNpQQAAALSNcgUAAGAh\nyhUAAICFKFcAAAAWolwBAABYiHIFAABgIcoVAACAhShXAAAAFqJcAQAAWIhyBQAAYCHKFQAAgIUo\nVwAAABaiXAEAAFiIcgUAAGAhyhUAAICFKFcAAAAWolwBAABYiHIFAABgIcoVAACAhShXAAAAFgqx\ncjCPx6OFCxfqq6++kt1u1+LFi3XllVda+RRAl8Y+AgDdn6VHrj744AM1NTXpT3/6kx577DHl5+db\nOTzQ5bGPAED3Z2m52r59u0aPHi1JiouL05dffmnl8ECXxz4CAN2fpacF3W63HA6H93ZwcLBaWloU\nEnLmpxkwILzNsd55epKV0Xymq+SUuk7WC8nZ3msqEJzrPiJ1rf0kkLZ/d85yoX/3QNo2QHdk6ZEr\nh8Ohuro6722Px9Pu/zSAnoZ9BAC6P0vL1fXXX69NmzZJkj799FNFR0dbOTzQ5bGPAED3ZzPGGKsG\n++83ob7++msZY7RkyRINGjTIquGBLo99BAC6P0vLFQAAQE/HJKIAAAAWolwBAABYKCDL1WeffSaX\ny+XvGOesublZGRkZcjqdSkpKUkVFhb8jnbXW1lbNnz9fKSkpmjZtmr7++mt/RzonR44c0dixY1Vd\nXe3vKJZqa1/YsGGD7rvvPk2dOlVlZWWSfvg8V25urqZOnSqXy6W9e/d2SpZ3331XU6ZMUUpKinJz\nc+XxeCRJ9957r1wul1wul+bPn98pWf74xz/qzjvv9D7vP//5T59vl7by1NTUeHO4XC6NGDFCq1ev\nluSbbdPR+48/XjNAj2UCzMqVK81dd91lpkyZ4u8o52zNmjVm8eLFxhhjjh07ZsaOHevfQOfg/fff\nN1lZWcYYY/72t7+Zhx9+2M+Jzl5TU5N55JFHzPjx480//vEPf8exTFv7QlNTk7ntttvM8ePHTWNj\no5k8ebKpqakx69evN5mZmcYYYz755BNL/4ZtZWloaDC33nqrqa+vN8YYM2fOHPPBBx+Y77//3kya\nNMmy5z+bLMYY89hjj5kvvvjilGW+3C4d5fmvHTt2GJfLZVpaWny2bdp7//HHawboyQLuyFVkZKSW\nL1/u7xjnZcKECfrNb34jSTLGKDg42M+Jzt5tt92mRYsWSZL27dunvn37+jnR2SsoKFBKSoouvfRS\nf0exVFv7QnV1tSIjI3XRRRfJbrdr+PDh2rZtm09nf28ri91uV2lpqXr37i1JamlpUWhoqPbs2aOG\nhgalpqZqxowZ+vTTT32eRZJ27typlStXatq0aXrppZck+X5W/I7es4wxWrRokRYuXKjg4GCfbZv2\n3n/88ZoBerKAK1eJiYlddlLFsLAwORwOud1uzZ49W+np6f6OdE5CQkKUmZmpRYsWaeLEif6Oc1bW\nrl2riIgI7/8gupO29gW3263w8P/NsB0WFia3293m7O++zBIUFKRLLrlEklRcXKz6+nrFx8erV69e\neuCBB/TKK6/oiSee0Ny5c32eRZLuvPNOLVy4UK+99pq2b9+ujRs3+nS7dJRH+uF03ODBgxUVFSVJ\nPts27b3/+OM1A/RkAVeuurr9+/drxowZmjRpUpcpKD9WUFCg9evXKycnR/X19f6O06Hy8nJt2bJF\nLpdLu3fvVmZmpmpqavwdy6d+Ost7XV2dwsPD/Tb7u8fjUUFBgSorK7V8+XLZbDZdddVVuvvuu70/\n9+vXz+d/F2OMZs6cqYiICNntdo0dO1a7du3y+6z469atU3Jysve2L7dNW+8/gfaaAbo7ypWFDh8+\nrNTUVGVkZCgpKcnfcc7JW2+95T2N0rt3b9lsNgUFBf7LY9WqVSopKVFxcbFiYmJUUFCgAQMG+DuW\nTw0aNEh79+7V8ePH1dTUpI8//ljDhg3z2+zvubm5amxsVFFRkff04Jo1a5Sfny9JOnjwoNxut8//\nLm63W3fddZfq6upkjFFVVZWGDh3q91nxv/zyS11//fXe277aNu29/wTaawbo7vgnioVWrFihkydP\nqqioSEVFRZKkl19+Wb169fJzso6NHz9e8+fP1/Tp09XS0qIFCxZ0idw9yTvvvKP6+npNnTpVWVlZ\neuCBB2SM0X333afLLrtMt99+uyorK5WSkuKd/d3XWYYOHao1a9ZoxIgRmjlzpiRpxowZSkpK0vz5\n8zVt2jTZbDYtWbLEZ0dEfrxd5syZoxkzZshut+umm27S2LFj5fF4Om27/DTP0aNH5XA4ZLPZvPf7\natuc6f1nypQpamhoCIjXDNCTMEM7AACAhQL/vA8AAEAXQrkCAACwEOUKAADAQpQrAAAAC1GuAAAA\nLES5AgAAsBDlCgAAwEKUKwAAAAv9P07oi50LKqXEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e70c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist(figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status of account             0\n",
       "Duration                      0\n",
       "Credit history                0\n",
       "Purpose                       0\n",
       "Credit amount                 0\n",
       "Savings account               0\n",
       "Present employment            0\n",
       "Installment rate              0\n",
       "Personal status and sex       0\n",
       "Other debtors                 0\n",
       "Present residence             0\n",
       "Property                      0\n",
       "Age                           0\n",
       "Other installment plans       0\n",
       "Housing                       0\n",
       "Number of existing credits    0\n",
       "Job                           0\n",
       "Number of people              0\n",
       "Telephone                     0\n",
       "Foreign worker                0\n",
       "y                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_features=['Duration','Credit amount','Installment rate',\n",
    "                    'Present residence','Age','Number of existing credits',\n",
    "                    'Number of people']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train['Status of account'] = le.fit_transform(train['Status of account'].values)\n",
    "train['Credit history'] = le.fit_transform(train['Credit history'].values)\n",
    "train['Purpose'] = le.fit_transform(train['Credit history'].values)\n",
    "train['Savings account'] = le.fit_transform(train['Savings account'].values)\n",
    "train['Present employment'] = le.fit_transform(train['Present employment'].values)\n",
    "train['Property'] = le.fit_transform(train['Property'].values)\n",
    "train['Other debtors'] = le.fit_transform(train['Other debtors'].values)\n",
    "train['Other installment plans'] = le.fit_transform(train['Other installment plans'].values)\n",
    "train['Housing'] = le.fit_transform(train['Housing'].values)\n",
    "train['Telephone'] = le.fit_transform(train['Telephone'].values)\n",
    "\n",
    "Foreign_worker_mapping = {\n",
    "           'A201': 1,\n",
    "           'A202': 0,\n",
    "           }\n",
    "\n",
    "train['Foreign worker'] = train['Foreign worker'].apply(lambda x: Foreign_worker_mapping[x])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "form_mapping = {\n",
    "           'A171': [0,0,0],\n",
    "           'A172': [1,0,0],\n",
    "           'A173': [1,1,0],\n",
    "            'A174':[1,1,1]\n",
    "}\n",
    "train['Job'] = train['Job'].apply(lambda x: form_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Job= pd.DataFrame(train.Job.tolist(),columns=['Job_1','Job_2','Job_3'] )\n",
    "train = train.drop('Job',axis=1)\n",
    "train=pd.concat([train,Job ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_mapping = {\n",
    "           'A91':'male',\n",
    "           'A93': 'male',\n",
    "           'A94': 'female',\n",
    "            'A92':'female',\n",
    "            'A95':'female'\n",
    "}\n",
    "train['Sex'] = train['Personal status and sex'].apply(lambda x: sex_mapping[x])\n",
    "\n",
    "\n",
    "Personal_status_mapping = {\n",
    "           'A91':'divorced/separated/married',\n",
    "           'A92': 'divorced/separated/married',\n",
    "           'A93': 'single',\n",
    "            'A94':'divorced/separated/married',\n",
    "            'A95':'single'\n",
    "}\n",
    "train['Personal status'] = train['Personal status and sex'].apply(lambda x: Personal_status_mapping[x])\n",
    "\n",
    "\n",
    "train=train.drop('Personal status and sex',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status of account</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Savings account</th>\n",
       "      <th>Present employment</th>\n",
       "      <th>Installment rate</th>\n",
       "      <th>Other debtors</th>\n",
       "      <th>Present residence</th>\n",
       "      <th>...</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign worker</th>\n",
       "      <th>y</th>\n",
       "      <th>Job_1</th>\n",
       "      <th>Job_2</th>\n",
       "      <th>Job_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_divorced/separated/married</th>\n",
       "      <th>Embarked_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5951</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2096</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4870</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status of account  Duration  Credit history  Purpose  Credit amount  \\\n",
       "0                  0         6               4        4           1169   \n",
       "1                  1        48               2        2           5951   \n",
       "2                  3        12               4        4           2096   \n",
       "3                  0        42               2        2           7882   \n",
       "4                  0        24               3        3           4870   \n",
       "\n",
       "   Savings account  Present employment  Installment rate  Other debtors  \\\n",
       "0                4                   4                 4              0   \n",
       "1                0                   2                 2              0   \n",
       "2                0                   3                 2              0   \n",
       "3                0                   3                 2              2   \n",
       "4                0                   2                 3              0   \n",
       "\n",
       "   Present residence       ...         Telephone  Foreign worker  y  Job_1  \\\n",
       "0                  4       ...                 1               1  1      1   \n",
       "1                  2       ...                 0               1  2      1   \n",
       "2                  3       ...                 0               1  1      1   \n",
       "3                  4       ...                 0               1  1      1   \n",
       "4                  4       ...                 0               1  2      1   \n",
       "\n",
       "   Job_2  Job_3  Sex_female  Sex_male  Embarked_divorced/separated/married  \\\n",
       "0      1      0           0         1                                    0   \n",
       "1      1      0           1         0                                    1   \n",
       "2      0      0           0         1                                    0   \n",
       "3      1      0           0         1                                    0   \n",
       "4      1      0           0         1                                    0   \n",
       "\n",
       "   Embarked_single  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_Sex=pd.get_dummies(train['Sex'],prefix='Sex')\n",
    "dummies_status = pd.get_dummies(train['Personal status'], prefix= 'Embarked') \n",
    "train = pd.concat([train, dummies_Sex, dummies_status], axis=1)\n",
    "train = train.drop(['Sex','Personal status'], axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in numerical_features: \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train[i] = scaler.fit_transform(train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status of account</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Savings account</th>\n",
       "      <th>Present employment</th>\n",
       "      <th>Installment rate</th>\n",
       "      <th>Other debtors</th>\n",
       "      <th>Present residence</th>\n",
       "      <th>...</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign worker</th>\n",
       "      <th>y</th>\n",
       "      <th>Job_1</th>\n",
       "      <th>Job_2</th>\n",
       "      <th>Job_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_divorced/separated/married</th>\n",
       "      <th>Embarked_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.236478</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.745131</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.248194</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949817</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.765977</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.738668</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.416562</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140505</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.750384</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.634247</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>2</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.566664</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status of account  Duration  Credit history  Purpose  Credit amount  \\\n",
       "0                  0 -1.236478               4        4      -0.745131   \n",
       "1                  1  2.248194               2        2       0.949817   \n",
       "2                  3 -0.738668               4        4      -0.416562   \n",
       "3                  0  1.750384               2        2       1.634247   \n",
       "4                  0  0.256953               3        3       0.566664   \n",
       "\n",
       "   Savings account  Present employment  Installment rate  Other debtors  \\\n",
       "0                4                   4          0.918477              0   \n",
       "1                0                   2         -0.870183              0   \n",
       "2                0                   3         -0.870183              0   \n",
       "3                0                   3         -0.870183              2   \n",
       "4                0                   2          0.024147              0   \n",
       "\n",
       "   Present residence       ...         Telephone  Foreign worker  y  Job_1  \\\n",
       "0           1.046987       ...                 1               1  1      1   \n",
       "1          -0.765977       ...                 0               1  2      1   \n",
       "2           0.140505       ...                 0               1  1      1   \n",
       "3           1.046987       ...                 0               1  1      1   \n",
       "4           1.046987       ...                 0               1  2      1   \n",
       "\n",
       "   Job_2  Job_3  Sex_female  Sex_male  Embarked_divorced/separated/married  \\\n",
       "0      1      0           0         1                                    0   \n",
       "1      1      0           1         0                                    1   \n",
       "2      0      0           0         1                                    0   \n",
       "3      1      0           0         1                                    0   \n",
       "4      1      0           0         1                                    0   \n",
       "\n",
       "   Embarked_single  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status of account</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Savings account</th>\n",
       "      <th>Present employment</th>\n",
       "      <th>Installment rate</th>\n",
       "      <th>Other debtors</th>\n",
       "      <th>Present residence</th>\n",
       "      <th>...</th>\n",
       "      <th>Number of people</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign worker</th>\n",
       "      <th>Job_1</th>\n",
       "      <th>Job_2</th>\n",
       "      <th>Job_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_divorced/separated/married</th>\n",
       "      <th>Embarked_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.236478</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.745131</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.248194</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949817</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.765977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.738668</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.416562</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140505</td>\n",
       "      <td>...</td>\n",
       "      <td>2.334869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.750384</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.634247</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>2</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>2.334869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.566664</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>2.334869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status of account  Duration  Credit history  Purpose  Credit amount  \\\n",
       "0                  0 -1.236478               4        4      -0.745131   \n",
       "1                  1  2.248194               2        2       0.949817   \n",
       "2                  3 -0.738668               4        4      -0.416562   \n",
       "3                  0  1.750384               2        2       1.634247   \n",
       "4                  0  0.256953               3        3       0.566664   \n",
       "\n",
       "   Savings account  Present employment  Installment rate  Other debtors  \\\n",
       "0                4                   4          0.918477              0   \n",
       "1                0                   2         -0.870183              0   \n",
       "2                0                   3         -0.870183              0   \n",
       "3                0                   3         -0.870183              2   \n",
       "4                0                   2          0.024147              0   \n",
       "\n",
       "   Present residence       ...         Number of people  Telephone  \\\n",
       "0           1.046987       ...                -0.428290          1   \n",
       "1          -0.765977       ...                -0.428290          0   \n",
       "2           0.140505       ...                 2.334869          0   \n",
       "3           1.046987       ...                 2.334869          0   \n",
       "4           1.046987       ...                 2.334869          0   \n",
       "\n",
       "   Foreign worker  Job_1  Job_2  Job_3  Sex_female  Sex_male  \\\n",
       "0               1      1      1      0           0         1   \n",
       "1               1      1      1      0           1         0   \n",
       "2               1      1      0      0           0         1   \n",
       "3               1      1      1      0           0         1   \n",
       "4               1      1      1      0           0         1   \n",
       "\n",
       "   Embarked_divorced/separated/married  Embarked_single  \n",
       "0                                    0                1  \n",
       "1                                    1                0  \n",
       "2                                    0                1  \n",
       "3                                    0                1  \n",
       "4                                    0                1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=train.drop(\"y\",axis=1)\n",
    "outcomes=train[\"y\"].values\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, outcomes, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranom Forest         70.67 (+/-) 3.77 \n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=5)\n",
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "cv_result = cross_val_score(model,X_train,Y_train, cv = kfold,scoring = \"accuracy\")\n",
    "results=[\"Ranom Forest\",cv_result.mean(),cv_result.std()]\n",
    "\n",
    "print('{:20s} {:2.2f} (+/-) {:2.2f} '.format(results[0] , results[1] * 100, results[2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166   4]\n",
      " [ 59  21]]\n",
      "74.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.98      0.84       170\n",
      "          2       0.84      0.26      0.40        80\n",
      "\n",
      "avg / total       0.77      0.75      0.70       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100,max_features='auto',bootstrap=True,oob_score=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151  19]\n",
      " [ 39  41]]\n",
      "76.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.89      0.84       170\n",
      "          2       0.68      0.51      0.59        80\n",
      "\n",
      "avg / total       0.76      0.77      0.76       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100,max_features=None,bootstrap=True,oob_score=True,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  29]\n",
      " [ 40  40]]\n",
      "72.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.83      0.80       170\n",
      "          2       0.58      0.50      0.54        80\n",
      "\n",
      "avg / total       0.72      0.72      0.72       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=1,max_features=None,bootstrap=False,max_depth=5)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest by xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[158  12]\n",
      " [ 43  37]]\n",
      "78.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.93      0.85       170\n",
      "          2       0.76      0.46      0.57        80\n",
      "\n",
      "avg / total       0.78      0.78      0.76       250\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b635b9ba9a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mfalse_positive_rate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mroc_auc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_rate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[1;32m    504\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 505\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    312\u001b[0m              \u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m              array_equal(classes, [1]))):\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=3,subsample=0.632,colsample_bytree=0.3)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate1, true_positive_rate1, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc1 = auc(false_positive_rate1, true_positive_rate1)\n",
    "print(roc_auc1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree by xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149  21]\n",
      " [ 43  37]]\n",
      "74.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.88      0.82       170\n",
      "          2       0.64      0.46      0.54        80\n",
      "\n",
      "avg / total       0.73      0.74      0.73       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=1,num_boost_round=1,max_depth=3,subsample=1,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagged decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[152  18]\n",
      " [ 40  40]]\n",
      "76.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.89      0.84       170\n",
      "          2       0.69      0.50      0.58        80\n",
      "\n",
      "avg / total       0.76      0.77      0.76       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "final_model = XGBClassifier(n_estimators=100,num_boost_round=1,max_depth=3,subsample=0.632,colsample_bytree=1)\n",
    "final_model.fit(X_train.values, Y_train.astype(int))\n",
    "y_pred = final_model.predict(X_test.values)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,History\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(640, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(640, activation='sigmoid'))\n",
    "m.add(Dropout(0.5))\n",
    "m.add(Dense(640, activation='sigmoid'))\n",
    "# m.add(Dropout(0.5))\n",
    "m.add(Dense(len(np.unique(Y_train)), activation='softmax'))\n",
    "    \n",
    "m.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01561418, -0.02596954, -0.03478066, ..., -0.02423057,\n",
       "         -0.00749107, -0.04753182],\n",
       "        [ 0.08588466,  0.00110547,  0.03656653, ...,  0.06312191,\n",
       "          0.08274621,  0.04087494],\n",
       "        [ 0.08248322,  0.05960596,  0.07256536, ...,  0.0632799 ,\n",
       "          0.06784885,  0.00446068],\n",
       "        ..., \n",
       "        [-0.03295828,  0.01184713, -0.07009637, ...,  0.001541  ,\n",
       "         -0.03002427, -0.06424326],\n",
       "        [ 0.09183723,  0.01363882,  0.07385056, ..., -0.02947772,\n",
       "         -0.04475392,  0.07793397],\n",
       "        [ 0.08721979,  0.0255806 ,  0.02710284, ...,  0.02433027,\n",
       "         -0.08511245,  0.07555759]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = m.layers[0].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/400\n",
      "Epoch 00000: val_loss improved from inf to 0.81231, saving model to best.model\n",
      "0s - loss: 0.8874 - binary_accuracy: 0.7150 - val_loss: 0.8123 - val_binary_accuracy: 0.3200\n",
      "Epoch 2/400\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7243 - binary_accuracy: 0.4700 - val_loss: 0.8190 - val_binary_accuracy: 0.6800\n",
      "Epoch 3/400\n",
      "Epoch 00002: val_loss improved from 0.81231 to 0.64157, saving model to best.model\n",
      "0s - loss: 0.7298 - binary_accuracy: 0.7133 - val_loss: 0.6416 - val_binary_accuracy: 0.6800\n",
      "Epoch 4/400\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6017 - binary_accuracy: 0.7117 - val_loss: 0.6467 - val_binary_accuracy: 0.6800\n",
      "Epoch 5/400\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6305 - binary_accuracy: 0.6950 - val_loss: 0.6550 - val_binary_accuracy: 0.6800\n",
      "Epoch 6/400\n",
      "Epoch 00005: val_loss improved from 0.64157 to 0.63007, saving model to best.model\n",
      "0s - loss: 0.6135 - binary_accuracy: 0.7133 - val_loss: 0.6301 - val_binary_accuracy: 0.6800\n",
      "Epoch 7/400\n",
      "Epoch 00006: val_loss improved from 0.63007 to 0.62180, saving model to best.model\n",
      "0s - loss: 0.5994 - binary_accuracy: 0.7133 - val_loss: 0.6218 - val_binary_accuracy: 0.6800\n",
      "Epoch 8/400\n",
      "Epoch 00007: val_loss improved from 0.62180 to 0.62053, saving model to best.model\n",
      "0s - loss: 0.6026 - binary_accuracy: 0.7133 - val_loss: 0.6205 - val_binary_accuracy: 0.6800\n",
      "Epoch 9/400\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5840 - binary_accuracy: 0.7133 - val_loss: 0.6359 - val_binary_accuracy: 0.6800\n",
      "Epoch 10/400\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6021 - binary_accuracy: 0.7133 - val_loss: 0.6226 - val_binary_accuracy: 0.6800\n",
      "Epoch 11/400\n",
      "Epoch 00010: val_loss improved from 0.62053 to 0.61277, saving model to best.model\n",
      "0s - loss: 0.5916 - binary_accuracy: 0.7133 - val_loss: 0.6128 - val_binary_accuracy: 0.6800\n",
      "Epoch 12/400\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6015 - binary_accuracy: 0.7133 - val_loss: 0.6150 - val_binary_accuracy: 0.6800\n",
      "Epoch 13/400\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5917 - binary_accuracy: 0.7133 - val_loss: 0.6186 - val_binary_accuracy: 0.6800\n",
      "Epoch 14/400\n",
      "Epoch 00013: val_loss improved from 0.61277 to 0.60658, saving model to best.model\n",
      "0s - loss: 0.5888 - binary_accuracy: 0.7133 - val_loss: 0.6066 - val_binary_accuracy: 0.6800\n",
      "Epoch 15/400\n",
      "Epoch 00014: val_loss improved from 0.60658 to 0.60205, saving model to best.model\n",
      "0s - loss: 0.5844 - binary_accuracy: 0.7150 - val_loss: 0.6020 - val_binary_accuracy: 0.6800\n",
      "Epoch 16/400\n",
      "Epoch 00015: val_loss improved from 0.60205 to 0.60007, saving model to best.model\n",
      "0s - loss: 0.5819 - binary_accuracy: 0.7133 - val_loss: 0.6001 - val_binary_accuracy: 0.6800\n",
      "Epoch 17/400\n",
      "Epoch 00016: val_loss improved from 0.60007 to 0.59112, saving model to best.model\n",
      "0s - loss: 0.5733 - binary_accuracy: 0.7200 - val_loss: 0.5911 - val_binary_accuracy: 0.6800\n",
      "Epoch 18/400\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5779 - binary_accuracy: 0.7183 - val_loss: 0.6051 - val_binary_accuracy: 0.6800\n",
      "Epoch 19/400\n",
      "Epoch 00018: val_loss improved from 0.59112 to 0.58570, saving model to best.model\n",
      "0s - loss: 0.5658 - binary_accuracy: 0.7150 - val_loss: 0.5857 - val_binary_accuracy: 0.6800\n",
      "Epoch 20/400\n",
      "Epoch 00019: val_loss improved from 0.58570 to 0.57183, saving model to best.model\n",
      "0s - loss: 0.5592 - binary_accuracy: 0.7167 - val_loss: 0.5718 - val_binary_accuracy: 0.6867\n",
      "Epoch 21/400\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5507 - binary_accuracy: 0.7267 - val_loss: 0.5814 - val_binary_accuracy: 0.6800\n",
      "Epoch 22/400\n",
      "Epoch 00021: val_loss improved from 0.57183 to 0.57076, saving model to best.model\n",
      "0s - loss: 0.5505 - binary_accuracy: 0.7183 - val_loss: 0.5708 - val_binary_accuracy: 0.6733\n",
      "Epoch 23/400\n",
      "Epoch 00022: val_loss improved from 0.57076 to 0.55099, saving model to best.model\n",
      "0s - loss: 0.5412 - binary_accuracy: 0.7300 - val_loss: 0.5510 - val_binary_accuracy: 0.6667\n",
      "Epoch 24/400\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5287 - binary_accuracy: 0.7533 - val_loss: 0.5781 - val_binary_accuracy: 0.6800\n",
      "Epoch 25/400\n",
      "Epoch 00024: val_loss improved from 0.55099 to 0.54065, saving model to best.model\n",
      "0s - loss: 0.5334 - binary_accuracy: 0.7217 - val_loss: 0.5407 - val_binary_accuracy: 0.6733\n",
      "Epoch 26/400\n",
      "Epoch 00025: val_loss improved from 0.54065 to 0.53910, saving model to best.model\n",
      "0s - loss: 0.5300 - binary_accuracy: 0.7433 - val_loss: 0.5391 - val_binary_accuracy: 0.6600\n",
      "Epoch 27/400\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5241 - binary_accuracy: 0.7417 - val_loss: 0.5500 - val_binary_accuracy: 0.6733\n",
      "Epoch 28/400\n",
      "Epoch 00027: val_loss improved from 0.53910 to 0.53798, saving model to best.model\n",
      "0s - loss: 0.5172 - binary_accuracy: 0.7400 - val_loss: 0.5380 - val_binary_accuracy: 0.6733\n",
      "Epoch 29/400\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5253 - binary_accuracy: 0.7367 - val_loss: 0.5382 - val_binary_accuracy: 0.6667\n",
      "Epoch 30/400\n",
      "Epoch 00029: val_loss improved from 0.53798 to 0.53315, saving model to best.model\n",
      "0s - loss: 0.4933 - binary_accuracy: 0.7550 - val_loss: 0.5331 - val_binary_accuracy: 0.6800\n",
      "Epoch 31/400\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5018 - binary_accuracy: 0.7667 - val_loss: 0.5492 - val_binary_accuracy: 0.6733\n",
      "Epoch 32/400\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5099 - binary_accuracy: 0.7450 - val_loss: 0.5526 - val_binary_accuracy: 0.6733\n",
      "Epoch 33/400\n",
      "Epoch 00032: val_loss improved from 0.53315 to 0.53240, saving model to best.model\n",
      "0s - loss: 0.5050 - binary_accuracy: 0.7600 - val_loss: 0.5324 - val_binary_accuracy: 0.6867\n",
      "Epoch 34/400\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.4943 - binary_accuracy: 0.7567 - val_loss: 0.5366 - val_binary_accuracy: 0.6800\n",
      "Epoch 35/400\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5115 - binary_accuracy: 0.7450 - val_loss: 0.5391 - val_binary_accuracy: 0.6867\n",
      "Epoch 36/400\n",
      "Epoch 00035: val_loss improved from 0.53240 to 0.52392, saving model to best.model\n",
      "0s - loss: 0.4842 - binary_accuracy: 0.7733 - val_loss: 0.5239 - val_binary_accuracy: 0.7200\n",
      "Epoch 37/400\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5036 - binary_accuracy: 0.7633 - val_loss: 0.5483 - val_binary_accuracy: 0.6800\n",
      "Epoch 38/400\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5209 - binary_accuracy: 0.7583 - val_loss: 0.5248 - val_binary_accuracy: 0.7000\n",
      "Epoch 39/400\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5140 - binary_accuracy: 0.7417 - val_loss: 0.5311 - val_binary_accuracy: 0.6933\n",
      "Epoch 40/400\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5225 - binary_accuracy: 0.7500 - val_loss: 0.5453 - val_binary_accuracy: 0.6800\n",
      "Epoch 41/400\n",
      "Epoch 00040: val_loss improved from 0.52392 to 0.52191, saving model to best.model\n",
      "0s - loss: 0.5115 - binary_accuracy: 0.7550 - val_loss: 0.5219 - val_binary_accuracy: 0.7400\n",
      "Epoch 42/400\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5253 - binary_accuracy: 0.7417 - val_loss: 0.5703 - val_binary_accuracy: 0.6933\n",
      "Epoch 43/400\n",
      "Epoch 00042: val_loss improved from 0.52191 to 0.51962, saving model to best.model\n",
      "0s - loss: 0.5209 - binary_accuracy: 0.7517 - val_loss: 0.5196 - val_binary_accuracy: 0.7067\n",
      "Epoch 44/400\n",
      "Epoch 00043: val_loss improved from 0.51962 to 0.51838, saving model to best.model\n",
      "0s - loss: 0.5010 - binary_accuracy: 0.7633 - val_loss: 0.5184 - val_binary_accuracy: 0.7200\n",
      "Epoch 45/400\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5228 - binary_accuracy: 0.7500 - val_loss: 0.5390 - val_binary_accuracy: 0.6800\n",
      "Epoch 46/400\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4874 - binary_accuracy: 0.7650 - val_loss: 0.5200 - val_binary_accuracy: 0.7467\n",
      "Epoch 47/400\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5055 - binary_accuracy: 0.7583 - val_loss: 0.5420 - val_binary_accuracy: 0.6733\n",
      "Epoch 48/400\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4921 - binary_accuracy: 0.7700 - val_loss: 0.5202 - val_binary_accuracy: 0.7067\n",
      "Epoch 49/400\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4946 - binary_accuracy: 0.7567 - val_loss: 0.5197 - val_binary_accuracy: 0.7067\n",
      "Epoch 50/400\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5026 - binary_accuracy: 0.7633 - val_loss: 0.5250 - val_binary_accuracy: 0.7133\n",
      "Epoch 51/400\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4907 - binary_accuracy: 0.7600 - val_loss: 0.5232 - val_binary_accuracy: 0.7133\n",
      "Epoch 52/400\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4923 - binary_accuracy: 0.7633 - val_loss: 0.5197 - val_binary_accuracy: 0.7000\n",
      "Epoch 53/400\n",
      "Epoch 00052: val_loss improved from 0.51838 to 0.51801, saving model to best.model\n",
      "0s - loss: 0.4908 - binary_accuracy: 0.7683 - val_loss: 0.5180 - val_binary_accuracy: 0.7133\n",
      "Epoch 54/400\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4901 - binary_accuracy: 0.7667 - val_loss: 0.5401 - val_binary_accuracy: 0.6800\n",
      "Epoch 55/400\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5091 - binary_accuracy: 0.7533 - val_loss: 0.5281 - val_binary_accuracy: 0.7067\n",
      "Epoch 56/400\n",
      "Epoch 00055: val_loss improved from 0.51801 to 0.51777, saving model to best.model\n",
      "0s - loss: 0.4892 - binary_accuracy: 0.7650 - val_loss: 0.5178 - val_binary_accuracy: 0.7400\n",
      "Epoch 57/400\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4910 - binary_accuracy: 0.7550 - val_loss: 0.5356 - val_binary_accuracy: 0.6933\n",
      "Epoch 58/400\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4877 - binary_accuracy: 0.7600 - val_loss: 0.5329 - val_binary_accuracy: 0.7000\n",
      "Epoch 59/400\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4957 - binary_accuracy: 0.7567 - val_loss: 0.5179 - val_binary_accuracy: 0.7333\n",
      "Epoch 60/400\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.5021 - binary_accuracy: 0.7517 - val_loss: 0.5250 - val_binary_accuracy: 0.7133\n",
      "Epoch 61/400\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.5068 - binary_accuracy: 0.7517 - val_loss: 0.5238 - val_binary_accuracy: 0.7133\n",
      "Epoch 62/400\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4842 - binary_accuracy: 0.7800 - val_loss: 0.5196 - val_binary_accuracy: 0.7533\n",
      "Epoch 63/400\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.5020 - binary_accuracy: 0.7467 - val_loss: 0.5273 - val_binary_accuracy: 0.7133\n",
      "Epoch 64/400\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4889 - binary_accuracy: 0.7683 - val_loss: 0.5404 - val_binary_accuracy: 0.6867\n",
      "Epoch 65/400\n",
      "Epoch 00064: val_loss improved from 0.51777 to 0.51685, saving model to best.model\n",
      "0s - loss: 0.4958 - binary_accuracy: 0.7650 - val_loss: 0.5168 - val_binary_accuracy: 0.7400\n",
      "Epoch 66/400\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4878 - binary_accuracy: 0.7600 - val_loss: 0.5234 - val_binary_accuracy: 0.7067\n",
      "Epoch 67/400\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4832 - binary_accuracy: 0.7667 - val_loss: 0.5199 - val_binary_accuracy: 0.7067\n",
      "Epoch 68/400\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4927 - binary_accuracy: 0.7650 - val_loss: 0.5171 - val_binary_accuracy: 0.7400\n",
      "Epoch 69/400\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4924 - binary_accuracy: 0.7667 - val_loss: 0.5268 - val_binary_accuracy: 0.7067\n",
      "Epoch 70/400\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4869 - binary_accuracy: 0.7683 - val_loss: 0.5184 - val_binary_accuracy: 0.7267\n",
      "Epoch 71/400\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4863 - binary_accuracy: 0.7633 - val_loss: 0.5252 - val_binary_accuracy: 0.7067\n",
      "Epoch 72/400\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4977 - binary_accuracy: 0.7600 - val_loss: 0.5335 - val_binary_accuracy: 0.7067\n",
      "Epoch 73/400\n",
      "Epoch 00072: val_loss improved from 0.51685 to 0.51593, saving model to best.model\n",
      "0s - loss: 0.4937 - binary_accuracy: 0.7667 - val_loss: 0.5159 - val_binary_accuracy: 0.7333\n",
      "Epoch 74/400\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4904 - binary_accuracy: 0.7700 - val_loss: 0.5308 - val_binary_accuracy: 0.7067\n",
      "Epoch 75/400\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4893 - binary_accuracy: 0.7633 - val_loss: 0.5167 - val_binary_accuracy: 0.7133\n",
      "Epoch 76/400\n",
      "Epoch 00075: val_loss improved from 0.51593 to 0.51546, saving model to best.model\n",
      "0s - loss: 0.4828 - binary_accuracy: 0.7667 - val_loss: 0.5155 - val_binary_accuracy: 0.7200\n",
      "Epoch 77/400\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4887 - binary_accuracy: 0.7567 - val_loss: 0.5157 - val_binary_accuracy: 0.7200\n",
      "Epoch 78/400\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4869 - binary_accuracy: 0.7633 - val_loss: 0.5163 - val_binary_accuracy: 0.7200\n",
      "Epoch 79/400\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4921 - binary_accuracy: 0.7800 - val_loss: 0.5163 - val_binary_accuracy: 0.7133\n",
      "Epoch 80/400\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4975 - binary_accuracy: 0.7767 - val_loss: 0.5175 - val_binary_accuracy: 0.7200\n",
      "Epoch 81/400\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4928 - binary_accuracy: 0.7700 - val_loss: 0.5184 - val_binary_accuracy: 0.7067\n",
      "Epoch 82/400\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4886 - binary_accuracy: 0.7633 - val_loss: 0.5158 - val_binary_accuracy: 0.7133\n",
      "Epoch 83/400\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4823 - binary_accuracy: 0.7683 - val_loss: 0.5172 - val_binary_accuracy: 0.7067\n",
      "Epoch 84/400\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4702 - binary_accuracy: 0.7683 - val_loss: 0.5194 - val_binary_accuracy: 0.7133\n",
      "Epoch 85/400\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4787 - binary_accuracy: 0.7717 - val_loss: 0.5169 - val_binary_accuracy: 0.7067\n",
      "Epoch 86/400\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4816 - binary_accuracy: 0.7717 - val_loss: 0.5156 - val_binary_accuracy: 0.7267\n",
      "Epoch 87/400\n",
      "Epoch 00086: val_loss improved from 0.51546 to 0.51479, saving model to best.model\n",
      "0s - loss: 0.4693 - binary_accuracy: 0.7867 - val_loss: 0.5148 - val_binary_accuracy: 0.7267\n",
      "Epoch 88/400\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4963 - binary_accuracy: 0.7600 - val_loss: 0.5151 - val_binary_accuracy: 0.7333\n",
      "Epoch 89/400\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4950 - binary_accuracy: 0.7683 - val_loss: 0.5387 - val_binary_accuracy: 0.6867\n",
      "Epoch 90/400\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4854 - binary_accuracy: 0.7583 - val_loss: 0.5150 - val_binary_accuracy: 0.7333\n",
      "Epoch 91/400\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4934 - binary_accuracy: 0.7700 - val_loss: 0.5165 - val_binary_accuracy: 0.7333\n",
      "Epoch 92/400\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4980 - binary_accuracy: 0.7617 - val_loss: 0.5274 - val_binary_accuracy: 0.7067\n",
      "Epoch 93/400\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4813 - binary_accuracy: 0.7900 - val_loss: 0.5149 - val_binary_accuracy: 0.7533\n",
      "Epoch 94/400\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4880 - binary_accuracy: 0.7583 - val_loss: 0.5204 - val_binary_accuracy: 0.7133\n",
      "Epoch 95/400\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4764 - binary_accuracy: 0.7600 - val_loss: 0.5322 - val_binary_accuracy: 0.6867\n",
      "Epoch 96/400\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4818 - binary_accuracy: 0.7750 - val_loss: 0.5161 - val_binary_accuracy: 0.7600\n",
      "Epoch 97/400\n",
      "Epoch 00096: val_loss improved from 0.51479 to 0.51467, saving model to best.model\n",
      "0s - loss: 0.4938 - binary_accuracy: 0.7683 - val_loss: 0.5147 - val_binary_accuracy: 0.7333\n",
      "Epoch 98/400\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4697 - binary_accuracy: 0.7700 - val_loss: 0.5381 - val_binary_accuracy: 0.6867\n",
      "Epoch 99/400\n",
      "Epoch 00098: val_loss improved from 0.51467 to 0.51410, saving model to best.model\n",
      "0s - loss: 0.4947 - binary_accuracy: 0.7617 - val_loss: 0.5141 - val_binary_accuracy: 0.7267\n",
      "Epoch 100/400\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4753 - binary_accuracy: 0.7667 - val_loss: 0.5142 - val_binary_accuracy: 0.7267\n",
      "Epoch 101/400\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4893 - binary_accuracy: 0.7717 - val_loss: 0.5313 - val_binary_accuracy: 0.7200\n",
      "Epoch 102/400\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4848 - binary_accuracy: 0.7733 - val_loss: 0.5156 - val_binary_accuracy: 0.7133\n",
      "Epoch 103/400\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4819 - binary_accuracy: 0.7767 - val_loss: 0.5154 - val_binary_accuracy: 0.7133\n",
      "Epoch 104/400\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4840 - binary_accuracy: 0.7833 - val_loss: 0.5246 - val_binary_accuracy: 0.7200\n",
      "Epoch 105/400\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4786 - binary_accuracy: 0.7700 - val_loss: 0.5157 - val_binary_accuracy: 0.7133\n",
      "Epoch 106/400\n",
      "Epoch 00105: val_loss improved from 0.51410 to 0.51262, saving model to best.model\n",
      "0s - loss: 0.4842 - binary_accuracy: 0.7700 - val_loss: 0.5126 - val_binary_accuracy: 0.7333\n",
      "Epoch 107/400\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4842 - binary_accuracy: 0.7717 - val_loss: 0.5300 - val_binary_accuracy: 0.6867\n",
      "Epoch 108/400\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4872 - binary_accuracy: 0.7683 - val_loss: 0.5265 - val_binary_accuracy: 0.6933\n",
      "Epoch 109/400\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4828 - binary_accuracy: 0.7700 - val_loss: 0.5129 - val_binary_accuracy: 0.7333\n",
      "Epoch 110/400\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4793 - binary_accuracy: 0.7683 - val_loss: 0.5160 - val_binary_accuracy: 0.7133\n",
      "Epoch 111/400\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4853 - binary_accuracy: 0.7767 - val_loss: 0.5186 - val_binary_accuracy: 0.7067\n",
      "Epoch 112/400\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4678 - binary_accuracy: 0.7850 - val_loss: 0.5136 - val_binary_accuracy: 0.7200\n",
      "Epoch 113/400\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.4839 - binary_accuracy: 0.7650 - val_loss: 0.5197 - val_binary_accuracy: 0.7200\n",
      "Epoch 114/400\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4766 - binary_accuracy: 0.7800 - val_loss: 0.5191 - val_binary_accuracy: 0.7133\n",
      "Epoch 115/400\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4848 - binary_accuracy: 0.7617 - val_loss: 0.5182 - val_binary_accuracy: 0.7133\n",
      "Epoch 116/400\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4758 - binary_accuracy: 0.7667 - val_loss: 0.5216 - val_binary_accuracy: 0.7200\n",
      "Epoch 117/400\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.4846 - binary_accuracy: 0.7667 - val_loss: 0.5141 - val_binary_accuracy: 0.7200\n",
      "Epoch 118/400\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.4805 - binary_accuracy: 0.7617 - val_loss: 0.5198 - val_binary_accuracy: 0.7133\n",
      "Epoch 119/400\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.4885 - binary_accuracy: 0.7667 - val_loss: 0.5221 - val_binary_accuracy: 0.7067\n",
      "Epoch 120/400\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.4667 - binary_accuracy: 0.7883 - val_loss: 0.5129 - val_binary_accuracy: 0.7267\n",
      "Epoch 121/400\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.4765 - binary_accuracy: 0.7750 - val_loss: 0.5144 - val_binary_accuracy: 0.7333\n",
      "Epoch 122/400\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.4682 - binary_accuracy: 0.7833 - val_loss: 0.5160 - val_binary_accuracy: 0.7133\n",
      "Epoch 123/400\n",
      "Epoch 00122: val_loss improved from 0.51262 to 0.51255, saving model to best.model\n",
      "0s - loss: 0.4786 - binary_accuracy: 0.7683 - val_loss: 0.5125 - val_binary_accuracy: 0.7267\n",
      "Epoch 124/400\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.4770 - binary_accuracy: 0.7767 - val_loss: 0.5341 - val_binary_accuracy: 0.6867\n",
      "Epoch 125/400\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.4799 - binary_accuracy: 0.7733 - val_loss: 0.5152 - val_binary_accuracy: 0.7133\n",
      "Epoch 126/400\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.4635 - binary_accuracy: 0.7833 - val_loss: 0.5150 - val_binary_accuracy: 0.7600\n",
      "Epoch 127/400\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.4774 - binary_accuracy: 0.7700 - val_loss: 0.5191 - val_binary_accuracy: 0.7200\n",
      "Epoch 128/400\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.4915 - binary_accuracy: 0.7750 - val_loss: 0.5175 - val_binary_accuracy: 0.7067\n",
      "Epoch 129/400\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.4805 - binary_accuracy: 0.7783 - val_loss: 0.5130 - val_binary_accuracy: 0.7267\n",
      "Epoch 130/400\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.4795 - binary_accuracy: 0.7767 - val_loss: 0.5218 - val_binary_accuracy: 0.7267\n",
      "Epoch 131/400\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.4689 - binary_accuracy: 0.7867 - val_loss: 0.5141 - val_binary_accuracy: 0.7333\n",
      "Epoch 132/400\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.4766 - binary_accuracy: 0.7700 - val_loss: 0.5148 - val_binary_accuracy: 0.7200\n",
      "Epoch 133/400\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.4683 - binary_accuracy: 0.7717 - val_loss: 0.5154 - val_binary_accuracy: 0.7200\n",
      "Epoch 134/400\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.4645 - binary_accuracy: 0.7850 - val_loss: 0.5248 - val_binary_accuracy: 0.7133\n",
      "Epoch 135/400\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.4789 - binary_accuracy: 0.7600 - val_loss: 0.5158 - val_binary_accuracy: 0.7200\n",
      "Epoch 136/400\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.4723 - binary_accuracy: 0.7767 - val_loss: 0.5176 - val_binary_accuracy: 0.7133\n",
      "Epoch 137/400\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.4654 - binary_accuracy: 0.7833 - val_loss: 0.5194 - val_binary_accuracy: 0.7067\n",
      "Epoch 138/400\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.4832 - binary_accuracy: 0.7667 - val_loss: 0.5161 - val_binary_accuracy: 0.7467\n",
      "Epoch 139/400\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.4884 - binary_accuracy: 0.7533 - val_loss: 0.5172 - val_binary_accuracy: 0.7133\n",
      "Epoch 140/400\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.4852 - binary_accuracy: 0.7650 - val_loss: 0.5198 - val_binary_accuracy: 0.7200\n",
      "Epoch 141/400\n",
      "Epoch 00140: val_loss improved from 0.51255 to 0.51127, saving model to best.model\n",
      "0s - loss: 0.4820 - binary_accuracy: 0.7733 - val_loss: 0.5113 - val_binary_accuracy: 0.7267\n",
      "Epoch 142/400\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.4771 - binary_accuracy: 0.7817 - val_loss: 0.5125 - val_binary_accuracy: 0.7133\n",
      "Epoch 143/400\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.4675 - binary_accuracy: 0.7767 - val_loss: 0.5163 - val_binary_accuracy: 0.7200\n",
      "Epoch 144/400\n",
      "Epoch 00143: val_loss improved from 0.51127 to 0.51104, saving model to best.model\n",
      "0s - loss: 0.4718 - binary_accuracy: 0.7783 - val_loss: 0.5110 - val_binary_accuracy: 0.7267\n",
      "Epoch 145/400\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.4780 - binary_accuracy: 0.7717 - val_loss: 0.5115 - val_binary_accuracy: 0.7267\n",
      "Epoch 146/400\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.4810 - binary_accuracy: 0.7900 - val_loss: 0.5133 - val_binary_accuracy: 0.7200\n",
      "Epoch 147/400\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.4793 - binary_accuracy: 0.7600 - val_loss: 0.5237 - val_binary_accuracy: 0.7267\n",
      "Epoch 148/400\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.4738 - binary_accuracy: 0.7783 - val_loss: 0.5119 - val_binary_accuracy: 0.7200\n",
      "Epoch 149/400\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.4725 - binary_accuracy: 0.7717 - val_loss: 0.5122 - val_binary_accuracy: 0.7200\n",
      "Epoch 150/400\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.4789 - binary_accuracy: 0.7733 - val_loss: 0.5225 - val_binary_accuracy: 0.7267\n",
      "Epoch 151/400\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.4719 - binary_accuracy: 0.7667 - val_loss: 0.5123 - val_binary_accuracy: 0.7333\n",
      "Epoch 152/400\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.4776 - binary_accuracy: 0.7633 - val_loss: 0.5131 - val_binary_accuracy: 0.7133\n",
      "Epoch 153/400\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.4779 - binary_accuracy: 0.7700 - val_loss: 0.5300 - val_binary_accuracy: 0.7000\n",
      "Epoch 154/400\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.4854 - binary_accuracy: 0.7650 - val_loss: 0.5179 - val_binary_accuracy: 0.7133\n",
      "Epoch 155/400\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.4793 - binary_accuracy: 0.7683 - val_loss: 0.5131 - val_binary_accuracy: 0.7067\n",
      "Epoch 156/400\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.4735 - binary_accuracy: 0.7917 - val_loss: 0.5145 - val_binary_accuracy: 0.7133\n",
      "Epoch 157/400\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.4637 - binary_accuracy: 0.7783 - val_loss: 0.5150 - val_binary_accuracy: 0.7133\n",
      "Epoch 158/400\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.4757 - binary_accuracy: 0.7633 - val_loss: 0.5137 - val_binary_accuracy: 0.7200\n",
      "Epoch 159/400\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.4811 - binary_accuracy: 0.7650 - val_loss: 0.5204 - val_binary_accuracy: 0.7267\n",
      "Epoch 160/400\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.4726 - binary_accuracy: 0.7617 - val_loss: 0.5192 - val_binary_accuracy: 0.7133\n",
      "Epoch 161/400\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.4745 - binary_accuracy: 0.7633 - val_loss: 0.5227 - val_binary_accuracy: 0.7200\n",
      "Epoch 162/400\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.4726 - binary_accuracy: 0.7717 - val_loss: 0.5151 - val_binary_accuracy: 0.7267\n",
      "Epoch 163/400\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.4837 - binary_accuracy: 0.7683 - val_loss: 0.5166 - val_binary_accuracy: 0.7133\n",
      "Epoch 164/400\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.4742 - binary_accuracy: 0.7817 - val_loss: 0.5300 - val_binary_accuracy: 0.7000\n",
      "Epoch 165/400\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.4703 - binary_accuracy: 0.7700 - val_loss: 0.5164 - val_binary_accuracy: 0.7200\n",
      "Epoch 166/400\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.4608 - binary_accuracy: 0.7833 - val_loss: 0.5173 - val_binary_accuracy: 0.7267\n",
      "Epoch 167/400\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.4696 - binary_accuracy: 0.7767 - val_loss: 0.5250 - val_binary_accuracy: 0.7133\n",
      "Epoch 168/400\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.4738 - binary_accuracy: 0.7833 - val_loss: 0.5189 - val_binary_accuracy: 0.7200\n",
      "Epoch 169/400\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.4679 - binary_accuracy: 0.7733 - val_loss: 0.5239 - val_binary_accuracy: 0.7200\n",
      "Epoch 170/400\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.4662 - binary_accuracy: 0.7817 - val_loss: 0.5340 - val_binary_accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "hist=m.fit(\n",
    "    # Feature matrix\n",
    "    X_train.values, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=400, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        history,\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.2,\n",
    "    batch_size=256, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAHMCAYAAACuiKKqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7926GKYY09AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129bfaf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.load_weights(\"best.model\")\n",
    "mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    ")\n",
    "y_pred_nn = [mapping[pred] for pred in m.predict(X_test.values).argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(m, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151  19]\n",
      " [ 40  40]]\n",
      "76.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.89      0.84       170\n",
      "          2       0.68      0.50      0.58        80\n",
      "\n",
      "avg / total       0.75      0.76      0.75       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred_nn)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred_nn) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred_nn)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2,\n",
       "       1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train,data_test=train_test_split(train,test_size=0.25, random_state=10)\n",
    "X_test=data_test.drop(['y'], axis=1).values\n",
    "Y_test=data_test['y'].ravel()\n",
    "\n",
    "\n",
    "def train_nn(data_train):\n",
    "    data_train_new=data_train.sample(frac=0.8,replace=True)\n",
    "    X_train=data_train_new.drop(['y'], axis=1).values\n",
    "    Y_train=data_train_new['y'].ravel()\n",
    "    \n",
    "    m = Sequential()\n",
    "    m.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='relu'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(128, activation='relu'))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(len(np.unique(Y_train)), activation='softmax'))\n",
    "    \n",
    "    m.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    m.fit(\n",
    "    # Feature matrix\n",
    "    X_train, \n",
    "    # Target class one-hot-encoded\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0]).as_matrix(),\n",
    "    # Iterations to be run if not stopped by EarlyStopping\n",
    "    epochs=200, \n",
    "    callbacks=[\n",
    "        # Stop iterations when validation loss has not improved\n",
    "        EarlyStopping(monitor='val_loss', patience=25),\n",
    "        # Nice for keeping the last model before overfitting occurs\n",
    "        ModelCheckpoint(\n",
    "            'best.model', \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256, \n",
    "    )\n",
    "    m.load_weights(\"best.model\")\n",
    "    mapping = (\n",
    "    pd.get_dummies(pd.DataFrame(Y_train), columns=[0], prefix='', prefix_sep='')\n",
    "    .columns.astype(int).values\n",
    "    )\n",
    "    y_pred = [mapping[pred] for pred in m.predict(X_test).argmax(axis=1)]\n",
    "    return y_pred \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.57525, saving model to best.model\n",
      "0s - loss: 0.7549 - acc: 0.6074 - val_loss: 0.5753 - val_acc: 0.7500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.57525 to 0.56478, saving model to best.model\n",
      "0s - loss: 0.7053 - acc: 0.6593 - val_loss: 0.5648 - val_acc: 0.7500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.56478 to 0.55667, saving model to best.model\n",
      "0s - loss: 0.6723 - acc: 0.6870 - val_loss: 0.5567 - val_acc: 0.7500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.55667 to 0.54973, saving model to best.model\n",
      "0s - loss: 0.6249 - acc: 0.6741 - val_loss: 0.5497 - val_acc: 0.7500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54973 to 0.54591, saving model to best.model\n",
      "0s - loss: 0.6281 - acc: 0.6759 - val_loss: 0.5459 - val_acc: 0.7500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.54591 to 0.54190, saving model to best.model\n",
      "0s - loss: 0.6204 - acc: 0.6963 - val_loss: 0.5419 - val_acc: 0.7500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6300 - acc: 0.6926 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6403 - acc: 0.6741 - val_loss: 0.5500 - val_acc: 0.7500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5995 - acc: 0.7074 - val_loss: 0.5511 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6260 - acc: 0.6778 - val_loss: 0.5436 - val_acc: 0.7500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.54190 to 0.52994, saving model to best.model\n",
      "0s - loss: 0.5844 - acc: 0.6926 - val_loss: 0.5299 - val_acc: 0.7500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.52994 to 0.52060, saving model to best.model\n",
      "0s - loss: 0.5568 - acc: 0.7111 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.52060 to 0.51218, saving model to best.model\n",
      "0s - loss: 0.5734 - acc: 0.6963 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.51218 to 0.50698, saving model to best.model\n",
      "0s - loss: 0.5750 - acc: 0.7148 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.50698 to 0.50447, saving model to best.model\n",
      "0s - loss: 0.5906 - acc: 0.7130 - val_loss: 0.5045 - val_acc: 0.7500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.50447 to 0.50346, saving model to best.model\n",
      "0s - loss: 0.5788 - acc: 0.7111 - val_loss: 0.5035 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.50346 to 0.50230, saving model to best.model\n",
      "0s - loss: 0.5335 - acc: 0.7241 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.50230 to 0.49978, saving model to best.model\n",
      "0s - loss: 0.5447 - acc: 0.7185 - val_loss: 0.4998 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.49978 to 0.49761, saving model to best.model\n",
      "0s - loss: 0.5298 - acc: 0.7500 - val_loss: 0.4976 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.49761 to 0.49488, saving model to best.model\n",
      "0s - loss: 0.5528 - acc: 0.7185 - val_loss: 0.4949 - val_acc: 0.7333\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.49488 to 0.49312, saving model to best.model\n",
      "0s - loss: 0.5716 - acc: 0.7148 - val_loss: 0.4931 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5372 - acc: 0.7185 - val_loss: 0.4933 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.49312 to 0.49146, saving model to best.model\n",
      "0s - loss: 0.5351 - acc: 0.7241 - val_loss: 0.4915 - val_acc: 0.7333\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.49146 to 0.48788, saving model to best.model\n",
      "0s - loss: 0.5244 - acc: 0.7296 - val_loss: 0.4879 - val_acc: 0.7333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.48788 to 0.48454, saving model to best.model\n",
      "0s - loss: 0.5364 - acc: 0.7296 - val_loss: 0.4845 - val_acc: 0.7333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5580 - acc: 0.7370 - val_loss: 0.4850 - val_acc: 0.7333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5384 - acc: 0.7333 - val_loss: 0.4860 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5265 - acc: 0.7500 - val_loss: 0.4868 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5223 - acc: 0.7222 - val_loss: 0.4866 - val_acc: 0.7167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5126 - acc: 0.7519 - val_loss: 0.4862 - val_acc: 0.7167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5062 - acc: 0.7426 - val_loss: 0.4874 - val_acc: 0.7167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5187 - acc: 0.7389 - val_loss: 0.4886 - val_acc: 0.7000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.4906 - acc: 0.7685 - val_loss: 0.4870 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.48454 to 0.48396, saving model to best.model\n",
      "0s - loss: 0.5029 - acc: 0.7352 - val_loss: 0.4840 - val_acc: 0.7333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.48396 to 0.47801, saving model to best.model\n",
      "0s - loss: 0.4865 - acc: 0.7611 - val_loss: 0.4780 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.47801 to 0.47030, saving model to best.model\n",
      "0s - loss: 0.4920 - acc: 0.7611 - val_loss: 0.4703 - val_acc: 0.7000\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.47030 to 0.46370, saving model to best.model\n",
      "0s - loss: 0.4978 - acc: 0.7574 - val_loss: 0.4637 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.46370 to 0.45935, saving model to best.model\n",
      "0s - loss: 0.4809 - acc: 0.7630 - val_loss: 0.4593 - val_acc: 0.7167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.45935 to 0.45701, saving model to best.model\n",
      "0s - loss: 0.5092 - acc: 0.7556 - val_loss: 0.4570 - val_acc: 0.7000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.45701 to 0.45589, saving model to best.model\n",
      "0s - loss: 0.5191 - acc: 0.7444 - val_loss: 0.4559 - val_acc: 0.7000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4847 - acc: 0.7741 - val_loss: 0.4580 - val_acc: 0.7333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5029 - acc: 0.7407 - val_loss: 0.4635 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4896 - acc: 0.7667 - val_loss: 0.4685 - val_acc: 0.7500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4812 - acc: 0.7778 - val_loss: 0.4703 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4988 - acc: 0.7426 - val_loss: 0.4681 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5034 - acc: 0.7389 - val_loss: 0.4651 - val_acc: 0.7333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4964 - acc: 0.7574 - val_loss: 0.4637 - val_acc: 0.6833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4854 - acc: 0.7574 - val_loss: 0.4637 - val_acc: 0.6667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4608 - acc: 0.7722 - val_loss: 0.4641 - val_acc: 0.6833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4754 - acc: 0.7537 - val_loss: 0.4635 - val_acc: 0.7000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4621 - acc: 0.7704 - val_loss: 0.4624 - val_acc: 0.7000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4626 - acc: 0.7759 - val_loss: 0.4619 - val_acc: 0.7000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4639 - acc: 0.7778 - val_loss: 0.4607 - val_acc: 0.7000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4719 - acc: 0.7759 - val_loss: 0.4607 - val_acc: 0.7000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4748 - acc: 0.7444 - val_loss: 0.4593 - val_acc: 0.7000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4548 - acc: 0.7630 - val_loss: 0.4573 - val_acc: 0.7000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4690 - acc: 0.7741 - val_loss: 0.4561 - val_acc: 0.7167\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.45589 to 0.45541, saving model to best.model\n",
      "0s - loss: 0.4689 - acc: 0.7778 - val_loss: 0.4554 - val_acc: 0.7167\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4737 - acc: 0.7556 - val_loss: 0.4564 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.45541 to 0.45535, saving model to best.model\n",
      "0s - loss: 0.4730 - acc: 0.7611 - val_loss: 0.4554 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.45535 to 0.45285, saving model to best.model\n",
      "0s - loss: 0.4848 - acc: 0.7667 - val_loss: 0.4528 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.45285 to 0.44918, saving model to best.model\n",
      "0s - loss: 0.4584 - acc: 0.7667 - val_loss: 0.4492 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.44918 to 0.44789, saving model to best.model\n",
      "0s - loss: 0.4682 - acc: 0.7722 - val_loss: 0.4479 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4654 - acc: 0.7611 - val_loss: 0.4483 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.44789 to 0.44744, saving model to best.model\n",
      "0s - loss: 0.4535 - acc: 0.7685 - val_loss: 0.4474 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.44744 to 0.44440, saving model to best.model\n",
      "0s - loss: 0.4497 - acc: 0.7722 - val_loss: 0.4444 - val_acc: 0.7500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.44440 to 0.43864, saving model to best.model\n",
      "0s - loss: 0.4402 - acc: 0.7907 - val_loss: 0.4386 - val_acc: 0.7500\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.43864 to 0.43103, saving model to best.model\n",
      "0s - loss: 0.4341 - acc: 0.8000 - val_loss: 0.4310 - val_acc: 0.7500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.43103 to 0.42552, saving model to best.model\n",
      "0s - loss: 0.4416 - acc: 0.7870 - val_loss: 0.4255 - val_acc: 0.7500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.42552 to 0.42191, saving model to best.model\n",
      "0s - loss: 0.4410 - acc: 0.7778 - val_loss: 0.4219 - val_acc: 0.7667\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.42191 to 0.42072, saving model to best.model\n",
      "0s - loss: 0.4414 - acc: 0.7944 - val_loss: 0.4207 - val_acc: 0.7500\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.42072 to 0.42051, saving model to best.model\n",
      "0s - loss: 0.4272 - acc: 0.7963 - val_loss: 0.4205 - val_acc: 0.7667\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4337 - acc: 0.7667 - val_loss: 0.4205 - val_acc: 0.7667\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4159 - acc: 0.8130 - val_loss: 0.4220 - val_acc: 0.7667\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4375 - acc: 0.7889 - val_loss: 0.4226 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4452 - acc: 0.7852 - val_loss: 0.4222 - val_acc: 0.7833\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.42051 to 0.41823, saving model to best.model\n",
      "0s - loss: 0.4240 - acc: 0.7963 - val_loss: 0.4182 - val_acc: 0.7667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.41823 to 0.41538, saving model to best.model\n",
      "0s - loss: 0.4339 - acc: 0.7778 - val_loss: 0.4154 - val_acc: 0.7500\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.41538 to 0.41402, saving model to best.model\n",
      "0s - loss: 0.4387 - acc: 0.7926 - val_loss: 0.4140 - val_acc: 0.7500\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.41402 to 0.41376, saving model to best.model\n",
      "0s - loss: 0.4112 - acc: 0.8019 - val_loss: 0.4138 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4385 - acc: 0.7870 - val_loss: 0.4161 - val_acc: 0.7500\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4161 - acc: 0.7963 - val_loss: 0.4199 - val_acc: 0.7500\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.3839 - acc: 0.8315 - val_loss: 0.4236 - val_acc: 0.7500\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4416 - acc: 0.7907 - val_loss: 0.4263 - val_acc: 0.7500\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4326 - acc: 0.7963 - val_loss: 0.4296 - val_acc: 0.7500\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.3958 - acc: 0.8185 - val_loss: 0.4304 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4088 - acc: 0.8074 - val_loss: 0.4300 - val_acc: 0.7500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4129 - acc: 0.8019 - val_loss: 0.4291 - val_acc: 0.7500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.3970 - acc: 0.8241 - val_loss: 0.4268 - val_acc: 0.7500\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4035 - acc: 0.8148 - val_loss: 0.4246 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4139 - acc: 0.8019 - val_loss: 0.4230 - val_acc: 0.7833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4162 - acc: 0.8056 - val_loss: 0.4209 - val_acc: 0.7833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4181 - acc: 0.8167 - val_loss: 0.4169 - val_acc: 0.8000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.41376 to 0.41153, saving model to best.model\n",
      "0s - loss: 0.3927 - acc: 0.8204 - val_loss: 0.4115 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.41153 to 0.40700, saving model to best.model\n",
      "0s - loss: 0.3819 - acc: 0.8278 - val_loss: 0.4070 - val_acc: 0.8167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.40700 to 0.40461, saving model to best.model\n",
      "0s - loss: 0.4070 - acc: 0.8111 - val_loss: 0.4046 - val_acc: 0.8167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4069 - acc: 0.8130 - val_loss: 0.4070 - val_acc: 0.8000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4119 - acc: 0.7981 - val_loss: 0.4062 - val_acc: 0.8000\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.40461 to 0.39902, saving model to best.model\n",
      "0s - loss: 0.3682 - acc: 0.8296 - val_loss: 0.3990 - val_acc: 0.8167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.39902 to 0.39334, saving model to best.model\n",
      "0s - loss: 0.3936 - acc: 0.8000 - val_loss: 0.3933 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.39334 to 0.39214, saving model to best.model\n",
      "0s - loss: 0.3962 - acc: 0.8222 - val_loss: 0.3921 - val_acc: 0.7667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.39214 to 0.39160, saving model to best.model\n",
      "0s - loss: 0.4008 - acc: 0.8241 - val_loss: 0.3916 - val_acc: 0.7667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.39160 to 0.39131, saving model to best.model\n",
      "0s - loss: 0.3861 - acc: 0.8167 - val_loss: 0.3913 - val_acc: 0.7667\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.39131 to 0.39108, saving model to best.model\n",
      "0s - loss: 0.3941 - acc: 0.8111 - val_loss: 0.3911 - val_acc: 0.7667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4179 - acc: 0.8259 - val_loss: 0.3912 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3719 - acc: 0.8333 - val_loss: 0.3914 - val_acc: 0.7667\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3702 - acc: 0.8426 - val_loss: 0.3916 - val_acc: 0.7667\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3816 - acc: 0.8407 - val_loss: 0.3923 - val_acc: 0.7667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3783 - acc: 0.8444 - val_loss: 0.3938 - val_acc: 0.7667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3789 - acc: 0.8370 - val_loss: 0.3960 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3620 - acc: 0.8407 - val_loss: 0.4000 - val_acc: 0.7667\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3716 - acc: 0.8315 - val_loss: 0.4042 - val_acc: 0.7667\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3635 - acc: 0.8389 - val_loss: 0.4041 - val_acc: 0.7667\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3688 - acc: 0.8315 - val_loss: 0.4027 - val_acc: 0.7667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3977 - acc: 0.8333 - val_loss: 0.4003 - val_acc: 0.7667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3727 - acc: 0.8500 - val_loss: 0.3948 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3692 - acc: 0.8481 - val_loss: 0.3917 - val_acc: 0.8000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.39108 to 0.39035, saving model to best.model\n",
      "0s - loss: 0.3748 - acc: 0.8481 - val_loss: 0.3904 - val_acc: 0.7667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.39035 to 0.38802, saving model to best.model\n",
      "0s - loss: 0.3644 - acc: 0.8463 - val_loss: 0.3880 - val_acc: 0.7667\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.38802 to 0.38522, saving model to best.model\n",
      "0s - loss: 0.3685 - acc: 0.8370 - val_loss: 0.3852 - val_acc: 0.7667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.38522 to 0.38162, saving model to best.model\n",
      "0s - loss: 0.3785 - acc: 0.8389 - val_loss: 0.3816 - val_acc: 0.7833\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.38162 to 0.38151, saving model to best.model\n",
      "0s - loss: 0.3656 - acc: 0.8352 - val_loss: 0.3815 - val_acc: 0.7667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3486 - acc: 0.8574 - val_loss: 0.3817 - val_acc: 0.8000\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.38151 to 0.38140, saving model to best.model\n",
      "0s - loss: 0.3177 - acc: 0.8667 - val_loss: 0.3814 - val_acc: 0.8000\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.38140 to 0.38064, saving model to best.model\n",
      "0s - loss: 0.3399 - acc: 0.8500 - val_loss: 0.3806 - val_acc: 0.8000\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3633 - acc: 0.8481 - val_loss: 0.3811 - val_acc: 0.8000\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.38064 to 0.37584, saving model to best.model\n",
      "0s - loss: 0.3323 - acc: 0.8556 - val_loss: 0.3758 - val_acc: 0.8000\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.37584 to 0.36978, saving model to best.model\n",
      "0s - loss: 0.3217 - acc: 0.8759 - val_loss: 0.3698 - val_acc: 0.8167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.36978 to 0.36588, saving model to best.model\n",
      "0s - loss: 0.3386 - acc: 0.8407 - val_loss: 0.3659 - val_acc: 0.8167\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.36588 to 0.35873, saving model to best.model\n",
      "0s - loss: 0.3593 - acc: 0.8333 - val_loss: 0.3587 - val_acc: 0.8167\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.35873 to 0.35180, saving model to best.model\n",
      "0s - loss: 0.3517 - acc: 0.8407 - val_loss: 0.3518 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.35180 to 0.34557, saving model to best.model\n",
      "0s - loss: 0.3286 - acc: 0.8593 - val_loss: 0.3456 - val_acc: 0.8333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.34557 to 0.34085, saving model to best.model\n",
      "0s - loss: 0.3198 - acc: 0.8685 - val_loss: 0.3409 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.34085 to 0.33790, saving model to best.model\n",
      "0s - loss: 0.3462 - acc: 0.8593 - val_loss: 0.3379 - val_acc: 0.8333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3440 - acc: 0.8574 - val_loss: 0.3389 - val_acc: 0.8333\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3555 - acc: 0.8370 - val_loss: 0.3402 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3158 - acc: 0.8741 - val_loss: 0.3416 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.33790 to 0.33788, saving model to best.model\n",
      "0s - loss: 0.3153 - acc: 0.8722 - val_loss: 0.3379 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.33788 to 0.33505, saving model to best.model\n",
      "0s - loss: 0.3106 - acc: 0.8685 - val_loss: 0.3350 - val_acc: 0.8333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.33505 to 0.33241, saving model to best.model\n",
      "0s - loss: 0.3352 - acc: 0.8685 - val_loss: 0.3324 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.33241 to 0.32921, saving model to best.model\n",
      "0s - loss: 0.3106 - acc: 0.8685 - val_loss: 0.3292 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.32921 to 0.32732, saving model to best.model\n",
      "0s - loss: 0.2937 - acc: 0.8722 - val_loss: 0.3273 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.32732 to 0.32710, saving model to best.model\n",
      "0s - loss: 0.3120 - acc: 0.8833 - val_loss: 0.3271 - val_acc: 0.8500\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3118 - acc: 0.8759 - val_loss: 0.3294 - val_acc: 0.8500\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3195 - acc: 0.8648 - val_loss: 0.3353 - val_acc: 0.8333\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3220 - acc: 0.8667 - val_loss: 0.3368 - val_acc: 0.8333\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3181 - acc: 0.8704 - val_loss: 0.3346 - val_acc: 0.8167\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3160 - acc: 0.8389 - val_loss: 0.3323 - val_acc: 0.8500\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3149 - acc: 0.8611 - val_loss: 0.3288 - val_acc: 0.8500\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.2883 - acc: 0.8796 - val_loss: 0.3278 - val_acc: 0.8500\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.2855 - acc: 0.8852 - val_loss: 0.3285 - val_acc: 0.8500\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.2802 - acc: 0.8759 - val_loss: 0.3306 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.2844 - acc: 0.8759 - val_loss: 0.3327 - val_acc: 0.8500\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.2878 - acc: 0.8778 - val_loss: 0.3334 - val_acc: 0.8167\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.2524 - acc: 0.8981 - val_loss: 0.3318 - val_acc: 0.8333\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2783 - acc: 0.8815 - val_loss: 0.3349 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3071 - acc: 0.8574 - val_loss: 0.3402 - val_acc: 0.8333\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.2803 - acc: 0.8889 - val_loss: 0.3432 - val_acc: 0.8333\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3014 - acc: 0.8722 - val_loss: 0.3426 - val_acc: 0.8333\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2938 - acc: 0.8870 - val_loss: 0.3392 - val_acc: 0.8333\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3001 - acc: 0.8685 - val_loss: 0.3410 - val_acc: 0.8333\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2874 - acc: 0.8741 - val_loss: 0.3483 - val_acc: 0.8333\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2854 - acc: 0.8796 - val_loss: 0.3533 - val_acc: 0.8167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2938 - acc: 0.8796 - val_loss: 0.3543 - val_acc: 0.8167\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2701 - acc: 0.8778 - val_loss: 0.3535 - val_acc: 0.8333\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2703 - acc: 0.8926 - val_loss: 0.3482 - val_acc: 0.8333\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2818 - acc: 0.8759 - val_loss: 0.3408 - val_acc: 0.8333\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2795 - acc: 0.8815 - val_loss: 0.3399 - val_acc: 0.8333\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3170 - acc: 0.8722 - val_loss: 0.3412 - val_acc: 0.8333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.52625, saving model to best.model\n",
      "0s - loss: 0.8817 - acc: 0.5093 - val_loss: 0.5263 - val_acc: 0.7500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.52625 to 0.52057, saving model to best.model\n",
      "0s - loss: 0.7784 - acc: 0.6296 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7720 - acc: 0.6463 - val_loss: 0.5262 - val_acc: 0.7500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6906 - acc: 0.6759 - val_loss: 0.5405 - val_acc: 0.7500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.7064 - acc: 0.6352 - val_loss: 0.5601 - val_acc: 0.7500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6619 - acc: 0.6130 - val_loss: 0.5683 - val_acc: 0.7500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6558 - acc: 0.6519 - val_loss: 0.5662 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6517 - acc: 0.6426 - val_loss: 0.5602 - val_acc: 0.7500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6226 - acc: 0.6426 - val_loss: 0.5554 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6187 - acc: 0.6667 - val_loss: 0.5541 - val_acc: 0.7500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6094 - acc: 0.6648 - val_loss: 0.5560 - val_acc: 0.7500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6293 - acc: 0.6611 - val_loss: 0.5621 - val_acc: 0.7833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5974 - acc: 0.6704 - val_loss: 0.5640 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6212 - acc: 0.6685 - val_loss: 0.5608 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.6132 - acc: 0.6704 - val_loss: 0.5545 - val_acc: 0.7667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6303 - acc: 0.6537 - val_loss: 0.5468 - val_acc: 0.7667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5999 - acc: 0.6778 - val_loss: 0.5434 - val_acc: 0.7667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5805 - acc: 0.7019 - val_loss: 0.5415 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.6065 - acc: 0.6722 - val_loss: 0.5363 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5901 - acc: 0.6796 - val_loss: 0.5320 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5794 - acc: 0.6963 - val_loss: 0.5293 - val_acc: 0.8000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5634 - acc: 0.6889 - val_loss: 0.5305 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5865 - acc: 0.6944 - val_loss: 0.5341 - val_acc: 0.8167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5896 - acc: 0.6815 - val_loss: 0.5372 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5688 - acc: 0.7019 - val_loss: 0.5400 - val_acc: 0.8333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5647 - acc: 0.7037 - val_loss: 0.5367 - val_acc: 0.8333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5567 - acc: 0.7241 - val_loss: 0.5317 - val_acc: 0.8167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5713 - acc: 0.6944 - val_loss: 0.5318 - val_acc: 0.8333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.73472, saving model to best.model\n",
      "0s - loss: 1.0014 - acc: 0.4722 - val_loss: 0.7347 - val_acc: 0.6167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.8175 - acc: 0.6222 - val_loss: 0.7959 - val_acc: 0.6167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7665 - acc: 0.6704 - val_loss: 0.7421 - val_acc: 0.6167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.73472 to 0.67677, saving model to best.model\n",
      "0s - loss: 0.6959 - acc: 0.6852 - val_loss: 0.6768 - val_acc: 0.6167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.67677 to 0.64189, saving model to best.model\n",
      "0s - loss: 0.6702 - acc: 0.6852 - val_loss: 0.6419 - val_acc: 0.6167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.64189 to 0.62819, saving model to best.model\n",
      "0s - loss: 0.6597 - acc: 0.6741 - val_loss: 0.6282 - val_acc: 0.6500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.62819 to 0.62543, saving model to best.model\n",
      "0s - loss: 0.6455 - acc: 0.6648 - val_loss: 0.6254 - val_acc: 0.6500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6269 - acc: 0.6833 - val_loss: 0.6270 - val_acc: 0.6500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6372 - acc: 0.6778 - val_loss: 0.6285 - val_acc: 0.6500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6195 - acc: 0.6907 - val_loss: 0.6285 - val_acc: 0.6500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6320 - acc: 0.6611 - val_loss: 0.6276 - val_acc: 0.6500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6029 - acc: 0.7074 - val_loss: 0.6265 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5879 - acc: 0.7204 - val_loss: 0.6260 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5574 - acc: 0.7130 - val_loss: 0.6254 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5901 - acc: 0.7037 - val_loss: 0.6255 - val_acc: 0.6833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5550 - acc: 0.7111 - val_loss: 0.6263 - val_acc: 0.6833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5630 - acc: 0.7426 - val_loss: 0.6255 - val_acc: 0.6833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.62543 to 0.62399, saving model to best.model\n",
      "0s - loss: 0.5639 - acc: 0.7148 - val_loss: 0.6240 - val_acc: 0.6833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.62399 to 0.62339, saving model to best.model\n",
      "0s - loss: 0.5673 - acc: 0.7167 - val_loss: 0.6234 - val_acc: 0.6833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.62339 to 0.62332, saving model to best.model\n",
      "0s - loss: 0.5484 - acc: 0.7259 - val_loss: 0.6233 - val_acc: 0.6833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.62332 to 0.62182, saving model to best.model\n",
      "0s - loss: 0.5401 - acc: 0.7111 - val_loss: 0.6218 - val_acc: 0.6833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.62182 to 0.61964, saving model to best.model\n",
      "0s - loss: 0.5418 - acc: 0.7370 - val_loss: 0.6196 - val_acc: 0.6667\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.61964 to 0.61851, saving model to best.model\n",
      "0s - loss: 0.5086 - acc: 0.7574 - val_loss: 0.6185 - val_acc: 0.6500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.61851 to 0.61842, saving model to best.model\n",
      "0s - loss: 0.5407 - acc: 0.7333 - val_loss: 0.6184 - val_acc: 0.6333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5328 - acc: 0.7389 - val_loss: 0.6187 - val_acc: 0.6333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5618 - acc: 0.7296 - val_loss: 0.6200 - val_acc: 0.6333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5392 - acc: 0.7296 - val_loss: 0.6201 - val_acc: 0.6333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5208 - acc: 0.7481 - val_loss: 0.6185 - val_acc: 0.6333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.61842 to 0.61668, saving model to best.model\n",
      "0s - loss: 0.5071 - acc: 0.7667 - val_loss: 0.6167 - val_acc: 0.6333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.61668 to 0.61667, saving model to best.model\n",
      "0s - loss: 0.5236 - acc: 0.7389 - val_loss: 0.6167 - val_acc: 0.6167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.61667 to 0.61648, saving model to best.model\n",
      "0s - loss: 0.5199 - acc: 0.7574 - val_loss: 0.6165 - val_acc: 0.6167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.61648 to 0.61528, saving model to best.model\n",
      "0s - loss: 0.5129 - acc: 0.7630 - val_loss: 0.6153 - val_acc: 0.6167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.61528 to 0.61423, saving model to best.model\n",
      "0s - loss: 0.5217 - acc: 0.7463 - val_loss: 0.6142 - val_acc: 0.6167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5142 - acc: 0.7556 - val_loss: 0.6151 - val_acc: 0.6333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5250 - acc: 0.7463 - val_loss: 0.6153 - val_acc: 0.6333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5116 - acc: 0.7333 - val_loss: 0.6147 - val_acc: 0.6333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5114 - acc: 0.7667 - val_loss: 0.6146 - val_acc: 0.6333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.61423 to 0.61262, saving model to best.model\n",
      "0s - loss: 0.5355 - acc: 0.7463 - val_loss: 0.6126 - val_acc: 0.6500\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.61262 to 0.61020, saving model to best.model\n",
      "0s - loss: 0.5371 - acc: 0.7611 - val_loss: 0.6102 - val_acc: 0.6500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.61020 to 0.60887, saving model to best.model\n",
      "0s - loss: 0.5285 - acc: 0.7481 - val_loss: 0.6089 - val_acc: 0.6500\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.60887 to 0.60809, saving model to best.model\n",
      "0s - loss: 0.4972 - acc: 0.7759 - val_loss: 0.6081 - val_acc: 0.6333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.60809 to 0.60627, saving model to best.model\n",
      "0s - loss: 0.5352 - acc: 0.7407 - val_loss: 0.6063 - val_acc: 0.6333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.60627 to 0.60337, saving model to best.model\n",
      "0s - loss: 0.5037 - acc: 0.7704 - val_loss: 0.6034 - val_acc: 0.6500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.60337 to 0.60167, saving model to best.model\n",
      "0s - loss: 0.4914 - acc: 0.7667 - val_loss: 0.6017 - val_acc: 0.6500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.60167 to 0.60086, saving model to best.model\n",
      "0s - loss: 0.4976 - acc: 0.7759 - val_loss: 0.6009 - val_acc: 0.6667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.60086 to 0.60048, saving model to best.model\n",
      "0s - loss: 0.4984 - acc: 0.7519 - val_loss: 0.6005 - val_acc: 0.6667\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.60048 to 0.60043, saving model to best.model\n",
      "0s - loss: 0.4907 - acc: 0.7833 - val_loss: 0.6004 - val_acc: 0.6667\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.60043 to 0.60043, saving model to best.model\n",
      "0s - loss: 0.5024 - acc: 0.7667 - val_loss: 0.6004 - val_acc: 0.6667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.60043 to 0.59899, saving model to best.model\n",
      "0s - loss: 0.4935 - acc: 0.7778 - val_loss: 0.5990 - val_acc: 0.6667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.59899 to 0.59757, saving model to best.model\n",
      "0s - loss: 0.4848 - acc: 0.7611 - val_loss: 0.5976 - val_acc: 0.6667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.59757 to 0.59618, saving model to best.model\n",
      "0s - loss: 0.4843 - acc: 0.7685 - val_loss: 0.5962 - val_acc: 0.6667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.59618 to 0.59443, saving model to best.model\n",
      "0s - loss: 0.4972 - acc: 0.7685 - val_loss: 0.5944 - val_acc: 0.6667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.59443 to 0.59355, saving model to best.model\n",
      "0s - loss: 0.4858 - acc: 0.7796 - val_loss: 0.5935 - val_acc: 0.6500\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.59355 to 0.59329, saving model to best.model\n",
      "0s - loss: 0.4820 - acc: 0.7704 - val_loss: 0.5933 - val_acc: 0.6500\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.59329 to 0.59233, saving model to best.model\n",
      "0s - loss: 0.4869 - acc: 0.7685 - val_loss: 0.5923 - val_acc: 0.6500\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.59233 to 0.58999, saving model to best.model\n",
      "0s - loss: 0.5114 - acc: 0.7537 - val_loss: 0.5900 - val_acc: 0.6500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.58999 to 0.58746, saving model to best.model\n",
      "0s - loss: 0.4670 - acc: 0.7907 - val_loss: 0.5875 - val_acc: 0.6500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.58746 to 0.58568, saving model to best.model\n",
      "0s - loss: 0.4697 - acc: 0.7963 - val_loss: 0.5857 - val_acc: 0.6500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.58568 to 0.58485, saving model to best.model\n",
      "0s - loss: 0.4874 - acc: 0.7611 - val_loss: 0.5849 - val_acc: 0.6500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4718 - acc: 0.7741 - val_loss: 0.5854 - val_acc: 0.6667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.58485 to 0.58441, saving model to best.model\n",
      "0s - loss: 0.4806 - acc: 0.7833 - val_loss: 0.5844 - val_acc: 0.6500\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.58441 to 0.58165, saving model to best.model\n",
      "0s - loss: 0.4824 - acc: 0.7796 - val_loss: 0.5817 - val_acc: 0.6667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.58165 to 0.57951, saving model to best.model\n",
      "0s - loss: 0.4818 - acc: 0.7889 - val_loss: 0.5795 - val_acc: 0.6500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.57951 to 0.57861, saving model to best.model\n",
      "0s - loss: 0.4722 - acc: 0.7852 - val_loss: 0.5786 - val_acc: 0.6500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4735 - acc: 0.7741 - val_loss: 0.5802 - val_acc: 0.6500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4765 - acc: 0.7759 - val_loss: 0.5824 - val_acc: 0.6500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4766 - acc: 0.7759 - val_loss: 0.5845 - val_acc: 0.6667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4930 - acc: 0.7593 - val_loss: 0.5844 - val_acc: 0.6667\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4607 - acc: 0.7852 - val_loss: 0.5813 - val_acc: 0.6500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4607 - acc: 0.7833 - val_loss: 0.5789 - val_acc: 0.6500\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4731 - acc: 0.7815 - val_loss: 0.5795 - val_acc: 0.6500\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4593 - acc: 0.8130 - val_loss: 0.5804 - val_acc: 0.6500\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4762 - acc: 0.8185 - val_loss: 0.5803 - val_acc: 0.6500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4622 - acc: 0.7815 - val_loss: 0.5805 - val_acc: 0.6667\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4599 - acc: 0.7963 - val_loss: 0.5802 - val_acc: 0.6667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4783 - acc: 0.7907 - val_loss: 0.5806 - val_acc: 0.6667\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4685 - acc: 0.7889 - val_loss: 0.5814 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4478 - acc: 0.8056 - val_loss: 0.5814 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4529 - acc: 0.7963 - val_loss: 0.5804 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4457 - acc: 0.7852 - val_loss: 0.5800 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4343 - acc: 0.8019 - val_loss: 0.5798 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4468 - acc: 0.7889 - val_loss: 0.5797 - val_acc: 0.6667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.57861 to 0.57786, saving model to best.model\n",
      "0s - loss: 0.4629 - acc: 0.7907 - val_loss: 0.5779 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4442 - acc: 0.8037 - val_loss: 0.5784 - val_acc: 0.6667\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4551 - acc: 0.7870 - val_loss: 0.5790 - val_acc: 0.6667\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.57786 to 0.57784, saving model to best.model\n",
      "0s - loss: 0.4479 - acc: 0.8130 - val_loss: 0.5778 - val_acc: 0.6500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.57784 to 0.57579, saving model to best.model\n",
      "0s - loss: 0.4661 - acc: 0.7907 - val_loss: 0.5758 - val_acc: 0.6500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.57579 to 0.57365, saving model to best.model\n",
      "0s - loss: 0.4482 - acc: 0.7815 - val_loss: 0.5736 - val_acc: 0.6500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.57365 to 0.57161, saving model to best.model\n",
      "0s - loss: 0.4457 - acc: 0.7889 - val_loss: 0.5716 - val_acc: 0.6500\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.57161 to 0.57011, saving model to best.model\n",
      "0s - loss: 0.4377 - acc: 0.8130 - val_loss: 0.5701 - val_acc: 0.6500\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.57011 to 0.56816, saving model to best.model\n",
      "0s - loss: 0.4454 - acc: 0.8037 - val_loss: 0.5682 - val_acc: 0.6500\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.56816 to 0.56628, saving model to best.model\n",
      "0s - loss: 0.4536 - acc: 0.7944 - val_loss: 0.5663 - val_acc: 0.6500\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.56628 to 0.56542, saving model to best.model\n",
      "0s - loss: 0.4488 - acc: 0.8019 - val_loss: 0.5654 - val_acc: 0.6500\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.56542 to 0.56516, saving model to best.model\n",
      "0s - loss: 0.4319 - acc: 0.8111 - val_loss: 0.5652 - val_acc: 0.6500\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4357 - acc: 0.8130 - val_loss: 0.5655 - val_acc: 0.6500\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4259 - acc: 0.8037 - val_loss: 0.5659 - val_acc: 0.6500\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4363 - acc: 0.8111 - val_loss: 0.5659 - val_acc: 0.6500\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4261 - acc: 0.7981 - val_loss: 0.5662 - val_acc: 0.6500\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4129 - acc: 0.8185 - val_loss: 0.5671 - val_acc: 0.6500\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4300 - acc: 0.8056 - val_loss: 0.5677 - val_acc: 0.6500\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4267 - acc: 0.8056 - val_loss: 0.5681 - val_acc: 0.6500\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4283 - acc: 0.8037 - val_loss: 0.5677 - val_acc: 0.6500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4259 - acc: 0.8093 - val_loss: 0.5666 - val_acc: 0.6333\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.56516 to 0.56474, saving model to best.model\n",
      "0s - loss: 0.4377 - acc: 0.8130 - val_loss: 0.5647 - val_acc: 0.6333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.56474 to 0.56407, saving model to best.model\n",
      "0s - loss: 0.4174 - acc: 0.8093 - val_loss: 0.5641 - val_acc: 0.6333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.56407 to 0.56361, saving model to best.model\n",
      "0s - loss: 0.4363 - acc: 0.8148 - val_loss: 0.5636 - val_acc: 0.6333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.56361 to 0.56186, saving model to best.model\n",
      "0s - loss: 0.4368 - acc: 0.8093 - val_loss: 0.5619 - val_acc: 0.6333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.56186 to 0.56119, saving model to best.model\n",
      "0s - loss: 0.4197 - acc: 0.8093 - val_loss: 0.5612 - val_acc: 0.6333\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.56119 to 0.55968, saving model to best.model\n",
      "0s - loss: 0.4187 - acc: 0.8056 - val_loss: 0.5597 - val_acc: 0.6333\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.55968 to 0.55845, saving model to best.model\n",
      "0s - loss: 0.4488 - acc: 0.8111 - val_loss: 0.5584 - val_acc: 0.6333\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.55845 to 0.55649, saving model to best.model\n",
      "0s - loss: 0.4086 - acc: 0.8000 - val_loss: 0.5565 - val_acc: 0.6333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.55649 to 0.55500, saving model to best.model\n",
      "0s - loss: 0.4268 - acc: 0.8056 - val_loss: 0.5550 - val_acc: 0.6333\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.4017 - acc: 0.8278 - val_loss: 0.5552 - val_acc: 0.6333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4018 - acc: 0.8019 - val_loss: 0.5557 - val_acc: 0.6333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4164 - acc: 0.8037 - val_loss: 0.5567 - val_acc: 0.6333\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4191 - acc: 0.8111 - val_loss: 0.5572 - val_acc: 0.6333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.4276 - acc: 0.8000 - val_loss: 0.5576 - val_acc: 0.6333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.4234 - acc: 0.8056 - val_loss: 0.5579 - val_acc: 0.6333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3963 - acc: 0.8185 - val_loss: 0.5579 - val_acc: 0.6333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3858 - acc: 0.8222 - val_loss: 0.5588 - val_acc: 0.6500\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3970 - acc: 0.8204 - val_loss: 0.5585 - val_acc: 0.6500\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3927 - acc: 0.8093 - val_loss: 0.5576 - val_acc: 0.6333\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.55500 to 0.55401, saving model to best.model\n",
      "0s - loss: 0.4086 - acc: 0.8111 - val_loss: 0.5540 - val_acc: 0.6500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.55401 to 0.54928, saving model to best.model\n",
      "0s - loss: 0.3961 - acc: 0.8167 - val_loss: 0.5493 - val_acc: 0.6333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.54928 to 0.54673, saving model to best.model\n",
      "0s - loss: 0.4186 - acc: 0.8056 - val_loss: 0.5467 - val_acc: 0.6333\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.54673 to 0.54243, saving model to best.model\n",
      "0s - loss: 0.3899 - acc: 0.8148 - val_loss: 0.5424 - val_acc: 0.6333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.54243 to 0.53966, saving model to best.model\n",
      "0s - loss: 0.3934 - acc: 0.8315 - val_loss: 0.5397 - val_acc: 0.6333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.53966 to 0.53892, saving model to best.model\n",
      "0s - loss: 0.3788 - acc: 0.8241 - val_loss: 0.5389 - val_acc: 0.6500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.53892 to 0.53839, saving model to best.model\n",
      "0s - loss: 0.3964 - acc: 0.8167 - val_loss: 0.5384 - val_acc: 0.6500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.53839 to 0.53815, saving model to best.model\n",
      "0s - loss: 0.3864 - acc: 0.8222 - val_loss: 0.5381 - val_acc: 0.6500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.53815 to 0.53783, saving model to best.model\n",
      "0s - loss: 0.4018 - acc: 0.8093 - val_loss: 0.5378 - val_acc: 0.6667\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.4010 - acc: 0.8167 - val_loss: 0.5393 - val_acc: 0.6667\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3870 - acc: 0.8204 - val_loss: 0.5420 - val_acc: 0.6500\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3997 - acc: 0.8130 - val_loss: 0.5442 - val_acc: 0.6500\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3762 - acc: 0.8204 - val_loss: 0.5479 - val_acc: 0.6500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3742 - acc: 0.8278 - val_loss: 0.5523 - val_acc: 0.6833\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3714 - acc: 0.8537 - val_loss: 0.5563 - val_acc: 0.6667\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3773 - acc: 0.8185 - val_loss: 0.5583 - val_acc: 0.6667\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3849 - acc: 0.8315 - val_loss: 0.5562 - val_acc: 0.6667\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3615 - acc: 0.8259 - val_loss: 0.5504 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3763 - acc: 0.8370 - val_loss: 0.5464 - val_acc: 0.6667\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3859 - acc: 0.8185 - val_loss: 0.5425 - val_acc: 0.6833\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3913 - acc: 0.8370 - val_loss: 0.5378 - val_acc: 0.6833\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.53783 to 0.53446, saving model to best.model\n",
      "0s - loss: 0.3811 - acc: 0.8333 - val_loss: 0.5345 - val_acc: 0.6833\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.53446 to 0.53071, saving model to best.model\n",
      "0s - loss: 0.3553 - acc: 0.8500 - val_loss: 0.5307 - val_acc: 0.7000\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.53071 to 0.52805, saving model to best.model\n",
      "0s - loss: 0.3643 - acc: 0.8333 - val_loss: 0.5281 - val_acc: 0.7000\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.52805 to 0.52727, saving model to best.model\n",
      "0s - loss: 0.3811 - acc: 0.8389 - val_loss: 0.5273 - val_acc: 0.7000\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3778 - acc: 0.8389 - val_loss: 0.5282 - val_acc: 0.7167\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3605 - acc: 0.8333 - val_loss: 0.5301 - val_acc: 0.7167\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3591 - acc: 0.8389 - val_loss: 0.5343 - val_acc: 0.7167\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3556 - acc: 0.8407 - val_loss: 0.5397 - val_acc: 0.7333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3710 - acc: 0.8352 - val_loss: 0.5461 - val_acc: 0.7167\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3768 - acc: 0.8407 - val_loss: 0.5507 - val_acc: 0.7167\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3732 - acc: 0.8352 - val_loss: 0.5594 - val_acc: 0.7000\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3802 - acc: 0.8222 - val_loss: 0.5670 - val_acc: 0.6500\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3498 - acc: 0.8315 - val_loss: 0.5651 - val_acc: 0.6667\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3431 - acc: 0.8407 - val_loss: 0.5605 - val_acc: 0.7000\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3656 - acc: 0.8278 - val_loss: 0.5581 - val_acc: 0.7000\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3549 - acc: 0.8444 - val_loss: 0.5533 - val_acc: 0.6833\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3417 - acc: 0.8463 - val_loss: 0.5457 - val_acc: 0.6667\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3380 - acc: 0.8556 - val_loss: 0.5411 - val_acc: 0.6833\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3659 - acc: 0.8407 - val_loss: 0.5402 - val_acc: 0.6833\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3383 - acc: 0.8556 - val_loss: 0.5407 - val_acc: 0.7000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3533 - acc: 0.8407 - val_loss: 0.5409 - val_acc: 0.7167\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3371 - acc: 0.8481 - val_loss: 0.5439 - val_acc: 0.7167\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3505 - acc: 0.8333 - val_loss: 0.5468 - val_acc: 0.7333\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3257 - acc: 0.8630 - val_loss: 0.5493 - val_acc: 0.7500\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3553 - acc: 0.8389 - val_loss: 0.5490 - val_acc: 0.7500\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3569 - acc: 0.8333 - val_loss: 0.5454 - val_acc: 0.7333\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3276 - acc: 0.8630 - val_loss: 0.5370 - val_acc: 0.7167\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.3284 - acc: 0.8611 - val_loss: 0.5338 - val_acc: 0.7167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3570 - acc: 0.8500 - val_loss: 0.5330 - val_acc: 0.7167\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3572 - acc: 0.8500 - val_loss: 0.5326 - val_acc: 0.7333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.51560, saving model to best.model\n",
      "0s - loss: 0.8015 - acc: 0.5741 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.51560 to 0.50705, saving model to best.model\n",
      "0s - loss: 0.7864 - acc: 0.6593 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.50705 to 0.50515, saving model to best.model\n",
      "0s - loss: 0.7314 - acc: 0.6537 - val_loss: 0.5051 - val_acc: 0.7500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.7071 - acc: 0.6426 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6639 - acc: 0.6648 - val_loss: 0.5236 - val_acc: 0.8000\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6478 - acc: 0.6463 - val_loss: 0.5269 - val_acc: 0.8000\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6140 - acc: 0.6278 - val_loss: 0.5143 - val_acc: 0.8000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.50515 to 0.49964, saving model to best.model\n",
      "0s - loss: 0.6200 - acc: 0.6648 - val_loss: 0.4996 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.49964 to 0.48762, saving model to best.model\n",
      "0s - loss: 0.6070 - acc: 0.6648 - val_loss: 0.4876 - val_acc: 0.8000\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.48762 to 0.47748, saving model to best.model\n",
      "0s - loss: 0.6113 - acc: 0.6685 - val_loss: 0.4775 - val_acc: 0.8167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.47748 to 0.47303, saving model to best.model\n",
      "0s - loss: 0.6171 - acc: 0.6667 - val_loss: 0.4730 - val_acc: 0.8333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.47303 to 0.47197, saving model to best.model\n",
      "0s - loss: 0.5838 - acc: 0.6963 - val_loss: 0.4720 - val_acc: 0.8333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5823 - acc: 0.6944 - val_loss: 0.4751 - val_acc: 0.8500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5790 - acc: 0.7056 - val_loss: 0.4778 - val_acc: 0.8667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5535 - acc: 0.6981 - val_loss: 0.4786 - val_acc: 0.8667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5494 - acc: 0.6889 - val_loss: 0.4741 - val_acc: 0.8500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.47197 to 0.46637, saving model to best.model\n",
      "0s - loss: 0.5459 - acc: 0.7167 - val_loss: 0.4664 - val_acc: 0.8500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.46637 to 0.45983, saving model to best.model\n",
      "0s - loss: 0.5767 - acc: 0.7056 - val_loss: 0.4598 - val_acc: 0.8500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.45983 to 0.45731, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7000 - val_loss: 0.4573 - val_acc: 0.8500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.45731 to 0.45582, saving model to best.model\n",
      "0s - loss: 0.5483 - acc: 0.7278 - val_loss: 0.4558 - val_acc: 0.8500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.45582 to 0.45507, saving model to best.model\n",
      "0s - loss: 0.5355 - acc: 0.7222 - val_loss: 0.4551 - val_acc: 0.8500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5368 - acc: 0.7130 - val_loss: 0.4572 - val_acc: 0.8333\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5423 - acc: 0.6815 - val_loss: 0.4615 - val_acc: 0.8333\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5522 - acc: 0.7241 - val_loss: 0.4645 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5335 - acc: 0.7259 - val_loss: 0.4684 - val_acc: 0.7667\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5393 - acc: 0.7259 - val_loss: 0.4666 - val_acc: 0.7667\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5362 - acc: 0.7333 - val_loss: 0.4618 - val_acc: 0.7667\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.45507 to 0.45477, saving model to best.model\n",
      "0s - loss: 0.5211 - acc: 0.7352 - val_loss: 0.4548 - val_acc: 0.7667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.45477 to 0.44534, saving model to best.model\n",
      "0s - loss: 0.5047 - acc: 0.7444 - val_loss: 0.4453 - val_acc: 0.8000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.44534 to 0.43889, saving model to best.model\n",
      "0s - loss: 0.5193 - acc: 0.7426 - val_loss: 0.4389 - val_acc: 0.8333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.43889 to 0.43625, saving model to best.model\n",
      "0s - loss: 0.5102 - acc: 0.7463 - val_loss: 0.4363 - val_acc: 0.8333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.43625 to 0.43510, saving model to best.model\n",
      "0s - loss: 0.5003 - acc: 0.7444 - val_loss: 0.4351 - val_acc: 0.8167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.43510 to 0.43380, saving model to best.model\n",
      "0s - loss: 0.5067 - acc: 0.7537 - val_loss: 0.4338 - val_acc: 0.8167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.43380 to 0.43182, saving model to best.model\n",
      "0s - loss: 0.4939 - acc: 0.7556 - val_loss: 0.4318 - val_acc: 0.8167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.43182 to 0.42997, saving model to best.model\n",
      "0s - loss: 0.5466 - acc: 0.7222 - val_loss: 0.4300 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.42997 to 0.42772, saving model to best.model\n",
      "0s - loss: 0.5030 - acc: 0.7537 - val_loss: 0.4277 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.42772 to 0.42460, saving model to best.model\n",
      "0s - loss: 0.5159 - acc: 0.7426 - val_loss: 0.4246 - val_acc: 0.8333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.42460 to 0.41990, saving model to best.model\n",
      "0s - loss: 0.5010 - acc: 0.7500 - val_loss: 0.4199 - val_acc: 0.8333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.41990 to 0.41618, saving model to best.model\n",
      "0s - loss: 0.4713 - acc: 0.7556 - val_loss: 0.4162 - val_acc: 0.8333\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.41618 to 0.41536, saving model to best.model\n",
      "0s - loss: 0.5150 - acc: 0.7389 - val_loss: 0.4154 - val_acc: 0.8333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4936 - acc: 0.7556 - val_loss: 0.4170 - val_acc: 0.8333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5014 - acc: 0.7630 - val_loss: 0.4204 - val_acc: 0.8333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4810 - acc: 0.7574 - val_loss: 0.4270 - val_acc: 0.8167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5193 - acc: 0.7519 - val_loss: 0.4368 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4932 - acc: 0.7519 - val_loss: 0.4383 - val_acc: 0.8000\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4815 - acc: 0.7796 - val_loss: 0.4311 - val_acc: 0.8167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4846 - acc: 0.7611 - val_loss: 0.4235 - val_acc: 0.8333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4960 - acc: 0.7648 - val_loss: 0.4172 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.41536 to 0.41533, saving model to best.model\n",
      "0s - loss: 0.4949 - acc: 0.7519 - val_loss: 0.4153 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4780 - acc: 0.7704 - val_loss: 0.4168 - val_acc: 0.8167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4692 - acc: 0.7685 - val_loss: 0.4183 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4684 - acc: 0.7685 - val_loss: 0.4183 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4716 - acc: 0.7741 - val_loss: 0.4199 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4476 - acc: 0.7889 - val_loss: 0.4188 - val_acc: 0.8000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4790 - acc: 0.7574 - val_loss: 0.4171 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4579 - acc: 0.7741 - val_loss: 0.4177 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4612 - acc: 0.7722 - val_loss: 0.4178 - val_acc: 0.8000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4685 - acc: 0.7685 - val_loss: 0.4160 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.41533 to 0.41435, saving model to best.model\n",
      "0s - loss: 0.4813 - acc: 0.7611 - val_loss: 0.4144 - val_acc: 0.8167\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.41435 to 0.41214, saving model to best.model\n",
      "0s - loss: 0.4550 - acc: 0.7759 - val_loss: 0.4121 - val_acc: 0.8333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.41214 to 0.41165, saving model to best.model\n",
      "0s - loss: 0.4434 - acc: 0.8000 - val_loss: 0.4116 - val_acc: 0.8333\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4678 - acc: 0.7593 - val_loss: 0.4146 - val_acc: 0.8167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4466 - acc: 0.7667 - val_loss: 0.4179 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4452 - acc: 0.7963 - val_loss: 0.4185 - val_acc: 0.8000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4667 - acc: 0.7667 - val_loss: 0.4187 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4491 - acc: 0.7907 - val_loss: 0.4174 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4576 - acc: 0.7852 - val_loss: 0.4161 - val_acc: 0.8167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4512 - acc: 0.7759 - val_loss: 0.4155 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4636 - acc: 0.7926 - val_loss: 0.4132 - val_acc: 0.8167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.41165 to 0.41155, saving model to best.model\n",
      "0s - loss: 0.4562 - acc: 0.7889 - val_loss: 0.4115 - val_acc: 0.8167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.41155 to 0.41149, saving model to best.model\n",
      "0s - loss: 0.4563 - acc: 0.7722 - val_loss: 0.4115 - val_acc: 0.8167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.41149 to 0.40906, saving model to best.model\n",
      "0s - loss: 0.4541 - acc: 0.7870 - val_loss: 0.4091 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.40906 to 0.40681, saving model to best.model\n",
      "0s - loss: 0.4365 - acc: 0.7889 - val_loss: 0.4068 - val_acc: 0.8167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.40681 to 0.40368, saving model to best.model\n",
      "0s - loss: 0.4245 - acc: 0.7815 - val_loss: 0.4037 - val_acc: 0.8167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.40368 to 0.40160, saving model to best.model\n",
      "0s - loss: 0.4127 - acc: 0.8130 - val_loss: 0.4016 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.40160 to 0.40098, saving model to best.model\n",
      "0s - loss: 0.4339 - acc: 0.8000 - val_loss: 0.4010 - val_acc: 0.8167\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.40098 to 0.40023, saving model to best.model\n",
      "0s - loss: 0.4412 - acc: 0.7852 - val_loss: 0.4002 - val_acc: 0.8167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4609 - acc: 0.7778 - val_loss: 0.4014 - val_acc: 0.8167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4237 - acc: 0.7889 - val_loss: 0.4035 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4195 - acc: 0.8037 - val_loss: 0.4048 - val_acc: 0.7833\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4158 - acc: 0.7963 - val_loss: 0.4082 - val_acc: 0.7833\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4362 - acc: 0.7981 - val_loss: 0.4089 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4272 - acc: 0.8167 - val_loss: 0.4084 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4596 - acc: 0.7889 - val_loss: 0.4065 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4214 - acc: 0.8093 - val_loss: 0.4059 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4181 - acc: 0.7944 - val_loss: 0.4014 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.40023 to 0.39528, saving model to best.model\n",
      "0s - loss: 0.4176 - acc: 0.8241 - val_loss: 0.3953 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.39528 to 0.39063, saving model to best.model\n",
      "0s - loss: 0.4270 - acc: 0.8130 - val_loss: 0.3906 - val_acc: 0.8167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.39063 to 0.38829, saving model to best.model\n",
      "0s - loss: 0.4133 - acc: 0.8000 - val_loss: 0.3883 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.38829 to 0.38673, saving model to best.model\n",
      "0s - loss: 0.4123 - acc: 0.8000 - val_loss: 0.3867 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4188 - acc: 0.8000 - val_loss: 0.3886 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4246 - acc: 0.8185 - val_loss: 0.3899 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4076 - acc: 0.8167 - val_loss: 0.3874 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.38673 to 0.38598, saving model to best.model\n",
      "0s - loss: 0.3929 - acc: 0.8333 - val_loss: 0.3860 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4105 - acc: 0.8315 - val_loss: 0.3913 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4391 - acc: 0.7981 - val_loss: 0.4001 - val_acc: 0.7833\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4117 - acc: 0.8241 - val_loss: 0.3950 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.38598 to 0.37967, saving model to best.model\n",
      "0s - loss: 0.4052 - acc: 0.8111 - val_loss: 0.3797 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.37967 to 0.37335, saving model to best.model\n",
      "0s - loss: 0.4120 - acc: 0.7870 - val_loss: 0.3733 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3864 - acc: 0.8074 - val_loss: 0.3741 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3846 - acc: 0.8130 - val_loss: 0.3771 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3837 - acc: 0.7963 - val_loss: 0.3810 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3847 - acc: 0.8315 - val_loss: 0.3863 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3840 - acc: 0.8111 - val_loss: 0.3897 - val_acc: 0.7667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3644 - acc: 0.8259 - val_loss: 0.3902 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3874 - acc: 0.8148 - val_loss: 0.3916 - val_acc: 0.7667\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3900 - acc: 0.8148 - val_loss: 0.3851 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3749 - acc: 0.8278 - val_loss: 0.3759 - val_acc: 0.8167\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.37335 to 0.37103, saving model to best.model\n",
      "0s - loss: 0.3842 - acc: 0.8222 - val_loss: 0.3710 - val_acc: 0.8167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.37103 to 0.36887, saving model to best.model\n",
      "0s - loss: 0.3805 - acc: 0.8315 - val_loss: 0.3689 - val_acc: 0.8167\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.36887 to 0.36813, saving model to best.model\n",
      "0s - loss: 0.3776 - acc: 0.8241 - val_loss: 0.3681 - val_acc: 0.8167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3599 - acc: 0.8315 - val_loss: 0.3690 - val_acc: 0.7833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3767 - acc: 0.8315 - val_loss: 0.3700 - val_acc: 0.7833\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3804 - acc: 0.8296 - val_loss: 0.3682 - val_acc: 0.7833\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.36813 to 0.36589, saving model to best.model\n",
      "0s - loss: 0.3701 - acc: 0.8296 - val_loss: 0.3659 - val_acc: 0.7833\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.36589 to 0.36227, saving model to best.model\n",
      "0s - loss: 0.3710 - acc: 0.8222 - val_loss: 0.3623 - val_acc: 0.7833\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.36227 to 0.35758, saving model to best.model\n",
      "0s - loss: 0.3736 - acc: 0.8296 - val_loss: 0.3576 - val_acc: 0.7833\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3510 - acc: 0.8519 - val_loss: 0.3577 - val_acc: 0.8000\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3609 - acc: 0.8426 - val_loss: 0.3619 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3604 - acc: 0.8426 - val_loss: 0.3622 - val_acc: 0.8000\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3476 - acc: 0.8481 - val_loss: 0.3621 - val_acc: 0.8000\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3717 - acc: 0.8167 - val_loss: 0.3636 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3518 - acc: 0.8333 - val_loss: 0.3613 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.35758 to 0.35349, saving model to best.model\n",
      "0s - loss: 0.3559 - acc: 0.8407 - val_loss: 0.3535 - val_acc: 0.8000\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.35349 to 0.34818, saving model to best.model\n",
      "0s - loss: 0.3528 - acc: 0.8426 - val_loss: 0.3482 - val_acc: 0.8000\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.34818 to 0.34474, saving model to best.model\n",
      "0s - loss: 0.3469 - acc: 0.8537 - val_loss: 0.3447 - val_acc: 0.7833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.34474 to 0.34288, saving model to best.model\n",
      "0s - loss: 0.3537 - acc: 0.8296 - val_loss: 0.3429 - val_acc: 0.7833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.34288 to 0.34202, saving model to best.model\n",
      "0s - loss: 0.3519 - acc: 0.8593 - val_loss: 0.3420 - val_acc: 0.7833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.34202 to 0.34120, saving model to best.model\n",
      "0s - loss: 0.3613 - acc: 0.8333 - val_loss: 0.3412 - val_acc: 0.8000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.34120 to 0.33775, saving model to best.model\n",
      "0s - loss: 0.3516 - acc: 0.8444 - val_loss: 0.3378 - val_acc: 0.8000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.33775 to 0.33765, saving model to best.model\n",
      "0s - loss: 0.3470 - acc: 0.8574 - val_loss: 0.3376 - val_acc: 0.8000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3497 - acc: 0.8463 - val_loss: 0.3414 - val_acc: 0.8000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3688 - acc: 0.8204 - val_loss: 0.3411 - val_acc: 0.8000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.33765 to 0.33438, saving model to best.model\n",
      "0s - loss: 0.3444 - acc: 0.8519 - val_loss: 0.3344 - val_acc: 0.8167\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.33438 to 0.32787, saving model to best.model\n",
      "0s - loss: 0.3333 - acc: 0.8426 - val_loss: 0.3279 - val_acc: 0.8333\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3546 - acc: 0.8407 - val_loss: 0.3317 - val_acc: 0.8500\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3255 - acc: 0.8537 - val_loss: 0.3360 - val_acc: 0.8500\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3244 - acc: 0.8630 - val_loss: 0.3383 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3268 - acc: 0.8463 - val_loss: 0.3361 - val_acc: 0.8333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3303 - acc: 0.8481 - val_loss: 0.3311 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.32787 to 0.32565, saving model to best.model\n",
      "0s - loss: 0.2966 - acc: 0.8722 - val_loss: 0.3256 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.32565 to 0.32136, saving model to best.model\n",
      "0s - loss: 0.3340 - acc: 0.8685 - val_loss: 0.3214 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.32136 to 0.32092, saving model to best.model\n",
      "0s - loss: 0.3125 - acc: 0.8519 - val_loss: 0.3209 - val_acc: 0.8500\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.2949 - acc: 0.8685 - val_loss: 0.3237 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3216 - acc: 0.8593 - val_loss: 0.3262 - val_acc: 0.8500\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3076 - acc: 0.8704 - val_loss: 0.3274 - val_acc: 0.8667\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3279 - acc: 0.8463 - val_loss: 0.3289 - val_acc: 0.8833\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3267 - acc: 0.8519 - val_loss: 0.3300 - val_acc: 0.8500\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3369 - acc: 0.8407 - val_loss: 0.3311 - val_acc: 0.8333\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.2906 - acc: 0.8796 - val_loss: 0.3295 - val_acc: 0.8333\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3155 - acc: 0.8593 - val_loss: 0.3287 - val_acc: 0.8333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3191 - acc: 0.8537 - val_loss: 0.3298 - val_acc: 0.8333\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.2715 - acc: 0.8870 - val_loss: 0.3307 - val_acc: 0.8667\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3258 - acc: 0.8463 - val_loss: 0.3292 - val_acc: 0.8833\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3088 - acc: 0.8611 - val_loss: 0.3243 - val_acc: 0.8500\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2997 - acc: 0.8704 - val_loss: 0.3219 - val_acc: 0.8500\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3036 - acc: 0.8796 - val_loss: 0.3227 - val_acc: 0.8500\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3085 - acc: 0.8685 - val_loss: 0.3261 - val_acc: 0.8333\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.2828 - acc: 0.8778 - val_loss: 0.3295 - val_acc: 0.8333\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2845 - acc: 0.8741 - val_loss: 0.3303 - val_acc: 0.8333\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2974 - acc: 0.8667 - val_loss: 0.3245 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.32092 to 0.31465, saving model to best.model\n",
      "0s - loss: 0.2966 - acc: 0.8500 - val_loss: 0.3146 - val_acc: 0.8667\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.31465 to 0.30646, saving model to best.model\n",
      "0s - loss: 0.2902 - acc: 0.8667 - val_loss: 0.3065 - val_acc: 0.8667\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2724 - acc: 0.8704 - val_loss: 0.3080 - val_acc: 0.8667\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.30646 to 0.30339, saving model to best.model\n",
      "0s - loss: 0.3153 - acc: 0.8648 - val_loss: 0.3034 - val_acc: 0.8667\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.30339 to 0.30126, saving model to best.model\n",
      "0s - loss: 0.2678 - acc: 0.8870 - val_loss: 0.3013 - val_acc: 0.8667\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2872 - acc: 0.8778 - val_loss: 0.3100 - val_acc: 0.8667\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2846 - acc: 0.8778 - val_loss: 0.3204 - val_acc: 0.8667\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2891 - acc: 0.8722 - val_loss: 0.3187 - val_acc: 0.8667\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2674 - acc: 0.8963 - val_loss: 0.3105 - val_acc: 0.8667\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2767 - acc: 0.8796 - val_loss: 0.3017 - val_acc: 0.8667\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.30126 to 0.29506, saving model to best.model\n",
      "0s - loss: 0.2863 - acc: 0.8741 - val_loss: 0.2951 - val_acc: 0.8667\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.29506 to 0.29197, saving model to best.model\n",
      "0s - loss: 0.2675 - acc: 0.8981 - val_loss: 0.2920 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2665 - acc: 0.8759 - val_loss: 0.2921 - val_acc: 0.8500\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2598 - acc: 0.8926 - val_loss: 0.2954 - val_acc: 0.8667\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2837 - acc: 0.8722 - val_loss: 0.3018 - val_acc: 0.8667\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2481 - acc: 0.8963 - val_loss: 0.3123 - val_acc: 0.8667\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2528 - acc: 0.8963 - val_loss: 0.3086 - val_acc: 0.8667\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.29197 to 0.29092, saving model to best.model\n",
      "0s - loss: 0.2481 - acc: 0.8833 - val_loss: 0.2909 - val_acc: 0.8667\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.29092 to 0.28137, saving model to best.model\n",
      "0s - loss: 0.2570 - acc: 0.8963 - val_loss: 0.2814 - val_acc: 0.8833\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.28137 to 0.28037, saving model to best.model\n",
      "0s - loss: 0.2660 - acc: 0.8963 - val_loss: 0.2804 - val_acc: 0.8667\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2616 - acc: 0.8889 - val_loss: 0.2807 - val_acc: 0.8500\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2668 - acc: 0.8889 - val_loss: 0.2804 - val_acc: 0.8500\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2485 - acc: 0.9000 - val_loss: 0.2819 - val_acc: 0.8500\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2470 - acc: 0.8926 - val_loss: 0.2837 - val_acc: 0.8500\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2470 - acc: 0.9037 - val_loss: 0.2818 - val_acc: 0.8667\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.28037 to 0.27644, saving model to best.model\n",
      "0s - loss: 0.2524 - acc: 0.8870 - val_loss: 0.2764 - val_acc: 0.8833\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.27644 to 0.26952, saving model to best.model\n",
      "0s - loss: 0.2451 - acc: 0.9019 - val_loss: 0.2695 - val_acc: 0.9000\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.26952 to 0.26527, saving model to best.model\n",
      "0s - loss: 0.2481 - acc: 0.8926 - val_loss: 0.2653 - val_acc: 0.8833\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.26527 to 0.26471, saving model to best.model\n",
      "0s - loss: 0.2649 - acc: 0.8833 - val_loss: 0.2647 - val_acc: 0.8833\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2760 - acc: 0.8907 - val_loss: 0.2683 - val_acc: 0.8833\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2446 - acc: 0.8963 - val_loss: 0.2696 - val_acc: 0.9000\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2837 - acc: 0.8815 - val_loss: 0.2777 - val_acc: 0.9000\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2661 - acc: 0.8889 - val_loss: 0.2916 - val_acc: 0.8667\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2538 - acc: 0.8963 - val_loss: 0.3068 - val_acc: 0.8500\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2462 - acc: 0.8926 - val_loss: 0.3110 - val_acc: 0.8500\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2600 - acc: 0.9000 - val_loss: 0.2890 - val_acc: 0.8833\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2406 - acc: 0.9037 - val_loss: 0.2690 - val_acc: 0.8833\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.26471 to 0.25882, saving model to best.model\n",
      "0s - loss: 0.2427 - acc: 0.8926 - val_loss: 0.2588 - val_acc: 0.8833\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.25882 to 0.25608, saving model to best.model\n",
      "0s - loss: 0.2542 - acc: 0.8907 - val_loss: 0.2561 - val_acc: 0.8833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.52348, saving model to best.model\n",
      "0s - loss: 0.6642 - acc: 0.6519 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.52348 to 0.51625, saving model to best.model\n",
      "0s - loss: 0.6920 - acc: 0.6704 - val_loss: 0.5163 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.51625 to 0.51174, saving model to best.model\n",
      "0s - loss: 0.5899 - acc: 0.7185 - val_loss: 0.5117 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6210 - acc: 0.7037 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6231 - acc: 0.7093 - val_loss: 0.5240 - val_acc: 0.7667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.5968 - acc: 0.6944 - val_loss: 0.5355 - val_acc: 0.7667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5945 - acc: 0.7037 - val_loss: 0.5381 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5978 - acc: 0.7000 - val_loss: 0.5342 - val_acc: 0.7667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6076 - acc: 0.6833 - val_loss: 0.5281 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5497 - acc: 0.7111 - val_loss: 0.5250 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5638 - acc: 0.7019 - val_loss: 0.5204 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5496 - acc: 0.7167 - val_loss: 0.5147 - val_acc: 0.7667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.51174 to 0.51132, saving model to best.model\n",
      "0s - loss: 0.5594 - acc: 0.7148 - val_loss: 0.5113 - val_acc: 0.7667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.51132 to 0.50727, saving model to best.model\n",
      "0s - loss: 0.5477 - acc: 0.7093 - val_loss: 0.5073 - val_acc: 0.7667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.50727 to 0.50194, saving model to best.model\n",
      "0s - loss: 0.5276 - acc: 0.7444 - val_loss: 0.5019 - val_acc: 0.7667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.50194 to 0.49479, saving model to best.model\n",
      "0s - loss: 0.5263 - acc: 0.7259 - val_loss: 0.4948 - val_acc: 0.7667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.49479 to 0.48850, saving model to best.model\n",
      "0s - loss: 0.5479 - acc: 0.7148 - val_loss: 0.4885 - val_acc: 0.7667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.48850 to 0.48506, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7222 - val_loss: 0.4851 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5325 - acc: 0.7315 - val_loss: 0.4863 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5332 - acc: 0.7315 - val_loss: 0.4858 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.48506 to 0.48439, saving model to best.model\n",
      "0s - loss: 0.5089 - acc: 0.7519 - val_loss: 0.4844 - val_acc: 0.7667\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.48439 to 0.47980, saving model to best.model\n",
      "0s - loss: 0.5388 - acc: 0.7222 - val_loss: 0.4798 - val_acc: 0.7667\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.47980 to 0.47613, saving model to best.model\n",
      "0s - loss: 0.5202 - acc: 0.7333 - val_loss: 0.4761 - val_acc: 0.7667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.47613 to 0.47552, saving model to best.model\n",
      "0s - loss: 0.5079 - acc: 0.7352 - val_loss: 0.4755 - val_acc: 0.7500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.47552 to 0.47400, saving model to best.model\n",
      "0s - loss: 0.5408 - acc: 0.7296 - val_loss: 0.4740 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.47400 to 0.47203, saving model to best.model\n",
      "0s - loss: 0.5303 - acc: 0.7352 - val_loss: 0.4720 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5303 - acc: 0.7296 - val_loss: 0.4731 - val_acc: 0.7500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5050 - acc: 0.7611 - val_loss: 0.4724 - val_acc: 0.7667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.47203 to 0.46991, saving model to best.model\n",
      "0s - loss: 0.4990 - acc: 0.7500 - val_loss: 0.4699 - val_acc: 0.7667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.46991 to 0.46673, saving model to best.model\n",
      "0s - loss: 0.5065 - acc: 0.7556 - val_loss: 0.4667 - val_acc: 0.7667\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.46673 to 0.46519, saving model to best.model\n",
      "0s - loss: 0.5117 - acc: 0.7463 - val_loss: 0.4652 - val_acc: 0.7667\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5008 - acc: 0.7667 - val_loss: 0.4663 - val_acc: 0.7667\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.4944 - acc: 0.7667 - val_loss: 0.4698 - val_acc: 0.7667\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5098 - acc: 0.7648 - val_loss: 0.4730 - val_acc: 0.7667\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.4784 - acc: 0.7870 - val_loss: 0.4700 - val_acc: 0.7667\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.4983 - acc: 0.7722 - val_loss: 0.4662 - val_acc: 0.7667\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.46519 to 0.45900, saving model to best.model\n",
      "0s - loss: 0.5214 - acc: 0.7593 - val_loss: 0.4590 - val_acc: 0.7667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.45900 to 0.45146, saving model to best.model\n",
      "0s - loss: 0.4994 - acc: 0.7574 - val_loss: 0.4515 - val_acc: 0.7667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.45146 to 0.44569, saving model to best.model\n",
      "0s - loss: 0.4774 - acc: 0.7815 - val_loss: 0.4457 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.44569 to 0.44172, saving model to best.model\n",
      "0s - loss: 0.4808 - acc: 0.7889 - val_loss: 0.4417 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.44172 to 0.43791, saving model to best.model\n",
      "0s - loss: 0.4843 - acc: 0.7722 - val_loss: 0.4379 - val_acc: 0.7667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.43791 to 0.43685, saving model to best.model\n",
      "0s - loss: 0.4970 - acc: 0.7722 - val_loss: 0.4368 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4775 - acc: 0.7648 - val_loss: 0.4406 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4843 - acc: 0.7796 - val_loss: 0.4485 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4875 - acc: 0.7537 - val_loss: 0.4564 - val_acc: 0.8000\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4776 - acc: 0.7685 - val_loss: 0.4561 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4808 - acc: 0.7778 - val_loss: 0.4513 - val_acc: 0.8000\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4783 - acc: 0.7796 - val_loss: 0.4465 - val_acc: 0.8000\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4606 - acc: 0.7704 - val_loss: 0.4407 - val_acc: 0.8000\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.43685 to 0.43296, saving model to best.model\n",
      "0s - loss: 0.4684 - acc: 0.7722 - val_loss: 0.4330 - val_acc: 0.8000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.43296 to 0.42547, saving model to best.model\n",
      "0s - loss: 0.4691 - acc: 0.7685 - val_loss: 0.4255 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.42547 to 0.42101, saving model to best.model\n",
      "0s - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4210 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.42101 to 0.41837, saving model to best.model\n",
      "0s - loss: 0.4833 - acc: 0.7796 - val_loss: 0.4184 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.41837 to 0.41657, saving model to best.model\n",
      "0s - loss: 0.4752 - acc: 0.7889 - val_loss: 0.4166 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.41657 to 0.41611, saving model to best.model\n",
      "0s - loss: 0.4776 - acc: 0.7796 - val_loss: 0.4161 - val_acc: 0.7833\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.41611 to 0.41608, saving model to best.model\n",
      "0s - loss: 0.4599 - acc: 0.7981 - val_loss: 0.4161 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4516 - acc: 0.7815 - val_loss: 0.4163 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4632 - acc: 0.7907 - val_loss: 0.4169 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4570 - acc: 0.7907 - val_loss: 0.4189 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4379 - acc: 0.8000 - val_loss: 0.4211 - val_acc: 0.8000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4510 - acc: 0.8000 - val_loss: 0.4205 - val_acc: 0.8000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4568 - acc: 0.8019 - val_loss: 0.4223 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4299 - acc: 0.8074 - val_loss: 0.4211 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4417 - acc: 0.8019 - val_loss: 0.4194 - val_acc: 0.8167\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.41608 to 0.41364, saving model to best.model\n",
      "0s - loss: 0.4341 - acc: 0.7981 - val_loss: 0.4136 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.41364 to 0.40687, saving model to best.model\n",
      "0s - loss: 0.4414 - acc: 0.8093 - val_loss: 0.4069 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.40687 to 0.40079, saving model to best.model\n",
      "0s - loss: 0.4472 - acc: 0.7926 - val_loss: 0.4008 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.40079 to 0.39692, saving model to best.model\n",
      "0s - loss: 0.4107 - acc: 0.8074 - val_loss: 0.3969 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.39692 to 0.39266, saving model to best.model\n",
      "0s - loss: 0.4203 - acc: 0.8185 - val_loss: 0.3927 - val_acc: 0.8000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.39266 to 0.38898, saving model to best.model\n",
      "0s - loss: 0.4243 - acc: 0.7981 - val_loss: 0.3890 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.38898 to 0.38650, saving model to best.model\n",
      "0s - loss: 0.4227 - acc: 0.8074 - val_loss: 0.3865 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.38650 to 0.38405, saving model to best.model\n",
      "0s - loss: 0.4387 - acc: 0.8019 - val_loss: 0.3841 - val_acc: 0.8000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.38405 to 0.38160, saving model to best.model\n",
      "0s - loss: 0.4380 - acc: 0.8167 - val_loss: 0.3816 - val_acc: 0.8000\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.38160 to 0.37890, saving model to best.model\n",
      "0s - loss: 0.4175 - acc: 0.8333 - val_loss: 0.3789 - val_acc: 0.8167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.37890 to 0.37657, saving model to best.model\n",
      "0s - loss: 0.4307 - acc: 0.8278 - val_loss: 0.3766 - val_acc: 0.8500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4189 - acc: 0.8130 - val_loss: 0.3772 - val_acc: 0.8500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4052 - acc: 0.8241 - val_loss: 0.3771 - val_acc: 0.8500\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4160 - acc: 0.8222 - val_loss: 0.3766 - val_acc: 0.8333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.37657 to 0.37504, saving model to best.model\n",
      "0s - loss: 0.4258 - acc: 0.8167 - val_loss: 0.3750 - val_acc: 0.8333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.37504 to 0.37378, saving model to best.model\n",
      "0s - loss: 0.4029 - acc: 0.8111 - val_loss: 0.3738 - val_acc: 0.8333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4149 - acc: 0.8185 - val_loss: 0.3747 - val_acc: 0.8333\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.37378 to 0.37306, saving model to best.model\n",
      "0s - loss: 0.4197 - acc: 0.8185 - val_loss: 0.3731 - val_acc: 0.8333\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.37306 to 0.37047, saving model to best.model\n",
      "0s - loss: 0.3882 - acc: 0.8222 - val_loss: 0.3705 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.37047 to 0.36898, saving model to best.model\n",
      "0s - loss: 0.4068 - acc: 0.8148 - val_loss: 0.3690 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.36898 to 0.36845, saving model to best.model\n",
      "0s - loss: 0.3994 - acc: 0.8315 - val_loss: 0.3685 - val_acc: 0.8333\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.36845 to 0.36833, saving model to best.model\n",
      "0s - loss: 0.4106 - acc: 0.8259 - val_loss: 0.3683 - val_acc: 0.8333\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.3859 - acc: 0.8259 - val_loss: 0.3686 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4151 - acc: 0.8204 - val_loss: 0.3691 - val_acc: 0.8333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.36833 to 0.36754, saving model to best.model\n",
      "0s - loss: 0.3795 - acc: 0.8407 - val_loss: 0.3675 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.36754 to 0.36476, saving model to best.model\n",
      "0s - loss: 0.3890 - acc: 0.8315 - val_loss: 0.3648 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.36476 to 0.36156, saving model to best.model\n",
      "0s - loss: 0.3839 - acc: 0.8407 - val_loss: 0.3616 - val_acc: 0.8333\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.36156 to 0.35850, saving model to best.model\n",
      "0s - loss: 0.3980 - acc: 0.8315 - val_loss: 0.3585 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.35850 to 0.35636, saving model to best.model\n",
      "0s - loss: 0.3618 - acc: 0.8556 - val_loss: 0.3564 - val_acc: 0.8500\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.35636 to 0.35345, saving model to best.model\n",
      "0s - loss: 0.3851 - acc: 0.8315 - val_loss: 0.3535 - val_acc: 0.8667\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.35345 to 0.35250, saving model to best.model\n",
      "0s - loss: 0.3919 - acc: 0.8204 - val_loss: 0.3525 - val_acc: 0.8500\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3563 - acc: 0.8463 - val_loss: 0.3551 - val_acc: 0.8333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3852 - acc: 0.8370 - val_loss: 0.3553 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4011 - acc: 0.8185 - val_loss: 0.3540 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.35250 to 0.35052, saving model to best.model\n",
      "0s - loss: 0.3751 - acc: 0.8278 - val_loss: 0.3505 - val_acc: 0.8500\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.35052 to 0.34571, saving model to best.model\n",
      "0s - loss: 0.3610 - acc: 0.8370 - val_loss: 0.3457 - val_acc: 0.8500\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.34571 to 0.34264, saving model to best.model\n",
      "0s - loss: 0.3719 - acc: 0.8556 - val_loss: 0.3426 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.34264 to 0.33893, saving model to best.model\n",
      "0s - loss: 0.3692 - acc: 0.8296 - val_loss: 0.3389 - val_acc: 0.8500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.33893 to 0.33360, saving model to best.model\n",
      "0s - loss: 0.3789 - acc: 0.8370 - val_loss: 0.3336 - val_acc: 0.8500\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.33360 to 0.33062, saving model to best.model\n",
      "0s - loss: 0.3619 - acc: 0.8463 - val_loss: 0.3306 - val_acc: 0.8333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3746 - acc: 0.8500 - val_loss: 0.3309 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3557 - acc: 0.8537 - val_loss: 0.3315 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.33062 to 0.32902, saving model to best.model\n",
      "0s - loss: 0.3484 - acc: 0.8370 - val_loss: 0.3290 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.32902 to 0.32677, saving model to best.model\n",
      "0s - loss: 0.3416 - acc: 0.8500 - val_loss: 0.3268 - val_acc: 0.8833\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3682 - acc: 0.8574 - val_loss: 0.3269 - val_acc: 0.8833\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3892 - acc: 0.8278 - val_loss: 0.3268 - val_acc: 0.8833\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.32677 to 0.32257, saving model to best.model\n",
      "0s - loss: 0.3634 - acc: 0.8556 - val_loss: 0.3226 - val_acc: 0.8833\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.32257 to 0.31549, saving model to best.model\n",
      "0s - loss: 0.3731 - acc: 0.8463 - val_loss: 0.3155 - val_acc: 0.9000\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.31549 to 0.31347, saving model to best.model\n",
      "0s - loss: 0.3712 - acc: 0.8370 - val_loss: 0.3135 - val_acc: 0.8500\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3521 - acc: 0.8426 - val_loss: 0.3149 - val_acc: 0.8333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.31347 to 0.31313, saving model to best.model\n",
      "0s - loss: 0.3556 - acc: 0.8574 - val_loss: 0.3131 - val_acc: 0.8500\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3410 - acc: 0.8500 - val_loss: 0.3142 - val_acc: 0.8500\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.31313 to 0.31029, saving model to best.model\n",
      "0s - loss: 0.3526 - acc: 0.8407 - val_loss: 0.3103 - val_acc: 0.8500\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.31029 to 0.30619, saving model to best.model\n",
      "0s - loss: 0.3695 - acc: 0.8574 - val_loss: 0.3062 - val_acc: 0.8667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3070 - acc: 0.8778 - val_loss: 0.3063 - val_acc: 0.8667\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3271 - acc: 0.8759 - val_loss: 0.3065 - val_acc: 0.8667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3386 - acc: 0.8574 - val_loss: 0.3065 - val_acc: 0.8667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.30619 to 0.30545, saving model to best.model\n",
      "0s - loss: 0.3370 - acc: 0.8537 - val_loss: 0.3054 - val_acc: 0.8667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.30545 to 0.30366, saving model to best.model\n",
      "0s - loss: 0.3341 - acc: 0.8519 - val_loss: 0.3037 - val_acc: 0.8833\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.30366 to 0.30090, saving model to best.model\n",
      "0s - loss: 0.3089 - acc: 0.8611 - val_loss: 0.3009 - val_acc: 0.8833\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.30090 to 0.29736, saving model to best.model\n",
      "0s - loss: 0.3224 - acc: 0.8574 - val_loss: 0.2974 - val_acc: 0.9000\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3485 - acc: 0.8481 - val_loss: 0.2981 - val_acc: 0.9000\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3182 - acc: 0.8611 - val_loss: 0.3005 - val_acc: 0.9000\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3302 - acc: 0.8704 - val_loss: 0.2978 - val_acc: 0.9167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.29736 to 0.29409, saving model to best.model\n",
      "0s - loss: 0.3082 - acc: 0.8852 - val_loss: 0.2941 - val_acc: 0.9000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.29409 to 0.29287, saving model to best.model\n",
      "0s - loss: 0.3273 - acc: 0.8630 - val_loss: 0.2929 - val_acc: 0.9000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.29287 to 0.29276, saving model to best.model\n",
      "0s - loss: 0.3147 - acc: 0.8815 - val_loss: 0.2928 - val_acc: 0.8833\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.29276 to 0.29073, saving model to best.model\n",
      "0s - loss: 0.3136 - acc: 0.8815 - val_loss: 0.2907 - val_acc: 0.9000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.29073 to 0.28796, saving model to best.model\n",
      "0s - loss: 0.3023 - acc: 0.8759 - val_loss: 0.2880 - val_acc: 0.9000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.28796 to 0.28662, saving model to best.model\n",
      "0s - loss: 0.3147 - acc: 0.8741 - val_loss: 0.2866 - val_acc: 0.9000\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.28662 to 0.28532, saving model to best.model\n",
      "0s - loss: 0.3040 - acc: 0.8667 - val_loss: 0.2853 - val_acc: 0.9000\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.28532 to 0.28501, saving model to best.model\n",
      "0s - loss: 0.2882 - acc: 0.8685 - val_loss: 0.2850 - val_acc: 0.9000\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.28501 to 0.28499, saving model to best.model\n",
      "0s - loss: 0.2886 - acc: 0.8759 - val_loss: 0.2850 - val_acc: 0.8667\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.28499 to 0.28299, saving model to best.model\n",
      "0s - loss: 0.2955 - acc: 0.8741 - val_loss: 0.2830 - val_acc: 0.8833\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.28299 to 0.28050, saving model to best.model\n",
      "0s - loss: 0.3017 - acc: 0.8481 - val_loss: 0.2805 - val_acc: 0.8833\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.28050 to 0.27683, saving model to best.model\n",
      "0s - loss: 0.3050 - acc: 0.8741 - val_loss: 0.2768 - val_acc: 0.8833\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.27683 to 0.27478, saving model to best.model\n",
      "0s - loss: 0.3105 - acc: 0.8685 - val_loss: 0.2748 - val_acc: 0.8833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.27478 to 0.27187, saving model to best.model\n",
      "0s - loss: 0.2863 - acc: 0.8778 - val_loss: 0.2719 - val_acc: 0.9000\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.27187 to 0.27067, saving model to best.model\n",
      "0s - loss: 0.2990 - acc: 0.8759 - val_loss: 0.2707 - val_acc: 0.9000\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.27067 to 0.26529, saving model to best.model\n",
      "0s - loss: 0.3010 - acc: 0.8611 - val_loss: 0.2653 - val_acc: 0.9167\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.26529 to 0.25957, saving model to best.model\n",
      "0s - loss: 0.2972 - acc: 0.8704 - val_loss: 0.2596 - val_acc: 0.9333\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.25957 to 0.25706, saving model to best.model\n",
      "0s - loss: 0.2926 - acc: 0.8907 - val_loss: 0.2571 - val_acc: 0.9333\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.25706 to 0.25527, saving model to best.model\n",
      "0s - loss: 0.3133 - acc: 0.8741 - val_loss: 0.2553 - val_acc: 0.9333\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.25527 to 0.25489, saving model to best.model\n",
      "0s - loss: 0.2667 - acc: 0.8833 - val_loss: 0.2549 - val_acc: 0.9333\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3062 - acc: 0.8759 - val_loss: 0.2561 - val_acc: 0.9333\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.2851 - acc: 0.8852 - val_loss: 0.2603 - val_acc: 0.9167\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.2860 - acc: 0.8833 - val_loss: 0.2618 - val_acc: 0.9167\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.2626 - acc: 0.9019 - val_loss: 0.2556 - val_acc: 0.9167\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.25489 to 0.24671, saving model to best.model\n",
      "0s - loss: 0.2700 - acc: 0.8889 - val_loss: 0.2467 - val_acc: 0.9167\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.24671 to 0.23530, saving model to best.model\n",
      "0s - loss: 0.2553 - acc: 0.9019 - val_loss: 0.2353 - val_acc: 0.9333\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.23530 to 0.23125, saving model to best.model\n",
      "0s - loss: 0.2707 - acc: 0.8944 - val_loss: 0.2313 - val_acc: 0.9333\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.23125 to 0.23078, saving model to best.model\n",
      "0s - loss: 0.3226 - acc: 0.8611 - val_loss: 0.2308 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3208 - acc: 0.8704 - val_loss: 0.2323 - val_acc: 0.9333\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.2552 - acc: 0.8889 - val_loss: 0.2432 - val_acc: 0.9167\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.2797 - acc: 0.8815 - val_loss: 0.2502 - val_acc: 0.9000\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2521 - acc: 0.9000 - val_loss: 0.2470 - val_acc: 0.9167\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2909 - acc: 0.8722 - val_loss: 0.2411 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2803 - acc: 0.8704 - val_loss: 0.2357 - val_acc: 0.9333\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.23078 to 0.22798, saving model to best.model\n",
      "0s - loss: 0.2690 - acc: 0.9000 - val_loss: 0.2280 - val_acc: 0.9333\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.22798 to 0.21870, saving model to best.model\n",
      "0s - loss: 0.2636 - acc: 0.8759 - val_loss: 0.2187 - val_acc: 0.9500\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.21870 to 0.21318, saving model to best.model\n",
      "0s - loss: 0.2462 - acc: 0.9093 - val_loss: 0.2132 - val_acc: 0.9500\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.21318 to 0.21170, saving model to best.model\n",
      "0s - loss: 0.2856 - acc: 0.8722 - val_loss: 0.2117 - val_acc: 0.9500\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.21170 to 0.20990, saving model to best.model\n",
      "0s - loss: 0.2697 - acc: 0.8741 - val_loss: 0.2099 - val_acc: 0.9333\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.20990 to 0.20779, saving model to best.model\n",
      "0s - loss: 0.2380 - acc: 0.9111 - val_loss: 0.2078 - val_acc: 0.9333\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2728 - acc: 0.8944 - val_loss: 0.2142 - val_acc: 0.9333\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2496 - acc: 0.8963 - val_loss: 0.2216 - val_acc: 0.9167\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2821 - acc: 0.8889 - val_loss: 0.2212 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2533 - acc: 0.9093 - val_loss: 0.2212 - val_acc: 0.9333\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.2539 - acc: 0.8926 - val_loss: 0.2256 - val_acc: 0.9167\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2260 - acc: 0.9019 - val_loss: 0.2295 - val_acc: 0.9000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2768 - acc: 0.8852 - val_loss: 0.2282 - val_acc: 0.9000\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2300 - acc: 0.9074 - val_loss: 0.2298 - val_acc: 0.9000\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2541 - acc: 0.8981 - val_loss: 0.2269 - val_acc: 0.9000\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2274 - acc: 0.9093 - val_loss: 0.2189 - val_acc: 0.9333\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2441 - acc: 0.9037 - val_loss: 0.2145 - val_acc: 0.9167\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2554 - acc: 0.8926 - val_loss: 0.2157 - val_acc: 0.9167\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2610 - acc: 0.8926 - val_loss: 0.2231 - val_acc: 0.9167\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2360 - acc: 0.9056 - val_loss: 0.2376 - val_acc: 0.9000\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2623 - acc: 0.8870 - val_loss: 0.2472 - val_acc: 0.8833\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2430 - acc: 0.9037 - val_loss: 0.2404 - val_acc: 0.9167\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2454 - acc: 0.8889 - val_loss: 0.2299 - val_acc: 0.9167\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2489 - acc: 0.8889 - val_loss: 0.2131 - val_acc: 0.9333\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.20779 to 0.20633, saving model to best.model\n",
      "0s - loss: 0.2486 - acc: 0.8963 - val_loss: 0.2063 - val_acc: 0.9333\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.20633 to 0.20439, saving model to best.model\n",
      "0s - loss: 0.2218 - acc: 0.9167 - val_loss: 0.2044 - val_acc: 0.9500\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2419 - acc: 0.8944 - val_loss: 0.2051 - val_acc: 0.9500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.2287 - acc: 0.9056 - val_loss: 0.2089 - val_acc: 0.9333\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2429 - acc: 0.8944 - val_loss: 0.2103 - val_acc: 0.9333\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.20439 to 0.20006, saving model to best.model\n",
      "0s - loss: 0.2453 - acc: 0.9093 - val_loss: 0.2001 - val_acc: 0.9333\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.20006 to 0.18898, saving model to best.model\n",
      "0s - loss: 0.2275 - acc: 0.8981 - val_loss: 0.1890 - val_acc: 0.9333\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.18898 to 0.18481, saving model to best.model\n",
      "0s - loss: 0.2144 - acc: 0.9074 - val_loss: 0.1848 - val_acc: 0.9333\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.18481 to 0.18334, saving model to best.model\n",
      "0s - loss: 0.2000 - acc: 0.9296 - val_loss: 0.1833 - val_acc: 0.9333\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2343 - acc: 0.9000 - val_loss: 0.1841 - val_acc: 0.9333\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.1999 - acc: 0.9259 - val_loss: 0.1875 - val_acc: 0.9167\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2172 - acc: 0.9074 - val_loss: 0.1939 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.1974 - acc: 0.9167 - val_loss: 0.2028 - val_acc: 0.9167\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.1942 - acc: 0.9204 - val_loss: 0.2028 - val_acc: 0.9167\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.55028, saving model to best.model\n",
      "0s - loss: 0.8731 - acc: 0.5815 - val_loss: 0.5503 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.55028 to 0.54555, saving model to best.model\n",
      "0s - loss: 0.7695 - acc: 0.6389 - val_loss: 0.5455 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.54555 to 0.53188, saving model to best.model\n",
      "0s - loss: 0.7339 - acc: 0.6481 - val_loss: 0.5319 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.53188 to 0.52364, saving model to best.model\n",
      "0s - loss: 0.6455 - acc: 0.6648 - val_loss: 0.5236 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52364 to 0.52173, saving model to best.model\n",
      "0s - loss: 0.6464 - acc: 0.6815 - val_loss: 0.5217 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6725 - acc: 0.6741 - val_loss: 0.5270 - val_acc: 0.7500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6085 - acc: 0.6833 - val_loss: 0.5354 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6090 - acc: 0.6574 - val_loss: 0.5347 - val_acc: 0.7500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5934 - acc: 0.6648 - val_loss: 0.5262 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.52173 to 0.51743, saving model to best.model\n",
      "0s - loss: 0.5850 - acc: 0.6796 - val_loss: 0.5174 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.51743 to 0.51306, saving model to best.model\n",
      "0s - loss: 0.5824 - acc: 0.7093 - val_loss: 0.5131 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.51306 to 0.51072, saving model to best.model\n",
      "0s - loss: 0.5644 - acc: 0.7000 - val_loss: 0.5107 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.51072 to 0.50937, saving model to best.model\n",
      "0s - loss: 0.5894 - acc: 0.6815 - val_loss: 0.5094 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5726 - acc: 0.6981 - val_loss: 0.5107 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5424 - acc: 0.7093 - val_loss: 0.5121 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5876 - acc: 0.7167 - val_loss: 0.5142 - val_acc: 0.7667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5688 - acc: 0.6907 - val_loss: 0.5148 - val_acc: 0.7667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5551 - acc: 0.6926 - val_loss: 0.5151 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5577 - acc: 0.7037 - val_loss: 0.5124 - val_acc: 0.7333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.50937 to 0.50583, saving model to best.model\n",
      "0s - loss: 0.5657 - acc: 0.7000 - val_loss: 0.5058 - val_acc: 0.7333\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.50583 to 0.49929, saving model to best.model\n",
      "0s - loss: 0.5611 - acc: 0.7333 - val_loss: 0.4993 - val_acc: 0.7500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.49929 to 0.49416, saving model to best.model\n",
      "0s - loss: 0.5372 - acc: 0.7241 - val_loss: 0.4942 - val_acc: 0.7667\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.49416 to 0.49182, saving model to best.model\n",
      "0s - loss: 0.5604 - acc: 0.7222 - val_loss: 0.4918 - val_acc: 0.7667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.49182 to 0.49115, saving model to best.model\n",
      "0s - loss: 0.5355 - acc: 0.7111 - val_loss: 0.4911 - val_acc: 0.7667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5440 - acc: 0.7352 - val_loss: 0.4913 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5338 - acc: 0.7130 - val_loss: 0.4923 - val_acc: 0.7333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5499 - acc: 0.7167 - val_loss: 0.4948 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5332 - acc: 0.7037 - val_loss: 0.5001 - val_acc: 0.7000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5528 - acc: 0.7259 - val_loss: 0.5049 - val_acc: 0.7000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5318 - acc: 0.7130 - val_loss: 0.5063 - val_acc: 0.7167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5256 - acc: 0.7481 - val_loss: 0.5059 - val_acc: 0.7000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5378 - acc: 0.7315 - val_loss: 0.5098 - val_acc: 0.6833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5184 - acc: 0.7352 - val_loss: 0.5128 - val_acc: 0.6833\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5206 - acc: 0.7315 - val_loss: 0.5094 - val_acc: 0.7167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5385 - acc: 0.7204 - val_loss: 0.5059 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5354 - acc: 0.7185 - val_loss: 0.5054 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5079 - acc: 0.7556 - val_loss: 0.5059 - val_acc: 0.7167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5406 - acc: 0.7389 - val_loss: 0.5080 - val_acc: 0.6833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5214 - acc: 0.7241 - val_loss: 0.5111 - val_acc: 0.6667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5195 - acc: 0.7556 - val_loss: 0.5145 - val_acc: 0.6667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4946 - acc: 0.7611 - val_loss: 0.5157 - val_acc: 0.6500\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4977 - acc: 0.7519 - val_loss: 0.5163 - val_acc: 0.6500\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5017 - acc: 0.7611 - val_loss: 0.5186 - val_acc: 0.6500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4924 - acc: 0.7556 - val_loss: 0.5148 - val_acc: 0.6667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4878 - acc: 0.7537 - val_loss: 0.5077 - val_acc: 0.6833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5207 - acc: 0.7352 - val_loss: 0.5038 - val_acc: 0.6833\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4936 - acc: 0.7389 - val_loss: 0.4999 - val_acc: 0.6833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5018 - acc: 0.7556 - val_loss: 0.4975 - val_acc: 0.6833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5218 - acc: 0.7463 - val_loss: 0.4974 - val_acc: 0.6833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4986 - acc: 0.7574 - val_loss: 0.4988 - val_acc: 0.6833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.64450, saving model to best.model\n",
      "0s - loss: 0.9916 - acc: 0.4704 - val_loss: 0.6445 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.8291 - acc: 0.6259 - val_loss: 0.6505 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.64450 to 0.63113, saving model to best.model\n",
      "0s - loss: 0.8276 - acc: 0.6870 - val_loss: 0.6311 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.63113 to 0.60158, saving model to best.model\n",
      "0s - loss: 0.7636 - acc: 0.6741 - val_loss: 0.6016 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.60158 to 0.58982, saving model to best.model\n",
      "0s - loss: 0.7032 - acc: 0.6667 - val_loss: 0.5898 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.58982 to 0.58809, saving model to best.model\n",
      "0s - loss: 0.6393 - acc: 0.6889 - val_loss: 0.5881 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.58809 to 0.58793, saving model to best.model\n",
      "0s - loss: 0.6218 - acc: 0.6981 - val_loss: 0.5879 - val_acc: 0.6500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6551 - acc: 0.6667 - val_loss: 0.5882 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.58793 to 0.58669, saving model to best.model\n",
      "0s - loss: 0.5917 - acc: 0.6870 - val_loss: 0.5867 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.58669 to 0.58346, saving model to best.model\n",
      "0s - loss: 0.6024 - acc: 0.6815 - val_loss: 0.5835 - val_acc: 0.6833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.58346 to 0.57675, saving model to best.model\n",
      "0s - loss: 0.6125 - acc: 0.6796 - val_loss: 0.5767 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.57675 to 0.56904, saving model to best.model\n",
      "0s - loss: 0.6024 - acc: 0.6944 - val_loss: 0.5690 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.56904 to 0.56187, saving model to best.model\n",
      "0s - loss: 0.6022 - acc: 0.6796 - val_loss: 0.5619 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.56187 to 0.55624, saving model to best.model\n",
      "0s - loss: 0.5631 - acc: 0.7148 - val_loss: 0.5562 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.55624 to 0.55111, saving model to best.model\n",
      "0s - loss: 0.6080 - acc: 0.7130 - val_loss: 0.5511 - val_acc: 0.6667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.55111 to 0.54626, saving model to best.model\n",
      "0s - loss: 0.5968 - acc: 0.7037 - val_loss: 0.5463 - val_acc: 0.6667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.54626 to 0.54292, saving model to best.model\n",
      "0s - loss: 0.5967 - acc: 0.7074 - val_loss: 0.5429 - val_acc: 0.6667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.54292 to 0.54114, saving model to best.model\n",
      "0s - loss: 0.5809 - acc: 0.7130 - val_loss: 0.5411 - val_acc: 0.6833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5914 - acc: 0.7167 - val_loss: 0.5416 - val_acc: 0.7000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5977 - acc: 0.7111 - val_loss: 0.5428 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5614 - acc: 0.7370 - val_loss: 0.5452 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5538 - acc: 0.7167 - val_loss: 0.5491 - val_acc: 0.7167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5667 - acc: 0.7074 - val_loss: 0.5497 - val_acc: 0.7000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5511 - acc: 0.7056 - val_loss: 0.5467 - val_acc: 0.7000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5370 - acc: 0.7315 - val_loss: 0.5420 - val_acc: 0.7000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.54114 to 0.53624, saving model to best.model\n",
      "0s - loss: 0.5572 - acc: 0.7204 - val_loss: 0.5362 - val_acc: 0.7000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.53624 to 0.53169, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7204 - val_loss: 0.5317 - val_acc: 0.7000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.53169 to 0.52918, saving model to best.model\n",
      "0s - loss: 0.5379 - acc: 0.7148 - val_loss: 0.5292 - val_acc: 0.7167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.52918 to 0.52776, saving model to best.model\n",
      "0s - loss: 0.5405 - acc: 0.7426 - val_loss: 0.5278 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.52776 to 0.52745, saving model to best.model\n",
      "0s - loss: 0.5204 - acc: 0.7593 - val_loss: 0.5275 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.52745 to 0.52580, saving model to best.model\n",
      "0s - loss: 0.5293 - acc: 0.7481 - val_loss: 0.5258 - val_acc: 0.7667\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.52580 to 0.52441, saving model to best.model\n",
      "0s - loss: 0.5514 - acc: 0.7185 - val_loss: 0.5244 - val_acc: 0.7833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.52441 to 0.52177, saving model to best.model\n",
      "0s - loss: 0.5468 - acc: 0.7370 - val_loss: 0.5218 - val_acc: 0.7833\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.52177 to 0.51861, saving model to best.model\n",
      "0s - loss: 0.5210 - acc: 0.7630 - val_loss: 0.5186 - val_acc: 0.7833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.51861 to 0.51541, saving model to best.model\n",
      "0s - loss: 0.5589 - acc: 0.7444 - val_loss: 0.5154 - val_acc: 0.7833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.51541 to 0.51192, saving model to best.model\n",
      "0s - loss: 0.5173 - acc: 0.7370 - val_loss: 0.5119 - val_acc: 0.7667\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.51192 to 0.50903, saving model to best.model\n",
      "0s - loss: 0.5441 - acc: 0.7370 - val_loss: 0.5090 - val_acc: 0.7667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5393 - acc: 0.7389 - val_loss: 0.5092 - val_acc: 0.7667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5114 - acc: 0.7630 - val_loss: 0.5124 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5270 - acc: 0.7556 - val_loss: 0.5140 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5262 - acc: 0.7537 - val_loss: 0.5161 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5044 - acc: 0.7704 - val_loss: 0.5175 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5311 - acc: 0.7481 - val_loss: 0.5172 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5317 - acc: 0.7630 - val_loss: 0.5159 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5317 - acc: 0.7500 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5406 - acc: 0.7630 - val_loss: 0.5155 - val_acc: 0.7333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5263 - acc: 0.7722 - val_loss: 0.5138 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5032 - acc: 0.7833 - val_loss: 0.5108 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.50903 to 0.50309, saving model to best.model\n",
      "0s - loss: 0.5132 - acc: 0.7648 - val_loss: 0.5031 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.50309 to 0.49606, saving model to best.model\n",
      "0s - loss: 0.5137 - acc: 0.7593 - val_loss: 0.4961 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.49606 to 0.48894, saving model to best.model\n",
      "0s - loss: 0.5041 - acc: 0.7593 - val_loss: 0.4889 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.48894 to 0.48320, saving model to best.model\n",
      "0s - loss: 0.5357 - acc: 0.7667 - val_loss: 0.4832 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.48320 to 0.48121, saving model to best.model\n",
      "0s - loss: 0.5118 - acc: 0.7537 - val_loss: 0.4812 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.48121 to 0.47994, saving model to best.model\n",
      "0s - loss: 0.4964 - acc: 0.7685 - val_loss: 0.4799 - val_acc: 0.7500\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.47994 to 0.47798, saving model to best.model\n",
      "0s - loss: 0.5107 - acc: 0.7796 - val_loss: 0.4780 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.47798 to 0.47638, saving model to best.model\n",
      "0s - loss: 0.5026 - acc: 0.7722 - val_loss: 0.4764 - val_acc: 0.7833\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.47638 to 0.47522, saving model to best.model\n",
      "0s - loss: 0.4726 - acc: 0.7778 - val_loss: 0.4752 - val_acc: 0.7667\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.47522 to 0.47299, saving model to best.model\n",
      "0s - loss: 0.4926 - acc: 0.7889 - val_loss: 0.4730 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.47299 to 0.47005, saving model to best.model\n",
      "0s - loss: 0.5007 - acc: 0.7833 - val_loss: 0.4701 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.47005 to 0.46870, saving model to best.model\n",
      "0s - loss: 0.4849 - acc: 0.7815 - val_loss: 0.4687 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4903 - acc: 0.7963 - val_loss: 0.4700 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4832 - acc: 0.7907 - val_loss: 0.4720 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4855 - acc: 0.7944 - val_loss: 0.4758 - val_acc: 0.7667\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4853 - acc: 0.7796 - val_loss: 0.4805 - val_acc: 0.7667\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4952 - acc: 0.7778 - val_loss: 0.4833 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4843 - acc: 0.7907 - val_loss: 0.4841 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4646 - acc: 0.8000 - val_loss: 0.4828 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4777 - acc: 0.7815 - val_loss: 0.4800 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4765 - acc: 0.7963 - val_loss: 0.4785 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4791 - acc: 0.7981 - val_loss: 0.4780 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4635 - acc: 0.8056 - val_loss: 0.4743 - val_acc: 0.7833\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4621 - acc: 0.7963 - val_loss: 0.4692 - val_acc: 0.8000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.46870 to 0.46448, saving model to best.model\n",
      "0s - loss: 0.4731 - acc: 0.7889 - val_loss: 0.4645 - val_acc: 0.8000\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.46448 to 0.46173, saving model to best.model\n",
      "0s - loss: 0.4584 - acc: 0.7944 - val_loss: 0.4617 - val_acc: 0.8000\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.46173 to 0.46032, saving model to best.model\n",
      "0s - loss: 0.4519 - acc: 0.8185 - val_loss: 0.4603 - val_acc: 0.8000\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4743 - acc: 0.8093 - val_loss: 0.4629 - val_acc: 0.8000\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4648 - acc: 0.8019 - val_loss: 0.4642 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4583 - acc: 0.8019 - val_loss: 0.4649 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4563 - acc: 0.7963 - val_loss: 0.4663 - val_acc: 0.8000\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4495 - acc: 0.8130 - val_loss: 0.4712 - val_acc: 0.8167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4538 - acc: 0.8037 - val_loss: 0.4736 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4432 - acc: 0.8074 - val_loss: 0.4704 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4470 - acc: 0.8204 - val_loss: 0.4646 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.46032 to 0.46030, saving model to best.model\n",
      "0s - loss: 0.4615 - acc: 0.7870 - val_loss: 0.4603 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.46030 to 0.45739, saving model to best.model\n",
      "0s - loss: 0.4743 - acc: 0.7944 - val_loss: 0.4574 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.45739 to 0.45442, saving model to best.model\n",
      "0s - loss: 0.4807 - acc: 0.8222 - val_loss: 0.4544 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.45442 to 0.45434, saving model to best.model\n",
      "0s - loss: 0.4262 - acc: 0.8130 - val_loss: 0.4543 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4365 - acc: 0.8056 - val_loss: 0.4577 - val_acc: 0.8167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4377 - acc: 0.8093 - val_loss: 0.4607 - val_acc: 0.8167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4306 - acc: 0.8222 - val_loss: 0.4629 - val_acc: 0.8167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4267 - acc: 0.8222 - val_loss: 0.4632 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4412 - acc: 0.8222 - val_loss: 0.4643 - val_acc: 0.8000\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4449 - acc: 0.8093 - val_loss: 0.4675 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4360 - acc: 0.8148 - val_loss: 0.4635 - val_acc: 0.7833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4384 - acc: 0.8056 - val_loss: 0.4597 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4230 - acc: 0.8148 - val_loss: 0.4579 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4487 - acc: 0.8222 - val_loss: 0.4604 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4149 - acc: 0.8241 - val_loss: 0.4698 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4297 - acc: 0.8148 - val_loss: 0.4791 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4174 - acc: 0.8111 - val_loss: 0.4834 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4114 - acc: 0.8204 - val_loss: 0.4769 - val_acc: 0.7667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4349 - acc: 0.8296 - val_loss: 0.4651 - val_acc: 0.7667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.45434 to 0.45327, saving model to best.model\n",
      "0s - loss: 0.4299 - acc: 0.8167 - val_loss: 0.4533 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.45327 to 0.44705, saving model to best.model\n",
      "0s - loss: 0.4284 - acc: 0.8130 - val_loss: 0.4471 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.44705 to 0.44450, saving model to best.model\n",
      "0s - loss: 0.4005 - acc: 0.8407 - val_loss: 0.4445 - val_acc: 0.8167\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4115 - acc: 0.8204 - val_loss: 0.4453 - val_acc: 0.8167\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4091 - acc: 0.8259 - val_loss: 0.4481 - val_acc: 0.8000\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4188 - acc: 0.8167 - val_loss: 0.4508 - val_acc: 0.8000\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4017 - acc: 0.8259 - val_loss: 0.4531 - val_acc: 0.7833\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4111 - acc: 0.8389 - val_loss: 0.4570 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3968 - acc: 0.8259 - val_loss: 0.4598 - val_acc: 0.7667\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4132 - acc: 0.8056 - val_loss: 0.4638 - val_acc: 0.7667\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.4142 - acc: 0.8296 - val_loss: 0.4682 - val_acc: 0.7667\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4156 - acc: 0.8278 - val_loss: 0.4660 - val_acc: 0.7667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4051 - acc: 0.8296 - val_loss: 0.4636 - val_acc: 0.7667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4029 - acc: 0.8241 - val_loss: 0.4646 - val_acc: 0.7667\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.4117 - acc: 0.8352 - val_loss: 0.4618 - val_acc: 0.7667\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.4032 - acc: 0.8241 - val_loss: 0.4584 - val_acc: 0.7667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3898 - acc: 0.8481 - val_loss: 0.4559 - val_acc: 0.7667\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3719 - acc: 0.8259 - val_loss: 0.4499 - val_acc: 0.7833\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.44450 to 0.44280, saving model to best.model\n",
      "0s - loss: 0.4035 - acc: 0.8185 - val_loss: 0.4428 - val_acc: 0.7833\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.44280 to 0.43941, saving model to best.model\n",
      "0s - loss: 0.3946 - acc: 0.8315 - val_loss: 0.4394 - val_acc: 0.7833\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.43941 to 0.43922, saving model to best.model\n",
      "0s - loss: 0.3921 - acc: 0.8593 - val_loss: 0.4392 - val_acc: 0.7833\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3887 - acc: 0.8315 - val_loss: 0.4410 - val_acc: 0.7833\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3910 - acc: 0.8370 - val_loss: 0.4412 - val_acc: 0.7833\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.43922 to 0.43824, saving model to best.model\n",
      "0s - loss: 0.3657 - acc: 0.8500 - val_loss: 0.4382 - val_acc: 0.7833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.43824 to 0.43531, saving model to best.model\n",
      "0s - loss: 0.3941 - acc: 0.8407 - val_loss: 0.4353 - val_acc: 0.7833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3815 - acc: 0.8222 - val_loss: 0.4373 - val_acc: 0.7833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3719 - acc: 0.8481 - val_loss: 0.4359 - val_acc: 0.7833\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.43531 to 0.43387, saving model to best.model\n",
      "0s - loss: 0.3531 - acc: 0.8519 - val_loss: 0.4339 - val_acc: 0.7833\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.43387 to 0.43063, saving model to best.model\n",
      "0s - loss: 0.3769 - acc: 0.8500 - val_loss: 0.4306 - val_acc: 0.7833\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.43063 to 0.42557, saving model to best.model\n",
      "0s - loss: 0.3891 - acc: 0.8148 - val_loss: 0.4256 - val_acc: 0.8000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3860 - acc: 0.8500 - val_loss: 0.4257 - val_acc: 0.8000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3671 - acc: 0.8500 - val_loss: 0.4303 - val_acc: 0.8000\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3397 - acc: 0.8593 - val_loss: 0.4361 - val_acc: 0.8000\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3777 - acc: 0.8537 - val_loss: 0.4396 - val_acc: 0.7833\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3770 - acc: 0.8463 - val_loss: 0.4346 - val_acc: 0.8167\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3570 - acc: 0.8426 - val_loss: 0.4320 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3514 - acc: 0.8630 - val_loss: 0.4276 - val_acc: 0.8333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.42557 to 0.42228, saving model to best.model\n",
      "0s - loss: 0.3558 - acc: 0.8611 - val_loss: 0.4223 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.42228 to 0.41928, saving model to best.model\n",
      "0s - loss: 0.3452 - acc: 0.8426 - val_loss: 0.4193 - val_acc: 0.8333\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.41928 to 0.41807, saving model to best.model\n",
      "0s - loss: 0.3718 - acc: 0.8556 - val_loss: 0.4181 - val_acc: 0.8333\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3638 - acc: 0.8556 - val_loss: 0.4214 - val_acc: 0.8333\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3485 - acc: 0.8556 - val_loss: 0.4256 - val_acc: 0.8167\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3432 - acc: 0.8593 - val_loss: 0.4279 - val_acc: 0.8167\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3346 - acc: 0.8500 - val_loss: 0.4321 - val_acc: 0.8167\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3493 - acc: 0.8667 - val_loss: 0.4408 - val_acc: 0.8000\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3337 - acc: 0.8685 - val_loss: 0.4358 - val_acc: 0.8000\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3446 - acc: 0.8648 - val_loss: 0.4295 - val_acc: 0.8000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3514 - acc: 0.8611 - val_loss: 0.4301 - val_acc: 0.8000\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3320 - acc: 0.8759 - val_loss: 0.4299 - val_acc: 0.8000\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3422 - acc: 0.8593 - val_loss: 0.4257 - val_acc: 0.8000\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3306 - acc: 0.8556 - val_loss: 0.4275 - val_acc: 0.7833\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3314 - acc: 0.8463 - val_loss: 0.4331 - val_acc: 0.8000\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3225 - acc: 0.8685 - val_loss: 0.4388 - val_acc: 0.8000\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3477 - acc: 0.8389 - val_loss: 0.4407 - val_acc: 0.8000\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3338 - acc: 0.8593 - val_loss: 0.4432 - val_acc: 0.7833\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3260 - acc: 0.8593 - val_loss: 0.4423 - val_acc: 0.7833\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3140 - acc: 0.8704 - val_loss: 0.4345 - val_acc: 0.7833\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3175 - acc: 0.8648 - val_loss: 0.4227 - val_acc: 0.8000\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.41807 to 0.41031, saving model to best.model\n",
      "0s - loss: 0.3033 - acc: 0.8796 - val_loss: 0.4103 - val_acc: 0.8000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.41031 to 0.39848, saving model to best.model\n",
      "0s - loss: 0.3211 - acc: 0.8759 - val_loss: 0.3985 - val_acc: 0.8167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.39848 to 0.39236, saving model to best.model\n",
      "0s - loss: 0.3268 - acc: 0.8574 - val_loss: 0.3924 - val_acc: 0.8167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3108 - acc: 0.8741 - val_loss: 0.3924 - val_acc: 0.8167\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3345 - acc: 0.8556 - val_loss: 0.4028 - val_acc: 0.8167\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3246 - acc: 0.8704 - val_loss: 0.4164 - val_acc: 0.8000\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2896 - acc: 0.8778 - val_loss: 0.4220 - val_acc: 0.7833\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3104 - acc: 0.8648 - val_loss: 0.4212 - val_acc: 0.7833\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2946 - acc: 0.8815 - val_loss: 0.4125 - val_acc: 0.8167\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3002 - acc: 0.8741 - val_loss: 0.4009 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2992 - acc: 0.8796 - val_loss: 0.3969 - val_acc: 0.8500\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3200 - acc: 0.8630 - val_loss: 0.3991 - val_acc: 0.8167\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3453 - acc: 0.8667 - val_loss: 0.4006 - val_acc: 0.8333\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2979 - acc: 0.8815 - val_loss: 0.4022 - val_acc: 0.8333\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.3103 - acc: 0.8741 - val_loss: 0.4040 - val_acc: 0.8167\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.3117 - acc: 0.8778 - val_loss: 0.4002 - val_acc: 0.8167\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.3137 - acc: 0.8630 - val_loss: 0.3963 - val_acc: 0.8500\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.39236 to 0.39235, saving model to best.model\n",
      "0s - loss: 0.2926 - acc: 0.8741 - val_loss: 0.3923 - val_acc: 0.8500\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.39235 to 0.38625, saving model to best.model\n",
      "0s - loss: 0.3097 - acc: 0.8722 - val_loss: 0.3862 - val_acc: 0.8500\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.38625 to 0.38177, saving model to best.model\n",
      "0s - loss: 0.3001 - acc: 0.8796 - val_loss: 0.3818 - val_acc: 0.8500\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.38177 to 0.37799, saving model to best.model\n",
      "0s - loss: 0.3062 - acc: 0.8759 - val_loss: 0.3780 - val_acc: 0.8500\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.37799 to 0.37557, saving model to best.model\n",
      "0s - loss: 0.2996 - acc: 0.8685 - val_loss: 0.3756 - val_acc: 0.8500\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.3001 - acc: 0.8815 - val_loss: 0.3775 - val_acc: 0.8500\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.3021 - acc: 0.8833 - val_loss: 0.3816 - val_acc: 0.8500\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2733 - acc: 0.8852 - val_loss: 0.3834 - val_acc: 0.8333\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2802 - acc: 0.8815 - val_loss: 0.3866 - val_acc: 0.8333\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2977 - acc: 0.8778 - val_loss: 0.3896 - val_acc: 0.8333\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2805 - acc: 0.8796 - val_loss: 0.3862 - val_acc: 0.8500\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2968 - acc: 0.8852 - val_loss: 0.3770 - val_acc: 0.8667\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.37557 to 0.37367, saving model to best.model\n",
      "0s - loss: 0.2709 - acc: 0.8852 - val_loss: 0.3737 - val_acc: 0.8500\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2598 - acc: 0.8889 - val_loss: 0.3766 - val_acc: 0.8500\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2763 - acc: 0.8778 - val_loss: 0.3844 - val_acc: 0.8500\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2844 - acc: 0.8852 - val_loss: 0.3832 - val_acc: 0.8500\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2624 - acc: 0.8981 - val_loss: 0.3760 - val_acc: 0.8500\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.37367 to 0.37059, saving model to best.model\n",
      "0s - loss: 0.2835 - acc: 0.8667 - val_loss: 0.3706 - val_acc: 0.8500\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2739 - acc: 0.8963 - val_loss: 0.3711 - val_acc: 0.8500\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2415 - acc: 0.9074 - val_loss: 0.3797 - val_acc: 0.8333\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2928 - acc: 0.8815 - val_loss: 0.3791 - val_acc: 0.8333\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2605 - acc: 0.8944 - val_loss: 0.3743 - val_acc: 0.8333\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.37059 to 0.36673, saving model to best.model\n",
      "0s - loss: 0.2599 - acc: 0.8870 - val_loss: 0.3667 - val_acc: 0.8500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.56099, saving model to best.model\n",
      "0s - loss: 0.8031 - acc: 0.5296 - val_loss: 0.5610 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.56099 to 0.55631, saving model to best.model\n",
      "0s - loss: 0.6941 - acc: 0.6389 - val_loss: 0.5563 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.55631 to 0.54293, saving model to best.model\n",
      "0s - loss: 0.7968 - acc: 0.6352 - val_loss: 0.5429 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.54293 to 0.52756, saving model to best.model\n",
      "0s - loss: 0.7498 - acc: 0.6500 - val_loss: 0.5276 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.52756 to 0.52106, saving model to best.model\n",
      "0s - loss: 0.7320 - acc: 0.6556 - val_loss: 0.5211 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.7114 - acc: 0.6241 - val_loss: 0.5293 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6574 - acc: 0.6426 - val_loss: 0.5413 - val_acc: 0.7167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6356 - acc: 0.6426 - val_loss: 0.5464 - val_acc: 0.7167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6411 - acc: 0.6519 - val_loss: 0.5470 - val_acc: 0.7167\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6287 - acc: 0.6630 - val_loss: 0.5454 - val_acc: 0.7500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6325 - acc: 0.6278 - val_loss: 0.5389 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6430 - acc: 0.6222 - val_loss: 0.5308 - val_acc: 0.7167\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6146 - acc: 0.6704 - val_loss: 0.5238 - val_acc: 0.7167\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.52106 to 0.51793, saving model to best.model\n",
      "0s - loss: 0.6198 - acc: 0.6759 - val_loss: 0.5179 - val_acc: 0.7167\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.51793 to 0.51175, saving model to best.model\n",
      "0s - loss: 0.5961 - acc: 0.6926 - val_loss: 0.5118 - val_acc: 0.7167\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.51175 to 0.50789, saving model to best.model\n",
      "0s - loss: 0.6151 - acc: 0.6852 - val_loss: 0.5079 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.50789 to 0.50660, saving model to best.model\n",
      "0s - loss: 0.5971 - acc: 0.6981 - val_loss: 0.5066 - val_acc: 0.7167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.6055 - acc: 0.6833 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.50660 to 0.50645, saving model to best.model\n",
      "0s - loss: 0.5916 - acc: 0.7037 - val_loss: 0.5064 - val_acc: 0.7667\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.50645 to 0.50544, saving model to best.model\n",
      "0s - loss: 0.5729 - acc: 0.7037 - val_loss: 0.5054 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.50544 to 0.50518, saving model to best.model\n",
      "0s - loss: 0.5964 - acc: 0.6944 - val_loss: 0.5052 - val_acc: 0.7667\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.6010 - acc: 0.6852 - val_loss: 0.5055 - val_acc: 0.7667\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.6085 - acc: 0.6870 - val_loss: 0.5090 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5895 - acc: 0.6852 - val_loss: 0.5126 - val_acc: 0.7667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5639 - acc: 0.6963 - val_loss: 0.5136 - val_acc: 0.7833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5585 - acc: 0.7315 - val_loss: 0.5103 - val_acc: 0.7833\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.50518 to 0.50189, saving model to best.model\n",
      "0s - loss: 0.5575 - acc: 0.7093 - val_loss: 0.5019 - val_acc: 0.7833\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.50189 to 0.49362, saving model to best.model\n",
      "0s - loss: 0.5746 - acc: 0.7167 - val_loss: 0.4936 - val_acc: 0.7833\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.49362 to 0.48922, saving model to best.model\n",
      "0s - loss: 0.5895 - acc: 0.6833 - val_loss: 0.4892 - val_acc: 0.8000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5798 - acc: 0.6815 - val_loss: 0.4896 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.48922 to 0.48908, saving model to best.model\n",
      "0s - loss: 0.5701 - acc: 0.7019 - val_loss: 0.4891 - val_acc: 0.8333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5782 - acc: 0.6944 - val_loss: 0.4899 - val_acc: 0.8167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5589 - acc: 0.6852 - val_loss: 0.4899 - val_acc: 0.8000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5604 - acc: 0.7074 - val_loss: 0.4898 - val_acc: 0.8000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5682 - acc: 0.6981 - val_loss: 0.4907 - val_acc: 0.8167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5586 - acc: 0.7056 - val_loss: 0.4901 - val_acc: 0.8167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5674 - acc: 0.7315 - val_loss: 0.4895 - val_acc: 0.8167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.48908 to 0.48848, saving model to best.model\n",
      "0s - loss: 0.5561 - acc: 0.7056 - val_loss: 0.4885 - val_acc: 0.8000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.48848 to 0.48436, saving model to best.model\n",
      "0s - loss: 0.5376 - acc: 0.7426 - val_loss: 0.4844 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.48436 to 0.47972, saving model to best.model\n",
      "0s - loss: 0.5375 - acc: 0.7370 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.47972 to 0.47588, saving model to best.model\n",
      "0s - loss: 0.5541 - acc: 0.7278 - val_loss: 0.4759 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.47588 to 0.47432, saving model to best.model\n",
      "0s - loss: 0.5460 - acc: 0.7259 - val_loss: 0.4743 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.47432 to 0.47270, saving model to best.model\n",
      "0s - loss: 0.5311 - acc: 0.7389 - val_loss: 0.4727 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.47270 to 0.47151, saving model to best.model\n",
      "0s - loss: 0.5438 - acc: 0.7389 - val_loss: 0.4715 - val_acc: 0.8333\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.47151 to 0.47057, saving model to best.model\n",
      "0s - loss: 0.5421 - acc: 0.7056 - val_loss: 0.4706 - val_acc: 0.8333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5415 - acc: 0.7167 - val_loss: 0.4710 - val_acc: 0.8333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.47057 to 0.47035, saving model to best.model\n",
      "0s - loss: 0.5094 - acc: 0.7259 - val_loss: 0.4703 - val_acc: 0.8333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.47035 to 0.46619, saving model to best.model\n",
      "0s - loss: 0.5345 - acc: 0.7204 - val_loss: 0.4662 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.46619 to 0.46194, saving model to best.model\n",
      "0s - loss: 0.5316 - acc: 0.7259 - val_loss: 0.4619 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.46194 to 0.46080, saving model to best.model\n",
      "0s - loss: 0.5284 - acc: 0.7148 - val_loss: 0.4608 - val_acc: 0.8333\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.46080 to 0.46017, saving model to best.model\n",
      "0s - loss: 0.5353 - acc: 0.7315 - val_loss: 0.4602 - val_acc: 0.8333\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.46017 to 0.45935, saving model to best.model\n",
      "0s - loss: 0.5143 - acc: 0.7370 - val_loss: 0.4594 - val_acc: 0.8333\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.45935 to 0.45930, saving model to best.model\n",
      "0s - loss: 0.5203 - acc: 0.7259 - val_loss: 0.4593 - val_acc: 0.8500\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.45930 to 0.45914, saving model to best.model\n",
      "0s - loss: 0.5416 - acc: 0.7241 - val_loss: 0.4591 - val_acc: 0.8333\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.45914 to 0.45338, saving model to best.model\n",
      "0s - loss: 0.5141 - acc: 0.7574 - val_loss: 0.4534 - val_acc: 0.8333\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.45338 to 0.44591, saving model to best.model\n",
      "0s - loss: 0.5110 - acc: 0.7519 - val_loss: 0.4459 - val_acc: 0.8500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.44591 to 0.44263, saving model to best.model\n",
      "0s - loss: 0.4904 - acc: 0.7463 - val_loss: 0.4426 - val_acc: 0.8500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.44263 to 0.43900, saving model to best.model\n",
      "0s - loss: 0.5326 - acc: 0.7333 - val_loss: 0.4390 - val_acc: 0.8500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.43900 to 0.43583, saving model to best.model\n",
      "0s - loss: 0.5206 - acc: 0.7389 - val_loss: 0.4358 - val_acc: 0.8500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.43583 to 0.43325, saving model to best.model\n",
      "0s - loss: 0.5183 - acc: 0.7296 - val_loss: 0.4333 - val_acc: 0.8333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.43325 to 0.43114, saving model to best.model\n",
      "0s - loss: 0.5156 - acc: 0.7426 - val_loss: 0.4311 - val_acc: 0.8333\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.43114 to 0.42883, saving model to best.model\n",
      "0s - loss: 0.5105 - acc: 0.7556 - val_loss: 0.4288 - val_acc: 0.8333\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.42883 to 0.42704, saving model to best.model\n",
      "0s - loss: 0.4982 - acc: 0.7593 - val_loss: 0.4270 - val_acc: 0.8333\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.5007 - acc: 0.7481 - val_loss: 0.4271 - val_acc: 0.8333\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.42704 to 0.42696, saving model to best.model\n",
      "0s - loss: 0.5042 - acc: 0.7574 - val_loss: 0.4270 - val_acc: 0.8333\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.42696 to 0.42493, saving model to best.model\n",
      "0s - loss: 0.5040 - acc: 0.7574 - val_loss: 0.4249 - val_acc: 0.8333\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.42493 to 0.42080, saving model to best.model\n",
      "0s - loss: 0.4840 - acc: 0.7667 - val_loss: 0.4208 - val_acc: 0.8333\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.42080 to 0.41711, saving model to best.model\n",
      "0s - loss: 0.4855 - acc: 0.7389 - val_loss: 0.4171 - val_acc: 0.8333\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4906 - acc: 0.7667 - val_loss: 0.4173 - val_acc: 0.8333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.5045 - acc: 0.7630 - val_loss: 0.4177 - val_acc: 0.8333\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.5066 - acc: 0.7685 - val_loss: 0.4177 - val_acc: 0.8333\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.41711 to 0.41443, saving model to best.model\n",
      "0s - loss: 0.4758 - acc: 0.7796 - val_loss: 0.4144 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.41443 to 0.41188, saving model to best.model\n",
      "0s - loss: 0.4769 - acc: 0.7944 - val_loss: 0.4119 - val_acc: 0.8500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.41188 to 0.40935, saving model to best.model\n",
      "0s - loss: 0.4862 - acc: 0.7685 - val_loss: 0.4094 - val_acc: 0.8333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.40935 to 0.40576, saving model to best.model\n",
      "0s - loss: 0.4599 - acc: 0.7852 - val_loss: 0.4058 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.40576 to 0.40296, saving model to best.model\n",
      "0s - loss: 0.4664 - acc: 0.7778 - val_loss: 0.4030 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4906 - acc: 0.7500 - val_loss: 0.4037 - val_acc: 0.8333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4638 - acc: 0.7741 - val_loss: 0.4069 - val_acc: 0.8167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4703 - acc: 0.7704 - val_loss: 0.4117 - val_acc: 0.8167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4595 - acc: 0.7889 - val_loss: 0.4149 - val_acc: 0.8167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4722 - acc: 0.7426 - val_loss: 0.4138 - val_acc: 0.8167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4723 - acc: 0.7815 - val_loss: 0.4129 - val_acc: 0.8500\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4713 - acc: 0.7778 - val_loss: 0.4114 - val_acc: 0.8500\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4575 - acc: 0.7815 - val_loss: 0.4094 - val_acc: 0.8333\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4699 - acc: 0.7611 - val_loss: 0.4063 - val_acc: 0.8333\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4825 - acc: 0.7537 - val_loss: 0.4050 - val_acc: 0.8500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4728 - acc: 0.7981 - val_loss: 0.4052 - val_acc: 0.8333\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4567 - acc: 0.7870 - val_loss: 0.4058 - val_acc: 0.8333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4629 - acc: 0.7907 - val_loss: 0.4083 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4486 - acc: 0.7852 - val_loss: 0.4107 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4708 - acc: 0.7611 - val_loss: 0.4104 - val_acc: 0.8333\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4379 - acc: 0.8000 - val_loss: 0.4065 - val_acc: 0.8333\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.40296 to 0.40173, saving model to best.model\n",
      "0s - loss: 0.4610 - acc: 0.7722 - val_loss: 0.4017 - val_acc: 0.8333\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.40173 to 0.39808, saving model to best.model\n",
      "0s - loss: 0.4304 - acc: 0.7889 - val_loss: 0.3981 - val_acc: 0.8667\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.39808 to 0.39657, saving model to best.model\n",
      "0s - loss: 0.4103 - acc: 0.8074 - val_loss: 0.3966 - val_acc: 0.8667\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4383 - acc: 0.7889 - val_loss: 0.3966 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4375 - acc: 0.7944 - val_loss: 0.3977 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4173 - acc: 0.8167 - val_loss: 0.3986 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4672 - acc: 0.7704 - val_loss: 0.4026 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4231 - acc: 0.8000 - val_loss: 0.4078 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4245 - acc: 0.7852 - val_loss: 0.4102 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4283 - acc: 0.8056 - val_loss: 0.4095 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4195 - acc: 0.8130 - val_loss: 0.4101 - val_acc: 0.8333\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4319 - acc: 0.7907 - val_loss: 0.4089 - val_acc: 0.8333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4194 - acc: 0.8204 - val_loss: 0.4057 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4279 - acc: 0.7852 - val_loss: 0.4032 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3912 - acc: 0.8296 - val_loss: 0.3989 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4205 - acc: 0.8259 - val_loss: 0.3986 - val_acc: 0.8333\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3911 - acc: 0.8426 - val_loss: 0.3996 - val_acc: 0.8500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3877 - acc: 0.8315 - val_loss: 0.4015 - val_acc: 0.8500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4052 - acc: 0.8204 - val_loss: 0.4029 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3885 - acc: 0.8278 - val_loss: 0.4033 - val_acc: 0.8333\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3941 - acc: 0.8185 - val_loss: 0.4023 - val_acc: 0.8333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4004 - val_acc: 0.8333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.39657 to 0.39294, saving model to best.model\n",
      "0s - loss: 0.4031 - acc: 0.8167 - val_loss: 0.3929 - val_acc: 0.8333\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.39294 to 0.38647, saving model to best.model\n",
      "0s - loss: 0.3896 - acc: 0.8204 - val_loss: 0.3865 - val_acc: 0.8333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.38647 to 0.38286, saving model to best.model\n",
      "0s - loss: 0.3967 - acc: 0.8037 - val_loss: 0.3829 - val_acc: 0.8333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.38286 to 0.38280, saving model to best.model\n",
      "0s - loss: 0.3717 - acc: 0.8370 - val_loss: 0.3828 - val_acc: 0.8333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3906 - acc: 0.8185 - val_loss: 0.3857 - val_acc: 0.8333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3792 - acc: 0.8204 - val_loss: 0.3880 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3921 - acc: 0.8259 - val_loss: 0.3870 - val_acc: 0.8333\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.4023 - acc: 0.8130 - val_loss: 0.3875 - val_acc: 0.8333\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.4074 - acc: 0.8130 - val_loss: 0.3887 - val_acc: 0.8333\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3861 - acc: 0.8315 - val_loss: 0.3929 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3668 - acc: 0.8185 - val_loss: 0.4019 - val_acc: 0.8333\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3730 - acc: 0.8241 - val_loss: 0.4039 - val_acc: 0.8333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3788 - acc: 0.8315 - val_loss: 0.3945 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3832 - acc: 0.8333 - val_loss: 0.3871 - val_acc: 0.8500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3790 - acc: 0.8315 - val_loss: 0.3868 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3678 - acc: 0.8111 - val_loss: 0.3908 - val_acc: 0.8500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3680 - acc: 0.8370 - val_loss: 0.3991 - val_acc: 0.8500\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3494 - acc: 0.8500 - val_loss: 0.4071 - val_acc: 0.8500\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3643 - acc: 0.8463 - val_loss: 0.4121 - val_acc: 0.8333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3537 - acc: 0.8389 - val_loss: 0.4162 - val_acc: 0.8500\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3645 - acc: 0.8463 - val_loss: 0.4224 - val_acc: 0.8500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3504 - acc: 0.8481 - val_loss: 0.4241 - val_acc: 0.8500\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3690 - acc: 0.8278 - val_loss: 0.4235 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3598 - acc: 0.8426 - val_loss: 0.4221 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3217 - acc: 0.8593 - val_loss: 0.4197 - val_acc: 0.8167\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3119 - acc: 0.8648 - val_loss: 0.4139 - val_acc: 0.8167\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3604 - acc: 0.8407 - val_loss: 0.4075 - val_acc: 0.8167\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3321 - acc: 0.8556 - val_loss: 0.4039 - val_acc: 0.8167\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3508 - acc: 0.8463 - val_loss: 0.4053 - val_acc: 0.8333\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3426 - acc: 0.8574 - val_loss: 0.4104 - val_acc: 0.8500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.64718, saving model to best.model\n",
      "0s - loss: 0.7107 - acc: 0.5704 - val_loss: 0.6472 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.64718 to 0.63837, saving model to best.model\n",
      "0s - loss: 0.6962 - acc: 0.6519 - val_loss: 0.6384 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.63837 to 0.61724, saving model to best.model\n",
      "0s - loss: 0.6938 - acc: 0.6704 - val_loss: 0.6172 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61724 to 0.60589, saving model to best.model\n",
      "0s - loss: 0.6790 - acc: 0.6630 - val_loss: 0.6059 - val_acc: 0.6500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.60589 to 0.60242, saving model to best.model\n",
      "0s - loss: 0.6283 - acc: 0.6667 - val_loss: 0.6024 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.60242 to 0.59948, saving model to best.model\n",
      "0s - loss: 0.6537 - acc: 0.6500 - val_loss: 0.5995 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.59948 to 0.59535, saving model to best.model\n",
      "0s - loss: 0.6083 - acc: 0.6741 - val_loss: 0.5954 - val_acc: 0.6833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.59535 to 0.58963, saving model to best.model\n",
      "0s - loss: 0.6231 - acc: 0.6537 - val_loss: 0.5896 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.58963 to 0.58484, saving model to best.model\n",
      "0s - loss: 0.6036 - acc: 0.6815 - val_loss: 0.5848 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.58484 to 0.58124, saving model to best.model\n",
      "0s - loss: 0.5986 - acc: 0.6944 - val_loss: 0.5812 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.58124 to 0.57871, saving model to best.model\n",
      "0s - loss: 0.6064 - acc: 0.7056 - val_loss: 0.5787 - val_acc: 0.6833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.57871 to 0.57514, saving model to best.model\n",
      "0s - loss: 0.5953 - acc: 0.6963 - val_loss: 0.5751 - val_acc: 0.6833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.57514 to 0.57313, saving model to best.model\n",
      "0s - loss: 0.5802 - acc: 0.7019 - val_loss: 0.5731 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.57313 to 0.56939, saving model to best.model\n",
      "0s - loss: 0.5717 - acc: 0.7148 - val_loss: 0.5694 - val_acc: 0.7000\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.56939 to 0.56660, saving model to best.model\n",
      "0s - loss: 0.5680 - acc: 0.7130 - val_loss: 0.5666 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.56660 to 0.56337, saving model to best.model\n",
      "0s - loss: 0.5691 - acc: 0.6963 - val_loss: 0.5634 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.56337 to 0.55888, saving model to best.model\n",
      "0s - loss: 0.6021 - acc: 0.6963 - val_loss: 0.5589 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.55888 to 0.55293, saving model to best.model\n",
      "0s - loss: 0.5825 - acc: 0.7037 - val_loss: 0.5529 - val_acc: 0.7167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.55293 to 0.54665, saving model to best.model\n",
      "0s - loss: 0.5619 - acc: 0.7315 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.54665 to 0.54099, saving model to best.model\n",
      "0s - loss: 0.5691 - acc: 0.7259 - val_loss: 0.5410 - val_acc: 0.7500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.54099 to 0.53759, saving model to best.model\n",
      "0s - loss: 0.5495 - acc: 0.7148 - val_loss: 0.5376 - val_acc: 0.7500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.53759 to 0.53284, saving model to best.model\n",
      "0s - loss: 0.5400 - acc: 0.7611 - val_loss: 0.5328 - val_acc: 0.7500\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.53284 to 0.52795, saving model to best.model\n",
      "0s - loss: 0.5568 - acc: 0.7111 - val_loss: 0.5280 - val_acc: 0.7500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52795 to 0.52426, saving model to best.model\n",
      "0s - loss: 0.5316 - acc: 0.7241 - val_loss: 0.5243 - val_acc: 0.7500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.52426 to 0.52046, saving model to best.model\n",
      "0s - loss: 0.5160 - acc: 0.7463 - val_loss: 0.5205 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52046 to 0.51663, saving model to best.model\n",
      "0s - loss: 0.5150 - acc: 0.7407 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.51663 to 0.51270, saving model to best.model\n",
      "0s - loss: 0.5243 - acc: 0.7426 - val_loss: 0.5127 - val_acc: 0.7500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.51270 to 0.50967, saving model to best.model\n",
      "0s - loss: 0.5413 - acc: 0.7426 - val_loss: 0.5097 - val_acc: 0.7667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.50967 to 0.50819, saving model to best.model\n",
      "0s - loss: 0.5111 - acc: 0.7426 - val_loss: 0.5082 - val_acc: 0.7667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.50819 to 0.50771, saving model to best.model\n",
      "0s - loss: 0.5159 - acc: 0.7222 - val_loss: 0.5077 - val_acc: 0.7667\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.50771 to 0.50645, saving model to best.model\n",
      "0s - loss: 0.5156 - acc: 0.7352 - val_loss: 0.5064 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.50645 to 0.50432, saving model to best.model\n",
      "0s - loss: 0.4970 - acc: 0.7519 - val_loss: 0.5043 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.50432 to 0.50242, saving model to best.model\n",
      "0s - loss: 0.5383 - acc: 0.7222 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.50242 to 0.50063, saving model to best.model\n",
      "0s - loss: 0.5170 - acc: 0.7444 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.50063 to 0.49732, saving model to best.model\n",
      "0s - loss: 0.4864 - acc: 0.7704 - val_loss: 0.4973 - val_acc: 0.7500\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.49732 to 0.49476, saving model to best.model\n",
      "0s - loss: 0.5196 - acc: 0.7444 - val_loss: 0.4948 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.49476 to 0.49297, saving model to best.model\n",
      "0s - loss: 0.5180 - acc: 0.7352 - val_loss: 0.4930 - val_acc: 0.7833\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.49297 to 0.49236, saving model to best.model\n",
      "0s - loss: 0.4992 - acc: 0.7481 - val_loss: 0.4924 - val_acc: 0.7667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.49236 to 0.49235, saving model to best.model\n",
      "0s - loss: 0.5059 - acc: 0.7630 - val_loss: 0.4924 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.49235 to 0.49113, saving model to best.model\n",
      "0s - loss: 0.4980 - acc: 0.7704 - val_loss: 0.4911 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.49113 to 0.48916, saving model to best.model\n",
      "0s - loss: 0.4875 - acc: 0.7611 - val_loss: 0.4892 - val_acc: 0.7667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.48916 to 0.48761, saving model to best.model\n",
      "0s - loss: 0.4942 - acc: 0.7611 - val_loss: 0.4876 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.48761 to 0.48685, saving model to best.model\n",
      "0s - loss: 0.4979 - acc: 0.7667 - val_loss: 0.4869 - val_acc: 0.7833\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4730 - acc: 0.7500 - val_loss: 0.4874 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4842 - acc: 0.7778 - val_loss: 0.4875 - val_acc: 0.7833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4860 - acc: 0.7500 - val_loss: 0.4870 - val_acc: 0.7833\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.48685 to 0.48616, saving model to best.model\n",
      "0s - loss: 0.4961 - acc: 0.7463 - val_loss: 0.4862 - val_acc: 0.7833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.48616 to 0.48589, saving model to best.model\n",
      "0s - loss: 0.4936 - acc: 0.7611 - val_loss: 0.4859 - val_acc: 0.7667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.48589 to 0.48513, saving model to best.model\n",
      "0s - loss: 0.4970 - acc: 0.7407 - val_loss: 0.4851 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.48513 to 0.48377, saving model to best.model\n",
      "0s - loss: 0.4825 - acc: 0.7722 - val_loss: 0.4838 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.48377 to 0.48276, saving model to best.model\n",
      "0s - loss: 0.4805 - acc: 0.7667 - val_loss: 0.4828 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.48276 to 0.48268, saving model to best.model\n",
      "0s - loss: 0.4822 - acc: 0.7611 - val_loss: 0.4827 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.48268 to 0.48215, saving model to best.model\n",
      "0s - loss: 0.4630 - acc: 0.7815 - val_loss: 0.4821 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.48215 to 0.48064, saving model to best.model\n",
      "0s - loss: 0.4585 - acc: 0.7704 - val_loss: 0.4806 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.48064 to 0.47946, saving model to best.model\n",
      "0s - loss: 0.4828 - acc: 0.7593 - val_loss: 0.4795 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.47946 to 0.47788, saving model to best.model\n",
      "0s - loss: 0.4495 - acc: 0.7889 - val_loss: 0.4779 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.47788 to 0.47543, saving model to best.model\n",
      "0s - loss: 0.4663 - acc: 0.7741 - val_loss: 0.4754 - val_acc: 0.7667\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.47543 to 0.47285, saving model to best.model\n",
      "0s - loss: 0.4710 - acc: 0.7704 - val_loss: 0.4729 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.47285 to 0.46941, saving model to best.model\n",
      "0s - loss: 0.4636 - acc: 0.7852 - val_loss: 0.4694 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.46941 to 0.46643, saving model to best.model\n",
      "0s - loss: 0.4536 - acc: 0.7852 - val_loss: 0.4664 - val_acc: 0.7500\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.46643 to 0.46600, saving model to best.model\n",
      "0s - loss: 0.4578 - acc: 0.7704 - val_loss: 0.4660 - val_acc: 0.7333\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.46600 to 0.46507, saving model to best.model\n",
      "0s - loss: 0.4494 - acc: 0.7926 - val_loss: 0.4651 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.46507 to 0.46340, saving model to best.model\n",
      "0s - loss: 0.4684 - acc: 0.7852 - val_loss: 0.4634 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.46340 to 0.46192, saving model to best.model\n",
      "0s - loss: 0.4432 - acc: 0.7889 - val_loss: 0.4619 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.46192 to 0.46146, saving model to best.model\n",
      "0s - loss: 0.4423 - acc: 0.7981 - val_loss: 0.4615 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.46146 to 0.46106, saving model to best.model\n",
      "0s - loss: 0.4593 - acc: 0.7704 - val_loss: 0.4611 - val_acc: 0.7500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.46106 to 0.45981, saving model to best.model\n",
      "0s - loss: 0.4589 - acc: 0.7722 - val_loss: 0.4598 - val_acc: 0.7500\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.45981 to 0.45873, saving model to best.model\n",
      "0s - loss: 0.4193 - acc: 0.7944 - val_loss: 0.4587 - val_acc: 0.7500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4313 - acc: 0.7870 - val_loss: 0.4593 - val_acc: 0.7500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4291 - acc: 0.8037 - val_loss: 0.4603 - val_acc: 0.7500\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4140 - acc: 0.8130 - val_loss: 0.4606 - val_acc: 0.7500\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4404 - acc: 0.7852 - val_loss: 0.4610 - val_acc: 0.7500\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4000 - acc: 0.8148 - val_loss: 0.4592 - val_acc: 0.7500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.45873 to 0.45848, saving model to best.model\n",
      "0s - loss: 0.4271 - acc: 0.8019 - val_loss: 0.4585 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4069 - acc: 0.8037 - val_loss: 0.4602 - val_acc: 0.7500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4102 - acc: 0.7963 - val_loss: 0.4632 - val_acc: 0.7333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4326 - acc: 0.7963 - val_loss: 0.4622 - val_acc: 0.7500\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4272 - acc: 0.7833 - val_loss: 0.4591 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.45848 to 0.45591, saving model to best.model\n",
      "0s - loss: 0.4400 - acc: 0.7907 - val_loss: 0.4559 - val_acc: 0.7500\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.45591 to 0.45526, saving model to best.model\n",
      "0s - loss: 0.4056 - acc: 0.7907 - val_loss: 0.4553 - val_acc: 0.7667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4131 - acc: 0.8241 - val_loss: 0.4563 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4242 - acc: 0.7870 - val_loss: 0.4571 - val_acc: 0.7667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4072 - acc: 0.8000 - val_loss: 0.4580 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4018 - acc: 0.8111 - val_loss: 0.4588 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4147 - acc: 0.8111 - val_loss: 0.4589 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4193 - acc: 0.7981 - val_loss: 0.4578 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4183 - acc: 0.8074 - val_loss: 0.4590 - val_acc: 0.7833\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.3894 - acc: 0.8185 - val_loss: 0.4638 - val_acc: 0.7667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4118 - acc: 0.8037 - val_loss: 0.4652 - val_acc: 0.7833\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4025 - acc: 0.8093 - val_loss: 0.4625 - val_acc: 0.7833\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3975 - acc: 0.8037 - val_loss: 0.4615 - val_acc: 0.7833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4108 - acc: 0.8093 - val_loss: 0.4631 - val_acc: 0.7833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4160 - acc: 0.8019 - val_loss: 0.4666 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.3937 - acc: 0.8093 - val_loss: 0.4675 - val_acc: 0.7833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3934 - acc: 0.8241 - val_loss: 0.4624 - val_acc: 0.7833\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3772 - acc: 0.8204 - val_loss: 0.4557 - val_acc: 0.7833\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.45526 to 0.45022, saving model to best.model\n",
      "0s - loss: 0.4051 - acc: 0.8204 - val_loss: 0.4502 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.45022 to 0.44579, saving model to best.model\n",
      "0s - loss: 0.4007 - acc: 0.8037 - val_loss: 0.4458 - val_acc: 0.8000\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.44579 to 0.44238, saving model to best.model\n",
      "0s - loss: 0.4144 - acc: 0.8111 - val_loss: 0.4424 - val_acc: 0.8000\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.44238 to 0.43886, saving model to best.model\n",
      "0s - loss: 0.3927 - acc: 0.8148 - val_loss: 0.4389 - val_acc: 0.8000\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.43886 to 0.43508, saving model to best.model\n",
      "0s - loss: 0.3912 - acc: 0.8185 - val_loss: 0.4351 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.43508 to 0.43397, saving model to best.model\n",
      "0s - loss: 0.3771 - acc: 0.8130 - val_loss: 0.4340 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3554 - acc: 0.8444 - val_loss: 0.4360 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3719 - acc: 0.8315 - val_loss: 0.4408 - val_acc: 0.7833\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4229 - acc: 0.8130 - val_loss: 0.4414 - val_acc: 0.7833\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3750 - acc: 0.8148 - val_loss: 0.4427 - val_acc: 0.8000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3806 - acc: 0.8130 - val_loss: 0.4405 - val_acc: 0.8000\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3950 - acc: 0.8278 - val_loss: 0.4368 - val_acc: 0.8000\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3816 - acc: 0.8500 - val_loss: 0.4355 - val_acc: 0.8000\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3606 - acc: 0.8426 - val_loss: 0.4360 - val_acc: 0.8000\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3641 - acc: 0.8333 - val_loss: 0.4375 - val_acc: 0.8000\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3684 - acc: 0.8389 - val_loss: 0.4374 - val_acc: 0.8000\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3516 - acc: 0.8370 - val_loss: 0.4355 - val_acc: 0.8167\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3544 - acc: 0.8370 - val_loss: 0.4361 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3802 - acc: 0.8278 - val_loss: 0.4362 - val_acc: 0.8167\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3667 - acc: 0.8519 - val_loss: 0.4384 - val_acc: 0.8167\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3427 - acc: 0.8481 - val_loss: 0.4442 - val_acc: 0.7833\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3841 - acc: 0.8204 - val_loss: 0.4490 - val_acc: 0.7667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3698 - acc: 0.8333 - val_loss: 0.4487 - val_acc: 0.7667\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3369 - acc: 0.8500 - val_loss: 0.4427 - val_acc: 0.7667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.43397 to 0.43233, saving model to best.model\n",
      "0s - loss: 0.3361 - acc: 0.8500 - val_loss: 0.4323 - val_acc: 0.7667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.43233 to 0.42133, saving model to best.model\n",
      "0s - loss: 0.3550 - acc: 0.8333 - val_loss: 0.4213 - val_acc: 0.7833\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.42133 to 0.41639, saving model to best.model\n",
      "0s - loss: 0.3512 - acc: 0.8426 - val_loss: 0.4164 - val_acc: 0.8333\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3531 - acc: 0.8315 - val_loss: 0.4186 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3421 - acc: 0.8444 - val_loss: 0.4223 - val_acc: 0.8167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3388 - acc: 0.8537 - val_loss: 0.4276 - val_acc: 0.8333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3354 - acc: 0.8463 - val_loss: 0.4346 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3481 - acc: 0.8463 - val_loss: 0.4340 - val_acc: 0.8333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3475 - acc: 0.8389 - val_loss: 0.4323 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3382 - acc: 0.8556 - val_loss: 0.4286 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3308 - acc: 0.8519 - val_loss: 0.4254 - val_acc: 0.8167\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3268 - acc: 0.8481 - val_loss: 0.4231 - val_acc: 0.8167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3115 - acc: 0.8630 - val_loss: 0.4218 - val_acc: 0.8333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3073 - acc: 0.8741 - val_loss: 0.4225 - val_acc: 0.8167\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3233 - acc: 0.8574 - val_loss: 0.4242 - val_acc: 0.8167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3351 - acc: 0.8574 - val_loss: 0.4238 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3101 - acc: 0.8722 - val_loss: 0.4204 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.41639 to 0.41341, saving model to best.model\n",
      "0s - loss: 0.3264 - acc: 0.8500 - val_loss: 0.4134 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.41341 to 0.40958, saving model to best.model\n",
      "0s - loss: 0.3015 - acc: 0.8685 - val_loss: 0.4096 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.40958 to 0.40933, saving model to best.model\n",
      "0s - loss: 0.3309 - acc: 0.8685 - val_loss: 0.4093 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3013 - acc: 0.8667 - val_loss: 0.4105 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3118 - acc: 0.8685 - val_loss: 0.4098 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3345 - acc: 0.8574 - val_loss: 0.4095 - val_acc: 0.8500\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.40933 to 0.40890, saving model to best.model\n",
      "0s - loss: 0.3146 - acc: 0.8519 - val_loss: 0.4089 - val_acc: 0.8500\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3175 - acc: 0.8481 - val_loss: 0.4118 - val_acc: 0.8167\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3383 - acc: 0.8593 - val_loss: 0.4130 - val_acc: 0.8500\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3123 - acc: 0.8815 - val_loss: 0.4156 - val_acc: 0.8500\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3270 - acc: 0.8407 - val_loss: 0.4122 - val_acc: 0.8500\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.40890 to 0.40690, saving model to best.model\n",
      "0s - loss: 0.3002 - acc: 0.8796 - val_loss: 0.4069 - val_acc: 0.8500\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.40690 to 0.40600, saving model to best.model\n",
      "0s - loss: 0.2912 - acc: 0.8704 - val_loss: 0.4060 - val_acc: 0.8667\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3195 - acc: 0.8630 - val_loss: 0.4113 - val_acc: 0.8500\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.2880 - acc: 0.8722 - val_loss: 0.4168 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.2779 - acc: 0.8870 - val_loss: 0.4179 - val_acc: 0.8667\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.2829 - acc: 0.8852 - val_loss: 0.4217 - val_acc: 0.8667\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3053 - acc: 0.8833 - val_loss: 0.4142 - val_acc: 0.8500\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2522 - acc: 0.9037 - val_loss: 0.4085 - val_acc: 0.8500\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.40600 to 0.40137, saving model to best.model\n",
      "0s - loss: 0.2956 - acc: 0.8796 - val_loss: 0.4014 - val_acc: 0.8500\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.40137 to 0.39632, saving model to best.model\n",
      "0s - loss: 0.2614 - acc: 0.8926 - val_loss: 0.3963 - val_acc: 0.8500\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.39632 to 0.39222, saving model to best.model\n",
      "0s - loss: 0.2671 - acc: 0.8833 - val_loss: 0.3922 - val_acc: 0.8667\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2702 - acc: 0.8796 - val_loss: 0.3973 - val_acc: 0.8500\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2622 - acc: 0.8944 - val_loss: 0.4059 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2865 - acc: 0.8889 - val_loss: 0.4172 - val_acc: 0.8500\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3249 - acc: 0.8537 - val_loss: 0.4172 - val_acc: 0.8500\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3076 - acc: 0.8722 - val_loss: 0.4050 - val_acc: 0.8333\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2919 - acc: 0.8722 - val_loss: 0.3971 - val_acc: 0.8333\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2677 - acc: 0.8926 - val_loss: 0.3964 - val_acc: 0.8167\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2881 - acc: 0.8833 - val_loss: 0.3983 - val_acc: 0.8167\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2805 - acc: 0.8759 - val_loss: 0.4017 - val_acc: 0.8167\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2677 - acc: 0.8926 - val_loss: 0.4077 - val_acc: 0.8333\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2925 - acc: 0.8741 - val_loss: 0.4132 - val_acc: 0.8667\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2335 - acc: 0.9148 - val_loss: 0.4197 - val_acc: 0.8500\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2435 - acc: 0.9167 - val_loss: 0.4172 - val_acc: 0.8500\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.2778 - acc: 0.8963 - val_loss: 0.4026 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.39222 to 0.39049, saving model to best.model\n",
      "0s - loss: 0.2813 - acc: 0.8889 - val_loss: 0.3905 - val_acc: 0.8833\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2626 - acc: 0.8926 - val_loss: 0.3906 - val_acc: 0.8833\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2715 - acc: 0.8889 - val_loss: 0.3937 - val_acc: 0.8833\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2254 - acc: 0.9093 - val_loss: 0.3978 - val_acc: 0.8833\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2566 - acc: 0.8944 - val_loss: 0.4021 - val_acc: 0.8833\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2343 - acc: 0.8889 - val_loss: 0.3997 - val_acc: 0.8833\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2564 - acc: 0.9019 - val_loss: 0.3973 - val_acc: 0.8833\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2682 - acc: 0.8852 - val_loss: 0.3936 - val_acc: 0.8833\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.39049 to 0.38919, saving model to best.model\n",
      "0s - loss: 0.2734 - acc: 0.8815 - val_loss: 0.3892 - val_acc: 0.8500\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.38919 to 0.38106, saving model to best.model\n",
      "0s - loss: 0.2256 - acc: 0.9074 - val_loss: 0.3811 - val_acc: 0.8500\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.38106 to 0.37203, saving model to best.model\n",
      "0s - loss: 0.2323 - acc: 0.9111 - val_loss: 0.3720 - val_acc: 0.8500\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2499 - acc: 0.9019 - val_loss: 0.3722 - val_acc: 0.8667\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2524 - acc: 0.8926 - val_loss: 0.3795 - val_acc: 0.8667\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2528 - acc: 0.8981 - val_loss: 0.3857 - val_acc: 0.8500\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2713 - acc: 0.9000 - val_loss: 0.3881 - val_acc: 0.8500\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2491 - acc: 0.9074 - val_loss: 0.3925 - val_acc: 0.8500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.2316 - acc: 0.9000 - val_loss: 0.4028 - val_acc: 0.8500\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2434 - acc: 0.9000 - val_loss: 0.4068 - val_acc: 0.8500\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2464 - acc: 0.9074 - val_loss: 0.4093 - val_acc: 0.8500\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2074 - acc: 0.9130 - val_loss: 0.4109 - val_acc: 0.8667\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2594 - acc: 0.8889 - val_loss: 0.4056 - val_acc: 0.8667\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2274 - acc: 0.9130 - val_loss: 0.4024 - val_acc: 0.8667\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2256 - acc: 0.9000 - val_loss: 0.4002 - val_acc: 0.8667\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2247 - acc: 0.9278 - val_loss: 0.4003 - val_acc: 0.8667\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.1946 - acc: 0.9333 - val_loss: 0.4066 - val_acc: 0.8667\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2175 - acc: 0.9167 - val_loss: 0.4190 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2123 - acc: 0.9148 - val_loss: 0.4236 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.61973, saving model to best.model\n",
      "0s - loss: 0.7430 - acc: 0.6204 - val_loss: 0.6197 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.61973 to 0.60705, saving model to best.model\n",
      "0s - loss: 0.7592 - acc: 0.6556 - val_loss: 0.6070 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.60705 to 0.60548, saving model to best.model\n",
      "0s - loss: 0.6999 - acc: 0.6556 - val_loss: 0.6055 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6919 - acc: 0.6463 - val_loss: 0.6071 - val_acc: 0.6333\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6715 - acc: 0.6648 - val_loss: 0.6075 - val_acc: 0.6333\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.60548 to 0.60459, saving model to best.model\n",
      "0s - loss: 0.6639 - acc: 0.6556 - val_loss: 0.6046 - val_acc: 0.6333\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.60459 to 0.60039, saving model to best.model\n",
      "0s - loss: 0.6301 - acc: 0.6722 - val_loss: 0.6004 - val_acc: 0.6333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.60039 to 0.59297, saving model to best.model\n",
      "0s - loss: 0.6363 - acc: 0.6667 - val_loss: 0.5930 - val_acc: 0.6333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.59297 to 0.58623, saving model to best.model\n",
      "0s - loss: 0.6447 - acc: 0.6889 - val_loss: 0.5862 - val_acc: 0.6333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.58623 to 0.58124, saving model to best.model\n",
      "0s - loss: 0.5965 - acc: 0.6907 - val_loss: 0.5812 - val_acc: 0.6167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.58124 to 0.57605, saving model to best.model\n",
      "0s - loss: 0.6064 - acc: 0.6648 - val_loss: 0.5760 - val_acc: 0.6500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.57605 to 0.57229, saving model to best.model\n",
      "0s - loss: 0.5956 - acc: 0.7130 - val_loss: 0.5723 - val_acc: 0.6500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.57229 to 0.57048, saving model to best.model\n",
      "0s - loss: 0.5982 - acc: 0.6889 - val_loss: 0.5705 - val_acc: 0.6500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6255 - acc: 0.6778 - val_loss: 0.5711 - val_acc: 0.6500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5875 - acc: 0.6981 - val_loss: 0.5747 - val_acc: 0.6333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6054 - acc: 0.6778 - val_loss: 0.5755 - val_acc: 0.6500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5927 - acc: 0.6852 - val_loss: 0.5742 - val_acc: 0.6667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5785 - acc: 0.6852 - val_loss: 0.5716 - val_acc: 0.6833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.57048 to 0.56669, saving model to best.model\n",
      "0s - loss: 0.5896 - acc: 0.6889 - val_loss: 0.5667 - val_acc: 0.6833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.56669 to 0.56276, saving model to best.model\n",
      "0s - loss: 0.6100 - acc: 0.7000 - val_loss: 0.5628 - val_acc: 0.6667\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.56276 to 0.56086, saving model to best.model\n",
      "0s - loss: 0.5778 - acc: 0.6944 - val_loss: 0.5609 - val_acc: 0.6667\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5633 - acc: 0.7000 - val_loss: 0.5619 - val_acc: 0.6833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5741 - acc: 0.7037 - val_loss: 0.5643 - val_acc: 0.6833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5699 - acc: 0.7074 - val_loss: 0.5645 - val_acc: 0.6833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5755 - acc: 0.7019 - val_loss: 0.5654 - val_acc: 0.7167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5687 - acc: 0.7074 - val_loss: 0.5659 - val_acc: 0.7167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5529 - acc: 0.7296 - val_loss: 0.5662 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5599 - acc: 0.7241 - val_loss: 0.5643 - val_acc: 0.7167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5453 - acc: 0.7222 - val_loss: 0.5621 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.56086 to 0.55823, saving model to best.model\n",
      "0s - loss: 0.5599 - acc: 0.7130 - val_loss: 0.5582 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.55823 to 0.55336, saving model to best.model\n",
      "0s - loss: 0.5731 - acc: 0.7222 - val_loss: 0.5534 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.55336 to 0.54911, saving model to best.model\n",
      "0s - loss: 0.5392 - acc: 0.7463 - val_loss: 0.5491 - val_acc: 0.7333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.54911 to 0.54634, saving model to best.model\n",
      "0s - loss: 0.5434 - acc: 0.7426 - val_loss: 0.5463 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.54634 to 0.54369, saving model to best.model\n",
      "0s - loss: 0.5396 - acc: 0.7296 - val_loss: 0.5437 - val_acc: 0.7333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.54369 to 0.53962, saving model to best.model\n",
      "0s - loss: 0.5307 - acc: 0.7407 - val_loss: 0.5396 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.53962 to 0.53824, saving model to best.model\n",
      "0s - loss: 0.5354 - acc: 0.7444 - val_loss: 0.5382 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5178 - acc: 0.7537 - val_loss: 0.5392 - val_acc: 0.7167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5223 - acc: 0.7481 - val_loss: 0.5390 - val_acc: 0.7167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5388 - acc: 0.7333 - val_loss: 0.5418 - val_acc: 0.7500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5220 - acc: 0.7648 - val_loss: 0.5475 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5186 - acc: 0.7481 - val_loss: 0.5532 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5426 - acc: 0.7352 - val_loss: 0.5539 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5392 - acc: 0.7574 - val_loss: 0.5475 - val_acc: 0.7833\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5334 - acc: 0.7481 - val_loss: 0.5399 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.53824 to 0.53200, saving model to best.model\n",
      "0s - loss: 0.5340 - acc: 0.7556 - val_loss: 0.5320 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.53200 to 0.52729, saving model to best.model\n",
      "0s - loss: 0.5079 - acc: 0.7481 - val_loss: 0.5273 - val_acc: 0.7333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.52729 to 0.52499, saving model to best.model\n",
      "0s - loss: 0.5195 - acc: 0.7574 - val_loss: 0.5250 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.52499 to 0.52399, saving model to best.model\n",
      "0s - loss: 0.5234 - acc: 0.7556 - val_loss: 0.5240 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.52399 to 0.52283, saving model to best.model\n",
      "0s - loss: 0.5230 - acc: 0.7481 - val_loss: 0.5228 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5052 - acc: 0.7481 - val_loss: 0.5232 - val_acc: 0.7833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.52283 to 0.52251, saving model to best.model\n",
      "0s - loss: 0.5064 - acc: 0.7574 - val_loss: 0.5225 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4939 - acc: 0.7685 - val_loss: 0.5247 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5081 - acc: 0.7630 - val_loss: 0.5242 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.52251 to 0.51994, saving model to best.model\n",
      "0s - loss: 0.4730 - acc: 0.7815 - val_loss: 0.5199 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.51994 to 0.51718, saving model to best.model\n",
      "0s - loss: 0.5001 - acc: 0.7704 - val_loss: 0.5172 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.51718 to 0.51534, saving model to best.model\n",
      "0s - loss: 0.4663 - acc: 0.7852 - val_loss: 0.5153 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5003 - acc: 0.7556 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.51534 to 0.51413, saving model to best.model\n",
      "0s - loss: 0.4602 - acc: 0.7889 - val_loss: 0.5141 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.51413 to 0.51078, saving model to best.model\n",
      "0s - loss: 0.4978 - acc: 0.7630 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.51078 to 0.50814, saving model to best.model\n",
      "0s - loss: 0.4919 - acc: 0.7778 - val_loss: 0.5081 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4724 - acc: 0.7926 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4773 - acc: 0.7907 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4997 - acc: 0.7704 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4882 - acc: 0.7759 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.5047 - acc: 0.7667 - val_loss: 0.5123 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4667 - acc: 0.7907 - val_loss: 0.5172 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4743 - acc: 0.8037 - val_loss: 0.5158 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4644 - acc: 0.7796 - val_loss: 0.5139 - val_acc: 0.7667\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4605 - acc: 0.8037 - val_loss: 0.5118 - val_acc: 0.7667\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.50814 to 0.50787, saving model to best.model\n",
      "0s - loss: 0.4992 - acc: 0.7815 - val_loss: 0.5079 - val_acc: 0.7667\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.50787 to 0.50541, saving model to best.model\n",
      "0s - loss: 0.4796 - acc: 0.7926 - val_loss: 0.5054 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4750 - acc: 0.7815 - val_loss: 0.5060 - val_acc: 0.7667\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4604 - acc: 0.7926 - val_loss: 0.5071 - val_acc: 0.7500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4473 - acc: 0.7963 - val_loss: 0.5068 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.50541 to 0.50421, saving model to best.model\n",
      "0s - loss: 0.4647 - acc: 0.7907 - val_loss: 0.5042 - val_acc: 0.7500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.50421 to 0.50011, saving model to best.model\n",
      "0s - loss: 0.4546 - acc: 0.7981 - val_loss: 0.5001 - val_acc: 0.7667\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.50011 to 0.49706, saving model to best.model\n",
      "0s - loss: 0.4563 - acc: 0.8056 - val_loss: 0.4971 - val_acc: 0.7667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4566 - acc: 0.8037 - val_loss: 0.4989 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4412 - acc: 0.8111 - val_loss: 0.5059 - val_acc: 0.7667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4428 - acc: 0.8074 - val_loss: 0.5085 - val_acc: 0.7667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4430 - acc: 0.8037 - val_loss: 0.5059 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4711 - acc: 0.7796 - val_loss: 0.5049 - val_acc: 0.7667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4422 - acc: 0.8074 - val_loss: 0.5052 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4499 - acc: 0.7889 - val_loss: 0.5052 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.7833 - val_loss: 0.5015 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4463 - acc: 0.7944 - val_loss: 0.4971 - val_acc: 0.7667\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.49706 to 0.49689, saving model to best.model\n",
      "0s - loss: 0.4639 - acc: 0.7926 - val_loss: 0.4969 - val_acc: 0.7667\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4297 - acc: 0.8000 - val_loss: 0.4995 - val_acc: 0.7667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4241 - acc: 0.8148 - val_loss: 0.4986 - val_acc: 0.7667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.49689 to 0.49630, saving model to best.model\n",
      "0s - loss: 0.4397 - acc: 0.8037 - val_loss: 0.4963 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4070 - acc: 0.8222 - val_loss: 0.4964 - val_acc: 0.7667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4227 - acc: 0.7907 - val_loss: 0.5011 - val_acc: 0.7667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4475 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4356 - acc: 0.8056 - val_loss: 0.4994 - val_acc: 0.7500\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4245 - acc: 0.8111 - val_loss: 0.5004 - val_acc: 0.7667\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4284 - acc: 0.8222 - val_loss: 0.5049 - val_acc: 0.7500\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4256 - acc: 0.8074 - val_loss: 0.5078 - val_acc: 0.7500\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4205 - acc: 0.8093 - val_loss: 0.5082 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4225 - acc: 0.8185 - val_loss: 0.5095 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4388 - acc: 0.8074 - val_loss: 0.5124 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4135 - acc: 0.8130 - val_loss: 0.5090 - val_acc: 0.7667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4143 - acc: 0.8296 - val_loss: 0.4993 - val_acc: 0.7833\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.49630 to 0.49330, saving model to best.model\n",
      "0s - loss: 0.4206 - acc: 0.8074 - val_loss: 0.4933 - val_acc: 0.7833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4127 - acc: 0.8259 - val_loss: 0.4943 - val_acc: 0.7833\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3998 - acc: 0.8204 - val_loss: 0.4977 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4035 - acc: 0.8296 - val_loss: 0.5017 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4027 - acc: 0.8185 - val_loss: 0.5031 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4189 - acc: 0.8130 - val_loss: 0.5018 - val_acc: 0.7667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4048 - acc: 0.8278 - val_loss: 0.5011 - val_acc: 0.7667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3964 - acc: 0.8333 - val_loss: 0.5034 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3948 - acc: 0.8130 - val_loss: 0.5079 - val_acc: 0.7667\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3908 - acc: 0.8352 - val_loss: 0.5109 - val_acc: 0.7667\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3779 - acc: 0.8463 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3715 - acc: 0.8389 - val_loss: 0.5127 - val_acc: 0.7500\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3833 - acc: 0.8370 - val_loss: 0.5100 - val_acc: 0.7167\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3731 - acc: 0.8407 - val_loss: 0.5105 - val_acc: 0.7333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3634 - acc: 0.8481 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3598 - acc: 0.8556 - val_loss: 0.5048 - val_acc: 0.7500\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3633 - acc: 0.8315 - val_loss: 0.5059 - val_acc: 0.7500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3790 - acc: 0.8333 - val_loss: 0.5007 - val_acc: 0.7667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3753 - acc: 0.8426 - val_loss: 0.4977 - val_acc: 0.7500\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.4001 - acc: 0.8444 - val_loss: 0.4989 - val_acc: 0.7500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3732 - acc: 0.8444 - val_loss: 0.5066 - val_acc: 0.7500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3785 - acc: 0.8259 - val_loss: 0.5170 - val_acc: 0.7333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3895 - acc: 0.8333 - val_loss: 0.5266 - val_acc: 0.7000\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3781 - acc: 0.8463 - val_loss: 0.5278 - val_acc: 0.7333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3574 - acc: 0.8556 - val_loss: 0.5255 - val_acc: 0.7333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3635 - acc: 0.8444 - val_loss: 0.5200 - val_acc: 0.7333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3550 - acc: 0.8481 - val_loss: 0.5179 - val_acc: 0.7333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58031, saving model to best.model\n",
      "0s - loss: 0.7916 - acc: 0.6204 - val_loss: 0.5803 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.58031 to 0.57178, saving model to best.model\n",
      "0s - loss: 0.7543 - acc: 0.6778 - val_loss: 0.5718 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.57178 to 0.53077, saving model to best.model\n",
      "0s - loss: 0.7646 - acc: 0.6704 - val_loss: 0.5308 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.53077 to 0.51202, saving model to best.model\n",
      "0s - loss: 0.6810 - acc: 0.6722 - val_loss: 0.5120 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6704 - acc: 0.6593 - val_loss: 0.5139 - val_acc: 0.7500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6358 - acc: 0.6630 - val_loss: 0.5183 - val_acc: 0.7667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6247 - acc: 0.6444 - val_loss: 0.5151 - val_acc: 0.7667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.51202 to 0.50947, saving model to best.model\n",
      "0s - loss: 0.6282 - acc: 0.6574 - val_loss: 0.5095 - val_acc: 0.7667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.50947 to 0.50701, saving model to best.model\n",
      "0s - loss: 0.6412 - acc: 0.6759 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.50701 to 0.50622, saving model to best.model\n",
      "0s - loss: 0.6046 - acc: 0.7019 - val_loss: 0.5062 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6137 - acc: 0.7093 - val_loss: 0.5064 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6214 - acc: 0.6889 - val_loss: 0.5077 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6168 - acc: 0.7111 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5559 - acc: 0.7222 - val_loss: 0.5073 - val_acc: 0.7667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.50622 to 0.50498, saving model to best.model\n",
      "0s - loss: 0.5829 - acc: 0.7056 - val_loss: 0.5050 - val_acc: 0.7667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.50498 to 0.50250, saving model to best.model\n",
      "0s - loss: 0.5946 - acc: 0.7037 - val_loss: 0.5025 - val_acc: 0.7667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.50250 to 0.50105, saving model to best.model\n",
      "0s - loss: 0.5468 - acc: 0.7185 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.50105 to 0.49850, saving model to best.model\n",
      "0s - loss: 0.5687 - acc: 0.7241 - val_loss: 0.4985 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.49850 to 0.49795, saving model to best.model\n",
      "0s - loss: 0.6007 - acc: 0.7185 - val_loss: 0.4980 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5936 - acc: 0.7019 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5829 - acc: 0.7185 - val_loss: 0.5018 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5868 - acc: 0.7074 - val_loss: 0.5022 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5802 - acc: 0.7185 - val_loss: 0.4987 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.49795 to 0.49466, saving model to best.model\n",
      "0s - loss: 0.5566 - acc: 0.7259 - val_loss: 0.4947 - val_acc: 0.7833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.49466 to 0.49216, saving model to best.model\n",
      "0s - loss: 0.5576 - acc: 0.7278 - val_loss: 0.4922 - val_acc: 0.7833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.49216 to 0.49082, saving model to best.model\n",
      "0s - loss: 0.5752 - acc: 0.7185 - val_loss: 0.4908 - val_acc: 0.7667\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.49082 to 0.49028, saving model to best.model\n",
      "0s - loss: 0.5677 - acc: 0.7167 - val_loss: 0.4903 - val_acc: 0.7833\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.49028 to 0.48924, saving model to best.model\n",
      "0s - loss: 0.5799 - acc: 0.7037 - val_loss: 0.4892 - val_acc: 0.7833\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.48924 to 0.48731, saving model to best.model\n",
      "0s - loss: 0.5623 - acc: 0.7259 - val_loss: 0.4873 - val_acc: 0.7833\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.48731 to 0.48680, saving model to best.model\n",
      "0s - loss: 0.5752 - acc: 0.7093 - val_loss: 0.4868 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.48680 to 0.48483, saving model to best.model\n",
      "0s - loss: 0.5457 - acc: 0.7130 - val_loss: 0.4848 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.48483 to 0.48290, saving model to best.model\n",
      "0s - loss: 0.5661 - acc: 0.7185 - val_loss: 0.4829 - val_acc: 0.8000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.48290 to 0.48104, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7389 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.48104 to 0.47945, saving model to best.model\n",
      "0s - loss: 0.5673 - acc: 0.7315 - val_loss: 0.4795 - val_acc: 0.8000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.47945 to 0.47846, saving model to best.model\n",
      "0s - loss: 0.5158 - acc: 0.7444 - val_loss: 0.4785 - val_acc: 0.8000\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.47846 to 0.47773, saving model to best.model\n",
      "0s - loss: 0.5323 - acc: 0.7370 - val_loss: 0.4777 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.47773 to 0.47300, saving model to best.model\n",
      "0s - loss: 0.5186 - acc: 0.7519 - val_loss: 0.4730 - val_acc: 0.7833\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.47300 to 0.46670, saving model to best.model\n",
      "0s - loss: 0.5178 - acc: 0.7259 - val_loss: 0.4667 - val_acc: 0.8000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.46670 to 0.46279, saving model to best.model\n",
      "0s - loss: 0.5443 - acc: 0.7426 - val_loss: 0.4628 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.46279 to 0.46033, saving model to best.model\n",
      "0s - loss: 0.5127 - acc: 0.7444 - val_loss: 0.4603 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.46033 to 0.45985, saving model to best.model\n",
      "0s - loss: 0.5417 - acc: 0.7352 - val_loss: 0.4599 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5461 - acc: 0.7315 - val_loss: 0.4610 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.45985 to 0.45925, saving model to best.model\n",
      "0s - loss: 0.5445 - acc: 0.7185 - val_loss: 0.4592 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.45925 to 0.45553, saving model to best.model\n",
      "0s - loss: 0.5416 - acc: 0.7481 - val_loss: 0.4555 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.45553 to 0.45196, saving model to best.model\n",
      "0s - loss: 0.5413 - acc: 0.7407 - val_loss: 0.4520 - val_acc: 0.8000\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.45196 to 0.44899, saving model to best.model\n",
      "0s - loss: 0.5359 - acc: 0.7407 - val_loss: 0.4490 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.44899 to 0.44630, saving model to best.model\n",
      "0s - loss: 0.5356 - acc: 0.7574 - val_loss: 0.4463 - val_acc: 0.8167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.44630 to 0.44418, saving model to best.model\n",
      "0s - loss: 0.5258 - acc: 0.7444 - val_loss: 0.4442 - val_acc: 0.8167\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.44418 to 0.44335, saving model to best.model\n",
      "0s - loss: 0.5212 - acc: 0.7389 - val_loss: 0.4433 - val_acc: 0.8000\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.44335 to 0.44250, saving model to best.model\n",
      "0s - loss: 0.5370 - acc: 0.7500 - val_loss: 0.4425 - val_acc: 0.8000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.44250 to 0.44228, saving model to best.model\n",
      "0s - loss: 0.5062 - acc: 0.7519 - val_loss: 0.4423 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.44228 to 0.44209, saving model to best.model\n",
      "0s - loss: 0.5136 - acc: 0.7537 - val_loss: 0.4421 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.44209 to 0.44036, saving model to best.model\n",
      "0s - loss: 0.5139 - acc: 0.7778 - val_loss: 0.4404 - val_acc: 0.8167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.44036 to 0.43864, saving model to best.model\n",
      "0s - loss: 0.5104 - acc: 0.7648 - val_loss: 0.4386 - val_acc: 0.8000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5079 - acc: 0.7722 - val_loss: 0.4387 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4951 - acc: 0.7630 - val_loss: 0.4404 - val_acc: 0.8167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4989 - acc: 0.7667 - val_loss: 0.4406 - val_acc: 0.8167\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4971 - acc: 0.7833 - val_loss: 0.4398 - val_acc: 0.8167\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5061 - acc: 0.7667 - val_loss: 0.4388 - val_acc: 0.8167\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.43864 to 0.43592, saving model to best.model\n",
      "0s - loss: 0.5145 - acc: 0.7611 - val_loss: 0.4359 - val_acc: 0.8167\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.43592 to 0.43240, saving model to best.model\n",
      "0s - loss: 0.4972 - acc: 0.7759 - val_loss: 0.4324 - val_acc: 0.8167\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4988 - acc: 0.7704 - val_loss: 0.4327 - val_acc: 0.8167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.43240 to 0.43167, saving model to best.model\n",
      "0s - loss: 0.5010 - acc: 0.7685 - val_loss: 0.4317 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.43167 to 0.42774, saving model to best.model\n",
      "0s - loss: 0.4969 - acc: 0.7593 - val_loss: 0.4277 - val_acc: 0.8000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.42774 to 0.42414, saving model to best.model\n",
      "0s - loss: 0.4787 - acc: 0.7741 - val_loss: 0.4241 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.42414 to 0.42088, saving model to best.model\n",
      "0s - loss: 0.4943 - acc: 0.7630 - val_loss: 0.4209 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.42088 to 0.41838, saving model to best.model\n",
      "0s - loss: 0.5019 - acc: 0.7537 - val_loss: 0.4184 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.41838 to 0.41772, saving model to best.model\n",
      "0s - loss: 0.5170 - acc: 0.7667 - val_loss: 0.4177 - val_acc: 0.8333\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4829 - acc: 0.7722 - val_loss: 0.4183 - val_acc: 0.8333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.41772 to 0.41700, saving model to best.model\n",
      "0s - loss: 0.5109 - acc: 0.7667 - val_loss: 0.4170 - val_acc: 0.8333\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.41700 to 0.41697, saving model to best.model\n",
      "0s - loss: 0.5112 - acc: 0.7870 - val_loss: 0.4170 - val_acc: 0.8333\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.5074 - acc: 0.7685 - val_loss: 0.4215 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4899 - acc: 0.7778 - val_loss: 0.4299 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4755 - acc: 0.7741 - val_loss: 0.4368 - val_acc: 0.8333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.5026 - acc: 0.7519 - val_loss: 0.4390 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4810 - acc: 0.7778 - val_loss: 0.4383 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.5053 - acc: 0.7796 - val_loss: 0.4329 - val_acc: 0.8333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.5083 - acc: 0.7648 - val_loss: 0.4260 - val_acc: 0.8333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.5073 - acc: 0.7630 - val_loss: 0.4216 - val_acc: 0.8333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.41697 to 0.41692, saving model to best.model\n",
      "0s - loss: 0.4573 - acc: 0.7870 - val_loss: 0.4169 - val_acc: 0.8333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.41692 to 0.41419, saving model to best.model\n",
      "0s - loss: 0.4775 - acc: 0.8000 - val_loss: 0.4142 - val_acc: 0.8167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.41419 to 0.41348, saving model to best.model\n",
      "0s - loss: 0.4756 - acc: 0.7852 - val_loss: 0.4135 - val_acc: 0.8167\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4694 - acc: 0.7704 - val_loss: 0.4147 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4772 - acc: 0.7741 - val_loss: 0.4169 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4760 - acc: 0.7944 - val_loss: 0.4195 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4695 - acc: 0.7778 - val_loss: 0.4199 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4560 - acc: 0.7870 - val_loss: 0.4172 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4691 - acc: 0.7870 - val_loss: 0.4160 - val_acc: 0.8167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4867 - acc: 0.7852 - val_loss: 0.4153 - val_acc: 0.8167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.41348 to 0.41151, saving model to best.model\n",
      "0s - loss: 0.4720 - acc: 0.7870 - val_loss: 0.4115 - val_acc: 0.8167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.41151 to 0.40757, saving model to best.model\n",
      "0s - loss: 0.4563 - acc: 0.7796 - val_loss: 0.4076 - val_acc: 0.8333\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.40757 to 0.40534, saving model to best.model\n",
      "0s - loss: 0.4534 - acc: 0.7907 - val_loss: 0.4053 - val_acc: 0.8333\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.40534 to 0.40482, saving model to best.model\n",
      "0s - loss: 0.4290 - acc: 0.8056 - val_loss: 0.4048 - val_acc: 0.8333\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.40482 to 0.40411, saving model to best.model\n",
      "0s - loss: 0.4460 - acc: 0.7889 - val_loss: 0.4041 - val_acc: 0.8333\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4666 - acc: 0.7963 - val_loss: 0.4051 - val_acc: 0.8333\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4684 - acc: 0.8000 - val_loss: 0.4081 - val_acc: 0.8333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4538 - acc: 0.7907 - val_loss: 0.4107 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4512 - acc: 0.7907 - val_loss: 0.4081 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4583 - acc: 0.7815 - val_loss: 0.4047 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.40411 to 0.40328, saving model to best.model\n",
      "0s - loss: 0.4569 - acc: 0.8019 - val_loss: 0.4033 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.40328 to 0.40256, saving model to best.model\n",
      "0s - loss: 0.4638 - acc: 0.7889 - val_loss: 0.4026 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.40256 to 0.40197, saving model to best.model\n",
      "0s - loss: 0.4408 - acc: 0.8037 - val_loss: 0.4020 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4507 - acc: 0.8000 - val_loss: 0.4021 - val_acc: 0.8333\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.40197 to 0.40134, saving model to best.model\n",
      "0s - loss: 0.4577 - acc: 0.8000 - val_loss: 0.4013 - val_acc: 0.8333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.40134 to 0.40043, saving model to best.model\n",
      "0s - loss: 0.4536 - acc: 0.8000 - val_loss: 0.4004 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.40043 to 0.40039, saving model to best.model\n",
      "0s - loss: 0.4513 - acc: 0.8074 - val_loss: 0.4004 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.40039 to 0.39948, saving model to best.model\n",
      "0s - loss: 0.4474 - acc: 0.7981 - val_loss: 0.3995 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.39948 to 0.39749, saving model to best.model\n",
      "0s - loss: 0.4176 - acc: 0.8019 - val_loss: 0.3975 - val_acc: 0.8333\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.39749 to 0.39710, saving model to best.model\n",
      "0s - loss: 0.4520 - acc: 0.7815 - val_loss: 0.3971 - val_acc: 0.8333\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4286 - acc: 0.8037 - val_loss: 0.3976 - val_acc: 0.8333\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4458 - acc: 0.8167 - val_loss: 0.3979 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4264 - acc: 0.8130 - val_loss: 0.3978 - val_acc: 0.8333\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.39710 to 0.39674, saving model to best.model\n",
      "0s - loss: 0.4437 - acc: 0.7944 - val_loss: 0.3967 - val_acc: 0.8333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.39674 to 0.39454, saving model to best.model\n",
      "0s - loss: 0.4337 - acc: 0.8000 - val_loss: 0.3945 - val_acc: 0.8333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.39454 to 0.39256, saving model to best.model\n",
      "0s - loss: 0.4246 - acc: 0.8111 - val_loss: 0.3926 - val_acc: 0.8333\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.39256 to 0.39084, saving model to best.model\n",
      "0s - loss: 0.4037 - acc: 0.8352 - val_loss: 0.3908 - val_acc: 0.8333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.39084 to 0.38975, saving model to best.model\n",
      "0s - loss: 0.4168 - acc: 0.8130 - val_loss: 0.3897 - val_acc: 0.8333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.38975 to 0.38816, saving model to best.model\n",
      "0s - loss: 0.4142 - acc: 0.8185 - val_loss: 0.3882 - val_acc: 0.8333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.38816 to 0.38704, saving model to best.model\n",
      "0s - loss: 0.4406 - acc: 0.8019 - val_loss: 0.3870 - val_acc: 0.8333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.4126 - acc: 0.8444 - val_loss: 0.3876 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.4377 - acc: 0.8130 - val_loss: 0.3894 - val_acc: 0.8333\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.4300 - acc: 0.8315 - val_loss: 0.3910 - val_acc: 0.8333\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.4196 - acc: 0.8148 - val_loss: 0.3902 - val_acc: 0.8333\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.4265 - acc: 0.8278 - val_loss: 0.3871 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.38704 to 0.38395, saving model to best.model\n",
      "0s - loss: 0.4105 - acc: 0.8222 - val_loss: 0.3840 - val_acc: 0.8333\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.38395 to 0.38103, saving model to best.model\n",
      "0s - loss: 0.3999 - acc: 0.8352 - val_loss: 0.3810 - val_acc: 0.8333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.38103 to 0.37824, saving model to best.model\n",
      "0s - loss: 0.3994 - acc: 0.8352 - val_loss: 0.3782 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.37824 to 0.37546, saving model to best.model\n",
      "0s - loss: 0.4090 - acc: 0.8148 - val_loss: 0.3755 - val_acc: 0.8333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.37546 to 0.37344, saving model to best.model\n",
      "0s - loss: 0.4099 - acc: 0.8315 - val_loss: 0.3734 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.37344 to 0.37154, saving model to best.model\n",
      "0s - loss: 0.4161 - acc: 0.8259 - val_loss: 0.3715 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.37154 to 0.37110, saving model to best.model\n",
      "0s - loss: 0.4000 - acc: 0.8352 - val_loss: 0.3711 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.37110 to 0.37076, saving model to best.model\n",
      "0s - loss: 0.4028 - acc: 0.8370 - val_loss: 0.3708 - val_acc: 0.8333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.37076 to 0.37052, saving model to best.model\n",
      "0s - loss: 0.4356 - acc: 0.8241 - val_loss: 0.3705 - val_acc: 0.8333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3988 - acc: 0.8241 - val_loss: 0.3732 - val_acc: 0.8333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3862 - acc: 0.8519 - val_loss: 0.3745 - val_acc: 0.8333\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3997 - acc: 0.8352 - val_loss: 0.3731 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.4085 - acc: 0.8315 - val_loss: 0.3721 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.4075 - acc: 0.8259 - val_loss: 0.3723 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3990 - acc: 0.8389 - val_loss: 0.3730 - val_acc: 0.8333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3913 - acc: 0.8296 - val_loss: 0.3718 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.37052 to 0.36828, saving model to best.model\n",
      "0s - loss: 0.4001 - acc: 0.8167 - val_loss: 0.3683 - val_acc: 0.8333\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.36828 to 0.36553, saving model to best.model\n",
      "0s - loss: 0.4165 - acc: 0.8185 - val_loss: 0.3655 - val_acc: 0.8333\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.36553 to 0.36330, saving model to best.model\n",
      "0s - loss: 0.3984 - acc: 0.8315 - val_loss: 0.3633 - val_acc: 0.8333\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.36330 to 0.36081, saving model to best.model\n",
      "0s - loss: 0.4040 - acc: 0.8259 - val_loss: 0.3608 - val_acc: 0.8333\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.36081 to 0.35842, saving model to best.model\n",
      "0s - loss: 0.3965 - acc: 0.8444 - val_loss: 0.3584 - val_acc: 0.8333\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.35842 to 0.35596, saving model to best.model\n",
      "0s - loss: 0.3968 - acc: 0.8296 - val_loss: 0.3560 - val_acc: 0.8333\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.35596 to 0.35268, saving model to best.model\n",
      "0s - loss: 0.4035 - acc: 0.8296 - val_loss: 0.3527 - val_acc: 0.8333\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.35268 to 0.35006, saving model to best.model\n",
      "0s - loss: 0.3865 - acc: 0.8352 - val_loss: 0.3501 - val_acc: 0.8333\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.35006 to 0.34684, saving model to best.model\n",
      "0s - loss: 0.3903 - acc: 0.8241 - val_loss: 0.3468 - val_acc: 0.8333\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.34684 to 0.34345, saving model to best.model\n",
      "0s - loss: 0.3705 - acc: 0.8315 - val_loss: 0.3435 - val_acc: 0.8333\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.34345 to 0.34195, saving model to best.model\n",
      "0s - loss: 0.3903 - acc: 0.8333 - val_loss: 0.3419 - val_acc: 0.8333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.34195 to 0.34086, saving model to best.model\n",
      "0s - loss: 0.3897 - acc: 0.8593 - val_loss: 0.3409 - val_acc: 0.8333\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.34086 to 0.34043, saving model to best.model\n",
      "0s - loss: 0.3814 - acc: 0.8333 - val_loss: 0.3404 - val_acc: 0.8333\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.34043 to 0.34007, saving model to best.model\n",
      "0s - loss: 0.3686 - acc: 0.8407 - val_loss: 0.3401 - val_acc: 0.8333\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.34007 to 0.34005, saving model to best.model\n",
      "0s - loss: 0.4002 - acc: 0.8296 - val_loss: 0.3401 - val_acc: 0.8333\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3668 - acc: 0.8481 - val_loss: 0.3412 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3845 - acc: 0.8333 - val_loss: 0.3426 - val_acc: 0.8333\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3810 - acc: 0.8481 - val_loss: 0.3422 - val_acc: 0.8333\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3902 - acc: 0.8352 - val_loss: 0.3431 - val_acc: 0.8333\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.4147 - acc: 0.8333 - val_loss: 0.3456 - val_acc: 0.8167\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3679 - acc: 0.8556 - val_loss: 0.3468 - val_acc: 0.8167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3458 - acc: 0.8556 - val_loss: 0.3460 - val_acc: 0.8167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3807 - acc: 0.8352 - val_loss: 0.3436 - val_acc: 0.8333\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3487 - acc: 0.8481 - val_loss: 0.3416 - val_acc: 0.8333\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3305 - acc: 0.8648 - val_loss: 0.3404 - val_acc: 0.8333\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.34005 to 0.33923, saving model to best.model\n",
      "0s - loss: 0.3404 - acc: 0.8407 - val_loss: 0.3392 - val_acc: 0.8333\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss improved from 0.33923 to 0.33854, saving model to best.model\n",
      "0s - loss: 0.3535 - acc: 0.8389 - val_loss: 0.3385 - val_acc: 0.8333\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3339 - acc: 0.8500 - val_loss: 0.3405 - val_acc: 0.8333\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3415 - acc: 0.8704 - val_loss: 0.3424 - val_acc: 0.8333\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3527 - acc: 0.8389 - val_loss: 0.3426 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.3442 - acc: 0.8667 - val_loss: 0.3425 - val_acc: 0.8500\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3482 - acc: 0.8593 - val_loss: 0.3438 - val_acc: 0.8500\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3467 - acc: 0.8574 - val_loss: 0.3448 - val_acc: 0.8500\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.3517 - acc: 0.8407 - val_loss: 0.3437 - val_acc: 0.8500\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.3363 - acc: 0.8537 - val_loss: 0.3431 - val_acc: 0.8500\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.3206 - acc: 0.8741 - val_loss: 0.3446 - val_acc: 0.8333\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.3406 - acc: 0.8722 - val_loss: 0.3463 - val_acc: 0.8333\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.3419 - acc: 0.8630 - val_loss: 0.3459 - val_acc: 0.8333\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.3320 - acc: 0.8667 - val_loss: 0.3448 - val_acc: 0.8333\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.3479 - acc: 0.8574 - val_loss: 0.3440 - val_acc: 0.8333\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.3321 - acc: 0.8667 - val_loss: 0.3425 - val_acc: 0.8333\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.3120 - acc: 0.8815 - val_loss: 0.3409 - val_acc: 0.8333\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.3144 - acc: 0.8685 - val_loss: 0.3414 - val_acc: 0.8333\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.3368 - acc: 0.8574 - val_loss: 0.3418 - val_acc: 0.8500\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.3239 - acc: 0.8685 - val_loss: 0.3433 - val_acc: 0.8500\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.3280 - acc: 0.8556 - val_loss: 0.3429 - val_acc: 0.8500\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.33854 to 0.33620, saving model to best.model\n",
      "0s - loss: 0.3176 - acc: 0.8704 - val_loss: 0.3362 - val_acc: 0.8667\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.33620 to 0.33246, saving model to best.model\n",
      "0s - loss: 0.3360 - acc: 0.8593 - val_loss: 0.3325 - val_acc: 0.8500\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.33246 to 0.32917, saving model to best.model\n",
      "0s - loss: 0.3548 - acc: 0.8500 - val_loss: 0.3292 - val_acc: 0.8500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.32917 to 0.32576, saving model to best.model\n",
      "0s - loss: 0.3435 - acc: 0.8463 - val_loss: 0.3258 - val_acc: 0.8500\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.3131 - acc: 0.8759 - val_loss: 0.3258 - val_acc: 0.8500\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.32576 to 0.32428, saving model to best.model\n",
      "0s - loss: 0.3193 - acc: 0.8852 - val_loss: 0.3243 - val_acc: 0.8500\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.32428 to 0.32109, saving model to best.model\n",
      "0s - loss: 0.3207 - acc: 0.8759 - val_loss: 0.3211 - val_acc: 0.8500\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.32109 to 0.31928, saving model to best.model\n",
      "0s - loss: 0.3236 - acc: 0.8704 - val_loss: 0.3193 - val_acc: 0.8500\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.3034 - acc: 0.8611 - val_loss: 0.3210 - val_acc: 0.8500\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.3132 - acc: 0.8741 - val_loss: 0.3215 - val_acc: 0.8500\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.31928 to 0.31845, saving model to best.model\n",
      "0s - loss: 0.3022 - acc: 0.8667 - val_loss: 0.3185 - val_acc: 0.8500\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.31845 to 0.31460, saving model to best.model\n",
      "0s - loss: 0.3093 - acc: 0.8741 - val_loss: 0.3146 - val_acc: 0.8667\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.31460 to 0.30771, saving model to best.model\n",
      "0s - loss: 0.3204 - acc: 0.8611 - val_loss: 0.3077 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.30771 to 0.29948, saving model to best.model\n",
      "0s - loss: 0.2909 - acc: 0.8778 - val_loss: 0.2995 - val_acc: 0.8500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.59055, saving model to best.model\n",
      "0s - loss: 0.7491 - acc: 0.6481 - val_loss: 0.5906 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.59055 to 0.57806, saving model to best.model\n",
      "0s - loss: 0.7040 - acc: 0.6315 - val_loss: 0.5781 - val_acc: 0.6833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.57806 to 0.56063, saving model to best.model\n",
      "0s - loss: 0.6518 - acc: 0.6685 - val_loss: 0.5606 - val_acc: 0.7000\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.56063 to 0.55367, saving model to best.model\n",
      "0s - loss: 0.7000 - acc: 0.6611 - val_loss: 0.5537 - val_acc: 0.7000\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.55367 to 0.55209, saving model to best.model\n",
      "0s - loss: 0.6438 - acc: 0.6926 - val_loss: 0.5521 - val_acc: 0.7000\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.55209 to 0.55111, saving model to best.model\n",
      "0s - loss: 0.6345 - acc: 0.6815 - val_loss: 0.5511 - val_acc: 0.7000\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6316 - acc: 0.6741 - val_loss: 0.5518 - val_acc: 0.7000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6232 - acc: 0.6889 - val_loss: 0.5533 - val_acc: 0.7167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6306 - acc: 0.6759 - val_loss: 0.5554 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6160 - acc: 0.6648 - val_loss: 0.5561 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6055 - acc: 0.7019 - val_loss: 0.5548 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5983 - acc: 0.6926 - val_loss: 0.5524 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6011 - acc: 0.6889 - val_loss: 0.5526 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5962 - acc: 0.6907 - val_loss: 0.5531 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5777 - acc: 0.7056 - val_loss: 0.5531 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5825 - acc: 0.7185 - val_loss: 0.5519 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5642 - acc: 0.7130 - val_loss: 0.5513 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5788 - acc: 0.7111 - val_loss: 0.5521 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5699 - acc: 0.6963 - val_loss: 0.5514 - val_acc: 0.8333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.55111 to 0.54819, saving model to best.model\n",
      "0s - loss: 0.5605 - acc: 0.7111 - val_loss: 0.5482 - val_acc: 0.8167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.54819 to 0.54231, saving model to best.model\n",
      "0s - loss: 0.5339 - acc: 0.7278 - val_loss: 0.5423 - val_acc: 0.8167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.54231 to 0.53586, saving model to best.model\n",
      "0s - loss: 0.5819 - acc: 0.6981 - val_loss: 0.5359 - val_acc: 0.8167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.53586 to 0.52975, saving model to best.model\n",
      "0s - loss: 0.5466 - acc: 0.7333 - val_loss: 0.5298 - val_acc: 0.8167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52975 to 0.52523, saving model to best.model\n",
      "0s - loss: 0.5729 - acc: 0.7222 - val_loss: 0.5252 - val_acc: 0.8167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.52523 to 0.52478, saving model to best.model\n",
      "0s - loss: 0.5348 - acc: 0.7296 - val_loss: 0.5248 - val_acc: 0.8167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52478 to 0.52454, saving model to best.model\n",
      "0s - loss: 0.5473 - acc: 0.7241 - val_loss: 0.5245 - val_acc: 0.8167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.52454 to 0.52091, saving model to best.model\n",
      "0s - loss: 0.5400 - acc: 0.7259 - val_loss: 0.5209 - val_acc: 0.8167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.52091 to 0.51738, saving model to best.model\n",
      "0s - loss: 0.5466 - acc: 0.7093 - val_loss: 0.5174 - val_acc: 0.8167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.51738 to 0.51717, saving model to best.model\n",
      "0s - loss: 0.5557 - acc: 0.7296 - val_loss: 0.5172 - val_acc: 0.8167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5386 - acc: 0.7333 - val_loss: 0.5190 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5369 - acc: 0.7315 - val_loss: 0.5212 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5527 - acc: 0.7222 - val_loss: 0.5213 - val_acc: 0.8000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5430 - acc: 0.7185 - val_loss: 0.5200 - val_acc: 0.8167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.51717 to 0.51686, saving model to best.model\n",
      "0s - loss: 0.5343 - acc: 0.7259 - val_loss: 0.5169 - val_acc: 0.8167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.51686 to 0.51182, saving model to best.model\n",
      "0s - loss: 0.5107 - acc: 0.7463 - val_loss: 0.5118 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.51182 to 0.50881, saving model to best.model\n",
      "0s - loss: 0.5191 - acc: 0.7315 - val_loss: 0.5088 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.50881 to 0.50562, saving model to best.model\n",
      "0s - loss: 0.5123 - acc: 0.7574 - val_loss: 0.5056 - val_acc: 0.8333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.50562 to 0.50139, saving model to best.model\n",
      "0s - loss: 0.5317 - acc: 0.7370 - val_loss: 0.5014 - val_acc: 0.8167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.50139 to 0.49902, saving model to best.model\n",
      "0s - loss: 0.5499 - acc: 0.7444 - val_loss: 0.4990 - val_acc: 0.8333\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.49902 to 0.49728, saving model to best.model\n",
      "0s - loss: 0.5165 - acc: 0.7407 - val_loss: 0.4973 - val_acc: 0.8333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.49728 to 0.49442, saving model to best.model\n",
      "0s - loss: 0.5156 - acc: 0.7481 - val_loss: 0.4944 - val_acc: 0.8333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.49442 to 0.49205, saving model to best.model\n",
      "0s - loss: 0.5226 - acc: 0.7444 - val_loss: 0.4921 - val_acc: 0.8333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.49205 to 0.48994, saving model to best.model\n",
      "0s - loss: 0.5336 - acc: 0.7370 - val_loss: 0.4899 - val_acc: 0.8167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.48994 to 0.48957, saving model to best.model\n",
      "0s - loss: 0.5407 - acc: 0.7352 - val_loss: 0.4896 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5233 - acc: 0.7593 - val_loss: 0.4898 - val_acc: 0.8000\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5259 - acc: 0.7315 - val_loss: 0.4896 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5085 - acc: 0.7426 - val_loss: 0.4906 - val_acc: 0.8000\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5126 - acc: 0.7389 - val_loss: 0.4930 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5151 - acc: 0.7537 - val_loss: 0.4930 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5067 - acc: 0.7500 - val_loss: 0.4928 - val_acc: 0.8167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5056 - acc: 0.7556 - val_loss: 0.4917 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.48957 to 0.48890, saving model to best.model\n",
      "0s - loss: 0.5045 - acc: 0.7481 - val_loss: 0.4889 - val_acc: 0.8167\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.48890 to 0.48698, saving model to best.model\n",
      "0s - loss: 0.4985 - acc: 0.7648 - val_loss: 0.4870 - val_acc: 0.8167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.48698 to 0.48602, saving model to best.model\n",
      "0s - loss: 0.5129 - acc: 0.7611 - val_loss: 0.4860 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.48602 to 0.48570, saving model to best.model\n",
      "0s - loss: 0.5090 - acc: 0.7574 - val_loss: 0.4857 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4965 - acc: 0.7630 - val_loss: 0.4858 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5045 - acc: 0.7574 - val_loss: 0.4869 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5075 - acc: 0.7630 - val_loss: 0.4871 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.48570 to 0.48560, saving model to best.model\n",
      "0s - loss: 0.5039 - acc: 0.7463 - val_loss: 0.4856 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.48560 to 0.48289, saving model to best.model\n",
      "0s - loss: 0.5051 - acc: 0.7630 - val_loss: 0.4829 - val_acc: 0.7833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.48289 to 0.47849, saving model to best.model\n",
      "0s - loss: 0.4867 - acc: 0.7685 - val_loss: 0.4785 - val_acc: 0.8000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.47849 to 0.47554, saving model to best.model\n",
      "0s - loss: 0.4860 - acc: 0.7667 - val_loss: 0.4755 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.47554 to 0.47358, saving model to best.model\n",
      "0s - loss: 0.4930 - acc: 0.7611 - val_loss: 0.4736 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.47358 to 0.47162, saving model to best.model\n",
      "0s - loss: 0.4980 - acc: 0.7648 - val_loss: 0.4716 - val_acc: 0.8167\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.47162 to 0.47039, saving model to best.model\n",
      "0s - loss: 0.4824 - acc: 0.7889 - val_loss: 0.4704 - val_acc: 0.8167\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4825 - acc: 0.7833 - val_loss: 0.4715 - val_acc: 0.8167\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4878 - acc: 0.7574 - val_loss: 0.4719 - val_acc: 0.8167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.5072 - acc: 0.7593 - val_loss: 0.4719 - val_acc: 0.8167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4578 - acc: 0.7759 - val_loss: 0.4707 - val_acc: 0.8167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4973 - acc: 0.7556 - val_loss: 0.4705 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.47039 to 0.47020, saving model to best.model\n",
      "0s - loss: 0.4835 - acc: 0.7778 - val_loss: 0.4702 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.47020 to 0.46879, saving model to best.model\n",
      "0s - loss: 0.4788 - acc: 0.7815 - val_loss: 0.4688 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.46879 to 0.46803, saving model to best.model\n",
      "0s - loss: 0.4590 - acc: 0.7981 - val_loss: 0.4680 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.46803 to 0.46581, saving model to best.model\n",
      "0s - loss: 0.4704 - acc: 0.7815 - val_loss: 0.4658 - val_acc: 0.8167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.46581 to 0.46471, saving model to best.model\n",
      "0s - loss: 0.4989 - acc: 0.7759 - val_loss: 0.4647 - val_acc: 0.8167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4978 - acc: 0.7741 - val_loss: 0.4656 - val_acc: 0.8167\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4926 - acc: 0.7704 - val_loss: 0.4679 - val_acc: 0.8167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4617 - acc: 0.7722 - val_loss: 0.4706 - val_acc: 0.8167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4650 - acc: 0.7667 - val_loss: 0.4718 - val_acc: 0.8167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4825 - acc: 0.7593 - val_loss: 0.4718 - val_acc: 0.8167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4752 - acc: 0.7889 - val_loss: 0.4714 - val_acc: 0.8167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4526 - acc: 0.7907 - val_loss: 0.4694 - val_acc: 0.8167\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4680 - acc: 0.7889 - val_loss: 0.4681 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4499 - acc: 0.7981 - val_loss: 0.4675 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4583 - acc: 0.7833 - val_loss: 0.4653 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.46471 to 0.46269, saving model to best.model\n",
      "0s - loss: 0.4623 - acc: 0.7815 - val_loss: 0.4627 - val_acc: 0.8000\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.46269 to 0.45856, saving model to best.model\n",
      "0s - loss: 0.4630 - acc: 0.7870 - val_loss: 0.4586 - val_acc: 0.8000\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.45856 to 0.45460, saving model to best.model\n",
      "0s - loss: 0.4367 - acc: 0.8000 - val_loss: 0.4546 - val_acc: 0.8000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.45460 to 0.45137, saving model to best.model\n",
      "0s - loss: 0.4545 - acc: 0.7815 - val_loss: 0.4514 - val_acc: 0.8000\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.45137 to 0.44849, saving model to best.model\n",
      "0s - loss: 0.4470 - acc: 0.7963 - val_loss: 0.4485 - val_acc: 0.8000\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.44849 to 0.44503, saving model to best.model\n",
      "0s - loss: 0.4391 - acc: 0.8019 - val_loss: 0.4450 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.44503 to 0.44359, saving model to best.model\n",
      "0s - loss: 0.4563 - acc: 0.7907 - val_loss: 0.4436 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4470 - acc: 0.8056 - val_loss: 0.4437 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.44359 to 0.44332, saving model to best.model\n",
      "0s - loss: 0.4516 - acc: 0.7889 - val_loss: 0.4433 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.44332 to 0.44121, saving model to best.model\n",
      "0s - loss: 0.4677 - acc: 0.7981 - val_loss: 0.4412 - val_acc: 0.8167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.44121 to 0.43852, saving model to best.model\n",
      "0s - loss: 0.4264 - acc: 0.8056 - val_loss: 0.4385 - val_acc: 0.8167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.43852 to 0.43699, saving model to best.model\n",
      "0s - loss: 0.4598 - acc: 0.7907 - val_loss: 0.4370 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.43699 to 0.43553, saving model to best.model\n",
      "0s - loss: 0.4569 - acc: 0.8037 - val_loss: 0.4355 - val_acc: 0.8500\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.43553 to 0.43440, saving model to best.model\n",
      "0s - loss: 0.4284 - acc: 0.8093 - val_loss: 0.4344 - val_acc: 0.8500\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.43440 to 0.43332, saving model to best.model\n",
      "0s - loss: 0.4532 - acc: 0.8074 - val_loss: 0.4333 - val_acc: 0.8500\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.43332 to 0.43174, saving model to best.model\n",
      "0s - loss: 0.4339 - acc: 0.8037 - val_loss: 0.4317 - val_acc: 0.8500\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4385 - acc: 0.8019 - val_loss: 0.4333 - val_acc: 0.8167\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4253 - acc: 0.8296 - val_loss: 0.4333 - val_acc: 0.8167\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.43174 to 0.43076, saving model to best.model\n",
      "0s - loss: 0.4528 - acc: 0.8074 - val_loss: 0.4308 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.43076 to 0.42662, saving model to best.model\n",
      "0s - loss: 0.4367 - acc: 0.8148 - val_loss: 0.4266 - val_acc: 0.8167\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.42662 to 0.42194, saving model to best.model\n",
      "0s - loss: 0.4129 - acc: 0.8204 - val_loss: 0.4219 - val_acc: 0.8167\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.42194 to 0.41749, saving model to best.model\n",
      "0s - loss: 0.4269 - acc: 0.8148 - val_loss: 0.4175 - val_acc: 0.8167\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.41749 to 0.41409, saving model to best.model\n",
      "0s - loss: 0.4529 - acc: 0.7944 - val_loss: 0.4141 - val_acc: 0.8333\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.41409 to 0.41094, saving model to best.model\n",
      "0s - loss: 0.4187 - acc: 0.8278 - val_loss: 0.4109 - val_acc: 0.8167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.41094 to 0.41003, saving model to best.model\n",
      "0s - loss: 0.4147 - acc: 0.8185 - val_loss: 0.4100 - val_acc: 0.8167\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4133 - acc: 0.8259 - val_loss: 0.4125 - val_acc: 0.8167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4265 - acc: 0.8204 - val_loss: 0.4120 - val_acc: 0.8167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.4308 - acc: 0.8185 - val_loss: 0.4120 - val_acc: 0.8000\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.41003 to 0.40750, saving model to best.model\n",
      "0s - loss: 0.4159 - acc: 0.8278 - val_loss: 0.4075 - val_acc: 0.8167\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.40750 to 0.40358, saving model to best.model\n",
      "0s - loss: 0.4207 - acc: 0.8222 - val_loss: 0.4036 - val_acc: 0.8167\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.40358 to 0.40262, saving model to best.model\n",
      "0s - loss: 0.4370 - acc: 0.8093 - val_loss: 0.4026 - val_acc: 0.8167\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.40262 to 0.40247, saving model to best.model\n",
      "0s - loss: 0.4060 - acc: 0.8185 - val_loss: 0.4025 - val_acc: 0.8333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.40247 to 0.40246, saving model to best.model\n",
      "0s - loss: 0.4067 - acc: 0.8333 - val_loss: 0.4025 - val_acc: 0.8333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.4138 - acc: 0.8222 - val_loss: 0.4036 - val_acc: 0.8167\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3962 - acc: 0.8426 - val_loss: 0.4061 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.4124 - acc: 0.8370 - val_loss: 0.4102 - val_acc: 0.8167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3935 - acc: 0.8315 - val_loss: 0.4092 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.4041 - acc: 0.8296 - val_loss: 0.4041 - val_acc: 0.8333\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.40246 to 0.40138, saving model to best.model\n",
      "0s - loss: 0.4061 - acc: 0.8241 - val_loss: 0.4014 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.40138 to 0.39779, saving model to best.model\n",
      "0s - loss: 0.3936 - acc: 0.8241 - val_loss: 0.3978 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.39779 to 0.39689, saving model to best.model\n",
      "0s - loss: 0.4174 - acc: 0.8259 - val_loss: 0.3969 - val_acc: 0.8500\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3749 - acc: 0.8444 - val_loss: 0.3982 - val_acc: 0.8500\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3828 - acc: 0.8241 - val_loss: 0.4002 - val_acc: 0.8500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3730 - acc: 0.8296 - val_loss: 0.3994 - val_acc: 0.8500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.39689 to 0.39458, saving model to best.model\n",
      "0s - loss: 0.3978 - acc: 0.8278 - val_loss: 0.3946 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3970 - acc: 0.8204 - val_loss: 0.3949 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3821 - acc: 0.8611 - val_loss: 0.3977 - val_acc: 0.8167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3884 - acc: 0.8537 - val_loss: 0.3964 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.39458 to 0.39346, saving model to best.model\n",
      "0s - loss: 0.4006 - acc: 0.8296 - val_loss: 0.3935 - val_acc: 0.8000\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.39346 to 0.39061, saving model to best.model\n",
      "0s - loss: 0.3897 - acc: 0.8407 - val_loss: 0.3906 - val_acc: 0.8167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.39061 to 0.38776, saving model to best.model\n",
      "0s - loss: 0.3869 - acc: 0.8389 - val_loss: 0.3878 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.38776 to 0.38462, saving model to best.model\n",
      "0s - loss: 0.3855 - acc: 0.8463 - val_loss: 0.3846 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.38462 to 0.38135, saving model to best.model\n",
      "0s - loss: 0.3880 - acc: 0.8444 - val_loss: 0.3813 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3831 - acc: 0.8481 - val_loss: 0.3815 - val_acc: 0.8167\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3933 - acc: 0.8481 - val_loss: 0.3865 - val_acc: 0.8167\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3549 - acc: 0.8704 - val_loss: 0.3865 - val_acc: 0.8167\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.38135 to 0.37933, saving model to best.model\n",
      "0s - loss: 0.3785 - acc: 0.8519 - val_loss: 0.3793 - val_acc: 0.8167\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.37933 to 0.36694, saving model to best.model\n",
      "0s - loss: 0.3747 - acc: 0.8426 - val_loss: 0.3669 - val_acc: 0.8333\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.36694 to 0.36076, saving model to best.model\n",
      "0s - loss: 0.3509 - acc: 0.8481 - val_loss: 0.3608 - val_acc: 0.8333\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.36076 to 0.35938, saving model to best.model\n",
      "0s - loss: 0.3498 - acc: 0.8519 - val_loss: 0.3594 - val_acc: 0.8333\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.35938 to 0.35876, saving model to best.model\n",
      "0s - loss: 0.3725 - acc: 0.8444 - val_loss: 0.3588 - val_acc: 0.8500\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3974 - acc: 0.8333 - val_loss: 0.3593 - val_acc: 0.8500\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3627 - acc: 0.8537 - val_loss: 0.3633 - val_acc: 0.8500\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3398 - acc: 0.8593 - val_loss: 0.3671 - val_acc: 0.8500\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3601 - acc: 0.8463 - val_loss: 0.3677 - val_acc: 0.8500\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3455 - acc: 0.8556 - val_loss: 0.3650 - val_acc: 0.8500\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3659 - acc: 0.8426 - val_loss: 0.3611 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3546 - acc: 0.8500 - val_loss: 0.3597 - val_acc: 0.8500\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3728 - acc: 0.8352 - val_loss: 0.3615 - val_acc: 0.8500\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3539 - acc: 0.8704 - val_loss: 0.3633 - val_acc: 0.8500\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3911 - acc: 0.8574 - val_loss: 0.3680 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3474 - acc: 0.8611 - val_loss: 0.3736 - val_acc: 0.8167\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3440 - acc: 0.8667 - val_loss: 0.3797 - val_acc: 0.8333\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3463 - acc: 0.8685 - val_loss: 0.3803 - val_acc: 0.8333\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3520 - acc: 0.8444 - val_loss: 0.3731 - val_acc: 0.8333\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3576 - acc: 0.8574 - val_loss: 0.3652 - val_acc: 0.8333\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3384 - acc: 0.8648 - val_loss: 0.3613 - val_acc: 0.8667\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3635 - acc: 0.8556 - val_loss: 0.3596 - val_acc: 0.8667\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss improved from 0.35876 to 0.35764, saving model to best.model\n",
      "0s - loss: 0.3386 - acc: 0.8722 - val_loss: 0.3576 - val_acc: 0.8667\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss improved from 0.35764 to 0.35682, saving model to best.model\n",
      "0s - loss: 0.3525 - acc: 0.8389 - val_loss: 0.3568 - val_acc: 0.8667\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3694 - acc: 0.8389 - val_loss: 0.3586 - val_acc: 0.8667\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3315 - acc: 0.8611 - val_loss: 0.3629 - val_acc: 0.8500\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3444 - acc: 0.8574 - val_loss: 0.3681 - val_acc: 0.8333\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3188 - acc: 0.8796 - val_loss: 0.3672 - val_acc: 0.8333\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3109 - acc: 0.8833 - val_loss: 0.3624 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.3338 - acc: 0.8667 - val_loss: 0.3586 - val_acc: 0.8667\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3246 - acc: 0.8685 - val_loss: 0.3570 - val_acc: 0.8667\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.35682 to 0.35595, saving model to best.model\n",
      "0s - loss: 0.3204 - acc: 0.8648 - val_loss: 0.3559 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.35595 to 0.35576, saving model to best.model\n",
      "0s - loss: 0.3205 - acc: 0.8796 - val_loss: 0.3558 - val_acc: 0.8667\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.3167 - acc: 0.8574 - val_loss: 0.3571 - val_acc: 0.8667\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.3351 - acc: 0.8630 - val_loss: 0.3583 - val_acc: 0.8500\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.3268 - acc: 0.8611 - val_loss: 0.3595 - val_acc: 0.8333\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.3335 - acc: 0.8648 - val_loss: 0.3594 - val_acc: 0.8333\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2712 - acc: 0.8926 - val_loss: 0.3596 - val_acc: 0.8500\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2888 - acc: 0.8852 - val_loss: 0.3600 - val_acc: 0.8500\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.3063 - acc: 0.8815 - val_loss: 0.3603 - val_acc: 0.8500\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2809 - acc: 0.8944 - val_loss: 0.3587 - val_acc: 0.8500\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.3472 - acc: 0.8648 - val_loss: 0.3584 - val_acc: 0.8667\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2908 - acc: 0.8796 - val_loss: 0.3582 - val_acc: 0.8667\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.3070 - acc: 0.8685 - val_loss: 0.3580 - val_acc: 0.8667\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2982 - acc: 0.8722 - val_loss: 0.3573 - val_acc: 0.8500\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2951 - acc: 0.8648 - val_loss: 0.3563 - val_acc: 0.8667\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2903 - acc: 0.8815 - val_loss: 0.3561 - val_acc: 0.8500\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.3306 - acc: 0.8630 - val_loss: 0.3558 - val_acc: 0.8500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.35576 to 0.35462, saving model to best.model\n",
      "0s - loss: 0.3070 - acc: 0.8722 - val_loss: 0.3546 - val_acc: 0.8500\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.35462 to 0.35291, saving model to best.model\n",
      "0s - loss: 0.2851 - acc: 0.8907 - val_loss: 0.3529 - val_acc: 0.8667\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.35291 to 0.35197, saving model to best.model\n",
      "0s - loss: 0.3250 - acc: 0.8574 - val_loss: 0.3520 - val_acc: 0.8667\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.3004 - acc: 0.8889 - val_loss: 0.3522 - val_acc: 0.8667\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2584 - acc: 0.9019 - val_loss: 0.3521 - val_acc: 0.8833\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss improved from 0.35197 to 0.35105, saving model to best.model\n",
      "0s - loss: 0.3012 - acc: 0.8778 - val_loss: 0.3511 - val_acc: 0.8833\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.35105 to 0.35041, saving model to best.model\n",
      "0s - loss: 0.2948 - acc: 0.8852 - val_loss: 0.3504 - val_acc: 0.8833\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss improved from 0.35041 to 0.34871, saving model to best.model\n",
      "0s - loss: 0.3137 - acc: 0.8815 - val_loss: 0.3487 - val_acc: 0.8833\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.34871 to 0.34716, saving model to best.model\n",
      "0s - loss: 0.3207 - acc: 0.8889 - val_loss: 0.3472 - val_acc: 0.8833\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.34716 to 0.34578, saving model to best.model\n",
      "0s - loss: 0.2652 - acc: 0.8963 - val_loss: 0.3458 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.34578 to 0.34452, saving model to best.model\n",
      "0s - loss: 0.3022 - acc: 0.8852 - val_loss: 0.3445 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.59637, saving model to best.model\n",
      "0s - loss: 0.7805 - acc: 0.5741 - val_loss: 0.5964 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.59637 to 0.58881, saving model to best.model\n",
      "0s - loss: 0.7632 - acc: 0.5870 - val_loss: 0.5888 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.58881 to 0.58328, saving model to best.model\n",
      "0s - loss: 0.7816 - acc: 0.5685 - val_loss: 0.5833 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58328 to 0.58254, saving model to best.model\n",
      "0s - loss: 0.7270 - acc: 0.6185 - val_loss: 0.5825 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.7522 - acc: 0.5889 - val_loss: 0.5910 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6716 - acc: 0.6407 - val_loss: 0.6039 - val_acc: 0.7500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6842 - acc: 0.6167 - val_loss: 0.6098 - val_acc: 0.7833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6723 - acc: 0.5981 - val_loss: 0.6091 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6339 - acc: 0.6167 - val_loss: 0.6038 - val_acc: 0.8000\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6557 - acc: 0.6130 - val_loss: 0.5971 - val_acc: 0.7167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6564 - acc: 0.6278 - val_loss: 0.5906 - val_acc: 0.7000\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6644 - acc: 0.6500 - val_loss: 0.5835 - val_acc: 0.7000\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.58254 to 0.57671, saving model to best.model\n",
      "0s - loss: 0.6403 - acc: 0.6352 - val_loss: 0.5767 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.57671 to 0.57262, saving model to best.model\n",
      "0s - loss: 0.6448 - acc: 0.6537 - val_loss: 0.5726 - val_acc: 0.7000\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.6171 - acc: 0.6648 - val_loss: 0.5734 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6174 - acc: 0.6500 - val_loss: 0.5755 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.6195 - acc: 0.6537 - val_loss: 0.5781 - val_acc: 0.7167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.6060 - acc: 0.6463 - val_loss: 0.5779 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.6296 - acc: 0.6296 - val_loss: 0.5826 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.6303 - acc: 0.6352 - val_loss: 0.5898 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.6091 - acc: 0.6611 - val_loss: 0.5901 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.6236 - acc: 0.6204 - val_loss: 0.5843 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.6348 - acc: 0.6296 - val_loss: 0.5783 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.6238 - acc: 0.6481 - val_loss: 0.5778 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.6171 - acc: 0.6259 - val_loss: 0.5775 - val_acc: 0.8000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.6076 - acc: 0.6741 - val_loss: 0.5775 - val_acc: 0.8000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.6062 - acc: 0.6574 - val_loss: 0.5773 - val_acc: 0.7833\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5949 - acc: 0.6685 - val_loss: 0.5776 - val_acc: 0.8000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5899 - acc: 0.6759 - val_loss: 0.5738 - val_acc: 0.8000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.57262 to 0.56531, saving model to best.model\n",
      "0s - loss: 0.6112 - acc: 0.6611 - val_loss: 0.5653 - val_acc: 0.8333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.56531 to 0.55571, saving model to best.model\n",
      "0s - loss: 0.5760 - acc: 0.6889 - val_loss: 0.5557 - val_acc: 0.8167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.55571 to 0.54811, saving model to best.model\n",
      "0s - loss: 0.6008 - acc: 0.6759 - val_loss: 0.5481 - val_acc: 0.8500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.54811 to 0.54384, saving model to best.model\n",
      "0s - loss: 0.5897 - acc: 0.6796 - val_loss: 0.5438 - val_acc: 0.8333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.54384 to 0.54170, saving model to best.model\n",
      "0s - loss: 0.5875 - acc: 0.7056 - val_loss: 0.5417 - val_acc: 0.8333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.54170 to 0.53778, saving model to best.model\n",
      "0s - loss: 0.5874 - acc: 0.6833 - val_loss: 0.5378 - val_acc: 0.8167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.53778 to 0.53313, saving model to best.model\n",
      "0s - loss: 0.5643 - acc: 0.6963 - val_loss: 0.5331 - val_acc: 0.8167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.53313 to 0.52927, saving model to best.model\n",
      "0s - loss: 0.5625 - acc: 0.7130 - val_loss: 0.5293 - val_acc: 0.8167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.52927 to 0.52284, saving model to best.model\n",
      "0s - loss: 0.5796 - acc: 0.6907 - val_loss: 0.5228 - val_acc: 0.8167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.52284 to 0.51718, saving model to best.model\n",
      "0s - loss: 0.5670 - acc: 0.6981 - val_loss: 0.5172 - val_acc: 0.8167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.51718 to 0.51230, saving model to best.model\n",
      "0s - loss: 0.5791 - acc: 0.7074 - val_loss: 0.5123 - val_acc: 0.8167\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.51230 to 0.50483, saving model to best.model\n",
      "0s - loss: 0.5739 - acc: 0.6889 - val_loss: 0.5048 - val_acc: 0.8167\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.50483 to 0.50242, saving model to best.model\n",
      "0s - loss: 0.5826 - acc: 0.7093 - val_loss: 0.5024 - val_acc: 0.8167\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5545 - acc: 0.6870 - val_loss: 0.5060 - val_acc: 0.7833\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5564 - acc: 0.7315 - val_loss: 0.5067 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5439 - acc: 0.7037 - val_loss: 0.5075 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5377 - acc: 0.7259 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5672 - acc: 0.7130 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5625 - acc: 0.7222 - val_loss: 0.5108 - val_acc: 0.7667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5388 - acc: 0.7278 - val_loss: 0.5096 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5595 - acc: 0.7148 - val_loss: 0.5105 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5433 - acc: 0.7315 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5254 - acc: 0.7389 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5535 - acc: 0.7019 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.50242 to 0.50047, saving model to best.model\n",
      "0s - loss: 0.5510 - acc: 0.7352 - val_loss: 0.5005 - val_acc: 0.7500\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.50047 to 0.50008, saving model to best.model\n",
      "0s - loss: 0.5156 - acc: 0.7556 - val_loss: 0.5001 - val_acc: 0.7500\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.50008 to 0.49991, saving model to best.model\n",
      "0s - loss: 0.5389 - acc: 0.7204 - val_loss: 0.4999 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5330 - acc: 0.7296 - val_loss: 0.5028 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5296 - acc: 0.7500 - val_loss: 0.5000 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.49991 to 0.49070, saving model to best.model\n",
      "0s - loss: 0.5296 - acc: 0.7222 - val_loss: 0.4907 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.49070 to 0.48091, saving model to best.model\n",
      "0s - loss: 0.5255 - acc: 0.7500 - val_loss: 0.4809 - val_acc: 0.7833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.48091 to 0.47399, saving model to best.model\n",
      "0s - loss: 0.5119 - acc: 0.7611 - val_loss: 0.4740 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.47399 to 0.47000, saving model to best.model\n",
      "0s - loss: 0.5254 - acc: 0.7278 - val_loss: 0.4700 - val_acc: 0.7833\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.5112 - acc: 0.7519 - val_loss: 0.4707 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.5077 - acc: 0.7407 - val_loss: 0.4742 - val_acc: 0.7667\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.5180 - acc: 0.7333 - val_loss: 0.4793 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.5102 - acc: 0.7500 - val_loss: 0.4851 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.5073 - acc: 0.7574 - val_loss: 0.4905 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4776 - acc: 0.7796 - val_loss: 0.4918 - val_acc: 0.7833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.5033 - acc: 0.7778 - val_loss: 0.4905 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.5054 - acc: 0.7685 - val_loss: 0.4841 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.5017 - acc: 0.7593 - val_loss: 0.4746 - val_acc: 0.7833\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.47000 to 0.46738, saving model to best.model\n",
      "0s - loss: 0.5041 - acc: 0.7426 - val_loss: 0.4674 - val_acc: 0.7833\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.46738 to 0.46585, saving model to best.model\n",
      "0s - loss: 0.4999 - acc: 0.7407 - val_loss: 0.4658 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.5027 - acc: 0.7704 - val_loss: 0.4667 - val_acc: 0.8000\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4958 - acc: 0.7556 - val_loss: 0.4695 - val_acc: 0.7667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.5081 - acc: 0.7667 - val_loss: 0.4714 - val_acc: 0.7667\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4949 - acc: 0.7667 - val_loss: 0.4675 - val_acc: 0.7833\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4893 - acc: 0.7704 - val_loss: 0.4676 - val_acc: 0.7833\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4809 - acc: 0.7556 - val_loss: 0.4756 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.5014 - acc: 0.7556 - val_loss: 0.4883 - val_acc: 0.7833\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4906 - acc: 0.7519 - val_loss: 0.4939 - val_acc: 0.7833\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4684 - acc: 0.7981 - val_loss: 0.4936 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4940 - acc: 0.7593 - val_loss: 0.4870 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4935 - acc: 0.7722 - val_loss: 0.4808 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4602 - acc: 0.7833 - val_loss: 0.4708 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.46585 to 0.46259, saving model to best.model\n",
      "0s - loss: 0.4675 - acc: 0.7778 - val_loss: 0.4626 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.46259 to 0.45847, saving model to best.model\n",
      "0s - loss: 0.4793 - acc: 0.7759 - val_loss: 0.4585 - val_acc: 0.8000\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.45847 to 0.45604, saving model to best.model\n",
      "0s - loss: 0.4697 - acc: 0.7870 - val_loss: 0.4560 - val_acc: 0.8000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.45604 to 0.45220, saving model to best.model\n",
      "0s - loss: 0.4771 - acc: 0.7907 - val_loss: 0.4522 - val_acc: 0.8167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.45220 to 0.44411, saving model to best.model\n",
      "0s - loss: 0.4346 - acc: 0.8019 - val_loss: 0.4441 - val_acc: 0.8167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.44411 to 0.43990, saving model to best.model\n",
      "0s - loss: 0.4722 - acc: 0.7722 - val_loss: 0.4399 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.43990 to 0.43568, saving model to best.model\n",
      "0s - loss: 0.4715 - acc: 0.7870 - val_loss: 0.4357 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.43568 to 0.43225, saving model to best.model\n",
      "0s - loss: 0.4836 - acc: 0.7685 - val_loss: 0.4322 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4698 - acc: 0.7815 - val_loss: 0.4323 - val_acc: 0.8000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4636 - acc: 0.7907 - val_loss: 0.4339 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4437 - acc: 0.7889 - val_loss: 0.4338 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.43225 to 0.43113, saving model to best.model\n",
      "0s - loss: 0.4567 - acc: 0.7833 - val_loss: 0.4311 - val_acc: 0.8000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.43113 to 0.42862, saving model to best.model\n",
      "0s - loss: 0.4535 - acc: 0.7944 - val_loss: 0.4286 - val_acc: 0.8000\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.42862 to 0.42624, saving model to best.model\n",
      "0s - loss: 0.4356 - acc: 0.7981 - val_loss: 0.4262 - val_acc: 0.8000\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.42624 to 0.42577, saving model to best.model\n",
      "0s - loss: 0.4381 - acc: 0.7926 - val_loss: 0.4258 - val_acc: 0.8000\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.42577 to 0.42513, saving model to best.model\n",
      "0s - loss: 0.4364 - acc: 0.7870 - val_loss: 0.4251 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4513 - acc: 0.7907 - val_loss: 0.4315 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4443 - acc: 0.7630 - val_loss: 0.4384 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4461 - acc: 0.8056 - val_loss: 0.4440 - val_acc: 0.7667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4410 - acc: 0.7963 - val_loss: 0.4462 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4124 - acc: 0.8130 - val_loss: 0.4447 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4376 - acc: 0.7963 - val_loss: 0.4396 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4575 - acc: 0.7667 - val_loss: 0.4294 - val_acc: 0.7833\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.42513 to 0.41973, saving model to best.model\n",
      "0s - loss: 0.4577 - acc: 0.7944 - val_loss: 0.4197 - val_acc: 0.8167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.41973 to 0.41035, saving model to best.model\n",
      "0s - loss: 0.4080 - acc: 0.8148 - val_loss: 0.4104 - val_acc: 0.8167\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.41035 to 0.40310, saving model to best.model\n",
      "0s - loss: 0.4063 - acc: 0.8093 - val_loss: 0.4031 - val_acc: 0.8167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.40310 to 0.39936, saving model to best.model\n",
      "0s - loss: 0.4572 - acc: 0.7870 - val_loss: 0.3994 - val_acc: 0.8167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.39936 to 0.39892, saving model to best.model\n",
      "0s - loss: 0.4533 - acc: 0.7944 - val_loss: 0.3989 - val_acc: 0.8167\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4196 - acc: 0.7704 - val_loss: 0.3995 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4165 - acc: 0.8019 - val_loss: 0.4008 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4080 - acc: 0.8074 - val_loss: 0.4036 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.4236 - acc: 0.8148 - val_loss: 0.4065 - val_acc: 0.8000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.4339 - acc: 0.8019 - val_loss: 0.4114 - val_acc: 0.8000\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3999 - acc: 0.8074 - val_loss: 0.4154 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.4029 - acc: 0.8093 - val_loss: 0.4128 - val_acc: 0.8000\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.4052 - acc: 0.8130 - val_loss: 0.4041 - val_acc: 0.8167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.4145 - acc: 0.8167 - val_loss: 0.4011 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.4079 - acc: 0.8222 - val_loss: 0.4020 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.4197 - acc: 0.8167 - val_loss: 0.4010 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.4282 - acc: 0.8130 - val_loss: 0.4012 - val_acc: 0.8167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.39892 to 0.39853, saving model to best.model\n",
      "0s - loss: 0.4056 - acc: 0.8130 - val_loss: 0.3985 - val_acc: 0.8167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.39853 to 0.39289, saving model to best.model\n",
      "0s - loss: 0.4203 - acc: 0.7981 - val_loss: 0.3929 - val_acc: 0.8500\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3947 - acc: 0.8370 - val_loss: 0.3956 - val_acc: 0.8333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3969 - acc: 0.8130 - val_loss: 0.4011 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.4047 - acc: 0.8426 - val_loss: 0.3991 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3975 - acc: 0.8093 - val_loss: 0.3941 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.39289 to 0.38865, saving model to best.model\n",
      "0s - loss: 0.3703 - acc: 0.8352 - val_loss: 0.3887 - val_acc: 0.8167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.38865 to 0.38705, saving model to best.model\n",
      "0s - loss: 0.3949 - acc: 0.8389 - val_loss: 0.3871 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3882 - acc: 0.8167 - val_loss: 0.3950 - val_acc: 0.8167\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3761 - acc: 0.8204 - val_loss: 0.4063 - val_acc: 0.8000\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.4011 - acc: 0.8370 - val_loss: 0.4113 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3956 - acc: 0.8185 - val_loss: 0.4105 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3799 - acc: 0.8352 - val_loss: 0.4009 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3808 - acc: 0.8444 - val_loss: 0.3891 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.38705 to 0.38114, saving model to best.model\n",
      "0s - loss: 0.3624 - acc: 0.8241 - val_loss: 0.3811 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.38114 to 0.37513, saving model to best.model\n",
      "0s - loss: 0.4061 - acc: 0.8278 - val_loss: 0.3751 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.37513 to 0.37494, saving model to best.model\n",
      "0s - loss: 0.3557 - acc: 0.8352 - val_loss: 0.3749 - val_acc: 0.8667\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.37494 to 0.36615, saving model to best.model\n",
      "0s - loss: 0.3580 - acc: 0.8259 - val_loss: 0.3661 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.36615 to 0.35528, saving model to best.model\n",
      "0s - loss: 0.3774 - acc: 0.8333 - val_loss: 0.3553 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.35528 to 0.34802, saving model to best.model\n",
      "0s - loss: 0.3795 - acc: 0.8481 - val_loss: 0.3480 - val_acc: 0.8667\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.34802 to 0.34233, saving model to best.model\n",
      "0s - loss: 0.3588 - acc: 0.8352 - val_loss: 0.3423 - val_acc: 0.8667\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.34233 to 0.34061, saving model to best.model\n",
      "0s - loss: 0.3638 - acc: 0.8333 - val_loss: 0.3406 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3934 - acc: 0.8148 - val_loss: 0.3417 - val_acc: 0.8667\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3887 - acc: 0.8278 - val_loss: 0.3511 - val_acc: 0.8500\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3600 - acc: 0.8407 - val_loss: 0.3660 - val_acc: 0.8333\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3447 - acc: 0.8444 - val_loss: 0.3872 - val_acc: 0.8333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3745 - acc: 0.8389 - val_loss: 0.3956 - val_acc: 0.8333\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3595 - acc: 0.8296 - val_loss: 0.3817 - val_acc: 0.8333\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3726 - acc: 0.8296 - val_loss: 0.3643 - val_acc: 0.8333\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3916 - acc: 0.8204 - val_loss: 0.3513 - val_acc: 0.8333\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.34061 to 0.33808, saving model to best.model\n",
      "0s - loss: 0.3525 - acc: 0.8463 - val_loss: 0.3381 - val_acc: 0.8500\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.33808 to 0.33040, saving model to best.model\n",
      "0s - loss: 0.3293 - acc: 0.8593 - val_loss: 0.3304 - val_acc: 0.8500\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.33040 to 0.32681, saving model to best.model\n",
      "0s - loss: 0.3687 - acc: 0.8611 - val_loss: 0.3268 - val_acc: 0.8500\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.32681 to 0.32665, saving model to best.model\n",
      "0s - loss: 0.3777 - acc: 0.8333 - val_loss: 0.3266 - val_acc: 0.8500\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3337 - acc: 0.8593 - val_loss: 0.3304 - val_acc: 0.8500\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3434 - acc: 0.8630 - val_loss: 0.3386 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3303 - acc: 0.8630 - val_loss: 0.3602 - val_acc: 0.8500\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3098 - acc: 0.8667 - val_loss: 0.3803 - val_acc: 0.8333\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3548 - acc: 0.8574 - val_loss: 0.3828 - val_acc: 0.8333\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3385 - acc: 0.8667 - val_loss: 0.3686 - val_acc: 0.8333\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3449 - acc: 0.8704 - val_loss: 0.3606 - val_acc: 0.8500\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3459 - acc: 0.8704 - val_loss: 0.3521 - val_acc: 0.8500\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3675 - acc: 0.8426 - val_loss: 0.3408 - val_acc: 0.8500\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3360 - acc: 0.8500 - val_loss: 0.3414 - val_acc: 0.8500\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3635 - acc: 0.8407 - val_loss: 0.3472 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.3254 - acc: 0.8556 - val_loss: 0.3528 - val_acc: 0.8333\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3426 - acc: 0.8389 - val_loss: 0.3496 - val_acc: 0.8333\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3203 - acc: 0.8519 - val_loss: 0.3380 - val_acc: 0.8333\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.3167 - acc: 0.8704 - val_loss: 0.3288 - val_acc: 0.8333\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.32665 to 0.31554, saving model to best.model\n",
      "0s - loss: 0.2953 - acc: 0.8722 - val_loss: 0.3155 - val_acc: 0.8500\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.31554 to 0.30501, saving model to best.model\n",
      "0s - loss: 0.3129 - acc: 0.8648 - val_loss: 0.3050 - val_acc: 0.8500\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.30501 to 0.30304, saving model to best.model\n",
      "0s - loss: 0.3249 - acc: 0.8648 - val_loss: 0.3030 - val_acc: 0.8667\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2932 - acc: 0.8907 - val_loss: 0.3059 - val_acc: 0.8667\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.3166 - acc: 0.8648 - val_loss: 0.3115 - val_acc: 0.8667\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.3325 - acc: 0.8407 - val_loss: 0.3195 - val_acc: 0.8667\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.3030 - acc: 0.8593 - val_loss: 0.3211 - val_acc: 0.8667\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2927 - acc: 0.8833 - val_loss: 0.3232 - val_acc: 0.8667\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2941 - acc: 0.8759 - val_loss: 0.3303 - val_acc: 0.8667\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.3367 - acc: 0.8722 - val_loss: 0.3420 - val_acc: 0.8500\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.3022 - acc: 0.8796 - val_loss: 0.3399 - val_acc: 0.8500\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.3221 - acc: 0.8722 - val_loss: 0.3292 - val_acc: 0.8500\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.3220 - acc: 0.8759 - val_loss: 0.3228 - val_acc: 0.8500\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.3129 - acc: 0.8648 - val_loss: 0.3227 - val_acc: 0.8500\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2652 - acc: 0.8963 - val_loss: 0.3254 - val_acc: 0.8500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.3086 - acc: 0.8722 - val_loss: 0.3220 - val_acc: 0.8500\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2850 - acc: 0.8889 - val_loss: 0.3134 - val_acc: 0.8500\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2957 - acc: 0.8796 - val_loss: 0.3074 - val_acc: 0.8500\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2711 - acc: 0.9000 - val_loss: 0.3174 - val_acc: 0.8333\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2836 - acc: 0.8889 - val_loss: 0.3401 - val_acc: 0.8333\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2772 - acc: 0.8889 - val_loss: 0.3541 - val_acc: 0.8000\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2827 - acc: 0.8870 - val_loss: 0.3411 - val_acc: 0.8333\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.3011 - acc: 0.8852 - val_loss: 0.3168 - val_acc: 0.8333\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss improved from 0.30304 to 0.29279, saving model to best.model\n",
      "0s - loss: 0.2932 - acc: 0.8778 - val_loss: 0.2928 - val_acc: 0.8500\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss improved from 0.29279 to 0.28106, saving model to best.model\n",
      "0s - loss: 0.2790 - acc: 0.8907 - val_loss: 0.2811 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss improved from 0.28106 to 0.27315, saving model to best.model\n",
      "0s - loss: 0.2837 - acc: 0.8889 - val_loss: 0.2732 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.59529, saving model to best.model\n",
      "0s - loss: 0.9453 - acc: 0.4889 - val_loss: 0.5953 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7284 - acc: 0.6500 - val_loss: 0.6167 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7295 - acc: 0.6852 - val_loss: 0.6057 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59529 to 0.58867, saving model to best.model\n",
      "0s - loss: 0.7263 - acc: 0.6926 - val_loss: 0.5887 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.58867 to 0.57966, saving model to best.model\n",
      "0s - loss: 0.6592 - acc: 0.6926 - val_loss: 0.5797 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6701 - acc: 0.6889 - val_loss: 0.5813 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6049 - acc: 0.6796 - val_loss: 0.5877 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5991 - acc: 0.6944 - val_loss: 0.5924 - val_acc: 0.7000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5968 - acc: 0.6685 - val_loss: 0.5923 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6251 - acc: 0.6722 - val_loss: 0.5883 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5749 - acc: 0.7056 - val_loss: 0.5839 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6125 - acc: 0.6796 - val_loss: 0.5808 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6011 - acc: 0.7000 - val_loss: 0.5803 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.57966 to 0.57861, saving model to best.model\n",
      "0s - loss: 0.5560 - acc: 0.7074 - val_loss: 0.5786 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.57861 to 0.57777, saving model to best.model\n",
      "0s - loss: 0.5729 - acc: 0.7148 - val_loss: 0.5778 - val_acc: 0.6667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.57777 to 0.57721, saving model to best.model\n",
      "0s - loss: 0.5766 - acc: 0.6963 - val_loss: 0.5772 - val_acc: 0.6833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.57721 to 0.57472, saving model to best.model\n",
      "0s - loss: 0.5888 - acc: 0.6944 - val_loss: 0.5747 - val_acc: 0.6833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.57472 to 0.57022, saving model to best.model\n",
      "0s - loss: 0.5489 - acc: 0.7093 - val_loss: 0.5702 - val_acc: 0.6833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.57022 to 0.56786, saving model to best.model\n",
      "0s - loss: 0.5844 - acc: 0.7167 - val_loss: 0.5679 - val_acc: 0.6833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.56786 to 0.56559, saving model to best.model\n",
      "0s - loss: 0.5568 - acc: 0.7259 - val_loss: 0.5656 - val_acc: 0.6833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.56559 to 0.56314, saving model to best.model\n",
      "0s - loss: 0.5554 - acc: 0.7278 - val_loss: 0.5631 - val_acc: 0.6833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.56314 to 0.55915, saving model to best.model\n",
      "0s - loss: 0.5554 - acc: 0.7259 - val_loss: 0.5591 - val_acc: 0.6833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.55915 to 0.55314, saving model to best.model\n",
      "0s - loss: 0.5394 - acc: 0.7111 - val_loss: 0.5531 - val_acc: 0.6833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.55314 to 0.54623, saving model to best.model\n",
      "0s - loss: 0.5362 - acc: 0.7185 - val_loss: 0.5462 - val_acc: 0.6833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.54623 to 0.54035, saving model to best.model\n",
      "0s - loss: 0.5684 - acc: 0.7074 - val_loss: 0.5404 - val_acc: 0.6833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.54035 to 0.53721, saving model to best.model\n",
      "0s - loss: 0.5570 - acc: 0.7130 - val_loss: 0.5372 - val_acc: 0.6833\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.53721 to 0.53567, saving model to best.model\n",
      "0s - loss: 0.5267 - acc: 0.7333 - val_loss: 0.5357 - val_acc: 0.7167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.53567 to 0.53441, saving model to best.model\n",
      "0s - loss: 0.5272 - acc: 0.7259 - val_loss: 0.5344 - val_acc: 0.7167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.53441 to 0.53248, saving model to best.model\n",
      "0s - loss: 0.5274 - acc: 0.7278 - val_loss: 0.5325 - val_acc: 0.7167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.53248 to 0.52805, saving model to best.model\n",
      "0s - loss: 0.5182 - acc: 0.7296 - val_loss: 0.5280 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.52805 to 0.52152, saving model to best.model\n",
      "0s - loss: 0.5276 - acc: 0.7241 - val_loss: 0.5215 - val_acc: 0.7167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.52152 to 0.51546, saving model to best.model\n",
      "0s - loss: 0.5417 - acc: 0.7352 - val_loss: 0.5155 - val_acc: 0.7000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.51546 to 0.50964, saving model to best.model\n",
      "0s - loss: 0.5176 - acc: 0.7278 - val_loss: 0.5096 - val_acc: 0.7000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.50964 to 0.50568, saving model to best.model\n",
      "0s - loss: 0.5247 - acc: 0.7352 - val_loss: 0.5057 - val_acc: 0.7000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.50568 to 0.50320, saving model to best.model\n",
      "0s - loss: 0.5188 - acc: 0.7296 - val_loss: 0.5032 - val_acc: 0.7167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.50320 to 0.50213, saving model to best.model\n",
      "0s - loss: 0.5219 - acc: 0.7278 - val_loss: 0.5021 - val_acc: 0.7167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.50213 to 0.50168, saving model to best.model\n",
      "0s - loss: 0.5128 - acc: 0.7370 - val_loss: 0.5017 - val_acc: 0.7167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.50168 to 0.50147, saving model to best.model\n",
      "0s - loss: 0.5141 - acc: 0.7444 - val_loss: 0.5015 - val_acc: 0.7167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5107 - acc: 0.7407 - val_loss: 0.5020 - val_acc: 0.7000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5138 - acc: 0.7426 - val_loss: 0.5037 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5134 - acc: 0.7389 - val_loss: 0.5053 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5117 - acc: 0.7593 - val_loss: 0.5057 - val_acc: 0.7833\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5033 - acc: 0.7611 - val_loss: 0.5035 - val_acc: 0.7833\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5179 - acc: 0.7463 - val_loss: 0.5017 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.50147 to 0.50060, saving model to best.model\n",
      "0s - loss: 0.5008 - acc: 0.7519 - val_loss: 0.5006 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.50060 to 0.49999, saving model to best.model\n",
      "0s - loss: 0.5009 - acc: 0.7500 - val_loss: 0.5000 - val_acc: 0.7667\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4743 - acc: 0.7759 - val_loss: 0.5007 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5067 - acc: 0.7463 - val_loss: 0.5024 - val_acc: 0.7167\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4831 - acc: 0.7759 - val_loss: 0.5025 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4973 - acc: 0.7574 - val_loss: 0.5012 - val_acc: 0.7333\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.49999 to 0.49936, saving model to best.model\n",
      "0s - loss: 0.4840 - acc: 0.7537 - val_loss: 0.4994 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.49936 to 0.49842, saving model to best.model\n",
      "0s - loss: 0.4753 - acc: 0.7704 - val_loss: 0.4984 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.49842 to 0.49771, saving model to best.model\n",
      "0s - loss: 0.4714 - acc: 0.7630 - val_loss: 0.4977 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.49771 to 0.49726, saving model to best.model\n",
      "0s - loss: 0.4725 - acc: 0.7630 - val_loss: 0.4973 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.49726 to 0.49684, saving model to best.model\n",
      "0s - loss: 0.4778 - acc: 0.7574 - val_loss: 0.4968 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.49684 to 0.49457, saving model to best.model\n",
      "0s - loss: 0.4972 - acc: 0.7407 - val_loss: 0.4946 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.49457 to 0.49326, saving model to best.model\n",
      "0s - loss: 0.4948 - acc: 0.7685 - val_loss: 0.4933 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.49326 to 0.49065, saving model to best.model\n",
      "0s - loss: 0.4897 - acc: 0.7537 - val_loss: 0.4906 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.49065 to 0.48766, saving model to best.model\n",
      "0s - loss: 0.4563 - acc: 0.7778 - val_loss: 0.4877 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.48766 to 0.48637, saving model to best.model\n",
      "0s - loss: 0.4734 - acc: 0.7704 - val_loss: 0.4864 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4600 - acc: 0.7685 - val_loss: 0.4871 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4668 - acc: 0.7519 - val_loss: 0.4897 - val_acc: 0.7833\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4640 - acc: 0.7870 - val_loss: 0.4942 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4717 - acc: 0.7611 - val_loss: 0.4980 - val_acc: 0.7667\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4695 - acc: 0.7741 - val_loss: 0.4985 - val_acc: 0.7667\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4620 - acc: 0.7778 - val_loss: 0.4939 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4690 - acc: 0.7704 - val_loss: 0.4907 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4662 - acc: 0.7778 - val_loss: 0.4895 - val_acc: 0.8167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4653 - acc: 0.7722 - val_loss: 0.4880 - val_acc: 0.8167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.48637 to 0.48558, saving model to best.model\n",
      "0s - loss: 0.4706 - acc: 0.7685 - val_loss: 0.4856 - val_acc: 0.8167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.48558 to 0.48335, saving model to best.model\n",
      "0s - loss: 0.4535 - acc: 0.7944 - val_loss: 0.4834 - val_acc: 0.8167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.48335 to 0.48140, saving model to best.model\n",
      "0s - loss: 0.4623 - acc: 0.7704 - val_loss: 0.4814 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.48140 to 0.48057, saving model to best.model\n",
      "0s - loss: 0.4462 - acc: 0.7870 - val_loss: 0.4806 - val_acc: 0.8167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4305 - acc: 0.7981 - val_loss: 0.4858 - val_acc: 0.8000\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4371 - acc: 0.7759 - val_loss: 0.4938 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4475 - acc: 0.8000 - val_loss: 0.4962 - val_acc: 0.7833\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4722 - acc: 0.7741 - val_loss: 0.4911 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4450 - acc: 0.7741 - val_loss: 0.4827 - val_acc: 0.8167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.48057 to 0.47849, saving model to best.model\n",
      "0s - loss: 0.4519 - acc: 0.8000 - val_loss: 0.4785 - val_acc: 0.8000\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.47849 to 0.47601, saving model to best.model\n",
      "0s - loss: 0.4343 - acc: 0.8093 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.47601 to 0.47349, saving model to best.model\n",
      "0s - loss: 0.4188 - acc: 0.8037 - val_loss: 0.4735 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.47349 to 0.47118, saving model to best.model\n",
      "0s - loss: 0.4370 - acc: 0.7870 - val_loss: 0.4712 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.47118 to 0.47109, saving model to best.model\n",
      "0s - loss: 0.4390 - acc: 0.7833 - val_loss: 0.4711 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4002 - acc: 0.8111 - val_loss: 0.4728 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4206 - acc: 0.8278 - val_loss: 0.4747 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4140 - acc: 0.8167 - val_loss: 0.4748 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4189 - acc: 0.7981 - val_loss: 0.4730 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4020 - acc: 0.8019 - val_loss: 0.4732 - val_acc: 0.8167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4238 - acc: 0.8000 - val_loss: 0.4724 - val_acc: 0.8167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.47109 to 0.47085, saving model to best.model\n",
      "0s - loss: 0.3986 - acc: 0.8389 - val_loss: 0.4709 - val_acc: 0.8167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.47085 to 0.47066, saving model to best.model\n",
      "0s - loss: 0.4095 - acc: 0.8204 - val_loss: 0.4707 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3910 - acc: 0.8185 - val_loss: 0.4734 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4162 - acc: 0.8130 - val_loss: 0.4767 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4125 - acc: 0.8093 - val_loss: 0.4799 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3996 - acc: 0.8037 - val_loss: 0.4837 - val_acc: 0.8167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4153 - acc: 0.7981 - val_loss: 0.4856 - val_acc: 0.8167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4067 - acc: 0.8148 - val_loss: 0.4853 - val_acc: 0.8167\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3942 - acc: 0.8130 - val_loss: 0.4828 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4120 - acc: 0.8167 - val_loss: 0.4813 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3914 - acc: 0.8185 - val_loss: 0.4837 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4053 - acc: 0.8093 - val_loss: 0.4845 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3893 - acc: 0.8130 - val_loss: 0.4815 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3755 - acc: 0.8333 - val_loss: 0.4781 - val_acc: 0.8333\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3909 - acc: 0.8130 - val_loss: 0.4751 - val_acc: 0.8333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3975 - acc: 0.8204 - val_loss: 0.4722 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3731 - acc: 0.8463 - val_loss: 0.4711 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4129 - acc: 0.8111 - val_loss: 0.4710 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.47066 to 0.46703, saving model to best.model\n",
      "0s - loss: 0.3924 - acc: 0.8278 - val_loss: 0.4670 - val_acc: 0.8167\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.46703 to 0.46344, saving model to best.model\n",
      "0s - loss: 0.3574 - acc: 0.8370 - val_loss: 0.4634 - val_acc: 0.8167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3846 - acc: 0.8259 - val_loss: 0.4659 - val_acc: 0.8167\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3941 - acc: 0.8278 - val_loss: 0.4721 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3991 - acc: 0.8296 - val_loss: 0.4759 - val_acc: 0.8333\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3581 - acc: 0.8370 - val_loss: 0.4757 - val_acc: 0.8333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3562 - acc: 0.8463 - val_loss: 0.4735 - val_acc: 0.8333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3864 - acc: 0.8037 - val_loss: 0.4725 - val_acc: 0.8333\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3955 - acc: 0.8259 - val_loss: 0.4714 - val_acc: 0.8333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3632 - acc: 0.8352 - val_loss: 0.4719 - val_acc: 0.8167\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3824 - acc: 0.8185 - val_loss: 0.4736 - val_acc: 0.8167\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3923 - acc: 0.8222 - val_loss: 0.4769 - val_acc: 0.8167\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3726 - acc: 0.8370 - val_loss: 0.4819 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3692 - acc: 0.8481 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3407 - acc: 0.8426 - val_loss: 0.4937 - val_acc: 0.8500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3625 - acc: 0.8426 - val_loss: 0.4911 - val_acc: 0.8500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3561 - acc: 0.8426 - val_loss: 0.4847 - val_acc: 0.8500\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3318 - acc: 0.8500 - val_loss: 0.4725 - val_acc: 0.8333\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3428 - acc: 0.8519 - val_loss: 0.4644 - val_acc: 0.8167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3568 - acc: 0.8407 - val_loss: 0.4649 - val_acc: 0.8167\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3581 - acc: 0.8389 - val_loss: 0.4701 - val_acc: 0.8167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3351 - acc: 0.8611 - val_loss: 0.4739 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3374 - acc: 0.8500 - val_loss: 0.4795 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3371 - acc: 0.8593 - val_loss: 0.4858 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3200 - acc: 0.8500 - val_loss: 0.4944 - val_acc: 0.8333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3415 - acc: 0.8389 - val_loss: 0.5022 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3309 - acc: 0.8500 - val_loss: 0.4990 - val_acc: 0.8000\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3334 - acc: 0.8481 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.55794, saving model to best.model\n",
      "0s - loss: 0.9620 - acc: 0.4556 - val_loss: 0.5579 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.6735 - acc: 0.6537 - val_loss: 0.6069 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.6898 - acc: 0.7093 - val_loss: 0.6222 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.7128 - acc: 0.7204 - val_loss: 0.5872 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6232 - acc: 0.7111 - val_loss: 0.5579 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.55794 to 0.54397, saving model to best.model\n",
      "0s - loss: 0.6175 - acc: 0.7278 - val_loss: 0.5440 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.54397 to 0.54062, saving model to best.model\n",
      "0s - loss: 0.5848 - acc: 0.7019 - val_loss: 0.5406 - val_acc: 0.7167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5661 - acc: 0.7185 - val_loss: 0.5419 - val_acc: 0.7167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5932 - acc: 0.7093 - val_loss: 0.5440 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5588 - acc: 0.7056 - val_loss: 0.5445 - val_acc: 0.7167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5642 - acc: 0.7167 - val_loss: 0.5420 - val_acc: 0.7167\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.54062 to 0.53805, saving model to best.model\n",
      "0s - loss: 0.5827 - acc: 0.7204 - val_loss: 0.5381 - val_acc: 0.7167\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.53805 to 0.53416, saving model to best.model\n",
      "0s - loss: 0.5460 - acc: 0.7185 - val_loss: 0.5342 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.53416 to 0.53100, saving model to best.model\n",
      "0s - loss: 0.5575 - acc: 0.7389 - val_loss: 0.5310 - val_acc: 0.7167\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.53100 to 0.53006, saving model to best.model\n",
      "0s - loss: 0.5741 - acc: 0.7352 - val_loss: 0.5301 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.53006 to 0.52932, saving model to best.model\n",
      "0s - loss: 0.5209 - acc: 0.7333 - val_loss: 0.5293 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.52932 to 0.52786, saving model to best.model\n",
      "0s - loss: 0.5211 - acc: 0.7463 - val_loss: 0.5279 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.52786 to 0.52610, saving model to best.model\n",
      "0s - loss: 0.5478 - acc: 0.7352 - val_loss: 0.5261 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.52610 to 0.52369, saving model to best.model\n",
      "0s - loss: 0.5148 - acc: 0.7463 - val_loss: 0.5237 - val_acc: 0.7167\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.52369 to 0.52116, saving model to best.model\n",
      "0s - loss: 0.5230 - acc: 0.7426 - val_loss: 0.5212 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.52116 to 0.51840, saving model to best.model\n",
      "0s - loss: 0.5101 - acc: 0.7519 - val_loss: 0.5184 - val_acc: 0.7000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.51840 to 0.51505, saving model to best.model\n",
      "0s - loss: 0.5366 - acc: 0.7278 - val_loss: 0.5150 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.51505 to 0.51209, saving model to best.model\n",
      "0s - loss: 0.5323 - acc: 0.7389 - val_loss: 0.5121 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.51209 to 0.50975, saving model to best.model\n",
      "0s - loss: 0.4977 - acc: 0.7333 - val_loss: 0.5098 - val_acc: 0.7333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.50975 to 0.50776, saving model to best.model\n",
      "0s - loss: 0.5195 - acc: 0.7296 - val_loss: 0.5078 - val_acc: 0.7333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.50776 to 0.50509, saving model to best.model\n",
      "0s - loss: 0.5231 - acc: 0.7407 - val_loss: 0.5051 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.50509 to 0.50187, saving model to best.model\n",
      "0s - loss: 0.4994 - acc: 0.7537 - val_loss: 0.5019 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.50187 to 0.49930, saving model to best.model\n",
      "0s - loss: 0.5094 - acc: 0.7463 - val_loss: 0.4993 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.49930 to 0.49693, saving model to best.model\n",
      "0s - loss: 0.4964 - acc: 0.7574 - val_loss: 0.4969 - val_acc: 0.7500\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.49693 to 0.49501, saving model to best.model\n",
      "0s - loss: 0.5137 - acc: 0.7481 - val_loss: 0.4950 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.49501 to 0.49250, saving model to best.model\n",
      "0s - loss: 0.5132 - acc: 0.7704 - val_loss: 0.4925 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.49250 to 0.48979, saving model to best.model\n",
      "0s - loss: 0.5029 - acc: 0.7741 - val_loss: 0.4898 - val_acc: 0.7333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.48979 to 0.48789, saving model to best.model\n",
      "0s - loss: 0.4916 - acc: 0.7685 - val_loss: 0.4879 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.48789 to 0.48680, saving model to best.model\n",
      "0s - loss: 0.4745 - acc: 0.7796 - val_loss: 0.4868 - val_acc: 0.7333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.48680 to 0.48530, saving model to best.model\n",
      "0s - loss: 0.4750 - acc: 0.7833 - val_loss: 0.4853 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.48530 to 0.48286, saving model to best.model\n",
      "0s - loss: 0.4930 - acc: 0.7444 - val_loss: 0.4829 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.48286 to 0.48032, saving model to best.model\n",
      "0s - loss: 0.4792 - acc: 0.7574 - val_loss: 0.4803 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.48032 to 0.47860, saving model to best.model\n",
      "0s - loss: 0.5030 - acc: 0.7685 - val_loss: 0.4786 - val_acc: 0.7667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.47860 to 0.47723, saving model to best.model\n",
      "0s - loss: 0.4851 - acc: 0.7778 - val_loss: 0.4772 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.47723 to 0.47523, saving model to best.model\n",
      "0s - loss: 0.4922 - acc: 0.7722 - val_loss: 0.4752 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.47523 to 0.47328, saving model to best.model\n",
      "0s - loss: 0.4663 - acc: 0.7907 - val_loss: 0.4733 - val_acc: 0.7667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.47328 to 0.47259, saving model to best.model\n",
      "0s - loss: 0.5030 - acc: 0.7556 - val_loss: 0.4726 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.47259 to 0.47167, saving model to best.model\n",
      "0s - loss: 0.4572 - acc: 0.7889 - val_loss: 0.4717 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.47167 to 0.47002, saving model to best.model\n",
      "0s - loss: 0.4652 - acc: 0.7963 - val_loss: 0.4700 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.47002 to 0.46695, saving model to best.model\n",
      "0s - loss: 0.4783 - acc: 0.7611 - val_loss: 0.4669 - val_acc: 0.7500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.46695 to 0.46477, saving model to best.model\n",
      "0s - loss: 0.4715 - acc: 0.7796 - val_loss: 0.4648 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.46477 to 0.46319, saving model to best.model\n",
      "0s - loss: 0.4639 - acc: 0.7852 - val_loss: 0.4632 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.46319 to 0.46150, saving model to best.model\n",
      "0s - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4615 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.46150 to 0.46056, saving model to best.model\n",
      "0s - loss: 0.4723 - acc: 0.7778 - val_loss: 0.4606 - val_acc: 0.7500\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4577 - acc: 0.8056 - val_loss: 0.4618 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.46056 to 0.46049, saving model to best.model\n",
      "0s - loss: 0.4762 - acc: 0.7944 - val_loss: 0.4605 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.46049 to 0.45774, saving model to best.model\n",
      "0s - loss: 0.4627 - acc: 0.7833 - val_loss: 0.4577 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.45774 to 0.45677, saving model to best.model\n",
      "0s - loss: 0.4567 - acc: 0.7907 - val_loss: 0.4568 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4751 - acc: 0.7815 - val_loss: 0.4585 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4713 - acc: 0.7926 - val_loss: 0.4591 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4450 - acc: 0.7981 - val_loss: 0.4591 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4425 - acc: 0.8093 - val_loss: 0.4585 - val_acc: 0.8000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.8093 - val_loss: 0.4588 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4478 - acc: 0.7833 - val_loss: 0.4582 - val_acc: 0.8000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4459 - acc: 0.7944 - val_loss: 0.4574 - val_acc: 0.8000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.45677 to 0.45581, saving model to best.model\n",
      "0s - loss: 0.4517 - acc: 0.7852 - val_loss: 0.4558 - val_acc: 0.8000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.45581 to 0.45134, saving model to best.model\n",
      "0s - loss: 0.4352 - acc: 0.8222 - val_loss: 0.4513 - val_acc: 0.8167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.45134 to 0.44770, saving model to best.model\n",
      "0s - loss: 0.4714 - acc: 0.7852 - val_loss: 0.4477 - val_acc: 0.8333\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.44770 to 0.44573, saving model to best.model\n",
      "0s - loss: 0.4338 - acc: 0.8074 - val_loss: 0.4457 - val_acc: 0.8333\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.44573 to 0.44354, saving model to best.model\n",
      "0s - loss: 0.4228 - acc: 0.8167 - val_loss: 0.4435 - val_acc: 0.8333\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.44354 to 0.44089, saving model to best.model\n",
      "0s - loss: 0.4449 - acc: 0.8019 - val_loss: 0.4409 - val_acc: 0.8333\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.44089 to 0.43721, saving model to best.model\n",
      "0s - loss: 0.4359 - acc: 0.8185 - val_loss: 0.4372 - val_acc: 0.8333\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.43721 to 0.43399, saving model to best.model\n",
      "0s - loss: 0.4355 - acc: 0.8000 - val_loss: 0.4340 - val_acc: 0.8333\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.43399 to 0.43356, saving model to best.model\n",
      "0s - loss: 0.4533 - acc: 0.8148 - val_loss: 0.4336 - val_acc: 0.8333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.43356 to 0.43276, saving model to best.model\n",
      "0s - loss: 0.4264 - acc: 0.7963 - val_loss: 0.4328 - val_acc: 0.8333\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.43276 to 0.43240, saving model to best.model\n",
      "0s - loss: 0.4180 - acc: 0.8352 - val_loss: 0.4324 - val_acc: 0.8167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.43240 to 0.43236, saving model to best.model\n",
      "0s - loss: 0.4115 - acc: 0.8148 - val_loss: 0.4324 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.43236 to 0.43138, saving model to best.model\n",
      "0s - loss: 0.4082 - acc: 0.8204 - val_loss: 0.4314 - val_acc: 0.8167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.43138 to 0.42877, saving model to best.model\n",
      "0s - loss: 0.4191 - acc: 0.8111 - val_loss: 0.4288 - val_acc: 0.8167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.42877 to 0.42337, saving model to best.model\n",
      "0s - loss: 0.4290 - acc: 0.8222 - val_loss: 0.4234 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.42337 to 0.42010, saving model to best.model\n",
      "0s - loss: 0.4025 - acc: 0.8241 - val_loss: 0.4201 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.42010 to 0.41833, saving model to best.model\n",
      "0s - loss: 0.4091 - acc: 0.8278 - val_loss: 0.4183 - val_acc: 0.8333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.41833 to 0.41607, saving model to best.model\n",
      "0s - loss: 0.4262 - acc: 0.8148 - val_loss: 0.4161 - val_acc: 0.8333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.41607 to 0.41512, saving model to best.model\n",
      "0s - loss: 0.4155 - acc: 0.8167 - val_loss: 0.4151 - val_acc: 0.8333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.3840 - acc: 0.8222 - val_loss: 0.4158 - val_acc: 0.8333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4085 - acc: 0.8296 - val_loss: 0.4182 - val_acc: 0.8167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.3917 - acc: 0.8222 - val_loss: 0.4205 - val_acc: 0.8167\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.3856 - acc: 0.8352 - val_loss: 0.4230 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4136 - acc: 0.8185 - val_loss: 0.4243 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.3982 - acc: 0.8370 - val_loss: 0.4233 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4059 - acc: 0.8315 - val_loss: 0.4231 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.3907 - acc: 0.8426 - val_loss: 0.4217 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.3979 - acc: 0.8315 - val_loss: 0.4204 - val_acc: 0.8167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4006 - acc: 0.8296 - val_loss: 0.4198 - val_acc: 0.8167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4102 - acc: 0.8259 - val_loss: 0.4210 - val_acc: 0.8167\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3922 - acc: 0.8333 - val_loss: 0.4248 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3981 - acc: 0.8241 - val_loss: 0.4273 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.3970 - acc: 0.8241 - val_loss: 0.4299 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4026 - acc: 0.8333 - val_loss: 0.4307 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3605 - acc: 0.8463 - val_loss: 0.4297 - val_acc: 0.8167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3774 - acc: 0.8463 - val_loss: 0.4273 - val_acc: 0.8167\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3720 - acc: 0.8333 - val_loss: 0.4217 - val_acc: 0.8167\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3537 - acc: 0.8352 - val_loss: 0.4170 - val_acc: 0.8167\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.41512 to 0.41346, saving model to best.model\n",
      "0s - loss: 0.3700 - acc: 0.8389 - val_loss: 0.4135 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.41346 to 0.41067, saving model to best.model\n",
      "0s - loss: 0.3741 - acc: 0.8444 - val_loss: 0.4107 - val_acc: 0.8167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.41067 to 0.40886, saving model to best.model\n",
      "0s - loss: 0.3770 - acc: 0.8296 - val_loss: 0.4089 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.40886 to 0.40519, saving model to best.model\n",
      "0s - loss: 0.3797 - acc: 0.8500 - val_loss: 0.4052 - val_acc: 0.8500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.40519 to 0.40188, saving model to best.model\n",
      "0s - loss: 0.3828 - acc: 0.8278 - val_loss: 0.4019 - val_acc: 0.8500\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3781 - acc: 0.8370 - val_loss: 0.4030 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4013 - acc: 0.8333 - val_loss: 0.4051 - val_acc: 0.8167\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3712 - acc: 0.8537 - val_loss: 0.4073 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3717 - acc: 0.8426 - val_loss: 0.4066 - val_acc: 0.8500\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3448 - acc: 0.8481 - val_loss: 0.4045 - val_acc: 0.8500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.40188 to 0.40039, saving model to best.model\n",
      "0s - loss: 0.3790 - acc: 0.8407 - val_loss: 0.4004 - val_acc: 0.8333\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.40039 to 0.39946, saving model to best.model\n",
      "0s - loss: 0.3385 - acc: 0.8444 - val_loss: 0.3995 - val_acc: 0.8333\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3396 - acc: 0.8611 - val_loss: 0.4014 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3260 - acc: 0.8741 - val_loss: 0.4003 - val_acc: 0.8500\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.39946 to 0.39482, saving model to best.model\n",
      "0s - loss: 0.3468 - acc: 0.8315 - val_loss: 0.3948 - val_acc: 0.8500\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.39482 to 0.39202, saving model to best.model\n",
      "0s - loss: 0.3561 - acc: 0.8481 - val_loss: 0.3920 - val_acc: 0.8500\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.39202 to 0.38970, saving model to best.model\n",
      "0s - loss: 0.3355 - acc: 0.8685 - val_loss: 0.3897 - val_acc: 0.8667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.38970 to 0.38339, saving model to best.model\n",
      "0s - loss: 0.3379 - acc: 0.8704 - val_loss: 0.3834 - val_acc: 0.8667\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.38339 to 0.38214, saving model to best.model\n",
      "0s - loss: 0.3611 - acc: 0.8426 - val_loss: 0.3821 - val_acc: 0.8833\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3415 - acc: 0.8481 - val_loss: 0.3872 - val_acc: 0.8333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3645 - acc: 0.8463 - val_loss: 0.3930 - val_acc: 0.8333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3680 - acc: 0.8463 - val_loss: 0.3897 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3179 - acc: 0.8593 - val_loss: 0.3857 - val_acc: 0.8333\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.38214 to 0.38149, saving model to best.model\n",
      "0s - loss: 0.3535 - acc: 0.8463 - val_loss: 0.3815 - val_acc: 0.8500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.38149 to 0.37432, saving model to best.model\n",
      "0s - loss: 0.3611 - acc: 0.8315 - val_loss: 0.3743 - val_acc: 0.8500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.37432 to 0.36741, saving model to best.model\n",
      "0s - loss: 0.3431 - acc: 0.8796 - val_loss: 0.3674 - val_acc: 0.8500\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3188 - acc: 0.8611 - val_loss: 0.3691 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3382 - acc: 0.8667 - val_loss: 0.3717 - val_acc: 0.8667\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3251 - acc: 0.8630 - val_loss: 0.3736 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3408 - acc: 0.8667 - val_loss: 0.3788 - val_acc: 0.8333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3187 - acc: 0.8759 - val_loss: 0.3823 - val_acc: 0.8500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3528 - acc: 0.8537 - val_loss: 0.3810 - val_acc: 0.8500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3253 - acc: 0.8704 - val_loss: 0.3775 - val_acc: 0.8500\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3258 - acc: 0.8722 - val_loss: 0.3746 - val_acc: 0.8333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3083 - acc: 0.8778 - val_loss: 0.3727 - val_acc: 0.8500\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3252 - acc: 0.8833 - val_loss: 0.3709 - val_acc: 0.8500\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.2915 - acc: 0.8852 - val_loss: 0.3709 - val_acc: 0.8667\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3163 - acc: 0.8759 - val_loss: 0.3725 - val_acc: 0.8667\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.2998 - acc: 0.8852 - val_loss: 0.3753 - val_acc: 0.8500\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3074 - acc: 0.8685 - val_loss: 0.3774 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3030 - acc: 0.8796 - val_loss: 0.3742 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.2997 - acc: 0.8685 - val_loss: 0.3690 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.36741 to 0.36608, saving model to best.model\n",
      "0s - loss: 0.2828 - acc: 0.9019 - val_loss: 0.3661 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3460 - acc: 0.8685 - val_loss: 0.3669 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.36608 to 0.36338, saving model to best.model\n",
      "0s - loss: 0.2959 - acc: 0.8704 - val_loss: 0.3634 - val_acc: 0.8500\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.36338 to 0.35240, saving model to best.model\n",
      "0s - loss: 0.3368 - acc: 0.8704 - val_loss: 0.3524 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.35240 to 0.34303, saving model to best.model\n",
      "0s - loss: 0.3056 - acc: 0.8907 - val_loss: 0.3430 - val_acc: 0.8833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.34303 to 0.34076, saving model to best.model\n",
      "0s - loss: 0.3013 - acc: 0.8759 - val_loss: 0.3408 - val_acc: 0.8833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.34076 to 0.33975, saving model to best.model\n",
      "0s - loss: 0.3149 - acc: 0.8667 - val_loss: 0.3398 - val_acc: 0.8833\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.33975 to 0.33754, saving model to best.model\n",
      "0s - loss: 0.2982 - acc: 0.8833 - val_loss: 0.3375 - val_acc: 0.8833\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.33754 to 0.33118, saving model to best.model\n",
      "0s - loss: 0.2858 - acc: 0.8833 - val_loss: 0.3312 - val_acc: 0.8667\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.33118 to 0.32243, saving model to best.model\n",
      "0s - loss: 0.2936 - acc: 0.8870 - val_loss: 0.3224 - val_acc: 0.8667\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.32243 to 0.31520, saving model to best.model\n",
      "0s - loss: 0.2721 - acc: 0.9037 - val_loss: 0.3152 - val_acc: 0.8667\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.31520 to 0.31165, saving model to best.model\n",
      "0s - loss: 0.2769 - acc: 0.8833 - val_loss: 0.3116 - val_acc: 0.8833\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.2858 - acc: 0.8722 - val_loss: 0.3173 - val_acc: 0.9000\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3285 - acc: 0.8833 - val_loss: 0.3252 - val_acc: 0.8667\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.2717 - acc: 0.8944 - val_loss: 0.3263 - val_acc: 0.8667\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2675 - acc: 0.9037 - val_loss: 0.3183 - val_acc: 0.8500\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.31165 to 0.30809, saving model to best.model\n",
      "0s - loss: 0.2732 - acc: 0.8981 - val_loss: 0.3081 - val_acc: 0.8500\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.30809 to 0.30369, saving model to best.model\n",
      "0s - loss: 0.2581 - acc: 0.9093 - val_loss: 0.3037 - val_acc: 0.8500\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.30369 to 0.29894, saving model to best.model\n",
      "0s - loss: 0.2794 - acc: 0.8796 - val_loss: 0.2989 - val_acc: 0.8500\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2724 - acc: 0.9037 - val_loss: 0.3042 - val_acc: 0.8500\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2757 - acc: 0.9019 - val_loss: 0.3249 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2567 - acc: 0.9037 - val_loss: 0.3424 - val_acc: 0.8333\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2725 - acc: 0.8981 - val_loss: 0.3470 - val_acc: 0.8167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2436 - acc: 0.9019 - val_loss: 0.3314 - val_acc: 0.8333\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2634 - acc: 0.9093 - val_loss: 0.3143 - val_acc: 0.8500\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2477 - acc: 0.8815 - val_loss: 0.3056 - val_acc: 0.8667\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2529 - acc: 0.8926 - val_loss: 0.3001 - val_acc: 0.8667\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.29894 to 0.29541, saving model to best.model\n",
      "0s - loss: 0.2595 - acc: 0.8852 - val_loss: 0.2954 - val_acc: 0.8667\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2693 - acc: 0.8907 - val_loss: 0.3000 - val_acc: 0.8667\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2653 - acc: 0.9056 - val_loss: 0.3026 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2427 - acc: 0.9111 - val_loss: 0.3011 - val_acc: 0.8500\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2705 - acc: 0.9019 - val_loss: 0.3000 - val_acc: 0.8500\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.2228 - acc: 0.9056 - val_loss: 0.2982 - val_acc: 0.8500\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.29541 to 0.29443, saving model to best.model\n",
      "0s - loss: 0.2400 - acc: 0.9204 - val_loss: 0.2944 - val_acc: 0.8500\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.29443 to 0.29124, saving model to best.model\n",
      "0s - loss: 0.2624 - acc: 0.8981 - val_loss: 0.2912 - val_acc: 0.8500\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.29124 to 0.28926, saving model to best.model\n",
      "0s - loss: 0.2272 - acc: 0.9148 - val_loss: 0.2893 - val_acc: 0.8500\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.28926 to 0.28368, saving model to best.model\n",
      "0s - loss: 0.2539 - acc: 0.9130 - val_loss: 0.2837 - val_acc: 0.8500\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.28368 to 0.27498, saving model to best.model\n",
      "0s - loss: 0.2288 - acc: 0.9111 - val_loss: 0.2750 - val_acc: 0.8500\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.27498 to 0.27097, saving model to best.model\n",
      "0s - loss: 0.2329 - acc: 0.9074 - val_loss: 0.2710 - val_acc: 0.8500\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2321 - acc: 0.8944 - val_loss: 0.2716 - val_acc: 0.8500\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2305 - acc: 0.9093 - val_loss: 0.2781 - val_acc: 0.8500\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2099 - acc: 0.9333 - val_loss: 0.2804 - val_acc: 0.8500\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2273 - acc: 0.9167 - val_loss: 0.2721 - val_acc: 0.8833\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss improved from 0.27097 to 0.26813, saving model to best.model\n",
      "0s - loss: 0.2297 - acc: 0.9148 - val_loss: 0.2681 - val_acc: 0.8833\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.26813 to 0.26289, saving model to best.model\n",
      "0s - loss: 0.2209 - acc: 0.9278 - val_loss: 0.2629 - val_acc: 0.8833\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.26289 to 0.25724, saving model to best.model\n",
      "0s - loss: 0.2345 - acc: 0.9167 - val_loss: 0.2572 - val_acc: 0.9167\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2343 - acc: 0.9148 - val_loss: 0.2592 - val_acc: 0.9167\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2301 - acc: 0.9167 - val_loss: 0.2602 - val_acc: 0.9167\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.25724 to 0.25444, saving model to best.model\n",
      "0s - loss: 0.2171 - acc: 0.9167 - val_loss: 0.2544 - val_acc: 0.9167\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss improved from 0.25444 to 0.24660, saving model to best.model\n",
      "0s - loss: 0.2454 - acc: 0.9148 - val_loss: 0.2466 - val_acc: 0.9000\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.24660 to 0.24194, saving model to best.model\n",
      "0s - loss: 0.2021 - acc: 0.9370 - val_loss: 0.2419 - val_acc: 0.9167\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2001 - acc: 0.9296 - val_loss: 0.2432 - val_acc: 0.9167\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.24194 to 0.24023, saving model to best.model\n",
      "0s - loss: 0.2093 - acc: 0.9241 - val_loss: 0.2402 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2199 - acc: 0.9093 - val_loss: 0.2420 - val_acc: 0.9167\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2147 - acc: 0.9000 - val_loss: 0.2467 - val_acc: 0.9000\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2103 - acc: 0.9185 - val_loss: 0.2533 - val_acc: 0.9000\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2262 - acc: 0.9093 - val_loss: 0.2555 - val_acc: 0.9000\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2139 - acc: 0.9278 - val_loss: 0.2522 - val_acc: 0.9000\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2197 - acc: 0.9259 - val_loss: 0.2529 - val_acc: 0.9000\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2165 - acc: 0.9111 - val_loss: 0.2597 - val_acc: 0.9000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.59364, saving model to best.model\n",
      "0s - loss: 0.8422 - acc: 0.6444 - val_loss: 0.5936 - val_acc: 0.7000\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.59364 to 0.57112, saving model to best.model\n",
      "0s - loss: 0.7697 - acc: 0.6296 - val_loss: 0.5711 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.57112 to 0.56069, saving model to best.model\n",
      "0s - loss: 0.7718 - acc: 0.6074 - val_loss: 0.5607 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.56069 to 0.55535, saving model to best.model\n",
      "0s - loss: 0.7180 - acc: 0.6574 - val_loss: 0.5553 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6661 - acc: 0.6519 - val_loss: 0.5555 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.7083 - acc: 0.6481 - val_loss: 0.5642 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6687 - acc: 0.6333 - val_loss: 0.5722 - val_acc: 0.7000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6508 - acc: 0.6463 - val_loss: 0.5716 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6281 - acc: 0.6444 - val_loss: 0.5679 - val_acc: 0.7167\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6142 - acc: 0.6796 - val_loss: 0.5624 - val_acc: 0.7167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.55535 to 0.55504, saving model to best.model\n",
      "0s - loss: 0.6057 - acc: 0.6667 - val_loss: 0.5550 - val_acc: 0.7000\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.55504 to 0.55095, saving model to best.model\n",
      "0s - loss: 0.6323 - acc: 0.6630 - val_loss: 0.5509 - val_acc: 0.7000\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.55095 to 0.54729, saving model to best.model\n",
      "0s - loss: 0.5691 - acc: 0.7019 - val_loss: 0.5473 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.54729 to 0.54406, saving model to best.model\n",
      "0s - loss: 0.5778 - acc: 0.6796 - val_loss: 0.5441 - val_acc: 0.7000\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.54406 to 0.54356, saving model to best.model\n",
      "0s - loss: 0.6253 - acc: 0.6815 - val_loss: 0.5436 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6022 - acc: 0.7074 - val_loss: 0.5462 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5786 - acc: 0.6963 - val_loss: 0.5506 - val_acc: 0.7667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.6092 - acc: 0.6778 - val_loss: 0.5554 - val_acc: 0.7167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5935 - acc: 0.7056 - val_loss: 0.5592 - val_acc: 0.7167\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.6076 - acc: 0.6648 - val_loss: 0.5598 - val_acc: 0.7167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5677 - acc: 0.6889 - val_loss: 0.5576 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5792 - acc: 0.6907 - val_loss: 0.5553 - val_acc: 0.7167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5795 - acc: 0.6870 - val_loss: 0.5524 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5979 - acc: 0.6944 - val_loss: 0.5471 - val_acc: 0.7667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.54356 to 0.54045, saving model to best.model\n",
      "0s - loss: 0.5596 - acc: 0.7204 - val_loss: 0.5404 - val_acc: 0.7667\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.54045 to 0.53547, saving model to best.model\n",
      "0s - loss: 0.5734 - acc: 0.6926 - val_loss: 0.5355 - val_acc: 0.7667\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.53547 to 0.53135, saving model to best.model\n",
      "0s - loss: 0.5525 - acc: 0.7204 - val_loss: 0.5313 - val_acc: 0.7667\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.53135 to 0.52721, saving model to best.model\n",
      "0s - loss: 0.5500 - acc: 0.7333 - val_loss: 0.5272 - val_acc: 0.7500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5610 - acc: 0.7019 - val_loss: 0.5277 - val_acc: 0.7500\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5564 - acc: 0.7333 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5471 - acc: 0.7241 - val_loss: 0.5294 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5537 - acc: 0.7259 - val_loss: 0.5298 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5363 - acc: 0.7500 - val_loss: 0.5282 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5404 - acc: 0.7370 - val_loss: 0.5278 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5585 - acc: 0.7222 - val_loss: 0.5296 - val_acc: 0.7167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5436 - acc: 0.7111 - val_loss: 0.5306 - val_acc: 0.7000\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5175 - acc: 0.7463 - val_loss: 0.5310 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5327 - acc: 0.7259 - val_loss: 0.5316 - val_acc: 0.7000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5478 - acc: 0.7352 - val_loss: 0.5322 - val_acc: 0.7000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5283 - acc: 0.7463 - val_loss: 0.5327 - val_acc: 0.7000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5468 - acc: 0.7148 - val_loss: 0.5321 - val_acc: 0.7000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.52721 to 0.52183, saving model to best.model\n",
      "0s - loss: 0.5214 - acc: 0.7315 - val_loss: 0.5218 - val_acc: 0.7167\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.52183 to 0.51144, saving model to best.model\n",
      "0s - loss: 0.5315 - acc: 0.7370 - val_loss: 0.5114 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.51144 to 0.50742, saving model to best.model\n",
      "0s - loss: 0.5333 - acc: 0.7519 - val_loss: 0.5074 - val_acc: 0.7333\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5549 - acc: 0.7370 - val_loss: 0.5080 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5176 - acc: 0.7426 - val_loss: 0.5138 - val_acc: 0.7000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5310 - acc: 0.7537 - val_loss: 0.5198 - val_acc: 0.7167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5325 - acc: 0.7463 - val_loss: 0.5256 - val_acc: 0.7000\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5371 - acc: 0.7593 - val_loss: 0.5308 - val_acc: 0.6833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5062 - acc: 0.7407 - val_loss: 0.5274 - val_acc: 0.7000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5014 - acc: 0.7481 - val_loss: 0.5206 - val_acc: 0.7000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5301 - acc: 0.7500 - val_loss: 0.5139 - val_acc: 0.7333\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5066 - acc: 0.7537 - val_loss: 0.5093 - val_acc: 0.7167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.50742 to 0.50674, saving model to best.model\n",
      "0s - loss: 0.5036 - acc: 0.7556 - val_loss: 0.5067 - val_acc: 0.7167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5210 - acc: 0.7574 - val_loss: 0.5080 - val_acc: 0.7167\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.5029 - acc: 0.7778 - val_loss: 0.5131 - val_acc: 0.7167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5018 - acc: 0.7593 - val_loss: 0.5196 - val_acc: 0.7000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5180 - acc: 0.7500 - val_loss: 0.5215 - val_acc: 0.7000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4921 - acc: 0.7704 - val_loss: 0.5210 - val_acc: 0.7000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4813 - acc: 0.7833 - val_loss: 0.5159 - val_acc: 0.7000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4797 - acc: 0.7741 - val_loss: 0.5113 - val_acc: 0.7167\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.5139 - acc: 0.7704 - val_loss: 0.5088 - val_acc: 0.7167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4746 - acc: 0.7630 - val_loss: 0.5082 - val_acc: 0.7167\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.5043 - acc: 0.7667 - val_loss: 0.5103 - val_acc: 0.7167\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4946 - acc: 0.7611 - val_loss: 0.5106 - val_acc: 0.7167\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.5001 - acc: 0.7611 - val_loss: 0.5104 - val_acc: 0.7000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4941 - acc: 0.7667 - val_loss: 0.5092 - val_acc: 0.6833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.50674 to 0.50658, saving model to best.model\n",
      "0s - loss: 0.4944 - acc: 0.7648 - val_loss: 0.5066 - val_acc: 0.7333\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.50658 to 0.50268, saving model to best.model\n",
      "0s - loss: 0.4706 - acc: 0.7852 - val_loss: 0.5027 - val_acc: 0.7167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.50268 to 0.49892, saving model to best.model\n",
      "0s - loss: 0.4826 - acc: 0.7907 - val_loss: 0.4989 - val_acc: 0.7167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.49892 to 0.49439, saving model to best.model\n",
      "0s - loss: 0.4729 - acc: 0.7796 - val_loss: 0.4944 - val_acc: 0.7333\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.49439 to 0.49309, saving model to best.model\n",
      "0s - loss: 0.4725 - acc: 0.7815 - val_loss: 0.4931 - val_acc: 0.7333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.49309 to 0.49305, saving model to best.model\n",
      "0s - loss: 0.4672 - acc: 0.7796 - val_loss: 0.4931 - val_acc: 0.7167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4734 - acc: 0.7815 - val_loss: 0.4942 - val_acc: 0.7333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.49305 to 0.48876, saving model to best.model\n",
      "0s - loss: 0.4633 - acc: 0.7852 - val_loss: 0.4888 - val_acc: 0.7167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.48876 to 0.47969, saving model to best.model\n",
      "0s - loss: 0.4740 - acc: 0.7741 - val_loss: 0.4797 - val_acc: 0.7667\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.47969 to 0.47405, saving model to best.model\n",
      "0s - loss: 0.4914 - acc: 0.7944 - val_loss: 0.4741 - val_acc: 0.7167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.47405 to 0.47196, saving model to best.model\n",
      "0s - loss: 0.4769 - acc: 0.7889 - val_loss: 0.4720 - val_acc: 0.7167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4982 - acc: 0.7815 - val_loss: 0.4723 - val_acc: 0.7167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4672 - acc: 0.7796 - val_loss: 0.4754 - val_acc: 0.7167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4603 - acc: 0.7981 - val_loss: 0.4814 - val_acc: 0.7500\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4626 - acc: 0.7926 - val_loss: 0.4904 - val_acc: 0.7333\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4677 - acc: 0.7796 - val_loss: 0.4955 - val_acc: 0.7167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4515 - acc: 0.8000 - val_loss: 0.4963 - val_acc: 0.7167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4588 - acc: 0.7815 - val_loss: 0.4937 - val_acc: 0.7333\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4609 - acc: 0.8056 - val_loss: 0.4906 - val_acc: 0.7333\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4703 - acc: 0.8000 - val_loss: 0.4900 - val_acc: 0.7333\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4497 - acc: 0.8019 - val_loss: 0.4888 - val_acc: 0.7333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4856 - acc: 0.7870 - val_loss: 0.4880 - val_acc: 0.7333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4497 - acc: 0.7981 - val_loss: 0.4902 - val_acc: 0.7333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4625 - acc: 0.7741 - val_loss: 0.4928 - val_acc: 0.7167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4391 - acc: 0.8093 - val_loss: 0.4925 - val_acc: 0.7167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4534 - acc: 0.8000 - val_loss: 0.4860 - val_acc: 0.7167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4156 - acc: 0.8241 - val_loss: 0.4772 - val_acc: 0.7333\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4611 - acc: 0.7944 - val_loss: 0.4722 - val_acc: 0.7333\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.47196 to 0.46803, saving model to best.model\n",
      "0s - loss: 0.4393 - acc: 0.8074 - val_loss: 0.4680 - val_acc: 0.7333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.46803 to 0.46382, saving model to best.model\n",
      "0s - loss: 0.4288 - acc: 0.8037 - val_loss: 0.4638 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.46382 to 0.46212, saving model to best.model\n",
      "0s - loss: 0.4684 - acc: 0.7870 - val_loss: 0.4621 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4626 - acc: 0.8056 - val_loss: 0.4626 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4211 - acc: 0.8148 - val_loss: 0.4672 - val_acc: 0.7833\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4329 - acc: 0.8111 - val_loss: 0.4696 - val_acc: 0.7833\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4518 - acc: 0.8074 - val_loss: 0.4703 - val_acc: 0.7833\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4432 - acc: 0.8241 - val_loss: 0.4688 - val_acc: 0.7833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4447 - acc: 0.8241 - val_loss: 0.4651 - val_acc: 0.7833\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4227 - acc: 0.8241 - val_loss: 0.4625 - val_acc: 0.7833\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.46212 to 0.45917, saving model to best.model\n",
      "0s - loss: 0.4386 - acc: 0.8148 - val_loss: 0.4592 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.45917 to 0.45602, saving model to best.model\n",
      "0s - loss: 0.4276 - acc: 0.8056 - val_loss: 0.4560 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.45602 to 0.45314, saving model to best.model\n",
      "0s - loss: 0.4246 - acc: 0.8167 - val_loss: 0.4531 - val_acc: 0.7833\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.45314 to 0.45058, saving model to best.model\n",
      "0s - loss: 0.4385 - acc: 0.8278 - val_loss: 0.4506 - val_acc: 0.7833\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.45058 to 0.44962, saving model to best.model\n",
      "0s - loss: 0.4169 - acc: 0.8222 - val_loss: 0.4496 - val_acc: 0.7833\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.44962 to 0.44675, saving model to best.model\n",
      "0s - loss: 0.3959 - acc: 0.8222 - val_loss: 0.4468 - val_acc: 0.7833\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.44675 to 0.44551, saving model to best.model\n",
      "0s - loss: 0.3801 - acc: 0.8426 - val_loss: 0.4455 - val_acc: 0.8000\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.44551 to 0.44545, saving model to best.model\n",
      "0s - loss: 0.4165 - acc: 0.8278 - val_loss: 0.4454 - val_acc: 0.8000\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.44545 to 0.44265, saving model to best.model\n",
      "0s - loss: 0.4142 - acc: 0.8222 - val_loss: 0.4426 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.44265 to 0.43924, saving model to best.model\n",
      "0s - loss: 0.4161 - acc: 0.8315 - val_loss: 0.4392 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.43924 to 0.43687, saving model to best.model\n",
      "0s - loss: 0.3992 - acc: 0.8204 - val_loss: 0.4369 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.43687 to 0.43613, saving model to best.model\n",
      "0s - loss: 0.3993 - acc: 0.8352 - val_loss: 0.4361 - val_acc: 0.8000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.43613 to 0.43485, saving model to best.model\n",
      "0s - loss: 0.3816 - acc: 0.8389 - val_loss: 0.4349 - val_acc: 0.8333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.43485 to 0.43312, saving model to best.model\n",
      "0s - loss: 0.3726 - acc: 0.8611 - val_loss: 0.4331 - val_acc: 0.8500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.43312 to 0.42686, saving model to best.model\n",
      "0s - loss: 0.3892 - acc: 0.8278 - val_loss: 0.4269 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.42686 to 0.42152, saving model to best.model\n",
      "0s - loss: 0.3834 - acc: 0.8407 - val_loss: 0.4215 - val_acc: 0.8167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.42152 to 0.41914, saving model to best.model\n",
      "0s - loss: 0.4009 - acc: 0.8333 - val_loss: 0.4191 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.41914 to 0.41806, saving model to best.model\n",
      "0s - loss: 0.4024 - acc: 0.8426 - val_loss: 0.4181 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.41806 to 0.41685, saving model to best.model\n",
      "0s - loss: 0.3997 - acc: 0.8148 - val_loss: 0.4169 - val_acc: 0.8167\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.41685 to 0.41566, saving model to best.model\n",
      "0s - loss: 0.3763 - acc: 0.8296 - val_loss: 0.4157 - val_acc: 0.8167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.41566 to 0.41269, saving model to best.model\n",
      "0s - loss: 0.3897 - acc: 0.8444 - val_loss: 0.4127 - val_acc: 0.8167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.41269 to 0.41007, saving model to best.model\n",
      "0s - loss: 0.3699 - acc: 0.8556 - val_loss: 0.4101 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.41007 to 0.40727, saving model to best.model\n",
      "0s - loss: 0.3841 - acc: 0.8296 - val_loss: 0.4073 - val_acc: 0.8167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.40727 to 0.40535, saving model to best.model\n",
      "0s - loss: 0.3966 - acc: 0.8370 - val_loss: 0.4053 - val_acc: 0.8167\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3791 - acc: 0.8444 - val_loss: 0.4056 - val_acc: 0.8167\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.4014 - acc: 0.8222 - val_loss: 0.4091 - val_acc: 0.8500\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3845 - acc: 0.8352 - val_loss: 0.4123 - val_acc: 0.8667\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3508 - acc: 0.8556 - val_loss: 0.4133 - val_acc: 0.8500\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.40535 to 0.40380, saving model to best.model\n",
      "0s - loss: 0.3772 - acc: 0.8296 - val_loss: 0.4038 - val_acc: 0.8333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.40380 to 0.39530, saving model to best.model\n",
      "0s - loss: 0.3547 - acc: 0.8574 - val_loss: 0.3953 - val_acc: 0.8500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.39530 to 0.39404, saving model to best.model\n",
      "0s - loss: 0.3378 - acc: 0.8593 - val_loss: 0.3940 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3680 - acc: 0.8463 - val_loss: 0.3957 - val_acc: 0.8167\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3705 - acc: 0.8333 - val_loss: 0.3998 - val_acc: 0.8333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3603 - acc: 0.8407 - val_loss: 0.4069 - val_acc: 0.8333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3586 - acc: 0.8648 - val_loss: 0.4145 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3604 - acc: 0.8426 - val_loss: 0.4177 - val_acc: 0.8333\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3516 - acc: 0.8389 - val_loss: 0.4183 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3644 - acc: 0.8611 - val_loss: 0.4174 - val_acc: 0.8500\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3472 - acc: 0.8648 - val_loss: 0.4204 - val_acc: 0.8833\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3570 - acc: 0.8574 - val_loss: 0.4206 - val_acc: 0.8833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3538 - acc: 0.8463 - val_loss: 0.4146 - val_acc: 0.8833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3730 - acc: 0.8426 - val_loss: 0.4065 - val_acc: 0.8500\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3561 - acc: 0.8500 - val_loss: 0.4035 - val_acc: 0.8000\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3404 - acc: 0.8630 - val_loss: 0.4051 - val_acc: 0.8000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3556 - acc: 0.8278 - val_loss: 0.4061 - val_acc: 0.8333\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3097 - acc: 0.8704 - val_loss: 0.4114 - val_acc: 0.8500\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3222 - acc: 0.8741 - val_loss: 0.4180 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3276 - acc: 0.8593 - val_loss: 0.4131 - val_acc: 0.8500\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3306 - acc: 0.8537 - val_loss: 0.4046 - val_acc: 0.8500\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3197 - acc: 0.8574 - val_loss: 0.3989 - val_acc: 0.8167\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3398 - acc: 0.8537 - val_loss: 0.3998 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.2931 - acc: 0.8722 - val_loss: 0.4059 - val_acc: 0.8500\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3501 - acc: 0.8481 - val_loss: 0.4128 - val_acc: 0.8500\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3231 - acc: 0.8574 - val_loss: 0.4246 - val_acc: 0.8500\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3409 - acc: 0.8519 - val_loss: 0.4328 - val_acc: 0.8667\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3380 - acc: 0.8704 - val_loss: 0.4296 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3262 - acc: 0.8630 - val_loss: 0.4204 - val_acc: 0.8500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58089, saving model to best.model\n",
      "0s - loss: 0.8194 - acc: 0.5630 - val_loss: 0.5809 - val_acc: 0.7000\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7558 - acc: 0.6907 - val_loss: 0.5826 - val_acc: 0.7000\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.58089 to 0.56245, saving model to best.model\n",
      "0s - loss: 0.7092 - acc: 0.6852 - val_loss: 0.5625 - val_acc: 0.7000\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.56245 to 0.56057, saving model to best.model\n",
      "0s - loss: 0.6931 - acc: 0.6852 - val_loss: 0.5606 - val_acc: 0.7000\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6562 - acc: 0.6722 - val_loss: 0.5708 - val_acc: 0.7000\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6426 - acc: 0.6722 - val_loss: 0.5776 - val_acc: 0.7000\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6417 - acc: 0.6500 - val_loss: 0.5792 - val_acc: 0.7000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6331 - acc: 0.6463 - val_loss: 0.5741 - val_acc: 0.7000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6182 - acc: 0.6833 - val_loss: 0.5670 - val_acc: 0.7000\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6312 - acc: 0.6944 - val_loss: 0.5627 - val_acc: 0.7000\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.56057 to 0.56000, saving model to best.model\n",
      "0s - loss: 0.5772 - acc: 0.6926 - val_loss: 0.5600 - val_acc: 0.7000\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.56000 to 0.55878, saving model to best.model\n",
      "0s - loss: 0.5753 - acc: 0.7204 - val_loss: 0.5588 - val_acc: 0.7000\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6071 - acc: 0.7037 - val_loss: 0.5589 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6110 - acc: 0.7093 - val_loss: 0.5602 - val_acc: 0.7000\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5670 - acc: 0.7296 - val_loss: 0.5607 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6101 - acc: 0.6963 - val_loss: 0.5602 - val_acc: 0.7000\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.6125 - acc: 0.6907 - val_loss: 0.5613 - val_acc: 0.7000\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5762 - acc: 0.7185 - val_loss: 0.5623 - val_acc: 0.7000\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5730 - acc: 0.7019 - val_loss: 0.5628 - val_acc: 0.7000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5878 - acc: 0.7019 - val_loss: 0.5635 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5766 - acc: 0.6944 - val_loss: 0.5645 - val_acc: 0.7000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5696 - acc: 0.7148 - val_loss: 0.5650 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5677 - acc: 0.7056 - val_loss: 0.5640 - val_acc: 0.7000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5672 - acc: 0.7167 - val_loss: 0.5639 - val_acc: 0.7000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5620 - acc: 0.7111 - val_loss: 0.5666 - val_acc: 0.7000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5834 - acc: 0.7074 - val_loss: 0.5681 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5493 - acc: 0.7259 - val_loss: 0.5653 - val_acc: 0.7000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5745 - acc: 0.7056 - val_loss: 0.5614 - val_acc: 0.7000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.55878 to 0.55853, saving model to best.model\n",
      "0s - loss: 0.5621 - acc: 0.7056 - val_loss: 0.5585 - val_acc: 0.7000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.55853 to 0.55846, saving model to best.model\n",
      "0s - loss: 0.5752 - acc: 0.7185 - val_loss: 0.5585 - val_acc: 0.7000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.55846 to 0.55810, saving model to best.model\n",
      "0s - loss: 0.5524 - acc: 0.7296 - val_loss: 0.5581 - val_acc: 0.7167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.55810 to 0.55494, saving model to best.model\n",
      "0s - loss: 0.5576 - acc: 0.7278 - val_loss: 0.5549 - val_acc: 0.7000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.55494 to 0.55223, saving model to best.model\n",
      "0s - loss: 0.5579 - acc: 0.7111 - val_loss: 0.5522 - val_acc: 0.7000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.55223 to 0.54953, saving model to best.model\n",
      "0s - loss: 0.5433 - acc: 0.7296 - val_loss: 0.5495 - val_acc: 0.7000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.54953 to 0.54757, saving model to best.model\n",
      "0s - loss: 0.5586 - acc: 0.7204 - val_loss: 0.5476 - val_acc: 0.7167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.54757 to 0.54611, saving model to best.model\n",
      "0s - loss: 0.5270 - acc: 0.7444 - val_loss: 0.5461 - val_acc: 0.7167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.54611 to 0.54440, saving model to best.model\n",
      "0s - loss: 0.5423 - acc: 0.7370 - val_loss: 0.5444 - val_acc: 0.7167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.54440 to 0.54194, saving model to best.model\n",
      "0s - loss: 0.5342 - acc: 0.7241 - val_loss: 0.5419 - val_acc: 0.7667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.54194 to 0.53892, saving model to best.model\n",
      "0s - loss: 0.5375 - acc: 0.7296 - val_loss: 0.5389 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.53892 to 0.53694, saving model to best.model\n",
      "0s - loss: 0.5463 - acc: 0.7241 - val_loss: 0.5369 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.53694 to 0.53638, saving model to best.model\n",
      "0s - loss: 0.5455 - acc: 0.7333 - val_loss: 0.5364 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5482 - acc: 0.7241 - val_loss: 0.5387 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5418 - acc: 0.7278 - val_loss: 0.5396 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5214 - acc: 0.7426 - val_loss: 0.5381 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5276 - acc: 0.7315 - val_loss: 0.5371 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5327 - acc: 0.7241 - val_loss: 0.5368 - val_acc: 0.7667\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.53638 to 0.53480, saving model to best.model\n",
      "0s - loss: 0.5223 - acc: 0.7278 - val_loss: 0.5348 - val_acc: 0.7667\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.53480 to 0.53230, saving model to best.model\n",
      "0s - loss: 0.5430 - acc: 0.7370 - val_loss: 0.5323 - val_acc: 0.7667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.53230 to 0.53092, saving model to best.model\n",
      "0s - loss: 0.5580 - acc: 0.7370 - val_loss: 0.5309 - val_acc: 0.7833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.53092 to 0.53020, saving model to best.model\n",
      "0s - loss: 0.5309 - acc: 0.7537 - val_loss: 0.5302 - val_acc: 0.7833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.53020 to 0.52880, saving model to best.model\n",
      "0s - loss: 0.5209 - acc: 0.7370 - val_loss: 0.5288 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.52880 to 0.52693, saving model to best.model\n",
      "0s - loss: 0.5327 - acc: 0.7370 - val_loss: 0.5269 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.52693 to 0.52590, saving model to best.model\n",
      "0s - loss: 0.5448 - acc: 0.7278 - val_loss: 0.5259 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.52590 to 0.52444, saving model to best.model\n",
      "0s - loss: 0.5208 - acc: 0.7370 - val_loss: 0.5244 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.52444 to 0.52256, saving model to best.model\n",
      "0s - loss: 0.5215 - acc: 0.7556 - val_loss: 0.5226 - val_acc: 0.7833\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.52256 to 0.52036, saving model to best.model\n",
      "0s - loss: 0.5066 - acc: 0.7593 - val_loss: 0.5204 - val_acc: 0.7833\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.52036 to 0.51916, saving model to best.model\n",
      "0s - loss: 0.5113 - acc: 0.7444 - val_loss: 0.5192 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.51916 to 0.51841, saving model to best.model\n",
      "0s - loss: 0.5180 - acc: 0.7630 - val_loss: 0.5184 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5438 - acc: 0.7463 - val_loss: 0.5187 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.5268 - acc: 0.7519 - val_loss: 0.5191 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.5134 - acc: 0.7389 - val_loss: 0.5201 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4997 - acc: 0.7481 - val_loss: 0.5191 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.5279 - acc: 0.7259 - val_loss: 0.5195 - val_acc: 0.7667\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.5301 - acc: 0.7444 - val_loss: 0.5217 - val_acc: 0.7667\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.5193 - acc: 0.7611 - val_loss: 0.5238 - val_acc: 0.7667\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4962 - acc: 0.7389 - val_loss: 0.5251 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.5153 - acc: 0.7611 - val_loss: 0.5255 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.5164 - acc: 0.7463 - val_loss: 0.5273 - val_acc: 0.7667\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.5219 - acc: 0.7407 - val_loss: 0.5288 - val_acc: 0.7667\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.5296 - acc: 0.7389 - val_loss: 0.5285 - val_acc: 0.7667\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4908 - acc: 0.7722 - val_loss: 0.5279 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4954 - acc: 0.7500 - val_loss: 0.5264 - val_acc: 0.7667\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4772 - acc: 0.7648 - val_loss: 0.5235 - val_acc: 0.7667\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.5060 - acc: 0.7630 - val_loss: 0.5219 - val_acc: 0.7667\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.5001 - acc: 0.7667 - val_loss: 0.5217 - val_acc: 0.7667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4947 - acc: 0.7648 - val_loss: 0.5213 - val_acc: 0.7667\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4853 - acc: 0.7759 - val_loss: 0.5222 - val_acc: 0.7667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.5063 - acc: 0.7574 - val_loss: 0.5258 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.5049 - acc: 0.7704 - val_loss: 0.5313 - val_acc: 0.7667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4968 - acc: 0.7611 - val_loss: 0.5322 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.5018 - acc: 0.7463 - val_loss: 0.5306 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.5020 - acc: 0.7778 - val_loss: 0.5272 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4894 - acc: 0.7722 - val_loss: 0.5234 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4822 - acc: 0.7796 - val_loss: 0.5207 - val_acc: 0.7667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.57249, saving model to best.model\n",
      "0s - loss: 1.1391 - acc: 0.4037 - val_loss: 0.5725 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.57249 to 0.55910, saving model to best.model\n",
      "0s - loss: 0.7337 - acc: 0.6241 - val_loss: 0.5591 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.55910 to 0.55789, saving model to best.model\n",
      "0s - loss: 0.7203 - acc: 0.6981 - val_loss: 0.5579 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.55789 to 0.53900, saving model to best.model\n",
      "0s - loss: 0.7228 - acc: 0.7259 - val_loss: 0.5390 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.53900 to 0.52028, saving model to best.model\n",
      "0s - loss: 0.7121 - acc: 0.7241 - val_loss: 0.5203 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.52028 to 0.51476, saving model to best.model\n",
      "0s - loss: 0.6327 - acc: 0.7204 - val_loss: 0.5148 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6129 - acc: 0.7056 - val_loss: 0.5197 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5744 - acc: 0.7093 - val_loss: 0.5263 - val_acc: 0.7833\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5754 - acc: 0.7315 - val_loss: 0.5272 - val_acc: 0.7833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5423 - acc: 0.7259 - val_loss: 0.5225 - val_acc: 0.8000\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.51476 to 0.51155, saving model to best.model\n",
      "0s - loss: 0.5442 - acc: 0.7333 - val_loss: 0.5115 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.51155 to 0.49960, saving model to best.model\n",
      "0s - loss: 0.5468 - acc: 0.7389 - val_loss: 0.4996 - val_acc: 0.7667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.49960 to 0.49126, saving model to best.model\n",
      "0s - loss: 0.4970 - acc: 0.7519 - val_loss: 0.4913 - val_acc: 0.7667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.49126 to 0.48549, saving model to best.model\n",
      "0s - loss: 0.5277 - acc: 0.7296 - val_loss: 0.4855 - val_acc: 0.7667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.48549 to 0.48526, saving model to best.model\n",
      "0s - loss: 0.5393 - acc: 0.7481 - val_loss: 0.4853 - val_acc: 0.7667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5088 - acc: 0.7444 - val_loss: 0.4859 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5188 - acc: 0.7389 - val_loss: 0.4854 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.48526 to 0.48220, saving model to best.model\n",
      "0s - loss: 0.4991 - acc: 0.7556 - val_loss: 0.4822 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.48220 to 0.47920, saving model to best.model\n",
      "0s - loss: 0.5085 - acc: 0.7444 - val_loss: 0.4792 - val_acc: 0.7167\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.47920 to 0.47492, saving model to best.model\n",
      "0s - loss: 0.5104 - acc: 0.7370 - val_loss: 0.4749 - val_acc: 0.7167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.47492 to 0.47208, saving model to best.model\n",
      "0s - loss: 0.5121 - acc: 0.7611 - val_loss: 0.4721 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.47208 to 0.47034, saving model to best.model\n",
      "0s - loss: 0.4865 - acc: 0.7593 - val_loss: 0.4703 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.47034 to 0.46947, saving model to best.model\n",
      "0s - loss: 0.5243 - acc: 0.7500 - val_loss: 0.4695 - val_acc: 0.7333\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5287 - acc: 0.7500 - val_loss: 0.4709 - val_acc: 0.7333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5124 - acc: 0.7481 - val_loss: 0.4738 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.7833 - val_loss: 0.4770 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.4657 - acc: 0.7778 - val_loss: 0.4786 - val_acc: 0.7500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.4835 - acc: 0.7611 - val_loss: 0.4773 - val_acc: 0.7500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.4554 - acc: 0.8000 - val_loss: 0.4747 - val_acc: 0.7500\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.4818 - acc: 0.7833 - val_loss: 0.4723 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.46947 to 0.46863, saving model to best.model\n",
      "0s - loss: 0.4661 - acc: 0.7685 - val_loss: 0.4686 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.46863 to 0.46570, saving model to best.model\n",
      "0s - loss: 0.4805 - acc: 0.7796 - val_loss: 0.4657 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.46570 to 0.46405, saving model to best.model\n",
      "0s - loss: 0.4720 - acc: 0.7889 - val_loss: 0.4641 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.46405 to 0.46300, saving model to best.model\n",
      "0s - loss: 0.4651 - acc: 0.7796 - val_loss: 0.4630 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.4525 - acc: 0.7870 - val_loss: 0.4636 - val_acc: 0.7500\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.4457 - acc: 0.7926 - val_loss: 0.4671 - val_acc: 0.7500\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.4349 - acc: 0.7907 - val_loss: 0.4670 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.4682 - acc: 0.7907 - val_loss: 0.4649 - val_acc: 0.7333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.4561 - acc: 0.7963 - val_loss: 0.4641 - val_acc: 0.7500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.4347 - acc: 0.7926 - val_loss: 0.4631 - val_acc: 0.7500\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.46300 to 0.46138, saving model to best.model\n",
      "0s - loss: 0.4480 - acc: 0.7870 - val_loss: 0.4614 - val_acc: 0.7500\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.46138 to 0.45911, saving model to best.model\n",
      "0s - loss: 0.4479 - acc: 0.8000 - val_loss: 0.4591 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.45911 to 0.45750, saving model to best.model\n",
      "0s - loss: 0.4514 - acc: 0.7889 - val_loss: 0.4575 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.45750 to 0.45619, saving model to best.model\n",
      "0s - loss: 0.4489 - acc: 0.7963 - val_loss: 0.4562 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4367 - acc: 0.8093 - val_loss: 0.4574 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4352 - acc: 0.7963 - val_loss: 0.4600 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4336 - acc: 0.7963 - val_loss: 0.4626 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4177 - acc: 0.8019 - val_loss: 0.4633 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4489 - acc: 0.8000 - val_loss: 0.4616 - val_acc: 0.7500\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4278 - acc: 0.8148 - val_loss: 0.4593 - val_acc: 0.7500\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4190 - acc: 0.7981 - val_loss: 0.4588 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4206 - acc: 0.7981 - val_loss: 0.4590 - val_acc: 0.7500\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4117 - acc: 0.8074 - val_loss: 0.4592 - val_acc: 0.7500\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4362 - acc: 0.8000 - val_loss: 0.4585 - val_acc: 0.7500\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4085 - acc: 0.7926 - val_loss: 0.4583 - val_acc: 0.7333\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4221 - acc: 0.8074 - val_loss: 0.4604 - val_acc: 0.7333\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4348 - acc: 0.8019 - val_loss: 0.4629 - val_acc: 0.7333\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4242 - acc: 0.8019 - val_loss: 0.4659 - val_acc: 0.7333\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4186 - acc: 0.8000 - val_loss: 0.4673 - val_acc: 0.7333\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4179 - acc: 0.8056 - val_loss: 0.4672 - val_acc: 0.7333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4100 - acc: 0.7815 - val_loss: 0.4659 - val_acc: 0.7500\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4140 - acc: 0.8167 - val_loss: 0.4648 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4292 - acc: 0.8019 - val_loss: 0.4646 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4086 - acc: 0.8167 - val_loss: 0.4642 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4042 - acc: 0.8148 - val_loss: 0.4642 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4078 - acc: 0.8111 - val_loss: 0.4641 - val_acc: 0.7500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4126 - acc: 0.8167 - val_loss: 0.4638 - val_acc: 0.7500\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4204 - acc: 0.7870 - val_loss: 0.4630 - val_acc: 0.7333\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4008 - acc: 0.7944 - val_loss: 0.4614 - val_acc: 0.7333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4089 - acc: 0.8093 - val_loss: 0.4601 - val_acc: 0.7333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58484, saving model to best.model\n",
      "0s - loss: 0.7543 - acc: 0.5870 - val_loss: 0.5848 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.6626 - acc: 0.6870 - val_loss: 0.5878 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.58484 to 0.58052, saving model to best.model\n",
      "0s - loss: 0.6989 - acc: 0.6685 - val_loss: 0.5805 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58052 to 0.57562, saving model to best.model\n",
      "0s - loss: 0.6695 - acc: 0.6519 - val_loss: 0.5756 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.57562 to 0.57144, saving model to best.model\n",
      "0s - loss: 0.6360 - acc: 0.6741 - val_loss: 0.5714 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.57144 to 0.56917, saving model to best.model\n",
      "0s - loss: 0.6541 - acc: 0.6556 - val_loss: 0.5692 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.56917 to 0.56834, saving model to best.model\n",
      "0s - loss: 0.6248 - acc: 0.6722 - val_loss: 0.5683 - val_acc: 0.7167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.56834 to 0.56636, saving model to best.model\n",
      "0s - loss: 0.6303 - acc: 0.6667 - val_loss: 0.5664 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.56636 to 0.56273, saving model to best.model\n",
      "0s - loss: 0.6138 - acc: 0.6889 - val_loss: 0.5627 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.56273 to 0.55871, saving model to best.model\n",
      "0s - loss: 0.6067 - acc: 0.6926 - val_loss: 0.5587 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.55871 to 0.55359, saving model to best.model\n",
      "0s - loss: 0.5864 - acc: 0.6981 - val_loss: 0.5536 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.55359 to 0.55125, saving model to best.model\n",
      "0s - loss: 0.6099 - acc: 0.7037 - val_loss: 0.5513 - val_acc: 0.7500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.55125 to 0.55008, saving model to best.model\n",
      "0s - loss: 0.5794 - acc: 0.7019 - val_loss: 0.5501 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.55008 to 0.54842, saving model to best.model\n",
      "0s - loss: 0.5737 - acc: 0.7185 - val_loss: 0.5484 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.54842 to 0.54617, saving model to best.model\n",
      "0s - loss: 0.5617 - acc: 0.7278 - val_loss: 0.5462 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.54617 to 0.54423, saving model to best.model\n",
      "0s - loss: 0.5482 - acc: 0.7148 - val_loss: 0.5442 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.54423 to 0.54255, saving model to best.model\n",
      "0s - loss: 0.5457 - acc: 0.7407 - val_loss: 0.5426 - val_acc: 0.7167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.54255 to 0.54142, saving model to best.model\n",
      "0s - loss: 0.5341 - acc: 0.7370 - val_loss: 0.5414 - val_acc: 0.7167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.54142 to 0.53945, saving model to best.model\n",
      "0s - loss: 0.5420 - acc: 0.7111 - val_loss: 0.5394 - val_acc: 0.7167\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.53945 to 0.53692, saving model to best.model\n",
      "0s - loss: 0.5430 - acc: 0.7333 - val_loss: 0.5369 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.53692 to 0.53560, saving model to best.model\n",
      "0s - loss: 0.5592 - acc: 0.7204 - val_loss: 0.5356 - val_acc: 0.6833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.53560 to 0.53494, saving model to best.model\n",
      "0s - loss: 0.5271 - acc: 0.7333 - val_loss: 0.5349 - val_acc: 0.6833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5268 - acc: 0.7296 - val_loss: 0.5355 - val_acc: 0.6667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5566 - acc: 0.7352 - val_loss: 0.5362 - val_acc: 0.7000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5100 - acc: 0.7537 - val_loss: 0.5367 - val_acc: 0.7333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.53494 to 0.53327, saving model to best.model\n",
      "0s - loss: 0.5333 - acc: 0.7463 - val_loss: 0.5333 - val_acc: 0.7000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.53327 to 0.53079, saving model to best.model\n",
      "0s - loss: 0.5370 - acc: 0.7111 - val_loss: 0.5308 - val_acc: 0.7000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.53079 to 0.52953, saving model to best.model\n",
      "0s - loss: 0.5153 - acc: 0.7389 - val_loss: 0.5295 - val_acc: 0.7000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5339 - acc: 0.7481 - val_loss: 0.5310 - val_acc: 0.7000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5055 - acc: 0.7537 - val_loss: 0.5299 - val_acc: 0.7000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.52953 to 0.52674, saving model to best.model\n",
      "0s - loss: 0.5091 - acc: 0.7407 - val_loss: 0.5267 - val_acc: 0.7167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.52674 to 0.52307, saving model to best.model\n",
      "0s - loss: 0.5115 - acc: 0.7685 - val_loss: 0.5231 - val_acc: 0.7167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.52307 to 0.52115, saving model to best.model\n",
      "0s - loss: 0.4992 - acc: 0.7426 - val_loss: 0.5212 - val_acc: 0.7000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.52115 to 0.51992, saving model to best.model\n",
      "0s - loss: 0.4946 - acc: 0.7667 - val_loss: 0.5199 - val_acc: 0.7000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.51992 to 0.51825, saving model to best.model\n",
      "0s - loss: 0.5054 - acc: 0.7500 - val_loss: 0.5182 - val_acc: 0.7000\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.51825 to 0.51697, saving model to best.model\n",
      "0s - loss: 0.5050 - acc: 0.7741 - val_loss: 0.5170 - val_acc: 0.7167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.51697 to 0.51620, saving model to best.model\n",
      "0s - loss: 0.5001 - acc: 0.7722 - val_loss: 0.5162 - val_acc: 0.7167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.51620 to 0.51607, saving model to best.model\n",
      "0s - loss: 0.4966 - acc: 0.7648 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.4899 - acc: 0.7759 - val_loss: 0.5165 - val_acc: 0.7333\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.4734 - acc: 0.7796 - val_loss: 0.5161 - val_acc: 0.7333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.51607 to 0.51566, saving model to best.model\n",
      "0s - loss: 0.4912 - acc: 0.7630 - val_loss: 0.5157 - val_acc: 0.7000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4841 - acc: 0.7537 - val_loss: 0.5159 - val_acc: 0.7000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.51566 to 0.51531, saving model to best.model\n",
      "0s - loss: 0.4888 - acc: 0.7481 - val_loss: 0.5153 - val_acc: 0.7000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.51531 to 0.51326, saving model to best.model\n",
      "0s - loss: 0.4751 - acc: 0.7685 - val_loss: 0.5133 - val_acc: 0.7167\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.51326 to 0.51182, saving model to best.model\n",
      "0s - loss: 0.5090 - acc: 0.7778 - val_loss: 0.5118 - val_acc: 0.7167\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.51182 to 0.51098, saving model to best.model\n",
      "0s - loss: 0.4594 - acc: 0.7796 - val_loss: 0.5110 - val_acc: 0.7167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.51098 to 0.50951, saving model to best.model\n",
      "0s - loss: 0.4934 - acc: 0.7611 - val_loss: 0.5095 - val_acc: 0.7167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.50951 to 0.50815, saving model to best.model\n",
      "0s - loss: 0.4778 - acc: 0.7704 - val_loss: 0.5081 - val_acc: 0.7000\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.50815 to 0.50795, saving model to best.model\n",
      "0s - loss: 0.4525 - acc: 0.7833 - val_loss: 0.5079 - val_acc: 0.7000\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.50795 to 0.50778, saving model to best.model\n",
      "0s - loss: 0.4805 - acc: 0.7667 - val_loss: 0.5078 - val_acc: 0.7000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.50778 to 0.50696, saving model to best.model\n",
      "0s - loss: 0.4832 - acc: 0.7667 - val_loss: 0.5070 - val_acc: 0.7000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4500 - acc: 0.7852 - val_loss: 0.5071 - val_acc: 0.7000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.50696 to 0.50627, saving model to best.model\n",
      "0s - loss: 0.4558 - acc: 0.7870 - val_loss: 0.5063 - val_acc: 0.7000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.50627 to 0.50584, saving model to best.model\n",
      "0s - loss: 0.4636 - acc: 0.7833 - val_loss: 0.5058 - val_acc: 0.7000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4515 - acc: 0.7907 - val_loss: 0.5059 - val_acc: 0.7000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.50584 to 0.50568, saving model to best.model\n",
      "0s - loss: 0.4711 - acc: 0.7944 - val_loss: 0.5057 - val_acc: 0.7000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4299 - acc: 0.7981 - val_loss: 0.5059 - val_acc: 0.7000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4418 - acc: 0.7870 - val_loss: 0.5064 - val_acc: 0.7000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4256 - acc: 0.8000 - val_loss: 0.5068 - val_acc: 0.7000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4612 - acc: 0.7833 - val_loss: 0.5066 - val_acc: 0.7000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4351 - acc: 0.8167 - val_loss: 0.5067 - val_acc: 0.7000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4692 - acc: 0.8074 - val_loss: 0.5060 - val_acc: 0.7000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.50568 to 0.50352, saving model to best.model\n",
      "0s - loss: 0.4890 - acc: 0.7778 - val_loss: 0.5035 - val_acc: 0.7000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.50352 to 0.50093, saving model to best.model\n",
      "0s - loss: 0.4340 - acc: 0.7833 - val_loss: 0.5009 - val_acc: 0.7167\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.50093 to 0.49936, saving model to best.model\n",
      "0s - loss: 0.4423 - acc: 0.8130 - val_loss: 0.4994 - val_acc: 0.7167\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4357 - acc: 0.8093 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4248 - acc: 0.8056 - val_loss: 0.5000 - val_acc: 0.7500\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.49936 to 0.49624, saving model to best.model\n",
      "0s - loss: 0.4326 - acc: 0.7889 - val_loss: 0.4962 - val_acc: 0.7500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.49624 to 0.49144, saving model to best.model\n",
      "0s - loss: 0.4286 - acc: 0.7963 - val_loss: 0.4914 - val_acc: 0.7167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.49144 to 0.48883, saving model to best.model\n",
      "0s - loss: 0.4344 - acc: 0.8148 - val_loss: 0.4888 - val_acc: 0.7000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.48883 to 0.48707, saving model to best.model\n",
      "0s - loss: 0.4335 - acc: 0.8074 - val_loss: 0.4871 - val_acc: 0.7167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.48707 to 0.48702, saving model to best.model\n",
      "0s - loss: 0.4112 - acc: 0.8222 - val_loss: 0.4870 - val_acc: 0.7500\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4157 - acc: 0.8019 - val_loss: 0.4883 - val_acc: 0.7667\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4081 - acc: 0.8111 - val_loss: 0.4883 - val_acc: 0.7667\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4427 - acc: 0.7852 - val_loss: 0.4875 - val_acc: 0.7667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.48702 to 0.48671, saving model to best.model\n",
      "0s - loss: 0.4107 - acc: 0.8167 - val_loss: 0.4867 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.48671 to 0.48590, saving model to best.model\n",
      "0s - loss: 0.4176 - acc: 0.8074 - val_loss: 0.4859 - val_acc: 0.7667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.48590 to 0.48559, saving model to best.model\n",
      "0s - loss: 0.4071 - acc: 0.8093 - val_loss: 0.4856 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4063 - acc: 0.8037 - val_loss: 0.4864 - val_acc: 0.7667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4188 - acc: 0.8056 - val_loss: 0.4866 - val_acc: 0.7667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4070 - acc: 0.8056 - val_loss: 0.4872 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.48559 to 0.48407, saving model to best.model\n",
      "0s - loss: 0.4181 - acc: 0.7889 - val_loss: 0.4841 - val_acc: 0.7667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.48407 to 0.48051, saving model to best.model\n",
      "0s - loss: 0.4010 - acc: 0.8037 - val_loss: 0.4805 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.48051 to 0.47897, saving model to best.model\n",
      "0s - loss: 0.3852 - acc: 0.8241 - val_loss: 0.4790 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.3828 - acc: 0.8148 - val_loss: 0.4801 - val_acc: 0.7667\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.47897 to 0.47778, saving model to best.model\n",
      "0s - loss: 0.4091 - acc: 0.8111 - val_loss: 0.4778 - val_acc: 0.7667\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.47778 to 0.47407, saving model to best.model\n",
      "0s - loss: 0.3696 - acc: 0.8296 - val_loss: 0.4741 - val_acc: 0.7833\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.47407 to 0.47117, saving model to best.model\n",
      "0s - loss: 0.3732 - acc: 0.8389 - val_loss: 0.4712 - val_acc: 0.8000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.47117 to 0.46881, saving model to best.model\n",
      "0s - loss: 0.4268 - acc: 0.8074 - val_loss: 0.4688 - val_acc: 0.8000\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.46881 to 0.46770, saving model to best.model\n",
      "0s - loss: 0.3734 - acc: 0.8241 - val_loss: 0.4677 - val_acc: 0.8000\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.46770 to 0.46746, saving model to best.model\n",
      "0s - loss: 0.3815 - acc: 0.8407 - val_loss: 0.4675 - val_acc: 0.8000\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.46746 to 0.46581, saving model to best.model\n",
      "0s - loss: 0.3971 - acc: 0.8389 - val_loss: 0.4658 - val_acc: 0.8000\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.46581 to 0.46386, saving model to best.model\n",
      "0s - loss: 0.3815 - acc: 0.8333 - val_loss: 0.4639 - val_acc: 0.8000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.46386 to 0.46272, saving model to best.model\n",
      "0s - loss: 0.3982 - acc: 0.8352 - val_loss: 0.4627 - val_acc: 0.8000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4019 - acc: 0.8185 - val_loss: 0.4632 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3839 - acc: 0.8333 - val_loss: 0.4647 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3625 - acc: 0.8519 - val_loss: 0.4656 - val_acc: 0.8000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4110 - acc: 0.8111 - val_loss: 0.4662 - val_acc: 0.8000\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3622 - acc: 0.8241 - val_loss: 0.4668 - val_acc: 0.8000\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3696 - acc: 0.8241 - val_loss: 0.4661 - val_acc: 0.8000\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3690 - acc: 0.8389 - val_loss: 0.4664 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3717 - acc: 0.8278 - val_loss: 0.4659 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3615 - acc: 0.8648 - val_loss: 0.4644 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3861 - acc: 0.8241 - val_loss: 0.4638 - val_acc: 0.8000\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3539 - acc: 0.8611 - val_loss: 0.4648 - val_acc: 0.8000\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3639 - acc: 0.8352 - val_loss: 0.4642 - val_acc: 0.8000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.46272 to 0.46226, saving model to best.model\n",
      "0s - loss: 0.3447 - acc: 0.8389 - val_loss: 0.4623 - val_acc: 0.8000\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.46226 to 0.45985, saving model to best.model\n",
      "0s - loss: 0.3391 - acc: 0.8593 - val_loss: 0.4599 - val_acc: 0.8000\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.45985 to 0.45815, saving model to best.model\n",
      "0s - loss: 0.3477 - acc: 0.8370 - val_loss: 0.4582 - val_acc: 0.8000\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.45815 to 0.45558, saving model to best.model\n",
      "0s - loss: 0.3485 - acc: 0.8370 - val_loss: 0.4556 - val_acc: 0.8000\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.45558 to 0.45370, saving model to best.model\n",
      "0s - loss: 0.3408 - acc: 0.8333 - val_loss: 0.4537 - val_acc: 0.8000\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.45370 to 0.45312, saving model to best.model\n",
      "0s - loss: 0.3465 - acc: 0.8389 - val_loss: 0.4531 - val_acc: 0.8000\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.45312 to 0.45192, saving model to best.model\n",
      "0s - loss: 0.3556 - acc: 0.8537 - val_loss: 0.4519 - val_acc: 0.8000\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.45192 to 0.44949, saving model to best.model\n",
      "0s - loss: 0.3111 - acc: 0.8556 - val_loss: 0.4495 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.44949 to 0.44716, saving model to best.model\n",
      "0s - loss: 0.3613 - acc: 0.8426 - val_loss: 0.4472 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.44716 to 0.44318, saving model to best.model\n",
      "0s - loss: 0.3302 - acc: 0.8537 - val_loss: 0.4432 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.44318 to 0.44134, saving model to best.model\n",
      "0s - loss: 0.3341 - acc: 0.8556 - val_loss: 0.4413 - val_acc: 0.8000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3238 - acc: 0.8611 - val_loss: 0.4429 - val_acc: 0.8000\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3159 - acc: 0.8481 - val_loss: 0.4442 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3497 - acc: 0.8407 - val_loss: 0.4446 - val_acc: 0.8167\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3148 - acc: 0.8630 - val_loss: 0.4483 - val_acc: 0.8167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3377 - acc: 0.8611 - val_loss: 0.4535 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3238 - acc: 0.8722 - val_loss: 0.4546 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3155 - acc: 0.8481 - val_loss: 0.4527 - val_acc: 0.8167\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3201 - acc: 0.8519 - val_loss: 0.4523 - val_acc: 0.8167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3392 - acc: 0.8389 - val_loss: 0.4528 - val_acc: 0.7833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3304 - acc: 0.8481 - val_loss: 0.4543 - val_acc: 0.7833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3140 - acc: 0.8556 - val_loss: 0.4544 - val_acc: 0.7833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3044 - acc: 0.8796 - val_loss: 0.4552 - val_acc: 0.8167\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3032 - acc: 0.8685 - val_loss: 0.4586 - val_acc: 0.7833\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.2783 - acc: 0.8870 - val_loss: 0.4682 - val_acc: 0.8167\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3018 - acc: 0.8667 - val_loss: 0.4802 - val_acc: 0.8167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3065 - acc: 0.8741 - val_loss: 0.4854 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3486 - acc: 0.8537 - val_loss: 0.4792 - val_acc: 0.8167\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3223 - acc: 0.8759 - val_loss: 0.4654 - val_acc: 0.8167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3156 - acc: 0.8796 - val_loss: 0.4559 - val_acc: 0.8000\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.2717 - acc: 0.8815 - val_loss: 0.4525 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3290 - acc: 0.8704 - val_loss: 0.4463 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.44134 to 0.43931, saving model to best.model\n",
      "0s - loss: 0.3112 - acc: 0.8630 - val_loss: 0.4393 - val_acc: 0.8333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.43931 to 0.43609, saving model to best.model\n",
      "0s - loss: 0.3108 - acc: 0.8722 - val_loss: 0.4361 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.2980 - acc: 0.8833 - val_loss: 0.4379 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.2928 - acc: 0.8611 - val_loss: 0.4418 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.2992 - acc: 0.8981 - val_loss: 0.4453 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.2909 - acc: 0.8722 - val_loss: 0.4478 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.2668 - acc: 0.8944 - val_loss: 0.4512 - val_acc: 0.8667\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.2739 - acc: 0.8815 - val_loss: 0.4562 - val_acc: 0.8667\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.2878 - acc: 0.8833 - val_loss: 0.4620 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3128 - acc: 0.8556 - val_loss: 0.4646 - val_acc: 0.8667\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.2736 - acc: 0.8815 - val_loss: 0.4663 - val_acc: 0.8500\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.2975 - acc: 0.8593 - val_loss: 0.4644 - val_acc: 0.8500\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.2772 - acc: 0.8759 - val_loss: 0.4640 - val_acc: 0.8333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.2837 - acc: 0.8704 - val_loss: 0.4634 - val_acc: 0.8333\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.2822 - acc: 0.8815 - val_loss: 0.4609 - val_acc: 0.8333\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.2944 - acc: 0.8759 - val_loss: 0.4559 - val_acc: 0.8167\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3010 - acc: 0.8667 - val_loss: 0.4517 - val_acc: 0.8333\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2882 - acc: 0.8722 - val_loss: 0.4507 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.2740 - acc: 0.8796 - val_loss: 0.4540 - val_acc: 0.8667\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.2688 - acc: 0.8907 - val_loss: 0.4582 - val_acc: 0.8667\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3073 - acc: 0.8704 - val_loss: 0.4561 - val_acc: 0.8667\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2467 - acc: 0.9019 - val_loss: 0.4546 - val_acc: 0.8500\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2971 - acc: 0.8796 - val_loss: 0.4540 - val_acc: 0.8333\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2353 - acc: 0.8981 - val_loss: 0.4573 - val_acc: 0.8167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2399 - acc: 0.9074 - val_loss: 0.4641 - val_acc: 0.8167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2550 - acc: 0.8981 - val_loss: 0.4710 - val_acc: 0.8167\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2994 - acc: 0.8704 - val_loss: 0.4773 - val_acc: 0.8333\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2460 - acc: 0.8981 - val_loss: 0.4855 - val_acc: 0.8333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.56256, saving model to best.model\n",
      "0s - loss: 0.8594 - acc: 0.6500 - val_loss: 0.5626 - val_acc: 0.7833\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.56256 to 0.55804, saving model to best.model\n",
      "0s - loss: 0.7721 - acc: 0.6019 - val_loss: 0.5580 - val_acc: 0.7833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.55804 to 0.53914, saving model to best.model\n",
      "0s - loss: 0.7431 - acc: 0.6389 - val_loss: 0.5391 - val_acc: 0.7667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.53914 to 0.51944, saving model to best.model\n",
      "0s - loss: 0.6533 - acc: 0.6537 - val_loss: 0.5194 - val_acc: 0.7833\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.51944 to 0.50397, saving model to best.model\n",
      "0s - loss: 0.6598 - acc: 0.6648 - val_loss: 0.5040 - val_acc: 0.7833\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.50397 to 0.50277, saving model to best.model\n",
      "0s - loss: 0.6770 - acc: 0.6722 - val_loss: 0.5028 - val_acc: 0.7833\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5841 - acc: 0.6907 - val_loss: 0.5035 - val_acc: 0.7833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6136 - acc: 0.6796 - val_loss: 0.5029 - val_acc: 0.7833\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.50277 to 0.50053, saving model to best.model\n",
      "0s - loss: 0.6073 - acc: 0.6833 - val_loss: 0.5005 - val_acc: 0.7833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.50053 to 0.49769, saving model to best.model\n",
      "0s - loss: 0.5817 - acc: 0.6963 - val_loss: 0.4977 - val_acc: 0.7833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.49769 to 0.49607, saving model to best.model\n",
      "0s - loss: 0.6129 - acc: 0.6907 - val_loss: 0.4961 - val_acc: 0.7833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.49607 to 0.49327, saving model to best.model\n",
      "0s - loss: 0.5918 - acc: 0.7093 - val_loss: 0.4933 - val_acc: 0.7833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.49327 to 0.49177, saving model to best.model\n",
      "0s - loss: 0.5716 - acc: 0.7185 - val_loss: 0.4918 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.49177 to 0.48721, saving model to best.model\n",
      "0s - loss: 0.5601 - acc: 0.6889 - val_loss: 0.4872 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.48721 to 0.47822, saving model to best.model\n",
      "0s - loss: 0.5424 - acc: 0.7407 - val_loss: 0.4782 - val_acc: 0.7833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.47822 to 0.46743, saving model to best.model\n",
      "0s - loss: 0.5464 - acc: 0.7148 - val_loss: 0.4674 - val_acc: 0.7833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.46743 to 0.45789, saving model to best.model\n",
      "0s - loss: 0.5795 - acc: 0.6981 - val_loss: 0.4579 - val_acc: 0.7833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.45789 to 0.45306, saving model to best.model\n",
      "0s - loss: 0.5596 - acc: 0.7130 - val_loss: 0.4531 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.45306 to 0.45104, saving model to best.model\n",
      "0s - loss: 0.5372 - acc: 0.7407 - val_loss: 0.4510 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5191 - acc: 0.7426 - val_loss: 0.4515 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5307 - acc: 0.7259 - val_loss: 0.4523 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5123 - acc: 0.7556 - val_loss: 0.4557 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5255 - acc: 0.7278 - val_loss: 0.4586 - val_acc: 0.7667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5172 - acc: 0.7481 - val_loss: 0.4616 - val_acc: 0.7667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5314 - acc: 0.7556 - val_loss: 0.4617 - val_acc: 0.7667\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5015 - acc: 0.7519 - val_loss: 0.4538 - val_acc: 0.7667\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.45104 to 0.44618, saving model to best.model\n",
      "0s - loss: 0.5117 - acc: 0.7352 - val_loss: 0.4462 - val_acc: 0.7667\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.44618 to 0.44183, saving model to best.model\n",
      "0s - loss: 0.5448 - acc: 0.7407 - val_loss: 0.4418 - val_acc: 0.7667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5462 - acc: 0.7093 - val_loss: 0.4454 - val_acc: 0.7667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5041 - acc: 0.7407 - val_loss: 0.4505 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.4950 - acc: 0.7519 - val_loss: 0.4554 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5106 - acc: 0.7556 - val_loss: 0.4552 - val_acc: 0.8000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.4973 - acc: 0.7593 - val_loss: 0.4499 - val_acc: 0.8000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.4773 - acc: 0.7593 - val_loss: 0.4441 - val_acc: 0.7833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.44183 to 0.44023, saving model to best.model\n",
      "0s - loss: 0.4704 - acc: 0.7685 - val_loss: 0.4402 - val_acc: 0.7833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.44023 to 0.43870, saving model to best.model\n",
      "0s - loss: 0.4911 - acc: 0.7722 - val_loss: 0.4387 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.43870 to 0.43597, saving model to best.model\n",
      "0s - loss: 0.4989 - acc: 0.7500 - val_loss: 0.4360 - val_acc: 0.7833\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.43597 to 0.43126, saving model to best.model\n",
      "0s - loss: 0.5068 - acc: 0.7593 - val_loss: 0.4313 - val_acc: 0.8000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.43126 to 0.42956, saving model to best.model\n",
      "0s - loss: 0.4718 - acc: 0.7722 - val_loss: 0.4296 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.42956 to 0.42941, saving model to best.model\n",
      "0s - loss: 0.4801 - acc: 0.7593 - val_loss: 0.4294 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4649 - acc: 0.7907 - val_loss: 0.4306 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4620 - acc: 0.7889 - val_loss: 0.4337 - val_acc: 0.7833\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4818 - acc: 0.7778 - val_loss: 0.4372 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4635 - acc: 0.7722 - val_loss: 0.4334 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.42941 to 0.42343, saving model to best.model\n",
      "0s - loss: 0.4705 - acc: 0.7685 - val_loss: 0.4234 - val_acc: 0.7833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.42343 to 0.41471, saving model to best.model\n",
      "0s - loss: 0.4726 - acc: 0.7796 - val_loss: 0.4147 - val_acc: 0.8167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.41471 to 0.40356, saving model to best.model\n",
      "0s - loss: 0.4601 - acc: 0.7852 - val_loss: 0.4036 - val_acc: 0.8333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.40356 to 0.39531, saving model to best.model\n",
      "0s - loss: 0.4372 - acc: 0.7907 - val_loss: 0.3953 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.39531 to 0.39066, saving model to best.model\n",
      "0s - loss: 0.4856 - acc: 0.7611 - val_loss: 0.3907 - val_acc: 0.8500\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4760 - acc: 0.7759 - val_loss: 0.3907 - val_acc: 0.8667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4372 - acc: 0.7889 - val_loss: 0.3933 - val_acc: 0.8333\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4473 - acc: 0.7741 - val_loss: 0.3962 - val_acc: 0.8333\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4722 - acc: 0.7815 - val_loss: 0.3997 - val_acc: 0.8167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4561 - acc: 0.7963 - val_loss: 0.4054 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4538 - acc: 0.8167 - val_loss: 0.4170 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4263 - acc: 0.8000 - val_loss: 0.4267 - val_acc: 0.7500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4312 - acc: 0.8037 - val_loss: 0.4276 - val_acc: 0.7500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4497 - acc: 0.7926 - val_loss: 0.4194 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4461 - acc: 0.7944 - val_loss: 0.4071 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4249 - acc: 0.7944 - val_loss: 0.3972 - val_acc: 0.7833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4368 - acc: 0.8093 - val_loss: 0.3915 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.39066 to 0.38750, saving model to best.model\n",
      "0s - loss: 0.4664 - acc: 0.7889 - val_loss: 0.3875 - val_acc: 0.8167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.38750 to 0.38662, saving model to best.model\n",
      "0s - loss: 0.4217 - acc: 0.8130 - val_loss: 0.3866 - val_acc: 0.8167\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.38662 to 0.38482, saving model to best.model\n",
      "0s - loss: 0.4489 - acc: 0.7963 - val_loss: 0.3848 - val_acc: 0.8333\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4310 - acc: 0.7963 - val_loss: 0.3869 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4505 - acc: 0.7889 - val_loss: 0.3884 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.8130 - val_loss: 0.3909 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4480 - acc: 0.7963 - val_loss: 0.3931 - val_acc: 0.7833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4507 - acc: 0.7889 - val_loss: 0.3967 - val_acc: 0.8000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4416 - acc: 0.7926 - val_loss: 0.3983 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4312 - acc: 0.8093 - val_loss: 0.3958 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4417 - acc: 0.7981 - val_loss: 0.3907 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4162 - acc: 0.8167 - val_loss: 0.3906 - val_acc: 0.8167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4237 - acc: 0.7963 - val_loss: 0.3929 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4130 - acc: 0.8093 - val_loss: 0.3963 - val_acc: 0.7667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4492 - acc: 0.7889 - val_loss: 0.4026 - val_acc: 0.7333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4353 - acc: 0.8000 - val_loss: 0.4037 - val_acc: 0.7333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4221 - acc: 0.8000 - val_loss: 0.4009 - val_acc: 0.7333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4190 - acc: 0.8111 - val_loss: 0.3954 - val_acc: 0.7333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4023 - acc: 0.8259 - val_loss: 0.3912 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4035 - acc: 0.8167 - val_loss: 0.3871 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.38482 to 0.38445, saving model to best.model\n",
      "0s - loss: 0.3938 - acc: 0.8315 - val_loss: 0.3845 - val_acc: 0.7667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4062 - acc: 0.8093 - val_loss: 0.3845 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4176 - acc: 0.7944 - val_loss: 0.3857 - val_acc: 0.7667\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4206 - acc: 0.8148 - val_loss: 0.3874 - val_acc: 0.7667\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4036 - acc: 0.8259 - val_loss: 0.3893 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4217 - acc: 0.7889 - val_loss: 0.3880 - val_acc: 0.7500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.3900 - acc: 0.8241 - val_loss: 0.3855 - val_acc: 0.7667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4012 - acc: 0.8278 - val_loss: 0.3847 - val_acc: 0.7667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4092 - acc: 0.8185 - val_loss: 0.3858 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3973 - acc: 0.8352 - val_loss: 0.3889 - val_acc: 0.7500\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3844 - acc: 0.8278 - val_loss: 0.3903 - val_acc: 0.7500\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.3915 - acc: 0.8185 - val_loss: 0.3916 - val_acc: 0.7333\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4293 - acc: 0.7981 - val_loss: 0.3923 - val_acc: 0.7500\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4050 - acc: 0.8222 - val_loss: 0.3941 - val_acc: 0.7667\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3783 - acc: 0.8370 - val_loss: 0.3914 - val_acc: 0.7833\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.38445 to 0.38208, saving model to best.model\n",
      "0s - loss: 0.3895 - acc: 0.8296 - val_loss: 0.3821 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.38208 to 0.37203, saving model to best.model\n",
      "0s - loss: 0.4067 - acc: 0.8278 - val_loss: 0.3720 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.37203 to 0.36695, saving model to best.model\n",
      "0s - loss: 0.4036 - acc: 0.8370 - val_loss: 0.3670 - val_acc: 0.8000\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.36695 to 0.36620, saving model to best.model\n",
      "0s - loss: 0.4011 - acc: 0.8167 - val_loss: 0.3662 - val_acc: 0.8000\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4089 - acc: 0.8074 - val_loss: 0.3663 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.36620 to 0.36590, saving model to best.model\n",
      "0s - loss: 0.3919 - acc: 0.8222 - val_loss: 0.3659 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.36590 to 0.36477, saving model to best.model\n",
      "0s - loss: 0.3857 - acc: 0.8519 - val_loss: 0.3648 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3534 - acc: 0.8407 - val_loss: 0.3652 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3779 - acc: 0.8333 - val_loss: 0.3666 - val_acc: 0.8167\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3987 - acc: 0.8241 - val_loss: 0.3678 - val_acc: 0.8167\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3837 - acc: 0.8463 - val_loss: 0.3697 - val_acc: 0.8167\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3808 - acc: 0.8370 - val_loss: 0.3732 - val_acc: 0.7500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3690 - acc: 0.8556 - val_loss: 0.3775 - val_acc: 0.7500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4060 - acc: 0.8352 - val_loss: 0.3853 - val_acc: 0.7500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3617 - acc: 0.8352 - val_loss: 0.3922 - val_acc: 0.8000\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4011 - acc: 0.8222 - val_loss: 0.3897 - val_acc: 0.7833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3902 - acc: 0.8241 - val_loss: 0.3783 - val_acc: 0.7833\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3895 - acc: 0.8389 - val_loss: 0.3659 - val_acc: 0.7667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.36477 to 0.35479, saving model to best.model\n",
      "0s - loss: 0.3976 - acc: 0.8407 - val_loss: 0.3548 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.35479 to 0.34971, saving model to best.model\n",
      "0s - loss: 0.3911 - acc: 0.8278 - val_loss: 0.3497 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3652 - acc: 0.8352 - val_loss: 0.3505 - val_acc: 0.7833\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3673 - acc: 0.8426 - val_loss: 0.3530 - val_acc: 0.7833\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3554 - acc: 0.8593 - val_loss: 0.3581 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3780 - acc: 0.8370 - val_loss: 0.3600 - val_acc: 0.8000\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3441 - acc: 0.8704 - val_loss: 0.3580 - val_acc: 0.8000\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3740 - acc: 0.8481 - val_loss: 0.3546 - val_acc: 0.8000\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3490 - acc: 0.8444 - val_loss: 0.3519 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3867 - acc: 0.8500 - val_loss: 0.3522 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3696 - acc: 0.8444 - val_loss: 0.3532 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3789 - acc: 0.8389 - val_loss: 0.3534 - val_acc: 0.8500\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3591 - acc: 0.8500 - val_loss: 0.3572 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3818 - acc: 0.8296 - val_loss: 0.3635 - val_acc: 0.8000\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3779 - acc: 0.8481 - val_loss: 0.3675 - val_acc: 0.8000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3288 - acc: 0.8630 - val_loss: 0.3692 - val_acc: 0.8000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3584 - acc: 0.8537 - val_loss: 0.3681 - val_acc: 0.8000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3462 - acc: 0.8574 - val_loss: 0.3647 - val_acc: 0.8000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3487 - acc: 0.8519 - val_loss: 0.3604 - val_acc: 0.8000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3389 - acc: 0.8704 - val_loss: 0.3502 - val_acc: 0.8333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.34971 to 0.34241, saving model to best.model\n",
      "0s - loss: 0.3236 - acc: 0.8685 - val_loss: 0.3424 - val_acc: 0.8667\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.34241 to 0.33790, saving model to best.model\n",
      "0s - loss: 0.3323 - acc: 0.8556 - val_loss: 0.3379 - val_acc: 0.8667\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.33790 to 0.33718, saving model to best.model\n",
      "0s - loss: 0.3311 - acc: 0.8537 - val_loss: 0.3372 - val_acc: 0.8667\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3411 - acc: 0.8611 - val_loss: 0.3390 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3525 - acc: 0.8741 - val_loss: 0.3415 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3113 - acc: 0.8648 - val_loss: 0.3418 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3265 - acc: 0.8778 - val_loss: 0.3422 - val_acc: 0.8667\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3496 - acc: 0.8593 - val_loss: 0.3392 - val_acc: 0.8667\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3348 - acc: 0.8593 - val_loss: 0.3373 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3250 - acc: 0.8611 - val_loss: 0.3389 - val_acc: 0.8500\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3438 - acc: 0.8463 - val_loss: 0.3418 - val_acc: 0.8500\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3362 - acc: 0.8556 - val_loss: 0.3462 - val_acc: 0.8833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3444 - acc: 0.8667 - val_loss: 0.3461 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3378 - acc: 0.8685 - val_loss: 0.3396 - val_acc: 0.8500\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.33718 to 0.33296, saving model to best.model\n",
      "0s - loss: 0.3252 - acc: 0.8519 - val_loss: 0.3330 - val_acc: 0.8333\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.33296 to 0.32829, saving model to best.model\n",
      "0s - loss: 0.3127 - acc: 0.8741 - val_loss: 0.3283 - val_acc: 0.8333\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.32829 to 0.32619, saving model to best.model\n",
      "0s - loss: 0.3108 - acc: 0.8833 - val_loss: 0.3262 - val_acc: 0.8667\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3243 - acc: 0.8796 - val_loss: 0.3296 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3168 - acc: 0.8556 - val_loss: 0.3323 - val_acc: 0.8500\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3033 - acc: 0.8759 - val_loss: 0.3306 - val_acc: 0.8500\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3044 - acc: 0.8796 - val_loss: 0.3300 - val_acc: 0.8667\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3099 - acc: 0.8593 - val_loss: 0.3318 - val_acc: 0.8667\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3134 - acc: 0.8685 - val_loss: 0.3368 - val_acc: 0.8667\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3150 - acc: 0.8759 - val_loss: 0.3417 - val_acc: 0.8667\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3017 - acc: 0.8815 - val_loss: 0.3478 - val_acc: 0.8833\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3539 - acc: 0.8704 - val_loss: 0.3547 - val_acc: 0.8500\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2984 - acc: 0.8815 - val_loss: 0.3578 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3306 - acc: 0.8796 - val_loss: 0.3488 - val_acc: 0.8833\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2925 - acc: 0.8815 - val_loss: 0.3355 - val_acc: 0.8833\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2967 - acc: 0.8833 - val_loss: 0.3279 - val_acc: 0.8833\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2820 - acc: 0.8815 - val_loss: 0.3266 - val_acc: 0.8833\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3171 - acc: 0.8685 - val_loss: 0.3274 - val_acc: 0.8833\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3375 - acc: 0.8519 - val_loss: 0.3315 - val_acc: 0.8833\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3034 - acc: 0.8704 - val_loss: 0.3372 - val_acc: 0.8833\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2838 - acc: 0.8796 - val_loss: 0.3448 - val_acc: 0.8667\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2846 - acc: 0.8778 - val_loss: 0.3485 - val_acc: 0.8833\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2934 - acc: 0.8833 - val_loss: 0.3511 - val_acc: 0.8833\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3012 - acc: 0.8667 - val_loss: 0.3538 - val_acc: 0.8833\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3039 - acc: 0.8870 - val_loss: 0.3460 - val_acc: 0.8833\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.3064 - acc: 0.8722 - val_loss: 0.3426 - val_acc: 0.8833\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2790 - acc: 0.8926 - val_loss: 0.3415 - val_acc: 0.8833\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2800 - acc: 0.8963 - val_loss: 0.3390 - val_acc: 0.9000\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2813 - acc: 0.8907 - val_loss: 0.3387 - val_acc: 0.8833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.60092, saving model to best.model\n",
      "0s - loss: 0.8244 - acc: 0.5333 - val_loss: 0.6009 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.60092 to 0.58722, saving model to best.model\n",
      "0s - loss: 0.7404 - acc: 0.6574 - val_loss: 0.5872 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.58722 to 0.57908, saving model to best.model\n",
      "0s - loss: 0.6841 - acc: 0.6981 - val_loss: 0.5791 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6483 - acc: 0.6926 - val_loss: 0.5809 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6378 - acc: 0.6870 - val_loss: 0.5889 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6411 - acc: 0.6611 - val_loss: 0.5948 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6330 - acc: 0.6759 - val_loss: 0.5951 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6079 - acc: 0.6833 - val_loss: 0.5885 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.57908 to 0.57787, saving model to best.model\n",
      "0s - loss: 0.5842 - acc: 0.6944 - val_loss: 0.5779 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.57787 to 0.56938, saving model to best.model\n",
      "0s - loss: 0.5905 - acc: 0.7204 - val_loss: 0.5694 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.56938 to 0.56567, saving model to best.model\n",
      "0s - loss: 0.5724 - acc: 0.7167 - val_loss: 0.5657 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.56567 to 0.56436, saving model to best.model\n",
      "0s - loss: 0.5701 - acc: 0.7241 - val_loss: 0.5644 - val_acc: 0.7500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.56436 to 0.56394, saving model to best.model\n",
      "0s - loss: 0.5702 - acc: 0.7130 - val_loss: 0.5639 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.56394 to 0.56081, saving model to best.model\n",
      "0s - loss: 0.5739 - acc: 0.7130 - val_loss: 0.5608 - val_acc: 0.7500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.56081 to 0.55500, saving model to best.model\n",
      "0s - loss: 0.5611 - acc: 0.7222 - val_loss: 0.5550 - val_acc: 0.7500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.55500 to 0.54898, saving model to best.model\n",
      "0s - loss: 0.5647 - acc: 0.7204 - val_loss: 0.5490 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.54898 to 0.54583, saving model to best.model\n",
      "0s - loss: 0.5512 - acc: 0.7315 - val_loss: 0.5458 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.54583 to 0.54444, saving model to best.model\n",
      "0s - loss: 0.5353 - acc: 0.7352 - val_loss: 0.5444 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.54444 to 0.54421, saving model to best.model\n",
      "0s - loss: 0.5341 - acc: 0.7222 - val_loss: 0.5442 - val_acc: 0.8000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.54421 to 0.53952, saving model to best.model\n",
      "0s - loss: 0.5277 - acc: 0.7278 - val_loss: 0.5395 - val_acc: 0.8000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.53952 to 0.53370, saving model to best.model\n",
      "0s - loss: 0.5414 - acc: 0.7111 - val_loss: 0.5337 - val_acc: 0.8000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.53370 to 0.52943, saving model to best.model\n",
      "0s - loss: 0.5330 - acc: 0.7556 - val_loss: 0.5294 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.52943 to 0.52828, saving model to best.model\n",
      "0s - loss: 0.5506 - acc: 0.7148 - val_loss: 0.5283 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52828 to 0.52707, saving model to best.model\n",
      "0s - loss: 0.5502 - acc: 0.7185 - val_loss: 0.5271 - val_acc: 0.8500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.52707 to 0.52418, saving model to best.model\n",
      "0s - loss: 0.5106 - acc: 0.7463 - val_loss: 0.5242 - val_acc: 0.8500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52418 to 0.51927, saving model to best.model\n",
      "0s - loss: 0.5302 - acc: 0.7593 - val_loss: 0.5193 - val_acc: 0.8500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.51927 to 0.51465, saving model to best.model\n",
      "0s - loss: 0.5247 - acc: 0.7352 - val_loss: 0.5146 - val_acc: 0.8500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.51465 to 0.51068, saving model to best.model\n",
      "0s - loss: 0.5284 - acc: 0.7593 - val_loss: 0.5107 - val_acc: 0.8500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.51068 to 0.50579, saving model to best.model\n",
      "0s - loss: 0.5257 - acc: 0.7407 - val_loss: 0.5058 - val_acc: 0.8500\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.50579 to 0.50049, saving model to best.model\n",
      "0s - loss: 0.5107 - acc: 0.7593 - val_loss: 0.5005 - val_acc: 0.8500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.50049 to 0.49656, saving model to best.model\n",
      "0s - loss: 0.5181 - acc: 0.7741 - val_loss: 0.4966 - val_acc: 0.8500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.49656 to 0.49501, saving model to best.model\n",
      "0s - loss: 0.5062 - acc: 0.7593 - val_loss: 0.4950 - val_acc: 0.8333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5114 - acc: 0.7389 - val_loss: 0.4960 - val_acc: 0.8333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5106 - acc: 0.7556 - val_loss: 0.4967 - val_acc: 0.8333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.49501 to 0.49474, saving model to best.model\n",
      "0s - loss: 0.5166 - acc: 0.7481 - val_loss: 0.4947 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.49474 to 0.49143, saving model to best.model\n",
      "0s - loss: 0.5032 - acc: 0.7444 - val_loss: 0.4914 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.49143 to 0.48950, saving model to best.model\n",
      "0s - loss: 0.5124 - acc: 0.7796 - val_loss: 0.4895 - val_acc: 0.8333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5041 - acc: 0.7722 - val_loss: 0.4895 - val_acc: 0.8333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5048 - acc: 0.7574 - val_loss: 0.4906 - val_acc: 0.8333\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.4923 - acc: 0.7630 - val_loss: 0.4940 - val_acc: 0.8167\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4979 - acc: 0.7537 - val_loss: 0.4947 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5006 - acc: 0.7611 - val_loss: 0.4925 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.48950 to 0.48823, saving model to best.model\n",
      "0s - loss: 0.5094 - acc: 0.7593 - val_loss: 0.4882 - val_acc: 0.8167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.48823 to 0.48390, saving model to best.model\n",
      "0s - loss: 0.4950 - acc: 0.7481 - val_loss: 0.4839 - val_acc: 0.8333\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.48390 to 0.48006, saving model to best.model\n",
      "0s - loss: 0.5064 - acc: 0.7574 - val_loss: 0.4801 - val_acc: 0.8333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.48006 to 0.47530, saving model to best.model\n",
      "0s - loss: 0.4949 - acc: 0.7667 - val_loss: 0.4753 - val_acc: 0.8333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.47530 to 0.47297, saving model to best.model\n",
      "0s - loss: 0.4731 - acc: 0.7593 - val_loss: 0.4730 - val_acc: 0.8333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.47297 to 0.47241, saving model to best.model\n",
      "0s - loss: 0.5014 - acc: 0.7556 - val_loss: 0.4724 - val_acc: 0.8500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5056 - acc: 0.7593 - val_loss: 0.4740 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5150 - acc: 0.7685 - val_loss: 0.4771 - val_acc: 0.8333\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4846 - acc: 0.7796 - val_loss: 0.4801 - val_acc: 0.8333\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4678 - acc: 0.7870 - val_loss: 0.4791 - val_acc: 0.8167\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4795 - acc: 0.7815 - val_loss: 0.4749 - val_acc: 0.8167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.47241 to 0.46802, saving model to best.model\n",
      "0s - loss: 0.5037 - acc: 0.7741 - val_loss: 0.4680 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.46802 to 0.46230, saving model to best.model\n",
      "0s - loss: 0.4598 - acc: 0.7815 - val_loss: 0.4623 - val_acc: 0.8333\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.46230 to 0.45915, saving model to best.model\n",
      "0s - loss: 0.4525 - acc: 0.8019 - val_loss: 0.4592 - val_acc: 0.8500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.45915 to 0.45817, saving model to best.model\n",
      "0s - loss: 0.4690 - acc: 0.7944 - val_loss: 0.4582 - val_acc: 0.8500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.45817 to 0.45733, saving model to best.model\n",
      "0s - loss: 0.4618 - acc: 0.7852 - val_loss: 0.4573 - val_acc: 0.8500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.45733 to 0.45718, saving model to best.model\n",
      "0s - loss: 0.4769 - acc: 0.7667 - val_loss: 0.4572 - val_acc: 0.8500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4796 - acc: 0.7833 - val_loss: 0.4589 - val_acc: 0.8167\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4755 - acc: 0.7944 - val_loss: 0.4619 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4705 - acc: 0.7815 - val_loss: 0.4644 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4462 - acc: 0.7907 - val_loss: 0.4640 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4530 - acc: 0.7926 - val_loss: 0.4613 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4558 - acc: 0.7944 - val_loss: 0.4582 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.45718 to 0.45466, saving model to best.model\n",
      "0s - loss: 0.4486 - acc: 0.7907 - val_loss: 0.4547 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.45466 to 0.45311, saving model to best.model\n",
      "0s - loss: 0.4598 - acc: 0.7741 - val_loss: 0.4531 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.45311 to 0.45186, saving model to best.model\n",
      "0s - loss: 0.4739 - acc: 0.7815 - val_loss: 0.4519 - val_acc: 0.8333\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.45186 to 0.45092, saving model to best.model\n",
      "0s - loss: 0.4610 - acc: 0.7963 - val_loss: 0.4509 - val_acc: 0.8333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4328 - acc: 0.8074 - val_loss: 0.4511 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4630 - acc: 0.7926 - val_loss: 0.4519 - val_acc: 0.8167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4514 - acc: 0.8148 - val_loss: 0.4545 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4514 - acc: 0.8056 - val_loss: 0.4558 - val_acc: 0.8167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4406 - acc: 0.7926 - val_loss: 0.4556 - val_acc: 0.8167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4574 - acc: 0.8130 - val_loss: 0.4550 - val_acc: 0.8167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4344 - acc: 0.7981 - val_loss: 0.4545 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4623 - acc: 0.7926 - val_loss: 0.4539 - val_acc: 0.8333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4402 - acc: 0.8019 - val_loss: 0.4538 - val_acc: 0.8500\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4383 - acc: 0.7981 - val_loss: 0.4519 - val_acc: 0.8167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.45092 to 0.44960, saving model to best.model\n",
      "0s - loss: 0.4536 - acc: 0.8111 - val_loss: 0.4496 - val_acc: 0.8333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.44960 to 0.44887, saving model to best.model\n",
      "0s - loss: 0.4434 - acc: 0.7963 - val_loss: 0.4489 - val_acc: 0.8167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.44887 to 0.44801, saving model to best.model\n",
      "0s - loss: 0.4530 - acc: 0.8056 - val_loss: 0.4480 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.44801 to 0.44576, saving model to best.model\n",
      "0s - loss: 0.4208 - acc: 0.8222 - val_loss: 0.4458 - val_acc: 0.8000\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.44576 to 0.44256, saving model to best.model\n",
      "0s - loss: 0.4205 - acc: 0.8056 - val_loss: 0.4426 - val_acc: 0.8500\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.44256 to 0.43933, saving model to best.model\n",
      "0s - loss: 0.4215 - acc: 0.8148 - val_loss: 0.4393 - val_acc: 0.8500\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.43933 to 0.43801, saving model to best.model\n",
      "0s - loss: 0.4486 - acc: 0.8185 - val_loss: 0.4380 - val_acc: 0.8500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.43801 to 0.43673, saving model to best.model\n",
      "0s - loss: 0.4011 - acc: 0.8148 - val_loss: 0.4367 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.43673 to 0.43472, saving model to best.model\n",
      "0s - loss: 0.4259 - acc: 0.7981 - val_loss: 0.4347 - val_acc: 0.8333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.43472 to 0.43270, saving model to best.model\n",
      "0s - loss: 0.4480 - acc: 0.8074 - val_loss: 0.4327 - val_acc: 0.8500\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.43270 to 0.43178, saving model to best.model\n",
      "0s - loss: 0.4311 - acc: 0.8167 - val_loss: 0.4318 - val_acc: 0.8500\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.43178 to 0.43098, saving model to best.model\n",
      "0s - loss: 0.4260 - acc: 0.7926 - val_loss: 0.4310 - val_acc: 0.8500\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.43098 to 0.43052, saving model to best.model\n",
      "0s - loss: 0.4119 - acc: 0.8111 - val_loss: 0.4305 - val_acc: 0.8500\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.43052 to 0.42929, saving model to best.model\n",
      "0s - loss: 0.4401 - acc: 0.8000 - val_loss: 0.4293 - val_acc: 0.8500\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.42929 to 0.42795, saving model to best.model\n",
      "0s - loss: 0.4385 - acc: 0.8074 - val_loss: 0.4280 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4326 - acc: 0.8056 - val_loss: 0.4301 - val_acc: 0.8167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4255 - acc: 0.8259 - val_loss: 0.4314 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4280 - acc: 0.8296 - val_loss: 0.4316 - val_acc: 0.8000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.42795 to 0.42756, saving model to best.model\n",
      "0s - loss: 0.4551 - acc: 0.7889 - val_loss: 0.4276 - val_acc: 0.8167\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.42756 to 0.42496, saving model to best.model\n",
      "0s - loss: 0.4263 - acc: 0.8241 - val_loss: 0.4250 - val_acc: 0.8167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.42496 to 0.42496, saving model to best.model\n",
      "0s - loss: 0.4176 - acc: 0.8278 - val_loss: 0.4250 - val_acc: 0.8167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.42496 to 0.42190, saving model to best.model\n",
      "0s - loss: 0.4240 - acc: 0.8241 - val_loss: 0.4219 - val_acc: 0.8167\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.42190 to 0.41629, saving model to best.model\n",
      "0s - loss: 0.4043 - acc: 0.8111 - val_loss: 0.4163 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.41629 to 0.41205, saving model to best.model\n",
      "0s - loss: 0.4107 - acc: 0.8185 - val_loss: 0.4121 - val_acc: 0.8500\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.41205 to 0.40889, saving model to best.model\n",
      "0s - loss: 0.3999 - acc: 0.8333 - val_loss: 0.4089 - val_acc: 0.8500\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.40889 to 0.40805, saving model to best.model\n",
      "0s - loss: 0.4124 - acc: 0.8074 - val_loss: 0.4080 - val_acc: 0.8500\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4282 - acc: 0.8389 - val_loss: 0.4091 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3987 - acc: 0.8333 - val_loss: 0.4095 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.40805 to 0.40792, saving model to best.model\n",
      "0s - loss: 0.3926 - acc: 0.8315 - val_loss: 0.4079 - val_acc: 0.8333\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.40792 to 0.40480, saving model to best.model\n",
      "0s - loss: 0.3884 - acc: 0.8352 - val_loss: 0.4048 - val_acc: 0.8333\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.40480 to 0.40237, saving model to best.model\n",
      "0s - loss: 0.4171 - acc: 0.8185 - val_loss: 0.4024 - val_acc: 0.8333\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.40237 to 0.40012, saving model to best.model\n",
      "0s - loss: 0.3938 - acc: 0.8222 - val_loss: 0.4001 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.40012 to 0.39776, saving model to best.model\n",
      "0s - loss: 0.3999 - acc: 0.8370 - val_loss: 0.3978 - val_acc: 0.8500\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.39776 to 0.39634, saving model to best.model\n",
      "0s - loss: 0.3961 - acc: 0.8481 - val_loss: 0.3963 - val_acc: 0.8500\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4011 - acc: 0.8259 - val_loss: 0.3982 - val_acc: 0.8500\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3754 - acc: 0.8463 - val_loss: 0.4019 - val_acc: 0.8333\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4022 - acc: 0.8241 - val_loss: 0.4027 - val_acc: 0.8167\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.4058 - acc: 0.8296 - val_loss: 0.3997 - val_acc: 0.8500\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3931 - acc: 0.8389 - val_loss: 0.3969 - val_acc: 0.8500\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.39634 to 0.39418, saving model to best.model\n",
      "0s - loss: 0.3628 - acc: 0.8519 - val_loss: 0.3942 - val_acc: 0.8500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.39418 to 0.39252, saving model to best.model\n",
      "0s - loss: 0.3854 - acc: 0.8426 - val_loss: 0.3925 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3672 - acc: 0.8241 - val_loss: 0.3950 - val_acc: 0.8333\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3931 - acc: 0.8370 - val_loss: 0.3969 - val_acc: 0.8333\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3915 - acc: 0.8463 - val_loss: 0.4006 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3869 - acc: 0.8222 - val_loss: 0.3976 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.39252 to 0.39099, saving model to best.model\n",
      "0s - loss: 0.3695 - acc: 0.8444 - val_loss: 0.3910 - val_acc: 0.8333\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.39099 to 0.38528, saving model to best.model\n",
      "0s - loss: 0.3726 - acc: 0.8500 - val_loss: 0.3853 - val_acc: 0.8333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.38528 to 0.38327, saving model to best.model\n",
      "0s - loss: 0.3710 - acc: 0.8611 - val_loss: 0.3833 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3718 - acc: 0.8389 - val_loss: 0.3841 - val_acc: 0.8500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3896 - acc: 0.8574 - val_loss: 0.3840 - val_acc: 0.8500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.4107 - acc: 0.8519 - val_loss: 0.3856 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3811 - acc: 0.8333 - val_loss: 0.3931 - val_acc: 0.8167\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3943 - acc: 0.8407 - val_loss: 0.4012 - val_acc: 0.8000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3704 - acc: 0.8537 - val_loss: 0.4044 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3726 - acc: 0.8519 - val_loss: 0.3991 - val_acc: 0.8333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3690 - acc: 0.8537 - val_loss: 0.3918 - val_acc: 0.8333\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3844 - acc: 0.8370 - val_loss: 0.3838 - val_acc: 0.8333\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.38327 to 0.38152, saving model to best.model\n",
      "0s - loss: 0.3575 - acc: 0.8463 - val_loss: 0.3815 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3631 - acc: 0.8574 - val_loss: 0.3837 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3491 - acc: 0.8593 - val_loss: 0.3845 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3453 - acc: 0.8574 - val_loss: 0.3831 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3375 - acc: 0.8685 - val_loss: 0.3832 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3430 - acc: 0.8556 - val_loss: 0.3848 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3482 - acc: 0.8593 - val_loss: 0.3867 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3379 - acc: 0.8648 - val_loss: 0.3864 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.38152 to 0.38094, saving model to best.model\n",
      "0s - loss: 0.3650 - acc: 0.8537 - val_loss: 0.3809 - val_acc: 0.8667\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.38094 to 0.37535, saving model to best.model\n",
      "0s - loss: 0.3773 - acc: 0.8463 - val_loss: 0.3753 - val_acc: 0.8667\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.37535 to 0.36973, saving model to best.model\n",
      "0s - loss: 0.3505 - acc: 0.8444 - val_loss: 0.3697 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.36973 to 0.36425, saving model to best.model\n",
      "0s - loss: 0.3547 - acc: 0.8667 - val_loss: 0.3643 - val_acc: 0.8667\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.36425 to 0.35982, saving model to best.model\n",
      "0s - loss: 0.3529 - acc: 0.8389 - val_loss: 0.3598 - val_acc: 0.8667\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.35982 to 0.35687, saving model to best.model\n",
      "0s - loss: 0.3547 - acc: 0.8611 - val_loss: 0.3569 - val_acc: 0.8667\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.35687 to 0.35366, saving model to best.model\n",
      "0s - loss: 0.3564 - acc: 0.8648 - val_loss: 0.3537 - val_acc: 0.8667\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.35366 to 0.35178, saving model to best.model\n",
      "0s - loss: 0.3592 - acc: 0.8667 - val_loss: 0.3518 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3341 - acc: 0.8778 - val_loss: 0.3518 - val_acc: 0.8500\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.35178 to 0.35044, saving model to best.model\n",
      "0s - loss: 0.3626 - acc: 0.8556 - val_loss: 0.3504 - val_acc: 0.8833\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.35044 to 0.34650, saving model to best.model\n",
      "0s - loss: 0.3467 - acc: 0.8667 - val_loss: 0.3465 - val_acc: 0.8500\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.34650 to 0.34370, saving model to best.model\n",
      "0s - loss: 0.3250 - acc: 0.8574 - val_loss: 0.3437 - val_acc: 0.8667\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3191 - acc: 0.8741 - val_loss: 0.3446 - val_acc: 0.8500\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3619 - acc: 0.8574 - val_loss: 0.3469 - val_acc: 0.8500\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3209 - acc: 0.8593 - val_loss: 0.3497 - val_acc: 0.8500\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3413 - acc: 0.8778 - val_loss: 0.3527 - val_acc: 0.8500\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3147 - acc: 0.8796 - val_loss: 0.3550 - val_acc: 0.8500\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3230 - acc: 0.8759 - val_loss: 0.3558 - val_acc: 0.8500\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3158 - acc: 0.8630 - val_loss: 0.3557 - val_acc: 0.8500\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3452 - acc: 0.8611 - val_loss: 0.3523 - val_acc: 0.8500\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3241 - acc: 0.8704 - val_loss: 0.3468 - val_acc: 0.8500\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.34370 to 0.34254, saving model to best.model\n",
      "0s - loss: 0.3313 - acc: 0.8667 - val_loss: 0.3425 - val_acc: 0.8333\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3507 - acc: 0.8630 - val_loss: 0.3443 - val_acc: 0.8333\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss improved from 0.34254 to 0.34144, saving model to best.model\n",
      "0s - loss: 0.3369 - acc: 0.8778 - val_loss: 0.3414 - val_acc: 0.8333\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss improved from 0.34144 to 0.33729, saving model to best.model\n",
      "0s - loss: 0.3216 - acc: 0.8685 - val_loss: 0.3373 - val_acc: 0.8333\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.33729 to 0.33515, saving model to best.model\n",
      "0s - loss: 0.3168 - acc: 0.8685 - val_loss: 0.3351 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.3135 - acc: 0.8833 - val_loss: 0.3372 - val_acc: 0.8500\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3451 - acc: 0.8500 - val_loss: 0.3408 - val_acc: 0.8500\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3136 - acc: 0.8741 - val_loss: 0.3442 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.3262 - acc: 0.8759 - val_loss: 0.3477 - val_acc: 0.9000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.3178 - acc: 0.8759 - val_loss: 0.3496 - val_acc: 0.8667\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.3284 - acc: 0.8611 - val_loss: 0.3502 - val_acc: 0.8667\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.3321 - acc: 0.8574 - val_loss: 0.3497 - val_acc: 0.8667\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.3136 - acc: 0.8704 - val_loss: 0.3488 - val_acc: 0.8667\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2759 - acc: 0.8981 - val_loss: 0.3489 - val_acc: 0.8667\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2966 - acc: 0.8889 - val_loss: 0.3497 - val_acc: 0.8667\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.3162 - acc: 0.8778 - val_loss: 0.3500 - val_acc: 0.8500\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.3351 - acc: 0.8722 - val_loss: 0.3514 - val_acc: 0.8667\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.3402 - acc: 0.8685 - val_loss: 0.3524 - val_acc: 0.8500\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2912 - acc: 0.8815 - val_loss: 0.3518 - val_acc: 0.8833\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.3122 - acc: 0.8759 - val_loss: 0.3539 - val_acc: 0.8833\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.3165 - acc: 0.8630 - val_loss: 0.3555 - val_acc: 0.8833\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.3055 - acc: 0.8778 - val_loss: 0.3526 - val_acc: 0.8833\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.3186 - acc: 0.8648 - val_loss: 0.3482 - val_acc: 0.8833\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2982 - acc: 0.8722 - val_loss: 0.3455 - val_acc: 0.8500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.3062 - acc: 0.8833 - val_loss: 0.3457 - val_acc: 0.8333\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2926 - acc: 0.8833 - val_loss: 0.3463 - val_acc: 0.8333\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2994 - acc: 0.8796 - val_loss: 0.3476 - val_acc: 0.8333\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2971 - acc: 0.8667 - val_loss: 0.3477 - val_acc: 0.8333\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2874 - acc: 0.8889 - val_loss: 0.3497 - val_acc: 0.8333\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.3135 - acc: 0.8759 - val_loss: 0.3505 - val_acc: 0.8333\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2987 - acc: 0.8907 - val_loss: 0.3540 - val_acc: 0.8333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.50493, saving model to best.model\n",
      "0s - loss: 0.7577 - acc: 0.5963 - val_loss: 0.5049 - val_acc: 0.7667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.50493 to 0.50366, saving model to best.model\n",
      "0s - loss: 0.7623 - acc: 0.6370 - val_loss: 0.5037 - val_acc: 0.7667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.6831 - acc: 0.6444 - val_loss: 0.5133 - val_acc: 0.7667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.7411 - acc: 0.6074 - val_loss: 0.5238 - val_acc: 0.7667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6616 - acc: 0.6444 - val_loss: 0.5301 - val_acc: 0.7667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6706 - acc: 0.6333 - val_loss: 0.5307 - val_acc: 0.7667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6283 - acc: 0.6611 - val_loss: 0.5259 - val_acc: 0.7667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6259 - acc: 0.6722 - val_loss: 0.5179 - val_acc: 0.7667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6212 - acc: 0.6685 - val_loss: 0.5106 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5932 - acc: 0.6926 - val_loss: 0.5078 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6278 - acc: 0.6889 - val_loss: 0.5070 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6081 - acc: 0.6963 - val_loss: 0.5078 - val_acc: 0.7667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6138 - acc: 0.6796 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5630 - acc: 0.7111 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5984 - acc: 0.6852 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5736 - acc: 0.6796 - val_loss: 0.5115 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5804 - acc: 0.6833 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5714 - acc: 0.7000 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.50366 to 0.49916, saving model to best.model\n",
      "0s - loss: 0.5786 - acc: 0.7130 - val_loss: 0.4992 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.49916 to 0.49516, saving model to best.model\n",
      "0s - loss: 0.5587 - acc: 0.7056 - val_loss: 0.4952 - val_acc: 0.7667\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.49516 to 0.49214, saving model to best.model\n",
      "0s - loss: 0.5638 - acc: 0.6981 - val_loss: 0.4921 - val_acc: 0.7667\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.49214 to 0.49025, saving model to best.model\n",
      "0s - loss: 0.5701 - acc: 0.7074 - val_loss: 0.4902 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5749 - acc: 0.6722 - val_loss: 0.4911 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5464 - acc: 0.7148 - val_loss: 0.4926 - val_acc: 0.8167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5617 - acc: 0.7056 - val_loss: 0.4936 - val_acc: 0.8333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.49025 to 0.48723, saving model to best.model\n",
      "0s - loss: 0.5243 - acc: 0.7389 - val_loss: 0.4872 - val_acc: 0.8333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.48723 to 0.47823, saving model to best.model\n",
      "0s - loss: 0.5693 - acc: 0.6963 - val_loss: 0.4782 - val_acc: 0.8333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.47823 to 0.46526, saving model to best.model\n",
      "0s - loss: 0.5503 - acc: 0.7389 - val_loss: 0.4653 - val_acc: 0.8167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.46526 to 0.45532, saving model to best.model\n",
      "0s - loss: 0.5711 - acc: 0.7019 - val_loss: 0.4553 - val_acc: 0.8167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.45532 to 0.44936, saving model to best.model\n",
      "0s - loss: 0.5265 - acc: 0.7500 - val_loss: 0.4494 - val_acc: 0.8167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.44936 to 0.44724, saving model to best.model\n",
      "0s - loss: 0.5299 - acc: 0.7278 - val_loss: 0.4472 - val_acc: 0.8167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5143 - acc: 0.7519 - val_loss: 0.4489 - val_acc: 0.8000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5142 - acc: 0.7389 - val_loss: 0.4536 - val_acc: 0.8000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5061 - acc: 0.7500 - val_loss: 0.4583 - val_acc: 0.8000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.4906 - acc: 0.7556 - val_loss: 0.4625 - val_acc: 0.8167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5218 - acc: 0.7630 - val_loss: 0.4698 - val_acc: 0.7667\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5193 - acc: 0.7426 - val_loss: 0.4757 - val_acc: 0.7667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5018 - acc: 0.7611 - val_loss: 0.4739 - val_acc: 0.7500\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.4873 - acc: 0.7704 - val_loss: 0.4664 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5027 - acc: 0.7593 - val_loss: 0.4609 - val_acc: 0.8167\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4755 - acc: 0.7778 - val_loss: 0.4572 - val_acc: 0.8167\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5223 - acc: 0.7352 - val_loss: 0.4576 - val_acc: 0.8167\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5023 - acc: 0.7722 - val_loss: 0.4581 - val_acc: 0.8167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5009 - acc: 0.7426 - val_loss: 0.4591 - val_acc: 0.8167\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4918 - acc: 0.7389 - val_loss: 0.4598 - val_acc: 0.8167\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4924 - acc: 0.7574 - val_loss: 0.4603 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4728 - acc: 0.7741 - val_loss: 0.4581 - val_acc: 0.8167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4812 - acc: 0.7667 - val_loss: 0.4562 - val_acc: 0.8167\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4949 - acc: 0.7796 - val_loss: 0.4554 - val_acc: 0.8167\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4742 - acc: 0.7852 - val_loss: 0.4556 - val_acc: 0.8167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4668 - acc: 0.7593 - val_loss: 0.4554 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4852 - acc: 0.7778 - val_loss: 0.4535 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4941 - acc: 0.7667 - val_loss: 0.4522 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4584 - acc: 0.7778 - val_loss: 0.4520 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4652 - acc: 0.7722 - val_loss: 0.4519 - val_acc: 0.8167\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4761 - acc: 0.7944 - val_loss: 0.4522 - val_acc: 0.8167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4650 - acc: 0.8074 - val_loss: 0.4515 - val_acc: 0.8167\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58937, saving model to best.model\n",
      "0s - loss: 0.9225 - acc: 0.5185 - val_loss: 0.5894 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7472 - acc: 0.6259 - val_loss: 0.6411 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7706 - acc: 0.6833 - val_loss: 0.5948 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58937 to 0.55888, saving model to best.model\n",
      "0s - loss: 0.7483 - acc: 0.6778 - val_loss: 0.5589 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.7266 - acc: 0.6352 - val_loss: 0.5628 - val_acc: 0.7000\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6720 - acc: 0.6537 - val_loss: 0.5780 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6641 - acc: 0.6426 - val_loss: 0.5835 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6407 - acc: 0.6481 - val_loss: 0.5829 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6441 - acc: 0.6630 - val_loss: 0.5800 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6476 - acc: 0.6500 - val_loss: 0.5774 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6351 - acc: 0.6796 - val_loss: 0.5742 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6272 - acc: 0.6574 - val_loss: 0.5743 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6133 - acc: 0.6648 - val_loss: 0.5756 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6050 - acc: 0.6759 - val_loss: 0.5768 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5978 - acc: 0.6981 - val_loss: 0.5760 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5965 - acc: 0.6981 - val_loss: 0.5739 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5807 - acc: 0.6889 - val_loss: 0.5718 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5866 - acc: 0.6889 - val_loss: 0.5676 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5877 - acc: 0.6889 - val_loss: 0.5619 - val_acc: 0.7333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.55888 to 0.55709, saving model to best.model\n",
      "0s - loss: 0.5882 - acc: 0.7093 - val_loss: 0.5571 - val_acc: 0.7333\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5651 - acc: 0.7204 - val_loss: 0.5573 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5531 - acc: 0.7315 - val_loss: 0.5579 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5651 - acc: 0.7333 - val_loss: 0.5578 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5637 - acc: 0.7000 - val_loss: 0.5596 - val_acc: 0.7000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5565 - acc: 0.7000 - val_loss: 0.5592 - val_acc: 0.7167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5545 - acc: 0.7296 - val_loss: 0.5583 - val_acc: 0.7167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.55709 to 0.55650, saving model to best.model\n",
      "0s - loss: 0.5490 - acc: 0.7167 - val_loss: 0.5565 - val_acc: 0.7000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.55650 to 0.55329, saving model to best.model\n",
      "0s - loss: 0.5429 - acc: 0.7130 - val_loss: 0.5533 - val_acc: 0.7000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5599 - acc: 0.7037 - val_loss: 0.5536 - val_acc: 0.6667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5460 - acc: 0.7389 - val_loss: 0.5543 - val_acc: 0.6667\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5582 - acc: 0.6926 - val_loss: 0.5537 - val_acc: 0.6667\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.55329 to 0.54991, saving model to best.model\n",
      "0s - loss: 0.5591 - acc: 0.7056 - val_loss: 0.5499 - val_acc: 0.6500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.54991 to 0.54481, saving model to best.model\n",
      "0s - loss: 0.5506 - acc: 0.7204 - val_loss: 0.5448 - val_acc: 0.6833\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.54481 to 0.54089, saving model to best.model\n",
      "0s - loss: 0.5418 - acc: 0.7241 - val_loss: 0.5409 - val_acc: 0.6833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.54089 to 0.53899, saving model to best.model\n",
      "0s - loss: 0.5440 - acc: 0.7481 - val_loss: 0.5390 - val_acc: 0.6833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.53899 to 0.53703, saving model to best.model\n",
      "0s - loss: 0.5051 - acc: 0.7333 - val_loss: 0.5370 - val_acc: 0.7000\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.53703 to 0.53515, saving model to best.model\n",
      "0s - loss: 0.5345 - acc: 0.7352 - val_loss: 0.5351 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.53515 to 0.53483, saving model to best.model\n",
      "0s - loss: 0.5416 - acc: 0.7185 - val_loss: 0.5348 - val_acc: 0.6833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5257 - acc: 0.7426 - val_loss: 0.5359 - val_acc: 0.6833\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5253 - acc: 0.7389 - val_loss: 0.5387 - val_acc: 0.6833\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5215 - acc: 0.7481 - val_loss: 0.5454 - val_acc: 0.6667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5310 - acc: 0.7352 - val_loss: 0.5542 - val_acc: 0.6667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5226 - acc: 0.7241 - val_loss: 0.5598 - val_acc: 0.6500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5164 - acc: 0.7426 - val_loss: 0.5553 - val_acc: 0.6500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5147 - acc: 0.7370 - val_loss: 0.5454 - val_acc: 0.6833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.53483 to 0.53437, saving model to best.model\n",
      "0s - loss: 0.5375 - acc: 0.7148 - val_loss: 0.5344 - val_acc: 0.6667\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.53437 to 0.52810, saving model to best.model\n",
      "0s - loss: 0.5221 - acc: 0.7593 - val_loss: 0.5281 - val_acc: 0.6833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.52810 to 0.52754, saving model to best.model\n",
      "0s - loss: 0.5446 - acc: 0.7463 - val_loss: 0.5275 - val_acc: 0.6833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5142 - acc: 0.7315 - val_loss: 0.5318 - val_acc: 0.6667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5128 - acc: 0.7444 - val_loss: 0.5343 - val_acc: 0.6833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5101 - acc: 0.7463 - val_loss: 0.5341 - val_acc: 0.7000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5004 - acc: 0.7389 - val_loss: 0.5294 - val_acc: 0.6833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.52754 to 0.52553, saving model to best.model\n",
      "0s - loss: 0.5139 - acc: 0.7407 - val_loss: 0.5255 - val_acc: 0.6833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.52553 to 0.52155, saving model to best.model\n",
      "0s - loss: 0.4969 - acc: 0.7500 - val_loss: 0.5215 - val_acc: 0.6833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.52155 to 0.51820, saving model to best.model\n",
      "0s - loss: 0.5129 - acc: 0.7481 - val_loss: 0.5182 - val_acc: 0.6667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.51820 to 0.51695, saving model to best.model\n",
      "0s - loss: 0.5185 - acc: 0.7352 - val_loss: 0.5169 - val_acc: 0.6667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5158 - acc: 0.7444 - val_loss: 0.5193 - val_acc: 0.6833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5160 - acc: 0.7519 - val_loss: 0.5260 - val_acc: 0.6833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4992 - acc: 0.7500 - val_loss: 0.5337 - val_acc: 0.7000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.5049 - acc: 0.7685 - val_loss: 0.5369 - val_acc: 0.6833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.5167 - acc: 0.7537 - val_loss: 0.5361 - val_acc: 0.6833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4793 - acc: 0.7722 - val_loss: 0.5305 - val_acc: 0.7000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.5021 - acc: 0.7537 - val_loss: 0.5269 - val_acc: 0.7000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.5038 - acc: 0.7722 - val_loss: 0.5260 - val_acc: 0.7000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.5099 - acc: 0.7611 - val_loss: 0.5217 - val_acc: 0.7000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4990 - acc: 0.7463 - val_loss: 0.5176 - val_acc: 0.7000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.51695 to 0.51613, saving model to best.model\n",
      "0s - loss: 0.4995 - acc: 0.7556 - val_loss: 0.5161 - val_acc: 0.7000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.51613 to 0.51582, saving model to best.model\n",
      "0s - loss: 0.4763 - acc: 0.7630 - val_loss: 0.5158 - val_acc: 0.6833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4811 - acc: 0.7833 - val_loss: 0.5167 - val_acc: 0.7000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4916 - acc: 0.7519 - val_loss: 0.5169 - val_acc: 0.7167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4846 - acc: 0.7667 - val_loss: 0.5173 - val_acc: 0.7167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4759 - acc: 0.7722 - val_loss: 0.5179 - val_acc: 0.7167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4965 - acc: 0.7426 - val_loss: 0.5165 - val_acc: 0.7167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.51582 to 0.51433, saving model to best.model\n",
      "0s - loss: 0.4821 - acc: 0.7704 - val_loss: 0.5143 - val_acc: 0.7167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.51433 to 0.51176, saving model to best.model\n",
      "0s - loss: 0.4835 - acc: 0.7704 - val_loss: 0.5118 - val_acc: 0.7167\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.51176 to 0.50908, saving model to best.model\n",
      "0s - loss: 0.4718 - acc: 0.7481 - val_loss: 0.5091 - val_acc: 0.7167\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.50908 to 0.50841, saving model to best.model\n",
      "0s - loss: 0.4713 - acc: 0.7722 - val_loss: 0.5084 - val_acc: 0.7167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.50841 to 0.50790, saving model to best.model\n",
      "0s - loss: 0.4887 - acc: 0.7611 - val_loss: 0.5079 - val_acc: 0.7167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.50790 to 0.50662, saving model to best.model\n",
      "0s - loss: 0.4905 - acc: 0.7759 - val_loss: 0.5066 - val_acc: 0.7167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4950 - acc: 0.7704 - val_loss: 0.5075 - val_acc: 0.7167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4717 - acc: 0.7796 - val_loss: 0.5090 - val_acc: 0.7167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4708 - acc: 0.7796 - val_loss: 0.5115 - val_acc: 0.7167\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4868 - acc: 0.7778 - val_loss: 0.5122 - val_acc: 0.7000\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4706 - acc: 0.7630 - val_loss: 0.5120 - val_acc: 0.7000\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4603 - acc: 0.7759 - val_loss: 0.5120 - val_acc: 0.7000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4619 - acc: 0.7704 - val_loss: 0.5101 - val_acc: 0.7000\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4565 - acc: 0.7796 - val_loss: 0.5099 - val_acc: 0.7000\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4767 - acc: 0.7833 - val_loss: 0.5089 - val_acc: 0.7000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4403 - acc: 0.7926 - val_loss: 0.5069 - val_acc: 0.7000\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.50662 to 0.50541, saving model to best.model\n",
      "0s - loss: 0.4535 - acc: 0.7981 - val_loss: 0.5054 - val_acc: 0.7000\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.50541 to 0.50516, saving model to best.model\n",
      "0s - loss: 0.4381 - acc: 0.8056 - val_loss: 0.5052 - val_acc: 0.7000\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.50516 to 0.50495, saving model to best.model\n",
      "0s - loss: 0.4456 - acc: 0.7833 - val_loss: 0.5050 - val_acc: 0.7000\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4534 - acc: 0.7944 - val_loss: 0.5051 - val_acc: 0.7000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.50495 to 0.50316, saving model to best.model\n",
      "0s - loss: 0.4436 - acc: 0.7889 - val_loss: 0.5032 - val_acc: 0.7000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.50316 to 0.50056, saving model to best.model\n",
      "0s - loss: 0.4397 - acc: 0.7926 - val_loss: 0.5006 - val_acc: 0.7000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.50056 to 0.49811, saving model to best.model\n",
      "0s - loss: 0.4491 - acc: 0.7963 - val_loss: 0.4981 - val_acc: 0.7000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.49811 to 0.49773, saving model to best.model\n",
      "0s - loss: 0.4497 - acc: 0.7852 - val_loss: 0.4977 - val_acc: 0.7000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4293 - acc: 0.8074 - val_loss: 0.5012 - val_acc: 0.6833\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4528 - acc: 0.7981 - val_loss: 0.5050 - val_acc: 0.6833\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4317 - acc: 0.8093 - val_loss: 0.5021 - val_acc: 0.6833\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.49773 to 0.49650, saving model to best.model\n",
      "0s - loss: 0.4459 - acc: 0.7778 - val_loss: 0.4965 - val_acc: 0.7000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.49650 to 0.49378, saving model to best.model\n",
      "0s - loss: 0.4306 - acc: 0.7963 - val_loss: 0.4938 - val_acc: 0.7000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4362 - acc: 0.7926 - val_loss: 0.4952 - val_acc: 0.7000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4962 - val_acc: 0.7000\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4312 - acc: 0.8111 - val_loss: 0.4970 - val_acc: 0.7000\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4366 - acc: 0.8037 - val_loss: 0.4965 - val_acc: 0.7000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4156 - acc: 0.8148 - val_loss: 0.4964 - val_acc: 0.7167\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4462 - acc: 0.8185 - val_loss: 0.4990 - val_acc: 0.7167\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4194 - acc: 0.8204 - val_loss: 0.5014 - val_acc: 0.7167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4364 - acc: 0.8000 - val_loss: 0.5023 - val_acc: 0.7167\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4192 - acc: 0.8222 - val_loss: 0.4981 - val_acc: 0.7167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4308 - acc: 0.8093 - val_loss: 0.4949 - val_acc: 0.7167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.49378 to 0.49201, saving model to best.model\n",
      "0s - loss: 0.4633 - acc: 0.7963 - val_loss: 0.4920 - val_acc: 0.7167\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.49201 to 0.48981, saving model to best.model\n",
      "0s - loss: 0.4212 - acc: 0.8185 - val_loss: 0.4898 - val_acc: 0.7000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.48981 to 0.48882, saving model to best.model\n",
      "0s - loss: 0.4176 - acc: 0.8074 - val_loss: 0.4888 - val_acc: 0.7167\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.48882 to 0.48707, saving model to best.model\n",
      "0s - loss: 0.3972 - acc: 0.8204 - val_loss: 0.4871 - val_acc: 0.7167\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.48707 to 0.48704, saving model to best.model\n",
      "0s - loss: 0.4120 - acc: 0.8185 - val_loss: 0.4870 - val_acc: 0.7333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.4240 - acc: 0.7981 - val_loss: 0.4931 - val_acc: 0.7167\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.4009 - acc: 0.8204 - val_loss: 0.4999 - val_acc: 0.7333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.4248 - acc: 0.8074 - val_loss: 0.4999 - val_acc: 0.7333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.4194 - acc: 0.8241 - val_loss: 0.4944 - val_acc: 0.7167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.4222 - acc: 0.7963 - val_loss: 0.4909 - val_acc: 0.7167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3867 - acc: 0.8148 - val_loss: 0.4895 - val_acc: 0.7167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.4074 - acc: 0.8185 - val_loss: 0.4892 - val_acc: 0.7167\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3832 - acc: 0.8444 - val_loss: 0.4930 - val_acc: 0.7167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.4069 - acc: 0.7981 - val_loss: 0.4992 - val_acc: 0.7167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.4041 - acc: 0.8204 - val_loss: 0.5042 - val_acc: 0.7333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.4026 - acc: 0.8315 - val_loss: 0.5072 - val_acc: 0.7333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3683 - acc: 0.8370 - val_loss: 0.5112 - val_acc: 0.7000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.4083 - acc: 0.8167 - val_loss: 0.5178 - val_acc: 0.7000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.4048 - acc: 0.8278 - val_loss: 0.5190 - val_acc: 0.7000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3991 - acc: 0.8111 - val_loss: 0.5153 - val_acc: 0.7333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3865 - acc: 0.8241 - val_loss: 0.5106 - val_acc: 0.7167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3797 - acc: 0.8259 - val_loss: 0.5044 - val_acc: 0.7167\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3877 - acc: 0.8444 - val_loss: 0.5007 - val_acc: 0.7167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3848 - acc: 0.8444 - val_loss: 0.4985 - val_acc: 0.7167\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3584 - acc: 0.8426 - val_loss: 0.4976 - val_acc: 0.7333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3829 - acc: 0.8056 - val_loss: 0.4995 - val_acc: 0.7333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3874 - acc: 0.8130 - val_loss: 0.5040 - val_acc: 0.7333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3666 - acc: 0.8259 - val_loss: 0.5035 - val_acc: 0.7333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3605 - acc: 0.8407 - val_loss: 0.5018 - val_acc: 0.7333\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3835 - acc: 0.8278 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3405 - acc: 0.8537 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.59525, saving model to best.model\n",
      "0s - loss: 0.8300 - acc: 0.5463 - val_loss: 0.5953 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.59525 to 0.57821, saving model to best.model\n",
      "0s - loss: 0.7245 - acc: 0.6296 - val_loss: 0.5782 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7654 - acc: 0.6056 - val_loss: 0.5815 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6989 - acc: 0.6167 - val_loss: 0.5916 - val_acc: 0.7500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.7182 - acc: 0.6130 - val_loss: 0.5991 - val_acc: 0.7500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6983 - acc: 0.6130 - val_loss: 0.5988 - val_acc: 0.7500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6849 - acc: 0.6111 - val_loss: 0.5864 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.57821 to 0.57606, saving model to best.model\n",
      "0s - loss: 0.6984 - acc: 0.6093 - val_loss: 0.5761 - val_acc: 0.7500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.57606 to 0.56860, saving model to best.model\n",
      "0s - loss: 0.6559 - acc: 0.6370 - val_loss: 0.5686 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.56860 to 0.56345, saving model to best.model\n",
      "0s - loss: 0.6296 - acc: 0.6500 - val_loss: 0.5634 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.56345 to 0.56315, saving model to best.model\n",
      "0s - loss: 0.6530 - acc: 0.6352 - val_loss: 0.5631 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.56315 to 0.56279, saving model to best.model\n",
      "0s - loss: 0.6613 - acc: 0.6389 - val_loss: 0.5628 - val_acc: 0.7500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6366 - acc: 0.6556 - val_loss: 0.5661 - val_acc: 0.7500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6332 - acc: 0.6519 - val_loss: 0.5716 - val_acc: 0.7500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.6173 - acc: 0.6630 - val_loss: 0.5759 - val_acc: 0.7500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6335 - acc: 0.6593 - val_loss: 0.5757 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.6377 - acc: 0.6389 - val_loss: 0.5764 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.6327 - acc: 0.6315 - val_loss: 0.5768 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5980 - acc: 0.6667 - val_loss: 0.5743 - val_acc: 0.7667\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.6248 - acc: 0.6667 - val_loss: 0.5692 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.6065 - acc: 0.6815 - val_loss: 0.5657 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.6222 - acc: 0.6574 - val_loss: 0.5670 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.6214 - acc: 0.6667 - val_loss: 0.5696 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.6088 - acc: 0.6833 - val_loss: 0.5697 - val_acc: 0.7833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.6134 - acc: 0.6778 - val_loss: 0.5678 - val_acc: 0.7833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5950 - acc: 0.6815 - val_loss: 0.5645 - val_acc: 0.7833\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.56279 to 0.55946, saving model to best.model\n",
      "0s - loss: 0.6116 - acc: 0.6593 - val_loss: 0.5595 - val_acc: 0.7833\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.55946 to 0.55213, saving model to best.model\n",
      "0s - loss: 0.5933 - acc: 0.6704 - val_loss: 0.5521 - val_acc: 0.8000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.55213 to 0.54644, saving model to best.model\n",
      "0s - loss: 0.6019 - acc: 0.6796 - val_loss: 0.5464 - val_acc: 0.8000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.54644 to 0.54019, saving model to best.model\n",
      "0s - loss: 0.5667 - acc: 0.7019 - val_loss: 0.5402 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.54019 to 0.53681, saving model to best.model\n",
      "0s - loss: 0.6076 - acc: 0.6815 - val_loss: 0.5368 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.6156 - acc: 0.6759 - val_loss: 0.5385 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.6202 - acc: 0.6556 - val_loss: 0.5434 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5620 - acc: 0.7000 - val_loss: 0.5471 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.6094 - acc: 0.6926 - val_loss: 0.5487 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5744 - acc: 0.7167 - val_loss: 0.5466 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5852 - acc: 0.6870 - val_loss: 0.5398 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.53681 to 0.52711, saving model to best.model\n",
      "0s - loss: 0.5674 - acc: 0.6981 - val_loss: 0.5271 - val_acc: 0.7333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.52711 to 0.51598, saving model to best.model\n",
      "0s - loss: 0.5923 - acc: 0.6778 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.51598 to 0.50922, saving model to best.model\n",
      "0s - loss: 0.5921 - acc: 0.6944 - val_loss: 0.5092 - val_acc: 0.7500\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.50922 to 0.50657, saving model to best.model\n",
      "0s - loss: 0.5567 - acc: 0.6889 - val_loss: 0.5066 - val_acc: 0.7500\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.50657 to 0.50515, saving model to best.model\n",
      "0s - loss: 0.5851 - acc: 0.7037 - val_loss: 0.5052 - val_acc: 0.7500\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5637 - acc: 0.7167 - val_loss: 0.5076 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5551 - acc: 0.7185 - val_loss: 0.5086 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5714 - acc: 0.7000 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5502 - acc: 0.7074 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5479 - acc: 0.7426 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5721 - acc: 0.7074 - val_loss: 0.5123 - val_acc: 0.7667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5647 - acc: 0.7222 - val_loss: 0.5104 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5430 - acc: 0.7333 - val_loss: 0.5076 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5710 - acc: 0.7019 - val_loss: 0.5092 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5545 - acc: 0.6963 - val_loss: 0.5104 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5526 - acc: 0.7148 - val_loss: 0.5105 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.5879 - acc: 0.7093 - val_loss: 0.5098 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5471 - acc: 0.7074 - val_loss: 0.5071 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.5670 - acc: 0.6907 - val_loss: 0.5064 - val_acc: 0.7333\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5483 - acc: 0.7241 - val_loss: 0.5056 - val_acc: 0.7333\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.50515 to 0.50062, saving model to best.model\n",
      "0s - loss: 0.5576 - acc: 0.7296 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.50062 to 0.49776, saving model to best.model\n",
      "0s - loss: 0.5506 - acc: 0.7352 - val_loss: 0.4978 - val_acc: 0.7500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.5238 - acc: 0.7537 - val_loss: 0.4982 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.5476 - acc: 0.7093 - val_loss: 0.5069 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.5403 - acc: 0.7037 - val_loss: 0.5134 - val_acc: 0.7833\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.5202 - acc: 0.7333 - val_loss: 0.5134 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.5301 - acc: 0.7352 - val_loss: 0.5107 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.5312 - acc: 0.7278 - val_loss: 0.5027 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.49776 to 0.49219, saving model to best.model\n",
      "0s - loss: 0.5376 - acc: 0.7093 - val_loss: 0.4922 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.49219 to 0.48594, saving model to best.model\n",
      "0s - loss: 0.5361 - acc: 0.7296 - val_loss: 0.4859 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.48594 to 0.48030, saving model to best.model\n",
      "0s - loss: 0.5239 - acc: 0.7278 - val_loss: 0.4803 - val_acc: 0.7500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.48030 to 0.47950, saving model to best.model\n",
      "0s - loss: 0.5503 - acc: 0.7093 - val_loss: 0.4795 - val_acc: 0.7500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.5246 - acc: 0.7278 - val_loss: 0.4809 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.5389 - acc: 0.7056 - val_loss: 0.4898 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.5299 - acc: 0.7370 - val_loss: 0.5080 - val_acc: 0.7667\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.5236 - acc: 0.7481 - val_loss: 0.5180 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.5203 - acc: 0.7500 - val_loss: 0.5135 - val_acc: 0.8000\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.5267 - acc: 0.7407 - val_loss: 0.4984 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.5128 - acc: 0.7444 - val_loss: 0.4827 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.47950 to 0.47459, saving model to best.model\n",
      "0s - loss: 0.5337 - acc: 0.7167 - val_loss: 0.4746 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.47459 to 0.47000, saving model to best.model\n",
      "0s - loss: 0.5175 - acc: 0.7426 - val_loss: 0.4700 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.5116 - acc: 0.7481 - val_loss: 0.4701 - val_acc: 0.8000\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.5211 - acc: 0.7333 - val_loss: 0.4718 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.5285 - acc: 0.7426 - val_loss: 0.4723 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.5336 - acc: 0.7333 - val_loss: 0.4760 - val_acc: 0.7667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.5067 - acc: 0.7556 - val_loss: 0.4814 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.5078 - acc: 0.7407 - val_loss: 0.4899 - val_acc: 0.7500\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.5205 - acc: 0.7241 - val_loss: 0.4942 - val_acc: 0.7500\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4934 - acc: 0.7444 - val_loss: 0.4963 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4961 - acc: 0.7519 - val_loss: 0.4958 - val_acc: 0.7500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.5140 - acc: 0.7537 - val_loss: 0.4920 - val_acc: 0.7500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.5121 - acc: 0.7407 - val_loss: 0.4885 - val_acc: 0.7667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4902 - acc: 0.7574 - val_loss: 0.4850 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4990 - acc: 0.7333 - val_loss: 0.4817 - val_acc: 0.7833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.5071 - acc: 0.7630 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4936 - acc: 0.7333 - val_loss: 0.4745 - val_acc: 0.8000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4846 - acc: 0.7667 - val_loss: 0.4748 - val_acc: 0.7833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.5040 - acc: 0.7667 - val_loss: 0.4764 - val_acc: 0.7500\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4887 - acc: 0.7667 - val_loss: 0.4754 - val_acc: 0.7500\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4991 - acc: 0.7574 - val_loss: 0.4750 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4906 - acc: 0.7593 - val_loss: 0.4751 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4751 - acc: 0.7611 - val_loss: 0.4828 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4964 - acc: 0.7722 - val_loss: 0.4879 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4773 - acc: 0.7833 - val_loss: 0.4876 - val_acc: 0.7500\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4960 - acc: 0.7481 - val_loss: 0.4866 - val_acc: 0.7667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4887 - acc: 0.7463 - val_loss: 0.4885 - val_acc: 0.7500\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4895 - acc: 0.7593 - val_loss: 0.4942 - val_acc: 0.7500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.54398, saving model to best.model\n",
      "0s - loss: 0.7753 - acc: 0.6167 - val_loss: 0.5440 - val_acc: 0.7667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.54398 to 0.52884, saving model to best.model\n",
      "0s - loss: 0.7119 - acc: 0.6556 - val_loss: 0.5288 - val_acc: 0.7667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.6901 - acc: 0.6741 - val_loss: 0.5340 - val_acc: 0.7667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.7010 - acc: 0.6704 - val_loss: 0.5417 - val_acc: 0.7667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6287 - acc: 0.6778 - val_loss: 0.5575 - val_acc: 0.8167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6267 - acc: 0.6593 - val_loss: 0.5717 - val_acc: 0.8167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6466 - acc: 0.6407 - val_loss: 0.5805 - val_acc: 0.8333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6799 - acc: 0.6148 - val_loss: 0.5703 - val_acc: 0.8333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6389 - acc: 0.6722 - val_loss: 0.5511 - val_acc: 0.8333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6243 - acc: 0.6352 - val_loss: 0.5359 - val_acc: 0.8500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.52884 to 0.52424, saving model to best.model\n",
      "0s - loss: 0.5953 - acc: 0.6833 - val_loss: 0.5242 - val_acc: 0.8500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.52424 to 0.51165, saving model to best.model\n",
      "0s - loss: 0.6084 - acc: 0.6852 - val_loss: 0.5117 - val_acc: 0.8500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.51165 to 0.50543, saving model to best.model\n",
      "0s - loss: 0.5976 - acc: 0.6759 - val_loss: 0.5054 - val_acc: 0.8500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6156 - acc: 0.6870 - val_loss: 0.5070 - val_acc: 0.8500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5909 - acc: 0.7000 - val_loss: 0.5107 - val_acc: 0.8667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5928 - acc: 0.6944 - val_loss: 0.5105 - val_acc: 0.8500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.6048 - acc: 0.6833 - val_loss: 0.5076 - val_acc: 0.8500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5712 - acc: 0.7074 - val_loss: 0.5072 - val_acc: 0.8500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5847 - acc: 0.7130 - val_loss: 0.5068 - val_acc: 0.8500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.50543 to 0.50537, saving model to best.model\n",
      "0s - loss: 0.5591 - acc: 0.7148 - val_loss: 0.5054 - val_acc: 0.8500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5659 - acc: 0.7130 - val_loss: 0.5057 - val_acc: 0.8333\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.50537 to 0.50522, saving model to best.model\n",
      "0s - loss: 0.5731 - acc: 0.7019 - val_loss: 0.5052 - val_acc: 0.8333\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5861 - acc: 0.6944 - val_loss: 0.5080 - val_acc: 0.8333\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5592 - acc: 0.7037 - val_loss: 0.5116 - val_acc: 0.8167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5601 - acc: 0.7167 - val_loss: 0.5122 - val_acc: 0.7833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5473 - acc: 0.7278 - val_loss: 0.5071 - val_acc: 0.8000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.50522 to 0.49575, saving model to best.model\n",
      "0s - loss: 0.5800 - acc: 0.6944 - val_loss: 0.4957 - val_acc: 0.8000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.49575 to 0.48638, saving model to best.model\n",
      "0s - loss: 0.5517 - acc: 0.7093 - val_loss: 0.4864 - val_acc: 0.8000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.48638 to 0.48351, saving model to best.model\n",
      "0s - loss: 0.5547 - acc: 0.7130 - val_loss: 0.4835 - val_acc: 0.8000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.48351 to 0.48191, saving model to best.model\n",
      "0s - loss: 0.5527 - acc: 0.7130 - val_loss: 0.4819 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.48191 to 0.47694, saving model to best.model\n",
      "0s - loss: 0.5525 - acc: 0.7352 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.47694 to 0.46767, saving model to best.model\n",
      "0s - loss: 0.5288 - acc: 0.7222 - val_loss: 0.4677 - val_acc: 0.8000\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.46767 to 0.46101, saving model to best.model\n",
      "0s - loss: 0.5353 - acc: 0.7148 - val_loss: 0.4610 - val_acc: 0.8000\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.46101 to 0.45680, saving model to best.model\n",
      "0s - loss: 0.5358 - acc: 0.7315 - val_loss: 0.4568 - val_acc: 0.8000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.45680 to 0.45461, saving model to best.model\n",
      "0s - loss: 0.5325 - acc: 0.7315 - val_loss: 0.4546 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.45461 to 0.45147, saving model to best.model\n",
      "0s - loss: 0.5405 - acc: 0.7111 - val_loss: 0.4515 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5436 - acc: 0.7315 - val_loss: 0.4538 - val_acc: 0.8167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5413 - acc: 0.7444 - val_loss: 0.4596 - val_acc: 0.8000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5272 - acc: 0.7352 - val_loss: 0.4655 - val_acc: 0.8167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5303 - acc: 0.7315 - val_loss: 0.4748 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5090 - acc: 0.7519 - val_loss: 0.4798 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5371 - acc: 0.7444 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5067 - acc: 0.7481 - val_loss: 0.4634 - val_acc: 0.8167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.45147 to 0.44897, saving model to best.model\n",
      "0s - loss: 0.5223 - acc: 0.7259 - val_loss: 0.4490 - val_acc: 0.8333\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.44897 to 0.43906, saving model to best.model\n",
      "0s - loss: 0.5404 - acc: 0.7333 - val_loss: 0.4391 - val_acc: 0.8333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.43906 to 0.43057, saving model to best.model\n",
      "0s - loss: 0.5164 - acc: 0.7574 - val_loss: 0.4306 - val_acc: 0.8333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.43057 to 0.42557, saving model to best.model\n",
      "0s - loss: 0.5172 - acc: 0.7352 - val_loss: 0.4256 - val_acc: 0.8500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5094 - acc: 0.7556 - val_loss: 0.4257 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5163 - acc: 0.7296 - val_loss: 0.4292 - val_acc: 0.8500\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5146 - acc: 0.7389 - val_loss: 0.4370 - val_acc: 0.8500\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5059 - acc: 0.7426 - val_loss: 0.4478 - val_acc: 0.8167\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4956 - acc: 0.7426 - val_loss: 0.4564 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5064 - acc: 0.7537 - val_loss: 0.4622 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.5168 - acc: 0.7519 - val_loss: 0.4706 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5024 - acc: 0.7667 - val_loss: 0.4738 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4989 - acc: 0.7648 - val_loss: 0.4727 - val_acc: 0.7833\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5004 - acc: 0.7685 - val_loss: 0.4754 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5045 - acc: 0.7667 - val_loss: 0.4776 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4942 - acc: 0.7519 - val_loss: 0.4688 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4773 - acc: 0.7907 - val_loss: 0.4567 - val_acc: 0.8000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4940 - acc: 0.7704 - val_loss: 0.4438 - val_acc: 0.8000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4642 - acc: 0.7833 - val_loss: 0.4305 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.42557 to 0.42062, saving model to best.model\n",
      "0s - loss: 0.4940 - acc: 0.7556 - val_loss: 0.4206 - val_acc: 0.8167\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.42062 to 0.41342, saving model to best.model\n",
      "0s - loss: 0.5039 - acc: 0.7815 - val_loss: 0.4134 - val_acc: 0.8167\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.41342 to 0.40838, saving model to best.model\n",
      "0s - loss: 0.5108 - acc: 0.7519 - val_loss: 0.4084 - val_acc: 0.8167\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.40838 to 0.40470, saving model to best.model\n",
      "0s - loss: 0.4603 - acc: 0.7944 - val_loss: 0.4047 - val_acc: 0.8333\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4886 - acc: 0.7370 - val_loss: 0.4098 - val_acc: 0.8167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4761 - acc: 0.7833 - val_loss: 0.4165 - val_acc: 0.8167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4636 - acc: 0.7722 - val_loss: 0.4214 - val_acc: 0.8333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4725 - acc: 0.7796 - val_loss: 0.4194 - val_acc: 0.8333\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4585 - acc: 0.7963 - val_loss: 0.4155 - val_acc: 0.8167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4733 - acc: 0.7778 - val_loss: 0.4103 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4481 - acc: 0.7833 - val_loss: 0.4072 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4714 - acc: 0.7630 - val_loss: 0.4155 - val_acc: 0.8333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4448 - acc: 0.8093 - val_loss: 0.4248 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4538 - acc: 0.7944 - val_loss: 0.4290 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4594 - acc: 0.7870 - val_loss: 0.4217 - val_acc: 0.8333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4721 - acc: 0.7759 - val_loss: 0.4144 - val_acc: 0.8333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4489 - acc: 0.7944 - val_loss: 0.4102 - val_acc: 0.8333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4656 - acc: 0.7870 - val_loss: 0.4119 - val_acc: 0.8167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4538 - acc: 0.7889 - val_loss: 0.4161 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4577 - acc: 0.7870 - val_loss: 0.4128 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4539 - acc: 0.7926 - val_loss: 0.4050 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.40470 to 0.40172, saving model to best.model\n",
      "0s - loss: 0.4628 - acc: 0.7907 - val_loss: 0.4017 - val_acc: 0.8167\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4625 - acc: 0.7778 - val_loss: 0.4021 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.40172 to 0.40154, saving model to best.model\n",
      "0s - loss: 0.4404 - acc: 0.8093 - val_loss: 0.4015 - val_acc: 0.8500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.40154 to 0.40072, saving model to best.model\n",
      "0s - loss: 0.4620 - acc: 0.7685 - val_loss: 0.4007 - val_acc: 0.8500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.40072 to 0.39916, saving model to best.model\n",
      "0s - loss: 0.4483 - acc: 0.7870 - val_loss: 0.3992 - val_acc: 0.8667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.39916 to 0.39630, saving model to best.model\n",
      "0s - loss: 0.4491 - acc: 0.8148 - val_loss: 0.3963 - val_acc: 0.8667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.39630 to 0.39225, saving model to best.model\n",
      "0s - loss: 0.4403 - acc: 0.7907 - val_loss: 0.3922 - val_acc: 0.8667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.39225 to 0.38687, saving model to best.model\n",
      "0s - loss: 0.4305 - acc: 0.7907 - val_loss: 0.3869 - val_acc: 0.8667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4609 - acc: 0.7741 - val_loss: 0.3885 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4542 - acc: 0.8241 - val_loss: 0.3924 - val_acc: 0.8667\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4230 - acc: 0.8019 - val_loss: 0.3963 - val_acc: 0.8667\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4272 - acc: 0.7870 - val_loss: 0.3991 - val_acc: 0.8667\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4238 - acc: 0.8185 - val_loss: 0.4002 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4298 - acc: 0.8222 - val_loss: 0.4099 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4403 - acc: 0.8185 - val_loss: 0.4154 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4491 - acc: 0.8000 - val_loss: 0.4175 - val_acc: 0.8167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4220 - acc: 0.7944 - val_loss: 0.4183 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4190 - acc: 0.8037 - val_loss: 0.4145 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4261 - acc: 0.7963 - val_loss: 0.4076 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4369 - acc: 0.8074 - val_loss: 0.4017 - val_acc: 0.8500\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3899 - acc: 0.8111 - val_loss: 0.3978 - val_acc: 0.8500\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4246 - acc: 0.8093 - val_loss: 0.3949 - val_acc: 0.8500\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3933 - acc: 0.8204 - val_loss: 0.3893 - val_acc: 0.8500\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.38687 to 0.38600, saving model to best.model\n",
      "0s - loss: 0.4127 - acc: 0.8111 - val_loss: 0.3860 - val_acc: 0.8667\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.38600 to 0.38395, saving model to best.model\n",
      "0s - loss: 0.3825 - acc: 0.8259 - val_loss: 0.3840 - val_acc: 0.8833\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3958 - acc: 0.8259 - val_loss: 0.3841 - val_acc: 0.8833\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.38395 to 0.38387, saving model to best.model\n",
      "0s - loss: 0.3897 - acc: 0.8093 - val_loss: 0.3839 - val_acc: 0.8833\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.38387 to 0.37624, saving model to best.model\n",
      "0s - loss: 0.3925 - acc: 0.8204 - val_loss: 0.3762 - val_acc: 0.8833\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.37624 to 0.36845, saving model to best.model\n",
      "0s - loss: 0.3997 - acc: 0.8352 - val_loss: 0.3685 - val_acc: 0.8667\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.36845 to 0.36627, saving model to best.model\n",
      "0s - loss: 0.4103 - acc: 0.7981 - val_loss: 0.3663 - val_acc: 0.8667\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3977 - acc: 0.8259 - val_loss: 0.3669 - val_acc: 0.8667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3973 - acc: 0.8148 - val_loss: 0.3707 - val_acc: 0.8667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4276 - acc: 0.8111 - val_loss: 0.3741 - val_acc: 0.8667\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3793 - acc: 0.8296 - val_loss: 0.3706 - val_acc: 0.8667\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3757 - acc: 0.8333 - val_loss: 0.3709 - val_acc: 0.8667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3769 - acc: 0.8352 - val_loss: 0.3826 - val_acc: 0.8500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.4012 - acc: 0.8204 - val_loss: 0.3974 - val_acc: 0.8667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3675 - acc: 0.8444 - val_loss: 0.4084 - val_acc: 0.8667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3668 - acc: 0.8167 - val_loss: 0.4146 - val_acc: 0.8667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.4068 - acc: 0.8148 - val_loss: 0.4087 - val_acc: 0.8500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3840 - acc: 0.8370 - val_loss: 0.4007 - val_acc: 0.8667\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3699 - acc: 0.8463 - val_loss: 0.3882 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3686 - acc: 0.8407 - val_loss: 0.3804 - val_acc: 0.8833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3754 - acc: 0.8426 - val_loss: 0.3811 - val_acc: 0.8833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3741 - acc: 0.8222 - val_loss: 0.3830 - val_acc: 0.8833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3741 - acc: 0.8278 - val_loss: 0.3867 - val_acc: 0.9000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3973 - acc: 0.8222 - val_loss: 0.3895 - val_acc: 0.9000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3307 - acc: 0.8704 - val_loss: 0.3874 - val_acc: 0.9000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3589 - acc: 0.8333 - val_loss: 0.3780 - val_acc: 0.9000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.36627 to 0.36608, saving model to best.model\n",
      "0s - loss: 0.3563 - acc: 0.8333 - val_loss: 0.3661 - val_acc: 0.9000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.36608 to 0.35267, saving model to best.model\n",
      "0s - loss: 0.3249 - acc: 0.8537 - val_loss: 0.3527 - val_acc: 0.9000\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.35267 to 0.34593, saving model to best.model\n",
      "0s - loss: 0.3704 - acc: 0.8259 - val_loss: 0.3459 - val_acc: 0.8833\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3450 - acc: 0.8389 - val_loss: 0.3465 - val_acc: 0.9000\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3506 - acc: 0.8519 - val_loss: 0.3508 - val_acc: 0.9000\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3575 - acc: 0.8593 - val_loss: 0.3630 - val_acc: 0.9000\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3431 - acc: 0.8741 - val_loss: 0.3760 - val_acc: 0.8667\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3376 - acc: 0.8722 - val_loss: 0.3656 - val_acc: 0.8833\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3292 - acc: 0.8630 - val_loss: 0.3531 - val_acc: 0.8833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3582 - acc: 0.8444 - val_loss: 0.3558 - val_acc: 0.8833\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3333 - acc: 0.8463 - val_loss: 0.3557 - val_acc: 0.8833\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3291 - acc: 0.8685 - val_loss: 0.3509 - val_acc: 0.9000\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.34593 to 0.34263, saving model to best.model\n",
      "0s - loss: 0.3301 - acc: 0.8611 - val_loss: 0.3426 - val_acc: 0.9000\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.34263 to 0.33601, saving model to best.model\n",
      "0s - loss: 0.3439 - acc: 0.8611 - val_loss: 0.3360 - val_acc: 0.9000\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.33601 to 0.33560, saving model to best.model\n",
      "0s - loss: 0.3519 - acc: 0.8407 - val_loss: 0.3356 - val_acc: 0.9000\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3021 - acc: 0.8685 - val_loss: 0.3421 - val_acc: 0.9000\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3163 - acc: 0.8611 - val_loss: 0.3485 - val_acc: 0.9000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3359 - acc: 0.8407 - val_loss: 0.3531 - val_acc: 0.9000\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3248 - acc: 0.8574 - val_loss: 0.3478 - val_acc: 0.9000\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.33560 to 0.33283, saving model to best.model\n",
      "0s - loss: 0.3546 - acc: 0.8481 - val_loss: 0.3328 - val_acc: 0.9000\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.33283 to 0.32442, saving model to best.model\n",
      "0s - loss: 0.3250 - acc: 0.8667 - val_loss: 0.3244 - val_acc: 0.9000\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.32442 to 0.32311, saving model to best.model\n",
      "0s - loss: 0.3371 - acc: 0.8630 - val_loss: 0.3231 - val_acc: 0.9000\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3316 - acc: 0.8611 - val_loss: 0.3259 - val_acc: 0.9000\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3279 - acc: 0.8648 - val_loss: 0.3347 - val_acc: 0.8833\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3279 - acc: 0.8685 - val_loss: 0.3511 - val_acc: 0.8667\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3384 - acc: 0.8574 - val_loss: 0.3596 - val_acc: 0.8667\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3688 - acc: 0.8389 - val_loss: 0.3453 - val_acc: 0.8833\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3217 - acc: 0.8500 - val_loss: 0.3256 - val_acc: 0.8833\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.32311 to 0.31620, saving model to best.model\n",
      "0s - loss: 0.3036 - acc: 0.8741 - val_loss: 0.3162 - val_acc: 0.9000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.31620 to 0.31244, saving model to best.model\n",
      "0s - loss: 0.3229 - acc: 0.8593 - val_loss: 0.3124 - val_acc: 0.9000\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2813 - acc: 0.8889 - val_loss: 0.3128 - val_acc: 0.9000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3013 - acc: 0.8852 - val_loss: 0.3136 - val_acc: 0.9000\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3101 - acc: 0.8704 - val_loss: 0.3131 - val_acc: 0.9000\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2921 - acc: 0.8833 - val_loss: 0.3146 - val_acc: 0.9000\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2818 - acc: 0.8963 - val_loss: 0.3169 - val_acc: 0.8833\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3043 - acc: 0.8815 - val_loss: 0.3193 - val_acc: 0.8833\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2895 - acc: 0.8815 - val_loss: 0.3209 - val_acc: 0.8833\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2889 - acc: 0.9000 - val_loss: 0.3252 - val_acc: 0.8833\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2929 - acc: 0.8759 - val_loss: 0.3268 - val_acc: 0.8833\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2948 - acc: 0.8741 - val_loss: 0.3193 - val_acc: 0.8833\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.31244 to 0.30806, saving model to best.model\n",
      "0s - loss: 0.3063 - acc: 0.8704 - val_loss: 0.3081 - val_acc: 0.9000\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2831 - acc: 0.8778 - val_loss: 0.3133 - val_acc: 0.9000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.3098 - acc: 0.8833 - val_loss: 0.3135 - val_acc: 0.9000\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2806 - acc: 0.8833 - val_loss: 0.3113 - val_acc: 0.9000\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2792 - acc: 0.8944 - val_loss: 0.3107 - val_acc: 0.9000\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2736 - acc: 0.8815 - val_loss: 0.3098 - val_acc: 0.8833\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.30806 to 0.30354, saving model to best.model\n",
      "0s - loss: 0.2955 - acc: 0.8556 - val_loss: 0.3035 - val_acc: 0.8833\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.30354 to 0.29776, saving model to best.model\n",
      "0s - loss: 0.2753 - acc: 0.8778 - val_loss: 0.2978 - val_acc: 0.9000\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2959 - acc: 0.8759 - val_loss: 0.2982 - val_acc: 0.8833\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2618 - acc: 0.9000 - val_loss: 0.3050 - val_acc: 0.8667\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2512 - acc: 0.9056 - val_loss: 0.3229 - val_acc: 0.8833\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2781 - acc: 0.8907 - val_loss: 0.3494 - val_acc: 0.8667\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2816 - acc: 0.8889 - val_loss: 0.3761 - val_acc: 0.8333\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2825 - acc: 0.8889 - val_loss: 0.3821 - val_acc: 0.8167\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.3205 - acc: 0.8685 - val_loss: 0.3525 - val_acc: 0.8667\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2911 - acc: 0.8685 - val_loss: 0.3234 - val_acc: 0.8667\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2812 - acc: 0.8870 - val_loss: 0.3058 - val_acc: 0.8667\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.3020 - acc: 0.8704 - val_loss: 0.3068 - val_acc: 0.8667\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2979 - acc: 0.8833 - val_loss: 0.3164 - val_acc: 0.8667\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2767 - acc: 0.8889 - val_loss: 0.3301 - val_acc: 0.8667\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2801 - acc: 0.8981 - val_loss: 0.3325 - val_acc: 0.8667\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2537 - acc: 0.9000 - val_loss: 0.3146 - val_acc: 0.8833\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2712 - acc: 0.8870 - val_loss: 0.3009 - val_acc: 0.8833\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss improved from 0.29776 to 0.29490, saving model to best.model\n",
      "0s - loss: 0.2514 - acc: 0.8852 - val_loss: 0.2949 - val_acc: 0.8833\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2565 - acc: 0.8981 - val_loss: 0.2978 - val_acc: 0.8833\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2474 - acc: 0.9056 - val_loss: 0.3024 - val_acc: 0.8667\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2958 - acc: 0.8722 - val_loss: 0.3059 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2505 - acc: 0.9056 - val_loss: 0.3094 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58204, saving model to best.model\n",
      "0s - loss: 0.9167 - acc: 0.4981 - val_loss: 0.5820 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.58204 to 0.57397, saving model to best.model\n",
      "0s - loss: 0.7535 - acc: 0.6500 - val_loss: 0.5740 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.57397 to 0.56344, saving model to best.model\n",
      "0s - loss: 0.7155 - acc: 0.6481 - val_loss: 0.5634 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6997 - acc: 0.6315 - val_loss: 0.5678 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6784 - acc: 0.6111 - val_loss: 0.5737 - val_acc: 0.7333\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6993 - acc: 0.6204 - val_loss: 0.5761 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6681 - acc: 0.6315 - val_loss: 0.5724 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6381 - acc: 0.6481 - val_loss: 0.5706 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6685 - acc: 0.6481 - val_loss: 0.5690 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6067 - acc: 0.6741 - val_loss: 0.5678 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6303 - acc: 0.6611 - val_loss: 0.5688 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6417 - acc: 0.6444 - val_loss: 0.5712 - val_acc: 0.7167\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6196 - acc: 0.6574 - val_loss: 0.5710 - val_acc: 0.7167\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6323 - acc: 0.6574 - val_loss: 0.5687 - val_acc: 0.7167\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.6227 - acc: 0.6704 - val_loss: 0.5645 - val_acc: 0.7167\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.56344 to 0.56148, saving model to best.model\n",
      "0s - loss: 0.6298 - acc: 0.6574 - val_loss: 0.5615 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.56148 to 0.56066, saving model to best.model\n",
      "0s - loss: 0.6083 - acc: 0.6741 - val_loss: 0.5607 - val_acc: 0.7167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.6157 - acc: 0.6574 - val_loss: 0.5619 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.56066 to 0.56038, saving model to best.model\n",
      "0s - loss: 0.6117 - acc: 0.6741 - val_loss: 0.5604 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.56038 to 0.55713, saving model to best.model\n",
      "0s - loss: 0.6079 - acc: 0.6593 - val_loss: 0.5571 - val_acc: 0.7500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.55713 to 0.55197, saving model to best.model\n",
      "0s - loss: 0.5900 - acc: 0.6722 - val_loss: 0.5520 - val_acc: 0.7500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.55197 to 0.54490, saving model to best.model\n",
      "0s - loss: 0.6027 - acc: 0.6556 - val_loss: 0.5449 - val_acc: 0.7500\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.54490 to 0.54097, saving model to best.model\n",
      "0s - loss: 0.6015 - acc: 0.6704 - val_loss: 0.5410 - val_acc: 0.7667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.6009 - acc: 0.6907 - val_loss: 0.5425 - val_acc: 0.7667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.6160 - acc: 0.6630 - val_loss: 0.5442 - val_acc: 0.7667\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5888 - acc: 0.6926 - val_loss: 0.5454 - val_acc: 0.7333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5810 - acc: 0.7037 - val_loss: 0.5447 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5841 - acc: 0.6778 - val_loss: 0.5455 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5865 - acc: 0.6963 - val_loss: 0.5410 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.54097 to 0.53400, saving model to best.model\n",
      "0s - loss: 0.5893 - acc: 0.6944 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.53400 to 0.52903, saving model to best.model\n",
      "0s - loss: 0.5942 - acc: 0.6889 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.52903 to 0.52753, saving model to best.model\n",
      "0s - loss: 0.5830 - acc: 0.7000 - val_loss: 0.5275 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.52753 to 0.52750, saving model to best.model\n",
      "0s - loss: 0.5755 - acc: 0.7037 - val_loss: 0.5275 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5689 - acc: 0.7241 - val_loss: 0.5283 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5386 - acc: 0.7315 - val_loss: 0.5305 - val_acc: 0.7500\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5837 - acc: 0.7074 - val_loss: 0.5324 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5554 - acc: 0.7074 - val_loss: 0.5343 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5546 - acc: 0.6944 - val_loss: 0.5339 - val_acc: 0.7167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5790 - acc: 0.6852 - val_loss: 0.5308 - val_acc: 0.7167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.52750 to 0.52436, saving model to best.model\n",
      "0s - loss: 0.5419 - acc: 0.7352 - val_loss: 0.5244 - val_acc: 0.7333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.52436 to 0.51935, saving model to best.model\n",
      "0s - loss: 0.5374 - acc: 0.7333 - val_loss: 0.5193 - val_acc: 0.7333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.51935 to 0.51775, saving model to best.model\n",
      "0s - loss: 0.5518 - acc: 0.7167 - val_loss: 0.5178 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.51775 to 0.51642, saving model to best.model\n",
      "0s - loss: 0.5651 - acc: 0.7074 - val_loss: 0.5164 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5565 - acc: 0.7167 - val_loss: 0.5171 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5504 - acc: 0.7204 - val_loss: 0.5183 - val_acc: 0.7833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5491 - acc: 0.7241 - val_loss: 0.5209 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5420 - acc: 0.7093 - val_loss: 0.5271 - val_acc: 0.7667\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5423 - acc: 0.7426 - val_loss: 0.5318 - val_acc: 0.7667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5311 - acc: 0.7259 - val_loss: 0.5353 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5310 - acc: 0.7407 - val_loss: 0.5335 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5449 - acc: 0.7241 - val_loss: 0.5260 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.51642 to 0.51540, saving model to best.model\n",
      "0s - loss: 0.5296 - acc: 0.7352 - val_loss: 0.5154 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.51540 to 0.50580, saving model to best.model\n",
      "0s - loss: 0.5082 - acc: 0.7407 - val_loss: 0.5058 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.50580 to 0.50092, saving model to best.model\n",
      "0s - loss: 0.5270 - acc: 0.7259 - val_loss: 0.5009 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.50092 to 0.49864, saving model to best.model\n",
      "0s - loss: 0.5185 - acc: 0.7426 - val_loss: 0.4986 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.5285 - acc: 0.7444 - val_loss: 0.4998 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5299 - acc: 0.7259 - val_loss: 0.5016 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5381 - acc: 0.7500 - val_loss: 0.5013 - val_acc: 0.7833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5349 - acc: 0.7185 - val_loss: 0.5011 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.5211 - acc: 0.7389 - val_loss: 0.4988 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.49864 to 0.49770, saving model to best.model\n",
      "0s - loss: 0.5154 - acc: 0.7556 - val_loss: 0.4977 - val_acc: 0.7500\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.49770 to 0.49399, saving model to best.model\n",
      "0s - loss: 0.5264 - acc: 0.7389 - val_loss: 0.4940 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.49399 to 0.48741, saving model to best.model\n",
      "0s - loss: 0.5149 - acc: 0.7759 - val_loss: 0.4874 - val_acc: 0.7667\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.48741 to 0.48184, saving model to best.model\n",
      "0s - loss: 0.5201 - acc: 0.7556 - val_loss: 0.4818 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.48184 to 0.48080, saving model to best.model\n",
      "0s - loss: 0.5323 - acc: 0.7537 - val_loss: 0.4808 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.48080 to 0.47993, saving model to best.model\n",
      "0s - loss: 0.5013 - acc: 0.7370 - val_loss: 0.4799 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.47993 to 0.47894, saving model to best.model\n",
      "0s - loss: 0.5077 - acc: 0.7407 - val_loss: 0.4789 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.47894 to 0.47798, saving model to best.model\n",
      "0s - loss: 0.4991 - acc: 0.7463 - val_loss: 0.4780 - val_acc: 0.7667\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.47798 to 0.47585, saving model to best.model\n",
      "0s - loss: 0.4981 - acc: 0.7648 - val_loss: 0.4759 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.47585 to 0.47507, saving model to best.model\n",
      "0s - loss: 0.5038 - acc: 0.7574 - val_loss: 0.4751 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.47507 to 0.47438, saving model to best.model\n",
      "0s - loss: 0.5249 - acc: 0.7352 - val_loss: 0.4744 - val_acc: 0.7833\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.47438 to 0.47269, saving model to best.model\n",
      "0s - loss: 0.5059 - acc: 0.7481 - val_loss: 0.4727 - val_acc: 0.7833\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.47269 to 0.47187, saving model to best.model\n",
      "0s - loss: 0.5116 - acc: 0.7463 - val_loss: 0.4719 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4988 - acc: 0.7481 - val_loss: 0.4739 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.5015 - acc: 0.7759 - val_loss: 0.4753 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4933 - acc: 0.7704 - val_loss: 0.4750 - val_acc: 0.8000\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.5049 - acc: 0.7444 - val_loss: 0.4736 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4761 - acc: 0.7778 - val_loss: 0.4737 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4943 - acc: 0.7611 - val_loss: 0.4745 - val_acc: 0.8000\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.5081 - acc: 0.7593 - val_loss: 0.4751 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4885 - acc: 0.7444 - val_loss: 0.4740 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4622 - acc: 0.7944 - val_loss: 0.4727 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4825 - acc: 0.7796 - val_loss: 0.4721 - val_acc: 0.8000\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.47187 to 0.46965, saving model to best.model\n",
      "0s - loss: 0.4903 - acc: 0.7667 - val_loss: 0.4696 - val_acc: 0.8000\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.46965 to 0.46936, saving model to best.model\n",
      "0s - loss: 0.4892 - acc: 0.7741 - val_loss: 0.4694 - val_acc: 0.8000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.46936 to 0.46910, saving model to best.model\n",
      "0s - loss: 0.4801 - acc: 0.7759 - val_loss: 0.4691 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.46910 to 0.46532, saving model to best.model\n",
      "0s - loss: 0.4783 - acc: 0.7778 - val_loss: 0.4653 - val_acc: 0.7833\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.46532 to 0.46034, saving model to best.model\n",
      "0s - loss: 0.4708 - acc: 0.7870 - val_loss: 0.4603 - val_acc: 0.7833\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.46034 to 0.45631, saving model to best.model\n",
      "0s - loss: 0.4679 - acc: 0.7796 - val_loss: 0.4563 - val_acc: 0.7833\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.45631 to 0.45553, saving model to best.model\n",
      "0s - loss: 0.4640 - acc: 0.7833 - val_loss: 0.4555 - val_acc: 0.7833\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4670 - acc: 0.7870 - val_loss: 0.4564 - val_acc: 0.7833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4624 - acc: 0.7981 - val_loss: 0.4609 - val_acc: 0.7833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4699 - acc: 0.7778 - val_loss: 0.4641 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4860 - acc: 0.7685 - val_loss: 0.4634 - val_acc: 0.7833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4663 - acc: 0.7944 - val_loss: 0.4587 - val_acc: 0.7833\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.45553 to 0.45448, saving model to best.model\n",
      "0s - loss: 0.4352 - acc: 0.7907 - val_loss: 0.4545 - val_acc: 0.7833\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.45448 to 0.45085, saving model to best.model\n",
      "0s - loss: 0.4589 - acc: 0.8000 - val_loss: 0.4508 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.45085 to 0.44954, saving model to best.model\n",
      "0s - loss: 0.4504 - acc: 0.7944 - val_loss: 0.4495 - val_acc: 0.7833\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4741 - acc: 0.7907 - val_loss: 0.4522 - val_acc: 0.7833\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4409 - acc: 0.8019 - val_loss: 0.4537 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.44954 to 0.44920, saving model to best.model\n",
      "0s - loss: 0.4392 - acc: 0.8056 - val_loss: 0.4492 - val_acc: 0.7833\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.44920 to 0.44346, saving model to best.model\n",
      "0s - loss: 0.4474 - acc: 0.8037 - val_loss: 0.4435 - val_acc: 0.7833\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.44346 to 0.43906, saving model to best.model\n",
      "0s - loss: 0.4719 - acc: 0.7833 - val_loss: 0.4391 - val_acc: 0.7833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.43906 to 0.43773, saving model to best.model\n",
      "0s - loss: 0.4476 - acc: 0.7889 - val_loss: 0.4377 - val_acc: 0.7833\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4521 - acc: 0.8019 - val_loss: 0.4391 - val_acc: 0.8000\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4744 - acc: 0.7815 - val_loss: 0.4429 - val_acc: 0.8000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4574 - acc: 0.7907 - val_loss: 0.4465 - val_acc: 0.8000\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4426 - acc: 0.8000 - val_loss: 0.4456 - val_acc: 0.8000\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4580 - acc: 0.8037 - val_loss: 0.4423 - val_acc: 0.8000\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4202 - acc: 0.8111 - val_loss: 0.4411 - val_acc: 0.8000\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4509 - acc: 0.7833 - val_loss: 0.4390 - val_acc: 0.8000\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.43773 to 0.43536, saving model to best.model\n",
      "0s - loss: 0.4707 - acc: 0.7833 - val_loss: 0.4354 - val_acc: 0.7833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.43536 to 0.43269, saving model to best.model\n",
      "0s - loss: 0.4454 - acc: 0.8074 - val_loss: 0.4327 - val_acc: 0.7833\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4566 - acc: 0.7815 - val_loss: 0.4337 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4343 - acc: 0.8074 - val_loss: 0.4387 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4432 - acc: 0.8056 - val_loss: 0.4475 - val_acc: 0.7833\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.4367 - acc: 0.8000 - val_loss: 0.4551 - val_acc: 0.7833\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.4345 - acc: 0.8148 - val_loss: 0.4503 - val_acc: 0.7833\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.4241 - acc: 0.8204 - val_loss: 0.4388 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.43269 to 0.42826, saving model to best.model\n",
      "0s - loss: 0.4209 - acc: 0.8093 - val_loss: 0.4283 - val_acc: 0.8000\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.42826 to 0.42293, saving model to best.model\n",
      "0s - loss: 0.3859 - acc: 0.8185 - val_loss: 0.4229 - val_acc: 0.8000\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.42293 to 0.42274, saving model to best.model\n",
      "0s - loss: 0.4589 - acc: 0.8000 - val_loss: 0.4227 - val_acc: 0.8000\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.4437 - acc: 0.7926 - val_loss: 0.4262 - val_acc: 0.8000\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.4232 - acc: 0.8111 - val_loss: 0.4330 - val_acc: 0.8000\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.4130 - acc: 0.8074 - val_loss: 0.4415 - val_acc: 0.7833\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.4237 - acc: 0.8185 - val_loss: 0.4466 - val_acc: 0.7833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.4018 - acc: 0.8037 - val_loss: 0.4475 - val_acc: 0.7833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3993 - acc: 0.8296 - val_loss: 0.4402 - val_acc: 0.8000\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.4034 - acc: 0.8093 - val_loss: 0.4337 - val_acc: 0.8000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.4061 - acc: 0.8130 - val_loss: 0.4332 - val_acc: 0.8000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.4047 - acc: 0.8074 - val_loss: 0.4334 - val_acc: 0.8000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.4058 - acc: 0.8093 - val_loss: 0.4315 - val_acc: 0.7833\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3916 - acc: 0.8241 - val_loss: 0.4314 - val_acc: 0.8000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3730 - acc: 0.8407 - val_loss: 0.4379 - val_acc: 0.7667\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.4116 - acc: 0.8111 - val_loss: 0.4398 - val_acc: 0.7833\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3880 - acc: 0.8370 - val_loss: 0.4365 - val_acc: 0.7667\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3918 - acc: 0.8278 - val_loss: 0.4341 - val_acc: 0.7833\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3649 - acc: 0.8426 - val_loss: 0.4340 - val_acc: 0.8000\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3768 - acc: 0.8222 - val_loss: 0.4378 - val_acc: 0.8000\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3979 - acc: 0.8315 - val_loss: 0.4422 - val_acc: 0.7833\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3840 - acc: 0.8426 - val_loss: 0.4462 - val_acc: 0.7833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3800 - acc: 0.8481 - val_loss: 0.4482 - val_acc: 0.7833\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3940 - acc: 0.8370 - val_loss: 0.4453 - val_acc: 0.7833\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.4149 - acc: 0.8204 - val_loss: 0.4437 - val_acc: 0.8000\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3925 - acc: 0.8370 - val_loss: 0.4470 - val_acc: 0.7833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3818 - acc: 0.8259 - val_loss: 0.4518 - val_acc: 0.7833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3762 - acc: 0.8259 - val_loss: 0.4517 - val_acc: 0.7833\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3570 - acc: 0.8167 - val_loss: 0.4451 - val_acc: 0.7667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.50791, saving model to best.model\n",
      "0s - loss: 0.8868 - acc: 0.5185 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.50791 to 0.48026, saving model to best.model\n",
      "0s - loss: 0.7096 - acc: 0.6574 - val_loss: 0.4803 - val_acc: 0.8000\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.48026 to 0.47675, saving model to best.model\n",
      "0s - loss: 0.7152 - acc: 0.6537 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6577 - acc: 0.7000 - val_loss: 0.4799 - val_acc: 0.8000\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6486 - acc: 0.7037 - val_loss: 0.4855 - val_acc: 0.8000\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6316 - acc: 0.7111 - val_loss: 0.4960 - val_acc: 0.8000\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5884 - acc: 0.7167 - val_loss: 0.5061 - val_acc: 0.8000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6042 - acc: 0.6833 - val_loss: 0.5127 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5935 - acc: 0.7019 - val_loss: 0.5173 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5698 - acc: 0.7259 - val_loss: 0.5142 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5772 - acc: 0.7093 - val_loss: 0.5069 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5552 - acc: 0.7278 - val_loss: 0.4963 - val_acc: 0.7667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5462 - acc: 0.7241 - val_loss: 0.4868 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5561 - acc: 0.7259 - val_loss: 0.4828 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5183 - acc: 0.7333 - val_loss: 0.4847 - val_acc: 0.7667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5475 - acc: 0.7259 - val_loss: 0.4923 - val_acc: 0.7667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5377 - acc: 0.7500 - val_loss: 0.5009 - val_acc: 0.7667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5191 - acc: 0.7463 - val_loss: 0.5034 - val_acc: 0.7667\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5641 - acc: 0.7185 - val_loss: 0.5031 - val_acc: 0.7667\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.4932 - acc: 0.7574 - val_loss: 0.5090 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5147 - acc: 0.7593 - val_loss: 0.5109 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5281 - acc: 0.7222 - val_loss: 0.5087 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.4922 - acc: 0.7722 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5280 - acc: 0.7333 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5071 - acc: 0.7611 - val_loss: 0.5091 - val_acc: 0.8000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5087 - acc: 0.7630 - val_loss: 0.5110 - val_acc: 0.8167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5130 - acc: 0.7463 - val_loss: 0.5122 - val_acc: 0.8000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.4653 - acc: 0.7981 - val_loss: 0.5102 - val_acc: 0.8000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5282 - acc: 0.7426 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58118, saving model to best.model\n",
      "0s - loss: 0.8829 - acc: 0.4352 - val_loss: 0.5812 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.58118 to 0.55563, saving model to best.model\n",
      "0s - loss: 0.7468 - acc: 0.6037 - val_loss: 0.5556 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.55563 to 0.54874, saving model to best.model\n",
      "0s - loss: 0.7043 - acc: 0.6556 - val_loss: 0.5487 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.54874 to 0.54444, saving model to best.model\n",
      "0s - loss: 0.6863 - acc: 0.6741 - val_loss: 0.5444 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54444 to 0.54243, saving model to best.model\n",
      "0s - loss: 0.6446 - acc: 0.6852 - val_loss: 0.5424 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6497 - acc: 0.6870 - val_loss: 0.5435 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6431 - acc: 0.6667 - val_loss: 0.5449 - val_acc: 0.7167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6095 - acc: 0.6907 - val_loss: 0.5457 - val_acc: 0.7167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6385 - acc: 0.6463 - val_loss: 0.5472 - val_acc: 0.7167\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6104 - acc: 0.6833 - val_loss: 0.5459 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.54243 to 0.54170, saving model to best.model\n",
      "0s - loss: 0.6328 - acc: 0.6833 - val_loss: 0.5417 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.54170 to 0.53595, saving model to best.model\n",
      "0s - loss: 0.6088 - acc: 0.6481 - val_loss: 0.5359 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.53595 to 0.52979, saving model to best.model\n",
      "0s - loss: 0.6138 - acc: 0.6685 - val_loss: 0.5298 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.52979 to 0.52349, saving model to best.model\n",
      "0s - loss: 0.5990 - acc: 0.6833 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.52349 to 0.52087, saving model to best.model\n",
      "0s - loss: 0.5941 - acc: 0.7019 - val_loss: 0.5209 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.52087 to 0.52037, saving model to best.model\n",
      "0s - loss: 0.5869 - acc: 0.6815 - val_loss: 0.5204 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5972 - acc: 0.6926 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5864 - acc: 0.6870 - val_loss: 0.5251 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5628 - acc: 0.7185 - val_loss: 0.5266 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5543 - acc: 0.7074 - val_loss: 0.5246 - val_acc: 0.8000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5710 - acc: 0.7167 - val_loss: 0.5253 - val_acc: 0.8000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5733 - acc: 0.7130 - val_loss: 0.5268 - val_acc: 0.8167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5576 - acc: 0.7204 - val_loss: 0.5253 - val_acc: 0.8167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52037 to 0.51927, saving model to best.model\n",
      "0s - loss: 0.5812 - acc: 0.6907 - val_loss: 0.5193 - val_acc: 0.8167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.51927 to 0.51068, saving model to best.model\n",
      "0s - loss: 0.5516 - acc: 0.7407 - val_loss: 0.5107 - val_acc: 0.8167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.51068 to 0.50282, saving model to best.model\n",
      "0s - loss: 0.5599 - acc: 0.7148 - val_loss: 0.5028 - val_acc: 0.8167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.50282 to 0.49871, saving model to best.model\n",
      "0s - loss: 0.5741 - acc: 0.7093 - val_loss: 0.4987 - val_acc: 0.8167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.49871 to 0.49553, saving model to best.model\n",
      "0s - loss: 0.5715 - acc: 0.7130 - val_loss: 0.4955 - val_acc: 0.8167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.49553 to 0.49504, saving model to best.model\n",
      "0s - loss: 0.5706 - acc: 0.7111 - val_loss: 0.4950 - val_acc: 0.8167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5529 - acc: 0.7222 - val_loss: 0.4954 - val_acc: 0.8167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5580 - acc: 0.7111 - val_loss: 0.4956 - val_acc: 0.8167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.49504 to 0.49492, saving model to best.model\n",
      "0s - loss: 0.5526 - acc: 0.7370 - val_loss: 0.4949 - val_acc: 0.8167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5617 - acc: 0.7130 - val_loss: 0.4960 - val_acc: 0.8167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5604 - acc: 0.7222 - val_loss: 0.4991 - val_acc: 0.8167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5468 - acc: 0.7481 - val_loss: 0.4997 - val_acc: 0.8167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5213 - acc: 0.7463 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5304 - acc: 0.7352 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5527 - acc: 0.7167 - val_loss: 0.5011 - val_acc: 0.7833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5519 - acc: 0.7204 - val_loss: 0.4989 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5265 - acc: 0.7519 - val_loss: 0.4986 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5339 - acc: 0.7296 - val_loss: 0.4977 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5291 - acc: 0.7426 - val_loss: 0.4951 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.49492 to 0.49163, saving model to best.model\n",
      "0s - loss: 0.5362 - acc: 0.7481 - val_loss: 0.4916 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.49163 to 0.49030, saving model to best.model\n",
      "0s - loss: 0.5096 - acc: 0.7611 - val_loss: 0.4903 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.49030 to 0.48602, saving model to best.model\n",
      "0s - loss: 0.5186 - acc: 0.7389 - val_loss: 0.4860 - val_acc: 0.8167\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.48602 to 0.47981, saving model to best.model\n",
      "0s - loss: 0.5327 - acc: 0.7667 - val_loss: 0.4798 - val_acc: 0.8167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.47981 to 0.47471, saving model to best.model\n",
      "0s - loss: 0.5352 - acc: 0.7537 - val_loss: 0.4747 - val_acc: 0.8167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.47471 to 0.47107, saving model to best.model\n",
      "0s - loss: 0.5021 - acc: 0.7593 - val_loss: 0.4711 - val_acc: 0.8167\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5228 - acc: 0.7556 - val_loss: 0.4724 - val_acc: 0.8167\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5216 - acc: 0.7648 - val_loss: 0.4758 - val_acc: 0.8167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4968 - acc: 0.7889 - val_loss: 0.4796 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5063 - acc: 0.7481 - val_loss: 0.4836 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5200 - acc: 0.7593 - val_loss: 0.4828 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4864 - acc: 0.7759 - val_loss: 0.4750 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.47107 to 0.46671, saving model to best.model\n",
      "0s - loss: 0.4984 - acc: 0.7704 - val_loss: 0.4667 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.46671 to 0.46116, saving model to best.model\n",
      "0s - loss: 0.4898 - acc: 0.7870 - val_loss: 0.4612 - val_acc: 0.8167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.46116 to 0.45801, saving model to best.model\n",
      "0s - loss: 0.5183 - acc: 0.7463 - val_loss: 0.4580 - val_acc: 0.8167\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4926 - acc: 0.7704 - val_loss: 0.4584 - val_acc: 0.8167\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.45801 to 0.45789, saving model to best.model\n",
      "0s - loss: 0.5066 - acc: 0.7667 - val_loss: 0.4579 - val_acc: 0.8167\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.45789 to 0.45657, saving model to best.model\n",
      "0s - loss: 0.4824 - acc: 0.7704 - val_loss: 0.4566 - val_acc: 0.8167\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.45657 to 0.45566, saving model to best.model\n",
      "0s - loss: 0.5050 - acc: 0.7574 - val_loss: 0.4557 - val_acc: 0.8167\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4791 - acc: 0.7778 - val_loss: 0.4566 - val_acc: 0.8167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4830 - acc: 0.7759 - val_loss: 0.4601 - val_acc: 0.8167\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4840 - acc: 0.7685 - val_loss: 0.4645 - val_acc: 0.8000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4673 - acc: 0.8000 - val_loss: 0.4675 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4725 - acc: 0.7907 - val_loss: 0.4632 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4743 - acc: 0.7815 - val_loss: 0.4575 - val_acc: 0.8167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.45566 to 0.45402, saving model to best.model\n",
      "0s - loss: 0.4985 - acc: 0.7611 - val_loss: 0.4540 - val_acc: 0.8167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.45402 to 0.45033, saving model to best.model\n",
      "0s - loss: 0.4845 - acc: 0.7630 - val_loss: 0.4503 - val_acc: 0.8167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.45033 to 0.44554, saving model to best.model\n",
      "0s - loss: 0.4760 - acc: 0.7630 - val_loss: 0.4455 - val_acc: 0.8167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.44554 to 0.44253, saving model to best.model\n",
      "0s - loss: 0.4704 - acc: 0.7704 - val_loss: 0.4425 - val_acc: 0.8333\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.44253 to 0.43925, saving model to best.model\n",
      "0s - loss: 0.4603 - acc: 0.7667 - val_loss: 0.4392 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.43925 to 0.43885, saving model to best.model\n",
      "0s - loss: 0.4795 - acc: 0.7648 - val_loss: 0.4388 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4797 - acc: 0.7685 - val_loss: 0.4409 - val_acc: 0.8333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4713 - acc: 0.7759 - val_loss: 0.4424 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4553 - acc: 0.7852 - val_loss: 0.4400 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.43885 to 0.43780, saving model to best.model\n",
      "0s - loss: 0.4616 - acc: 0.7685 - val_loss: 0.4378 - val_acc: 0.8333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.43780 to 0.43452, saving model to best.model\n",
      "0s - loss: 0.4568 - acc: 0.7907 - val_loss: 0.4345 - val_acc: 0.8500\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.43452 to 0.43087, saving model to best.model\n",
      "0s - loss: 0.4594 - acc: 0.7759 - val_loss: 0.4309 - val_acc: 0.8500\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.43087 to 0.42913, saving model to best.model\n",
      "0s - loss: 0.4570 - acc: 0.7778 - val_loss: 0.4291 - val_acc: 0.8500\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4665 - acc: 0.7870 - val_loss: 0.4299 - val_acc: 0.8500\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4772 - acc: 0.7852 - val_loss: 0.4304 - val_acc: 0.8500\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4614 - acc: 0.7833 - val_loss: 0.4322 - val_acc: 0.8333\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4703 - acc: 0.8130 - val_loss: 0.4345 - val_acc: 0.8333\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4709 - acc: 0.7833 - val_loss: 0.4367 - val_acc: 0.8167\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4602 - acc: 0.7852 - val_loss: 0.4327 - val_acc: 0.8500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.42913 to 0.42791, saving model to best.model\n",
      "0s - loss: 0.4333 - acc: 0.7963 - val_loss: 0.4279 - val_acc: 0.8500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.42791 to 0.42531, saving model to best.model\n",
      "0s - loss: 0.4260 - acc: 0.8074 - val_loss: 0.4253 - val_acc: 0.8333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.42531 to 0.42500, saving model to best.model\n",
      "0s - loss: 0.4414 - acc: 0.8019 - val_loss: 0.4250 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4452 - acc: 0.8130 - val_loss: 0.4256 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4612 - acc: 0.7907 - val_loss: 0.4285 - val_acc: 0.8500\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4496 - acc: 0.7926 - val_loss: 0.4335 - val_acc: 0.8833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4585 - acc: 0.8111 - val_loss: 0.4368 - val_acc: 0.8833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4333 - acc: 0.8093 - val_loss: 0.4343 - val_acc: 0.8833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4374 - acc: 0.8074 - val_loss: 0.4301 - val_acc: 0.8833\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4322 - acc: 0.7963 - val_loss: 0.4280 - val_acc: 0.8833\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.42500 to 0.42259, saving model to best.model\n",
      "0s - loss: 0.4454 - acc: 0.7944 - val_loss: 0.4226 - val_acc: 0.8833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.42259 to 0.41637, saving model to best.model\n",
      "0s - loss: 0.4219 - acc: 0.8056 - val_loss: 0.4164 - val_acc: 0.8667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.41637 to 0.41312, saving model to best.model\n",
      "0s - loss: 0.4360 - acc: 0.7907 - val_loss: 0.4131 - val_acc: 0.8667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4039 - acc: 0.8278 - val_loss: 0.4132 - val_acc: 0.8833\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.41312 to 0.41298, saving model to best.model\n",
      "0s - loss: 0.4242 - acc: 0.7963 - val_loss: 0.4130 - val_acc: 0.8833\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.41298 to 0.40939, saving model to best.model\n",
      "0s - loss: 0.4122 - acc: 0.8056 - val_loss: 0.4094 - val_acc: 0.8667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.40939 to 0.40682, saving model to best.model\n",
      "0s - loss: 0.4241 - acc: 0.8185 - val_loss: 0.4068 - val_acc: 0.8667\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.40682 to 0.40337, saving model to best.model\n",
      "0s - loss: 0.4092 - acc: 0.8130 - val_loss: 0.4034 - val_acc: 0.8500\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3989 - acc: 0.8278 - val_loss: 0.4035 - val_acc: 0.8500\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4197 - acc: 0.8333 - val_loss: 0.4063 - val_acc: 0.8667\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4010 - acc: 0.8130 - val_loss: 0.4084 - val_acc: 0.8667\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3970 - acc: 0.8259 - val_loss: 0.4099 - val_acc: 0.8667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4238 - acc: 0.8093 - val_loss: 0.4118 - val_acc: 0.8667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4308 - acc: 0.8037 - val_loss: 0.4137 - val_acc: 0.8667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4250 - acc: 0.8222 - val_loss: 0.4135 - val_acc: 0.8833\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.4024 - acc: 0.8130 - val_loss: 0.4123 - val_acc: 0.8833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3800 - acc: 0.8352 - val_loss: 0.4122 - val_acc: 0.8833\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3609 - acc: 0.8481 - val_loss: 0.4088 - val_acc: 0.9000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3719 - acc: 0.8222 - val_loss: 0.4042 - val_acc: 0.9000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.40337 to 0.39967, saving model to best.model\n",
      "0s - loss: 0.3701 - acc: 0.8500 - val_loss: 0.3997 - val_acc: 0.9000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.39967 to 0.39465, saving model to best.model\n",
      "0s - loss: 0.4018 - acc: 0.8204 - val_loss: 0.3947 - val_acc: 0.8667\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.39465 to 0.39142, saving model to best.model\n",
      "0s - loss: 0.4096 - acc: 0.8148 - val_loss: 0.3914 - val_acc: 0.8833\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.39142 to 0.39064, saving model to best.model\n",
      "0s - loss: 0.3592 - acc: 0.8574 - val_loss: 0.3906 - val_acc: 0.8833\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3955 - acc: 0.8241 - val_loss: 0.3933 - val_acc: 0.8667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3830 - acc: 0.8315 - val_loss: 0.3969 - val_acc: 0.8667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3858 - acc: 0.8111 - val_loss: 0.3984 - val_acc: 0.8667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3719 - acc: 0.8222 - val_loss: 0.3977 - val_acc: 0.8667\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3749 - acc: 0.8204 - val_loss: 0.3986 - val_acc: 0.8667\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3674 - acc: 0.8296 - val_loss: 0.4024 - val_acc: 0.8833\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3796 - acc: 0.8259 - val_loss: 0.4075 - val_acc: 0.8833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3620 - acc: 0.8500 - val_loss: 0.4103 - val_acc: 0.8833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3677 - acc: 0.8426 - val_loss: 0.4141 - val_acc: 0.8667\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3270 - acc: 0.8574 - val_loss: 0.4170 - val_acc: 0.8667\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3359 - acc: 0.8537 - val_loss: 0.4165 - val_acc: 0.8833\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3599 - acc: 0.8556 - val_loss: 0.4113 - val_acc: 0.8667\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3696 - acc: 0.8574 - val_loss: 0.4093 - val_acc: 0.8667\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3591 - acc: 0.8370 - val_loss: 0.4104 - val_acc: 0.8833\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3610 - acc: 0.8500 - val_loss: 0.4131 - val_acc: 0.8833\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3463 - acc: 0.8500 - val_loss: 0.4158 - val_acc: 0.8667\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3391 - acc: 0.8667 - val_loss: 0.4180 - val_acc: 0.8667\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3644 - acc: 0.8444 - val_loss: 0.4228 - val_acc: 0.8667\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3527 - acc: 0.8463 - val_loss: 0.4239 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3424 - acc: 0.8685 - val_loss: 0.4254 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3372 - acc: 0.8500 - val_loss: 0.4265 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3423 - acc: 0.8463 - val_loss: 0.4213 - val_acc: 0.8500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3120 - acc: 0.8630 - val_loss: 0.4145 - val_acc: 0.8500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3304 - acc: 0.8630 - val_loss: 0.4091 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3271 - acc: 0.8593 - val_loss: 0.4033 - val_acc: 0.9000\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3514 - acc: 0.8426 - val_loss: 0.4012 - val_acc: 0.9000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.52260, saving model to best.model\n",
      "0s - loss: 0.9622 - acc: 0.4630 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.52260 to 0.52134, saving model to best.model\n",
      "0s - loss: 0.7116 - acc: 0.6759 - val_loss: 0.5213 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.52134 to 0.51355, saving model to best.model\n",
      "0s - loss: 0.7588 - acc: 0.6852 - val_loss: 0.5135 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.51355 to 0.51025, saving model to best.model\n",
      "0s - loss: 0.7097 - acc: 0.6963 - val_loss: 0.5102 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6302 - acc: 0.6926 - val_loss: 0.5181 - val_acc: 0.7333\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6271 - acc: 0.6870 - val_loss: 0.5300 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6366 - acc: 0.6741 - val_loss: 0.5404 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6231 - acc: 0.6815 - val_loss: 0.5504 - val_acc: 0.7667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6374 - acc: 0.6611 - val_loss: 0.5549 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6023 - acc: 0.6648 - val_loss: 0.5516 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5984 - acc: 0.6870 - val_loss: 0.5475 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5828 - acc: 0.6907 - val_loss: 0.5419 - val_acc: 0.7667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5890 - acc: 0.7074 - val_loss: 0.5329 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5823 - acc: 0.7222 - val_loss: 0.5245 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5574 - acc: 0.7185 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5946 - acc: 0.6963 - val_loss: 0.5240 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5732 - acc: 0.7111 - val_loss: 0.5257 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5726 - acc: 0.7019 - val_loss: 0.5264 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5720 - acc: 0.7130 - val_loss: 0.5252 - val_acc: 0.7333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5646 - acc: 0.7296 - val_loss: 0.5232 - val_acc: 0.7667\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5915 - acc: 0.7148 - val_loss: 0.5235 - val_acc: 0.7500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5688 - acc: 0.7315 - val_loss: 0.5273 - val_acc: 0.7500\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5647 - acc: 0.7204 - val_loss: 0.5282 - val_acc: 0.7500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5381 - acc: 0.7148 - val_loss: 0.5257 - val_acc: 0.7667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5571 - acc: 0.7167 - val_loss: 0.5251 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5552 - acc: 0.7296 - val_loss: 0.5210 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5185 - acc: 0.7463 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.51025 to 0.50306, saving model to best.model\n",
      "0s - loss: 0.5506 - acc: 0.7370 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.50306 to 0.49962, saving model to best.model\n",
      "0s - loss: 0.5246 - acc: 0.7370 - val_loss: 0.4996 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.49962 to 0.49865, saving model to best.model\n",
      "0s - loss: 0.5557 - acc: 0.7463 - val_loss: 0.4987 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.49865 to 0.49801, saving model to best.model\n",
      "0s - loss: 0.5637 - acc: 0.7204 - val_loss: 0.4980 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.49801 to 0.49439, saving model to best.model\n",
      "0s - loss: 0.5369 - acc: 0.7315 - val_loss: 0.4944 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.49439 to 0.49185, saving model to best.model\n",
      "0s - loss: 0.5319 - acc: 0.7037 - val_loss: 0.4919 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.49185 to 0.48812, saving model to best.model\n",
      "0s - loss: 0.5043 - acc: 0.7407 - val_loss: 0.4881 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.48812 to 0.48198, saving model to best.model\n",
      "0s - loss: 0.5280 - acc: 0.7333 - val_loss: 0.4820 - val_acc: 0.7500\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.48198 to 0.47666, saving model to best.model\n",
      "0s - loss: 0.5271 - acc: 0.7630 - val_loss: 0.4767 - val_acc: 0.7500\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.47666 to 0.47156, saving model to best.model\n",
      "0s - loss: 0.5233 - acc: 0.7519 - val_loss: 0.4716 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.47156 to 0.46632, saving model to best.model\n",
      "0s - loss: 0.4828 - acc: 0.7759 - val_loss: 0.4663 - val_acc: 0.7333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.46632 to 0.46091, saving model to best.model\n",
      "0s - loss: 0.4884 - acc: 0.7519 - val_loss: 0.4609 - val_acc: 0.7500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.46091 to 0.45974, saving model to best.model\n",
      "0s - loss: 0.5128 - acc: 0.7500 - val_loss: 0.4597 - val_acc: 0.7833\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5132 - acc: 0.7444 - val_loss: 0.4614 - val_acc: 0.7667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4980 - acc: 0.7722 - val_loss: 0.4634 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5257 - acc: 0.7463 - val_loss: 0.4692 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5140 - acc: 0.7593 - val_loss: 0.4748 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4957 - acc: 0.7556 - val_loss: 0.4717 - val_acc: 0.7833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4858 - acc: 0.7519 - val_loss: 0.4676 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.45974 to 0.45879, saving model to best.model\n",
      "0s - loss: 0.4910 - acc: 0.7463 - val_loss: 0.4588 - val_acc: 0.8167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.45879 to 0.44784, saving model to best.model\n",
      "0s - loss: 0.4714 - acc: 0.7796 - val_loss: 0.4478 - val_acc: 0.7833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.44784 to 0.43864, saving model to best.model\n",
      "0s - loss: 0.5057 - acc: 0.7481 - val_loss: 0.4386 - val_acc: 0.7833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.43864 to 0.43421, saving model to best.model\n",
      "0s - loss: 0.5116 - acc: 0.7611 - val_loss: 0.4342 - val_acc: 0.7833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.43421 to 0.43366, saving model to best.model\n",
      "0s - loss: 0.4639 - acc: 0.7815 - val_loss: 0.4337 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5202 - acc: 0.7426 - val_loss: 0.4354 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4840 - acc: 0.7519 - val_loss: 0.4379 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4836 - acc: 0.7685 - val_loss: 0.4399 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4548 - acc: 0.7926 - val_loss: 0.4403 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4725 - acc: 0.7593 - val_loss: 0.4397 - val_acc: 0.8167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4837 - acc: 0.7722 - val_loss: 0.4383 - val_acc: 0.8333\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.43366 to 0.43226, saving model to best.model\n",
      "0s - loss: 0.4734 - acc: 0.7741 - val_loss: 0.4323 - val_acc: 0.8333\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.43226 to 0.42554, saving model to best.model\n",
      "0s - loss: 0.4816 - acc: 0.7685 - val_loss: 0.4255 - val_acc: 0.8333\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.42554 to 0.41982, saving model to best.model\n",
      "0s - loss: 0.4522 - acc: 0.7963 - val_loss: 0.4198 - val_acc: 0.8333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.41982 to 0.41714, saving model to best.model\n",
      "0s - loss: 0.4716 - acc: 0.7981 - val_loss: 0.4171 - val_acc: 0.8333\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.41714 to 0.41706, saving model to best.model\n",
      "0s - loss: 0.4811 - acc: 0.7907 - val_loss: 0.4171 - val_acc: 0.8333\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4870 - acc: 0.7630 - val_loss: 0.4171 - val_acc: 0.8333\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4634 - acc: 0.7889 - val_loss: 0.4177 - val_acc: 0.8500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4478 - acc: 0.7926 - val_loss: 0.4194 - val_acc: 0.8500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4674 - acc: 0.7759 - val_loss: 0.4207 - val_acc: 0.8500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4755 - acc: 0.7889 - val_loss: 0.4206 - val_acc: 0.8500\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4602 - acc: 0.7833 - val_loss: 0.4194 - val_acc: 0.8500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4439 - acc: 0.7833 - val_loss: 0.4206 - val_acc: 0.8500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4837 - acc: 0.7778 - val_loss: 0.4221 - val_acc: 0.8500\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4596 - acc: 0.7815 - val_loss: 0.4263 - val_acc: 0.8333\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4522 - acc: 0.8019 - val_loss: 0.4269 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4421 - acc: 0.7833 - val_loss: 0.4217 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4585 - acc: 0.7944 - val_loss: 0.4202 - val_acc: 0.8500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.41706 to 0.41607, saving model to best.model\n",
      "0s - loss: 0.4719 - acc: 0.7963 - val_loss: 0.4161 - val_acc: 0.8500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.41607 to 0.41080, saving model to best.model\n",
      "0s - loss: 0.4631 - acc: 0.7796 - val_loss: 0.4108 - val_acc: 0.8500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.41080 to 0.40863, saving model to best.model\n",
      "0s - loss: 0.4509 - acc: 0.8056 - val_loss: 0.4086 - val_acc: 0.8500\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.40863 to 0.40615, saving model to best.model\n",
      "0s - loss: 0.4644 - acc: 0.7963 - val_loss: 0.4062 - val_acc: 0.8500\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.40615 to 0.40414, saving model to best.model\n",
      "0s - loss: 0.4288 - acc: 0.8037 - val_loss: 0.4041 - val_acc: 0.8500\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.40414 to 0.40170, saving model to best.model\n",
      "0s - loss: 0.4421 - acc: 0.7907 - val_loss: 0.4017 - val_acc: 0.8333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4364 - acc: 0.8056 - val_loss: 0.4033 - val_acc: 0.8667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4690 - acc: 0.7833 - val_loss: 0.4094 - val_acc: 0.8667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4238 - acc: 0.8074 - val_loss: 0.4121 - val_acc: 0.8500\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4593 - acc: 0.7963 - val_loss: 0.4121 - val_acc: 0.8500\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4330 - acc: 0.7981 - val_loss: 0.4086 - val_acc: 0.8500\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4492 - acc: 0.7796 - val_loss: 0.4057 - val_acc: 0.8500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4257 - acc: 0.8056 - val_loss: 0.4071 - val_acc: 0.8500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4206 - acc: 0.8130 - val_loss: 0.4092 - val_acc: 0.8500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4446 - acc: 0.8074 - val_loss: 0.4151 - val_acc: 0.8667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4275 - acc: 0.7981 - val_loss: 0.4065 - val_acc: 0.8667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.40170 to 0.39733, saving model to best.model\n",
      "0s - loss: 0.4281 - acc: 0.8037 - val_loss: 0.3973 - val_acc: 0.8667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4184 - acc: 0.7870 - val_loss: 0.4012 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4399 - acc: 0.7981 - val_loss: 0.4070 - val_acc: 0.8667\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4208 - acc: 0.8074 - val_loss: 0.4098 - val_acc: 0.9000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4075 - acc: 0.8222 - val_loss: 0.4074 - val_acc: 0.9000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.39733 to 0.39474, saving model to best.model\n",
      "0s - loss: 0.4105 - acc: 0.7944 - val_loss: 0.3947 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.39474 to 0.38017, saving model to best.model\n",
      "0s - loss: 0.4360 - acc: 0.8111 - val_loss: 0.3802 - val_acc: 0.8500\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.38017 to 0.37096, saving model to best.model\n",
      "0s - loss: 0.4137 - acc: 0.7944 - val_loss: 0.3710 - val_acc: 0.8667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.37096 to 0.36566, saving model to best.model\n",
      "0s - loss: 0.4173 - acc: 0.8241 - val_loss: 0.3657 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.36566 to 0.36419, saving model to best.model\n",
      "0s - loss: 0.4349 - acc: 0.7981 - val_loss: 0.3642 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4095 - acc: 0.8259 - val_loss: 0.3676 - val_acc: 0.8667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3993 - acc: 0.8333 - val_loss: 0.3749 - val_acc: 0.8667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3892 - acc: 0.8352 - val_loss: 0.3824 - val_acc: 0.8833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4132 - acc: 0.8093 - val_loss: 0.3837 - val_acc: 0.9167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4005 - acc: 0.8130 - val_loss: 0.3769 - val_acc: 0.9167\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4021 - acc: 0.8259 - val_loss: 0.3691 - val_acc: 0.9167\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss improved from 0.36419 to 0.36126, saving model to best.model\n",
      "0s - loss: 0.3788 - acc: 0.8389 - val_loss: 0.3613 - val_acc: 0.8833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.36126 to 0.35394, saving model to best.model\n",
      "0s - loss: 0.4066 - acc: 0.8204 - val_loss: 0.3539 - val_acc: 0.8833\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.35394 to 0.35006, saving model to best.model\n",
      "0s - loss: 0.3907 - acc: 0.8148 - val_loss: 0.3501 - val_acc: 0.8833\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.35006 to 0.34610, saving model to best.model\n",
      "0s - loss: 0.3862 - acc: 0.8333 - val_loss: 0.3461 - val_acc: 0.8833\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.34610 to 0.34365, saving model to best.model\n",
      "0s - loss: 0.3955 - acc: 0.8278 - val_loss: 0.3437 - val_acc: 0.8833\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.34365 to 0.34261, saving model to best.model\n",
      "0s - loss: 0.3954 - acc: 0.8185 - val_loss: 0.3426 - val_acc: 0.9167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3830 - acc: 0.8352 - val_loss: 0.3446 - val_acc: 0.9167\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3756 - acc: 0.8463 - val_loss: 0.3461 - val_acc: 0.9167\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3928 - acc: 0.8352 - val_loss: 0.3466 - val_acc: 0.9167\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3788 - acc: 0.8222 - val_loss: 0.3516 - val_acc: 0.9000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3659 - acc: 0.8519 - val_loss: 0.3610 - val_acc: 0.9000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3590 - acc: 0.8352 - val_loss: 0.3668 - val_acc: 0.9000\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3708 - acc: 0.8444 - val_loss: 0.3744 - val_acc: 0.9000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3699 - acc: 0.8407 - val_loss: 0.3763 - val_acc: 0.9000\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3448 - acc: 0.8556 - val_loss: 0.3734 - val_acc: 0.9000\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3698 - acc: 0.8463 - val_loss: 0.3717 - val_acc: 0.9000\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3756 - acc: 0.8370 - val_loss: 0.3681 - val_acc: 0.9000\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3398 - acc: 0.8463 - val_loss: 0.3569 - val_acc: 0.9000\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3724 - acc: 0.8500 - val_loss: 0.3491 - val_acc: 0.8833\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3723 - acc: 0.8519 - val_loss: 0.3461 - val_acc: 0.8833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3621 - acc: 0.8463 - val_loss: 0.3454 - val_acc: 0.9000\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3534 - acc: 0.8463 - val_loss: 0.3480 - val_acc: 0.8833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3709 - acc: 0.8407 - val_loss: 0.3544 - val_acc: 0.9000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3601 - acc: 0.8259 - val_loss: 0.3615 - val_acc: 0.9000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3547 - acc: 0.8481 - val_loss: 0.3593 - val_acc: 0.8833\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3634 - acc: 0.8370 - val_loss: 0.3547 - val_acc: 0.8833\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3420 - acc: 0.8500 - val_loss: 0.3537 - val_acc: 0.8667\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3481 - acc: 0.8481 - val_loss: 0.3490 - val_acc: 0.8667\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3465 - acc: 0.8463 - val_loss: 0.3426 - val_acc: 0.8667\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.34261 to 0.33529, saving model to best.model\n",
      "0s - loss: 0.3268 - acc: 0.8593 - val_loss: 0.3353 - val_acc: 0.8667\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.33529 to 0.33146, saving model to best.model\n",
      "0s - loss: 0.3482 - acc: 0.8407 - val_loss: 0.3315 - val_acc: 0.8833\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3412 - acc: 0.8556 - val_loss: 0.3336 - val_acc: 0.9000\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3179 - acc: 0.8741 - val_loss: 0.3401 - val_acc: 0.9000\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3194 - acc: 0.8630 - val_loss: 0.3440 - val_acc: 0.9000\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3249 - acc: 0.8759 - val_loss: 0.3409 - val_acc: 0.8833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3414 - acc: 0.8407 - val_loss: 0.3389 - val_acc: 0.8667\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3425 - acc: 0.8611 - val_loss: 0.3350 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.33146 to 0.32959, saving model to best.model\n",
      "0s - loss: 0.3184 - acc: 0.8685 - val_loss: 0.3296 - val_acc: 0.8833\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.32959 to 0.32292, saving model to best.model\n",
      "0s - loss: 0.3074 - acc: 0.8778 - val_loss: 0.3229 - val_acc: 0.8833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.32292 to 0.31614, saving model to best.model\n",
      "0s - loss: 0.3440 - acc: 0.8722 - val_loss: 0.3161 - val_acc: 0.8833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.31614 to 0.30996, saving model to best.model\n",
      "0s - loss: 0.3172 - acc: 0.8722 - val_loss: 0.3100 - val_acc: 0.8833\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.30996 to 0.30685, saving model to best.model\n",
      "0s - loss: 0.3153 - acc: 0.8556 - val_loss: 0.3068 - val_acc: 0.8833\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.2915 - acc: 0.8722 - val_loss: 0.3086 - val_acc: 0.9000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3177 - acc: 0.8778 - val_loss: 0.3167 - val_acc: 0.9000\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3231 - acc: 0.8778 - val_loss: 0.3199 - val_acc: 0.9000\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.2785 - acc: 0.8833 - val_loss: 0.3183 - val_acc: 0.8833\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3111 - acc: 0.8648 - val_loss: 0.3186 - val_acc: 0.9000\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3080 - acc: 0.8722 - val_loss: 0.3222 - val_acc: 0.9000\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3510 - acc: 0.8611 - val_loss: 0.3338 - val_acc: 0.9000\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3152 - acc: 0.8704 - val_loss: 0.3426 - val_acc: 0.9000\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.2995 - acc: 0.8667 - val_loss: 0.3455 - val_acc: 0.9000\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3230 - acc: 0.8593 - val_loss: 0.3401 - val_acc: 0.8667\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3503 - acc: 0.8519 - val_loss: 0.3284 - val_acc: 0.8667\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3102 - acc: 0.8815 - val_loss: 0.3191 - val_acc: 0.8667\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2929 - acc: 0.8852 - val_loss: 0.3155 - val_acc: 0.8667\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2821 - acc: 0.8963 - val_loss: 0.3185 - val_acc: 0.8667\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3202 - acc: 0.8500 - val_loss: 0.3229 - val_acc: 0.8833\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2827 - acc: 0.8870 - val_loss: 0.3260 - val_acc: 0.8833\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2963 - acc: 0.8685 - val_loss: 0.3238 - val_acc: 0.8833\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2796 - acc: 0.8852 - val_loss: 0.3211 - val_acc: 0.8667\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2940 - acc: 0.8833 - val_loss: 0.3231 - val_acc: 0.8667\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2861 - acc: 0.8833 - val_loss: 0.3296 - val_acc: 0.8667\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3038 - acc: 0.8963 - val_loss: 0.3401 - val_acc: 0.8833\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2900 - acc: 0.8759 - val_loss: 0.3493 - val_acc: 0.8833\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2847 - acc: 0.8907 - val_loss: 0.3575 - val_acc: 0.8833\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2619 - acc: 0.8981 - val_loss: 0.3619 - val_acc: 0.8833\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3053 - acc: 0.8574 - val_loss: 0.3577 - val_acc: 0.8833\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.3047 - acc: 0.8704 - val_loss: 0.3519 - val_acc: 0.8833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.49996, saving model to best.model\n",
      "0s - loss: 0.7750 - acc: 0.5981 - val_loss: 0.5000 - val_acc: 0.7833\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7493 - acc: 0.6407 - val_loss: 0.5028 - val_acc: 0.7833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.6618 - acc: 0.6759 - val_loss: 0.5093 - val_acc: 0.7833\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6854 - acc: 0.6611 - val_loss: 0.5126 - val_acc: 0.7833\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6316 - acc: 0.6704 - val_loss: 0.5092 - val_acc: 0.7833\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6107 - acc: 0.6796 - val_loss: 0.5080 - val_acc: 0.7833\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6095 - acc: 0.6722 - val_loss: 0.5081 - val_acc: 0.7833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6252 - acc: 0.6704 - val_loss: 0.5049 - val_acc: 0.7833\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5987 - acc: 0.7111 - val_loss: 0.5040 - val_acc: 0.7833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5809 - acc: 0.6870 - val_loss: 0.5039 - val_acc: 0.7833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6277 - acc: 0.6963 - val_loss: 0.5045 - val_acc: 0.7833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6145 - acc: 0.7130 - val_loss: 0.5115 - val_acc: 0.7833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5770 - acc: 0.7148 - val_loss: 0.5165 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6155 - acc: 0.6778 - val_loss: 0.5180 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5925 - acc: 0.6852 - val_loss: 0.5175 - val_acc: 0.7833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5710 - acc: 0.7130 - val_loss: 0.5132 - val_acc: 0.7833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5843 - acc: 0.6889 - val_loss: 0.5055 - val_acc: 0.7833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.49996 to 0.49795, saving model to best.model\n",
      "0s - loss: 0.5821 - acc: 0.6963 - val_loss: 0.4980 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.49795 to 0.49565, saving model to best.model\n",
      "0s - loss: 0.5904 - acc: 0.7130 - val_loss: 0.4957 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.49565 to 0.49438, saving model to best.model\n",
      "0s - loss: 0.5723 - acc: 0.7333 - val_loss: 0.4944 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5311 - acc: 0.7537 - val_loss: 0.4956 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5544 - acc: 0.7315 - val_loss: 0.4955 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5507 - acc: 0.7333 - val_loss: 0.4993 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5467 - acc: 0.7315 - val_loss: 0.5054 - val_acc: 0.8333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5452 - acc: 0.7167 - val_loss: 0.5058 - val_acc: 0.8167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5383 - acc: 0.7389 - val_loss: 0.5030 - val_acc: 0.8167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5460 - acc: 0.7296 - val_loss: 0.4977 - val_acc: 0.8167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.49438 to 0.48605, saving model to best.model\n",
      "0s - loss: 0.5262 - acc: 0.7370 - val_loss: 0.4861 - val_acc: 0.8167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.48605 to 0.47544, saving model to best.model\n",
      "0s - loss: 0.5540 - acc: 0.7352 - val_loss: 0.4754 - val_acc: 0.8167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.47544 to 0.47034, saving model to best.model\n",
      "0s - loss: 0.5462 - acc: 0.7241 - val_loss: 0.4703 - val_acc: 0.8167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5259 - acc: 0.7426 - val_loss: 0.4706 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5180 - acc: 0.7481 - val_loss: 0.4746 - val_acc: 0.8167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5193 - acc: 0.7519 - val_loss: 0.4839 - val_acc: 0.8167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5422 - acc: 0.7315 - val_loss: 0.4930 - val_acc: 0.8167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5459 - acc: 0.7204 - val_loss: 0.4971 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5373 - acc: 0.7315 - val_loss: 0.4949 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5298 - acc: 0.7370 - val_loss: 0.4909 - val_acc: 0.8333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5218 - acc: 0.7370 - val_loss: 0.4865 - val_acc: 0.8333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.4987 - acc: 0.7704 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5298 - acc: 0.7389 - val_loss: 0.4728 - val_acc: 0.8500\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.47034 to 0.46308, saving model to best.model\n",
      "0s - loss: 0.5172 - acc: 0.7500 - val_loss: 0.4631 - val_acc: 0.8333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.46308 to 0.46110, saving model to best.model\n",
      "0s - loss: 0.5104 - acc: 0.7685 - val_loss: 0.4611 - val_acc: 0.8500\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5170 - acc: 0.7556 - val_loss: 0.4642 - val_acc: 0.8500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5118 - acc: 0.7556 - val_loss: 0.4651 - val_acc: 0.8500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4867 - acc: 0.7537 - val_loss: 0.4628 - val_acc: 0.8500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.46110 to 0.45756, saving model to best.model\n",
      "0s - loss: 0.5004 - acc: 0.7667 - val_loss: 0.4576 - val_acc: 0.8500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.45756 to 0.45161, saving model to best.model\n",
      "0s - loss: 0.4999 - acc: 0.7667 - val_loss: 0.4516 - val_acc: 0.8500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.45161 to 0.44372, saving model to best.model\n",
      "0s - loss: 0.4954 - acc: 0.7630 - val_loss: 0.4437 - val_acc: 0.8500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.44372 to 0.43631, saving model to best.model\n",
      "0s - loss: 0.5257 - acc: 0.7278 - val_loss: 0.4363 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.43631 to 0.43310, saving model to best.model\n",
      "0s - loss: 0.5182 - acc: 0.7500 - val_loss: 0.4331 - val_acc: 0.8500\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5110 - acc: 0.7722 - val_loss: 0.4352 - val_acc: 0.8333\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4855 - acc: 0.7648 - val_loss: 0.4418 - val_acc: 0.8500\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4764 - acc: 0.7685 - val_loss: 0.4478 - val_acc: 0.8167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4747 - acc: 0.7685 - val_loss: 0.4471 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4876 - acc: 0.7722 - val_loss: 0.4437 - val_acc: 0.8167\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4689 - acc: 0.7889 - val_loss: 0.4370 - val_acc: 0.8500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.43310 to 0.43181, saving model to best.model\n",
      "0s - loss: 0.4612 - acc: 0.7852 - val_loss: 0.4318 - val_acc: 0.8500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.43181 to 0.42704, saving model to best.model\n",
      "0s - loss: 0.4764 - acc: 0.8037 - val_loss: 0.4270 - val_acc: 0.8833\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.42704 to 0.42414, saving model to best.model\n",
      "0s - loss: 0.4852 - acc: 0.7759 - val_loss: 0.4241 - val_acc: 0.9000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.42414 to 0.42222, saving model to best.model\n",
      "0s - loss: 0.4973 - acc: 0.7704 - val_loss: 0.4222 - val_acc: 0.9000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4611 - acc: 0.7796 - val_loss: 0.4224 - val_acc: 0.9000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.42222 to 0.42176, saving model to best.model\n",
      "0s - loss: 0.4716 - acc: 0.7759 - val_loss: 0.4218 - val_acc: 0.9000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.42176 to 0.42068, saving model to best.model\n",
      "0s - loss: 0.4713 - acc: 0.7778 - val_loss: 0.4207 - val_acc: 0.8667\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.42068 to 0.41707, saving model to best.model\n",
      "0s - loss: 0.4611 - acc: 0.7852 - val_loss: 0.4171 - val_acc: 0.9000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.41707 to 0.41492, saving model to best.model\n",
      "0s - loss: 0.4570 - acc: 0.7889 - val_loss: 0.4149 - val_acc: 0.9000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4836 - acc: 0.7815 - val_loss: 0.4166 - val_acc: 0.9000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4637 - acc: 0.7833 - val_loss: 0.4213 - val_acc: 0.9000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4781 - acc: 0.7944 - val_loss: 0.4275 - val_acc: 0.9000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4706 - acc: 0.7926 - val_loss: 0.4334 - val_acc: 0.8500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4517 - acc: 0.7944 - val_loss: 0.4349 - val_acc: 0.8500\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4517 - acc: 0.8000 - val_loss: 0.4350 - val_acc: 0.8500\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4643 - acc: 0.7833 - val_loss: 0.4320 - val_acc: 0.8833\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4468 - acc: 0.7833 - val_loss: 0.4282 - val_acc: 0.8833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4375 - acc: 0.7963 - val_loss: 0.4253 - val_acc: 0.8667\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4496 - acc: 0.8019 - val_loss: 0.4273 - val_acc: 0.8833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4465 - acc: 0.8241 - val_loss: 0.4315 - val_acc: 0.8500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4539 - acc: 0.7796 - val_loss: 0.4312 - val_acc: 0.8500\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4484 - acc: 0.7981 - val_loss: 0.4254 - val_acc: 0.8667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4499 - acc: 0.7963 - val_loss: 0.4201 - val_acc: 0.8667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4403 - acc: 0.8093 - val_loss: 0.4151 - val_acc: 0.8667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.41492 to 0.41011, saving model to best.model\n",
      "0s - loss: 0.4608 - acc: 0.8056 - val_loss: 0.4101 - val_acc: 0.8667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.41011 to 0.41002, saving model to best.model\n",
      "0s - loss: 0.4434 - acc: 0.8056 - val_loss: 0.4100 - val_acc: 0.8667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4251 - acc: 0.8074 - val_loss: 0.4113 - val_acc: 0.8667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4324 - acc: 0.8167 - val_loss: 0.4135 - val_acc: 0.8667\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4353 - acc: 0.8019 - val_loss: 0.4153 - val_acc: 0.8667\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4168 - acc: 0.8074 - val_loss: 0.4115 - val_acc: 0.8667\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.41002 to 0.40633, saving model to best.model\n",
      "0s - loss: 0.4135 - acc: 0.8130 - val_loss: 0.4063 - val_acc: 0.8667\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.40633 to 0.40344, saving model to best.model\n",
      "0s - loss: 0.4211 - acc: 0.8019 - val_loss: 0.4034 - val_acc: 0.8667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.40344 to 0.40242, saving model to best.model\n",
      "0s - loss: 0.4304 - acc: 0.8037 - val_loss: 0.4024 - val_acc: 0.8667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4107 - acc: 0.8259 - val_loss: 0.4039 - val_acc: 0.8667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4131 - acc: 0.8222 - val_loss: 0.4045 - val_acc: 0.8667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4019 - acc: 0.8259 - val_loss: 0.4031 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4328 - acc: 0.8093 - val_loss: 0.4059 - val_acc: 0.8667\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4202 - acc: 0.8204 - val_loss: 0.4131 - val_acc: 0.8667\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4376 - acc: 0.8130 - val_loss: 0.4190 - val_acc: 0.8667\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3981 - acc: 0.8167 - val_loss: 0.4136 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3805 - acc: 0.8444 - val_loss: 0.4088 - val_acc: 0.8667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3879 - acc: 0.8352 - val_loss: 0.4047 - val_acc: 0.8667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.40242 to 0.40158, saving model to best.model\n",
      "0s - loss: 0.4240 - acc: 0.8111 - val_loss: 0.4016 - val_acc: 0.8667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.40158 to 0.40141, saving model to best.model\n",
      "0s - loss: 0.4243 - acc: 0.8000 - val_loss: 0.4014 - val_acc: 0.8667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3957 - acc: 0.8241 - val_loss: 0.4030 - val_acc: 0.8667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3958 - acc: 0.8296 - val_loss: 0.4166 - val_acc: 0.8667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3829 - acc: 0.8259 - val_loss: 0.4374 - val_acc: 0.8667\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3859 - acc: 0.8185 - val_loss: 0.4414 - val_acc: 0.8667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4021 - acc: 0.8222 - val_loss: 0.4309 - val_acc: 0.8667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3859 - acc: 0.8519 - val_loss: 0.4161 - val_acc: 0.8500\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3981 - acc: 0.8222 - val_loss: 0.4025 - val_acc: 0.8500\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.40141 to 0.39976, saving model to best.model\n",
      "0s - loss: 0.4060 - acc: 0.8278 - val_loss: 0.3998 - val_acc: 0.8500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3616 - acc: 0.8537 - val_loss: 0.4029 - val_acc: 0.8500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3665 - acc: 0.8352 - val_loss: 0.4084 - val_acc: 0.8500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3718 - acc: 0.8389 - val_loss: 0.4150 - val_acc: 0.8500\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3948 - acc: 0.8296 - val_loss: 0.4229 - val_acc: 0.8667\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3574 - acc: 0.8537 - val_loss: 0.4272 - val_acc: 0.8667\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3593 - acc: 0.8519 - val_loss: 0.4273 - val_acc: 0.8667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3812 - acc: 0.8315 - val_loss: 0.4238 - val_acc: 0.8667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3449 - acc: 0.8481 - val_loss: 0.4181 - val_acc: 0.8333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3771 - acc: 0.8444 - val_loss: 0.4164 - val_acc: 0.8333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3640 - acc: 0.8370 - val_loss: 0.4179 - val_acc: 0.8500\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3578 - acc: 0.8519 - val_loss: 0.4208 - val_acc: 0.8667\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3470 - acc: 0.8389 - val_loss: 0.4265 - val_acc: 0.8500\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3773 - acc: 0.8389 - val_loss: 0.4255 - val_acc: 0.8500\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3728 - acc: 0.8407 - val_loss: 0.4165 - val_acc: 0.8500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3669 - acc: 0.8407 - val_loss: 0.4101 - val_acc: 0.8500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3312 - acc: 0.8500 - val_loss: 0.4066 - val_acc: 0.8500\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3810 - acc: 0.8370 - val_loss: 0.4069 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3519 - acc: 0.8370 - val_loss: 0.4065 - val_acc: 0.8333\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3500 - acc: 0.8519 - val_loss: 0.4065 - val_acc: 0.8500\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3376 - acc: 0.8500 - val_loss: 0.4097 - val_acc: 0.8500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3422 - acc: 0.8519 - val_loss: 0.4199 - val_acc: 0.8500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3505 - acc: 0.8574 - val_loss: 0.4291 - val_acc: 0.8500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3449 - acc: 0.8556 - val_loss: 0.4325 - val_acc: 0.8500\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3539 - acc: 0.8500 - val_loss: 0.4305 - val_acc: 0.8500\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3411 - acc: 0.8463 - val_loss: 0.4294 - val_acc: 0.8667\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3288 - acc: 0.8481 - val_loss: 0.4366 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.50811, saving model to best.model\n",
      "0s - loss: 0.9288 - acc: 0.5259 - val_loss: 0.5081 - val_acc: 0.7667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7084 - acc: 0.6667 - val_loss: 0.5183 - val_acc: 0.7667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.50811 to 0.50500, saving model to best.model\n",
      "0s - loss: 0.7257 - acc: 0.7204 - val_loss: 0.5050 - val_acc: 0.7667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.50500 to 0.49159, saving model to best.model\n",
      "0s - loss: 0.6754 - acc: 0.7074 - val_loss: 0.4916 - val_acc: 0.7667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6567 - acc: 0.7148 - val_loss: 0.4944 - val_acc: 0.7667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.5897 - acc: 0.7204 - val_loss: 0.5132 - val_acc: 0.7667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5963 - acc: 0.7130 - val_loss: 0.5326 - val_acc: 0.7833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5944 - acc: 0.7056 - val_loss: 0.5447 - val_acc: 0.7667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6066 - acc: 0.7019 - val_loss: 0.5502 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5657 - acc: 0.7185 - val_loss: 0.5451 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5588 - acc: 0.7148 - val_loss: 0.5362 - val_acc: 0.7833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5691 - acc: 0.7222 - val_loss: 0.5311 - val_acc: 0.7833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5594 - acc: 0.7093 - val_loss: 0.5245 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5419 - acc: 0.7315 - val_loss: 0.5140 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5611 - acc: 0.7185 - val_loss: 0.5031 - val_acc: 0.7833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5731 - acc: 0.7167 - val_loss: 0.4970 - val_acc: 0.7833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5457 - acc: 0.7352 - val_loss: 0.4935 - val_acc: 0.7833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.49159 to 0.48981, saving model to best.model\n",
      "0s - loss: 0.5189 - acc: 0.7389 - val_loss: 0.4898 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.48981 to 0.48945, saving model to best.model\n",
      "0s - loss: 0.5347 - acc: 0.7407 - val_loss: 0.4894 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5312 - acc: 0.7444 - val_loss: 0.4898 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.48945 to 0.48879, saving model to best.model\n",
      "0s - loss: 0.5138 - acc: 0.7481 - val_loss: 0.4888 - val_acc: 0.8000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.48879 to 0.48585, saving model to best.model\n",
      "0s - loss: 0.5255 - acc: 0.7389 - val_loss: 0.4859 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5459 - acc: 0.7444 - val_loss: 0.4880 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5316 - acc: 0.7296 - val_loss: 0.4945 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5377 - acc: 0.7407 - val_loss: 0.4968 - val_acc: 0.8000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5494 - acc: 0.7296 - val_loss: 0.4970 - val_acc: 0.8000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5145 - acc: 0.7352 - val_loss: 0.4988 - val_acc: 0.7833\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5201 - acc: 0.7389 - val_loss: 0.4937 - val_acc: 0.7833\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.48585 to 0.48168, saving model to best.model\n",
      "0s - loss: 0.5231 - acc: 0.7241 - val_loss: 0.4817 - val_acc: 0.7833\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.48168 to 0.46914, saving model to best.model\n",
      "0s - loss: 0.5083 - acc: 0.7630 - val_loss: 0.4691 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.46914 to 0.45843, saving model to best.model\n",
      "0s - loss: 0.5103 - acc: 0.7574 - val_loss: 0.4584 - val_acc: 0.7833\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.45843 to 0.45147, saving model to best.model\n",
      "0s - loss: 0.5208 - acc: 0.7593 - val_loss: 0.4515 - val_acc: 0.7833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.45147 to 0.44671, saving model to best.model\n",
      "0s - loss: 0.5237 - acc: 0.7389 - val_loss: 0.4467 - val_acc: 0.7833\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.44671 to 0.44342, saving model to best.model\n",
      "0s - loss: 0.4932 - acc: 0.7370 - val_loss: 0.4434 - val_acc: 0.7833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.44342 to 0.44224, saving model to best.model\n",
      "0s - loss: 0.5047 - acc: 0.7500 - val_loss: 0.4422 - val_acc: 0.7833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.44224 to 0.44113, saving model to best.model\n",
      "0s - loss: 0.4814 - acc: 0.7556 - val_loss: 0.4411 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.44113 to 0.44001, saving model to best.model\n",
      "0s - loss: 0.4958 - acc: 0.7611 - val_loss: 0.4400 - val_acc: 0.8000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.44001 to 0.43893, saving model to best.model\n",
      "0s - loss: 0.4763 - acc: 0.7852 - val_loss: 0.4389 - val_acc: 0.8000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.43893 to 0.43797, saving model to best.model\n",
      "0s - loss: 0.4823 - acc: 0.7500 - val_loss: 0.4380 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.43797 to 0.43747, saving model to best.model\n",
      "0s - loss: 0.4696 - acc: 0.7611 - val_loss: 0.4375 - val_acc: 0.7833\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4692 - acc: 0.7759 - val_loss: 0.4383 - val_acc: 0.7667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4896 - acc: 0.7722 - val_loss: 0.4389 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.43747 to 0.43593, saving model to best.model\n",
      "0s - loss: 0.4784 - acc: 0.7759 - val_loss: 0.4359 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.43593 to 0.43177, saving model to best.model\n",
      "0s - loss: 0.5025 - acc: 0.7648 - val_loss: 0.4318 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.43177 to 0.43006, saving model to best.model\n",
      "0s - loss: 0.4850 - acc: 0.7556 - val_loss: 0.4301 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.43006 to 0.42770, saving model to best.model\n",
      "0s - loss: 0.5054 - acc: 0.7519 - val_loss: 0.4277 - val_acc: 0.7667\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.42770 to 0.42596, saving model to best.model\n",
      "0s - loss: 0.4708 - acc: 0.7556 - val_loss: 0.4260 - val_acc: 0.7667\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4991 - acc: 0.7667 - val_loss: 0.4263 - val_acc: 0.7667\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4880 - acc: 0.7648 - val_loss: 0.4278 - val_acc: 0.7667\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4810 - acc: 0.7704 - val_loss: 0.4283 - val_acc: 0.7833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4902 - acc: 0.7796 - val_loss: 0.4273 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.42596 to 0.42534, saving model to best.model\n",
      "0s - loss: 0.4756 - acc: 0.7685 - val_loss: 0.4253 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.42534 to 0.42308, saving model to best.model\n",
      "0s - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4231 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.42308 to 0.42232, saving model to best.model\n",
      "0s - loss: 0.4532 - acc: 0.7852 - val_loss: 0.4223 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4482 - acc: 0.7870 - val_loss: 0.4225 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4644 - acc: 0.7870 - val_loss: 0.4225 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4639 - acc: 0.7815 - val_loss: 0.4233 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4702 - acc: 0.7815 - val_loss: 0.4256 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4642 - acc: 0.7944 - val_loss: 0.4309 - val_acc: 0.8000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4565 - acc: 0.7870 - val_loss: 0.4339 - val_acc: 0.7833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4303 - acc: 0.8111 - val_loss: 0.4342 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4667 - acc: 0.7907 - val_loss: 0.4316 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4496 - acc: 0.7852 - val_loss: 0.4279 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4405 - acc: 0.7833 - val_loss: 0.4252 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4476 - acc: 0.8000 - val_loss: 0.4227 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.42232 to 0.42026, saving model to best.model\n",
      "0s - loss: 0.4413 - acc: 0.7944 - val_loss: 0.4203 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.42026 to 0.41849, saving model to best.model\n",
      "0s - loss: 0.4401 - acc: 0.7796 - val_loss: 0.4185 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.41849 to 0.41738, saving model to best.model\n",
      "0s - loss: 0.4053 - acc: 0.8037 - val_loss: 0.4174 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.41738 to 0.41724, saving model to best.model\n",
      "0s - loss: 0.4498 - acc: 0.7944 - val_loss: 0.4172 - val_acc: 0.8000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4620 - acc: 0.7778 - val_loss: 0.4180 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4441 - acc: 0.7889 - val_loss: 0.4173 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.41724 to 0.41657, saving model to best.model\n",
      "0s - loss: 0.4263 - acc: 0.7981 - val_loss: 0.4166 - val_acc: 0.8000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4399 - acc: 0.8093 - val_loss: 0.4180 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4251 - acc: 0.8074 - val_loss: 0.4257 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4251 - acc: 0.8111 - val_loss: 0.4290 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4466 - acc: 0.7963 - val_loss: 0.4258 - val_acc: 0.7833\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4377 - acc: 0.8056 - val_loss: 0.4231 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4417 - acc: 0.7796 - val_loss: 0.4208 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4268 - acc: 0.8185 - val_loss: 0.4191 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4084 - acc: 0.8037 - val_loss: 0.4170 - val_acc: 0.7833\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4178 - acc: 0.8074 - val_loss: 0.4169 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4363 - acc: 0.7963 - val_loss: 0.4193 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4508 - acc: 0.8111 - val_loss: 0.4224 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4261 - acc: 0.8037 - val_loss: 0.4251 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4203 - acc: 0.8185 - val_loss: 0.4285 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4252 - acc: 0.8056 - val_loss: 0.4337 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4154 - acc: 0.8130 - val_loss: 0.4362 - val_acc: 0.7833\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4326 - acc: 0.7926 - val_loss: 0.4348 - val_acc: 0.7833\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4075 - acc: 0.8241 - val_loss: 0.4345 - val_acc: 0.7833\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4237 - acc: 0.8056 - val_loss: 0.4338 - val_acc: 0.7833\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4448 - acc: 0.7981 - val_loss: 0.4358 - val_acc: 0.8000\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4185 - acc: 0.8278 - val_loss: 0.4375 - val_acc: 0.8000\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4117 - acc: 0.8259 - val_loss: 0.4364 - val_acc: 0.8000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4123 - acc: 0.8111 - val_loss: 0.4336 - val_acc: 0.8000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3952 - acc: 0.8204 - val_loss: 0.4289 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4048 - acc: 0.7963 - val_loss: 0.4246 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3901 - acc: 0.8352 - val_loss: 0.4226 - val_acc: 0.8000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4104 - acc: 0.8204 - val_loss: 0.4222 - val_acc: 0.8000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.61755, saving model to best.model\n",
      "0s - loss: 1.0375 - acc: 0.4093 - val_loss: 0.6175 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7274 - acc: 0.6148 - val_loss: 0.6409 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7542 - acc: 0.6648 - val_loss: 0.6363 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61755 to 0.60376, saving model to best.model\n",
      "0s - loss: 0.6952 - acc: 0.6630 - val_loss: 0.6038 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.60376 to 0.57862, saving model to best.model\n",
      "0s - loss: 0.6867 - acc: 0.6611 - val_loss: 0.5786 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.57862 to 0.56621, saving model to best.model\n",
      "0s - loss: 0.6328 - acc: 0.6833 - val_loss: 0.5662 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.56621 to 0.56500, saving model to best.model\n",
      "0s - loss: 0.6355 - acc: 0.6537 - val_loss: 0.5650 - val_acc: 0.6833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.56500 to 0.56391, saving model to best.model\n",
      "0s - loss: 0.6216 - acc: 0.6685 - val_loss: 0.5639 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.56391 to 0.55983, saving model to best.model\n",
      "0s - loss: 0.6148 - acc: 0.6704 - val_loss: 0.5598 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.55983 to 0.55338, saving model to best.model\n",
      "0s - loss: 0.5832 - acc: 0.7000 - val_loss: 0.5534 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.55338 to 0.54804, saving model to best.model\n",
      "0s - loss: 0.6013 - acc: 0.6963 - val_loss: 0.5480 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.54804 to 0.54371, saving model to best.model\n",
      "0s - loss: 0.6002 - acc: 0.6870 - val_loss: 0.5437 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.54371 to 0.53941, saving model to best.model\n",
      "0s - loss: 0.5920 - acc: 0.6870 - val_loss: 0.5394 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.53941 to 0.53534, saving model to best.model\n",
      "0s - loss: 0.5781 - acc: 0.7019 - val_loss: 0.5353 - val_acc: 0.6833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.53534 to 0.53153, saving model to best.model\n",
      "0s - loss: 0.5857 - acc: 0.7148 - val_loss: 0.5315 - val_acc: 0.6833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.53153 to 0.52812, saving model to best.model\n",
      "0s - loss: 0.5770 - acc: 0.7130 - val_loss: 0.5281 - val_acc: 0.6833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.52812 to 0.52615, saving model to best.model\n",
      "0s - loss: 0.5691 - acc: 0.6963 - val_loss: 0.5262 - val_acc: 0.7000\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.52615 to 0.52374, saving model to best.model\n",
      "0s - loss: 0.5601 - acc: 0.7204 - val_loss: 0.5237 - val_acc: 0.7167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.52374 to 0.52129, saving model to best.model\n",
      "0s - loss: 0.5727 - acc: 0.7333 - val_loss: 0.5213 - val_acc: 0.7000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.52129 to 0.51753, saving model to best.model\n",
      "0s - loss: 0.5726 - acc: 0.7185 - val_loss: 0.5175 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.51753 to 0.51264, saving model to best.model\n",
      "0s - loss: 0.5408 - acc: 0.7463 - val_loss: 0.5126 - val_acc: 0.7000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.51264 to 0.50819, saving model to best.model\n",
      "0s - loss: 0.5507 - acc: 0.7204 - val_loss: 0.5082 - val_acc: 0.7167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.50819 to 0.50567, saving model to best.model\n",
      "0s - loss: 0.5733 - acc: 0.7352 - val_loss: 0.5057 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.50567 to 0.50314, saving model to best.model\n",
      "0s - loss: 0.5372 - acc: 0.7370 - val_loss: 0.5031 - val_acc: 0.7167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.50314 to 0.50113, saving model to best.model\n",
      "0s - loss: 0.5411 - acc: 0.7241 - val_loss: 0.5011 - val_acc: 0.7000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.50113 to 0.49946, saving model to best.model\n",
      "0s - loss: 0.5322 - acc: 0.7500 - val_loss: 0.4995 - val_acc: 0.7333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.49946 to 0.49739, saving model to best.model\n",
      "0s - loss: 0.5170 - acc: 0.7593 - val_loss: 0.4974 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.49739 to 0.49477, saving model to best.model\n",
      "0s - loss: 0.5083 - acc: 0.7556 - val_loss: 0.4948 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.49477 to 0.49226, saving model to best.model\n",
      "0s - loss: 0.5190 - acc: 0.7407 - val_loss: 0.4923 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.49226 to 0.49004, saving model to best.model\n",
      "0s - loss: 0.5333 - acc: 0.7667 - val_loss: 0.4900 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.49004 to 0.48807, saving model to best.model\n",
      "0s - loss: 0.5320 - acc: 0.7556 - val_loss: 0.4881 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.48807 to 0.48549, saving model to best.model\n",
      "0s - loss: 0.5382 - acc: 0.7463 - val_loss: 0.4855 - val_acc: 0.7333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.48549 to 0.48219, saving model to best.model\n",
      "0s - loss: 0.5159 - acc: 0.7500 - val_loss: 0.4822 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.48219 to 0.47794, saving model to best.model\n",
      "0s - loss: 0.5098 - acc: 0.7704 - val_loss: 0.4779 - val_acc: 0.7333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.47794 to 0.47390, saving model to best.model\n",
      "0s - loss: 0.5156 - acc: 0.7500 - val_loss: 0.4739 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.47390 to 0.47083, saving model to best.model\n",
      "0s - loss: 0.5418 - acc: 0.7130 - val_loss: 0.4708 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.47083 to 0.46828, saving model to best.model\n",
      "0s - loss: 0.5114 - acc: 0.7315 - val_loss: 0.4683 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.46828 to 0.46703, saving model to best.model\n",
      "0s - loss: 0.5114 - acc: 0.7630 - val_loss: 0.4670 - val_acc: 0.7333\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.46703 to 0.46642, saving model to best.model\n",
      "0s - loss: 0.5068 - acc: 0.7593 - val_loss: 0.4664 - val_acc: 0.7500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.46642 to 0.46302, saving model to best.model\n",
      "0s - loss: 0.5141 - acc: 0.7685 - val_loss: 0.4630 - val_acc: 0.7333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.46302 to 0.45854, saving model to best.model\n",
      "0s - loss: 0.4985 - acc: 0.7759 - val_loss: 0.4585 - val_acc: 0.7333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.45854 to 0.45568, saving model to best.model\n",
      "0s - loss: 0.4892 - acc: 0.7630 - val_loss: 0.4557 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.45568 to 0.45414, saving model to best.model\n",
      "0s - loss: 0.4937 - acc: 0.7519 - val_loss: 0.4541 - val_acc: 0.7500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4930 - acc: 0.7611 - val_loss: 0.4544 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.45414 to 0.45396, saving model to best.model\n",
      "0s - loss: 0.4771 - acc: 0.7833 - val_loss: 0.4540 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.45396 to 0.45260, saving model to best.model\n",
      "0s - loss: 0.4831 - acc: 0.7704 - val_loss: 0.4526 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.45260 to 0.45108, saving model to best.model\n",
      "0s - loss: 0.4766 - acc: 0.7796 - val_loss: 0.4511 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.45108 to 0.45044, saving model to best.model\n",
      "0s - loss: 0.4846 - acc: 0.7704 - val_loss: 0.4504 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.45044 to 0.44847, saving model to best.model\n",
      "0s - loss: 0.4599 - acc: 0.8056 - val_loss: 0.4485 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4727 - acc: 0.7685 - val_loss: 0.4485 - val_acc: 0.7333\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4871 - acc: 0.7815 - val_loss: 0.4498 - val_acc: 0.7500\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4740 - acc: 0.7796 - val_loss: 0.4520 - val_acc: 0.7500\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4743 - acc: 0.7889 - val_loss: 0.4503 - val_acc: 0.7500\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.44847 to 0.44527, saving model to best.model\n",
      "0s - loss: 0.4780 - acc: 0.7926 - val_loss: 0.4453 - val_acc: 0.7500\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.44527 to 0.43998, saving model to best.model\n",
      "0s - loss: 0.4542 - acc: 0.7963 - val_loss: 0.4400 - val_acc: 0.7500\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.43998 to 0.43533, saving model to best.model\n",
      "0s - loss: 0.4598 - acc: 0.8056 - val_loss: 0.4353 - val_acc: 0.7500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.43533 to 0.43377, saving model to best.model\n",
      "0s - loss: 0.4739 - acc: 0.7778 - val_loss: 0.4338 - val_acc: 0.7667\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.43377 to 0.43278, saving model to best.model\n",
      "0s - loss: 0.4787 - acc: 0.7704 - val_loss: 0.4328 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.43278 to 0.43211, saving model to best.model\n",
      "0s - loss: 0.4634 - acc: 0.7963 - val_loss: 0.4321 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4856 - acc: 0.7759 - val_loss: 0.4326 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4862 - acc: 0.7759 - val_loss: 0.4334 - val_acc: 0.7500\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4442 - acc: 0.7944 - val_loss: 0.4338 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4595 - acc: 0.7870 - val_loss: 0.4334 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.43211 to 0.43116, saving model to best.model\n",
      "0s - loss: 0.4587 - acc: 0.7944 - val_loss: 0.4312 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.43116 to 0.42881, saving model to best.model\n",
      "0s - loss: 0.4591 - acc: 0.7889 - val_loss: 0.4288 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.42881 to 0.42616, saving model to best.model\n",
      "0s - loss: 0.4567 - acc: 0.7870 - val_loss: 0.4262 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.42616 to 0.42296, saving model to best.model\n",
      "0s - loss: 0.4394 - acc: 0.8093 - val_loss: 0.4230 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.42296 to 0.42179, saving model to best.model\n",
      "0s - loss: 0.4532 - acc: 0.7889 - val_loss: 0.4218 - val_acc: 0.7833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4427 - acc: 0.7963 - val_loss: 0.4226 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4101 - acc: 0.8204 - val_loss: 0.4232 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4278 - acc: 0.8111 - val_loss: 0.4230 - val_acc: 0.7833\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4200 - acc: 0.8111 - val_loss: 0.4224 - val_acc: 0.7833\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.42179 to 0.42148, saving model to best.model\n",
      "0s - loss: 0.4301 - acc: 0.8037 - val_loss: 0.4215 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.42148 to 0.41833, saving model to best.model\n",
      "0s - loss: 0.4270 - acc: 0.8278 - val_loss: 0.4183 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.41833 to 0.41312, saving model to best.model\n",
      "0s - loss: 0.4360 - acc: 0.8056 - val_loss: 0.4131 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.41312 to 0.40949, saving model to best.model\n",
      "0s - loss: 0.4330 - acc: 0.8019 - val_loss: 0.4095 - val_acc: 0.7833\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4179 - acc: 0.8019 - val_loss: 0.4101 - val_acc: 0.7833\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.40949 to 0.40866, saving model to best.model\n",
      "0s - loss: 0.4187 - acc: 0.8093 - val_loss: 0.4087 - val_acc: 0.7833\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.40866 to 0.40507, saving model to best.model\n",
      "0s - loss: 0.4225 - acc: 0.8000 - val_loss: 0.4051 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.40507 to 0.39984, saving model to best.model\n",
      "0s - loss: 0.4117 - acc: 0.8074 - val_loss: 0.3998 - val_acc: 0.7833\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.39984 to 0.39590, saving model to best.model\n",
      "0s - loss: 0.4129 - acc: 0.8000 - val_loss: 0.3959 - val_acc: 0.7833\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.39590 to 0.39319, saving model to best.model\n",
      "0s - loss: 0.3936 - acc: 0.8278 - val_loss: 0.3932 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.39319 to 0.39189, saving model to best.model\n",
      "0s - loss: 0.3977 - acc: 0.8352 - val_loss: 0.3919 - val_acc: 0.8000\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.39189 to 0.39086, saving model to best.model\n",
      "0s - loss: 0.3984 - acc: 0.8389 - val_loss: 0.3909 - val_acc: 0.8333\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4066 - acc: 0.8093 - val_loss: 0.3920 - val_acc: 0.8000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4133 - acc: 0.8222 - val_loss: 0.3953 - val_acc: 0.8000\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.3990 - acc: 0.8259 - val_loss: 0.3994 - val_acc: 0.8000\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4048 - acc: 0.8167 - val_loss: 0.4040 - val_acc: 0.7833\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.3977 - acc: 0.8333 - val_loss: 0.4060 - val_acc: 0.7833\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.3984 - acc: 0.8352 - val_loss: 0.4060 - val_acc: 0.7833\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3932 - acc: 0.8296 - val_loss: 0.4074 - val_acc: 0.7833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3633 - acc: 0.8593 - val_loss: 0.4098 - val_acc: 0.7833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.3777 - acc: 0.8278 - val_loss: 0.4092 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.3658 - acc: 0.8519 - val_loss: 0.4092 - val_acc: 0.7833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3901 - acc: 0.8093 - val_loss: 0.4053 - val_acc: 0.7833\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3949 - acc: 0.8167 - val_loss: 0.4011 - val_acc: 0.7833\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3907 - acc: 0.8185 - val_loss: 0.4025 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3607 - acc: 0.8333 - val_loss: 0.4039 - val_acc: 0.7833\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3630 - acc: 0.8500 - val_loss: 0.4080 - val_acc: 0.7833\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3835 - acc: 0.8259 - val_loss: 0.4154 - val_acc: 0.7833\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3717 - acc: 0.8389 - val_loss: 0.4152 - val_acc: 0.7833\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3647 - acc: 0.8407 - val_loss: 0.4078 - val_acc: 0.7833\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3620 - acc: 0.8463 - val_loss: 0.4031 - val_acc: 0.7833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3657 - acc: 0.8259 - val_loss: 0.4066 - val_acc: 0.7833\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3714 - acc: 0.8296 - val_loss: 0.4137 - val_acc: 0.7833\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3702 - acc: 0.8426 - val_loss: 0.4145 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3752 - acc: 0.8278 - val_loss: 0.4129 - val_acc: 0.8000\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3522 - acc: 0.8426 - val_loss: 0.4067 - val_acc: 0.8167\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3639 - acc: 0.8444 - val_loss: 0.4053 - val_acc: 0.8167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3390 - acc: 0.8463 - val_loss: 0.4075 - val_acc: 0.8000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.67992, saving model to best.model\n",
      "0s - loss: 1.3857 - acc: 0.3926 - val_loss: 0.6799 - val_acc: 0.6167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.9086 - acc: 0.5481 - val_loss: 0.7968 - val_acc: 0.6167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.8054 - acc: 0.6407 - val_loss: 0.8538 - val_acc: 0.6167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.8163 - acc: 0.6648 - val_loss: 0.8212 - val_acc: 0.6167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.7295 - acc: 0.6870 - val_loss: 0.7564 - val_acc: 0.6167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.7390 - acc: 0.6630 - val_loss: 0.7010 - val_acc: 0.6167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.67992 to 0.66448, saving model to best.model\n",
      "0s - loss: 0.6524 - acc: 0.6593 - val_loss: 0.6645 - val_acc: 0.6167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.66448 to 0.64820, saving model to best.model\n",
      "0s - loss: 0.6289 - acc: 0.6722 - val_loss: 0.6482 - val_acc: 0.6167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.64820 to 0.64218, saving model to best.model\n",
      "0s - loss: 0.6503 - acc: 0.6222 - val_loss: 0.6422 - val_acc: 0.6000\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.64218 to 0.63891, saving model to best.model\n",
      "0s - loss: 0.6188 - acc: 0.6759 - val_loss: 0.6389 - val_acc: 0.6167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.63891 to 0.63752, saving model to best.model\n",
      "0s - loss: 0.5931 - acc: 0.6759 - val_loss: 0.6375 - val_acc: 0.6167\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.63752 to 0.63654, saving model to best.model\n",
      "0s - loss: 0.5705 - acc: 0.7130 - val_loss: 0.6365 - val_acc: 0.6167\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5856 - acc: 0.6796 - val_loss: 0.6372 - val_acc: 0.6167\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6055 - acc: 0.6815 - val_loss: 0.6395 - val_acc: 0.6333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5963 - acc: 0.6889 - val_loss: 0.6396 - val_acc: 0.6333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5590 - acc: 0.7167 - val_loss: 0.6393 - val_acc: 0.6333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5651 - acc: 0.7167 - val_loss: 0.6383 - val_acc: 0.6500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5704 - acc: 0.7037 - val_loss: 0.6372 - val_acc: 0.6667\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.63654 to 0.63627, saving model to best.model\n",
      "0s - loss: 0.5781 - acc: 0.6889 - val_loss: 0.6363 - val_acc: 0.7333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.63627 to 0.63486, saving model to best.model\n",
      "0s - loss: 0.5553 - acc: 0.7000 - val_loss: 0.6349 - val_acc: 0.7167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.63486 to 0.63351, saving model to best.model\n",
      "0s - loss: 0.5652 - acc: 0.6870 - val_loss: 0.6335 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.63351 to 0.63227, saving model to best.model\n",
      "0s - loss: 0.5538 - acc: 0.7333 - val_loss: 0.6323 - val_acc: 0.7167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.63227 to 0.63137, saving model to best.model\n",
      "0s - loss: 0.5630 - acc: 0.7259 - val_loss: 0.6314 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5369 - acc: 0.7148 - val_loss: 0.6314 - val_acc: 0.7167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5150 - acc: 0.7426 - val_loss: 0.6320 - val_acc: 0.7167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5503 - acc: 0.7093 - val_loss: 0.6329 - val_acc: 0.7167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5440 - acc: 0.7093 - val_loss: 0.6343 - val_acc: 0.7167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5207 - acc: 0.7444 - val_loss: 0.6371 - val_acc: 0.7167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5232 - acc: 0.7481 - val_loss: 0.6408 - val_acc: 0.7167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5480 - acc: 0.7389 - val_loss: 0.6425 - val_acc: 0.7167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5240 - acc: 0.7296 - val_loss: 0.6448 - val_acc: 0.7167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5379 - acc: 0.7333 - val_loss: 0.6472 - val_acc: 0.7167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5202 - acc: 0.7389 - val_loss: 0.6514 - val_acc: 0.7167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5183 - acc: 0.7500 - val_loss: 0.6586 - val_acc: 0.7167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5217 - acc: 0.7296 - val_loss: 0.6660 - val_acc: 0.7167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5393 - acc: 0.7407 - val_loss: 0.6675 - val_acc: 0.7167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5137 - acc: 0.7407 - val_loss: 0.6733 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5311 - acc: 0.7352 - val_loss: 0.6789 - val_acc: 0.6833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.4852 - acc: 0.7704 - val_loss: 0.6817 - val_acc: 0.6667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5229 - acc: 0.7426 - val_loss: 0.6823 - val_acc: 0.6667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5203 - acc: 0.7519 - val_loss: 0.6793 - val_acc: 0.6667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5110 - acc: 0.7278 - val_loss: 0.6725 - val_acc: 0.6667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4973 - acc: 0.7722 - val_loss: 0.6630 - val_acc: 0.6833\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4885 - acc: 0.7648 - val_loss: 0.6615 - val_acc: 0.6833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5074 - acc: 0.7407 - val_loss: 0.6633 - val_acc: 0.6833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4881 - acc: 0.7648 - val_loss: 0.6664 - val_acc: 0.6833\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.5185 - acc: 0.7537 - val_loss: 0.6682 - val_acc: 0.6833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4801 - acc: 0.7722 - val_loss: 0.6692 - val_acc: 0.6833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4816 - acc: 0.7630 - val_loss: 0.6683 - val_acc: 0.6833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.61707, saving model to best.model\n",
      "0s - loss: 0.8860 - acc: 0.4852 - val_loss: 0.6171 - val_acc: 0.6500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.61707 to 0.60483, saving model to best.model\n",
      "0s - loss: 0.7378 - acc: 0.6000 - val_loss: 0.6048 - val_acc: 0.6500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.60483 to 0.59540, saving model to best.model\n",
      "0s - loss: 0.7388 - acc: 0.6685 - val_loss: 0.5954 - val_acc: 0.6500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.59540 to 0.58021, saving model to best.model\n",
      "0s - loss: 0.7366 - acc: 0.6759 - val_loss: 0.5802 - val_acc: 0.6500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6896 - acc: 0.6556 - val_loss: 0.5805 - val_acc: 0.6333\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6520 - acc: 0.6870 - val_loss: 0.5885 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6234 - acc: 0.6537 - val_loss: 0.5951 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6419 - acc: 0.6241 - val_loss: 0.5968 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6331 - acc: 0.6278 - val_loss: 0.5940 - val_acc: 0.8000\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6206 - acc: 0.6833 - val_loss: 0.5860 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.58021 to 0.57538, saving model to best.model\n",
      "0s - loss: 0.6206 - acc: 0.6556 - val_loss: 0.5754 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.57538 to 0.56846, saving model to best.model\n",
      "0s - loss: 0.5592 - acc: 0.6852 - val_loss: 0.5685 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.56846 to 0.56441, saving model to best.model\n",
      "0s - loss: 0.5873 - acc: 0.6815 - val_loss: 0.5644 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.56441 to 0.56156, saving model to best.model\n",
      "0s - loss: 0.6041 - acc: 0.6926 - val_loss: 0.5616 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.56156 to 0.56065, saving model to best.model\n",
      "0s - loss: 0.6154 - acc: 0.6759 - val_loss: 0.5606 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.6243 - acc: 0.6630 - val_loss: 0.5612 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.56065 to 0.55981, saving model to best.model\n",
      "0s - loss: 0.5724 - acc: 0.7185 - val_loss: 0.5598 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.55981 to 0.55708, saving model to best.model\n",
      "0s - loss: 0.5610 - acc: 0.7111 - val_loss: 0.5571 - val_acc: 0.7667\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.55708 to 0.55520, saving model to best.model\n",
      "0s - loss: 0.5672 - acc: 0.6926 - val_loss: 0.5552 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.55520 to 0.55309, saving model to best.model\n",
      "0s - loss: 0.5740 - acc: 0.6889 - val_loss: 0.5531 - val_acc: 0.7667\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.55309 to 0.55150, saving model to best.model\n",
      "0s - loss: 0.5768 - acc: 0.6944 - val_loss: 0.5515 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.55150 to 0.54885, saving model to best.model\n",
      "0s - loss: 0.5627 - acc: 0.7093 - val_loss: 0.5488 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.54885 to 0.54233, saving model to best.model\n",
      "0s - loss: 0.5576 - acc: 0.7222 - val_loss: 0.5423 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.54233 to 0.53450, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7093 - val_loss: 0.5345 - val_acc: 0.7833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.53450 to 0.52717, saving model to best.model\n",
      "0s - loss: 0.5293 - acc: 0.7241 - val_loss: 0.5272 - val_acc: 0.7667\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52717 to 0.52075, saving model to best.model\n",
      "0s - loss: 0.5455 - acc: 0.7296 - val_loss: 0.5207 - val_acc: 0.7833\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.52075 to 0.51677, saving model to best.model\n",
      "0s - loss: 0.5617 - acc: 0.7074 - val_loss: 0.5168 - val_acc: 0.7667\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.51677 to 0.51503, saving model to best.model\n",
      "0s - loss: 0.5567 - acc: 0.7093 - val_loss: 0.5150 - val_acc: 0.7667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.51503 to 0.51388, saving model to best.model\n",
      "0s - loss: 0.5379 - acc: 0.7037 - val_loss: 0.5139 - val_acc: 0.7667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.51388 to 0.51323, saving model to best.model\n",
      "0s - loss: 0.5211 - acc: 0.7259 - val_loss: 0.5132 - val_acc: 0.7667\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5325 - acc: 0.7296 - val_loss: 0.5138 - val_acc: 0.7667\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5398 - acc: 0.7074 - val_loss: 0.5160 - val_acc: 0.7833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5439 - acc: 0.7148 - val_loss: 0.5197 - val_acc: 0.7667\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5280 - acc: 0.7222 - val_loss: 0.5216 - val_acc: 0.7667\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5485 - acc: 0.7185 - val_loss: 0.5214 - val_acc: 0.7667\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5292 - acc: 0.7222 - val_loss: 0.5209 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5356 - acc: 0.7241 - val_loss: 0.5192 - val_acc: 0.7833\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5227 - acc: 0.7259 - val_loss: 0.5173 - val_acc: 0.7833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5426 - acc: 0.7278 - val_loss: 0.5168 - val_acc: 0.7833\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.5527 - acc: 0.7185 - val_loss: 0.5162 - val_acc: 0.7833\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5007 - acc: 0.7556 - val_loss: 0.5140 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.51323 to 0.50827, saving model to best.model\n",
      "0s - loss: 0.5299 - acc: 0.7333 - val_loss: 0.5083 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.50827 to 0.50239, saving model to best.model\n",
      "0s - loss: 0.4861 - acc: 0.7611 - val_loss: 0.5024 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.50239 to 0.49928, saving model to best.model\n",
      "0s - loss: 0.5083 - acc: 0.7630 - val_loss: 0.4993 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.49928 to 0.49871, saving model to best.model\n",
      "0s - loss: 0.5333 - acc: 0.7241 - val_loss: 0.4987 - val_acc: 0.7833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5028 - acc: 0.7500 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4910 - acc: 0.7611 - val_loss: 0.5029 - val_acc: 0.7833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.5186 - acc: 0.7315 - val_loss: 0.5043 - val_acc: 0.7833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5037 - acc: 0.7426 - val_loss: 0.5036 - val_acc: 0.7833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4977 - acc: 0.7593 - val_loss: 0.5014 - val_acc: 0.7833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4928 - acc: 0.7556 - val_loss: 0.4995 - val_acc: 0.7833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.49871 to 0.49723, saving model to best.model\n",
      "0s - loss: 0.4816 - acc: 0.7667 - val_loss: 0.4972 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.49723 to 0.49582, saving model to best.model\n",
      "0s - loss: 0.4875 - acc: 0.7537 - val_loss: 0.4958 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.49582 to 0.49524, saving model to best.model\n",
      "0s - loss: 0.4991 - acc: 0.7741 - val_loss: 0.4952 - val_acc: 0.8000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4883 - acc: 0.7667 - val_loss: 0.4954 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4866 - acc: 0.7574 - val_loss: 0.4963 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4640 - acc: 0.7852 - val_loss: 0.4975 - val_acc: 0.7667\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4708 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5213 - acc: 0.7352 - val_loss: 0.4988 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4713 - acc: 0.7648 - val_loss: 0.4977 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4814 - acc: 0.7741 - val_loss: 0.4975 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4756 - acc: 0.7833 - val_loss: 0.4966 - val_acc: 0.7833\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4886 - acc: 0.7778 - val_loss: 0.4955 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.49524 to 0.49434, saving model to best.model\n",
      "0s - loss: 0.4772 - acc: 0.7704 - val_loss: 0.4943 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4855 - acc: 0.7667 - val_loss: 0.4948 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4854 - acc: 0.7630 - val_loss: 0.4956 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4630 - acc: 0.7685 - val_loss: 0.4953 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.49434 to 0.49412, saving model to best.model\n",
      "0s - loss: 0.4773 - acc: 0.7759 - val_loss: 0.4941 - val_acc: 0.7833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.49412 to 0.49334, saving model to best.model\n",
      "0s - loss: 0.4738 - acc: 0.7519 - val_loss: 0.4933 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.49334 to 0.49308, saving model to best.model\n",
      "0s - loss: 0.4785 - acc: 0.7944 - val_loss: 0.4931 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4612 - acc: 0.7741 - val_loss: 0.4940 - val_acc: 0.7833\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4653 - acc: 0.8074 - val_loss: 0.4944 - val_acc: 0.7833\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4659 - acc: 0.7648 - val_loss: 0.4938 - val_acc: 0.7667\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4539 - acc: 0.7815 - val_loss: 0.4937 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4776 - acc: 0.7778 - val_loss: 0.4933 - val_acc: 0.7500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.7852 - val_loss: 0.4935 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4514 - acc: 0.7722 - val_loss: 0.4934 - val_acc: 0.7500\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.49308 to 0.49289, saving model to best.model\n",
      "0s - loss: 0.4442 - acc: 0.8019 - val_loss: 0.4929 - val_acc: 0.7500\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.49289 to 0.49273, saving model to best.model\n",
      "0s - loss: 0.4573 - acc: 0.7759 - val_loss: 0.4927 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4474 - acc: 0.7870 - val_loss: 0.4935 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4673 - acc: 0.7889 - val_loss: 0.4950 - val_acc: 0.7833\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4481 - acc: 0.8056 - val_loss: 0.4964 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4497 - acc: 0.7944 - val_loss: 0.4964 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4503 - acc: 0.7944 - val_loss: 0.4943 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.49273 to 0.48732, saving model to best.model\n",
      "0s - loss: 0.4471 - acc: 0.7833 - val_loss: 0.4873 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.48732 to 0.48034, saving model to best.model\n",
      "0s - loss: 0.4537 - acc: 0.7926 - val_loss: 0.4803 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.48034 to 0.47379, saving model to best.model\n",
      "0s - loss: 0.4605 - acc: 0.7648 - val_loss: 0.4738 - val_acc: 0.7833\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.47379 to 0.46891, saving model to best.model\n",
      "0s - loss: 0.4442 - acc: 0.7981 - val_loss: 0.4689 - val_acc: 0.8000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.46891 to 0.46597, saving model to best.model\n",
      "0s - loss: 0.4358 - acc: 0.7963 - val_loss: 0.4660 - val_acc: 0.8000\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.46597 to 0.46283, saving model to best.model\n",
      "0s - loss: 0.4333 - acc: 0.8019 - val_loss: 0.4628 - val_acc: 0.8000\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.46283 to 0.45817, saving model to best.model\n",
      "0s - loss: 0.4359 - acc: 0.8019 - val_loss: 0.4582 - val_acc: 0.8167\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.45817 to 0.45371, saving model to best.model\n",
      "0s - loss: 0.4318 - acc: 0.7944 - val_loss: 0.4537 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.45371 to 0.45056, saving model to best.model\n",
      "0s - loss: 0.4182 - acc: 0.7944 - val_loss: 0.4506 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4341 - acc: 0.7944 - val_loss: 0.4506 - val_acc: 0.8167\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4243 - acc: 0.7833 - val_loss: 0.4513 - val_acc: 0.8333\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4327 - acc: 0.8056 - val_loss: 0.4541 - val_acc: 0.8333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4285 - acc: 0.7907 - val_loss: 0.4551 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4349 - acc: 0.8000 - val_loss: 0.4575 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4118 - acc: 0.8296 - val_loss: 0.4604 - val_acc: 0.8167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3805 - acc: 0.8278 - val_loss: 0.4617 - val_acc: 0.8167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4047 - acc: 0.8148 - val_loss: 0.4620 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4253 - acc: 0.8093 - val_loss: 0.4634 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4118 - acc: 0.8315 - val_loss: 0.4633 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3983 - acc: 0.8130 - val_loss: 0.4624 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3952 - acc: 0.8370 - val_loss: 0.4645 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4044 - acc: 0.8037 - val_loss: 0.4624 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4104 - acc: 0.8204 - val_loss: 0.4558 - val_acc: 0.8167\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss improved from 0.45056 to 0.45011, saving model to best.model\n",
      "0s - loss: 0.4170 - acc: 0.8204 - val_loss: 0.4501 - val_acc: 0.8167\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.45011 to 0.44962, saving model to best.model\n",
      "0s - loss: 0.3993 - acc: 0.8185 - val_loss: 0.4496 - val_acc: 0.8167\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.4121 - acc: 0.8074 - val_loss: 0.4518 - val_acc: 0.8167\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3936 - acc: 0.8333 - val_loss: 0.4554 - val_acc: 0.8167\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3936 - acc: 0.8259 - val_loss: 0.4599 - val_acc: 0.8167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3690 - acc: 0.8426 - val_loss: 0.4628 - val_acc: 0.8167\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3724 - acc: 0.8204 - val_loss: 0.4651 - val_acc: 0.8167\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3980 - acc: 0.8093 - val_loss: 0.4695 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3948 - acc: 0.8296 - val_loss: 0.4693 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3803 - acc: 0.8185 - val_loss: 0.4611 - val_acc: 0.8167\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3818 - acc: 0.8537 - val_loss: 0.4540 - val_acc: 0.8167\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3872 - acc: 0.8185 - val_loss: 0.4527 - val_acc: 0.8167\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3809 - acc: 0.8222 - val_loss: 0.4551 - val_acc: 0.8167\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.4323 - acc: 0.7981 - val_loss: 0.4555 - val_acc: 0.8167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3762 - acc: 0.8278 - val_loss: 0.4593 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3751 - acc: 0.8333 - val_loss: 0.4672 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3979 - acc: 0.8204 - val_loss: 0.4757 - val_acc: 0.8167\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3601 - acc: 0.8426 - val_loss: 0.4775 - val_acc: 0.8167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3677 - acc: 0.8352 - val_loss: 0.4706 - val_acc: 0.8167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3608 - acc: 0.8519 - val_loss: 0.4633 - val_acc: 0.8167\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3572 - acc: 0.8444 - val_loss: 0.4614 - val_acc: 0.8167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3669 - acc: 0.8519 - val_loss: 0.4625 - val_acc: 0.8000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3573 - acc: 0.8426 - val_loss: 0.4634 - val_acc: 0.8000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3517 - acc: 0.8481 - val_loss: 0.4622 - val_acc: 0.8167\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3575 - acc: 0.8444 - val_loss: 0.4626 - val_acc: 0.8167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3656 - acc: 0.8222 - val_loss: 0.4581 - val_acc: 0.8167\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3541 - acc: 0.8407 - val_loss: 0.4525 - val_acc: 0.8167\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.44962 to 0.44691, saving model to best.model\n",
      "0s - loss: 0.3555 - acc: 0.8481 - val_loss: 0.4469 - val_acc: 0.8167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.44691 to 0.44361, saving model to best.model\n",
      "0s - loss: 0.3617 - acc: 0.8296 - val_loss: 0.4436 - val_acc: 0.8167\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.44361 to 0.44357, saving model to best.model\n",
      "0s - loss: 0.3386 - acc: 0.8407 - val_loss: 0.4436 - val_acc: 0.8167\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3487 - acc: 0.8556 - val_loss: 0.4451 - val_acc: 0.8167\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3290 - acc: 0.8759 - val_loss: 0.4488 - val_acc: 0.8167\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3195 - acc: 0.8667 - val_loss: 0.4534 - val_acc: 0.8167\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3803 - acc: 0.8241 - val_loss: 0.4577 - val_acc: 0.8167\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3326 - acc: 0.8574 - val_loss: 0.4614 - val_acc: 0.8167\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3256 - acc: 0.8593 - val_loss: 0.4658 - val_acc: 0.8167\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3156 - acc: 0.8611 - val_loss: 0.4679 - val_acc: 0.8167\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3381 - acc: 0.8481 - val_loss: 0.4650 - val_acc: 0.8167\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3401 - acc: 0.8519 - val_loss: 0.4601 - val_acc: 0.8167\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3335 - acc: 0.8667 - val_loss: 0.4592 - val_acc: 0.8167\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3520 - acc: 0.8352 - val_loss: 0.4591 - val_acc: 0.8333\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3005 - acc: 0.8796 - val_loss: 0.4618 - val_acc: 0.8333\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3282 - acc: 0.8444 - val_loss: 0.4654 - val_acc: 0.8333\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3063 - acc: 0.8648 - val_loss: 0.4698 - val_acc: 0.8333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3276 - acc: 0.8556 - val_loss: 0.4767 - val_acc: 0.8167\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3027 - acc: 0.8722 - val_loss: 0.4817 - val_acc: 0.8000\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3021 - acc: 0.8685 - val_loss: 0.4811 - val_acc: 0.8167\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3023 - acc: 0.8685 - val_loss: 0.4780 - val_acc: 0.8333\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2832 - acc: 0.8852 - val_loss: 0.4788 - val_acc: 0.8167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3114 - acc: 0.8648 - val_loss: 0.4799 - val_acc: 0.8167\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.2985 - acc: 0.8833 - val_loss: 0.4785 - val_acc: 0.8167\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.2982 - acc: 0.8704 - val_loss: 0.4755 - val_acc: 0.8167\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3177 - acc: 0.8556 - val_loss: 0.4692 - val_acc: 0.8167\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3308 - acc: 0.8722 - val_loss: 0.4627 - val_acc: 0.8167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3051 - acc: 0.8685 - val_loss: 0.4574 - val_acc: 0.8167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2969 - acc: 0.8630 - val_loss: 0.4571 - val_acc: 0.8167\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.68642, saving model to best.model\n",
      "0s - loss: 0.6275 - acc: 0.6704 - val_loss: 0.6864 - val_acc: 0.5833\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.68642 to 0.65928, saving model to best.model\n",
      "0s - loss: 0.6804 - acc: 0.6796 - val_loss: 0.6593 - val_acc: 0.5833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.65928 to 0.63968, saving model to best.model\n",
      "0s - loss: 0.6653 - acc: 0.6722 - val_loss: 0.6397 - val_acc: 0.5833\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.63968 to 0.63210, saving model to best.model\n",
      "0s - loss: 0.6769 - acc: 0.6352 - val_loss: 0.6321 - val_acc: 0.5833\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.63210 to 0.62945, saving model to best.model\n",
      "0s - loss: 0.5946 - acc: 0.6981 - val_loss: 0.6294 - val_acc: 0.5833\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.62945 to 0.62379, saving model to best.model\n",
      "0s - loss: 0.6012 - acc: 0.7000 - val_loss: 0.6238 - val_acc: 0.5833\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.62379 to 0.61918, saving model to best.model\n",
      "0s - loss: 0.6239 - acc: 0.6759 - val_loss: 0.6192 - val_acc: 0.6000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.61918 to 0.61448, saving model to best.model\n",
      "0s - loss: 0.6083 - acc: 0.6907 - val_loss: 0.6145 - val_acc: 0.6167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.61448 to 0.61182, saving model to best.model\n",
      "0s - loss: 0.5913 - acc: 0.6963 - val_loss: 0.6118 - val_acc: 0.6333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.61182 to 0.61076, saving model to best.model\n",
      "0s - loss: 0.6135 - acc: 0.6944 - val_loss: 0.6108 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.61076 to 0.60993, saving model to best.model\n",
      "0s - loss: 0.5799 - acc: 0.6889 - val_loss: 0.6099 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5863 - acc: 0.6963 - val_loss: 0.6100 - val_acc: 0.6500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5669 - acc: 0.7241 - val_loss: 0.6120 - val_acc: 0.6167\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5415 - acc: 0.7370 - val_loss: 0.6148 - val_acc: 0.6167\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5668 - acc: 0.7130 - val_loss: 0.6163 - val_acc: 0.6167\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5646 - acc: 0.7111 - val_loss: 0.6124 - val_acc: 0.6333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.60993 to 0.60692, saving model to best.model\n",
      "0s - loss: 0.5540 - acc: 0.7333 - val_loss: 0.6069 - val_acc: 0.6333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.60692 to 0.60336, saving model to best.model\n",
      "0s - loss: 0.5437 - acc: 0.7222 - val_loss: 0.6034 - val_acc: 0.6500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.60336 to 0.60123, saving model to best.model\n",
      "0s - loss: 0.5514 - acc: 0.7389 - val_loss: 0.6012 - val_acc: 0.6333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.60123 to 0.60005, saving model to best.model\n",
      "0s - loss: 0.5405 - acc: 0.7259 - val_loss: 0.6001 - val_acc: 0.6500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.60005 to 0.59892, saving model to best.model\n",
      "0s - loss: 0.5461 - acc: 0.7259 - val_loss: 0.5989 - val_acc: 0.6833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.59892 to 0.59752, saving model to best.model\n",
      "0s - loss: 0.5419 - acc: 0.7148 - val_loss: 0.5975 - val_acc: 0.6833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.59752 to 0.59712, saving model to best.model\n",
      "0s - loss: 0.5526 - acc: 0.7370 - val_loss: 0.5971 - val_acc: 0.6667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5344 - acc: 0.7296 - val_loss: 0.5988 - val_acc: 0.6667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5522 - acc: 0.7241 - val_loss: 0.6007 - val_acc: 0.6500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5303 - acc: 0.7333 - val_loss: 0.6038 - val_acc: 0.6500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5477 - acc: 0.7148 - val_loss: 0.6058 - val_acc: 0.6333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5311 - acc: 0.7352 - val_loss: 0.6041 - val_acc: 0.6333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5128 - acc: 0.7222 - val_loss: 0.6027 - val_acc: 0.6333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5321 - acc: 0.7185 - val_loss: 0.6014 - val_acc: 0.6500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5344 - acc: 0.7185 - val_loss: 0.5998 - val_acc: 0.6500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5267 - acc: 0.7315 - val_loss: 0.6001 - val_acc: 0.6333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5176 - acc: 0.7167 - val_loss: 0.5994 - val_acc: 0.6500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.59712 to 0.59500, saving model to best.model\n",
      "0s - loss: 0.5295 - acc: 0.7278 - val_loss: 0.5950 - val_acc: 0.6667\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.59500 to 0.59106, saving model to best.model\n",
      "0s - loss: 0.5039 - acc: 0.7574 - val_loss: 0.5911 - val_acc: 0.6833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.59106 to 0.59005, saving model to best.model\n",
      "0s - loss: 0.5197 - acc: 0.7407 - val_loss: 0.5900 - val_acc: 0.7000\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.4983 - acc: 0.7556 - val_loss: 0.5909 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.59005 to 0.58980, saving model to best.model\n",
      "0s - loss: 0.5234 - acc: 0.7259 - val_loss: 0.5898 - val_acc: 0.7000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.58980 to 0.58892, saving model to best.model\n",
      "0s - loss: 0.5104 - acc: 0.7278 - val_loss: 0.5889 - val_acc: 0.7000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.58892 to 0.58742, saving model to best.model\n",
      "0s - loss: 0.5137 - acc: 0.7556 - val_loss: 0.5874 - val_acc: 0.7000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.58742 to 0.58428, saving model to best.model\n",
      "0s - loss: 0.4967 - acc: 0.7352 - val_loss: 0.5843 - val_acc: 0.7000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.58428 to 0.58403, saving model to best.model\n",
      "0s - loss: 0.5043 - acc: 0.7481 - val_loss: 0.5840 - val_acc: 0.7167\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4891 - acc: 0.7500 - val_loss: 0.5843 - val_acc: 0.7167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.58403 to 0.58284, saving model to best.model\n",
      "0s - loss: 0.4936 - acc: 0.7463 - val_loss: 0.5828 - val_acc: 0.7333\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.58284 to 0.58032, saving model to best.model\n",
      "0s - loss: 0.4837 - acc: 0.7648 - val_loss: 0.5803 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.58032 to 0.57689, saving model to best.model\n",
      "0s - loss: 0.5228 - acc: 0.7426 - val_loss: 0.5769 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.57689 to 0.57521, saving model to best.model\n",
      "0s - loss: 0.4838 - acc: 0.7759 - val_loss: 0.5752 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.57521 to 0.57449, saving model to best.model\n",
      "0s - loss: 0.4683 - acc: 0.7630 - val_loss: 0.5745 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.57449 to 0.57396, saving model to best.model\n",
      "0s - loss: 0.5057 - acc: 0.7574 - val_loss: 0.5740 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.57396 to 0.57264, saving model to best.model\n",
      "0s - loss: 0.4636 - acc: 0.7926 - val_loss: 0.5726 - val_acc: 0.7500\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.57264 to 0.56890, saving model to best.model\n",
      "0s - loss: 0.4918 - acc: 0.7574 - val_loss: 0.5689 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.56890 to 0.56401, saving model to best.model\n",
      "0s - loss: 0.4768 - acc: 0.7722 - val_loss: 0.5640 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4930 - acc: 0.7519 - val_loss: 0.5641 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.5028 - acc: 0.7685 - val_loss: 0.5679 - val_acc: 0.7667\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4981 - acc: 0.7500 - val_loss: 0.5719 - val_acc: 0.7333\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4843 - acc: 0.7630 - val_loss: 0.5758 - val_acc: 0.7500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4686 - acc: 0.7852 - val_loss: 0.5812 - val_acc: 0.7500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4820 - acc: 0.7667 - val_loss: 0.5844 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4907 - acc: 0.7574 - val_loss: 0.5783 - val_acc: 0.7500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4527 - acc: 0.7981 - val_loss: 0.5715 - val_acc: 0.7333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4686 - acc: 0.7667 - val_loss: 0.5693 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4643 - acc: 0.7741 - val_loss: 0.5688 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4802 - acc: 0.7852 - val_loss: 0.5655 - val_acc: 0.7667\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.56401 to 0.55970, saving model to best.model\n",
      "0s - loss: 0.4706 - acc: 0.8037 - val_loss: 0.5597 - val_acc: 0.7667\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.55970 to 0.55388, saving model to best.model\n",
      "0s - loss: 0.4610 - acc: 0.7778 - val_loss: 0.5539 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.55388 to 0.55050, saving model to best.model\n",
      "0s - loss: 0.4622 - acc: 0.7944 - val_loss: 0.5505 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4618 - acc: 0.7796 - val_loss: 0.5506 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.55050 to 0.54881, saving model to best.model\n",
      "0s - loss: 0.4571 - acc: 0.7870 - val_loss: 0.5488 - val_acc: 0.7667\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.54881 to 0.54842, saving model to best.model\n",
      "0s - loss: 0.4477 - acc: 0.8093 - val_loss: 0.5484 - val_acc: 0.7667\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4595 - acc: 0.7833 - val_loss: 0.5515 - val_acc: 0.7667\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4398 - acc: 0.7926 - val_loss: 0.5520 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.54842 to 0.54768, saving model to best.model\n",
      "0s - loss: 0.4471 - acc: 0.7870 - val_loss: 0.5477 - val_acc: 0.7667\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.54768 to 0.54141, saving model to best.model\n",
      "0s - loss: 0.4814 - acc: 0.7944 - val_loss: 0.5414 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.54141 to 0.53835, saving model to best.model\n",
      "0s - loss: 0.4310 - acc: 0.7926 - val_loss: 0.5384 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.53835 to 0.53581, saving model to best.model\n",
      "0s - loss: 0.4335 - acc: 0.8222 - val_loss: 0.5358 - val_acc: 0.7833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.53581 to 0.53416, saving model to best.model\n",
      "0s - loss: 0.4369 - acc: 0.7926 - val_loss: 0.5342 - val_acc: 0.8000\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4192 - acc: 0.8074 - val_loss: 0.5359 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4509 - acc: 0.7833 - val_loss: 0.5405 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4367 - acc: 0.8056 - val_loss: 0.5439 - val_acc: 0.8167\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4274 - acc: 0.8019 - val_loss: 0.5533 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4224 - acc: 0.8130 - val_loss: 0.5573 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4491 - acc: 0.7833 - val_loss: 0.5554 - val_acc: 0.8000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4365 - acc: 0.8074 - val_loss: 0.5503 - val_acc: 0.8167\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4250 - acc: 0.8056 - val_loss: 0.5439 - val_acc: 0.8000\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4303 - acc: 0.8019 - val_loss: 0.5404 - val_acc: 0.8000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4338 - acc: 0.7963 - val_loss: 0.5343 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.53416 to 0.53146, saving model to best.model\n",
      "0s - loss: 0.4131 - acc: 0.7981 - val_loss: 0.5315 - val_acc: 0.8333\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.53146 to 0.52775, saving model to best.model\n",
      "0s - loss: 0.4074 - acc: 0.8222 - val_loss: 0.5278 - val_acc: 0.8333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.52775 to 0.52556, saving model to best.model\n",
      "0s - loss: 0.3880 - acc: 0.8296 - val_loss: 0.5256 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4139 - acc: 0.8148 - val_loss: 0.5264 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3768 - acc: 0.8407 - val_loss: 0.5303 - val_acc: 0.8333\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4075 - acc: 0.8278 - val_loss: 0.5337 - val_acc: 0.8333\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.3829 - acc: 0.8204 - val_loss: 0.5353 - val_acc: 0.8333\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4108 - acc: 0.8111 - val_loss: 0.5343 - val_acc: 0.8333\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3891 - acc: 0.8296 - val_loss: 0.5394 - val_acc: 0.8167\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4132 - acc: 0.8259 - val_loss: 0.5434 - val_acc: 0.8333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3869 - acc: 0.8315 - val_loss: 0.5466 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3950 - acc: 0.8259 - val_loss: 0.5425 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3752 - acc: 0.8315 - val_loss: 0.5326 - val_acc: 0.8500\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.52556 to 0.52524, saving model to best.model\n",
      "0s - loss: 0.3963 - acc: 0.8333 - val_loss: 0.5252 - val_acc: 0.8500\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.52524 to 0.52163, saving model to best.model\n",
      "0s - loss: 0.4036 - acc: 0.8074 - val_loss: 0.5216 - val_acc: 0.8500\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3897 - acc: 0.8278 - val_loss: 0.5277 - val_acc: 0.8500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3800 - acc: 0.8185 - val_loss: 0.5421 - val_acc: 0.8333\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3642 - acc: 0.8352 - val_loss: 0.5632 - val_acc: 0.8333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3623 - acc: 0.8463 - val_loss: 0.5819 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3702 - acc: 0.8407 - val_loss: 0.5882 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3806 - acc: 0.8185 - val_loss: 0.5700 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3651 - acc: 0.8537 - val_loss: 0.5523 - val_acc: 0.8500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3851 - acc: 0.8185 - val_loss: 0.5392 - val_acc: 0.8500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3483 - acc: 0.8537 - val_loss: 0.5301 - val_acc: 0.8500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3652 - acc: 0.8463 - val_loss: 0.5275 - val_acc: 0.8500\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3421 - acc: 0.8574 - val_loss: 0.5327 - val_acc: 0.8500\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3501 - acc: 0.8574 - val_loss: 0.5446 - val_acc: 0.8500\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3847 - acc: 0.8426 - val_loss: 0.5513 - val_acc: 0.8500\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3563 - acc: 0.8500 - val_loss: 0.5560 - val_acc: 0.8500\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3410 - acc: 0.8481 - val_loss: 0.5638 - val_acc: 0.8500\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3607 - acc: 0.8370 - val_loss: 0.5647 - val_acc: 0.8500\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3546 - acc: 0.8500 - val_loss: 0.5539 - val_acc: 0.8500\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3413 - acc: 0.8537 - val_loss: 0.5478 - val_acc: 0.8500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3565 - acc: 0.8259 - val_loss: 0.5418 - val_acc: 0.8667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3294 - acc: 0.8574 - val_loss: 0.5446 - val_acc: 0.8667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3568 - acc: 0.8481 - val_loss: 0.5558 - val_acc: 0.8500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3286 - acc: 0.8463 - val_loss: 0.5659 - val_acc: 0.8500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3244 - acc: 0.8685 - val_loss: 0.5732 - val_acc: 0.8500\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3025 - acc: 0.8648 - val_loss: 0.5860 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3550 - acc: 0.8370 - val_loss: 0.5857 - val_acc: 0.8500\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3626 - acc: 0.8537 - val_loss: 0.5664 - val_acc: 0.8500\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.50866, saving model to best.model\n",
      "0s - loss: 0.7472 - acc: 0.6204 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.50866 to 0.50111, saving model to best.model\n",
      "0s - loss: 0.7448 - acc: 0.6648 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.50111 to 0.49485, saving model to best.model\n",
      "0s - loss: 0.6751 - acc: 0.6889 - val_loss: 0.4948 - val_acc: 0.7500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6570 - acc: 0.6759 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6204 - acc: 0.6611 - val_loss: 0.5049 - val_acc: 0.7500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6383 - acc: 0.6667 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6293 - acc: 0.7000 - val_loss: 0.4985 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6238 - acc: 0.6944 - val_loss: 0.4973 - val_acc: 0.7667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6228 - acc: 0.6778 - val_loss: 0.4955 - val_acc: 0.7667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.49485 to 0.48728, saving model to best.model\n",
      "0s - loss: 0.5908 - acc: 0.6981 - val_loss: 0.4873 - val_acc: 0.7667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.48728 to 0.48199, saving model to best.model\n",
      "0s - loss: 0.5970 - acc: 0.7111 - val_loss: 0.4820 - val_acc: 0.7667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.48199 to 0.48192, saving model to best.model\n",
      "0s - loss: 0.5908 - acc: 0.6981 - val_loss: 0.4819 - val_acc: 0.7667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.48192 to 0.48156, saving model to best.model\n",
      "0s - loss: 0.5994 - acc: 0.7130 - val_loss: 0.4816 - val_acc: 0.7667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.48156 to 0.47931, saving model to best.model\n",
      "0s - loss: 0.5998 - acc: 0.7204 - val_loss: 0.4793 - val_acc: 0.7667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.47931 to 0.47683, saving model to best.model\n",
      "0s - loss: 0.5934 - acc: 0.7093 - val_loss: 0.4768 - val_acc: 0.7667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.47683 to 0.47395, saving model to best.model\n",
      "0s - loss: 0.5568 - acc: 0.7185 - val_loss: 0.4740 - val_acc: 0.7667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.47395 to 0.46976, saving model to best.model\n",
      "0s - loss: 0.5580 - acc: 0.7130 - val_loss: 0.4698 - val_acc: 0.7667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.46976 to 0.46702, saving model to best.model\n",
      "0s - loss: 0.5685 - acc: 0.7130 - val_loss: 0.4670 - val_acc: 0.7833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5710 - acc: 0.7241 - val_loss: 0.4677 - val_acc: 0.8000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5401 - acc: 0.7167 - val_loss: 0.4695 - val_acc: 0.8167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5432 - acc: 0.7444 - val_loss: 0.4702 - val_acc: 0.8167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.46702 to 0.46493, saving model to best.model\n",
      "0s - loss: 0.5118 - acc: 0.7407 - val_loss: 0.4649 - val_acc: 0.8167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.46493 to 0.45562, saving model to best.model\n",
      "0s - loss: 0.5380 - acc: 0.7296 - val_loss: 0.4556 - val_acc: 0.8167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.45562 to 0.44658, saving model to best.model\n",
      "0s - loss: 0.5279 - acc: 0.7426 - val_loss: 0.4466 - val_acc: 0.8333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.44658 to 0.44068, saving model to best.model\n",
      "0s - loss: 0.5108 - acc: 0.7500 - val_loss: 0.4407 - val_acc: 0.8333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.44068 to 0.43669, saving model to best.model\n",
      "0s - loss: 0.5163 - acc: 0.7407 - val_loss: 0.4367 - val_acc: 0.8333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.43669 to 0.43440, saving model to best.model\n",
      "0s - loss: 0.5225 - acc: 0.7500 - val_loss: 0.4344 - val_acc: 0.8500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5228 - acc: 0.7481 - val_loss: 0.4365 - val_acc: 0.8667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5023 - acc: 0.7648 - val_loss: 0.4393 - val_acc: 0.8667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5355 - acc: 0.7519 - val_loss: 0.4379 - val_acc: 0.8667\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.43440 to 0.43005, saving model to best.model\n",
      "0s - loss: 0.5032 - acc: 0.7407 - val_loss: 0.4301 - val_acc: 0.8667\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.43005 to 0.42012, saving model to best.model\n",
      "0s - loss: 0.4983 - acc: 0.7778 - val_loss: 0.4201 - val_acc: 0.8667\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.42012 to 0.41174, saving model to best.model\n",
      "0s - loss: 0.4939 - acc: 0.7481 - val_loss: 0.4117 - val_acc: 0.8667\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.41174 to 0.40422, saving model to best.model\n",
      "0s - loss: 0.5335 - acc: 0.7537 - val_loss: 0.4042 - val_acc: 0.8667\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.40422 to 0.40142, saving model to best.model\n",
      "0s - loss: 0.5306 - acc: 0.7519 - val_loss: 0.4014 - val_acc: 0.8667\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5165 - acc: 0.7444 - val_loss: 0.4065 - val_acc: 0.8667\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5221 - acc: 0.7407 - val_loss: 0.4105 - val_acc: 0.8500\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5034 - acc: 0.7759 - val_loss: 0.4146 - val_acc: 0.8500\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5130 - acc: 0.7722 - val_loss: 0.4167 - val_acc: 0.8500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.4826 - acc: 0.7722 - val_loss: 0.4135 - val_acc: 0.8500\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4729 - acc: 0.7815 - val_loss: 0.4058 - val_acc: 0.8500\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.40142 to 0.39870, saving model to best.model\n",
      "0s - loss: 0.4928 - acc: 0.7778 - val_loss: 0.3987 - val_acc: 0.8500\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.39870 to 0.39243, saving model to best.model\n",
      "0s - loss: 0.4761 - acc: 0.7796 - val_loss: 0.3924 - val_acc: 0.8500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.39243 to 0.38623, saving model to best.model\n",
      "0s - loss: 0.4535 - acc: 0.7778 - val_loss: 0.3862 - val_acc: 0.8500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.38623 to 0.38338, saving model to best.model\n",
      "0s - loss: 0.4774 - acc: 0.7796 - val_loss: 0.3834 - val_acc: 0.8500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4928 - acc: 0.7870 - val_loss: 0.3851 - val_acc: 0.8500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4896 - acc: 0.7926 - val_loss: 0.3845 - val_acc: 0.8500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4681 - acc: 0.7833 - val_loss: 0.3852 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4564 - acc: 0.8093 - val_loss: 0.3875 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4656 - acc: 0.8037 - val_loss: 0.3894 - val_acc: 0.8333\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4665 - acc: 0.8056 - val_loss: 0.3938 - val_acc: 0.8167\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4553 - acc: 0.7815 - val_loss: 0.3937 - val_acc: 0.8167\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4410 - acc: 0.7944 - val_loss: 0.3891 - val_acc: 0.8167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.38338 to 0.38287, saving model to best.model\n",
      "0s - loss: 0.4497 - acc: 0.7889 - val_loss: 0.3829 - val_acc: 0.8333\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.38287 to 0.38146, saving model to best.model\n",
      "0s - loss: 0.4942 - acc: 0.7833 - val_loss: 0.3815 - val_acc: 0.8500\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.38146 to 0.37670, saving model to best.model\n",
      "0s - loss: 0.4666 - acc: 0.7907 - val_loss: 0.3767 - val_acc: 0.8500\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.37670 to 0.37241, saving model to best.model\n",
      "0s - loss: 0.4541 - acc: 0.8056 - val_loss: 0.3724 - val_acc: 0.8500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.37241 to 0.36987, saving model to best.model\n",
      "0s - loss: 0.4360 - acc: 0.8093 - val_loss: 0.3699 - val_acc: 0.8500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.36987 to 0.36967, saving model to best.model\n",
      "0s - loss: 0.4212 - acc: 0.8111 - val_loss: 0.3697 - val_acc: 0.8500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4313 - acc: 0.8222 - val_loss: 0.3706 - val_acc: 0.8500\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.36967 to 0.36710, saving model to best.model\n",
      "0s - loss: 0.4363 - acc: 0.8185 - val_loss: 0.3671 - val_acc: 0.8500\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.36710 to 0.36290, saving model to best.model\n",
      "0s - loss: 0.4431 - acc: 0.7944 - val_loss: 0.3629 - val_acc: 0.8500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.36290 to 0.36150, saving model to best.model\n",
      "0s - loss: 0.4437 - acc: 0.8167 - val_loss: 0.3615 - val_acc: 0.8333\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4142 - acc: 0.8241 - val_loss: 0.3616 - val_acc: 0.8333\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.36150 to 0.35952, saving model to best.model\n",
      "0s - loss: 0.4061 - acc: 0.8278 - val_loss: 0.3595 - val_acc: 0.8500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.35952 to 0.35606, saving model to best.model\n",
      "0s - loss: 0.4302 - acc: 0.8074 - val_loss: 0.3561 - val_acc: 0.8667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.35606 to 0.35393, saving model to best.model\n",
      "0s - loss: 0.4349 - acc: 0.8185 - val_loss: 0.3539 - val_acc: 0.8667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4447 - acc: 0.8074 - val_loss: 0.3572 - val_acc: 0.8500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4004 - acc: 0.8389 - val_loss: 0.3590 - val_acc: 0.8500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4243 - acc: 0.8111 - val_loss: 0.3612 - val_acc: 0.8667\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4220 - acc: 0.8000 - val_loss: 0.3659 - val_acc: 0.8667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4358 - acc: 0.8315 - val_loss: 0.3700 - val_acc: 0.8500\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4227 - acc: 0.7981 - val_loss: 0.3727 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4113 - acc: 0.8426 - val_loss: 0.3715 - val_acc: 0.8500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4223 - acc: 0.8333 - val_loss: 0.3711 - val_acc: 0.8500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4078 - acc: 0.8259 - val_loss: 0.3657 - val_acc: 0.8500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.3887 - acc: 0.8259 - val_loss: 0.3607 - val_acc: 0.8500\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4274 - acc: 0.8019 - val_loss: 0.3580 - val_acc: 0.8500\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.35393 to 0.35321, saving model to best.model\n",
      "0s - loss: 0.4219 - acc: 0.8056 - val_loss: 0.3532 - val_acc: 0.8667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.35321 to 0.34824, saving model to best.model\n",
      "0s - loss: 0.3982 - acc: 0.8111 - val_loss: 0.3482 - val_acc: 0.8667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.34824 to 0.34654, saving model to best.model\n",
      "0s - loss: 0.4328 - acc: 0.8093 - val_loss: 0.3465 - val_acc: 0.8667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.34654 to 0.34634, saving model to best.model\n",
      "0s - loss: 0.4095 - acc: 0.8296 - val_loss: 0.3463 - val_acc: 0.8667\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.3942 - acc: 0.8333 - val_loss: 0.3517 - val_acc: 0.8667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4003 - acc: 0.8222 - val_loss: 0.3559 - val_acc: 0.8667\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.3831 - acc: 0.8481 - val_loss: 0.3519 - val_acc: 0.8667\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.34634 to 0.34431, saving model to best.model\n",
      "0s - loss: 0.4080 - acc: 0.8056 - val_loss: 0.3443 - val_acc: 0.8667\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.34431 to 0.34140, saving model to best.model\n",
      "0s - loss: 0.4043 - acc: 0.8333 - val_loss: 0.3414 - val_acc: 0.8500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4081 - acc: 0.8333 - val_loss: 0.3430 - val_acc: 0.8500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4024 - acc: 0.8315 - val_loss: 0.3450 - val_acc: 0.8500\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.3909 - acc: 0.8278 - val_loss: 0.3464 - val_acc: 0.8500\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3947 - acc: 0.8370 - val_loss: 0.3458 - val_acc: 0.8333\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3971 - acc: 0.8333 - val_loss: 0.3428 - val_acc: 0.8333\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.34140 to 0.33919, saving model to best.model\n",
      "0s - loss: 0.3821 - acc: 0.8389 - val_loss: 0.3392 - val_acc: 0.8500\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.33919 to 0.33510, saving model to best.model\n",
      "0s - loss: 0.3974 - acc: 0.8426 - val_loss: 0.3351 - val_acc: 0.8500\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.33510 to 0.32956, saving model to best.model\n",
      "0s - loss: 0.3782 - acc: 0.8481 - val_loss: 0.3296 - val_acc: 0.8500\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.32956 to 0.32549, saving model to best.model\n",
      "0s - loss: 0.3808 - acc: 0.8333 - val_loss: 0.3255 - val_acc: 0.8500\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.32549 to 0.32371, saving model to best.model\n",
      "0s - loss: 0.3864 - acc: 0.8389 - val_loss: 0.3237 - val_acc: 0.8500\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.32371 to 0.32347, saving model to best.model\n",
      "0s - loss: 0.3698 - acc: 0.8463 - val_loss: 0.3235 - val_acc: 0.8667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3679 - acc: 0.8333 - val_loss: 0.3316 - val_acc: 0.8667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3674 - acc: 0.8481 - val_loss: 0.3479 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3539 - acc: 0.8519 - val_loss: 0.3552 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3530 - acc: 0.8574 - val_loss: 0.3437 - val_acc: 0.8500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3766 - acc: 0.8444 - val_loss: 0.3323 - val_acc: 0.8833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3815 - acc: 0.8370 - val_loss: 0.3287 - val_acc: 0.8667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3490 - acc: 0.8426 - val_loss: 0.3285 - val_acc: 0.8833\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3968 - acc: 0.8352 - val_loss: 0.3294 - val_acc: 0.8667\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3585 - acc: 0.8519 - val_loss: 0.3323 - val_acc: 0.8667\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3588 - acc: 0.8519 - val_loss: 0.3355 - val_acc: 0.8667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3779 - acc: 0.8370 - val_loss: 0.3371 - val_acc: 0.8667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3195 - acc: 0.8741 - val_loss: 0.3341 - val_acc: 0.8667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3768 - acc: 0.8370 - val_loss: 0.3300 - val_acc: 0.8667\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.32347 to 0.32303, saving model to best.model\n",
      "0s - loss: 0.3558 - acc: 0.8593 - val_loss: 0.3230 - val_acc: 0.8833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.32303 to 0.31646, saving model to best.model\n",
      "0s - loss: 0.3395 - acc: 0.8593 - val_loss: 0.3165 - val_acc: 0.8833\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.31646 to 0.31223, saving model to best.model\n",
      "0s - loss: 0.3647 - acc: 0.8537 - val_loss: 0.3122 - val_acc: 0.8667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.31223 to 0.31092, saving model to best.model\n",
      "0s - loss: 0.3290 - acc: 0.8796 - val_loss: 0.3109 - val_acc: 0.8667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3266 - acc: 0.8741 - val_loss: 0.3147 - val_acc: 0.8500\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3745 - acc: 0.8481 - val_loss: 0.3186 - val_acc: 0.8667\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3496 - acc: 0.8444 - val_loss: 0.3288 - val_acc: 0.8667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3428 - acc: 0.8537 - val_loss: 0.3361 - val_acc: 0.8500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3338 - acc: 0.8648 - val_loss: 0.3383 - val_acc: 0.8500\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3587 - acc: 0.8481 - val_loss: 0.3308 - val_acc: 0.8500\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3446 - acc: 0.8704 - val_loss: 0.3184 - val_acc: 0.8833\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.31092 to 0.31012, saving model to best.model\n",
      "0s - loss: 0.3242 - acc: 0.8556 - val_loss: 0.3101 - val_acc: 0.8833\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.31012 to 0.30624, saving model to best.model\n",
      "0s - loss: 0.3712 - acc: 0.8537 - val_loss: 0.3062 - val_acc: 0.8833\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.30624 to 0.30415, saving model to best.model\n",
      "0s - loss: 0.3346 - acc: 0.8444 - val_loss: 0.3042 - val_acc: 0.8833\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.30415 to 0.30296, saving model to best.model\n",
      "0s - loss: 0.3426 - acc: 0.8611 - val_loss: 0.3030 - val_acc: 0.8833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.30296 to 0.30240, saving model to best.model\n",
      "0s - loss: 0.3038 - acc: 0.8778 - val_loss: 0.3024 - val_acc: 0.8833\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3352 - acc: 0.8519 - val_loss: 0.3032 - val_acc: 0.8833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3099 - acc: 0.8759 - val_loss: 0.3037 - val_acc: 0.8833\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3257 - acc: 0.8556 - val_loss: 0.3031 - val_acc: 0.8833\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3260 - acc: 0.8630 - val_loss: 0.3043 - val_acc: 0.8833\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3317 - acc: 0.8519 - val_loss: 0.3069 - val_acc: 0.8833\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3406 - acc: 0.8667 - val_loss: 0.3053 - val_acc: 0.8833\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3148 - acc: 0.8630 - val_loss: 0.3068 - val_acc: 0.8667\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3142 - acc: 0.8704 - val_loss: 0.3117 - val_acc: 0.8500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3353 - acc: 0.8574 - val_loss: 0.3140 - val_acc: 0.8500\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3066 - acc: 0.8833 - val_loss: 0.3119 - val_acc: 0.8667\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3152 - acc: 0.8611 - val_loss: 0.3120 - val_acc: 0.8667\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3328 - acc: 0.8537 - val_loss: 0.3148 - val_acc: 0.8667\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3111 - acc: 0.8685 - val_loss: 0.3137 - val_acc: 0.8667\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3066 - acc: 0.8778 - val_loss: 0.3103 - val_acc: 0.8667\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.2884 - acc: 0.8796 - val_loss: 0.3072 - val_acc: 0.8667\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.2955 - acc: 0.8870 - val_loss: 0.3107 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.2797 - acc: 0.8963 - val_loss: 0.3163 - val_acc: 0.8833\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3170 - acc: 0.8852 - val_loss: 0.3161 - val_acc: 0.8833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3121 - acc: 0.8759 - val_loss: 0.3119 - val_acc: 0.8833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.2925 - acc: 0.8870 - val_loss: 0.3053 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.30240 to 0.30047, saving model to best.model\n",
      "0s - loss: 0.3185 - acc: 0.8648 - val_loss: 0.3005 - val_acc: 0.8667\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.2858 - acc: 0.8833 - val_loss: 0.3009 - val_acc: 0.8667\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.2905 - acc: 0.8852 - val_loss: 0.3044 - val_acc: 0.8833\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.2851 - acc: 0.8870 - val_loss: 0.3134 - val_acc: 0.8833\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.2982 - acc: 0.8852 - val_loss: 0.3079 - val_acc: 0.8833\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.30047 to 0.29614, saving model to best.model\n",
      "0s - loss: 0.2904 - acc: 0.8815 - val_loss: 0.2961 - val_acc: 0.8833\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.29614 to 0.28841, saving model to best.model\n",
      "0s - loss: 0.2995 - acc: 0.8852 - val_loss: 0.2884 - val_acc: 0.8667\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.28841 to 0.28608, saving model to best.model\n",
      "0s - loss: 0.3040 - acc: 0.8852 - val_loss: 0.2861 - val_acc: 0.8833\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.2967 - acc: 0.8870 - val_loss: 0.2891 - val_acc: 0.9000\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.2842 - acc: 0.8852 - val_loss: 0.2919 - val_acc: 0.9000\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.2927 - acc: 0.8796 - val_loss: 0.2924 - val_acc: 0.9000\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.2742 - acc: 0.8870 - val_loss: 0.2919 - val_acc: 0.9000\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.2795 - acc: 0.8926 - val_loss: 0.2938 - val_acc: 0.9000\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3109 - acc: 0.8796 - val_loss: 0.2975 - val_acc: 0.9000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2888 - acc: 0.8944 - val_loss: 0.2998 - val_acc: 0.9000\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.2698 - acc: 0.8815 - val_loss: 0.3002 - val_acc: 0.9000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2726 - acc: 0.8963 - val_loss: 0.2956 - val_acc: 0.8833\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2993 - acc: 0.8722 - val_loss: 0.2880 - val_acc: 0.8667\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss improved from 0.28608 to 0.28507, saving model to best.model\n",
      "0s - loss: 0.2585 - acc: 0.8963 - val_loss: 0.2851 - val_acc: 0.8667\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.2737 - acc: 0.8963 - val_loss: 0.2855 - val_acc: 0.8667\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2663 - acc: 0.8907 - val_loss: 0.2871 - val_acc: 0.8667\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2800 - acc: 0.8796 - val_loss: 0.2858 - val_acc: 0.8667\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss improved from 0.28507 to 0.28412, saving model to best.model\n",
      "0s - loss: 0.2596 - acc: 0.8907 - val_loss: 0.2841 - val_acc: 0.8667\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2630 - acc: 0.9000 - val_loss: 0.2853 - val_acc: 0.8833\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2623 - acc: 0.8870 - val_loss: 0.2931 - val_acc: 0.9000\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.2683 - acc: 0.8852 - val_loss: 0.2977 - val_acc: 0.9000\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2502 - acc: 0.8963 - val_loss: 0.2926 - val_acc: 0.9000\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2617 - acc: 0.8907 - val_loss: 0.2872 - val_acc: 0.8833\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2661 - acc: 0.8926 - val_loss: 0.2871 - val_acc: 0.9000\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2312 - acc: 0.9148 - val_loss: 0.2906 - val_acc: 0.9000\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2418 - acc: 0.9056 - val_loss: 0.2991 - val_acc: 0.9000\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2825 - acc: 0.8926 - val_loss: 0.2993 - val_acc: 0.9000\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2503 - acc: 0.9019 - val_loss: 0.2922 - val_acc: 0.9000\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2408 - acc: 0.9056 - val_loss: 0.2883 - val_acc: 0.9000\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2495 - acc: 0.9074 - val_loss: 0.2871 - val_acc: 0.9000\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2540 - acc: 0.8944 - val_loss: 0.2874 - val_acc: 0.8833\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2507 - acc: 0.9000 - val_loss: 0.2904 - val_acc: 0.9000\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2590 - acc: 0.8944 - val_loss: 0.2921 - val_acc: 0.9000\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2428 - acc: 0.8981 - val_loss: 0.2903 - val_acc: 0.9000\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2388 - acc: 0.9093 - val_loss: 0.2905 - val_acc: 0.9000\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2278 - acc: 0.9093 - val_loss: 0.2907 - val_acc: 0.9000\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2485 - acc: 0.9019 - val_loss: 0.2908 - val_acc: 0.9000\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.2257 - acc: 0.9111 - val_loss: 0.2870 - val_acc: 0.9000\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss improved from 0.28412 to 0.28346, saving model to best.model\n",
      "0s - loss: 0.2449 - acc: 0.9000 - val_loss: 0.2835 - val_acc: 0.9167\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss improved from 0.28346 to 0.27798, saving model to best.model\n",
      "0s - loss: 0.2245 - acc: 0.9019 - val_loss: 0.2780 - val_acc: 0.9167\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss improved from 0.27798 to 0.27421, saving model to best.model\n",
      "0s - loss: 0.2233 - acc: 0.8944 - val_loss: 0.2742 - val_acc: 0.8833\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss improved from 0.27421 to 0.27394, saving model to best.model\n",
      "0s - loss: 0.2344 - acc: 0.9204 - val_loss: 0.2739 - val_acc: 0.8833\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2434 - acc: 0.9056 - val_loss: 0.2789 - val_acc: 0.8833\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2202 - acc: 0.9259 - val_loss: 0.2876 - val_acc: 0.8833\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2235 - acc: 0.9056 - val_loss: 0.2934 - val_acc: 0.8833\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2054 - acc: 0.9241 - val_loss: 0.2939 - val_acc: 0.8833\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2102 - acc: 0.9278 - val_loss: 0.2925 - val_acc: 0.8833\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2386 - acc: 0.9111 - val_loss: 0.2933 - val_acc: 0.8833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.69072, saving model to best.model\n",
      "0s - loss: 0.7953 - acc: 0.5037 - val_loss: 0.6907 - val_acc: 0.5833\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7264 - acc: 0.6204 - val_loss: 0.7192 - val_acc: 0.5833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7316 - acc: 0.6426 - val_loss: 0.6956 - val_acc: 0.5833\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.69072 to 0.66957, saving model to best.model\n",
      "0s - loss: 0.6770 - acc: 0.6426 - val_loss: 0.6696 - val_acc: 0.5833\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.66957 to 0.65441, saving model to best.model\n",
      "0s - loss: 0.6857 - acc: 0.6370 - val_loss: 0.6544 - val_acc: 0.5833\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.65441 to 0.64590, saving model to best.model\n",
      "0s - loss: 0.6421 - acc: 0.6630 - val_loss: 0.6459 - val_acc: 0.6000\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.64590 to 0.64266, saving model to best.model\n",
      "0s - loss: 0.6256 - acc: 0.6407 - val_loss: 0.6427 - val_acc: 0.6000\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.64266 to 0.64245, saving model to best.model\n",
      "0s - loss: 0.6845 - acc: 0.6241 - val_loss: 0.6425 - val_acc: 0.6000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6438 - acc: 0.6333 - val_loss: 0.6425 - val_acc: 0.6000\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.64245 to 0.64077, saving model to best.model\n",
      "0s - loss: 0.6066 - acc: 0.6759 - val_loss: 0.6408 - val_acc: 0.5833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.64077 to 0.63991, saving model to best.model\n",
      "0s - loss: 0.6020 - acc: 0.6796 - val_loss: 0.6399 - val_acc: 0.6000\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.63991 to 0.63758, saving model to best.model\n",
      "0s - loss: 0.6085 - acc: 0.6944 - val_loss: 0.6376 - val_acc: 0.5833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.63758 to 0.63467, saving model to best.model\n",
      "0s - loss: 0.6162 - acc: 0.6704 - val_loss: 0.6347 - val_acc: 0.6167\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.63467 to 0.63261, saving model to best.model\n",
      "0s - loss: 0.6308 - acc: 0.6667 - val_loss: 0.6326 - val_acc: 0.6333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.63261 to 0.63073, saving model to best.model\n",
      "0s - loss: 0.6076 - acc: 0.6648 - val_loss: 0.6307 - val_acc: 0.6500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.63073 to 0.62870, saving model to best.model\n",
      "0s - loss: 0.5810 - acc: 0.6778 - val_loss: 0.6287 - val_acc: 0.6833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.62870 to 0.62700, saving model to best.model\n",
      "0s - loss: 0.6008 - acc: 0.6759 - val_loss: 0.6270 - val_acc: 0.6667\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.62700 to 0.62557, saving model to best.model\n",
      "0s - loss: 0.5833 - acc: 0.6759 - val_loss: 0.6256 - val_acc: 0.6667\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.62557 to 0.62294, saving model to best.model\n",
      "0s - loss: 0.5988 - acc: 0.7074 - val_loss: 0.6229 - val_acc: 0.6667\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.62294 to 0.61866, saving model to best.model\n",
      "0s - loss: 0.6110 - acc: 0.6907 - val_loss: 0.6187 - val_acc: 0.6833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.61866 to 0.61547, saving model to best.model\n",
      "0s - loss: 0.6141 - acc: 0.6796 - val_loss: 0.6155 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.61547 to 0.61340, saving model to best.model\n",
      "0s - loss: 0.5793 - acc: 0.7093 - val_loss: 0.6134 - val_acc: 0.7167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.61340 to 0.61206, saving model to best.model\n",
      "0s - loss: 0.5802 - acc: 0.6981 - val_loss: 0.6121 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.6033 - acc: 0.6870 - val_loss: 0.6122 - val_acc: 0.7167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.61206 to 0.61194, saving model to best.model\n",
      "0s - loss: 0.5743 - acc: 0.6963 - val_loss: 0.6119 - val_acc: 0.7000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.61194 to 0.61071, saving model to best.model\n",
      "0s - loss: 0.5792 - acc: 0.6944 - val_loss: 0.6107 - val_acc: 0.7000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.61071 to 0.61045, saving model to best.model\n",
      "0s - loss: 0.5610 - acc: 0.6907 - val_loss: 0.6105 - val_acc: 0.7000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5536 - acc: 0.7130 - val_loss: 0.6111 - val_acc: 0.6833\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5501 - acc: 0.7148 - val_loss: 0.6138 - val_acc: 0.6833\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5739 - acc: 0.7037 - val_loss: 0.6176 - val_acc: 0.7000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5612 - acc: 0.7185 - val_loss: 0.6170 - val_acc: 0.6833\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5734 - acc: 0.7093 - val_loss: 0.6131 - val_acc: 0.6833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.61045 to 0.60774, saving model to best.model\n",
      "0s - loss: 0.5598 - acc: 0.7222 - val_loss: 0.6077 - val_acc: 0.7167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.60774 to 0.60364, saving model to best.model\n",
      "0s - loss: 0.5471 - acc: 0.7130 - val_loss: 0.6036 - val_acc: 0.7000\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.60364 to 0.60095, saving model to best.model\n",
      "0s - loss: 0.5369 - acc: 0.7093 - val_loss: 0.6010 - val_acc: 0.6833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.60095 to 0.59716, saving model to best.model\n",
      "0s - loss: 0.5685 - acc: 0.7222 - val_loss: 0.5972 - val_acc: 0.6833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.59716 to 0.59399, saving model to best.model\n",
      "0s - loss: 0.5363 - acc: 0.7481 - val_loss: 0.5940 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.59399 to 0.59236, saving model to best.model\n",
      "0s - loss: 0.5123 - acc: 0.7444 - val_loss: 0.5924 - val_acc: 0.7167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.59236 to 0.59126, saving model to best.model\n",
      "0s - loss: 0.5454 - acc: 0.7222 - val_loss: 0.5913 - val_acc: 0.7167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.59126 to 0.58949, saving model to best.model\n",
      "0s - loss: 0.5481 - acc: 0.7148 - val_loss: 0.5895 - val_acc: 0.7167\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.58949 to 0.58813, saving model to best.model\n",
      "0s - loss: 0.5273 - acc: 0.7037 - val_loss: 0.5881 - val_acc: 0.7167\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.58813 to 0.58774, saving model to best.model\n",
      "0s - loss: 0.5306 - acc: 0.7463 - val_loss: 0.5877 - val_acc: 0.7167\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.58774 to 0.58743, saving model to best.model\n",
      "0s - loss: 0.5249 - acc: 0.7463 - val_loss: 0.5874 - val_acc: 0.7000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.58743 to 0.58671, saving model to best.model\n",
      "0s - loss: 0.5180 - acc: 0.7500 - val_loss: 0.5867 - val_acc: 0.7167\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.58671 to 0.58420, saving model to best.model\n",
      "0s - loss: 0.5231 - acc: 0.7444 - val_loss: 0.5842 - val_acc: 0.7167\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.58420 to 0.58102, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7389 - val_loss: 0.5810 - val_acc: 0.7167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.58102 to 0.57897, saving model to best.model\n",
      "0s - loss: 0.5267 - acc: 0.7259 - val_loss: 0.5790 - val_acc: 0.7167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.57897 to 0.57859, saving model to best.model\n",
      "0s - loss: 0.5317 - acc: 0.7352 - val_loss: 0.5786 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5230 - acc: 0.7426 - val_loss: 0.5800 - val_acc: 0.7000\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4932 - acc: 0.7722 - val_loss: 0.5834 - val_acc: 0.7167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.5244 - acc: 0.7593 - val_loss: 0.5849 - val_acc: 0.7333\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.5125 - acc: 0.7352 - val_loss: 0.5838 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4925 - acc: 0.7704 - val_loss: 0.5845 - val_acc: 0.7333\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.5056 - acc: 0.7648 - val_loss: 0.5860 - val_acc: 0.7333\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5003 - acc: 0.7278 - val_loss: 0.5846 - val_acc: 0.7333\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4927 - acc: 0.7481 - val_loss: 0.5841 - val_acc: 0.7333\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.5100 - acc: 0.7556 - val_loss: 0.5821 - val_acc: 0.7500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5029 - acc: 0.7500 - val_loss: 0.5809 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5074 - acc: 0.7519 - val_loss: 0.5814 - val_acc: 0.7500\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4733 - acc: 0.7593 - val_loss: 0.5810 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4829 - acc: 0.7815 - val_loss: 0.5797 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4651 - acc: 0.7796 - val_loss: 0.5788 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.57859 to 0.57612, saving model to best.model\n",
      "0s - loss: 0.4900 - acc: 0.7593 - val_loss: 0.5761 - val_acc: 0.7333\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.57612 to 0.57442, saving model to best.model\n",
      "0s - loss: 0.4740 - acc: 0.7593 - val_loss: 0.5744 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.57442 to 0.57306, saving model to best.model\n",
      "0s - loss: 0.4605 - acc: 0.8130 - val_loss: 0.5731 - val_acc: 0.7333\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.57306 to 0.57098, saving model to best.model\n",
      "0s - loss: 0.5035 - acc: 0.7722 - val_loss: 0.5710 - val_acc: 0.7167\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.57098 to 0.56975, saving model to best.model\n",
      "0s - loss: 0.4743 - acc: 0.7648 - val_loss: 0.5697 - val_acc: 0.7167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.56975 to 0.56794, saving model to best.model\n",
      "0s - loss: 0.5058 - acc: 0.7537 - val_loss: 0.5679 - val_acc: 0.7167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.56794 to 0.56566, saving model to best.model\n",
      "0s - loss: 0.4706 - acc: 0.7630 - val_loss: 0.5657 - val_acc: 0.7167\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.56566 to 0.56331, saving model to best.model\n",
      "0s - loss: 0.4708 - acc: 0.7704 - val_loss: 0.5633 - val_acc: 0.7167\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.56331 to 0.56231, saving model to best.model\n",
      "0s - loss: 0.4577 - acc: 0.7944 - val_loss: 0.5623 - val_acc: 0.7167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4521 - acc: 0.7759 - val_loss: 0.5640 - val_acc: 0.7333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4674 - acc: 0.7796 - val_loss: 0.5683 - val_acc: 0.7333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4482 - acc: 0.7741 - val_loss: 0.5721 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4549 - acc: 0.7796 - val_loss: 0.5731 - val_acc: 0.7333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4653 - acc: 0.7815 - val_loss: 0.5701 - val_acc: 0.7333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4719 - acc: 0.7907 - val_loss: 0.5671 - val_acc: 0.7167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4596 - acc: 0.7907 - val_loss: 0.5629 - val_acc: 0.7167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.56231 to 0.55894, saving model to best.model\n",
      "0s - loss: 0.4645 - acc: 0.7611 - val_loss: 0.5589 - val_acc: 0.7333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4563 - acc: 0.7981 - val_loss: 0.5596 - val_acc: 0.7167\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4560 - acc: 0.7889 - val_loss: 0.5620 - val_acc: 0.7167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4459 - acc: 0.8056 - val_loss: 0.5678 - val_acc: 0.7333\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.7907 - val_loss: 0.5746 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4384 - acc: 0.7963 - val_loss: 0.5798 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4538 - acc: 0.8000 - val_loss: 0.5817 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4577 - acc: 0.7926 - val_loss: 0.5787 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4559 - acc: 0.7796 - val_loss: 0.5750 - val_acc: 0.7167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4693 - acc: 0.7648 - val_loss: 0.5731 - val_acc: 0.7000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4198 - acc: 0.7833 - val_loss: 0.5719 - val_acc: 0.7167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4548 - acc: 0.7944 - val_loss: 0.5683 - val_acc: 0.7333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4094 - acc: 0.8130 - val_loss: 0.5645 - val_acc: 0.7500\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.55894 to 0.55870, saving model to best.model\n",
      "0s - loss: 0.4536 - acc: 0.8148 - val_loss: 0.5587 - val_acc: 0.7500\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.55870 to 0.55131, saving model to best.model\n",
      "0s - loss: 0.4199 - acc: 0.8037 - val_loss: 0.5513 - val_acc: 0.7667\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.55131 to 0.54516, saving model to best.model\n",
      "0s - loss: 0.4216 - acc: 0.8296 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.54516 to 0.54352, saving model to best.model\n",
      "0s - loss: 0.4273 - acc: 0.7926 - val_loss: 0.5435 - val_acc: 0.7333\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4320 - acc: 0.8056 - val_loss: 0.5453 - val_acc: 0.7333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4218 - acc: 0.8037 - val_loss: 0.5528 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4059 - acc: 0.8296 - val_loss: 0.5593 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4225 - acc: 0.8093 - val_loss: 0.5554 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4098 - acc: 0.8222 - val_loss: 0.5494 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4280 - acc: 0.8185 - val_loss: 0.5442 - val_acc: 0.7500\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.54352 to 0.53943, saving model to best.model\n",
      "0s - loss: 0.4117 - acc: 0.8407 - val_loss: 0.5394 - val_acc: 0.7500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.53943 to 0.53474, saving model to best.model\n",
      "0s - loss: 0.4313 - acc: 0.7944 - val_loss: 0.5347 - val_acc: 0.7333\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.53474 to 0.53074, saving model to best.model\n",
      "0s - loss: 0.4046 - acc: 0.8241 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.53074 to 0.52795, saving model to best.model\n",
      "0s - loss: 0.4123 - acc: 0.8056 - val_loss: 0.5279 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4091 - acc: 0.8148 - val_loss: 0.5281 - val_acc: 0.8000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3630 - acc: 0.8519 - val_loss: 0.5311 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4009 - acc: 0.8056 - val_loss: 0.5342 - val_acc: 0.7667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4099 - acc: 0.7926 - val_loss: 0.5344 - val_acc: 0.7667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3974 - acc: 0.8278 - val_loss: 0.5312 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.52795 to 0.52683, saving model to best.model\n",
      "0s - loss: 0.3813 - acc: 0.8130 - val_loss: 0.5268 - val_acc: 0.8000\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.52683 to 0.52312, saving model to best.model\n",
      "0s - loss: 0.3954 - acc: 0.8315 - val_loss: 0.5231 - val_acc: 0.7833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.52312 to 0.52188, saving model to best.model\n",
      "0s - loss: 0.3972 - acc: 0.8204 - val_loss: 0.5219 - val_acc: 0.7833\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4137 - acc: 0.7907 - val_loss: 0.5242 - val_acc: 0.7667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4085 - acc: 0.8241 - val_loss: 0.5258 - val_acc: 0.7833\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3966 - acc: 0.8259 - val_loss: 0.5283 - val_acc: 0.7667\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3724 - acc: 0.8222 - val_loss: 0.5393 - val_acc: 0.7833\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3914 - acc: 0.8352 - val_loss: 0.5455 - val_acc: 0.7833\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3700 - acc: 0.8296 - val_loss: 0.5371 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3718 - acc: 0.8278 - val_loss: 0.5282 - val_acc: 0.7833\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3716 - acc: 0.8444 - val_loss: 0.5259 - val_acc: 0.7833\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3809 - acc: 0.8444 - val_loss: 0.5236 - val_acc: 0.7500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.52188 to 0.52159, saving model to best.model\n",
      "0s - loss: 0.3870 - acc: 0.8444 - val_loss: 0.5216 - val_acc: 0.7500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.52159 to 0.52084, saving model to best.model\n",
      "0s - loss: 0.3816 - acc: 0.8463 - val_loss: 0.5208 - val_acc: 0.7500\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.4005 - acc: 0.8130 - val_loss: 0.5235 - val_acc: 0.7667\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3499 - acc: 0.8611 - val_loss: 0.5246 - val_acc: 0.7667\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3770 - acc: 0.8315 - val_loss: 0.5251 - val_acc: 0.7667\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3699 - acc: 0.8296 - val_loss: 0.5252 - val_acc: 0.7500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3720 - acc: 0.8574 - val_loss: 0.5267 - val_acc: 0.7500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3598 - acc: 0.8407 - val_loss: 0.5302 - val_acc: 0.7500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3707 - acc: 0.8444 - val_loss: 0.5303 - val_acc: 0.7333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3502 - acc: 0.8519 - val_loss: 0.5315 - val_acc: 0.7333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3532 - acc: 0.8463 - val_loss: 0.5321 - val_acc: 0.7333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3505 - acc: 0.8389 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3445 - acc: 0.8593 - val_loss: 0.5288 - val_acc: 0.7500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3138 - acc: 0.8833 - val_loss: 0.5270 - val_acc: 0.7500\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3820 - acc: 0.8259 - val_loss: 0.5278 - val_acc: 0.7500\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3422 - acc: 0.8481 - val_loss: 0.5341 - val_acc: 0.7667\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3221 - acc: 0.8426 - val_loss: 0.5361 - val_acc: 0.7667\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3608 - acc: 0.8352 - val_loss: 0.5264 - val_acc: 0.7833\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss improved from 0.52084 to 0.51027, saving model to best.model\n",
      "0s - loss: 0.3589 - acc: 0.8500 - val_loss: 0.5103 - val_acc: 0.7833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.51027 to 0.50534, saving model to best.model\n",
      "0s - loss: 0.3612 - acc: 0.8315 - val_loss: 0.5053 - val_acc: 0.7667\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.50534 to 0.50408, saving model to best.model\n",
      "0s - loss: 0.3649 - acc: 0.8500 - val_loss: 0.5041 - val_acc: 0.7667\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3292 - acc: 0.8630 - val_loss: 0.5065 - val_acc: 0.7667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3183 - acc: 0.8704 - val_loss: 0.5113 - val_acc: 0.7833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3428 - acc: 0.8574 - val_loss: 0.5141 - val_acc: 0.8167\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3292 - acc: 0.8704 - val_loss: 0.5141 - val_acc: 0.8167\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3472 - acc: 0.8463 - val_loss: 0.5093 - val_acc: 0.8167\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.50408 to 0.50257, saving model to best.model\n",
      "0s - loss: 0.3359 - acc: 0.8722 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.50257 to 0.49889, saving model to best.model\n",
      "0s - loss: 0.3160 - acc: 0.8704 - val_loss: 0.4989 - val_acc: 0.7833\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.49889 to 0.49613, saving model to best.model\n",
      "0s - loss: 0.3462 - acc: 0.8574 - val_loss: 0.4961 - val_acc: 0.7833\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.49613 to 0.49131, saving model to best.model\n",
      "0s - loss: 0.3162 - acc: 0.8741 - val_loss: 0.4913 - val_acc: 0.8000\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.49131 to 0.48890, saving model to best.model\n",
      "0s - loss: 0.3237 - acc: 0.8704 - val_loss: 0.4889 - val_acc: 0.7833\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3217 - acc: 0.8574 - val_loss: 0.4901 - val_acc: 0.7833\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.3405 - acc: 0.8444 - val_loss: 0.4896 - val_acc: 0.7833\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss improved from 0.48890 to 0.48002, saving model to best.model\n",
      "0s - loss: 0.3372 - acc: 0.8556 - val_loss: 0.4800 - val_acc: 0.7833\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.48002 to 0.47266, saving model to best.model\n",
      "0s - loss: 0.3145 - acc: 0.8667 - val_loss: 0.4727 - val_acc: 0.7833\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.47266 to 0.46431, saving model to best.model\n",
      "0s - loss: 0.3299 - acc: 0.8741 - val_loss: 0.4643 - val_acc: 0.7833\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.46431 to 0.46149, saving model to best.model\n",
      "0s - loss: 0.3229 - acc: 0.8815 - val_loss: 0.4615 - val_acc: 0.7833\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3290 - acc: 0.8648 - val_loss: 0.4625 - val_acc: 0.7833\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3166 - acc: 0.8648 - val_loss: 0.4676 - val_acc: 0.8167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3192 - acc: 0.8889 - val_loss: 0.4775 - val_acc: 0.7833\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3429 - acc: 0.8722 - val_loss: 0.4957 - val_acc: 0.8000\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3329 - acc: 0.8574 - val_loss: 0.5025 - val_acc: 0.8000\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3082 - acc: 0.8667 - val_loss: 0.4983 - val_acc: 0.8000\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3228 - acc: 0.8667 - val_loss: 0.4873 - val_acc: 0.8000\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3255 - acc: 0.8667 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3049 - acc: 0.8852 - val_loss: 0.4756 - val_acc: 0.8167\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3139 - acc: 0.8852 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3047 - acc: 0.8611 - val_loss: 0.4802 - val_acc: 0.8000\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2843 - acc: 0.8815 - val_loss: 0.4838 - val_acc: 0.8000\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.3223 - acc: 0.8667 - val_loss: 0.4838 - val_acc: 0.8000\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3013 - acc: 0.8741 - val_loss: 0.4837 - val_acc: 0.8000\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2863 - acc: 0.8926 - val_loss: 0.4832 - val_acc: 0.8167\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2895 - acc: 0.8852 - val_loss: 0.4782 - val_acc: 0.8167\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.3059 - acc: 0.8667 - val_loss: 0.4684 - val_acc: 0.8000\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2954 - acc: 0.8722 - val_loss: 0.4626 - val_acc: 0.8000\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2999 - acc: 0.8907 - val_loss: 0.4667 - val_acc: 0.8000\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2828 - acc: 0.8778 - val_loss: 0.4713 - val_acc: 0.8000\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2860 - acc: 0.8815 - val_loss: 0.4727 - val_acc: 0.8000\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2876 - acc: 0.8796 - val_loss: 0.4675 - val_acc: 0.8000\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2777 - acc: 0.8870 - val_loss: 0.4680 - val_acc: 0.8000\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2770 - acc: 0.8889 - val_loss: 0.4682 - val_acc: 0.8000\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2786 - acc: 0.8907 - val_loss: 0.4705 - val_acc: 0.8000\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2714 - acc: 0.8815 - val_loss: 0.4738 - val_acc: 0.8000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.37642, saving model to best.model\n",
      "0s - loss: 0.8604 - acc: 0.5333 - val_loss: 0.3764 - val_acc: 0.8667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.37642 to 0.33866, saving model to best.model\n",
      "0s - loss: 0.6680 - acc: 0.6833 - val_loss: 0.3387 - val_acc: 0.8667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.33866 to 0.33390, saving model to best.model\n",
      "0s - loss: 0.6969 - acc: 0.6963 - val_loss: 0.3339 - val_acc: 0.8667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6601 - acc: 0.7093 - val_loss: 0.3431 - val_acc: 0.8667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6337 - acc: 0.7019 - val_loss: 0.3677 - val_acc: 0.8667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.5932 - acc: 0.7111 - val_loss: 0.3983 - val_acc: 0.8667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6022 - acc: 0.6907 - val_loss: 0.4220 - val_acc: 0.8667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6126 - acc: 0.6722 - val_loss: 0.4224 - val_acc: 0.8667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5623 - acc: 0.7111 - val_loss: 0.4105 - val_acc: 0.8667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5885 - acc: 0.7148 - val_loss: 0.3961 - val_acc: 0.8667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5749 - acc: 0.7000 - val_loss: 0.3816 - val_acc: 0.8667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5701 - acc: 0.7148 - val_loss: 0.3744 - val_acc: 0.8667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5628 - acc: 0.7204 - val_loss: 0.3685 - val_acc: 0.8667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5829 - acc: 0.7056 - val_loss: 0.3680 - val_acc: 0.8500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5637 - acc: 0.7259 - val_loss: 0.3743 - val_acc: 0.8500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5864 - acc: 0.7056 - val_loss: 0.3800 - val_acc: 0.8667\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5548 - acc: 0.7333 - val_loss: 0.3776 - val_acc: 0.9167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5563 - acc: 0.7278 - val_loss: 0.3729 - val_acc: 0.9167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5432 - acc: 0.7278 - val_loss: 0.3666 - val_acc: 0.9167\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5634 - acc: 0.7333 - val_loss: 0.3626 - val_acc: 0.9167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5538 - acc: 0.7352 - val_loss: 0.3550 - val_acc: 0.9167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5330 - acc: 0.7481 - val_loss: 0.3504 - val_acc: 0.9167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5421 - acc: 0.7093 - val_loss: 0.3479 - val_acc: 0.9167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5339 - acc: 0.7444 - val_loss: 0.3455 - val_acc: 0.9167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5416 - acc: 0.7241 - val_loss: 0.3453 - val_acc: 0.9167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5113 - acc: 0.7574 - val_loss: 0.3520 - val_acc: 0.9167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5426 - acc: 0.7593 - val_loss: 0.3565 - val_acc: 0.9167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5287 - acc: 0.7481 - val_loss: 0.3568 - val_acc: 0.9167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5460 - acc: 0.7426 - val_loss: 0.3564 - val_acc: 0.9167\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.60832, saving model to best.model\n",
      "0s - loss: 1.4508 - acc: 0.3685 - val_loss: 0.6083 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.8180 - acc: 0.5685 - val_loss: 0.6245 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7637 - acc: 0.6704 - val_loss: 0.6517 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.7589 - acc: 0.6907 - val_loss: 0.6296 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.60832 to 0.59315, saving model to best.model\n",
      "0s - loss: 0.7277 - acc: 0.6963 - val_loss: 0.5931 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.59315 to 0.56414, saving model to best.model\n",
      "0s - loss: 0.6675 - acc: 0.6796 - val_loss: 0.5641 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.56414 to 0.55423, saving model to best.model\n",
      "0s - loss: 0.6179 - acc: 0.6889 - val_loss: 0.5542 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6346 - acc: 0.6648 - val_loss: 0.5570 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6194 - acc: 0.6407 - val_loss: 0.5609 - val_acc: 0.6833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6070 - acc: 0.6519 - val_loss: 0.5622 - val_acc: 0.6833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6199 - acc: 0.6667 - val_loss: 0.5596 - val_acc: 0.6833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.6039 - acc: 0.6833 - val_loss: 0.5547 - val_acc: 0.6833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.55423 to 0.55035, saving model to best.model\n",
      "0s - loss: 0.6221 - acc: 0.6685 - val_loss: 0.5504 - val_acc: 0.6833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.55035 to 0.54723, saving model to best.model\n",
      "0s - loss: 0.6074 - acc: 0.6648 - val_loss: 0.5472 - val_acc: 0.6833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.54723 to 0.54378, saving model to best.model\n",
      "0s - loss: 0.5875 - acc: 0.6833 - val_loss: 0.5438 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.54378 to 0.53989, saving model to best.model\n",
      "0s - loss: 0.5650 - acc: 0.7204 - val_loss: 0.5399 - val_acc: 0.7000\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.53989 to 0.53666, saving model to best.model\n",
      "0s - loss: 0.5710 - acc: 0.6963 - val_loss: 0.5367 - val_acc: 0.7000\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.53666 to 0.53417, saving model to best.model\n",
      "0s - loss: 0.5930 - acc: 0.6852 - val_loss: 0.5342 - val_acc: 0.7000\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.53417 to 0.53191, saving model to best.model\n",
      "0s - loss: 0.5690 - acc: 0.6963 - val_loss: 0.5319 - val_acc: 0.6833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.53191 to 0.52973, saving model to best.model\n",
      "0s - loss: 0.5610 - acc: 0.7185 - val_loss: 0.5297 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.52973 to 0.52875, saving model to best.model\n",
      "0s - loss: 0.5717 - acc: 0.6981 - val_loss: 0.5288 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.52875 to 0.52711, saving model to best.model\n",
      "0s - loss: 0.5661 - acc: 0.7185 - val_loss: 0.5271 - val_acc: 0.7167\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.52711 to 0.52502, saving model to best.model\n",
      "0s - loss: 0.5531 - acc: 0.7241 - val_loss: 0.5250 - val_acc: 0.7333\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52502 to 0.52285, saving model to best.model\n",
      "0s - loss: 0.5429 - acc: 0.7056 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.52285 to 0.52116, saving model to best.model\n",
      "0s - loss: 0.5389 - acc: 0.7130 - val_loss: 0.5212 - val_acc: 0.7167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52116 to 0.51948, saving model to best.model\n",
      "0s - loss: 0.5339 - acc: 0.7019 - val_loss: 0.5195 - val_acc: 0.7167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.51948 to 0.51885, saving model to best.model\n",
      "0s - loss: 0.5439 - acc: 0.7130 - val_loss: 0.5188 - val_acc: 0.7167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.51885 to 0.51688, saving model to best.model\n",
      "0s - loss: 0.5410 - acc: 0.7130 - val_loss: 0.5169 - val_acc: 0.7500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.51688 to 0.51503, saving model to best.model\n",
      "0s - loss: 0.5456 - acc: 0.7352 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.51503 to 0.51308, saving model to best.model\n",
      "0s - loss: 0.5249 - acc: 0.7278 - val_loss: 0.5131 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.51308 to 0.51145, saving model to best.model\n",
      "0s - loss: 0.5434 - acc: 0.7315 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.51145 to 0.51100, saving model to best.model\n",
      "0s - loss: 0.5167 - acc: 0.7426 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.51100 to 0.50985, saving model to best.model\n",
      "0s - loss: 0.5244 - acc: 0.7407 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.50985 to 0.50897, saving model to best.model\n",
      "0s - loss: 0.5258 - acc: 0.7407 - val_loss: 0.5090 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.50897 to 0.50757, saving model to best.model\n",
      "0s - loss: 0.5133 - acc: 0.7463 - val_loss: 0.5076 - val_acc: 0.7667\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.50757 to 0.50610, saving model to best.model\n",
      "0s - loss: 0.5254 - acc: 0.7241 - val_loss: 0.5061 - val_acc: 0.7667\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.50610 to 0.50538, saving model to best.model\n",
      "0s - loss: 0.5287 - acc: 0.7259 - val_loss: 0.5054 - val_acc: 0.7667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.50538 to 0.50522, saving model to best.model\n",
      "0s - loss: 0.5159 - acc: 0.7463 - val_loss: 0.5052 - val_acc: 0.7833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.50522 to 0.50391, saving model to best.model\n",
      "0s - loss: 0.5068 - acc: 0.7352 - val_loss: 0.5039 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.50391 to 0.50145, saving model to best.model\n",
      "0s - loss: 0.5019 - acc: 0.7444 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.50145 to 0.49855, saving model to best.model\n",
      "0s - loss: 0.5082 - acc: 0.7333 - val_loss: 0.4986 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.49855 to 0.49602, saving model to best.model\n",
      "0s - loss: 0.5243 - acc: 0.7444 - val_loss: 0.4960 - val_acc: 0.8000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.49602 to 0.49439, saving model to best.model\n",
      "0s - loss: 0.5047 - acc: 0.7426 - val_loss: 0.4944 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.49439 to 0.49236, saving model to best.model\n",
      "0s - loss: 0.5086 - acc: 0.7481 - val_loss: 0.4924 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.49236 to 0.49173, saving model to best.model\n",
      "0s - loss: 0.5011 - acc: 0.7611 - val_loss: 0.4917 - val_acc: 0.8000\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.49173 to 0.49097, saving model to best.model\n",
      "0s - loss: 0.4986 - acc: 0.7333 - val_loss: 0.4910 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4842 - acc: 0.7333 - val_loss: 0.4920 - val_acc: 0.8000\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4796 - acc: 0.7667 - val_loss: 0.4923 - val_acc: 0.8000\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4823 - acc: 0.7537 - val_loss: 0.4926 - val_acc: 0.8000\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4724 - acc: 0.7778 - val_loss: 0.4922 - val_acc: 0.8000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4816 - acc: 0.7833 - val_loss: 0.4917 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.49097 to 0.48858, saving model to best.model\n",
      "0s - loss: 0.4716 - acc: 0.7685 - val_loss: 0.4886 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.48858 to 0.48617, saving model to best.model\n",
      "0s - loss: 0.4801 - acc: 0.7741 - val_loss: 0.4862 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4692 - acc: 0.7796 - val_loss: 0.4864 - val_acc: 0.8000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5076 - acc: 0.7519 - val_loss: 0.4873 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.5007 - acc: 0.7630 - val_loss: 0.4881 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4988 - acc: 0.7537 - val_loss: 0.4882 - val_acc: 0.8000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.5126 - acc: 0.7463 - val_loss: 0.4878 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5126 - acc: 0.7278 - val_loss: 0.4882 - val_acc: 0.8000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4702 - acc: 0.7519 - val_loss: 0.4892 - val_acc: 0.8000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4710 - acc: 0.7926 - val_loss: 0.4904 - val_acc: 0.8000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4390 - acc: 0.7907 - val_loss: 0.4912 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4561 - acc: 0.7833 - val_loss: 0.4916 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4598 - acc: 0.7741 - val_loss: 0.4925 - val_acc: 0.8000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4789 - acc: 0.7556 - val_loss: 0.4920 - val_acc: 0.8167\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4541 - acc: 0.7778 - val_loss: 0.4911 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4598 - acc: 0.7667 - val_loss: 0.4903 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4478 - acc: 0.7944 - val_loss: 0.4893 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4631 - acc: 0.7870 - val_loss: 0.4893 - val_acc: 0.8000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4653 - acc: 0.7815 - val_loss: 0.4897 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4624 - acc: 0.7648 - val_loss: 0.4902 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4596 - acc: 0.7704 - val_loss: 0.4907 - val_acc: 0.8000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4389 - acc: 0.7907 - val_loss: 0.4926 - val_acc: 0.8333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4476 - acc: 0.8019 - val_loss: 0.4929 - val_acc: 0.8333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4450 - acc: 0.7685 - val_loss: 0.4911 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4375 - acc: 0.7907 - val_loss: 0.4886 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4247 - acc: 0.8074 - val_loss: 0.4871 - val_acc: 0.8167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4595 - acc: 0.7852 - val_loss: 0.4869 - val_acc: 0.8167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4268 - acc: 0.7944 - val_loss: 0.4873 - val_acc: 0.8167\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.61018, saving model to best.model\n",
      "0s - loss: 0.8808 - acc: 0.5389 - val_loss: 0.6102 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.61018 to 0.60776, saving model to best.model\n",
      "0s - loss: 0.7860 - acc: 0.6037 - val_loss: 0.6078 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.60776 to 0.58593, saving model to best.model\n",
      "0s - loss: 0.7995 - acc: 0.6352 - val_loss: 0.5859 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58593 to 0.57724, saving model to best.model\n",
      "0s - loss: 0.7234 - acc: 0.6259 - val_loss: 0.5772 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.7210 - acc: 0.6222 - val_loss: 0.5796 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6962 - acc: 0.6130 - val_loss: 0.5822 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6573 - acc: 0.6481 - val_loss: 0.5792 - val_acc: 0.7667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.57724 to 0.57335, saving model to best.model\n",
      "0s - loss: 0.6703 - acc: 0.6241 - val_loss: 0.5734 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.57335 to 0.56630, saving model to best.model\n",
      "0s - loss: 0.6489 - acc: 0.6426 - val_loss: 0.5663 - val_acc: 0.7833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.56630 to 0.56000, saving model to best.model\n",
      "0s - loss: 0.6682 - acc: 0.6296 - val_loss: 0.5600 - val_acc: 0.7500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.56000 to 0.55295, saving model to best.model\n",
      "0s - loss: 0.6008 - acc: 0.6815 - val_loss: 0.5529 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.55295 to 0.54737, saving model to best.model\n",
      "0s - loss: 0.6211 - acc: 0.6593 - val_loss: 0.5474 - val_acc: 0.7500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.54737 to 0.54313, saving model to best.model\n",
      "0s - loss: 0.6087 - acc: 0.6926 - val_loss: 0.5431 - val_acc: 0.7500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.54313 to 0.54107, saving model to best.model\n",
      "0s - loss: 0.5831 - acc: 0.7074 - val_loss: 0.5411 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.54107 to 0.53882, saving model to best.model\n",
      "0s - loss: 0.5962 - acc: 0.6815 - val_loss: 0.5388 - val_acc: 0.7833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.53882 to 0.53690, saving model to best.model\n",
      "0s - loss: 0.6038 - acc: 0.6815 - val_loss: 0.5369 - val_acc: 0.8000\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.53690 to 0.53683, saving model to best.model\n",
      "0s - loss: 0.5994 - acc: 0.6815 - val_loss: 0.5368 - val_acc: 0.8167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.53683 to 0.53567, saving model to best.model\n",
      "0s - loss: 0.5840 - acc: 0.6852 - val_loss: 0.5357 - val_acc: 0.8167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.53567 to 0.53400, saving model to best.model\n",
      "0s - loss: 0.5706 - acc: 0.7074 - val_loss: 0.5340 - val_acc: 0.8333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.53400 to 0.53310, saving model to best.model\n",
      "0s - loss: 0.5891 - acc: 0.6963 - val_loss: 0.5331 - val_acc: 0.8333\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.53310 to 0.53150, saving model to best.model\n",
      "0s - loss: 0.5785 - acc: 0.6981 - val_loss: 0.5315 - val_acc: 0.8500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.53150 to 0.52961, saving model to best.model\n",
      "0s - loss: 0.5979 - acc: 0.6907 - val_loss: 0.5296 - val_acc: 0.8500\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.52961 to 0.52690, saving model to best.model\n",
      "0s - loss: 0.5697 - acc: 0.6870 - val_loss: 0.5269 - val_acc: 0.8500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52690 to 0.52496, saving model to best.model\n",
      "0s - loss: 0.5669 - acc: 0.7259 - val_loss: 0.5250 - val_acc: 0.8500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.52496 to 0.52433, saving model to best.model\n",
      "0s - loss: 0.5603 - acc: 0.7130 - val_loss: 0.5243 - val_acc: 0.8333\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52433 to 0.52428, saving model to best.model\n",
      "0s - loss: 0.5635 - acc: 0.7111 - val_loss: 0.5243 - val_acc: 0.8333\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5573 - acc: 0.7148 - val_loss: 0.5249 - val_acc: 0.8333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5447 - acc: 0.7278 - val_loss: 0.5268 - val_acc: 0.8333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5662 - acc: 0.7333 - val_loss: 0.5246 - val_acc: 0.8333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.52428 to 0.51947, saving model to best.model\n",
      "0s - loss: 0.5614 - acc: 0.7222 - val_loss: 0.5195 - val_acc: 0.8167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.51947 to 0.51735, saving model to best.model\n",
      "0s - loss: 0.5622 - acc: 0.7241 - val_loss: 0.5174 - val_acc: 0.8333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5393 - acc: 0.7241 - val_loss: 0.5178 - val_acc: 0.8333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5381 - acc: 0.7370 - val_loss: 0.5191 - val_acc: 0.8333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5330 - acc: 0.7481 - val_loss: 0.5178 - val_acc: 0.8333\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.51735 to 0.51622, saving model to best.model\n",
      "0s - loss: 0.5492 - acc: 0.7093 - val_loss: 0.5162 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.51622 to 0.51507, saving model to best.model\n",
      "0s - loss: 0.5252 - acc: 0.7407 - val_loss: 0.5151 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.51507 to 0.51339, saving model to best.model\n",
      "0s - loss: 0.5151 - acc: 0.7611 - val_loss: 0.5134 - val_acc: 0.8167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.51339 to 0.51217, saving model to best.model\n",
      "0s - loss: 0.5608 - acc: 0.7056 - val_loss: 0.5122 - val_acc: 0.8167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.51217 to 0.51016, saving model to best.model\n",
      "0s - loss: 0.5059 - acc: 0.7556 - val_loss: 0.5102 - val_acc: 0.8167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.51016 to 0.50859, saving model to best.model\n",
      "0s - loss: 0.5338 - acc: 0.7426 - val_loss: 0.5086 - val_acc: 0.8333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.50859 to 0.50785, saving model to best.model\n",
      "0s - loss: 0.5410 - acc: 0.7241 - val_loss: 0.5079 - val_acc: 0.8333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5290 - acc: 0.7407 - val_loss: 0.5084 - val_acc: 0.8333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5231 - acc: 0.7611 - val_loss: 0.5080 - val_acc: 0.8167\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5350 - acc: 0.7426 - val_loss: 0.5079 - val_acc: 0.8167\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5193 - acc: 0.7481 - val_loss: 0.5081 - val_acc: 0.8167\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5285 - acc: 0.7370 - val_loss: 0.5081 - val_acc: 0.8167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.50785 to 0.50768, saving model to best.model\n",
      "0s - loss: 0.5261 - acc: 0.7574 - val_loss: 0.5077 - val_acc: 0.8167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.50768 to 0.50758, saving model to best.model\n",
      "0s - loss: 0.5284 - acc: 0.7278 - val_loss: 0.5076 - val_acc: 0.8167\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.5107 - acc: 0.7352 - val_loss: 0.5077 - val_acc: 0.8167\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5224 - acc: 0.7389 - val_loss: 0.5077 - val_acc: 0.8167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.50758 to 0.50680, saving model to best.model\n",
      "0s - loss: 0.5041 - acc: 0.7500 - val_loss: 0.5068 - val_acc: 0.8500\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.50680 to 0.50531, saving model to best.model\n",
      "0s - loss: 0.5088 - acc: 0.7481 - val_loss: 0.5053 - val_acc: 0.8500\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.50531 to 0.50493, saving model to best.model\n",
      "0s - loss: 0.5139 - acc: 0.7407 - val_loss: 0.5049 - val_acc: 0.8500\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.5159 - acc: 0.7574 - val_loss: 0.5056 - val_acc: 0.8167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.5096 - acc: 0.7574 - val_loss: 0.5061 - val_acc: 0.8167\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4985 - acc: 0.7685 - val_loss: 0.5065 - val_acc: 0.8167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4917 - acc: 0.7519 - val_loss: 0.5056 - val_acc: 0.8167\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.50493 to 0.50422, saving model to best.model\n",
      "0s - loss: 0.5159 - acc: 0.7667 - val_loss: 0.5042 - val_acc: 0.8167\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.50422 to 0.50407, saving model to best.model\n",
      "0s - loss: 0.4993 - acc: 0.7500 - val_loss: 0.5041 - val_acc: 0.8167\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.50407 to 0.50324, saving model to best.model\n",
      "0s - loss: 0.5073 - acc: 0.7630 - val_loss: 0.5032 - val_acc: 0.8167\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.50324 to 0.50152, saving model to best.model\n",
      "0s - loss: 0.4878 - acc: 0.7833 - val_loss: 0.5015 - val_acc: 0.8167\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.50152 to 0.50020, saving model to best.model\n",
      "0s - loss: 0.5031 - acc: 0.7296 - val_loss: 0.5002 - val_acc: 0.8167\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.50020 to 0.49904, saving model to best.model\n",
      "0s - loss: 0.4932 - acc: 0.7611 - val_loss: 0.4990 - val_acc: 0.8500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.49904 to 0.49808, saving model to best.model\n",
      "0s - loss: 0.4882 - acc: 0.7426 - val_loss: 0.4981 - val_acc: 0.8500\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.49808 to 0.49760, saving model to best.model\n",
      "0s - loss: 0.5045 - acc: 0.7722 - val_loss: 0.4976 - val_acc: 0.8500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.49760 to 0.49733, saving model to best.model\n",
      "0s - loss: 0.5088 - acc: 0.7556 - val_loss: 0.4973 - val_acc: 0.8500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.49733 to 0.49721, saving model to best.model\n",
      "0s - loss: 0.4759 - acc: 0.7685 - val_loss: 0.4972 - val_acc: 0.8500\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.49721 to 0.49605, saving model to best.model\n",
      "0s - loss: 0.4834 - acc: 0.7815 - val_loss: 0.4961 - val_acc: 0.8500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.49605 to 0.49546, saving model to best.model\n",
      "0s - loss: 0.5004 - acc: 0.7759 - val_loss: 0.4955 - val_acc: 0.8500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.49546 to 0.49427, saving model to best.model\n",
      "0s - loss: 0.4804 - acc: 0.7667 - val_loss: 0.4943 - val_acc: 0.8333\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.49427 to 0.49196, saving model to best.model\n",
      "0s - loss: 0.4931 - acc: 0.7759 - val_loss: 0.4920 - val_acc: 0.8167\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.49196 to 0.48976, saving model to best.model\n",
      "0s - loss: 0.4708 - acc: 0.7815 - val_loss: 0.4898 - val_acc: 0.8167\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.48976 to 0.48793, saving model to best.model\n",
      "0s - loss: 0.4848 - acc: 0.7611 - val_loss: 0.4879 - val_acc: 0.8167\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.48793 to 0.48618, saving model to best.model\n",
      "0s - loss: 0.4732 - acc: 0.7648 - val_loss: 0.4862 - val_acc: 0.8167\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.48618 to 0.48532, saving model to best.model\n",
      "0s - loss: 0.4703 - acc: 0.7889 - val_loss: 0.4853 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.48532 to 0.48424, saving model to best.model\n",
      "0s - loss: 0.4700 - acc: 0.7648 - val_loss: 0.4842 - val_acc: 0.8333\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4816 - acc: 0.7648 - val_loss: 0.4844 - val_acc: 0.8167\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4608 - acc: 0.7870 - val_loss: 0.4847 - val_acc: 0.8167\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4889 - acc: 0.7648 - val_loss: 0.4845 - val_acc: 0.8333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.48424 to 0.48280, saving model to best.model\n",
      "0s - loss: 0.4729 - acc: 0.7778 - val_loss: 0.4828 - val_acc: 0.8333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.48280 to 0.48132, saving model to best.model\n",
      "0s - loss: 0.4532 - acc: 0.7907 - val_loss: 0.4813 - val_acc: 0.8167\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.48132 to 0.48115, saving model to best.model\n",
      "0s - loss: 0.4516 - acc: 0.8019 - val_loss: 0.4812 - val_acc: 0.8333\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4812 - acc: 0.7778 - val_loss: 0.4813 - val_acc: 0.8333\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4692 - acc: 0.7889 - val_loss: 0.4814 - val_acc: 0.8333\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4621 - acc: 0.7852 - val_loss: 0.4815 - val_acc: 0.8333\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4667 - acc: 0.7889 - val_loss: 0.4816 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4486 - acc: 0.7759 - val_loss: 0.4823 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4375 - acc: 0.8037 - val_loss: 0.4855 - val_acc: 0.8000\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4415 - acc: 0.7741 - val_loss: 0.4886 - val_acc: 0.8167\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4475 - acc: 0.7926 - val_loss: 0.4905 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4548 - acc: 0.7963 - val_loss: 0.4894 - val_acc: 0.8000\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4651 - acc: 0.7741 - val_loss: 0.4889 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4250 - acc: 0.7981 - val_loss: 0.4862 - val_acc: 0.8167\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4517 - acc: 0.7685 - val_loss: 0.4833 - val_acc: 0.8333\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4501 - acc: 0.7907 - val_loss: 0.4818 - val_acc: 0.8333\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss improved from 0.48115 to 0.47961, saving model to best.model\n",
      "0s - loss: 0.4472 - acc: 0.8074 - val_loss: 0.4796 - val_acc: 0.8333\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.47961 to 0.47657, saving model to best.model\n",
      "0s - loss: 0.4474 - acc: 0.7907 - val_loss: 0.4766 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.47657 to 0.47557, saving model to best.model\n",
      "0s - loss: 0.4379 - acc: 0.7852 - val_loss: 0.4756 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.47557 to 0.47409, saving model to best.model\n",
      "0s - loss: 0.4470 - acc: 0.7833 - val_loss: 0.4741 - val_acc: 0.8167\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.47409 to 0.47182, saving model to best.model\n",
      "0s - loss: 0.4355 - acc: 0.7852 - val_loss: 0.4718 - val_acc: 0.8167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4383 - acc: 0.8093 - val_loss: 0.4722 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4369 - acc: 0.7963 - val_loss: 0.4729 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4248 - acc: 0.8093 - val_loss: 0.4724 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.47182 to 0.47062, saving model to best.model\n",
      "0s - loss: 0.4321 - acc: 0.8037 - val_loss: 0.4706 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.47062 to 0.46961, saving model to best.model\n",
      "0s - loss: 0.4471 - acc: 0.7981 - val_loss: 0.4696 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4194 - acc: 0.7944 - val_loss: 0.4704 - val_acc: 0.8333\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4253 - acc: 0.8019 - val_loss: 0.4711 - val_acc: 0.8500\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4312 - acc: 0.7981 - val_loss: 0.4705 - val_acc: 0.8500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4478 - acc: 0.8000 - val_loss: 0.4697 - val_acc: 0.8500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.46961 to 0.46941, saving model to best.model\n",
      "0s - loss: 0.4161 - acc: 0.7944 - val_loss: 0.4694 - val_acc: 0.8500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4113 - acc: 0.8056 - val_loss: 0.4700 - val_acc: 0.8500\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3969 - acc: 0.8296 - val_loss: 0.4701 - val_acc: 0.8500\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.4006 - acc: 0.8315 - val_loss: 0.4701 - val_acc: 0.8333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4095 - acc: 0.8278 - val_loss: 0.4701 - val_acc: 0.8333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.4119 - acc: 0.8185 - val_loss: 0.4720 - val_acc: 0.8500\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3852 - acc: 0.8241 - val_loss: 0.4733 - val_acc: 0.8500\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3952 - acc: 0.8167 - val_loss: 0.4730 - val_acc: 0.8333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3973 - acc: 0.8333 - val_loss: 0.4713 - val_acc: 0.8333\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.4182 - acc: 0.8056 - val_loss: 0.4700 - val_acc: 0.8333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.46941 to 0.46861, saving model to best.model\n",
      "0s - loss: 0.4234 - acc: 0.7981 - val_loss: 0.4686 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.46861 to 0.46708, saving model to best.model\n",
      "0s - loss: 0.3922 - acc: 0.8296 - val_loss: 0.4671 - val_acc: 0.8167\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.46708 to 0.46461, saving model to best.model\n",
      "0s - loss: 0.3808 - acc: 0.8333 - val_loss: 0.4646 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.46461 to 0.46063, saving model to best.model\n",
      "0s - loss: 0.4037 - acc: 0.8111 - val_loss: 0.4606 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.46063 to 0.45680, saving model to best.model\n",
      "0s - loss: 0.4137 - acc: 0.8111 - val_loss: 0.4568 - val_acc: 0.8167\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.45680 to 0.45511, saving model to best.model\n",
      "0s - loss: 0.3865 - acc: 0.8296 - val_loss: 0.4551 - val_acc: 0.8167\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.45511 to 0.45372, saving model to best.model\n",
      "0s - loss: 0.3928 - acc: 0.8167 - val_loss: 0.4537 - val_acc: 0.8167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.45372 to 0.45250, saving model to best.model\n",
      "0s - loss: 0.4016 - acc: 0.8204 - val_loss: 0.4525 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.45250 to 0.45207, saving model to best.model\n",
      "0s - loss: 0.3870 - acc: 0.8296 - val_loss: 0.4521 - val_acc: 0.8333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3849 - acc: 0.8296 - val_loss: 0.4524 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss improved from 0.45207 to 0.45188, saving model to best.model\n",
      "0s - loss: 0.3801 - acc: 0.8315 - val_loss: 0.4519 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss improved from 0.45188 to 0.45022, saving model to best.model\n",
      "0s - loss: 0.3911 - acc: 0.8111 - val_loss: 0.4502 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.45022 to 0.44921, saving model to best.model\n",
      "0s - loss: 0.3826 - acc: 0.8370 - val_loss: 0.4492 - val_acc: 0.8333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.44921 to 0.44768, saving model to best.model\n",
      "0s - loss: 0.3886 - acc: 0.8167 - val_loss: 0.4477 - val_acc: 0.8333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.44768 to 0.44384, saving model to best.model\n",
      "0s - loss: 0.3847 - acc: 0.8426 - val_loss: 0.4438 - val_acc: 0.8333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.44384 to 0.44300, saving model to best.model\n",
      "0s - loss: 0.3711 - acc: 0.8148 - val_loss: 0.4430 - val_acc: 0.8167\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.44300 to 0.44297, saving model to best.model\n",
      "0s - loss: 0.3844 - acc: 0.8370 - val_loss: 0.4430 - val_acc: 0.8167\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3646 - acc: 0.8278 - val_loss: 0.4434 - val_acc: 0.8333\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3449 - acc: 0.8389 - val_loss: 0.4471 - val_acc: 0.8167\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3585 - acc: 0.8519 - val_loss: 0.4501 - val_acc: 0.8167\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3542 - acc: 0.8333 - val_loss: 0.4517 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3815 - acc: 0.8241 - val_loss: 0.4513 - val_acc: 0.8167\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3436 - acc: 0.8352 - val_loss: 0.4489 - val_acc: 0.8167\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3644 - acc: 0.8389 - val_loss: 0.4455 - val_acc: 0.8333\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.44297 to 0.43907, saving model to best.model\n",
      "0s - loss: 0.3771 - acc: 0.8259 - val_loss: 0.4391 - val_acc: 0.8333\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.43907 to 0.43389, saving model to best.model\n",
      "0s - loss: 0.3342 - acc: 0.8500 - val_loss: 0.4339 - val_acc: 0.8500\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.43389 to 0.43276, saving model to best.model\n",
      "0s - loss: 0.3759 - acc: 0.8352 - val_loss: 0.4328 - val_acc: 0.8500\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3544 - acc: 0.8481 - val_loss: 0.4335 - val_acc: 0.8500\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3613 - acc: 0.8370 - val_loss: 0.4359 - val_acc: 0.8167\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3579 - acc: 0.8500 - val_loss: 0.4400 - val_acc: 0.8167\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3601 - acc: 0.8444 - val_loss: 0.4434 - val_acc: 0.8167\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3528 - acc: 0.8574 - val_loss: 0.4435 - val_acc: 0.8167\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3049 - acc: 0.8796 - val_loss: 0.4412 - val_acc: 0.8000\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 0.3555 - acc: 0.8463 - val_loss: 0.4402 - val_acc: 0.8167\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.3530 - acc: 0.8481 - val_loss: 0.4338 - val_acc: 0.8000\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss improved from 0.43276 to 0.42904, saving model to best.model\n",
      "0s - loss: 0.3472 - acc: 0.8556 - val_loss: 0.4290 - val_acc: 0.8167\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3388 - acc: 0.8370 - val_loss: 0.4327 - val_acc: 0.8167\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.3363 - acc: 0.8537 - val_loss: 0.4451 - val_acc: 0.8167\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3536 - acc: 0.8463 - val_loss: 0.4412 - val_acc: 0.8167\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 0.3251 - acc: 0.8519 - val_loss: 0.4358 - val_acc: 0.8167\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.3268 - acc: 0.8426 - val_loss: 0.4310 - val_acc: 0.8167\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.3267 - acc: 0.8648 - val_loss: 0.4306 - val_acc: 0.8167\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.3111 - acc: 0.8685 - val_loss: 0.4329 - val_acc: 0.8167\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3356 - acc: 0.8278 - val_loss: 0.4347 - val_acc: 0.8167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.3140 - acc: 0.8685 - val_loss: 0.4389 - val_acc: 0.8167\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3197 - acc: 0.8667 - val_loss: 0.4441 - val_acc: 0.8167\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3356 - acc: 0.8574 - val_loss: 0.4526 - val_acc: 0.8167\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3291 - acc: 0.8574 - val_loss: 0.4596 - val_acc: 0.8167\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.3303 - acc: 0.8593 - val_loss: 0.4542 - val_acc: 0.8167\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.3023 - acc: 0.8611 - val_loss: 0.4472 - val_acc: 0.8167\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.3136 - acc: 0.8685 - val_loss: 0.4358 - val_acc: 0.8167\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss improved from 0.42904 to 0.42695, saving model to best.model\n",
      "0s - loss: 0.3027 - acc: 0.8611 - val_loss: 0.4270 - val_acc: 0.8167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.42695 to 0.42383, saving model to best.model\n",
      "0s - loss: 0.3457 - acc: 0.8481 - val_loss: 0.4238 - val_acc: 0.8167\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.3484 - acc: 0.8537 - val_loss: 0.4254 - val_acc: 0.8333\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.3051 - acc: 0.8667 - val_loss: 0.4263 - val_acc: 0.8333\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2919 - acc: 0.8889 - val_loss: 0.4259 - val_acc: 0.8333\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.42383 to 0.42045, saving model to best.model\n",
      "0s - loss: 0.3116 - acc: 0.8556 - val_loss: 0.4204 - val_acc: 0.8333\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.42045 to 0.41314, saving model to best.model\n",
      "0s - loss: 0.2999 - acc: 0.8648 - val_loss: 0.4131 - val_acc: 0.8333\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.3084 - acc: 0.8759 - val_loss: 0.4135 - val_acc: 0.8333\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.3031 - acc: 0.8611 - val_loss: 0.4180 - val_acc: 0.8333\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2824 - acc: 0.8759 - val_loss: 0.4294 - val_acc: 0.8000\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.2990 - acc: 0.8630 - val_loss: 0.4478 - val_acc: 0.8000\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2964 - acc: 0.8630 - val_loss: 0.4565 - val_acc: 0.8000\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2872 - acc: 0.8722 - val_loss: 0.4438 - val_acc: 0.8167\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.3123 - acc: 0.8611 - val_loss: 0.4376 - val_acc: 0.8167\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 0.2748 - acc: 0.8907 - val_loss: 0.4381 - val_acc: 0.8167\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 0.2881 - acc: 0.8815 - val_loss: 0.4425 - val_acc: 0.8000\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2855 - acc: 0.8833 - val_loss: 0.4444 - val_acc: 0.8000\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2944 - acc: 0.8815 - val_loss: 0.4427 - val_acc: 0.8000\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2822 - acc: 0.8796 - val_loss: 0.4381 - val_acc: 0.8000\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.2720 - acc: 0.8852 - val_loss: 0.4249 - val_acc: 0.8167\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2697 - acc: 0.8852 - val_loss: 0.4147 - val_acc: 0.8333\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2964 - acc: 0.8778 - val_loss: 0.4140 - val_acc: 0.8500\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2622 - acc: 0.9000 - val_loss: 0.4172 - val_acc: 0.8167\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2971 - acc: 0.8574 - val_loss: 0.4256 - val_acc: 0.8000\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2807 - acc: 0.8833 - val_loss: 0.4310 - val_acc: 0.8167\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2746 - acc: 0.8981 - val_loss: 0.4348 - val_acc: 0.8167\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.3052 - acc: 0.8815 - val_loss: 0.4348 - val_acc: 0.8167\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2978 - acc: 0.8833 - val_loss: 0.4264 - val_acc: 0.8000\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2640 - acc: 0.8889 - val_loss: 0.4196 - val_acc: 0.8167\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2647 - acc: 0.8778 - val_loss: 0.4175 - val_acc: 0.8167\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.51009, saving model to best.model\n",
      "0s - loss: 0.8778 - acc: 0.4722 - val_loss: 0.5101 - val_acc: 0.7833\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.51009 to 0.49788, saving model to best.model\n",
      "0s - loss: 0.6721 - acc: 0.7000 - val_loss: 0.4979 - val_acc: 0.7833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.49788 to 0.49779, saving model to best.model\n",
      "0s - loss: 0.6412 - acc: 0.7315 - val_loss: 0.4978 - val_acc: 0.7833\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.49779 to 0.49401, saving model to best.model\n",
      "0s - loss: 0.7033 - acc: 0.7278 - val_loss: 0.4940 - val_acc: 0.7833\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6079 - acc: 0.7407 - val_loss: 0.4991 - val_acc: 0.7833\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6042 - acc: 0.7222 - val_loss: 0.5155 - val_acc: 0.7833\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6112 - acc: 0.7241 - val_loss: 0.5321 - val_acc: 0.7833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6206 - acc: 0.6907 - val_loss: 0.5445 - val_acc: 0.7833\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5744 - acc: 0.7148 - val_loss: 0.5490 - val_acc: 0.7833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5923 - acc: 0.6722 - val_loss: 0.5440 - val_acc: 0.7833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5775 - acc: 0.7000 - val_loss: 0.5335 - val_acc: 0.7833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5639 - acc: 0.7315 - val_loss: 0.5224 - val_acc: 0.7833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5479 - acc: 0.7593 - val_loss: 0.5142 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5484 - acc: 0.7407 - val_loss: 0.5076 - val_acc: 0.7833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5554 - acc: 0.7444 - val_loss: 0.5052 - val_acc: 0.7833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5441 - acc: 0.7370 - val_loss: 0.5056 - val_acc: 0.7833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5316 - acc: 0.7500 - val_loss: 0.5057 - val_acc: 0.7833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5301 - acc: 0.7519 - val_loss: 0.5092 - val_acc: 0.7667\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5247 - acc: 0.7630 - val_loss: 0.5137 - val_acc: 0.7833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5481 - acc: 0.7278 - val_loss: 0.5132 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5470 - acc: 0.7370 - val_loss: 0.5109 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5293 - acc: 0.7426 - val_loss: 0.5072 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5452 - acc: 0.7370 - val_loss: 0.5023 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5271 - acc: 0.7519 - val_loss: 0.4968 - val_acc: 0.7833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.49401 to 0.49338, saving model to best.model\n",
      "0s - loss: 0.5318 - acc: 0.7426 - val_loss: 0.4934 - val_acc: 0.7833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.49338 to 0.49037, saving model to best.model\n",
      "0s - loss: 0.4981 - acc: 0.7556 - val_loss: 0.4904 - val_acc: 0.7833\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.49037 to 0.49007, saving model to best.model\n",
      "0s - loss: 0.5245 - acc: 0.7407 - val_loss: 0.4901 - val_acc: 0.7833\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.49007 to 0.48944, saving model to best.model\n",
      "0s - loss: 0.4927 - acc: 0.7741 - val_loss: 0.4894 - val_acc: 0.7833\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5283 - acc: 0.7593 - val_loss: 0.4900 - val_acc: 0.7833\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.4792 - acc: 0.7667 - val_loss: 0.4909 - val_acc: 0.7833\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.4893 - acc: 0.7593 - val_loss: 0.4917 - val_acc: 0.7833\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5197 - acc: 0.7333 - val_loss: 0.4905 - val_acc: 0.7833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5225 - acc: 0.7648 - val_loss: 0.4898 - val_acc: 0.7833\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.4927 - acc: 0.7556 - val_loss: 0.4918 - val_acc: 0.7833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.4931 - acc: 0.7630 - val_loss: 0.4938 - val_acc: 0.7833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5061 - acc: 0.7463 - val_loss: 0.4929 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.4984 - acc: 0.7500 - val_loss: 0.4907 - val_acc: 0.7833\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.48944 to 0.48720, saving model to best.model\n",
      "0s - loss: 0.4975 - acc: 0.7481 - val_loss: 0.4872 - val_acc: 0.7833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.48720 to 0.48500, saving model to best.model\n",
      "0s - loss: 0.4948 - acc: 0.7519 - val_loss: 0.4850 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.48500 to 0.48313, saving model to best.model\n",
      "0s - loss: 0.4772 - acc: 0.7556 - val_loss: 0.4831 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.4616 - acc: 0.7704 - val_loss: 0.4838 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4776 - acc: 0.7556 - val_loss: 0.4858 - val_acc: 0.7833\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4644 - acc: 0.7704 - val_loss: 0.4878 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4750 - acc: 0.7926 - val_loss: 0.4865 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.48313 to 0.48286, saving model to best.model\n",
      "0s - loss: 0.4696 - acc: 0.7704 - val_loss: 0.4829 - val_acc: 0.8167\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.48286 to 0.48122, saving model to best.model\n",
      "0s - loss: 0.4702 - acc: 0.7815 - val_loss: 0.4812 - val_acc: 0.8167\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4694 - acc: 0.7741 - val_loss: 0.4821 - val_acc: 0.8167\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4763 - acc: 0.7426 - val_loss: 0.4836 - val_acc: 0.8167\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4496 - acc: 0.7796 - val_loss: 0.4853 - val_acc: 0.8167\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4745 - acc: 0.7685 - val_loss: 0.4863 - val_acc: 0.8000\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4738 - acc: 0.7648 - val_loss: 0.4872 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4454 - acc: 0.8019 - val_loss: 0.4872 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4601 - acc: 0.7815 - val_loss: 0.4871 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4669 - acc: 0.7778 - val_loss: 0.4884 - val_acc: 0.8000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4510 - acc: 0.7648 - val_loss: 0.4905 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4673 - acc: 0.7907 - val_loss: 0.4930 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4618 - acc: 0.7722 - val_loss: 0.4966 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4568 - acc: 0.8093 - val_loss: 0.4988 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4623 - acc: 0.7852 - val_loss: 0.5015 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4600 - acc: 0.7889 - val_loss: 0.5027 - val_acc: 0.7667\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4483 - acc: 0.7852 - val_loss: 0.5031 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4445 - acc: 0.7926 - val_loss: 0.5031 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4361 - acc: 0.7926 - val_loss: 0.5030 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4421 - acc: 0.7944 - val_loss: 0.5026 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4487 - acc: 0.7926 - val_loss: 0.5024 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4341 - acc: 0.7889 - val_loss: 0.5030 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4390 - acc: 0.7944 - val_loss: 0.5030 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4277 - acc: 0.7944 - val_loss: 0.5040 - val_acc: 0.7833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4533 - acc: 0.7889 - val_loss: 0.5057 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4244 - acc: 0.8000 - val_loss: 0.5079 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4465 - acc: 0.8037 - val_loss: 0.5087 - val_acc: 0.7833\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4167 - acc: 0.8111 - val_loss: 0.5104 - val_acc: 0.7833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.62405, saving model to best.model\n",
      "0s - loss: 0.8253 - acc: 0.5148 - val_loss: 0.6241 - val_acc: 0.6500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.6930 - acc: 0.6259 - val_loss: 0.6294 - val_acc: 0.6500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.62405 to 0.62310, saving model to best.model\n",
      "0s - loss: 0.6898 - acc: 0.6704 - val_loss: 0.6231 - val_acc: 0.6500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.62310 to 0.60611, saving model to best.model\n",
      "0s - loss: 0.6398 - acc: 0.7019 - val_loss: 0.6061 - val_acc: 0.6500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.60611 to 0.59414, saving model to best.model\n",
      "0s - loss: 0.6217 - acc: 0.6852 - val_loss: 0.5941 - val_acc: 0.6500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.59414 to 0.58905, saving model to best.model\n",
      "0s - loss: 0.6259 - acc: 0.6796 - val_loss: 0.5891 - val_acc: 0.6500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.58905 to 0.58715, saving model to best.model\n",
      "0s - loss: 0.5933 - acc: 0.7056 - val_loss: 0.5871 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.58715 to 0.58462, saving model to best.model\n",
      "0s - loss: 0.6065 - acc: 0.6611 - val_loss: 0.5846 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.58462 to 0.58036, saving model to best.model\n",
      "0s - loss: 0.5964 - acc: 0.7130 - val_loss: 0.5804 - val_acc: 0.6833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.58036 to 0.57646, saving model to best.model\n",
      "0s - loss: 0.6175 - acc: 0.6704 - val_loss: 0.5765 - val_acc: 0.7000\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.57646 to 0.57134, saving model to best.model\n",
      "0s - loss: 0.5981 - acc: 0.6870 - val_loss: 0.5713 - val_acc: 0.7000\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.57134 to 0.56531, saving model to best.model\n",
      "0s - loss: 0.5724 - acc: 0.7093 - val_loss: 0.5653 - val_acc: 0.7000\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.56531 to 0.55857, saving model to best.model\n",
      "0s - loss: 0.5672 - acc: 0.7167 - val_loss: 0.5586 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.55857 to 0.55210, saving model to best.model\n",
      "0s - loss: 0.5731 - acc: 0.7296 - val_loss: 0.5521 - val_acc: 0.7000\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.55210 to 0.54473, saving model to best.model\n",
      "0s - loss: 0.5488 - acc: 0.7148 - val_loss: 0.5447 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.54473 to 0.53725, saving model to best.model\n",
      "0s - loss: 0.5612 - acc: 0.7296 - val_loss: 0.5373 - val_acc: 0.7000\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.53725 to 0.53066, saving model to best.model\n",
      "0s - loss: 0.5483 - acc: 0.7056 - val_loss: 0.5307 - val_acc: 0.7167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.53066 to 0.52420, saving model to best.model\n",
      "0s - loss: 0.5464 - acc: 0.7222 - val_loss: 0.5242 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.52420 to 0.51635, saving model to best.model\n",
      "0s - loss: 0.5520 - acc: 0.7204 - val_loss: 0.5164 - val_acc: 0.7667\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.51635 to 0.50812, saving model to best.model\n",
      "0s - loss: 0.5707 - acc: 0.7130 - val_loss: 0.5081 - val_acc: 0.7833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.50812 to 0.50248, saving model to best.model\n",
      "0s - loss: 0.5788 - acc: 0.7259 - val_loss: 0.5025 - val_acc: 0.7833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.50248 to 0.49957, saving model to best.model\n",
      "0s - loss: 0.5533 - acc: 0.7352 - val_loss: 0.4996 - val_acc: 0.7833\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.49957 to 0.49662, saving model to best.model\n",
      "0s - loss: 0.5398 - acc: 0.7370 - val_loss: 0.4966 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.49662 to 0.49366, saving model to best.model\n",
      "0s - loss: 0.5541 - acc: 0.7074 - val_loss: 0.4937 - val_acc: 0.7833\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.49366 to 0.49059, saving model to best.model\n",
      "0s - loss: 0.5234 - acc: 0.7389 - val_loss: 0.4906 - val_acc: 0.7833\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.49059 to 0.48720, saving model to best.model\n",
      "0s - loss: 0.5202 - acc: 0.7407 - val_loss: 0.4872 - val_acc: 0.7833\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.48720 to 0.48268, saving model to best.model\n",
      "0s - loss: 0.5057 - acc: 0.7574 - val_loss: 0.4827 - val_acc: 0.8000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.48268 to 0.47719, saving model to best.model\n",
      "0s - loss: 0.4955 - acc: 0.7611 - val_loss: 0.4772 - val_acc: 0.8000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.47719 to 0.47276, saving model to best.model\n",
      "0s - loss: 0.5104 - acc: 0.7500 - val_loss: 0.4728 - val_acc: 0.7833\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.47276 to 0.46920, saving model to best.model\n",
      "0s - loss: 0.5246 - acc: 0.7426 - val_loss: 0.4692 - val_acc: 0.7833\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.46920 to 0.46434, saving model to best.model\n",
      "0s - loss: 0.4982 - acc: 0.7389 - val_loss: 0.4643 - val_acc: 0.7833\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.46434 to 0.46030, saving model to best.model\n",
      "0s - loss: 0.5057 - acc: 0.7611 - val_loss: 0.4603 - val_acc: 0.7833\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.46030 to 0.45523, saving model to best.model\n",
      "0s - loss: 0.5191 - acc: 0.7389 - val_loss: 0.4552 - val_acc: 0.7833\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.45523 to 0.44918, saving model to best.model\n",
      "0s - loss: 0.5104 - acc: 0.7630 - val_loss: 0.4492 - val_acc: 0.7833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.44918 to 0.44335, saving model to best.model\n",
      "0s - loss: 0.4933 - acc: 0.7630 - val_loss: 0.4434 - val_acc: 0.8000\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.44335 to 0.43916, saving model to best.model\n",
      "0s - loss: 0.4781 - acc: 0.7704 - val_loss: 0.4392 - val_acc: 0.8167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.43916 to 0.43658, saving model to best.model\n",
      "0s - loss: 0.4885 - acc: 0.7685 - val_loss: 0.4366 - val_acc: 0.8167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.43658 to 0.43341, saving model to best.model\n",
      "0s - loss: 0.4949 - acc: 0.7426 - val_loss: 0.4334 - val_acc: 0.8000\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.43341 to 0.43029, saving model to best.model\n",
      "0s - loss: 0.4683 - acc: 0.7685 - val_loss: 0.4303 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.43029 to 0.42736, saving model to best.model\n",
      "0s - loss: 0.4700 - acc: 0.7574 - val_loss: 0.4274 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.42736 to 0.42476, saving model to best.model\n",
      "0s - loss: 0.4827 - acc: 0.7741 - val_loss: 0.4248 - val_acc: 0.7833\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.42476 to 0.42234, saving model to best.model\n",
      "0s - loss: 0.5116 - acc: 0.7444 - val_loss: 0.4223 - val_acc: 0.7833\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.42234 to 0.42015, saving model to best.model\n",
      "0s - loss: 0.4775 - acc: 0.7667 - val_loss: 0.4202 - val_acc: 0.7833\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.42015 to 0.41942, saving model to best.model\n",
      "0s - loss: 0.4724 - acc: 0.7815 - val_loss: 0.4194 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4924 - acc: 0.7519 - val_loss: 0.4209 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4679 - acc: 0.8074 - val_loss: 0.4216 - val_acc: 0.7667\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4944 - acc: 0.7574 - val_loss: 0.4220 - val_acc: 0.7667\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4726 - acc: 0.7648 - val_loss: 0.4228 - val_acc: 0.7833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4671 - acc: 0.7722 - val_loss: 0.4228 - val_acc: 0.7833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4421 - acc: 0.7944 - val_loss: 0.4222 - val_acc: 0.7667\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4956 - acc: 0.7667 - val_loss: 0.4228 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4661 - acc: 0.7852 - val_loss: 0.4246 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4600 - acc: 0.7907 - val_loss: 0.4269 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4562 - acc: 0.7815 - val_loss: 0.4273 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4459 - acc: 0.7852 - val_loss: 0.4262 - val_acc: 0.7833\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4836 - acc: 0.7889 - val_loss: 0.4255 - val_acc: 0.7833\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4426 - acc: 0.7796 - val_loss: 0.4223 - val_acc: 0.8000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.41942 to 0.41712, saving model to best.model\n",
      "0s - loss: 0.4346 - acc: 0.8037 - val_loss: 0.4171 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.41712 to 0.41189, saving model to best.model\n",
      "0s - loss: 0.4574 - acc: 0.8037 - val_loss: 0.4119 - val_acc: 0.8000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.41189 to 0.40777, saving model to best.model\n",
      "0s - loss: 0.4502 - acc: 0.7815 - val_loss: 0.4078 - val_acc: 0.8000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.40777 to 0.40390, saving model to best.model\n",
      "0s - loss: 0.4540 - acc: 0.8019 - val_loss: 0.4039 - val_acc: 0.8000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.40390 to 0.40068, saving model to best.model\n",
      "0s - loss: 0.4300 - acc: 0.7815 - val_loss: 0.4007 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.40068 to 0.39837, saving model to best.model\n",
      "0s - loss: 0.4692 - acc: 0.7815 - val_loss: 0.3984 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.39837 to 0.39606, saving model to best.model\n",
      "0s - loss: 0.4604 - acc: 0.7907 - val_loss: 0.3961 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.39606 to 0.39512, saving model to best.model\n",
      "0s - loss: 0.4358 - acc: 0.8241 - val_loss: 0.3951 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4266 - acc: 0.7907 - val_loss: 0.3954 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4455 - acc: 0.7926 - val_loss: 0.3958 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4281 - acc: 0.8111 - val_loss: 0.3954 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.39512 to 0.39491, saving model to best.model\n",
      "0s - loss: 0.4361 - acc: 0.8019 - val_loss: 0.3949 - val_acc: 0.8000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.39491 to 0.39230, saving model to best.model\n",
      "0s - loss: 0.4514 - acc: 0.8037 - val_loss: 0.3923 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.39230 to 0.38862, saving model to best.model\n",
      "0s - loss: 0.4439 - acc: 0.7944 - val_loss: 0.3886 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.38862 to 0.38634, saving model to best.model\n",
      "0s - loss: 0.4509 - acc: 0.7870 - val_loss: 0.3863 - val_acc: 0.8000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.38634 to 0.38350, saving model to best.model\n",
      "0s - loss: 0.4464 - acc: 0.7944 - val_loss: 0.3835 - val_acc: 0.7667\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.38350 to 0.38138, saving model to best.model\n",
      "0s - loss: 0.4438 - acc: 0.8037 - val_loss: 0.3814 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.38138 to 0.37932, saving model to best.model\n",
      "0s - loss: 0.4289 - acc: 0.8130 - val_loss: 0.3793 - val_acc: 0.8000\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.37932 to 0.37895, saving model to best.model\n",
      "0s - loss: 0.4265 - acc: 0.8111 - val_loss: 0.3790 - val_acc: 0.8000\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.37895 to 0.37873, saving model to best.model\n",
      "0s - loss: 0.4237 - acc: 0.8074 - val_loss: 0.3787 - val_acc: 0.7833\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.37873 to 0.37606, saving model to best.model\n",
      "0s - loss: 0.3975 - acc: 0.8185 - val_loss: 0.3761 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.37606 to 0.37423, saving model to best.model\n",
      "0s - loss: 0.4209 - acc: 0.8130 - val_loss: 0.3742 - val_acc: 0.8000\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.37423 to 0.37003, saving model to best.model\n",
      "0s - loss: 0.4119 - acc: 0.8167 - val_loss: 0.3700 - val_acc: 0.8000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.37003 to 0.36336, saving model to best.model\n",
      "0s - loss: 0.3984 - acc: 0.8204 - val_loss: 0.3634 - val_acc: 0.7833\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.36336 to 0.36009, saving model to best.model\n",
      "0s - loss: 0.4142 - acc: 0.8111 - val_loss: 0.3601 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.36009 to 0.35922, saving model to best.model\n",
      "0s - loss: 0.3916 - acc: 0.8167 - val_loss: 0.3592 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.35922 to 0.35632, saving model to best.model\n",
      "0s - loss: 0.4233 - acc: 0.8241 - val_loss: 0.3563 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.35632 to 0.35309, saving model to best.model\n",
      "0s - loss: 0.4070 - acc: 0.8204 - val_loss: 0.3531 - val_acc: 0.8000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.35309 to 0.35020, saving model to best.model\n",
      "0s - loss: 0.4234 - acc: 0.8148 - val_loss: 0.3502 - val_acc: 0.8167\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.35020 to 0.34581, saving model to best.model\n",
      "0s - loss: 0.4155 - acc: 0.8278 - val_loss: 0.3458 - val_acc: 0.8167\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.34581 to 0.34162, saving model to best.model\n",
      "0s - loss: 0.4242 - acc: 0.8074 - val_loss: 0.3416 - val_acc: 0.8167\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss improved from 0.34162 to 0.33712, saving model to best.model\n",
      "0s - loss: 0.4035 - acc: 0.8148 - val_loss: 0.3371 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.33712 to 0.33257, saving model to best.model\n",
      "0s - loss: 0.4061 - acc: 0.8130 - val_loss: 0.3326 - val_acc: 0.8333\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.33257 to 0.32936, saving model to best.model\n",
      "0s - loss: 0.4215 - acc: 0.8259 - val_loss: 0.3294 - val_acc: 0.8333\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3969 - acc: 0.8315 - val_loss: 0.3303 - val_acc: 0.8167\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4025 - acc: 0.8148 - val_loss: 0.3364 - val_acc: 0.8000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4080 - acc: 0.8111 - val_loss: 0.3433 - val_acc: 0.8000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4020 - acc: 0.8407 - val_loss: 0.3432 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4082 - acc: 0.8019 - val_loss: 0.3392 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3861 - acc: 0.8463 - val_loss: 0.3363 - val_acc: 0.8167\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3698 - acc: 0.8389 - val_loss: 0.3374 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4090 - acc: 0.8333 - val_loss: 0.3392 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4005 - acc: 0.8056 - val_loss: 0.3389 - val_acc: 0.8167\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3777 - acc: 0.8481 - val_loss: 0.3397 - val_acc: 0.8167\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4015 - acc: 0.8222 - val_loss: 0.3433 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3823 - acc: 0.8352 - val_loss: 0.3486 - val_acc: 0.7667\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3771 - acc: 0.8333 - val_loss: 0.3490 - val_acc: 0.7667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3955 - acc: 0.8315 - val_loss: 0.3424 - val_acc: 0.7833\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3890 - acc: 0.8278 - val_loss: 0.3338 - val_acc: 0.8167\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3839 - acc: 0.8315 - val_loss: 0.3321 - val_acc: 0.8333\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3665 - acc: 0.8444 - val_loss: 0.3358 - val_acc: 0.8500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3684 - acc: 0.8426 - val_loss: 0.3372 - val_acc: 0.8500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3675 - acc: 0.8574 - val_loss: 0.3335 - val_acc: 0.8500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.32936 to 0.32771, saving model to best.model\n",
      "0s - loss: 0.3493 - acc: 0.8574 - val_loss: 0.3277 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.32771 to 0.32245, saving model to best.model\n",
      "0s - loss: 0.3766 - acc: 0.8333 - val_loss: 0.3225 - val_acc: 0.8167\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss improved from 0.32245 to 0.32061, saving model to best.model\n",
      "0s - loss: 0.3461 - acc: 0.8593 - val_loss: 0.3206 - val_acc: 0.8167\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.32061 to 0.32020, saving model to best.model\n",
      "0s - loss: 0.3389 - acc: 0.8426 - val_loss: 0.3202 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.32020 to 0.31382, saving model to best.model\n",
      "0s - loss: 0.3573 - acc: 0.8389 - val_loss: 0.3138 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.31382 to 0.30522, saving model to best.model\n",
      "0s - loss: 0.3332 - acc: 0.8574 - val_loss: 0.3052 - val_acc: 0.8333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.30522 to 0.29952, saving model to best.model\n",
      "0s - loss: 0.3624 - acc: 0.8426 - val_loss: 0.2995 - val_acc: 0.8500\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.29952 to 0.29698, saving model to best.model\n",
      "0s - loss: 0.3693 - acc: 0.8426 - val_loss: 0.2970 - val_acc: 0.8500\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3795 - acc: 0.8444 - val_loss: 0.2978 - val_acc: 0.8500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3648 - acc: 0.8481 - val_loss: 0.2982 - val_acc: 0.8500\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3329 - acc: 0.8722 - val_loss: 0.2971 - val_acc: 0.8500\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.29698 to 0.29330, saving model to best.model\n",
      "0s - loss: 0.3744 - acc: 0.8370 - val_loss: 0.2933 - val_acc: 0.8500\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss improved from 0.29330 to 0.29132, saving model to best.model\n",
      "0s - loss: 0.3751 - acc: 0.8556 - val_loss: 0.2913 - val_acc: 0.8500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.29132 to 0.28877, saving model to best.model\n",
      "0s - loss: 0.3438 - acc: 0.8685 - val_loss: 0.2888 - val_acc: 0.8667\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.28877 to 0.28737, saving model to best.model\n",
      "0s - loss: 0.3697 - acc: 0.8444 - val_loss: 0.2874 - val_acc: 0.8667\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.28737 to 0.28372, saving model to best.model\n",
      "0s - loss: 0.3483 - acc: 0.8537 - val_loss: 0.2837 - val_acc: 0.8833\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3677 - acc: 0.8500 - val_loss: 0.2857 - val_acc: 0.9000\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3517 - acc: 0.8481 - val_loss: 0.2868 - val_acc: 0.8833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3548 - acc: 0.8574 - val_loss: 0.2867 - val_acc: 0.8667\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3023 - acc: 0.8833 - val_loss: 0.2879 - val_acc: 0.8500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3290 - acc: 0.8741 - val_loss: 0.2892 - val_acc: 0.8500\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3483 - acc: 0.8519 - val_loss: 0.2848 - val_acc: 0.8500\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.28372 to 0.27477, saving model to best.model\n",
      "0s - loss: 0.3423 - acc: 0.8537 - val_loss: 0.2748 - val_acc: 0.8500\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss improved from 0.27477 to 0.26797, saving model to best.model\n",
      "0s - loss: 0.3469 - acc: 0.8611 - val_loss: 0.2680 - val_acc: 0.8667\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss improved from 0.26797 to 0.26336, saving model to best.model\n",
      "0s - loss: 0.3502 - acc: 0.8741 - val_loss: 0.2634 - val_acc: 0.8833\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss improved from 0.26336 to 0.25748, saving model to best.model\n",
      "0s - loss: 0.3339 - acc: 0.8611 - val_loss: 0.2575 - val_acc: 0.8833\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.25748 to 0.25560, saving model to best.model\n",
      "0s - loss: 0.3347 - acc: 0.8611 - val_loss: 0.2556 - val_acc: 0.9000\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3519 - acc: 0.8481 - val_loss: 0.2564 - val_acc: 0.9000\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.25560 to 0.25392, saving model to best.model\n",
      "0s - loss: 0.3182 - acc: 0.8685 - val_loss: 0.2539 - val_acc: 0.9000\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3156 - acc: 0.8685 - val_loss: 0.2552 - val_acc: 0.9000\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3464 - acc: 0.8481 - val_loss: 0.2601 - val_acc: 0.8833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3509 - acc: 0.8500 - val_loss: 0.2641 - val_acc: 0.8833\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3394 - acc: 0.8407 - val_loss: 0.2621 - val_acc: 0.8833\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.25392 to 0.25376, saving model to best.model\n",
      "0s - loss: 0.3017 - acc: 0.8778 - val_loss: 0.2538 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.25376 to 0.24932, saving model to best.model\n",
      "0s - loss: 0.2904 - acc: 0.8704 - val_loss: 0.2493 - val_acc: 0.8833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.24932 to 0.24724, saving model to best.model\n",
      "0s - loss: 0.3067 - acc: 0.8759 - val_loss: 0.2472 - val_acc: 0.8833\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3113 - acc: 0.8630 - val_loss: 0.2492 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3205 - acc: 0.8685 - val_loss: 0.2498 - val_acc: 0.8667\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss improved from 0.24724 to 0.24689, saving model to best.model\n",
      "0s - loss: 0.3073 - acc: 0.8648 - val_loss: 0.2469 - val_acc: 0.8833\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.24689 to 0.24223, saving model to best.model\n",
      "0s - loss: 0.3269 - acc: 0.8648 - val_loss: 0.2422 - val_acc: 0.8833\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.24223 to 0.23741, saving model to best.model\n",
      "0s - loss: 0.3021 - acc: 0.8685 - val_loss: 0.2374 - val_acc: 0.8667\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.23741 to 0.23103, saving model to best.model\n",
      "0s - loss: 0.3171 - acc: 0.8611 - val_loss: 0.2310 - val_acc: 0.8833\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.23103 to 0.22620, saving model to best.model\n",
      "0s - loss: 0.3058 - acc: 0.8833 - val_loss: 0.2262 - val_acc: 0.8833\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss improved from 0.22620 to 0.22382, saving model to best.model\n",
      "0s - loss: 0.2970 - acc: 0.8833 - val_loss: 0.2238 - val_acc: 0.8833\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.2802 - acc: 0.8852 - val_loss: 0.2242 - val_acc: 0.9000\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3087 - acc: 0.8741 - val_loss: 0.2257 - val_acc: 0.9000\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 0.2954 - acc: 0.8870 - val_loss: 0.2255 - val_acc: 0.9000\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 0.3006 - acc: 0.8778 - val_loss: 0.2248 - val_acc: 0.9000\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.22382 to 0.22374, saving model to best.model\n",
      "0s - loss: 0.3019 - acc: 0.8759 - val_loss: 0.2237 - val_acc: 0.9167\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.22374 to 0.22334, saving model to best.model\n",
      "0s - loss: 0.2995 - acc: 0.8648 - val_loss: 0.2233 - val_acc: 0.9000\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 0.2924 - acc: 0.8778 - val_loss: 0.2246 - val_acc: 0.9000\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 0.2991 - acc: 0.8704 - val_loss: 0.2279 - val_acc: 0.9000\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss did not improve\n",
      "0s - loss: 0.3186 - acc: 0.8611 - val_loss: 0.2360 - val_acc: 0.9167\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2948 - acc: 0.8759 - val_loss: 0.2424 - val_acc: 0.9333\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.2999 - acc: 0.8722 - val_loss: 0.2436 - val_acc: 0.9167\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.3093 - acc: 0.9000 - val_loss: 0.2418 - val_acc: 0.9167\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3015 - acc: 0.8907 - val_loss: 0.2456 - val_acc: 0.9167\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2863 - acc: 0.8796 - val_loss: 0.2493 - val_acc: 0.9167\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2925 - acc: 0.8815 - val_loss: 0.2436 - val_acc: 0.9167\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2646 - acc: 0.8981 - val_loss: 0.2380 - val_acc: 0.9167\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2822 - acc: 0.8852 - val_loss: 0.2300 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss improved from 0.22334 to 0.22049, saving model to best.model\n",
      "0s - loss: 0.2746 - acc: 0.8833 - val_loss: 0.2205 - val_acc: 0.9167\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss improved from 0.22049 to 0.21515, saving model to best.model\n",
      "0s - loss: 0.2987 - acc: 0.8796 - val_loss: 0.2151 - val_acc: 0.9167\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss improved from 0.21515 to 0.21225, saving model to best.model\n",
      "0s - loss: 0.2736 - acc: 0.8833 - val_loss: 0.2123 - val_acc: 0.9167\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss improved from 0.21225 to 0.20953, saving model to best.model\n",
      "0s - loss: 0.2731 - acc: 0.8815 - val_loss: 0.2095 - val_acc: 0.9167\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss improved from 0.20953 to 0.20689, saving model to best.model\n",
      "0s - loss: 0.2891 - acc: 0.8870 - val_loss: 0.2069 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss improved from 0.20689 to 0.20323, saving model to best.model\n",
      "0s - loss: 0.2619 - acc: 0.9000 - val_loss: 0.2032 - val_acc: 0.9167\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss improved from 0.20323 to 0.20172, saving model to best.model\n",
      "0s - loss: 0.2872 - acc: 0.8852 - val_loss: 0.2017 - val_acc: 0.9167\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 0.2676 - acc: 0.8889 - val_loss: 0.2054 - val_acc: 0.9167\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.2463 - acc: 0.9037 - val_loss: 0.2098 - val_acc: 0.9000\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 0.3206 - acc: 0.8759 - val_loss: 0.2104 - val_acc: 0.9000\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 0.2702 - acc: 0.9037 - val_loss: 0.2080 - val_acc: 0.9000\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 0.2935 - acc: 0.8815 - val_loss: 0.2051 - val_acc: 0.9000\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2650 - acc: 0.8944 - val_loss: 0.2020 - val_acc: 0.9000\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.20172 to 0.19961, saving model to best.model\n",
      "0s - loss: 0.2662 - acc: 0.9019 - val_loss: 0.1996 - val_acc: 0.9000\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.19961 to 0.19864, saving model to best.model\n",
      "0s - loss: 0.2650 - acc: 0.8815 - val_loss: 0.1986 - val_acc: 0.9333\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 0.2408 - acc: 0.9056 - val_loss: 0.2031 - val_acc: 0.8833\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 0.2784 - acc: 0.8944 - val_loss: 0.2009 - val_acc: 0.8833\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss improved from 0.19864 to 0.19437, saving model to best.model\n",
      "0s - loss: 0.2426 - acc: 0.9185 - val_loss: 0.1944 - val_acc: 0.9500\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.2759 - acc: 0.8852 - val_loss: 0.1945 - val_acc: 0.9167\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2795 - acc: 0.9000 - val_loss: 0.1960 - val_acc: 0.9500\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2683 - acc: 0.8944 - val_loss: 0.1989 - val_acc: 0.9167\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2524 - acc: 0.8907 - val_loss: 0.2073 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2339 - acc: 0.9019 - val_loss: 0.2177 - val_acc: 0.9000\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.3257 - acc: 0.8796 - val_loss: 0.2351 - val_acc: 0.9000\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.3042 - acc: 0.8667 - val_loss: 0.2488 - val_acc: 0.9000\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2587 - acc: 0.8981 - val_loss: 0.2567 - val_acc: 0.8833\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2524 - acc: 0.9111 - val_loss: 0.2630 - val_acc: 0.8833\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2405 - acc: 0.9093 - val_loss: 0.2668 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2683 - acc: 0.9056 - val_loss: 0.2695 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66694, saving model to best.model\n",
      "0s - loss: 0.9444 - acc: 0.4963 - val_loss: 0.6669 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7522 - acc: 0.6389 - val_loss: 0.6975 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.66694 to 0.65908, saving model to best.model\n",
      "0s - loss: 0.8033 - acc: 0.6648 - val_loss: 0.6591 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.65908 to 0.61759, saving model to best.model\n",
      "0s - loss: 0.7251 - acc: 0.6630 - val_loss: 0.6176 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.61759 to 0.60600, saving model to best.model\n",
      "0s - loss: 0.6602 - acc: 0.6704 - val_loss: 0.6060 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6776 - acc: 0.6185 - val_loss: 0.6071 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6903 - acc: 0.6111 - val_loss: 0.6089 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.60600 to 0.60512, saving model to best.model\n",
      "0s - loss: 0.6454 - acc: 0.6204 - val_loss: 0.6051 - val_acc: 0.6833\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.60512 to 0.59603, saving model to best.model\n",
      "0s - loss: 0.6523 - acc: 0.6407 - val_loss: 0.5960 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.59603 to 0.58762, saving model to best.model\n",
      "0s - loss: 0.6278 - acc: 0.6611 - val_loss: 0.5876 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.58762 to 0.58307, saving model to best.model\n",
      "0s - loss: 0.6128 - acc: 0.6926 - val_loss: 0.5831 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.58307 to 0.58070, saving model to best.model\n",
      "0s - loss: 0.6022 - acc: 0.6944 - val_loss: 0.5807 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.58070 to 0.57959, saving model to best.model\n",
      "0s - loss: 0.5830 - acc: 0.7167 - val_loss: 0.5796 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.6262 - acc: 0.6889 - val_loss: 0.5805 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5724 - acc: 0.6963 - val_loss: 0.5813 - val_acc: 0.6667\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.57959 to 0.57952, saving model to best.model\n",
      "0s - loss: 0.5940 - acc: 0.6944 - val_loss: 0.5795 - val_acc: 0.6833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.57952 to 0.57811, saving model to best.model\n",
      "0s - loss: 0.6018 - acc: 0.7019 - val_loss: 0.5781 - val_acc: 0.7000\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.57811 to 0.57634, saving model to best.model\n",
      "0s - loss: 0.5783 - acc: 0.6833 - val_loss: 0.5763 - val_acc: 0.7000\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.57634 to 0.57236, saving model to best.model\n",
      "0s - loss: 0.5661 - acc: 0.7037 - val_loss: 0.5724 - val_acc: 0.7000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.57236 to 0.56614, saving model to best.model\n",
      "0s - loss: 0.5593 - acc: 0.7074 - val_loss: 0.5661 - val_acc: 0.7000\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.56614 to 0.55847, saving model to best.model\n",
      "0s - loss: 0.5670 - acc: 0.6981 - val_loss: 0.5585 - val_acc: 0.7000\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.55847 to 0.54797, saving model to best.model\n",
      "0s - loss: 0.5828 - acc: 0.7074 - val_loss: 0.5480 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.54797 to 0.53846, saving model to best.model\n",
      "0s - loss: 0.5357 - acc: 0.7111 - val_loss: 0.5385 - val_acc: 0.7000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.53846 to 0.53058, saving model to best.model\n",
      "0s - loss: 0.5485 - acc: 0.7148 - val_loss: 0.5306 - val_acc: 0.7000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.53058 to 0.52548, saving model to best.model\n",
      "0s - loss: 0.5683 - acc: 0.7185 - val_loss: 0.5255 - val_acc: 0.7000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.52548 to 0.52242, saving model to best.model\n",
      "0s - loss: 0.5400 - acc: 0.7296 - val_loss: 0.5224 - val_acc: 0.7000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.52242 to 0.51976, saving model to best.model\n",
      "0s - loss: 0.5487 - acc: 0.7241 - val_loss: 0.5198 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.51976 to 0.51670, saving model to best.model\n",
      "0s - loss: 0.5489 - acc: 0.7315 - val_loss: 0.5167 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.51670 to 0.51037, saving model to best.model\n",
      "0s - loss: 0.5381 - acc: 0.7296 - val_loss: 0.5104 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.51037 to 0.50514, saving model to best.model\n",
      "0s - loss: 0.5280 - acc: 0.7278 - val_loss: 0.5051 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5253 - acc: 0.7407 - val_loss: 0.5069 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5583 - acc: 0.7130 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5252 - acc: 0.7296 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.5325 - acc: 0.7389 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.5193 - acc: 0.7333 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.50514 to 0.50225, saving model to best.model\n",
      "0s - loss: 0.5345 - acc: 0.7185 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.50225 to 0.49530, saving model to best.model\n",
      "0s - loss: 0.5408 - acc: 0.7278 - val_loss: 0.4953 - val_acc: 0.7500\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.49530 to 0.49025, saving model to best.model\n",
      "0s - loss: 0.5179 - acc: 0.7463 - val_loss: 0.4902 - val_acc: 0.7500\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.49025 to 0.48454, saving model to best.model\n",
      "0s - loss: 0.5374 - acc: 0.7444 - val_loss: 0.4845 - val_acc: 0.7500\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.48454 to 0.48069, saving model to best.model\n",
      "0s - loss: 0.5350 - acc: 0.7296 - val_loss: 0.4807 - val_acc: 0.7500\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.48069 to 0.47890, saving model to best.model\n",
      "0s - loss: 0.5573 - acc: 0.7296 - val_loss: 0.4789 - val_acc: 0.7500\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.47890 to 0.47782, saving model to best.model\n",
      "0s - loss: 0.5281 - acc: 0.7352 - val_loss: 0.4778 - val_acc: 0.7500\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.47782 to 0.47651, saving model to best.model\n",
      "0s - loss: 0.5136 - acc: 0.7333 - val_loss: 0.4765 - val_acc: 0.7500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.47651 to 0.47587, saving model to best.model\n",
      "0s - loss: 0.5118 - acc: 0.7463 - val_loss: 0.4759 - val_acc: 0.7667\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5216 - acc: 0.7630 - val_loss: 0.4781 - val_acc: 0.7667\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.5220 - acc: 0.7574 - val_loss: 0.4793 - val_acc: 0.7833\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4921 - acc: 0.7778 - val_loss: 0.4782 - val_acc: 0.7833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.47587 to 0.47353, saving model to best.model\n",
      "0s - loss: 0.4953 - acc: 0.7593 - val_loss: 0.4735 - val_acc: 0.7833\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss improved from 0.47353 to 0.46833, saving model to best.model\n",
      "0s - loss: 0.4968 - acc: 0.7685 - val_loss: 0.4683 - val_acc: 0.7833\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.46833 to 0.46211, saving model to best.model\n",
      "0s - loss: 0.5048 - acc: 0.7648 - val_loss: 0.4621 - val_acc: 0.7833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.46211 to 0.45587, saving model to best.model\n",
      "0s - loss: 0.5090 - acc: 0.7796 - val_loss: 0.4559 - val_acc: 0.7667\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.45587 to 0.45194, saving model to best.model\n",
      "0s - loss: 0.5198 - acc: 0.7426 - val_loss: 0.4519 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.45194 to 0.44893, saving model to best.model\n",
      "0s - loss: 0.5058 - acc: 0.7537 - val_loss: 0.4489 - val_acc: 0.7833\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.44893 to 0.44603, saving model to best.model\n",
      "0s - loss: 0.4942 - acc: 0.7611 - val_loss: 0.4460 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.44603 to 0.44322, saving model to best.model\n",
      "0s - loss: 0.5214 - acc: 0.7556 - val_loss: 0.4432 - val_acc: 0.7833\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.44322 to 0.44011, saving model to best.model\n",
      "0s - loss: 0.4697 - acc: 0.7741 - val_loss: 0.4401 - val_acc: 0.7833\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.44011 to 0.43916, saving model to best.model\n",
      "0s - loss: 0.4789 - acc: 0.7630 - val_loss: 0.4392 - val_acc: 0.7833\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4904 - acc: 0.7537 - val_loss: 0.4396 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.5019 - acc: 0.7722 - val_loss: 0.4413 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4826 - acc: 0.7593 - val_loss: 0.4421 - val_acc: 0.7833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4494 - acc: 0.7815 - val_loss: 0.4429 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4942 - acc: 0.7537 - val_loss: 0.4411 - val_acc: 0.7667\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.43916 to 0.43807, saving model to best.model\n",
      "0s - loss: 0.4851 - acc: 0.7704 - val_loss: 0.4381 - val_acc: 0.7667\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.43807 to 0.43767, saving model to best.model\n",
      "0s - loss: 0.4683 - acc: 0.7759 - val_loss: 0.4377 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.43767 to 0.43627, saving model to best.model\n",
      "0s - loss: 0.4742 - acc: 0.7815 - val_loss: 0.4363 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.43627 to 0.43506, saving model to best.model\n",
      "0s - loss: 0.4780 - acc: 0.7796 - val_loss: 0.4351 - val_acc: 0.8000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.43506 to 0.43339, saving model to best.model\n",
      "0s - loss: 0.4859 - acc: 0.7630 - val_loss: 0.4334 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.43339 to 0.43219, saving model to best.model\n",
      "0s - loss: 0.4692 - acc: 0.7685 - val_loss: 0.4322 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4755 - acc: 0.7630 - val_loss: 0.4327 - val_acc: 0.8000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4763 - acc: 0.7796 - val_loss: 0.4347 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4548 - acc: 0.7926 - val_loss: 0.4355 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4715 - acc: 0.7778 - val_loss: 0.4360 - val_acc: 0.8000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4687 - acc: 0.7796 - val_loss: 0.4335 - val_acc: 0.7833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.43219 to 0.43032, saving model to best.model\n",
      "0s - loss: 0.4536 - acc: 0.7926 - val_loss: 0.4303 - val_acc: 0.7833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.43032 to 0.42970, saving model to best.model\n",
      "0s - loss: 0.4713 - acc: 0.7889 - val_loss: 0.4297 - val_acc: 0.7667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4710 - acc: 0.7778 - val_loss: 0.4322 - val_acc: 0.7833\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4383 - acc: 0.8093 - val_loss: 0.4337 - val_acc: 0.7833\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4720 - acc: 0.7796 - val_loss: 0.4331 - val_acc: 0.7833\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4285 - acc: 0.8037 - val_loss: 0.4332 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4552 - acc: 0.7926 - val_loss: 0.4344 - val_acc: 0.7833\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4497 - acc: 0.7778 - val_loss: 0.4317 - val_acc: 0.7833\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.42970 to 0.42787, saving model to best.model\n",
      "0s - loss: 0.4283 - acc: 0.7852 - val_loss: 0.4279 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.42787 to 0.42564, saving model to best.model\n",
      "0s - loss: 0.4518 - acc: 0.8074 - val_loss: 0.4256 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.42564 to 0.42438, saving model to best.model\n",
      "0s - loss: 0.4469 - acc: 0.7926 - val_loss: 0.4244 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4415 - acc: 0.7963 - val_loss: 0.4253 - val_acc: 0.8000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4254 - acc: 0.8056 - val_loss: 0.4281 - val_acc: 0.8000\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4208 - acc: 0.7944 - val_loss: 0.4300 - val_acc: 0.7667\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4394 - acc: 0.8019 - val_loss: 0.4287 - val_acc: 0.7500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4281 - acc: 0.7963 - val_loss: 0.4258 - val_acc: 0.7833\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.42438 to 0.42396, saving model to best.model\n",
      "0s - loss: 0.4540 - acc: 0.7870 - val_loss: 0.4240 - val_acc: 0.7833\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4362 - acc: 0.8056 - val_loss: 0.4268 - val_acc: 0.7833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4073 - acc: 0.8111 - val_loss: 0.4311 - val_acc: 0.7833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4171 - acc: 0.8167 - val_loss: 0.4414 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4151 - acc: 0.8222 - val_loss: 0.4519 - val_acc: 0.7667\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4138 - acc: 0.8074 - val_loss: 0.4596 - val_acc: 0.7667\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4041 - acc: 0.8130 - val_loss: 0.4574 - val_acc: 0.7667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4177 - acc: 0.8111 - val_loss: 0.4443 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4017 - acc: 0.8259 - val_loss: 0.4351 - val_acc: 0.7500\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3922 - acc: 0.8241 - val_loss: 0.4337 - val_acc: 0.7500\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4274 - acc: 0.8074 - val_loss: 0.4322 - val_acc: 0.7500\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4151 - acc: 0.8000 - val_loss: 0.4306 - val_acc: 0.7500\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4161 - acc: 0.7926 - val_loss: 0.4308 - val_acc: 0.7500\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4096 - acc: 0.8167 - val_loss: 0.4337 - val_acc: 0.7500\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4011 - acc: 0.8315 - val_loss: 0.4424 - val_acc: 0.7333\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3984 - acc: 0.8037 - val_loss: 0.4536 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3892 - acc: 0.8185 - val_loss: 0.4551 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3847 - acc: 0.8241 - val_loss: 0.4499 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3948 - acc: 0.8222 - val_loss: 0.4405 - val_acc: 0.7667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3986 - acc: 0.8167 - val_loss: 0.4319 - val_acc: 0.7500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.42396 to 0.42177, saving model to best.model\n",
      "0s - loss: 0.4159 - acc: 0.8000 - val_loss: 0.4218 - val_acc: 0.7500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.42177 to 0.41389, saving model to best.model\n",
      "0s - loss: 0.4072 - acc: 0.8130 - val_loss: 0.4139 - val_acc: 0.7333\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.41389 to 0.41148, saving model to best.model\n",
      "0s - loss: 0.4036 - acc: 0.8148 - val_loss: 0.4115 - val_acc: 0.7333\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3704 - acc: 0.8444 - val_loss: 0.4126 - val_acc: 0.7333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.4097 - acc: 0.8278 - val_loss: 0.4252 - val_acc: 0.7833\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3689 - acc: 0.8444 - val_loss: 0.4367 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.4035 - acc: 0.8241 - val_loss: 0.4411 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3952 - acc: 0.8278 - val_loss: 0.4391 - val_acc: 0.8000\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3708 - acc: 0.8278 - val_loss: 0.4369 - val_acc: 0.8000\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3756 - acc: 0.8185 - val_loss: 0.4357 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.4041 - acc: 0.8056 - val_loss: 0.4289 - val_acc: 0.7833\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3801 - acc: 0.8204 - val_loss: 0.4272 - val_acc: 0.7833\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3697 - acc: 0.8444 - val_loss: 0.4294 - val_acc: 0.7667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3601 - acc: 0.8241 - val_loss: 0.4288 - val_acc: 0.7667\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3547 - acc: 0.8426 - val_loss: 0.4246 - val_acc: 0.7500\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3507 - acc: 0.8370 - val_loss: 0.4245 - val_acc: 0.7667\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3776 - acc: 0.8185 - val_loss: 0.4233 - val_acc: 0.7667\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3763 - acc: 0.8481 - val_loss: 0.4207 - val_acc: 0.7500\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3442 - acc: 0.8500 - val_loss: 0.4176 - val_acc: 0.7500\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3951 - acc: 0.8259 - val_loss: 0.4178 - val_acc: 0.7500\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3756 - acc: 0.8296 - val_loss: 0.4270 - val_acc: 0.7500\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3581 - acc: 0.8333 - val_loss: 0.4391 - val_acc: 0.7333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3651 - acc: 0.8500 - val_loss: 0.4428 - val_acc: 0.7667\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3332 - acc: 0.8463 - val_loss: 0.4363 - val_acc: 0.7500\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3725 - acc: 0.8444 - val_loss: 0.4308 - val_acc: 0.7500\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3572 - acc: 0.8333 - val_loss: 0.4250 - val_acc: 0.7667\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3244 - acc: 0.8704 - val_loss: 0.4198 - val_acc: 0.7667\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3685 - acc: 0.8315 - val_loss: 0.4182 - val_acc: 0.7667\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3399 - acc: 0.8537 - val_loss: 0.4148 - val_acc: 0.7667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.56550, saving model to best.model\n",
      "0s - loss: 0.8373 - acc: 0.5389 - val_loss: 0.5655 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.6905 - acc: 0.6815 - val_loss: 0.5765 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.56550 to 0.55917, saving model to best.model\n",
      "0s - loss: 0.7060 - acc: 0.7074 - val_loss: 0.5592 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.55917 to 0.54428, saving model to best.model\n",
      "0s - loss: 0.7120 - acc: 0.7019 - val_loss: 0.5443 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.54428 to 0.54393, saving model to best.model\n",
      "0s - loss: 0.6549 - acc: 0.6852 - val_loss: 0.5439 - val_acc: 0.7333\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6247 - acc: 0.7037 - val_loss: 0.5526 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6341 - acc: 0.6630 - val_loss: 0.5557 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6262 - acc: 0.6796 - val_loss: 0.5531 - val_acc: 0.7167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6301 - acc: 0.6778 - val_loss: 0.5506 - val_acc: 0.7167\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5923 - acc: 0.7111 - val_loss: 0.5462 - val_acc: 0.7167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.54393 to 0.53890, saving model to best.model\n",
      "0s - loss: 0.5875 - acc: 0.7074 - val_loss: 0.5389 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.53890 to 0.53141, saving model to best.model\n",
      "0s - loss: 0.6012 - acc: 0.7037 - val_loss: 0.5314 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.53141 to 0.52613, saving model to best.model\n",
      "0s - loss: 0.5777 - acc: 0.7019 - val_loss: 0.5261 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.52613 to 0.52347, saving model to best.model\n",
      "0s - loss: 0.5896 - acc: 0.7074 - val_loss: 0.5235 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5791 - acc: 0.7204 - val_loss: 0.5243 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5537 - acc: 0.7315 - val_loss: 0.5252 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5581 - acc: 0.7130 - val_loss: 0.5245 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5867 - acc: 0.7056 - val_loss: 0.5250 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5684 - acc: 0.7222 - val_loss: 0.5240 - val_acc: 0.7333\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.52347 to 0.52105, saving model to best.model\n",
      "0s - loss: 0.5559 - acc: 0.7278 - val_loss: 0.5210 - val_acc: 0.7333\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.52105 to 0.51781, saving model to best.model\n",
      "0s - loss: 0.5635 - acc: 0.7296 - val_loss: 0.5178 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.51781 to 0.51357, saving model to best.model\n",
      "0s - loss: 0.5216 - acc: 0.7481 - val_loss: 0.5136 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.51357 to 0.50845, saving model to best.model\n",
      "0s - loss: 0.5573 - acc: 0.7241 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.50845 to 0.50407, saving model to best.model\n",
      "0s - loss: 0.5425 - acc: 0.7352 - val_loss: 0.5041 - val_acc: 0.7500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.50407 to 0.50049, saving model to best.model\n",
      "0s - loss: 0.5327 - acc: 0.7296 - val_loss: 0.5005 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.50049 to 0.49806, saving model to best.model\n",
      "0s - loss: 0.5141 - acc: 0.7426 - val_loss: 0.4981 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5578 - acc: 0.7444 - val_loss: 0.4986 - val_acc: 0.7500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5338 - acc: 0.7241 - val_loss: 0.4997 - val_acc: 0.7500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5311 - acc: 0.7370 - val_loss: 0.5000 - val_acc: 0.7500\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5230 - acc: 0.7593 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.5108 - acc: 0.7574 - val_loss: 0.5012 - val_acc: 0.7667\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.5218 - acc: 0.7407 - val_loss: 0.5010 - val_acc: 0.7667\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.5167 - acc: 0.7407 - val_loss: 0.4992 - val_acc: 0.7667\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.49806 to 0.49618, saving model to best.model\n",
      "0s - loss: 0.5099 - acc: 0.7500 - val_loss: 0.4962 - val_acc: 0.7667\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.49618 to 0.49528, saving model to best.model\n",
      "0s - loss: 0.5495 - acc: 0.7370 - val_loss: 0.4953 - val_acc: 0.7667\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5028 - acc: 0.7556 - val_loss: 0.4968 - val_acc: 0.7667\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5271 - acc: 0.7463 - val_loss: 0.4973 - val_acc: 0.7667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5122 - acc: 0.7481 - val_loss: 0.4969 - val_acc: 0.7667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.5232 - acc: 0.7500 - val_loss: 0.4955 - val_acc: 0.7667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.49528 to 0.49483, saving model to best.model\n",
      "0s - loss: 0.5254 - acc: 0.7519 - val_loss: 0.4948 - val_acc: 0.7667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 0.5064 - acc: 0.7611 - val_loss: 0.4954 - val_acc: 0.7667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.5199 - acc: 0.7630 - val_loss: 0.4983 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.5042 - acc: 0.7611 - val_loss: 0.5008 - val_acc: 0.7667\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.5076 - acc: 0.7593 - val_loss: 0.5010 - val_acc: 0.7833\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.5082 - acc: 0.7556 - val_loss: 0.4988 - val_acc: 0.7833\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4967 - acc: 0.7537 - val_loss: 0.4965 - val_acc: 0.7833\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.49483 to 0.49256, saving model to best.model\n",
      "0s - loss: 0.4770 - acc: 0.7630 - val_loss: 0.4926 - val_acc: 0.7833\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.49256 to 0.49014, saving model to best.model\n",
      "0s - loss: 0.4956 - acc: 0.7648 - val_loss: 0.4901 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4925 - acc: 0.7685 - val_loss: 0.4903 - val_acc: 0.7500\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5049 - acc: 0.7630 - val_loss: 0.4908 - val_acc: 0.7500\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4942 - acc: 0.7667 - val_loss: 0.4906 - val_acc: 0.7500\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4986 - acc: 0.7741 - val_loss: 0.4902 - val_acc: 0.7667\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4802 - acc: 0.7630 - val_loss: 0.4915 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4931 - acc: 0.7648 - val_loss: 0.4934 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4972 - acc: 0.7556 - val_loss: 0.4948 - val_acc: 0.7833\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.5009 - acc: 0.7685 - val_loss: 0.4952 - val_acc: 0.7833\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4807 - acc: 0.7741 - val_loss: 0.4955 - val_acc: 0.7667\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4673 - acc: 0.7667 - val_loss: 0.4940 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4793 - acc: 0.7704 - val_loss: 0.4923 - val_acc: 0.7833\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4634 - acc: 0.7870 - val_loss: 0.4905 - val_acc: 0.7833\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.49014 to 0.48953, saving model to best.model\n",
      "0s - loss: 0.4800 - acc: 0.7926 - val_loss: 0.4895 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss improved from 0.48953 to 0.48928, saving model to best.model\n",
      "0s - loss: 0.4797 - acc: 0.7796 - val_loss: 0.4893 - val_acc: 0.7833\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.48928 to 0.48826, saving model to best.model\n",
      "0s - loss: 0.4732 - acc: 0.7722 - val_loss: 0.4883 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.48826 to 0.48706, saving model to best.model\n",
      "0s - loss: 0.4812 - acc: 0.7926 - val_loss: 0.4871 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.48706 to 0.48629, saving model to best.model\n",
      "0s - loss: 0.4605 - acc: 0.7704 - val_loss: 0.4863 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.48629 to 0.48560, saving model to best.model\n",
      "0s - loss: 0.4794 - acc: 0.7630 - val_loss: 0.4856 - val_acc: 0.7833\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.48560 to 0.48445, saving model to best.model\n",
      "0s - loss: 0.4717 - acc: 0.7648 - val_loss: 0.4844 - val_acc: 0.7833\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.48445 to 0.48386, saving model to best.model\n",
      "0s - loss: 0.4623 - acc: 0.7722 - val_loss: 0.4839 - val_acc: 0.7833\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.48386 to 0.48384, saving model to best.model\n",
      "0s - loss: 0.4699 - acc: 0.7870 - val_loss: 0.4838 - val_acc: 0.7833\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.48384 to 0.48381, saving model to best.model\n",
      "0s - loss: 0.4982 - acc: 0.7889 - val_loss: 0.4838 - val_acc: 0.7833\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss improved from 0.48381 to 0.48365, saving model to best.model\n",
      "0s - loss: 0.4578 - acc: 0.7963 - val_loss: 0.4837 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4632 - acc: 0.7759 - val_loss: 0.4861 - val_acc: 0.7667\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4602 - acc: 0.7889 - val_loss: 0.4930 - val_acc: 0.7500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.4865 - acc: 0.7741 - val_loss: 0.5001 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4677 - acc: 0.8000 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4798 - acc: 0.7704 - val_loss: 0.4957 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4604 - acc: 0.8019 - val_loss: 0.4872 - val_acc: 0.7667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.48365 to 0.47896, saving model to best.model\n",
      "0s - loss: 0.4687 - acc: 0.7778 - val_loss: 0.4790 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.47896 to 0.47445, saving model to best.model\n",
      "0s - loss: 0.4584 - acc: 0.7796 - val_loss: 0.4745 - val_acc: 0.7667\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.47445 to 0.47144, saving model to best.model\n",
      "0s - loss: 0.4426 - acc: 0.7852 - val_loss: 0.4714 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.47144 to 0.46996, saving model to best.model\n",
      "0s - loss: 0.4462 - acc: 0.8037 - val_loss: 0.4700 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.46996 to 0.46945, saving model to best.model\n",
      "0s - loss: 0.4629 - acc: 0.7741 - val_loss: 0.4694 - val_acc: 0.7500\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4524 - acc: 0.8056 - val_loss: 0.4699 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4431 - acc: 0.7778 - val_loss: 0.4720 - val_acc: 0.7667\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4330 - acc: 0.8093 - val_loss: 0.4751 - val_acc: 0.7667\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4331 - acc: 0.8130 - val_loss: 0.4777 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4588 - acc: 0.7889 - val_loss: 0.4797 - val_acc: 0.7667\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.4442 - acc: 0.7926 - val_loss: 0.4777 - val_acc: 0.7667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4035 - acc: 0.8296 - val_loss: 0.4745 - val_acc: 0.7667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4376 - acc: 0.7944 - val_loss: 0.4739 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4201 - acc: 0.8296 - val_loss: 0.4733 - val_acc: 0.7667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4142 - acc: 0.8185 - val_loss: 0.4705 - val_acc: 0.7667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.46945 to 0.46857, saving model to best.model\n",
      "0s - loss: 0.4195 - acc: 0.8185 - val_loss: 0.4686 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.46857 to 0.46823, saving model to best.model\n",
      "0s - loss: 0.4356 - acc: 0.8056 - val_loss: 0.4682 - val_acc: 0.7833\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4233 - acc: 0.8037 - val_loss: 0.4691 - val_acc: 0.7833\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4231 - acc: 0.8019 - val_loss: 0.4703 - val_acc: 0.7667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4282 - acc: 0.8056 - val_loss: 0.4731 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4364 - acc: 0.8056 - val_loss: 0.4759 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.4158 - acc: 0.8315 - val_loss: 0.4740 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.4131 - acc: 0.8111 - val_loss: 0.4709 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.46823 to 0.46786, saving model to best.model\n",
      "0s - loss: 0.4262 - acc: 0.8111 - val_loss: 0.4679 - val_acc: 0.7667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.46786 to 0.46473, saving model to best.model\n",
      "0s - loss: 0.3886 - acc: 0.8259 - val_loss: 0.4647 - val_acc: 0.7667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.46473 to 0.46441, saving model to best.model\n",
      "0s - loss: 0.4069 - acc: 0.8241 - val_loss: 0.4644 - val_acc: 0.7667\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.46441 to 0.46435, saving model to best.model\n",
      "0s - loss: 0.4078 - acc: 0.8241 - val_loss: 0.4644 - val_acc: 0.7667\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.4237 - acc: 0.8222 - val_loss: 0.4654 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4126 - acc: 0.8204 - val_loss: 0.4657 - val_acc: 0.7667\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.4062 - acc: 0.8204 - val_loss: 0.4651 - val_acc: 0.7667\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3994 - acc: 0.8204 - val_loss: 0.4652 - val_acc: 0.7667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.4002 - acc: 0.8278 - val_loss: 0.4649 - val_acc: 0.7667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.46435 to 0.46348, saving model to best.model\n",
      "0s - loss: 0.3885 - acc: 0.8370 - val_loss: 0.4635 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.4097 - acc: 0.8259 - val_loss: 0.4647 - val_acc: 0.7667\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3926 - acc: 0.8278 - val_loss: 0.4650 - val_acc: 0.7667\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.4110 - acc: 0.8111 - val_loss: 0.4642 - val_acc: 0.7667\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss improved from 0.46348 to 0.46329, saving model to best.model\n",
      "0s - loss: 0.3935 - acc: 0.8204 - val_loss: 0.4633 - val_acc: 0.7667\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss improved from 0.46329 to 0.46261, saving model to best.model\n",
      "0s - loss: 0.3661 - acc: 0.8556 - val_loss: 0.4626 - val_acc: 0.7667\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss improved from 0.46261 to 0.46254, saving model to best.model\n",
      "0s - loss: 0.4089 - acc: 0.8333 - val_loss: 0.4625 - val_acc: 0.7667\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss improved from 0.46254 to 0.46221, saving model to best.model\n",
      "0s - loss: 0.3932 - acc: 0.8407 - val_loss: 0.4622 - val_acc: 0.7667\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss improved from 0.46221 to 0.46092, saving model to best.model\n",
      "0s - loss: 0.3957 - acc: 0.8296 - val_loss: 0.4609 - val_acc: 0.7667\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3889 - acc: 0.8296 - val_loss: 0.4617 - val_acc: 0.7667\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3694 - acc: 0.8241 - val_loss: 0.4619 - val_acc: 0.7667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.46092 to 0.46072, saving model to best.model\n",
      "0s - loss: 0.3644 - acc: 0.8389 - val_loss: 0.4607 - val_acc: 0.7667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.46072 to 0.45948, saving model to best.model\n",
      "0s - loss: 0.3518 - acc: 0.8444 - val_loss: 0.4595 - val_acc: 0.7667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3593 - acc: 0.8519 - val_loss: 0.4599 - val_acc: 0.7667\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 0.3802 - acc: 0.8185 - val_loss: 0.4627 - val_acc: 0.7667\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 0.3635 - acc: 0.8389 - val_loss: 0.4668 - val_acc: 0.7667\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss did not improve\n",
      "0s - loss: 0.3545 - acc: 0.8407 - val_loss: 0.4727 - val_acc: 0.7167\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3887 - acc: 0.8481 - val_loss: 0.4809 - val_acc: 0.7167\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3588 - acc: 0.8352 - val_loss: 0.4864 - val_acc: 0.7167\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3755 - acc: 0.8333 - val_loss: 0.4854 - val_acc: 0.7167\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3582 - acc: 0.8519 - val_loss: 0.4821 - val_acc: 0.7167\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3440 - acc: 0.8574 - val_loss: 0.4793 - val_acc: 0.7167\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3415 - acc: 0.8593 - val_loss: 0.4753 - val_acc: 0.7167\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3715 - acc: 0.8481 - val_loss: 0.4724 - val_acc: 0.7333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3630 - acc: 0.8370 - val_loss: 0.4702 - val_acc: 0.7333\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3528 - acc: 0.8426 - val_loss: 0.4694 - val_acc: 0.7500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3552 - acc: 0.8537 - val_loss: 0.4696 - val_acc: 0.7500\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3404 - acc: 0.8556 - val_loss: 0.4711 - val_acc: 0.7500\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3509 - acc: 0.8556 - val_loss: 0.4715 - val_acc: 0.7333\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3506 - acc: 0.8556 - val_loss: 0.4750 - val_acc: 0.7333\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3206 - acc: 0.8796 - val_loss: 0.4820 - val_acc: 0.7333\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3583 - acc: 0.8370 - val_loss: 0.4835 - val_acc: 0.7500\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3231 - acc: 0.8722 - val_loss: 0.4799 - val_acc: 0.7500\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3513 - acc: 0.8444 - val_loss: 0.4786 - val_acc: 0.7500\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3326 - acc: 0.8500 - val_loss: 0.4815 - val_acc: 0.7500\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3327 - acc: 0.8741 - val_loss: 0.4893 - val_acc: 0.7333\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3221 - acc: 0.8722 - val_loss: 0.5034 - val_acc: 0.7500\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3610 - acc: 0.8537 - val_loss: 0.5226 - val_acc: 0.7333\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3703 - acc: 0.8500 - val_loss: 0.5200 - val_acc: 0.7333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.66306, saving model to best.model\n",
      "0s - loss: 0.8357 - acc: 0.5333 - val_loss: 0.6631 - val_acc: 0.6500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.6878 - acc: 0.7019 - val_loss: 0.7029 - val_acc: 0.6500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7240 - acc: 0.6574 - val_loss: 0.6876 - val_acc: 0.6500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.66306 to 0.65743, saving model to best.model\n",
      "0s - loss: 0.6986 - acc: 0.6759 - val_loss: 0.6574 - val_acc: 0.6500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.65743 to 0.63982, saving model to best.model\n",
      "0s - loss: 0.6406 - acc: 0.6889 - val_loss: 0.6398 - val_acc: 0.6500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.63982 to 0.63407, saving model to best.model\n",
      "0s - loss: 0.6374 - acc: 0.6981 - val_loss: 0.6341 - val_acc: 0.6500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.63407 to 0.62811, saving model to best.model\n",
      "0s - loss: 0.6104 - acc: 0.6796 - val_loss: 0.6281 - val_acc: 0.6500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.62811 to 0.62359, saving model to best.model\n",
      "0s - loss: 0.5856 - acc: 0.6944 - val_loss: 0.6236 - val_acc: 0.6500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.62359 to 0.61895, saving model to best.model\n",
      "0s - loss: 0.5635 - acc: 0.7148 - val_loss: 0.6190 - val_acc: 0.6500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.61895 to 0.61661, saving model to best.model\n",
      "0s - loss: 0.5815 - acc: 0.6926 - val_loss: 0.6166 - val_acc: 0.6500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.61661 to 0.61214, saving model to best.model\n",
      "0s - loss: 0.5841 - acc: 0.7000 - val_loss: 0.6121 - val_acc: 0.6500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.61214 to 0.60783, saving model to best.model\n",
      "0s - loss: 0.5283 - acc: 0.7222 - val_loss: 0.6078 - val_acc: 0.6500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.60783 to 0.60618, saving model to best.model\n",
      "0s - loss: 0.5545 - acc: 0.7259 - val_loss: 0.6062 - val_acc: 0.6500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5527 - acc: 0.7130 - val_loss: 0.6067 - val_acc: 0.6500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5412 - acc: 0.7056 - val_loss: 0.6103 - val_acc: 0.6500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5465 - acc: 0.7019 - val_loss: 0.6169 - val_acc: 0.6500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5445 - acc: 0.7222 - val_loss: 0.6216 - val_acc: 0.6500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5307 - acc: 0.7352 - val_loss: 0.6224 - val_acc: 0.6500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5413 - acc: 0.7481 - val_loss: 0.6217 - val_acc: 0.6500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5285 - acc: 0.7481 - val_loss: 0.6189 - val_acc: 0.6500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5144 - acc: 0.7296 - val_loss: 0.6132 - val_acc: 0.6833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.60618 to 0.60397, saving model to best.model\n",
      "0s - loss: 0.5227 - acc: 0.7370 - val_loss: 0.6040 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.60397 to 0.59911, saving model to best.model\n",
      "0s - loss: 0.4947 - acc: 0.7759 - val_loss: 0.5991 - val_acc: 0.7000\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.59911 to 0.59821, saving model to best.model\n",
      "0s - loss: 0.5120 - acc: 0.7407 - val_loss: 0.5982 - val_acc: 0.7000\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5185 - acc: 0.7463 - val_loss: 0.6016 - val_acc: 0.7000\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5060 - acc: 0.7593 - val_loss: 0.6069 - val_acc: 0.7000\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5156 - acc: 0.7741 - val_loss: 0.6111 - val_acc: 0.7000\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.4834 - acc: 0.7667 - val_loss: 0.6125 - val_acc: 0.7000\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.4891 - acc: 0.7574 - val_loss: 0.6112 - val_acc: 0.7000\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.4796 - acc: 0.7833 - val_loss: 0.6076 - val_acc: 0.7000\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.4919 - acc: 0.7611 - val_loss: 0.6039 - val_acc: 0.7000\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 0.4893 - acc: 0.7796 - val_loss: 0.6014 - val_acc: 0.6500\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.4912 - acc: 0.7685 - val_loss: 0.6000 - val_acc: 0.6500\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.4976 - acc: 0.7815 - val_loss: 0.6009 - val_acc: 0.6500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.4699 - acc: 0.7981 - val_loss: 0.6028 - val_acc: 0.6500\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.4954 - acc: 0.7796 - val_loss: 0.6044 - val_acc: 0.6833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5099 - acc: 0.7722 - val_loss: 0.5992 - val_acc: 0.6667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.59821 to 0.59336, saving model to best.model\n",
      "0s - loss: 0.4948 - acc: 0.7944 - val_loss: 0.5934 - val_acc: 0.6667\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.59336 to 0.59160, saving model to best.model\n",
      "0s - loss: 0.4777 - acc: 0.7519 - val_loss: 0.5916 - val_acc: 0.6667\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.59160 to 0.59000, saving model to best.model\n",
      "0s - loss: 0.4827 - acc: 0.7759 - val_loss: 0.5900 - val_acc: 0.6833\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.59000 to 0.58877, saving model to best.model\n",
      "0s - loss: 0.4614 - acc: 0.7593 - val_loss: 0.5888 - val_acc: 0.7000\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.58877 to 0.58573, saving model to best.model\n",
      "0s - loss: 0.4553 - acc: 0.7963 - val_loss: 0.5857 - val_acc: 0.7000\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4695 - acc: 0.8093 - val_loss: 0.5858 - val_acc: 0.7000\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4651 - acc: 0.8037 - val_loss: 0.5891 - val_acc: 0.7000\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4744 - acc: 0.7870 - val_loss: 0.5914 - val_acc: 0.7000\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4812 - acc: 0.7870 - val_loss: 0.5933 - val_acc: 0.7000\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4440 - acc: 0.8000 - val_loss: 0.5960 - val_acc: 0.7000\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4377 - acc: 0.8148 - val_loss: 0.5945 - val_acc: 0.7000\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4585 - acc: 0.7944 - val_loss: 0.5958 - val_acc: 0.7000\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4628 - acc: 0.7981 - val_loss: 0.5956 - val_acc: 0.6833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4641 - acc: 0.8000 - val_loss: 0.5947 - val_acc: 0.6833\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4544 - acc: 0.8130 - val_loss: 0.5939 - val_acc: 0.7000\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4426 - acc: 0.8056 - val_loss: 0.5930 - val_acc: 0.7000\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4279 - acc: 0.8093 - val_loss: 0.5913 - val_acc: 0.7000\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.58573 to 0.58370, saving model to best.model\n",
      "0s - loss: 0.4748 - acc: 0.7907 - val_loss: 0.5837 - val_acc: 0.7000\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.58370 to 0.57498, saving model to best.model\n",
      "0s - loss: 0.4743 - acc: 0.7889 - val_loss: 0.5750 - val_acc: 0.7000\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.57498 to 0.57015, saving model to best.model\n",
      "0s - loss: 0.4756 - acc: 0.7926 - val_loss: 0.5701 - val_acc: 0.7000\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.57015 to 0.56588, saving model to best.model\n",
      "0s - loss: 0.4502 - acc: 0.7963 - val_loss: 0.5659 - val_acc: 0.7000\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss improved from 0.56588 to 0.56367, saving model to best.model\n",
      "0s - loss: 0.4489 - acc: 0.8056 - val_loss: 0.5637 - val_acc: 0.7000\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss improved from 0.56367 to 0.56236, saving model to best.model\n",
      "0s - loss: 0.4316 - acc: 0.8222 - val_loss: 0.5624 - val_acc: 0.7000\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4206 - acc: 0.8037 - val_loss: 0.5632 - val_acc: 0.7000\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4728 - acc: 0.7944 - val_loss: 0.5662 - val_acc: 0.7000\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4477 - acc: 0.8056 - val_loss: 0.5679 - val_acc: 0.7000\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4301 - acc: 0.8222 - val_loss: 0.5721 - val_acc: 0.7000\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 0.4279 - acc: 0.8185 - val_loss: 0.5735 - val_acc: 0.7000\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4119 - acc: 0.8148 - val_loss: 0.5691 - val_acc: 0.7000\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.4360 - acc: 0.8000 - val_loss: 0.5661 - val_acc: 0.7000\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4186 - acc: 0.8241 - val_loss: 0.5653 - val_acc: 0.7000\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.56236 to 0.56233, saving model to best.model\n",
      "0s - loss: 0.4377 - acc: 0.8056 - val_loss: 0.5623 - val_acc: 0.7000\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss improved from 0.56233 to 0.56189, saving model to best.model\n",
      "0s - loss: 0.4187 - acc: 0.8111 - val_loss: 0.5619 - val_acc: 0.7000\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4259 - acc: 0.8000 - val_loss: 0.5655 - val_acc: 0.7000\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4198 - acc: 0.8056 - val_loss: 0.5649 - val_acc: 0.7000\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4119 - acc: 0.8185 - val_loss: 0.5634 - val_acc: 0.6833\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.56189 to 0.56182, saving model to best.model\n",
      "0s - loss: 0.4266 - acc: 0.8167 - val_loss: 0.5618 - val_acc: 0.6833\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.4073 - acc: 0.8222 - val_loss: 0.5637 - val_acc: 0.6833\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4317 - acc: 0.8056 - val_loss: 0.5711 - val_acc: 0.7000\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4091 - acc: 0.8222 - val_loss: 0.5812 - val_acc: 0.7000\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4273 - acc: 0.7944 - val_loss: 0.5858 - val_acc: 0.7000\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.4200 - acc: 0.8241 - val_loss: 0.5861 - val_acc: 0.7000\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.4201 - acc: 0.8185 - val_loss: 0.5838 - val_acc: 0.7000\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.4253 - acc: 0.8185 - val_loss: 0.5774 - val_acc: 0.7000\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4183 - acc: 0.8333 - val_loss: 0.5662 - val_acc: 0.7000\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.56182 to 0.56069, saving model to best.model\n",
      "0s - loss: 0.3882 - acc: 0.8352 - val_loss: 0.5607 - val_acc: 0.7000\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4073 - acc: 0.8148 - val_loss: 0.5634 - val_acc: 0.7000\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.3965 - acc: 0.8259 - val_loss: 0.5649 - val_acc: 0.7000\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4041 - acc: 0.8352 - val_loss: 0.5626 - val_acc: 0.7000\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4142 - acc: 0.8130 - val_loss: 0.5642 - val_acc: 0.6833\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.3879 - acc: 0.8148 - val_loss: 0.5717 - val_acc: 0.6833\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.3911 - acc: 0.8352 - val_loss: 0.5783 - val_acc: 0.7000\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.3929 - acc: 0.8426 - val_loss: 0.5753 - val_acc: 0.7000\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3853 - acc: 0.8278 - val_loss: 0.5712 - val_acc: 0.6833\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3852 - acc: 0.8407 - val_loss: 0.5708 - val_acc: 0.6833\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.3789 - acc: 0.8204 - val_loss: 0.5783 - val_acc: 0.7000\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.3997 - acc: 0.8259 - val_loss: 0.5832 - val_acc: 0.7000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3892 - acc: 0.8315 - val_loss: 0.5843 - val_acc: 0.7000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3606 - acc: 0.8500 - val_loss: 0.5857 - val_acc: 0.7000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4033 - acc: 0.8315 - val_loss: 0.5821 - val_acc: 0.7000\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3785 - acc: 0.8556 - val_loss: 0.5707 - val_acc: 0.6833\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3487 - acc: 0.8556 - val_loss: 0.5678 - val_acc: 0.6667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3820 - acc: 0.8315 - val_loss: 0.5696 - val_acc: 0.6667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3977 - acc: 0.8259 - val_loss: 0.5709 - val_acc: 0.7000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3688 - acc: 0.8389 - val_loss: 0.5731 - val_acc: 0.7000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3883 - acc: 0.8315 - val_loss: 0.5759 - val_acc: 0.7000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3869 - acc: 0.8444 - val_loss: 0.5700 - val_acc: 0.7000\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3836 - acc: 0.8407 - val_loss: 0.5654 - val_acc: 0.7000\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.3757 - acc: 0.8333 - val_loss: 0.5637 - val_acc: 0.7000\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3738 - acc: 0.8648 - val_loss: 0.5615 - val_acc: 0.6833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3727 - acc: 0.8333 - val_loss: 0.5618 - val_acc: 0.6833\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3684 - acc: 0.8463 - val_loss: 0.5643 - val_acc: 0.6833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58474, saving model to best.model\n",
      "0s - loss: 0.7268 - acc: 0.6463 - val_loss: 0.5847 - val_acc: 0.7167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.58474 to 0.57605, saving model to best.model\n",
      "0s - loss: 0.6722 - acc: 0.6944 - val_loss: 0.5761 - val_acc: 0.7167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.57605 to 0.56393, saving model to best.model\n",
      "0s - loss: 0.6489 - acc: 0.6870 - val_loss: 0.5639 - val_acc: 0.7167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.56393 to 0.56354, saving model to best.model\n",
      "0s - loss: 0.6151 - acc: 0.7000 - val_loss: 0.5635 - val_acc: 0.7167\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6439 - acc: 0.7074 - val_loss: 0.5730 - val_acc: 0.7167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.5875 - acc: 0.6963 - val_loss: 0.5804 - val_acc: 0.7167\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5813 - acc: 0.6926 - val_loss: 0.5811 - val_acc: 0.7167\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5652 - acc: 0.7148 - val_loss: 0.5769 - val_acc: 0.7167\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5634 - acc: 0.7056 - val_loss: 0.5711 - val_acc: 0.7167\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5360 - acc: 0.7426 - val_loss: 0.5663 - val_acc: 0.7167\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5823 - acc: 0.7222 - val_loss: 0.5644 - val_acc: 0.7167\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5433 - acc: 0.7426 - val_loss: 0.5644 - val_acc: 0.7167\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5625 - acc: 0.7352 - val_loss: 0.5649 - val_acc: 0.7167\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5279 - acc: 0.7426 - val_loss: 0.5654 - val_acc: 0.7167\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5446 - acc: 0.7463 - val_loss: 0.5666 - val_acc: 0.7167\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5199 - acc: 0.7333 - val_loss: 0.5672 - val_acc: 0.7167\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5278 - acc: 0.7352 - val_loss: 0.5666 - val_acc: 0.7167\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5561 - acc: 0.7241 - val_loss: 0.5656 - val_acc: 0.7167\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5434 - acc: 0.7241 - val_loss: 0.5642 - val_acc: 0.7167\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5160 - acc: 0.7444 - val_loss: 0.5639 - val_acc: 0.7167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5112 - acc: 0.7463 - val_loss: 0.5643 - val_acc: 0.7167\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5200 - acc: 0.7407 - val_loss: 0.5639 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5140 - acc: 0.7481 - val_loss: 0.5636 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.56354 to 0.56345, saving model to best.model\n",
      "0s - loss: 0.4875 - acc: 0.7593 - val_loss: 0.5635 - val_acc: 0.7167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.4981 - acc: 0.7648 - val_loss: 0.5640 - val_acc: 0.7167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.4895 - acc: 0.7519 - val_loss: 0.5649 - val_acc: 0.7167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.4994 - acc: 0.7648 - val_loss: 0.5653 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5046 - acc: 0.7519 - val_loss: 0.5649 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.4930 - acc: 0.7778 - val_loss: 0.5653 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 0.5052 - acc: 0.7444 - val_loss: 0.5655 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 0.4786 - acc: 0.7648 - val_loss: 0.5638 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.56345 to 0.56287, saving model to best.model\n",
      "0s - loss: 0.4718 - acc: 0.7593 - val_loss: 0.5629 - val_acc: 0.7167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 0.4515 - acc: 0.7870 - val_loss: 0.5637 - val_acc: 0.7167\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 0.4728 - acc: 0.7870 - val_loss: 0.5640 - val_acc: 0.7167\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 0.4545 - acc: 0.7685 - val_loss: 0.5632 - val_acc: 0.7167\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.56287 to 0.56246, saving model to best.model\n",
      "0s - loss: 0.4585 - acc: 0.7778 - val_loss: 0.5625 - val_acc: 0.7167\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.56246 to 0.56238, saving model to best.model\n",
      "0s - loss: 0.4826 - acc: 0.7685 - val_loss: 0.5624 - val_acc: 0.7167\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.56238 to 0.56217, saving model to best.model\n",
      "0s - loss: 0.4710 - acc: 0.7741 - val_loss: 0.5622 - val_acc: 0.7167\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.56217 to 0.56195, saving model to best.model\n",
      "0s - loss: 0.4729 - acc: 0.7611 - val_loss: 0.5620 - val_acc: 0.7167\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 0.4711 - acc: 0.7537 - val_loss: 0.5624 - val_acc: 0.7167\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.56195 to 0.56185, saving model to best.model\n",
      "0s - loss: 0.4675 - acc: 0.7907 - val_loss: 0.5618 - val_acc: 0.7333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 0.4693 - acc: 0.7870 - val_loss: 0.5622 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.56185 to 0.56103, saving model to best.model\n",
      "0s - loss: 0.4634 - acc: 0.7815 - val_loss: 0.5610 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.56103 to 0.55938, saving model to best.model\n",
      "0s - loss: 0.4491 - acc: 0.7944 - val_loss: 0.5594 - val_acc: 0.7333\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.55938 to 0.55898, saving model to best.model\n",
      "0s - loss: 0.4384 - acc: 0.8037 - val_loss: 0.5590 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 0.4511 - acc: 0.7889 - val_loss: 0.5593 - val_acc: 0.7333\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 0.4259 - acc: 0.8204 - val_loss: 0.5594 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4497 - acc: 0.8000 - val_loss: 0.5608 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4490 - acc: 0.7981 - val_loss: 0.5636 - val_acc: 0.7167\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.4267 - acc: 0.7889 - val_loss: 0.5660 - val_acc: 0.7167\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4287 - acc: 0.8056 - val_loss: 0.5687 - val_acc: 0.7167\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4410 - acc: 0.7944 - val_loss: 0.5699 - val_acc: 0.7167\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.4328 - acc: 0.7963 - val_loss: 0.5701 - val_acc: 0.7167\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4542 - acc: 0.7926 - val_loss: 0.5699 - val_acc: 0.7167\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4200 - acc: 0.8148 - val_loss: 0.5703 - val_acc: 0.7167\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 0.4151 - acc: 0.8222 - val_loss: 0.5696 - val_acc: 0.7167\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 0.4270 - acc: 0.7981 - val_loss: 0.5689 - val_acc: 0.7167\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 0.4215 - acc: 0.8074 - val_loss: 0.5664 - val_acc: 0.7167\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4209 - acc: 0.8259 - val_loss: 0.5654 - val_acc: 0.7333\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4285 - acc: 0.8093 - val_loss: 0.5650 - val_acc: 0.7333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4184 - acc: 0.8241 - val_loss: 0.5656 - val_acc: 0.7333\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4301 - acc: 0.8278 - val_loss: 0.5640 - val_acc: 0.7333\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.55898 to 0.55386, saving model to best.model\n",
      "0s - loss: 0.4608 - acc: 0.7852 - val_loss: 0.5539 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.55386 to 0.54821, saving model to best.model\n",
      "0s - loss: 0.4273 - acc: 0.8111 - val_loss: 0.5482 - val_acc: 0.7833\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.54821 to 0.54656, saving model to best.model\n",
      "0s - loss: 0.4210 - acc: 0.8056 - val_loss: 0.5466 - val_acc: 0.7833\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 0.4081 - acc: 0.8222 - val_loss: 0.5490 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 0.3861 - acc: 0.8278 - val_loss: 0.5559 - val_acc: 0.7333\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4092 - acc: 0.8167 - val_loss: 0.5636 - val_acc: 0.7500\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.3968 - acc: 0.8111 - val_loss: 0.5639 - val_acc: 0.7333\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.3899 - acc: 0.8407 - val_loss: 0.5611 - val_acc: 0.7333\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4141 - acc: 0.7907 - val_loss: 0.5592 - val_acc: 0.7333\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.3837 - acc: 0.8222 - val_loss: 0.5606 - val_acc: 0.7333\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.3953 - acc: 0.8278 - val_loss: 0.5636 - val_acc: 0.7333\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 0.3907 - acc: 0.8167 - val_loss: 0.5671 - val_acc: 0.7333\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 0.3930 - acc: 0.8222 - val_loss: 0.5675 - val_acc: 0.7333\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.3932 - acc: 0.8148 - val_loss: 0.5568 - val_acc: 0.7667\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4105 - acc: 0.8167 - val_loss: 0.5487 - val_acc: 0.7667\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.54656 to 0.54651, saving model to best.model\n",
      "0s - loss: 0.3721 - acc: 0.8352 - val_loss: 0.5465 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 0.3964 - acc: 0.8278 - val_loss: 0.5465 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.3760 - acc: 0.8407 - val_loss: 0.5465 - val_acc: 0.7667\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 0.3995 - acc: 0.8222 - val_loss: 0.5492 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.3864 - acc: 0.8185 - val_loss: 0.5539 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4077 - acc: 0.8222 - val_loss: 0.5602 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.3705 - acc: 0.8426 - val_loss: 0.5704 - val_acc: 0.7667\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.3633 - acc: 0.8296 - val_loss: 0.5774 - val_acc: 0.7500\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.3632 - acc: 0.8593 - val_loss: 0.5824 - val_acc: 0.7667\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.3766 - acc: 0.8500 - val_loss: 0.5853 - val_acc: 0.7667\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 0.3870 - acc: 0.8407 - val_loss: 0.5803 - val_acc: 0.7667\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4104 - acc: 0.8241 - val_loss: 0.5741 - val_acc: 0.7667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.3754 - acc: 0.8500 - val_loss: 0.5745 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.3614 - acc: 0.8370 - val_loss: 0.5736 - val_acc: 0.7667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.3781 - acc: 0.8463 - val_loss: 0.5702 - val_acc: 0.7667\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.3386 - acc: 0.8574 - val_loss: 0.5706 - val_acc: 0.7667\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.3557 - acc: 0.8463 - val_loss: 0.5756 - val_acc: 0.7667\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.3563 - acc: 0.8481 - val_loss: 0.5791 - val_acc: 0.7333\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.3361 - acc: 0.8611 - val_loss: 0.5748 - val_acc: 0.7667\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.3489 - acc: 0.8407 - val_loss: 0.5695 - val_acc: 0.7833\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.3564 - acc: 0.8519 - val_loss: 0.5681 - val_acc: 0.7833\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 0.3446 - acc: 0.8648 - val_loss: 0.5698 - val_acc: 0.7833\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.3461 - acc: 0.8593 - val_loss: 0.5759 - val_acc: 0.7833\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.3550 - acc: 0.8574 - val_loss: 0.5759 - val_acc: 0.7833\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.3365 - acc: 0.8611 - val_loss: 0.5729 - val_acc: 0.7833\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.3580 - acc: 0.8389 - val_loss: 0.5678 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.3166 - acc: 0.8907 - val_loss: 0.5600 - val_acc: 0.7833\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.44276, saving model to best.model\n",
      "0s - loss: 0.8135 - acc: 0.5778 - val_loss: 0.4428 - val_acc: 0.8167\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.44276 to 0.43544, saving model to best.model\n",
      "0s - loss: 0.7634 - acc: 0.6407 - val_loss: 0.4354 - val_acc: 0.8167\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.7519 - acc: 0.6630 - val_loss: 0.4481 - val_acc: 0.8167\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6705 - acc: 0.6519 - val_loss: 0.4803 - val_acc: 0.8333\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6557 - acc: 0.6593 - val_loss: 0.4871 - val_acc: 0.8167\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6200 - acc: 0.6741 - val_loss: 0.4823 - val_acc: 0.8500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6695 - acc: 0.6537 - val_loss: 0.4752 - val_acc: 0.8500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6004 - acc: 0.6815 - val_loss: 0.4646 - val_acc: 0.8333\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.5852 - acc: 0.7056 - val_loss: 0.4617 - val_acc: 0.8333\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5979 - acc: 0.7111 - val_loss: 0.4635 - val_acc: 0.8500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5684 - acc: 0.7037 - val_loss: 0.4712 - val_acc: 0.8500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5817 - acc: 0.6907 - val_loss: 0.4796 - val_acc: 0.8333\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.5773 - acc: 0.6815 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5694 - acc: 0.6870 - val_loss: 0.4939 - val_acc: 0.8333\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5544 - acc: 0.7056 - val_loss: 0.4945 - val_acc: 0.8333\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5492 - acc: 0.7389 - val_loss: 0.4855 - val_acc: 0.8333\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5460 - acc: 0.7167 - val_loss: 0.4785 - val_acc: 0.8333\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5555 - acc: 0.7130 - val_loss: 0.4796 - val_acc: 0.8500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5787 - acc: 0.7037 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5534 - acc: 0.7352 - val_loss: 0.4917 - val_acc: 0.8667\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5443 - acc: 0.7111 - val_loss: 0.4859 - val_acc: 0.8667\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5158 - acc: 0.7481 - val_loss: 0.4820 - val_acc: 0.8667\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5414 - acc: 0.7241 - val_loss: 0.4796 - val_acc: 0.8667\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5292 - acc: 0.7315 - val_loss: 0.4737 - val_acc: 0.8667\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5303 - acc: 0.7259 - val_loss: 0.4674 - val_acc: 0.8667\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5246 - acc: 0.7352 - val_loss: 0.4704 - val_acc: 0.8667\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5366 - acc: 0.7537 - val_loss: 0.4790 - val_acc: 0.8500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5271 - acc: 0.7222 - val_loss: 0.4894 - val_acc: 0.8333\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.58535, saving model to best.model\n",
      "0s - loss: 0.9285 - acc: 0.4889 - val_loss: 0.5853 - val_acc: 0.6833\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss did not improve\n",
      "0s - loss: 0.7338 - acc: 0.6611 - val_loss: 0.5928 - val_acc: 0.6833\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.58535 to 0.58395, saving model to best.model\n",
      "0s - loss: 0.6688 - acc: 0.6852 - val_loss: 0.5840 - val_acc: 0.6833\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.58395 to 0.57281, saving model to best.model\n",
      "0s - loss: 0.6819 - acc: 0.6926 - val_loss: 0.5728 - val_acc: 0.6833\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.57281 to 0.56805, saving model to best.model\n",
      "0s - loss: 0.6415 - acc: 0.7000 - val_loss: 0.5680 - val_acc: 0.6833\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.56805 to 0.56697, saving model to best.model\n",
      "0s - loss: 0.6263 - acc: 0.7056 - val_loss: 0.5670 - val_acc: 0.6833\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5941 - acc: 0.7204 - val_loss: 0.5683 - val_acc: 0.6833\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6029 - acc: 0.7148 - val_loss: 0.5683 - val_acc: 0.6833\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.56697 to 0.56485, saving model to best.model\n",
      "0s - loss: 0.5941 - acc: 0.7019 - val_loss: 0.5649 - val_acc: 0.6833\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.56485 to 0.56237, saving model to best.model\n",
      "0s - loss: 0.6196 - acc: 0.6593 - val_loss: 0.5624 - val_acc: 0.6833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.56237 to 0.55953, saving model to best.model\n",
      "0s - loss: 0.5803 - acc: 0.6778 - val_loss: 0.5595 - val_acc: 0.7000\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.55953 to 0.55410, saving model to best.model\n",
      "0s - loss: 0.5747 - acc: 0.6796 - val_loss: 0.5541 - val_acc: 0.7167\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.55410 to 0.54791, saving model to best.model\n",
      "0s - loss: 0.5786 - acc: 0.6981 - val_loss: 0.5479 - val_acc: 0.7000\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.54791 to 0.54411, saving model to best.model\n",
      "0s - loss: 0.5978 - acc: 0.7111 - val_loss: 0.5441 - val_acc: 0.7000\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.54411 to 0.54135, saving model to best.model\n",
      "0s - loss: 0.5564 - acc: 0.7241 - val_loss: 0.5413 - val_acc: 0.7000\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.54135 to 0.53981, saving model to best.model\n",
      "0s - loss: 0.5642 - acc: 0.7148 - val_loss: 0.5398 - val_acc: 0.7000\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.53981 to 0.53826, saving model to best.model\n",
      "0s - loss: 0.5463 - acc: 0.7241 - val_loss: 0.5383 - val_acc: 0.7000\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.53826 to 0.53663, saving model to best.model\n",
      "0s - loss: 0.5796 - acc: 0.7148 - val_loss: 0.5366 - val_acc: 0.7000\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.53663 to 0.53538, saving model to best.model\n",
      "0s - loss: 0.5728 - acc: 0.7352 - val_loss: 0.5354 - val_acc: 0.7000\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5446 - acc: 0.7204 - val_loss: 0.5362 - val_acc: 0.7167\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.53538 to 0.53475, saving model to best.model\n",
      "0s - loss: 0.5554 - acc: 0.7167 - val_loss: 0.5348 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.53475 to 0.53143, saving model to best.model\n",
      "0s - loss: 0.5639 - acc: 0.7259 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.53143 to 0.52738, saving model to best.model\n",
      "0s - loss: 0.5289 - acc: 0.7389 - val_loss: 0.5274 - val_acc: 0.7500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.52738 to 0.52568, saving model to best.model\n",
      "0s - loss: 0.5266 - acc: 0.7315 - val_loss: 0.5257 - val_acc: 0.7500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.52568 to 0.52519, saving model to best.model\n",
      "0s - loss: 0.5586 - acc: 0.7130 - val_loss: 0.5252 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5194 - acc: 0.7389 - val_loss: 0.5255 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.52519 to 0.52420, saving model to best.model\n",
      "0s - loss: 0.5235 - acc: 0.7407 - val_loss: 0.5242 - val_acc: 0.7667\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.52420 to 0.52220, saving model to best.model\n",
      "0s - loss: 0.5188 - acc: 0.7611 - val_loss: 0.5222 - val_acc: 0.7667\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.52220 to 0.52070, saving model to best.model\n",
      "0s - loss: 0.5128 - acc: 0.7759 - val_loss: 0.5207 - val_acc: 0.7667\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.52070 to 0.51972, saving model to best.model\n",
      "0s - loss: 0.5385 - acc: 0.7333 - val_loss: 0.5197 - val_acc: 0.7833\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.51972 to 0.51856, saving model to best.model\n",
      "0s - loss: 0.5272 - acc: 0.7241 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.51856 to 0.51659, saving model to best.model\n",
      "0s - loss: 0.5110 - acc: 0.7630 - val_loss: 0.5166 - val_acc: 0.7333\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.51659 to 0.51475, saving model to best.model\n",
      "0s - loss: 0.5102 - acc: 0.7222 - val_loss: 0.5148 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.51475 to 0.51370, saving model to best.model\n",
      "0s - loss: 0.5181 - acc: 0.7556 - val_loss: 0.5137 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.51370 to 0.51303, saving model to best.model\n",
      "0s - loss: 0.5145 - acc: 0.7741 - val_loss: 0.5130 - val_acc: 0.7667\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 0.5021 - acc: 0.7537 - val_loss: 0.5143 - val_acc: 0.7833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 0.5117 - acc: 0.7611 - val_loss: 0.5151 - val_acc: 0.7667\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 0.5223 - acc: 0.7537 - val_loss: 0.5153 - val_acc: 0.7500\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 0.4987 - acc: 0.7667 - val_loss: 0.5149 - val_acc: 0.7333\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.51303 to 0.51245, saving model to best.model\n",
      "0s - loss: 0.4877 - acc: 0.7648 - val_loss: 0.5124 - val_acc: 0.7333\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.51245 to 0.51034, saving model to best.model\n",
      "0s - loss: 0.4827 - acc: 0.7593 - val_loss: 0.5103 - val_acc: 0.7333\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.51034 to 0.50766, saving model to best.model\n",
      "0s - loss: 0.4902 - acc: 0.7574 - val_loss: 0.5077 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss improved from 0.50766 to 0.50488, saving model to best.model\n",
      "0s - loss: 0.4860 - acc: 0.7852 - val_loss: 0.5049 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss improved from 0.50488 to 0.50205, saving model to best.model\n",
      "0s - loss: 0.4905 - acc: 0.7463 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss improved from 0.50205 to 0.49988, saving model to best.model\n",
      "0s - loss: 0.5010 - acc: 0.7611 - val_loss: 0.4999 - val_acc: 0.7500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.49988 to 0.49828, saving model to best.model\n",
      "0s - loss: 0.4639 - acc: 0.7889 - val_loss: 0.4983 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.49828 to 0.49709, saving model to best.model\n",
      "0s - loss: 0.4631 - acc: 0.7741 - val_loss: 0.4971 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 0.4811 - acc: 0.7889 - val_loss: 0.4972 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4594 - acc: 0.7907 - val_loss: 0.4983 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 0.5049 - acc: 0.7833 - val_loss: 0.4999 - val_acc: 0.7333\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 0.4790 - acc: 0.7611 - val_loss: 0.5004 - val_acc: 0.7333\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 0.4921 - acc: 0.7815 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 0.5114 - acc: 0.7630 - val_loss: 0.5012 - val_acc: 0.7667\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 0.4562 - acc: 0.7926 - val_loss: 0.5006 - val_acc: 0.7833\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 0.4600 - acc: 0.7963 - val_loss: 0.4991 - val_acc: 0.7667\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.49709 to 0.49703, saving model to best.model\n",
      "0s - loss: 0.4669 - acc: 0.7704 - val_loss: 0.4970 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.49703 to 0.49621, saving model to best.model\n",
      "0s - loss: 0.4714 - acc: 0.7907 - val_loss: 0.4962 - val_acc: 0.7500\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.49621 to 0.49582, saving model to best.model\n",
      "0s - loss: 0.4587 - acc: 0.7815 - val_loss: 0.4958 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4768 - acc: 0.7833 - val_loss: 0.4959 - val_acc: 0.7333\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4491 - acc: 0.7889 - val_loss: 0.4958 - val_acc: 0.7333\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss improved from 0.49582 to 0.49549, saving model to best.model\n",
      "0s - loss: 0.4746 - acc: 0.7852 - val_loss: 0.4955 - val_acc: 0.7333\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4675 - acc: 0.7833 - val_loss: 0.4957 - val_acc: 0.7333\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss improved from 0.49549 to 0.49469, saving model to best.model\n",
      "0s - loss: 0.4520 - acc: 0.8111 - val_loss: 0.4947 - val_acc: 0.7167\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss improved from 0.49469 to 0.48964, saving model to best.model\n",
      "0s - loss: 0.4437 - acc: 0.7889 - val_loss: 0.4896 - val_acc: 0.7333\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.48964 to 0.48501, saving model to best.model\n",
      "0s - loss: 0.4582 - acc: 0.8000 - val_loss: 0.4850 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.48501 to 0.48298, saving model to best.model\n",
      "0s - loss: 0.4390 - acc: 0.8037 - val_loss: 0.4830 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.48298 to 0.48220, saving model to best.model\n",
      "0s - loss: 0.4515 - acc: 0.7852 - val_loss: 0.4822 - val_acc: 0.7667\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 0.4496 - acc: 0.7870 - val_loss: 0.4827 - val_acc: 0.7667\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 0.4518 - acc: 0.8019 - val_loss: 0.4831 - val_acc: 0.7667\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4340 - acc: 0.8074 - val_loss: 0.4841 - val_acc: 0.7667\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4442 - acc: 0.7889 - val_loss: 0.4852 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 0.4508 - acc: 0.8056 - val_loss: 0.4860 - val_acc: 0.7500\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 0.4492 - acc: 0.7870 - val_loss: 0.4847 - val_acc: 0.7500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.48220 to 0.48210, saving model to best.model\n",
      "0s - loss: 0.4576 - acc: 0.8056 - val_loss: 0.4821 - val_acc: 0.7667\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.48210 to 0.48075, saving model to best.model\n",
      "0s - loss: 0.4478 - acc: 0.7870 - val_loss: 0.4808 - val_acc: 0.7667\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 0.4183 - acc: 0.8056 - val_loss: 0.4816 - val_acc: 0.7167\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 0.4450 - acc: 0.8000 - val_loss: 0.4828 - val_acc: 0.7333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 0.4378 - acc: 0.8074 - val_loss: 0.4822 - val_acc: 0.7333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.48075 to 0.47903, saving model to best.model\n",
      "0s - loss: 0.4392 - acc: 0.8130 - val_loss: 0.4790 - val_acc: 0.7333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.47903 to 0.47518, saving model to best.model\n",
      "0s - loss: 0.4455 - acc: 0.8185 - val_loss: 0.4752 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.47518 to 0.47296, saving model to best.model\n",
      "0s - loss: 0.4120 - acc: 0.8167 - val_loss: 0.4730 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss improved from 0.47296 to 0.47275, saving model to best.model\n",
      "0s - loss: 0.4353 - acc: 0.8148 - val_loss: 0.4727 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss improved from 0.47275 to 0.47219, saving model to best.model\n",
      "0s - loss: 0.4242 - acc: 0.8074 - val_loss: 0.4722 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss improved from 0.47219 to 0.47097, saving model to best.model\n",
      "0s - loss: 0.4267 - acc: 0.8111 - val_loss: 0.4710 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss improved from 0.47097 to 0.47005, saving model to best.model\n",
      "0s - loss: 0.4138 - acc: 0.8000 - val_loss: 0.4700 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 0.4088 - acc: 0.8259 - val_loss: 0.4704 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 0.4150 - acc: 0.8296 - val_loss: 0.4708 - val_acc: 0.7667\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.47005 to 0.46915, saving model to best.model\n",
      "0s - loss: 0.4196 - acc: 0.8130 - val_loss: 0.4691 - val_acc: 0.7333\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4297 - acc: 0.8185 - val_loss: 0.4699 - val_acc: 0.7667\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.4316 - acc: 0.8296 - val_loss: 0.4722 - val_acc: 0.7667\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 0.4305 - acc: 0.8093 - val_loss: 0.4701 - val_acc: 0.7667\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss improved from 0.46915 to 0.46742, saving model to best.model\n",
      "0s - loss: 0.4090 - acc: 0.8148 - val_loss: 0.4674 - val_acc: 0.7500\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss improved from 0.46742 to 0.46506, saving model to best.model\n",
      "0s - loss: 0.4267 - acc: 0.8111 - val_loss: 0.4651 - val_acc: 0.7500\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss improved from 0.46506 to 0.46325, saving model to best.model\n",
      "0s - loss: 0.4136 - acc: 0.8111 - val_loss: 0.4632 - val_acc: 0.7500\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss improved from 0.46325 to 0.46296, saving model to best.model\n",
      "0s - loss: 0.4186 - acc: 0.8093 - val_loss: 0.4630 - val_acc: 0.7500\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4245 - acc: 0.8222 - val_loss: 0.4634 - val_acc: 0.7500\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 0.4016 - acc: 0.8333 - val_loss: 0.4643 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 0.4079 - acc: 0.8333 - val_loss: 0.4637 - val_acc: 0.7833\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.46296 to 0.46267, saving model to best.model\n",
      "0s - loss: 0.4159 - acc: 0.8185 - val_loss: 0.4627 - val_acc: 0.7833\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.46267 to 0.46248, saving model to best.model\n",
      "0s - loss: 0.3874 - acc: 0.8333 - val_loss: 0.4625 - val_acc: 0.7833\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 0.4082 - acc: 0.8222 - val_loss: 0.4636 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 0.4044 - acc: 0.8241 - val_loss: 0.4655 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 0.4245 - acc: 0.8259 - val_loss: 0.4681 - val_acc: 0.7833\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 0.4000 - acc: 0.8426 - val_loss: 0.4698 - val_acc: 0.7833\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 0.3884 - acc: 0.8389 - val_loss: 0.4701 - val_acc: 0.7833\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 0.4022 - acc: 0.8259 - val_loss: 0.4671 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3801 - acc: 0.8500 - val_loss: 0.4647 - val_acc: 0.7500\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.3894 - acc: 0.8481 - val_loss: 0.4643 - val_acc: 0.7500\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 0.3838 - acc: 0.8296 - val_loss: 0.4683 - val_acc: 0.7500\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.3807 - acc: 0.8407 - val_loss: 0.4726 - val_acc: 0.7500\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 0.3962 - acc: 0.8278 - val_loss: 0.4750 - val_acc: 0.7500\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 0.3965 - acc: 0.8315 - val_loss: 0.4758 - val_acc: 0.7333\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3800 - acc: 0.8370 - val_loss: 0.4783 - val_acc: 0.7333\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3992 - acc: 0.8278 - val_loss: 0.4791 - val_acc: 0.7500\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3755 - acc: 0.8259 - val_loss: 0.4776 - val_acc: 0.7500\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3949 - acc: 0.8407 - val_loss: 0.4776 - val_acc: 0.7500\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3829 - acc: 0.8407 - val_loss: 0.4772 - val_acc: 0.7500\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3720 - acc: 0.8463 - val_loss: 0.4759 - val_acc: 0.7500\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 0.3602 - acc: 0.8426 - val_loss: 0.4737 - val_acc: 0.7500\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.3601 - acc: 0.8389 - val_loss: 0.4722 - val_acc: 0.7667\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 0.3747 - acc: 0.8500 - val_loss: 0.4709 - val_acc: 0.7667\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 0.3729 - acc: 0.8426 - val_loss: 0.4678 - val_acc: 0.7667\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3672 - acc: 0.8574 - val_loss: 0.4637 - val_acc: 0.7500\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.46248 to 0.45819, saving model to best.model\n",
      "0s - loss: 0.3577 - acc: 0.8537 - val_loss: 0.4582 - val_acc: 0.7667\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.45819 to 0.45572, saving model to best.model\n",
      "0s - loss: 0.3546 - acc: 0.8556 - val_loss: 0.4557 - val_acc: 0.8000\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.45572 to 0.45567, saving model to best.model\n",
      "0s - loss: 0.3684 - acc: 0.8389 - val_loss: 0.4557 - val_acc: 0.8000\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 0.3461 - acc: 0.8556 - val_loss: 0.4576 - val_acc: 0.7667\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 0.3794 - acc: 0.8370 - val_loss: 0.4605 - val_acc: 0.7833\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 0.3728 - acc: 0.8370 - val_loss: 0.4654 - val_acc: 0.8000\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3321 - acc: 0.8685 - val_loss: 0.4696 - val_acc: 0.8000\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3538 - acc: 0.8574 - val_loss: 0.4719 - val_acc: 0.8000\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 0.3570 - acc: 0.8500 - val_loss: 0.4733 - val_acc: 0.8000\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 0.3483 - acc: 0.8593 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3416 - acc: 0.8630 - val_loss: 0.4784 - val_acc: 0.7833\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3512 - acc: 0.8574 - val_loss: 0.4786 - val_acc: 0.7667\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3378 - acc: 0.8667 - val_loss: 0.4751 - val_acc: 0.7833\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 0.3497 - acc: 0.8426 - val_loss: 0.4691 - val_acc: 0.7833\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 0.3256 - acc: 0.8593 - val_loss: 0.4656 - val_acc: 0.7833\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 0.3343 - acc: 0.8593 - val_loss: 0.4651 - val_acc: 0.7833\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.3410 - acc: 0.8593 - val_loss: 0.4678 - val_acc: 0.7833\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3402 - acc: 0.8704 - val_loss: 0.4739 - val_acc: 0.7833\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 0.3557 - acc: 0.8500 - val_loss: 0.4794 - val_acc: 0.7833\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 0.3311 - acc: 0.8630 - val_loss: 0.4754 - val_acc: 0.7833\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 0.3455 - acc: 0.8778 - val_loss: 0.4692 - val_acc: 0.7667\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 0.3047 - acc: 0.8796 - val_loss: 0.4679 - val_acc: 0.7833\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 0.3228 - acc: 0.8593 - val_loss: 0.4724 - val_acc: 0.8000\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 0.3378 - acc: 0.8611 - val_loss: 0.4784 - val_acc: 0.7833\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 0.3237 - acc: 0.8833 - val_loss: 0.4845 - val_acc: 0.7833\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3644 - acc: 0.8500 - val_loss: 0.4885 - val_acc: 0.8000\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.3035 - acc: 0.8759 - val_loss: 0.4959 - val_acc: 0.8000\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 0.3103 - acc: 0.8796 - val_loss: 0.4996 - val_acc: 0.8000\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 0.3362 - acc: 0.8667 - val_loss: 0.4997 - val_acc: 0.8000\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.62254, saving model to best.model\n",
      "0s - loss: 0.8951 - acc: 0.4370 - val_loss: 0.6225 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.62254 to 0.61785, saving model to best.model\n",
      "0s - loss: 0.6703 - acc: 0.6444 - val_loss: 0.6179 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss did not improve\n",
      "0s - loss: 0.6653 - acc: 0.6759 - val_loss: 0.6182 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss improved from 0.61785 to 0.60880, saving model to best.model\n",
      "0s - loss: 0.6393 - acc: 0.7093 - val_loss: 0.6088 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss improved from 0.60880 to 0.59873, saving model to best.model\n",
      "0s - loss: 0.6391 - acc: 0.7130 - val_loss: 0.5987 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss improved from 0.59873 to 0.59295, saving model to best.model\n",
      "0s - loss: 0.6647 - acc: 0.6926 - val_loss: 0.5929 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss improved from 0.59295 to 0.59008, saving model to best.model\n",
      "0s - loss: 0.5802 - acc: 0.7093 - val_loss: 0.5901 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss improved from 0.59008 to 0.58807, saving model to best.model\n",
      "0s - loss: 0.5985 - acc: 0.7074 - val_loss: 0.5881 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss improved from 0.58807 to 0.58634, saving model to best.model\n",
      "0s - loss: 0.6112 - acc: 0.6926 - val_loss: 0.5863 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss improved from 0.58634 to 0.58460, saving model to best.model\n",
      "0s - loss: 0.5769 - acc: 0.7037 - val_loss: 0.5846 - val_acc: 0.6833\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss improved from 0.58460 to 0.58320, saving model to best.model\n",
      "0s - loss: 0.6100 - acc: 0.7167 - val_loss: 0.5832 - val_acc: 0.6833\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss improved from 0.58320 to 0.58220, saving model to best.model\n",
      "0s - loss: 0.5764 - acc: 0.7111 - val_loss: 0.5822 - val_acc: 0.6833\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss improved from 0.58220 to 0.58167, saving model to best.model\n",
      "0s - loss: 0.6025 - acc: 0.7074 - val_loss: 0.5817 - val_acc: 0.6833\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss improved from 0.58167 to 0.58037, saving model to best.model\n",
      "0s - loss: 0.5612 - acc: 0.7185 - val_loss: 0.5804 - val_acc: 0.6833\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss improved from 0.58037 to 0.57864, saving model to best.model\n",
      "0s - loss: 0.5857 - acc: 0.7148 - val_loss: 0.5786 - val_acc: 0.6833\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss improved from 0.57864 to 0.57679, saving model to best.model\n",
      "0s - loss: 0.5717 - acc: 0.7056 - val_loss: 0.5768 - val_acc: 0.6833\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss improved from 0.57679 to 0.57436, saving model to best.model\n",
      "0s - loss: 0.5501 - acc: 0.7352 - val_loss: 0.5744 - val_acc: 0.6833\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss improved from 0.57436 to 0.57189, saving model to best.model\n",
      "0s - loss: 0.5755 - acc: 0.7093 - val_loss: 0.5719 - val_acc: 0.6833\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss improved from 0.57189 to 0.57051, saving model to best.model\n",
      "0s - loss: 0.5743 - acc: 0.7148 - val_loss: 0.5705 - val_acc: 0.6833\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss improved from 0.57051 to 0.56896, saving model to best.model\n",
      "0s - loss: 0.5301 - acc: 0.7463 - val_loss: 0.5690 - val_acc: 0.6833\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss improved from 0.56896 to 0.56710, saving model to best.model\n",
      "0s - loss: 0.5359 - acc: 0.7352 - val_loss: 0.5671 - val_acc: 0.6833\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss improved from 0.56710 to 0.56374, saving model to best.model\n",
      "0s - loss: 0.5723 - acc: 0.7167 - val_loss: 0.5637 - val_acc: 0.7000\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss improved from 0.56374 to 0.56008, saving model to best.model\n",
      "0s - loss: 0.5372 - acc: 0.7296 - val_loss: 0.5601 - val_acc: 0.7167\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss improved from 0.56008 to 0.55691, saving model to best.model\n",
      "0s - loss: 0.5355 - acc: 0.7370 - val_loss: 0.5569 - val_acc: 0.7167\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss improved from 0.55691 to 0.55434, saving model to best.model\n",
      "0s - loss: 0.5273 - acc: 0.7333 - val_loss: 0.5543 - val_acc: 0.7167\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss improved from 0.55434 to 0.55256, saving model to best.model\n",
      "0s - loss: 0.5312 - acc: 0.7370 - val_loss: 0.5526 - val_acc: 0.7167\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss improved from 0.55256 to 0.55152, saving model to best.model\n",
      "0s - loss: 0.5598 - acc: 0.7148 - val_loss: 0.5515 - val_acc: 0.7167\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss improved from 0.55152 to 0.55124, saving model to best.model\n",
      "0s - loss: 0.5282 - acc: 0.7352 - val_loss: 0.5512 - val_acc: 0.7167\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss improved from 0.55124 to 0.55098, saving model to best.model\n",
      "0s - loss: 0.5293 - acc: 0.7426 - val_loss: 0.5510 - val_acc: 0.7167\n",
      "Epoch 30/200\n",
      "Epoch 00029: val_loss improved from 0.55098 to 0.55094, saving model to best.model\n",
      "0s - loss: 0.5126 - acc: 0.7500 - val_loss: 0.5509 - val_acc: 0.7167\n",
      "Epoch 31/200\n",
      "Epoch 00030: val_loss improved from 0.55094 to 0.55043, saving model to best.model\n",
      "0s - loss: 0.5311 - acc: 0.7296 - val_loss: 0.5504 - val_acc: 0.7167\n",
      "Epoch 32/200\n",
      "Epoch 00031: val_loss improved from 0.55043 to 0.54914, saving model to best.model\n",
      "0s - loss: 0.5257 - acc: 0.7278 - val_loss: 0.5491 - val_acc: 0.7167\n",
      "Epoch 33/200\n",
      "Epoch 00032: val_loss improved from 0.54914 to 0.54661, saving model to best.model\n",
      "0s - loss: 0.5125 - acc: 0.7315 - val_loss: 0.5466 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "Epoch 00033: val_loss improved from 0.54661 to 0.54469, saving model to best.model\n",
      "0s - loss: 0.5457 - acc: 0.7148 - val_loss: 0.5447 - val_acc: 0.6833\n",
      "Epoch 35/200\n",
      "Epoch 00034: val_loss improved from 0.54469 to 0.54321, saving model to best.model\n",
      "0s - loss: 0.5221 - acc: 0.7296 - val_loss: 0.5432 - val_acc: 0.6833\n",
      "Epoch 36/200\n",
      "Epoch 00035: val_loss improved from 0.54321 to 0.54201, saving model to best.model\n",
      "0s - loss: 0.5231 - acc: 0.7481 - val_loss: 0.5420 - val_acc: 0.6833\n",
      "Epoch 37/200\n",
      "Epoch 00036: val_loss improved from 0.54201 to 0.54045, saving model to best.model\n",
      "0s - loss: 0.5066 - acc: 0.7463 - val_loss: 0.5405 - val_acc: 0.6833\n",
      "Epoch 38/200\n",
      "Epoch 00037: val_loss improved from 0.54045 to 0.53843, saving model to best.model\n",
      "0s - loss: 0.4991 - acc: 0.7333 - val_loss: 0.5384 - val_acc: 0.6833\n",
      "Epoch 39/200\n",
      "Epoch 00038: val_loss improved from 0.53843 to 0.53639, saving model to best.model\n",
      "0s - loss: 0.5151 - acc: 0.7463 - val_loss: 0.5364 - val_acc: 0.6833\n",
      "Epoch 40/200\n",
      "Epoch 00039: val_loss improved from 0.53639 to 0.53507, saving model to best.model\n",
      "0s - loss: 0.5225 - acc: 0.7352 - val_loss: 0.5351 - val_acc: 0.6667\n",
      "Epoch 41/200\n",
      "Epoch 00040: val_loss improved from 0.53507 to 0.53465, saving model to best.model\n",
      "0s - loss: 0.4948 - acc: 0.7537 - val_loss: 0.5347 - val_acc: 0.6667\n",
      "Epoch 42/200\n",
      "Epoch 00041: val_loss improved from 0.53465 to 0.53403, saving model to best.model\n",
      "0s - loss: 0.5091 - acc: 0.7519 - val_loss: 0.5340 - val_acc: 0.6500\n",
      "Epoch 43/200\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 0.4753 - acc: 0.7685 - val_loss: 0.5346 - val_acc: 0.6500\n",
      "Epoch 44/200\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 0.4937 - acc: 0.7593 - val_loss: 0.5358 - val_acc: 0.6500\n",
      "Epoch 45/200\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 0.4963 - acc: 0.7574 - val_loss: 0.5356 - val_acc: 0.6500\n",
      "Epoch 46/200\n",
      "Epoch 00045: val_loss improved from 0.53403 to 0.53377, saving model to best.model\n",
      "0s - loss: 0.4928 - acc: 0.7648 - val_loss: 0.5338 - val_acc: 0.6500\n",
      "Epoch 47/200\n",
      "Epoch 00046: val_loss improved from 0.53377 to 0.53261, saving model to best.model\n",
      "0s - loss: 0.4790 - acc: 0.7685 - val_loss: 0.5326 - val_acc: 0.6500\n",
      "Epoch 48/200\n",
      "Epoch 00047: val_loss improved from 0.53261 to 0.53252, saving model to best.model\n",
      "0s - loss: 0.4834 - acc: 0.7704 - val_loss: 0.5325 - val_acc: 0.6500\n",
      "Epoch 49/200\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 0.4837 - acc: 0.7685 - val_loss: 0.5326 - val_acc: 0.6500\n",
      "Epoch 50/200\n",
      "Epoch 00049: val_loss improved from 0.53252 to 0.53143, saving model to best.model\n",
      "0s - loss: 0.4881 - acc: 0.7481 - val_loss: 0.5314 - val_acc: 0.6833\n",
      "Epoch 51/200\n",
      "Epoch 00050: val_loss improved from 0.53143 to 0.52864, saving model to best.model\n",
      "0s - loss: 0.4897 - acc: 0.7741 - val_loss: 0.5286 - val_acc: 0.7000\n",
      "Epoch 52/200\n",
      "Epoch 00051: val_loss improved from 0.52864 to 0.52730, saving model to best.model\n",
      "0s - loss: 0.4919 - acc: 0.7519 - val_loss: 0.5273 - val_acc: 0.7333\n",
      "Epoch 53/200\n",
      "Epoch 00052: val_loss improved from 0.52730 to 0.52617, saving model to best.model\n",
      "0s - loss: 0.4639 - acc: 0.7648 - val_loss: 0.5262 - val_acc: 0.7333\n",
      "Epoch 54/200\n",
      "Epoch 00053: val_loss improved from 0.52617 to 0.52306, saving model to best.model\n",
      "0s - loss: 0.4611 - acc: 0.7741 - val_loss: 0.5231 - val_acc: 0.7333\n",
      "Epoch 55/200\n",
      "Epoch 00054: val_loss improved from 0.52306 to 0.52115, saving model to best.model\n",
      "0s - loss: 0.4828 - acc: 0.7519 - val_loss: 0.5212 - val_acc: 0.7333\n",
      "Epoch 56/200\n",
      "Epoch 00055: val_loss improved from 0.52115 to 0.52012, saving model to best.model\n",
      "0s - loss: 0.4857 - acc: 0.7574 - val_loss: 0.5201 - val_acc: 0.7667\n",
      "Epoch 57/200\n",
      "Epoch 00056: val_loss improved from 0.52012 to 0.51993, saving model to best.model\n",
      "0s - loss: 0.4695 - acc: 0.7537 - val_loss: 0.5199 - val_acc: 0.7667\n",
      "Epoch 58/200\n",
      "Epoch 00057: val_loss improved from 0.51993 to 0.51937, saving model to best.model\n",
      "0s - loss: 0.4617 - acc: 0.7796 - val_loss: 0.5194 - val_acc: 0.7667\n",
      "Epoch 59/200\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 0.4550 - acc: 0.7852 - val_loss: 0.5197 - val_acc: 0.7667\n",
      "Epoch 60/200\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 0.4622 - acc: 0.7741 - val_loss: 0.5200 - val_acc: 0.7500\n",
      "Epoch 61/200\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 0.4543 - acc: 0.7704 - val_loss: 0.5216 - val_acc: 0.7833\n",
      "Epoch 62/200\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 0.4711 - acc: 0.7704 - val_loss: 0.5230 - val_acc: 0.7833\n",
      "Epoch 63/200\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 0.4635 - acc: 0.7778 - val_loss: 0.5221 - val_acc: 0.7833\n",
      "Epoch 64/200\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 0.4468 - acc: 0.7944 - val_loss: 0.5201 - val_acc: 0.7667\n",
      "Epoch 65/200\n",
      "Epoch 00064: val_loss improved from 0.51937 to 0.51521, saving model to best.model\n",
      "0s - loss: 0.4866 - acc: 0.7630 - val_loss: 0.5152 - val_acc: 0.7667\n",
      "Epoch 66/200\n",
      "Epoch 00065: val_loss improved from 0.51521 to 0.51278, saving model to best.model\n",
      "0s - loss: 0.4539 - acc: 0.7815 - val_loss: 0.5128 - val_acc: 0.7500\n",
      "Epoch 67/200\n",
      "Epoch 00066: val_loss improved from 0.51278 to 0.51172, saving model to best.model\n",
      "0s - loss: 0.4455 - acc: 0.7704 - val_loss: 0.5117 - val_acc: 0.7167\n",
      "Epoch 68/200\n",
      "Epoch 00067: val_loss improved from 0.51172 to 0.51046, saving model to best.model\n",
      "0s - loss: 0.4579 - acc: 0.7796 - val_loss: 0.5105 - val_acc: 0.7167\n",
      "Epoch 69/200\n",
      "Epoch 00068: val_loss improved from 0.51046 to 0.50985, saving model to best.model\n",
      "0s - loss: 0.4538 - acc: 0.7944 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 70/200\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 0.4360 - acc: 0.7815 - val_loss: 0.5115 - val_acc: 0.7500\n",
      "Epoch 71/200\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 0.4574 - acc: 0.7852 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 72/200\n",
      "Epoch 00071: val_loss improved from 0.50985 to 0.50802, saving model to best.model\n",
      "0s - loss: 0.4491 - acc: 0.7907 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 73/200\n",
      "Epoch 00072: val_loss improved from 0.50802 to 0.50649, saving model to best.model\n",
      "0s - loss: 0.4601 - acc: 0.7963 - val_loss: 0.5065 - val_acc: 0.7500\n",
      "Epoch 74/200\n",
      "Epoch 00073: val_loss improved from 0.50649 to 0.50476, saving model to best.model\n",
      "0s - loss: 0.4615 - acc: 0.7907 - val_loss: 0.5048 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "Epoch 00074: val_loss improved from 0.50476 to 0.50275, saving model to best.model\n",
      "0s - loss: 0.4518 - acc: 0.7759 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 76/200\n",
      "Epoch 00075: val_loss improved from 0.50275 to 0.49928, saving model to best.model\n",
      "0s - loss: 0.4475 - acc: 0.7741 - val_loss: 0.4993 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      "Epoch 00076: val_loss improved from 0.49928 to 0.49616, saving model to best.model\n",
      "0s - loss: 0.4442 - acc: 0.8037 - val_loss: 0.4962 - val_acc: 0.7333\n",
      "Epoch 78/200\n",
      "Epoch 00077: val_loss improved from 0.49616 to 0.49407, saving model to best.model\n",
      "0s - loss: 0.4543 - acc: 0.7796 - val_loss: 0.4941 - val_acc: 0.7333\n",
      "Epoch 79/200\n",
      "Epoch 00078: val_loss improved from 0.49407 to 0.49201, saving model to best.model\n",
      "0s - loss: 0.4285 - acc: 0.7981 - val_loss: 0.4920 - val_acc: 0.7333\n",
      "Epoch 80/200\n",
      "Epoch 00079: val_loss improved from 0.49201 to 0.49005, saving model to best.model\n",
      "0s - loss: 0.4153 - acc: 0.8000 - val_loss: 0.4900 - val_acc: 0.7333\n",
      "Epoch 81/200\n",
      "Epoch 00080: val_loss improved from 0.49005 to 0.48990, saving model to best.model\n",
      "0s - loss: 0.4273 - acc: 0.7963 - val_loss: 0.4899 - val_acc: 0.7500\n",
      "Epoch 82/200\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 0.4203 - acc: 0.8000 - val_loss: 0.4936 - val_acc: 0.7833\n",
      "Epoch 83/200\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 0.4341 - acc: 0.7889 - val_loss: 0.4986 - val_acc: 0.7667\n",
      "Epoch 84/200\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 0.4267 - acc: 0.7926 - val_loss: 0.5008 - val_acc: 0.7833\n",
      "Epoch 85/200\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 0.4581 - acc: 0.7870 - val_loss: 0.4976 - val_acc: 0.7833\n",
      "Epoch 86/200\n",
      "Epoch 00085: val_loss improved from 0.48990 to 0.48909, saving model to best.model\n",
      "0s - loss: 0.4239 - acc: 0.8037 - val_loss: 0.4891 - val_acc: 0.7667\n",
      "Epoch 87/200\n",
      "Epoch 00086: val_loss improved from 0.48909 to 0.48248, saving model to best.model\n",
      "0s - loss: 0.4208 - acc: 0.7981 - val_loss: 0.4825 - val_acc: 0.7500\n",
      "Epoch 88/200\n",
      "Epoch 00087: val_loss improved from 0.48248 to 0.48051, saving model to best.model\n",
      "0s - loss: 0.4307 - acc: 0.8130 - val_loss: 0.4805 - val_acc: 0.7500\n",
      "Epoch 89/200\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 0.4300 - acc: 0.7944 - val_loss: 0.4806 - val_acc: 0.7500\n",
      "Epoch 90/200\n",
      "Epoch 00089: val_loss improved from 0.48051 to 0.48003, saving model to best.model\n",
      "0s - loss: 0.4235 - acc: 0.8037 - val_loss: 0.4800 - val_acc: 0.7500\n",
      "Epoch 91/200\n",
      "Epoch 00090: val_loss improved from 0.48003 to 0.47864, saving model to best.model\n",
      "0s - loss: 0.4199 - acc: 0.8000 - val_loss: 0.4786 - val_acc: 0.7500\n",
      "Epoch 92/200\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 0.4165 - acc: 0.8074 - val_loss: 0.4795 - val_acc: 0.7500\n",
      "Epoch 93/200\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 0.4067 - acc: 0.8074 - val_loss: 0.4820 - val_acc: 0.7833\n",
      "Epoch 94/200\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 0.4151 - acc: 0.8093 - val_loss: 0.4837 - val_acc: 0.8000\n",
      "Epoch 95/200\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 0.4252 - acc: 0.8093 - val_loss: 0.4838 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 0.4192 - acc: 0.8130 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 97/200\n",
      "Epoch 00096: val_loss improved from 0.47864 to 0.47414, saving model to best.model\n",
      "0s - loss: 0.4303 - acc: 0.8056 - val_loss: 0.4741 - val_acc: 0.7667\n",
      "Epoch 98/200\n",
      "Epoch 00097: val_loss improved from 0.47414 to 0.47110, saving model to best.model\n",
      "0s - loss: 0.4240 - acc: 0.8130 - val_loss: 0.4711 - val_acc: 0.7667\n",
      "Epoch 99/200\n",
      "Epoch 00098: val_loss improved from 0.47110 to 0.46958, saving model to best.model\n",
      "0s - loss: 0.3849 - acc: 0.8111 - val_loss: 0.4696 - val_acc: 0.7667\n",
      "Epoch 100/200\n",
      "Epoch 00099: val_loss improved from 0.46958 to 0.46768, saving model to best.model\n",
      "0s - loss: 0.4049 - acc: 0.8019 - val_loss: 0.4677 - val_acc: 0.7667\n",
      "Epoch 101/200\n",
      "Epoch 00100: val_loss improved from 0.46768 to 0.46515, saving model to best.model\n",
      "0s - loss: 0.4154 - acc: 0.8204 - val_loss: 0.4652 - val_acc: 0.7667\n",
      "Epoch 102/200\n",
      "Epoch 00101: val_loss improved from 0.46515 to 0.46297, saving model to best.model\n",
      "0s - loss: 0.3845 - acc: 0.8315 - val_loss: 0.4630 - val_acc: 0.7667\n",
      "Epoch 103/200\n",
      "Epoch 00102: val_loss improved from 0.46297 to 0.46080, saving model to best.model\n",
      "0s - loss: 0.4111 - acc: 0.8370 - val_loss: 0.4608 - val_acc: 0.7667\n",
      "Epoch 104/200\n",
      "Epoch 00103: val_loss improved from 0.46080 to 0.45841, saving model to best.model\n",
      "0s - loss: 0.4207 - acc: 0.8204 - val_loss: 0.4584 - val_acc: 0.7500\n",
      "Epoch 105/200\n",
      "Epoch 00104: val_loss improved from 0.45841 to 0.45616, saving model to best.model\n",
      "0s - loss: 0.3998 - acc: 0.8204 - val_loss: 0.4562 - val_acc: 0.7667\n",
      "Epoch 106/200\n",
      "Epoch 00105: val_loss improved from 0.45616 to 0.45513, saving model to best.model\n",
      "0s - loss: 0.3633 - acc: 0.8630 - val_loss: 0.4551 - val_acc: 0.7833\n",
      "Epoch 107/200\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 0.3981 - acc: 0.8093 - val_loss: 0.4556 - val_acc: 0.7833\n",
      "Epoch 108/200\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 0.4029 - acc: 0.8037 - val_loss: 0.4554 - val_acc: 0.7667\n",
      "Epoch 109/200\n",
      "Epoch 00108: val_loss improved from 0.45513 to 0.45479, saving model to best.model\n",
      "0s - loss: 0.3842 - acc: 0.8204 - val_loss: 0.4548 - val_acc: 0.7667\n",
      "Epoch 110/200\n",
      "Epoch 00109: val_loss improved from 0.45479 to 0.45221, saving model to best.model\n",
      "0s - loss: 0.3759 - acc: 0.8222 - val_loss: 0.4522 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "Epoch 00110: val_loss improved from 0.45221 to 0.44971, saving model to best.model\n",
      "0s - loss: 0.3775 - acc: 0.8259 - val_loss: 0.4497 - val_acc: 0.7833\n",
      "Epoch 112/200\n",
      "Epoch 00111: val_loss improved from 0.44971 to 0.44836, saving model to best.model\n",
      "0s - loss: 0.3951 - acc: 0.8185 - val_loss: 0.4484 - val_acc: 0.7833\n",
      "Epoch 113/200\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 0.3739 - acc: 0.8352 - val_loss: 0.4484 - val_acc: 0.8000\n",
      "Epoch 114/200\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 0.3771 - acc: 0.8333 - val_loss: 0.4501 - val_acc: 0.8333\n",
      "Epoch 115/200\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 0.3759 - acc: 0.8389 - val_loss: 0.4520 - val_acc: 0.8333\n",
      "Epoch 116/200\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 0.3925 - acc: 0.8278 - val_loss: 0.4538 - val_acc: 0.8333\n",
      "Epoch 117/200\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 0.3845 - acc: 0.8296 - val_loss: 0.4523 - val_acc: 0.8333\n",
      "Epoch 118/200\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 0.3761 - acc: 0.8296 - val_loss: 0.4491 - val_acc: 0.8167\n",
      "Epoch 119/200\n",
      "Epoch 00118: val_loss improved from 0.44836 to 0.44529, saving model to best.model\n",
      "0s - loss: 0.3711 - acc: 0.8500 - val_loss: 0.4453 - val_acc: 0.8333\n",
      "Epoch 120/200\n",
      "Epoch 00119: val_loss improved from 0.44529 to 0.44261, saving model to best.model\n",
      "0s - loss: 0.3843 - acc: 0.8222 - val_loss: 0.4426 - val_acc: 0.8333\n",
      "Epoch 121/200\n",
      "Epoch 00120: val_loss improved from 0.44261 to 0.44011, saving model to best.model\n",
      "0s - loss: 0.3774 - acc: 0.8333 - val_loss: 0.4401 - val_acc: 0.8333\n",
      "Epoch 122/200\n",
      "Epoch 00121: val_loss improved from 0.44011 to 0.43906, saving model to best.model\n",
      "0s - loss: 0.3617 - acc: 0.8500 - val_loss: 0.4391 - val_acc: 0.8167\n",
      "Epoch 123/200\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 0.3652 - acc: 0.8259 - val_loss: 0.4392 - val_acc: 0.8167\n",
      "Epoch 124/200\n",
      "Epoch 00123: val_loss improved from 0.43906 to 0.43811, saving model to best.model\n",
      "0s - loss: 0.3637 - acc: 0.8407 - val_loss: 0.4381 - val_acc: 0.8333\n",
      "Epoch 125/200\n",
      "Epoch 00124: val_loss improved from 0.43811 to 0.43706, saving model to best.model\n",
      "0s - loss: 0.3851 - acc: 0.8241 - val_loss: 0.4371 - val_acc: 0.8500\n",
      "Epoch 126/200\n",
      "Epoch 00125: val_loss improved from 0.43706 to 0.43658, saving model to best.model\n",
      "0s - loss: 0.3801 - acc: 0.8481 - val_loss: 0.4366 - val_acc: 0.8500\n",
      "Epoch 127/200\n",
      "Epoch 00126: val_loss improved from 0.43658 to 0.43215, saving model to best.model\n",
      "0s - loss: 0.3580 - acc: 0.8296 - val_loss: 0.4321 - val_acc: 0.8333\n",
      "Epoch 128/200\n",
      "Epoch 00127: val_loss improved from 0.43215 to 0.42555, saving model to best.model\n",
      "0s - loss: 0.3649 - acc: 0.8426 - val_loss: 0.4255 - val_acc: 0.8333\n",
      "Epoch 129/200\n",
      "Epoch 00128: val_loss improved from 0.42555 to 0.42251, saving model to best.model\n",
      "0s - loss: 0.3461 - acc: 0.8537 - val_loss: 0.4225 - val_acc: 0.8333\n",
      "Epoch 130/200\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.3616 - acc: 0.8370 - val_loss: 0.4226 - val_acc: 0.8333\n",
      "Epoch 131/200\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 0.3321 - acc: 0.8574 - val_loss: 0.4231 - val_acc: 0.8333\n",
      "Epoch 132/200\n",
      "Epoch 00131: val_loss improved from 0.42251 to 0.42249, saving model to best.model\n",
      "0s - loss: 0.3367 - acc: 0.8500 - val_loss: 0.4225 - val_acc: 0.8333\n",
      "Epoch 133/200\n",
      "Epoch 00132: val_loss improved from 0.42249 to 0.42188, saving model to best.model\n",
      "0s - loss: 0.3490 - acc: 0.8463 - val_loss: 0.4219 - val_acc: 0.8333\n",
      "Epoch 134/200\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 0.3524 - acc: 0.8500 - val_loss: 0.4226 - val_acc: 0.8500\n",
      "Epoch 135/200\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 0.3520 - acc: 0.8426 - val_loss: 0.4242 - val_acc: 0.8500\n",
      "Epoch 136/200\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 0.3494 - acc: 0.8519 - val_loss: 0.4226 - val_acc: 0.8500\n",
      "Epoch 137/200\n",
      "Epoch 00136: val_loss improved from 0.42188 to 0.42036, saving model to best.model\n",
      "0s - loss: 0.3284 - acc: 0.8648 - val_loss: 0.4204 - val_acc: 0.8500\n",
      "Epoch 138/200\n",
      "Epoch 00137: val_loss improved from 0.42036 to 0.41823, saving model to best.model\n",
      "0s - loss: 0.3196 - acc: 0.8574 - val_loss: 0.4182 - val_acc: 0.8500\n",
      "Epoch 139/200\n",
      "Epoch 00138: val_loss improved from 0.41823 to 0.41277, saving model to best.model\n",
      "0s - loss: 0.3396 - acc: 0.8500 - val_loss: 0.4128 - val_acc: 0.8500\n",
      "Epoch 140/200\n",
      "Epoch 00139: val_loss improved from 0.41277 to 0.41225, saving model to best.model\n",
      "0s - loss: 0.3238 - acc: 0.8574 - val_loss: 0.4122 - val_acc: 0.8500\n",
      "Epoch 141/200\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 0.3361 - acc: 0.8667 - val_loss: 0.4139 - val_acc: 0.8333\n",
      "Epoch 142/200\n",
      "Epoch 00141: val_loss improved from 0.41225 to 0.41216, saving model to best.model\n",
      "0s - loss: 0.3395 - acc: 0.8537 - val_loss: 0.4122 - val_acc: 0.8667\n",
      "Epoch 143/200\n",
      "Epoch 00142: val_loss improved from 0.41216 to 0.40701, saving model to best.model\n",
      "0s - loss: 0.3100 - acc: 0.8648 - val_loss: 0.4070 - val_acc: 0.8833\n",
      "Epoch 144/200\n",
      "Epoch 00143: val_loss improved from 0.40701 to 0.40134, saving model to best.model\n",
      "0s - loss: 0.3415 - acc: 0.8519 - val_loss: 0.4013 - val_acc: 0.8833\n",
      "Epoch 145/200\n",
      "Epoch 00144: val_loss improved from 0.40134 to 0.39560, saving model to best.model\n",
      "0s - loss: 0.3214 - acc: 0.8574 - val_loss: 0.3956 - val_acc: 0.8667\n",
      "Epoch 146/200\n",
      "Epoch 00145: val_loss improved from 0.39560 to 0.39192, saving model to best.model\n",
      "0s - loss: 0.3066 - acc: 0.8481 - val_loss: 0.3919 - val_acc: 0.8667\n",
      "Epoch 147/200\n",
      "Epoch 00146: val_loss improved from 0.39192 to 0.38931, saving model to best.model\n",
      "0s - loss: 0.3244 - acc: 0.8630 - val_loss: 0.3893 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "Epoch 00147: val_loss improved from 0.38931 to 0.38915, saving model to best.model\n",
      "0s - loss: 0.3210 - acc: 0.8667 - val_loss: 0.3891 - val_acc: 0.8500\n",
      "Epoch 149/200\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 0.3043 - acc: 0.8833 - val_loss: 0.3892 - val_acc: 0.8667\n",
      "Epoch 150/200\n",
      "Epoch 00149: val_loss improved from 0.38915 to 0.38708, saving model to best.model\n",
      "0s - loss: 0.3165 - acc: 0.8741 - val_loss: 0.3871 - val_acc: 0.8500\n",
      "Epoch 151/200\n",
      "Epoch 00150: val_loss improved from 0.38708 to 0.38624, saving model to best.model\n",
      "0s - loss: 0.3215 - acc: 0.8574 - val_loss: 0.3862 - val_acc: 0.8333\n",
      "Epoch 152/200\n",
      "Epoch 00151: val_loss improved from 0.38624 to 0.38560, saving model to best.model\n",
      "0s - loss: 0.3107 - acc: 0.8667 - val_loss: 0.3856 - val_acc: 0.8500\n",
      "Epoch 153/200\n",
      "Epoch 00152: val_loss improved from 0.38560 to 0.38181, saving model to best.model\n",
      "0s - loss: 0.3139 - acc: 0.8815 - val_loss: 0.3818 - val_acc: 0.8333\n",
      "Epoch 154/200\n",
      "Epoch 00153: val_loss did not improve\n",
      "0s - loss: 0.2899 - acc: 0.8630 - val_loss: 0.3875 - val_acc: 0.8667\n",
      "Epoch 155/200\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 0.2971 - acc: 0.8685 - val_loss: 0.3926 - val_acc: 0.8667\n",
      "Epoch 156/200\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 0.3525 - acc: 0.8685 - val_loss: 0.3887 - val_acc: 0.8667\n",
      "Epoch 157/200\n",
      "Epoch 00156: val_loss improved from 0.38181 to 0.37839, saving model to best.model\n",
      "0s - loss: 0.3191 - acc: 0.8611 - val_loss: 0.3784 - val_acc: 0.8667\n",
      "Epoch 158/200\n",
      "Epoch 00157: val_loss improved from 0.37839 to 0.37140, saving model to best.model\n",
      "0s - loss: 0.3287 - acc: 0.8574 - val_loss: 0.3714 - val_acc: 0.8500\n",
      "Epoch 159/200\n",
      "Epoch 00158: val_loss improved from 0.37140 to 0.36896, saving model to best.model\n",
      "0s - loss: 0.3089 - acc: 0.8722 - val_loss: 0.3690 - val_acc: 0.8667\n",
      "Epoch 160/200\n",
      "Epoch 00159: val_loss improved from 0.36896 to 0.36843, saving model to best.model\n",
      "0s - loss: 0.3066 - acc: 0.8685 - val_loss: 0.3684 - val_acc: 0.8667\n",
      "Epoch 161/200\n",
      "Epoch 00160: val_loss improved from 0.36843 to 0.36694, saving model to best.model\n",
      "0s - loss: 0.3001 - acc: 0.8667 - val_loss: 0.3669 - val_acc: 0.8667\n",
      "Epoch 162/200\n",
      "Epoch 00161: val_loss improved from 0.36694 to 0.36507, saving model to best.model\n",
      "0s - loss: 0.3219 - acc: 0.8630 - val_loss: 0.3651 - val_acc: 0.8667\n",
      "Epoch 163/200\n",
      "Epoch 00162: val_loss improved from 0.36507 to 0.36323, saving model to best.model\n",
      "0s - loss: 0.2741 - acc: 0.8870 - val_loss: 0.3632 - val_acc: 0.8833\n",
      "Epoch 164/200\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 0.2874 - acc: 0.8963 - val_loss: 0.3632 - val_acc: 0.8833\n",
      "Epoch 165/200\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 0.3187 - acc: 0.8519 - val_loss: 0.3674 - val_acc: 0.8833\n",
      "Epoch 166/200\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 0.2900 - acc: 0.8796 - val_loss: 0.3716 - val_acc: 0.8833\n",
      "Epoch 167/200\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 0.3061 - acc: 0.8722 - val_loss: 0.3726 - val_acc: 0.8833\n",
      "Epoch 168/200\n",
      "Epoch 00167: val_loss did not improve\n",
      "0s - loss: 0.2871 - acc: 0.8796 - val_loss: 0.3728 - val_acc: 0.8833\n",
      "Epoch 169/200\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 0.2712 - acc: 0.8944 - val_loss: 0.3682 - val_acc: 0.8833\n",
      "Epoch 170/200\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.2903 - acc: 0.8870 - val_loss: 0.3669 - val_acc: 0.8500\n",
      "Epoch 171/200\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 0.2811 - acc: 0.8778 - val_loss: 0.3663 - val_acc: 0.8500\n",
      "Epoch 172/200\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 0.2963 - acc: 0.8741 - val_loss: 0.3647 - val_acc: 0.8500\n",
      "Epoch 173/200\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 0.2429 - acc: 0.9222 - val_loss: 0.3642 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "Epoch 00173: val_loss did not improve\n",
      "0s - loss: 0.2890 - acc: 0.8981 - val_loss: 0.3699 - val_acc: 0.8833\n",
      "Epoch 175/200\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 0.2582 - acc: 0.8926 - val_loss: 0.3784 - val_acc: 0.8667\n",
      "Epoch 176/200\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 0.2954 - acc: 0.8778 - val_loss: 0.3789 - val_acc: 0.8833\n",
      "Epoch 177/200\n",
      "Epoch 00176: val_loss did not improve\n",
      "0s - loss: 0.2491 - acc: 0.8981 - val_loss: 0.3730 - val_acc: 0.8833\n",
      "Epoch 178/200\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 0.2493 - acc: 0.9000 - val_loss: 0.3653 - val_acc: 0.8667\n",
      "Epoch 179/200\n",
      "Epoch 00178: val_loss improved from 0.36323 to 0.35772, saving model to best.model\n",
      "0s - loss: 0.2692 - acc: 0.8926 - val_loss: 0.3577 - val_acc: 0.8667\n",
      "Epoch 180/200\n",
      "Epoch 00179: val_loss improved from 0.35772 to 0.35516, saving model to best.model\n",
      "0s - loss: 0.2448 - acc: 0.8944 - val_loss: 0.3552 - val_acc: 0.8667\n",
      "Epoch 181/200\n",
      "Epoch 00180: val_loss improved from 0.35516 to 0.35304, saving model to best.model\n",
      "0s - loss: 0.2666 - acc: 0.8704 - val_loss: 0.3530 - val_acc: 0.8500\n",
      "Epoch 182/200\n",
      "Epoch 00181: val_loss improved from 0.35304 to 0.34626, saving model to best.model\n",
      "0s - loss: 0.2987 - acc: 0.8796 - val_loss: 0.3463 - val_acc: 0.8667\n",
      "Epoch 183/200\n",
      "Epoch 00182: val_loss improved from 0.34626 to 0.34443, saving model to best.model\n",
      "0s - loss: 0.2492 - acc: 0.9019 - val_loss: 0.3444 - val_acc: 0.8833\n",
      "Epoch 184/200\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 0.2536 - acc: 0.8944 - val_loss: 0.3467 - val_acc: 0.8833\n",
      "Epoch 185/200\n",
      "Epoch 00184: val_loss improved from 0.34443 to 0.34382, saving model to best.model\n",
      "0s - loss: 0.2831 - acc: 0.8889 - val_loss: 0.3438 - val_acc: 0.8833\n",
      "Epoch 186/200\n",
      "Epoch 00185: val_loss improved from 0.34382 to 0.33780, saving model to best.model\n",
      "0s - loss: 0.2495 - acc: 0.8778 - val_loss: 0.3378 - val_acc: 0.8833\n",
      "Epoch 187/200\n",
      "Epoch 00186: val_loss improved from 0.33780 to 0.32920, saving model to best.model\n",
      "0s - loss: 0.2337 - acc: 0.9056 - val_loss: 0.3292 - val_acc: 0.8667\n",
      "Epoch 188/200\n",
      "Epoch 00187: val_loss improved from 0.32920 to 0.32868, saving model to best.model\n",
      "0s - loss: 0.2488 - acc: 0.9000 - val_loss: 0.3287 - val_acc: 0.8667\n",
      "Epoch 189/200\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 0.2715 - acc: 0.8778 - val_loss: 0.3334 - val_acc: 0.8667\n",
      "Epoch 190/200\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.2833 - acc: 0.8796 - val_loss: 0.3347 - val_acc: 0.8667\n",
      "Epoch 191/200\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 0.2692 - acc: 0.8963 - val_loss: 0.3356 - val_acc: 0.8833\n",
      "Epoch 192/200\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 0.2453 - acc: 0.8944 - val_loss: 0.3404 - val_acc: 0.8833\n",
      "Epoch 193/200\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 0.2744 - acc: 0.8833 - val_loss: 0.3462 - val_acc: 0.8667\n",
      "Epoch 194/200\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 0.2555 - acc: 0.8889 - val_loss: 0.3481 - val_acc: 0.8667\n",
      "Epoch 195/200\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 0.2406 - acc: 0.8907 - val_loss: 0.3441 - val_acc: 0.8667\n",
      "Epoch 196/200\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 0.2477 - acc: 0.8981 - val_loss: 0.3406 - val_acc: 0.8500\n",
      "Epoch 197/200\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 0.2452 - acc: 0.9093 - val_loss: 0.3388 - val_acc: 0.8500\n",
      "Epoch 198/200\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 0.2307 - acc: 0.9130 - val_loss: 0.3432 - val_acc: 0.8667\n",
      "Epoch 199/200\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 0.2310 - acc: 0.9204 - val_loss: 0.3499 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.2224 - acc: 0.9056 - val_loss: 0.3448 - val_acc: 0.8667\n",
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/200\n",
      "Epoch 00000: val_loss improved from inf to 0.47091, saving model to best.model\n",
      "0s - loss: 0.9278 - acc: 0.4667 - val_loss: 0.4709 - val_acc: 0.8500\n",
      "Epoch 2/200\n",
      "Epoch 00001: val_loss improved from 0.47091 to 0.40502, saving model to best.model\n",
      "0s - loss: 0.7277 - acc: 0.6278 - val_loss: 0.4050 - val_acc: 0.8500\n",
      "Epoch 3/200\n",
      "Epoch 00002: val_loss improved from 0.40502 to 0.39886, saving model to best.model\n",
      "0s - loss: 0.7111 - acc: 0.6611 - val_loss: 0.3989 - val_acc: 0.8500\n",
      "Epoch 4/200\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.7142 - acc: 0.6611 - val_loss: 0.4080 - val_acc: 0.8500\n",
      "Epoch 5/200\n",
      "Epoch 00004: val_loss did not improve\n",
      "0s - loss: 0.6514 - acc: 0.6815 - val_loss: 0.4282 - val_acc: 0.8500\n",
      "Epoch 6/200\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.6727 - acc: 0.6519 - val_loss: 0.4520 - val_acc: 0.8500\n",
      "Epoch 7/200\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.6127 - acc: 0.6778 - val_loss: 0.4715 - val_acc: 0.8500\n",
      "Epoch 8/200\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.6339 - acc: 0.6778 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 9/200\n",
      "Epoch 00008: val_loss did not improve\n",
      "0s - loss: 0.6324 - acc: 0.6463 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 10/200\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.6086 - acc: 0.6944 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 11/200\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.6300 - acc: 0.6426 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 12/200\n",
      "Epoch 00011: val_loss did not improve\n",
      "0s - loss: 0.5953 - acc: 0.6852 - val_loss: 0.4776 - val_acc: 0.8500\n",
      "Epoch 13/200\n",
      "Epoch 00012: val_loss did not improve\n",
      "0s - loss: 0.6070 - acc: 0.6907 - val_loss: 0.4715 - val_acc: 0.8500\n",
      "Epoch 14/200\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5810 - acc: 0.6944 - val_loss: 0.4672 - val_acc: 0.8500\n",
      "Epoch 15/200\n",
      "Epoch 00014: val_loss did not improve\n",
      "0s - loss: 0.5881 - acc: 0.6704 - val_loss: 0.4689 - val_acc: 0.8500\n",
      "Epoch 16/200\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5999 - acc: 0.7000 - val_loss: 0.4727 - val_acc: 0.8500\n",
      "Epoch 17/200\n",
      "Epoch 00016: val_loss did not improve\n",
      "0s - loss: 0.5858 - acc: 0.6926 - val_loss: 0.4735 - val_acc: 0.8500\n",
      "Epoch 18/200\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5791 - acc: 0.6796 - val_loss: 0.4741 - val_acc: 0.8500\n",
      "Epoch 19/200\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5776 - acc: 0.6870 - val_loss: 0.4717 - val_acc: 0.8500\n",
      "Epoch 20/200\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5792 - acc: 0.7019 - val_loss: 0.4684 - val_acc: 0.8500\n",
      "Epoch 21/200\n",
      "Epoch 00020: val_loss did not improve\n",
      "0s - loss: 0.5627 - acc: 0.7019 - val_loss: 0.4650 - val_acc: 0.8500\n",
      "Epoch 22/200\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 0.5816 - acc: 0.6907 - val_loss: 0.4595 - val_acc: 0.8500\n",
      "Epoch 23/200\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 0.5635 - acc: 0.7056 - val_loss: 0.4508 - val_acc: 0.8500\n",
      "Epoch 24/200\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 0.5686 - acc: 0.7093 - val_loss: 0.4426 - val_acc: 0.8500\n",
      "Epoch 25/200\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 0.5481 - acc: 0.7130 - val_loss: 0.4345 - val_acc: 0.8500\n",
      "Epoch 26/200\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 0.5511 - acc: 0.6944 - val_loss: 0.4265 - val_acc: 0.8500\n",
      "Epoch 27/200\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 0.5356 - acc: 0.7185 - val_loss: 0.4225 - val_acc: 0.8500\n",
      "Epoch 28/200\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 0.5681 - acc: 0.7111 - val_loss: 0.4225 - val_acc: 0.8500\n",
      "Epoch 29/200\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 0.5463 - acc: 0.7037 - val_loss: 0.4300 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(50):\n",
    "    y_pred=train_nn(data_train)\n",
    "    result.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 2],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 2],\n",
       "       ..., \n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 2, 1, 2],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new=np.array(result)\n",
    "result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52, 50, 50, 50, 50, 53, 50, 51, 94, 78, 54, 54, 93, 76, 86, 68, 50,\n",
       "       95, 50, 93, 54, 52, 50, 80, 52, 50, 50, 74, 51, 50, 90, 57, 66, 82,\n",
       "       51, 50, 95, 50, 50, 50, 50, 75, 85, 50, 50, 72, 50, 50, 52, 90, 52,\n",
       "       51, 50, 55, 61, 93, 89, 50, 54, 50, 80, 50, 90, 68, 55, 51, 78, 57,\n",
       "       91, 50, 62, 93, 67, 50, 50, 51, 51, 50, 50, 55, 50, 50, 54, 53, 50,\n",
       "       50, 50, 70, 50, 81, 52, 62, 50, 62, 50, 79, 85, 50, 52, 95, 81, 61,\n",
       "       53, 50, 50, 50, 75, 50, 50, 70, 50, 50, 71, 56, 91, 50, 93, 50, 61,\n",
       "       73, 50, 50, 50, 51, 53, 50, 50, 83, 57, 50, 50, 53, 82, 53, 75, 52,\n",
       "       76, 50, 50, 50, 55, 50, 81, 50, 50, 50, 81, 50, 52, 50, 85, 50, 60,\n",
       "       62, 91, 50, 93, 51, 51, 50, 91, 53, 63, 50, 50, 78, 57, 51, 53, 64,\n",
       "       50, 50, 50, 57, 59, 59, 94, 85, 68, 50, 64, 94, 89, 50, 90, 52, 77,\n",
       "       70, 62, 50, 50, 50, 92, 53, 73, 93, 74, 51, 50, 50, 70, 69, 63, 53,\n",
       "       50, 53, 70, 50, 50, 65, 50, 67, 50, 53, 50, 95, 63, 51, 87, 64, 50,\n",
       "       51, 50, 50, 62, 57, 55, 54, 50, 68, 59, 50, 94, 50, 85, 60, 75, 50,\n",
       "       50, 53, 50, 50, 50, 55, 65, 50, 53, 59, 50, 85])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=result_new.sum(axis=0)\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for each in re:\n",
    "    if each>=68:\n",
    "        y_pred.append(2)\n",
    "    else:\n",
    "        y_pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148  22]\n",
      " [ 32  48]]\n",
      "78.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.82      0.87      0.85       170\n",
      "          2       0.69      0.60      0.64        80\n",
      "\n",
      "avg / total       0.78      0.78      0.78       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cf = confusion_matrix(Y_test.astype(int), y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(Y_test.astype(int), y_pred) * 100) \n",
    "\n",
    "# #Update. 19Jun2017. Included classiifcation report.\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test.astype(int), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bruce/anaconda/lib/python2.7/site-packages/sklearn/tree/export.py:386: DeprecationWarning: out_file can be set to None starting from 0.18. This will be the default in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "export_graphviz(final_model.estimators_[0],\n",
    "                feature_names=X_train.columns,\n",
    "                filled=True,\n",
    "                rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
